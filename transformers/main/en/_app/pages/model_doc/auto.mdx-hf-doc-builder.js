import{S as E3a,i as C3a,s as w3a,e as a,k as l,w as F,t as o,M as A3a,c as n,d as t,m as i,a as s,x as T,h as r,b as m,G as e,g as b,y as M,q as E,o as C,B as w,v as L3a,L as q}from"../../chunks/vendor-hf-doc-builder.js";import{T as GAt}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as B}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as oe}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as N}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function y3a($){let g,v,u,f,p,d,h,$o,bd,zf,Tt,vd,Fd,n$,Qf,Xe,He,Td,ms,s$,cs,fs,l$,Md,gs,i$,Ed,Wf,on;return{c(){g=a("p"),v=o("If your "),u=a("code"),f=o("NewModelConfig"),p=o(" is a subclass of "),d=a("code"),h=o("~transformer.PretrainedConfig"),$o=o(`, make sure its
`),bd=a("code"),zf=o("model_type"),Tt=o(" attribute is set to the same key you use when registering the config (here "),vd=a("code"),Fd=o('"new-model"'),n$=o(")."),Qf=l(),Xe=a("p"),He=o("Likewise, if your "),Td=a("code"),ms=o("NewModel"),s$=o(" is a subclass of "),cs=a("a"),fs=o("PreTrainedModel"),l$=o(`, make sure its
`),Md=a("code"),gs=o("config_class"),i$=o(` attribute is set to the same class you use when registering the model (here
`),Ed=a("code"),Wf=o("NewModelConfig"),on=o(")."),this.h()},l(Je){g=n(Je,"P",{});var Ae=s(g);v=r(Ae,"If your "),u=n(Ae,"CODE",{});var MN=s(u);f=r(MN,"NewModelConfig"),MN.forEach(t),p=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var Cd=s(d);h=r(Cd,"~transformer.PretrainedConfig"),Cd.forEach(t),$o=r(Ae,`, make sure its
`),bd=n(Ae,"CODE",{});var EN=s(bd);zf=r(EN,"model_type"),EN.forEach(t),Tt=r(Ae," attribute is set to the same key you use when registering the config (here "),vd=n(Ae,"CODE",{});var CN=s(vd);Fd=r(CN,'"new-model"'),CN.forEach(t),n$=r(Ae,")."),Ae.forEach(t),Qf=i(Je),Xe=n(Je,"P",{});var ko=s(Xe);He=r(ko,"Likewise, if your "),Td=n(ko,"CODE",{});var rn=s(Td);ms=r(rn,"NewModel"),rn.forEach(t),s$=r(ko," is a subclass of "),cs=n(ko,"A",{href:!0});var wN=s(cs);fs=r(wN,"PreTrainedModel"),wN.forEach(t),l$=r(ko,`, make sure its
`),Md=n(ko,"CODE",{});var Uf=s(Md);gs=r(Uf,"config_class"),Uf.forEach(t),i$=r(ko,` attribute is set to the same class you use when registering the model (here
`),Ed=n(ko,"CODE",{});var AN=s(Ed);Wf=r(AN,"NewModelConfig"),AN.forEach(t),on=r(ko,")."),ko.forEach(t),this.h()},h(){m(cs,"href","/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel")},m(Je,Ae){b(Je,g,Ae),e(g,v),e(g,u),e(u,f),e(g,p),e(g,d),e(d,h),e(g,$o),e(g,bd),e(bd,zf),e(g,Tt),e(g,vd),e(vd,Fd),e(g,n$),b(Je,Qf,Ae),b(Je,Xe,Ae),e(Xe,He),e(Xe,Td),e(Td,ms),e(Xe,s$),e(Xe,cs),e(cs,fs),e(Xe,l$),e(Xe,Md),e(Md,gs),e(Xe,i$),e(Xe,Ed),e(Ed,Wf),e(Xe,on)},d(Je){Je&&t(g),Je&&t(Qf),Je&&t(Xe)}}}function x3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function $3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function k3a($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var $o=s(u);f=r($o,"use_auth_token=True"),$o.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(d){d&&t(g)}}}function S3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function R3a($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var $o=s(u);f=r($o,"use_auth_token=True"),$o.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(d){d&&t(g)}}}function P3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function B3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function I3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function N3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function q3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function j3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function D3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function G3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDepthEstimation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForDepthEstimation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDepthEstimation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function O3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDepthEstimation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForDepthEstimation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForDepthEstimation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForDepthEstimation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDepthEstimation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function V3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function X3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function z3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Q3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function W3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function U3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function H3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function J3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Y3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Z3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function K3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function e5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function o5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function r5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function t5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function a5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function n5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = AutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function s5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/layoutlm_tf_model_config.json")
model = AutoModelForDocumentQuestionAnswering.from_pretrained(
    "./tf_model/layoutlm_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/layoutlm_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/layoutlm_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function l5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function i5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function d5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVideoClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function m5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVideoClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function c5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function f5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function g5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function h5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function u5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function p5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function _5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function b5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function v5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function F5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function T5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function M5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function E5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function C5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function w5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function A5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function L5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function y5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function x5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function $5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function k5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function S5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function R5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function P5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function B5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForZeroShotObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForZeroShotObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForZeroShotObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function I5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForZeroShotObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForZeroShotObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForZeroShotObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForZeroShotObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForZeroShotObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function N5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function q5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function j5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function D5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function G5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function O5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function V5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function X5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function z5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Q5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSemanticSegmentation.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function W5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function U5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function H5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function J5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Y5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Z5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function K5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function e0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function o0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function r0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function t0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function a0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function n0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function s0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/layoutlm_pt_model_config.json")
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
    "./pt_model/layoutlm_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/layoutlm_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/layoutlm_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function l0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function i0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function d0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function m0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function c0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function f0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function g0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function h0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function u0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function p0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function _0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function b0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function v0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function F0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function T0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function M0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function E0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function C0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function w0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function A0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function L0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function y0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function x0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function $0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function k0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function S0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function R0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function P0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function B0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function I0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function N0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function q0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function j0a($){let g,v,u,f,p,d,h,$o,bd,zf,Tt,vd,Fd,n$,Qf,Xe,He,Td,ms,s$,cs,fs,l$,Md,gs,i$,Ed,Wf,on,Je,Ae,MN,Cd,EN,CN,ko,rn,wN,Uf,AN,mio,wto,wd,Hf,cfe,d$,cio,ffe,fio,Ato,hs,gio,gfe,hio,uio,hfe,pio,_io,Lto,m$,yto,LN,bio,xto,Jf,$to,Ad,Yf,ufe,c$,vio,pfe,Fio,kto,So,f$,Tio,g$,Mio,yN,Eio,Cio,wio,h$,Aio,_fe,Lio,yio,xio,qr,u$,$io,bfe,kio,Sio,Ld,Rio,vfe,Pio,Bio,Ffe,Iio,Nio,qio,A,Zf,Tfe,jio,Dio,xN,Gio,Oio,Vio,Kf,Mfe,Xio,zio,$N,Qio,Wio,Uio,eg,Efe,Hio,Jio,kN,Yio,Zio,Kio,og,Cfe,edo,odo,SN,rdo,tdo,ado,rg,wfe,ndo,sdo,RN,ldo,ido,ddo,tg,Afe,mdo,cdo,PN,fdo,gdo,hdo,ag,Lfe,udo,pdo,BN,_do,bdo,vdo,ng,yfe,Fdo,Tdo,IN,Mdo,Edo,Cdo,sg,xfe,wdo,Ado,NN,Ldo,ydo,xdo,lg,$fe,$do,kdo,qN,Sdo,Rdo,Pdo,ig,kfe,Bdo,Ido,jN,Ndo,qdo,jdo,dg,Sfe,Ddo,Gdo,DN,Odo,Vdo,Xdo,mg,Rfe,zdo,Qdo,GN,Wdo,Udo,Hdo,cg,Pfe,Jdo,Ydo,ON,Zdo,Kdo,emo,fg,Bfe,omo,rmo,VN,tmo,amo,nmo,gg,Ife,smo,lmo,XN,imo,dmo,mmo,hg,Nfe,cmo,fmo,zN,gmo,hmo,umo,ug,qfe,pmo,_mo,QN,bmo,vmo,Fmo,pg,jfe,Tmo,Mmo,WN,Emo,Cmo,wmo,_g,Dfe,Amo,Lmo,UN,ymo,xmo,$mo,bg,Gfe,kmo,Smo,HN,Rmo,Pmo,Bmo,vg,Ofe,Imo,Nmo,JN,qmo,jmo,Dmo,Fg,Vfe,Gmo,Omo,YN,Vmo,Xmo,zmo,Tg,Xfe,Qmo,Wmo,ZN,Umo,Hmo,Jmo,Mg,zfe,Ymo,Zmo,KN,Kmo,eco,oco,Eg,Qfe,rco,tco,eq,aco,nco,sco,Cg,Wfe,lco,ico,oq,dco,mco,cco,wg,Ufe,fco,gco,rq,hco,uco,pco,Ag,Hfe,_co,bco,tq,vco,Fco,Tco,Lg,Jfe,Mco,Eco,aq,Cco,wco,Aco,yg,Yfe,Lco,yco,nq,xco,$co,kco,xg,Zfe,Sco,Rco,sq,Pco,Bco,Ico,$g,Kfe,Nco,qco,lq,jco,Dco,Gco,kg,ege,Oco,Vco,iq,Xco,zco,Qco,Sg,oge,Wco,Uco,dq,Hco,Jco,Yco,Rg,rge,Zco,Kco,mq,efo,ofo,rfo,Pg,tge,tfo,afo,cq,nfo,sfo,lfo,Bg,age,ifo,dfo,fq,mfo,cfo,ffo,Ig,nge,gfo,hfo,gq,ufo,pfo,_fo,Ng,sge,bfo,vfo,hq,Ffo,Tfo,Mfo,qg,lge,Efo,Cfo,uq,wfo,Afo,Lfo,jg,ige,yfo,xfo,pq,$fo,kfo,Sfo,Dg,dge,Rfo,Pfo,_q,Bfo,Ifo,Nfo,Gg,mge,qfo,jfo,bq,Dfo,Gfo,Ofo,Og,cge,Vfo,Xfo,vq,zfo,Qfo,Wfo,Vg,fge,Ufo,Hfo,Fq,Jfo,Yfo,Zfo,Xg,gge,Kfo,ego,Tq,ogo,rgo,tgo,zg,hge,ago,ngo,Mq,sgo,lgo,igo,Qg,uge,dgo,mgo,Eq,cgo,fgo,ggo,Wg,pge,hgo,ugo,Cq,pgo,_go,bgo,Ug,_ge,vgo,Fgo,wq,Tgo,Mgo,Ego,Hg,bge,Cgo,wgo,Aq,Ago,Lgo,ygo,Jg,vge,xgo,$go,Lq,kgo,Sgo,Rgo,Yg,Fge,Pgo,Bgo,yq,Igo,Ngo,qgo,Zg,Tge,jgo,Dgo,xq,Ggo,Ogo,Vgo,Kg,Mge,Xgo,zgo,$q,Qgo,Wgo,Ugo,eh,Ege,Hgo,Jgo,kq,Ygo,Zgo,Kgo,oh,Cge,eho,oho,Sq,rho,tho,aho,rh,wge,nho,sho,Rq,lho,iho,dho,th,Age,mho,cho,Pq,fho,gho,hho,ah,Lge,uho,pho,Bq,_ho,bho,vho,nh,yge,Fho,Tho,Iq,Mho,Eho,Cho,sh,xge,who,Aho,Nq,Lho,yho,xho,lh,$ge,$ho,kho,qq,Sho,Rho,Pho,ih,kge,Bho,Iho,jq,Nho,qho,jho,dh,Sge,Dho,Gho,Dq,Oho,Vho,Xho,mh,Rge,zho,Qho,Gq,Who,Uho,Hho,ch,Pge,Jho,Yho,Oq,Zho,Kho,euo,fh,Bge,ouo,ruo,Vq,tuo,auo,nuo,gh,Ige,suo,luo,Xq,iuo,duo,muo,hh,Nge,cuo,fuo,zq,guo,huo,uuo,uh,qge,puo,_uo,Qq,buo,vuo,Fuo,ph,jge,Tuo,Muo,Wq,Euo,Cuo,wuo,_h,Dge,Auo,Luo,Uq,yuo,xuo,$uo,bh,Gge,kuo,Suo,Hq,Ruo,Puo,Buo,vh,Oge,Iuo,Nuo,Jq,quo,juo,Duo,Fh,Vge,Guo,Ouo,Yq,Vuo,Xuo,zuo,Th,Xge,Quo,Wuo,Zq,Uuo,Huo,Juo,Mh,zge,Yuo,Zuo,Kq,Kuo,epo,opo,Eh,Qge,rpo,tpo,ej,apo,npo,spo,Ch,Wge,lpo,ipo,oj,dpo,mpo,cpo,wh,Uge,fpo,gpo,rj,hpo,upo,ppo,Ah,Hge,_po,bpo,tj,vpo,Fpo,Tpo,Lh,Jge,Mpo,Epo,aj,Cpo,wpo,Apo,yh,Yge,Lpo,ypo,nj,xpo,$po,kpo,xh,Zge,Spo,Rpo,sj,Ppo,Bpo,Ipo,$h,Kge,Npo,qpo,lj,jpo,Dpo,Gpo,kh,ehe,Opo,Vpo,ij,Xpo,zpo,Qpo,Sh,ohe,Wpo,Upo,dj,Hpo,Jpo,Ypo,Rh,rhe,Zpo,Kpo,mj,e_o,o_o,r_o,Ph,the,t_o,a_o,cj,n_o,s_o,l_o,Bh,ahe,i_o,d_o,fj,m_o,c_o,f_o,Ih,nhe,g_o,h_o,gj,u_o,p_o,__o,Nh,she,b_o,v_o,hj,F_o,T_o,M_o,qh,lhe,E_o,C_o,uj,w_o,A_o,L_o,jh,ihe,y_o,x_o,pj,$_o,k_o,S_o,Dh,dhe,R_o,P_o,_j,B_o,I_o,N_o,Gh,mhe,q_o,j_o,bj,D_o,G_o,O_o,Oh,che,V_o,X_o,vj,z_o,Q_o,W_o,Vh,fhe,U_o,H_o,Fj,J_o,Y_o,Z_o,Xh,ghe,K_o,e1o,Tj,o1o,r1o,t1o,zh,hhe,a1o,n1o,Mj,s1o,l1o,i1o,Qh,uhe,d1o,m1o,Ej,c1o,f1o,g1o,Wh,phe,h1o,u1o,Cj,p1o,_1o,b1o,Uh,_he,v1o,F1o,wj,T1o,M1o,E1o,Hh,bhe,C1o,w1o,Aj,A1o,L1o,y1o,Jh,vhe,x1o,$1o,Lj,k1o,S1o,R1o,Yh,Fhe,P1o,B1o,yj,I1o,N1o,q1o,Zh,The,j1o,D1o,xj,G1o,O1o,V1o,Kh,Mhe,X1o,z1o,$j,Q1o,W1o,U1o,eu,Ehe,H1o,J1o,kj,Y1o,Z1o,K1o,ou,Che,e2o,o2o,Sj,r2o,t2o,a2o,ru,whe,n2o,s2o,Rj,l2o,i2o,d2o,tu,Ahe,m2o,c2o,Pj,f2o,g2o,h2o,au,Lhe,u2o,p2o,Bj,_2o,b2o,v2o,nu,yhe,F2o,T2o,Ij,M2o,E2o,C2o,su,xhe,w2o,A2o,Nj,L2o,y2o,x2o,lu,$he,$2o,k2o,qj,S2o,R2o,P2o,iu,khe,B2o,I2o,jj,N2o,q2o,j2o,du,She,D2o,G2o,Dj,O2o,V2o,X2o,mu,Rhe,z2o,Q2o,Gj,W2o,U2o,H2o,cu,Phe,J2o,Y2o,Oj,Z2o,K2o,ebo,fu,Bhe,obo,rbo,Vj,tbo,abo,nbo,gu,Ihe,sbo,lbo,Xj,ibo,dbo,mbo,hu,Nhe,cbo,fbo,zj,gbo,hbo,ubo,uu,qhe,pbo,_bo,Qj,bbo,vbo,Fbo,pu,jhe,Tbo,Mbo,Wj,Ebo,Cbo,wbo,_u,Dhe,Abo,Lbo,Uj,ybo,xbo,$bo,bu,Ghe,kbo,Sbo,Hj,Rbo,Pbo,Bbo,vu,Ohe,Ibo,Nbo,Jj,qbo,jbo,Dbo,Fu,Vhe,Gbo,Obo,Yj,Vbo,Xbo,zbo,Tu,Xhe,Qbo,Wbo,Zj,Ubo,Hbo,Jbo,Mu,zhe,Ybo,Zbo,Kj,Kbo,evo,ovo,Eu,Qhe,rvo,tvo,eD,avo,nvo,svo,Cu,Whe,lvo,ivo,oD,dvo,mvo,cvo,wu,fvo,Au,p$,gvo,Uhe,hvo,Sto,yd,Lu,Hhe,_$,uvo,Jhe,pvo,Rto,Ro,b$,_vo,v$,bvo,rD,vvo,Fvo,Tvo,F$,Mvo,Yhe,Evo,Cvo,wvo,jr,T$,Avo,Zhe,Lvo,yvo,tn,xvo,Khe,$vo,kvo,eue,Svo,Rvo,oue,Pvo,Bvo,Ivo,k,us,rue,Nvo,qvo,tD,jvo,Dvo,aD,Gvo,Ovo,Vvo,ps,tue,Xvo,zvo,nD,Qvo,Wvo,sD,Uvo,Hvo,Jvo,_s,aue,Yvo,Zvo,lD,Kvo,eFo,iD,oFo,rFo,tFo,yu,nue,aFo,nFo,dD,sFo,lFo,iFo,bs,sue,dFo,mFo,mD,cFo,fFo,cD,gFo,hFo,uFo,xu,lue,pFo,_Fo,fD,bFo,vFo,FFo,$u,iue,TFo,MFo,gD,EFo,CFo,wFo,ku,due,AFo,LFo,hD,yFo,xFo,$Fo,vs,mue,kFo,SFo,uD,RFo,PFo,pD,BFo,IFo,NFo,Fs,cue,qFo,jFo,_D,DFo,GFo,bD,OFo,VFo,XFo,Ts,fue,zFo,QFo,vD,WFo,UFo,FD,HFo,JFo,YFo,Su,gue,ZFo,KFo,TD,eTo,oTo,rTo,Ru,hue,tTo,aTo,MD,nTo,sTo,lTo,Pu,uue,iTo,dTo,ED,mTo,cTo,fTo,Ms,pue,gTo,hTo,CD,uTo,pTo,wD,_To,bTo,vTo,Bu,_ue,FTo,TTo,AD,MTo,ETo,CTo,Es,bue,wTo,ATo,LD,LTo,yTo,yD,xTo,$To,kTo,Cs,vue,STo,RTo,xD,PTo,BTo,$D,ITo,NTo,qTo,ws,Fue,jTo,DTo,kD,GTo,OTo,SD,VTo,XTo,zTo,As,Tue,QTo,WTo,RD,UTo,HTo,PD,JTo,YTo,ZTo,Iu,Mue,KTo,eMo,BD,oMo,rMo,tMo,Ls,Eue,aMo,nMo,ID,sMo,lMo,ND,iMo,dMo,mMo,ys,Cue,cMo,fMo,qD,gMo,hMo,jD,uMo,pMo,_Mo,xs,wue,bMo,vMo,DD,FMo,TMo,GD,MMo,EMo,CMo,$s,Aue,wMo,AMo,OD,LMo,yMo,VD,xMo,$Mo,kMo,ks,Lue,SMo,RMo,XD,PMo,BMo,zD,IMo,NMo,qMo,Ss,yue,jMo,DMo,QD,GMo,OMo,WD,VMo,XMo,zMo,Rs,xue,QMo,WMo,UD,UMo,HMo,HD,JMo,YMo,ZMo,Nu,$ue,KMo,eEo,JD,oEo,rEo,tEo,qu,kue,aEo,nEo,YD,sEo,lEo,iEo,Ps,Sue,dEo,mEo,ZD,cEo,fEo,KD,gEo,hEo,uEo,ju,Rue,pEo,_Eo,eG,bEo,vEo,FEo,Bs,Pue,TEo,MEo,oG,EEo,CEo,rG,wEo,AEo,LEo,Is,Bue,yEo,xEo,tG,$Eo,kEo,aG,SEo,REo,PEo,Ns,Iue,BEo,IEo,nG,NEo,qEo,sG,jEo,DEo,GEo,Du,Nue,OEo,VEo,lG,XEo,zEo,QEo,Gu,que,WEo,UEo,iG,HEo,JEo,YEo,qs,jue,ZEo,KEo,dG,e4o,o4o,mG,r4o,t4o,a4o,js,Due,n4o,s4o,cG,l4o,i4o,fG,d4o,m4o,c4o,Ds,Gue,f4o,g4o,gG,h4o,u4o,hG,p4o,_4o,b4o,Ou,Oue,v4o,F4o,uG,T4o,M4o,E4o,Gs,Vue,C4o,w4o,pG,A4o,L4o,_G,y4o,x4o,$4o,Os,Xue,k4o,S4o,bG,R4o,P4o,vG,B4o,I4o,N4o,Vs,zue,q4o,j4o,FG,D4o,G4o,TG,O4o,V4o,X4o,Xs,Que,z4o,Q4o,MG,W4o,U4o,EG,H4o,J4o,Y4o,zs,Wue,Z4o,K4o,CG,eCo,oCo,wG,rCo,tCo,aCo,Qs,Uue,nCo,sCo,AG,lCo,iCo,LG,dCo,mCo,cCo,Ws,Hue,fCo,gCo,yG,hCo,uCo,xG,pCo,_Co,bCo,Us,Jue,vCo,FCo,$G,TCo,MCo,kG,ECo,CCo,wCo,Hs,Yue,ACo,LCo,SG,yCo,xCo,RG,$Co,kCo,SCo,Vu,Zue,RCo,PCo,PG,BCo,ICo,NCo,Js,Kue,qCo,jCo,BG,DCo,GCo,IG,OCo,VCo,XCo,Xu,epe,zCo,QCo,NG,WCo,UCo,HCo,zu,ope,JCo,YCo,qG,ZCo,KCo,e3o,Ys,rpe,o3o,r3o,jG,t3o,a3o,DG,n3o,s3o,l3o,Zs,tpe,i3o,d3o,GG,m3o,c3o,OG,f3o,g3o,h3o,Ks,ape,u3o,p3o,VG,_3o,b3o,XG,v3o,F3o,T3o,Qu,npe,M3o,E3o,zG,C3o,w3o,A3o,el,spe,L3o,y3o,QG,x3o,$3o,WG,k3o,S3o,R3o,ol,lpe,P3o,B3o,UG,I3o,N3o,HG,q3o,j3o,D3o,rl,ipe,G3o,O3o,JG,V3o,X3o,YG,z3o,Q3o,W3o,tl,dpe,U3o,H3o,ZG,J3o,Y3o,KG,Z3o,K3o,e5o,al,mpe,o5o,r5o,eO,t5o,a5o,oO,n5o,s5o,l5o,nl,cpe,i5o,d5o,rO,m5o,c5o,tO,f5o,g5o,h5o,sl,fpe,u5o,p5o,aO,_5o,b5o,nO,v5o,F5o,T5o,ll,gpe,M5o,E5o,sO,C5o,w5o,lO,A5o,L5o,y5o,Wu,hpe,x5o,$5o,iO,k5o,S5o,R5o,il,upe,P5o,B5o,dO,I5o,N5o,mO,q5o,j5o,D5o,dl,ppe,G5o,O5o,cO,V5o,X5o,fO,z5o,Q5o,W5o,ml,_pe,U5o,H5o,gO,J5o,Y5o,hO,Z5o,K5o,e0o,Uu,bpe,o0o,r0o,uO,t0o,a0o,n0o,Hu,vpe,s0o,l0o,pO,i0o,d0o,m0o,Ju,Fpe,c0o,f0o,_O,g0o,h0o,u0o,Yu,Tpe,p0o,_0o,bO,b0o,v0o,F0o,cl,Mpe,T0o,M0o,vO,E0o,C0o,FO,w0o,A0o,L0o,Zu,Epe,y0o,x0o,TO,$0o,k0o,S0o,fl,Cpe,R0o,P0o,MO,B0o,I0o,EO,N0o,q0o,j0o,gl,wpe,D0o,G0o,CO,O0o,V0o,wO,X0o,z0o,Q0o,hl,Ape,W0o,U0o,AO,H0o,J0o,LO,Y0o,Z0o,K0o,ul,Lpe,ewo,owo,yO,rwo,two,xO,awo,nwo,swo,pl,ype,lwo,iwo,$O,dwo,mwo,kO,cwo,fwo,gwo,_l,xpe,hwo,uwo,SO,pwo,_wo,RO,bwo,vwo,Fwo,Ku,$pe,Two,Mwo,PO,Ewo,Cwo,wwo,ep,kpe,Awo,Lwo,BO,ywo,xwo,$wo,bl,Spe,kwo,Swo,IO,Rwo,Pwo,NO,Bwo,Iwo,Nwo,vl,Rpe,qwo,jwo,qO,Dwo,Gwo,jO,Owo,Vwo,Xwo,Fl,Ppe,zwo,Qwo,DO,Wwo,Uwo,GO,Hwo,Jwo,Ywo,op,Bpe,Zwo,Kwo,OO,eAo,oAo,rAo,rp,Ipe,tAo,aAo,VO,nAo,sAo,lAo,tp,Npe,iAo,dAo,XO,mAo,cAo,fAo,Tl,qpe,gAo,hAo,zO,uAo,pAo,QO,_Ao,bAo,vAo,Ml,jpe,FAo,TAo,WO,MAo,EAo,UO,CAo,wAo,AAo,ap,Dpe,LAo,yAo,HO,xAo,$Ao,kAo,np,Gpe,SAo,RAo,JO,PAo,BAo,IAo,sp,Ope,NAo,qAo,YO,jAo,DAo,GAo,lp,Vpe,OAo,VAo,ZO,XAo,zAo,QAo,El,Xpe,WAo,UAo,KO,HAo,JAo,eV,YAo,ZAo,KAo,Cl,zpe,e6o,o6o,oV,r6o,t6o,rV,a6o,n6o,s6o,ip,Qpe,l6o,i6o,tV,d6o,m6o,c6o,dp,Wpe,f6o,g6o,aV,h6o,u6o,p6o,wl,Upe,_6o,b6o,nV,v6o,F6o,sV,T6o,M6o,E6o,Al,Hpe,C6o,w6o,lV,A6o,L6o,iV,y6o,x6o,$6o,Ll,Jpe,k6o,S6o,dV,R6o,P6o,mV,B6o,I6o,N6o,yl,Ype,q6o,j6o,cV,D6o,G6o,fV,O6o,V6o,X6o,mp,z6o,cp,M$,Q6o,Zpe,W6o,Pto,xd,fp,Kpe,E$,U6o,e_e,H6o,Bto,Po,C$,J6o,w$,Y6o,gV,Z6o,K6o,e7o,A$,o7o,o_e,r7o,t7o,a7o,Ye,L$,n7o,r_e,s7o,l7o,an,i7o,t_e,d7o,m7o,a_e,c7o,f7o,n_e,g7o,h7o,u7o,z,gp,s_e,p7o,_7o,hV,b7o,v7o,F7o,hp,l_e,T7o,M7o,uV,E7o,C7o,w7o,up,i_e,A7o,L7o,pV,y7o,x7o,$7o,pp,d_e,k7o,S7o,_V,R7o,P7o,B7o,_p,m_e,I7o,N7o,bV,q7o,j7o,D7o,bp,c_e,G7o,O7o,vV,V7o,X7o,z7o,vp,f_e,Q7o,W7o,FV,U7o,H7o,J7o,Fp,g_e,Y7o,Z7o,TV,K7o,e8o,o8o,Tp,h_e,r8o,t8o,MV,a8o,n8o,s8o,Mp,u_e,l8o,i8o,EV,d8o,m8o,c8o,Ep,p_e,f8o,g8o,CV,h8o,u8o,p8o,Cp,__e,_8o,b8o,wV,v8o,F8o,T8o,wp,b_e,M8o,E8o,AV,C8o,w8o,A8o,Ap,v_e,L8o,y8o,LV,x8o,$8o,k8o,Lp,F_e,S8o,R8o,yV,P8o,B8o,I8o,yp,T_e,N8o,q8o,xV,j8o,D8o,G8o,xp,M_e,O8o,V8o,$V,X8o,z8o,Q8o,$p,E_e,W8o,U8o,kV,H8o,J8o,Y8o,kp,C_e,Z8o,K8o,SV,eLo,oLo,rLo,Sp,w_e,tLo,aLo,RV,nLo,sLo,lLo,Rp,A_e,iLo,dLo,PV,mLo,cLo,fLo,Pp,L_e,gLo,hLo,BV,uLo,pLo,_Lo,Bp,y_e,bLo,vLo,IV,FLo,TLo,MLo,Ip,x_e,ELo,CLo,NV,wLo,ALo,LLo,Np,$_e,yLo,xLo,qV,$Lo,kLo,SLo,qp,k_e,RLo,PLo,jV,BLo,ILo,NLo,jp,S_e,qLo,jLo,DV,DLo,GLo,OLo,Dp,R_e,VLo,XLo,GV,zLo,QLo,WLo,Gp,P_e,ULo,HLo,OV,JLo,YLo,ZLo,Op,B_e,KLo,eyo,VV,oyo,ryo,tyo,Vp,I_e,ayo,nyo,XV,syo,lyo,iyo,Xp,N_e,dyo,myo,zV,cyo,fyo,gyo,zp,q_e,hyo,uyo,QV,pyo,_yo,byo,Qp,j_e,vyo,Fyo,WV,Tyo,Myo,Eyo,Wp,D_e,Cyo,wyo,UV,Ayo,Lyo,yyo,Up,G_e,xyo,$yo,HV,kyo,Syo,Ryo,Hp,O_e,Pyo,Byo,JV,Iyo,Nyo,qyo,Jp,V_e,jyo,Dyo,YV,Gyo,Oyo,Vyo,Yp,X_e,Xyo,zyo,ZV,Qyo,Wyo,Uyo,Zp,z_e,Hyo,Jyo,KV,Yyo,Zyo,Kyo,Kp,Q_e,e9o,o9o,eX,r9o,t9o,a9o,e_,W_e,n9o,s9o,oX,l9o,i9o,d9o,o_,U_e,m9o,c9o,rX,f9o,g9o,h9o,r_,H_e,u9o,p9o,tX,_9o,b9o,v9o,t_,F9o,a_,T9o,n_,y$,M9o,J_e,E9o,Ito,$d,s_,Y_e,x$,C9o,Z_e,w9o,Nto,Bo,$$,A9o,k$,L9o,aX,y9o,x9o,$9o,S$,k9o,K_e,S9o,R9o,P9o,Ze,R$,B9o,e1e,I9o,N9o,kd,q9o,o1e,j9o,D9o,r1e,G9o,O9o,V9o,le,l_,t1e,X9o,z9o,nX,Q9o,W9o,U9o,i_,a1e,H9o,J9o,sX,Y9o,Z9o,K9o,d_,n1e,exo,oxo,lX,rxo,txo,axo,m_,s1e,nxo,sxo,iX,lxo,ixo,dxo,c_,l1e,mxo,cxo,dX,fxo,gxo,hxo,f_,i1e,uxo,pxo,mX,_xo,bxo,vxo,g_,d1e,Fxo,Txo,cX,Mxo,Exo,Cxo,h_,m1e,wxo,Axo,fX,Lxo,yxo,xxo,u_,c1e,$xo,kxo,gX,Sxo,Rxo,Pxo,p_,f1e,Bxo,Ixo,hX,Nxo,qxo,jxo,__,g1e,Dxo,Gxo,uX,Oxo,Vxo,Xxo,b_,h1e,zxo,Qxo,pX,Wxo,Uxo,Hxo,v_,u1e,Jxo,Yxo,_X,Zxo,Kxo,e$o,F_,p1e,o$o,r$o,bX,t$o,a$o,n$o,T_,_1e,s$o,l$o,vX,i$o,d$o,m$o,M_,b1e,c$o,f$o,FX,g$o,h$o,u$o,E_,v1e,p$o,_$o,TX,b$o,v$o,F$o,C_,F1e,T$o,M$o,MX,E$o,C$o,w$o,w_,T1e,A$o,L$o,EX,y$o,x$o,$$o,A_,M1e,k$o,S$o,CX,R$o,P$o,B$o,L_,E1e,I$o,N$o,wX,q$o,j$o,D$o,y_,C1e,G$o,O$o,AX,V$o,X$o,z$o,x_,Q$o,$_,W$o,k_,P$,U$o,w1e,H$o,qto,Sd,S_,A1e,B$,J$o,L1e,Y$o,jto,Io,I$,Z$o,Rd,K$o,LX,eko,oko,yX,rko,tko,ako,N$,nko,y1e,sko,lko,iko,Mt,q$,dko,x1e,mko,cko,Pd,fko,$1e,gko,hko,xX,uko,pko,_ko,R_,bko,Ke,j$,vko,k1e,Fko,Tko,nn,Mko,S1e,Eko,Cko,R1e,wko,Ako,P1e,Lko,yko,xko,y,P_,B1e,$ko,kko,$X,Sko,Rko,Pko,B_,I1e,Bko,Iko,kX,Nko,qko,jko,I_,N1e,Dko,Gko,SX,Oko,Vko,Xko,N_,q1e,zko,Qko,RX,Wko,Uko,Hko,q_,j1e,Jko,Yko,PX,Zko,Kko,eSo,j_,D1e,oSo,rSo,BX,tSo,aSo,nSo,D_,G1e,sSo,lSo,IX,iSo,dSo,mSo,G_,O1e,cSo,fSo,NX,gSo,hSo,uSo,O_,V1e,pSo,_So,qX,bSo,vSo,FSo,V_,X1e,TSo,MSo,jX,ESo,CSo,wSo,X_,z1e,ASo,LSo,DX,ySo,xSo,$So,z_,Q1e,kSo,SSo,GX,RSo,PSo,BSo,Q_,W1e,ISo,NSo,OX,qSo,jSo,DSo,W_,U1e,GSo,OSo,VX,VSo,XSo,zSo,U_,H1e,QSo,WSo,XX,USo,HSo,JSo,H_,J1e,YSo,ZSo,zX,KSo,eRo,oRo,J_,Y1e,rRo,tRo,QX,aRo,nRo,sRo,Y_,Z1e,lRo,iRo,WX,dRo,mRo,cRo,Z_,K1e,fRo,gRo,UX,hRo,uRo,pRo,K_,e2e,_Ro,bRo,HX,vRo,FRo,TRo,e1,o2e,MRo,ERo,JX,CRo,wRo,ARo,o1,r2e,LRo,yRo,YX,xRo,$Ro,kRo,r1,t2e,SRo,RRo,ZX,PRo,BRo,IRo,t1,a2e,NRo,qRo,KX,jRo,DRo,GRo,a1,n2e,ORo,VRo,ez,XRo,zRo,QRo,n1,s2e,WRo,URo,oz,HRo,JRo,YRo,s1,l2e,ZRo,KRo,rz,ePo,oPo,rPo,l1,i2e,tPo,aPo,tz,nPo,sPo,lPo,i1,d2e,iPo,dPo,az,mPo,cPo,fPo,d1,m2e,gPo,hPo,nz,uPo,pPo,_Po,m1,c2e,bPo,vPo,sz,FPo,TPo,MPo,c1,f2e,EPo,CPo,lz,wPo,APo,LPo,f1,g2e,yPo,xPo,iz,$Po,kPo,SPo,g1,h2e,RPo,PPo,dz,BPo,IPo,NPo,h1,u2e,qPo,jPo,mz,DPo,GPo,OPo,u1,p2e,VPo,XPo,cz,zPo,QPo,WPo,p1,_2e,UPo,HPo,fz,JPo,YPo,ZPo,_1,b2e,KPo,eBo,gz,oBo,rBo,tBo,b1,v2e,aBo,nBo,hz,sBo,lBo,iBo,xl,F2e,dBo,mBo,uz,cBo,fBo,pz,gBo,hBo,uBo,v1,T2e,pBo,_Bo,_z,bBo,vBo,FBo,F1,M2e,TBo,MBo,bz,EBo,CBo,wBo,T1,E2e,ABo,LBo,vz,yBo,xBo,$Bo,M1,C2e,kBo,SBo,Fz,RBo,PBo,BBo,E1,w2e,IBo,NBo,Tz,qBo,jBo,DBo,C1,A2e,GBo,OBo,Mz,VBo,XBo,zBo,w1,L2e,QBo,WBo,Ez,UBo,HBo,JBo,A1,y2e,YBo,ZBo,Cz,KBo,eIo,oIo,L1,x2e,rIo,tIo,wz,aIo,nIo,sIo,y1,$2e,lIo,iIo,Az,dIo,mIo,cIo,x1,k2e,fIo,gIo,Lz,hIo,uIo,pIo,$1,S2e,_Io,bIo,yz,vIo,FIo,TIo,k1,R2e,MIo,EIo,xz,CIo,wIo,AIo,S1,P2e,LIo,yIo,$z,xIo,$Io,kIo,R1,B2e,SIo,RIo,kz,PIo,BIo,IIo,P1,I2e,NIo,qIo,Sz,jIo,DIo,GIo,B1,N2e,OIo,VIo,Rz,XIo,zIo,QIo,I1,q2e,WIo,UIo,Pz,HIo,JIo,YIo,N1,j2e,ZIo,KIo,Bz,eNo,oNo,rNo,q1,D2e,tNo,aNo,Iz,nNo,sNo,lNo,j1,G2e,iNo,dNo,Nz,mNo,cNo,fNo,D1,O2e,gNo,hNo,qz,uNo,pNo,_No,G1,V2e,bNo,vNo,jz,FNo,TNo,MNo,O1,X2e,ENo,CNo,Dz,wNo,ANo,LNo,V1,z2e,yNo,xNo,Gz,$No,kNo,SNo,X1,Q2e,RNo,PNo,Oz,BNo,INo,NNo,z1,W2e,qNo,jNo,Vz,DNo,GNo,ONo,Q1,U2e,VNo,XNo,Xz,zNo,QNo,WNo,W1,H2e,UNo,HNo,zz,JNo,YNo,ZNo,U1,J2e,KNo,eqo,Qz,oqo,rqo,tqo,H1,Y2e,aqo,nqo,Wz,sqo,lqo,iqo,J1,Z2e,dqo,mqo,Uz,cqo,fqo,gqo,Y1,K2e,hqo,uqo,Hz,pqo,_qo,bqo,Z1,ebe,vqo,Fqo,Jz,Tqo,Mqo,Eqo,K1,obe,Cqo,wqo,Yz,Aqo,Lqo,yqo,e2,rbe,xqo,$qo,Zz,kqo,Sqo,Rqo,o2,tbe,Pqo,Bqo,Kz,Iqo,Nqo,qqo,r2,abe,jqo,Dqo,eQ,Gqo,Oqo,Vqo,t2,nbe,Xqo,zqo,oQ,Qqo,Wqo,Uqo,a2,sbe,Hqo,Jqo,rQ,Yqo,Zqo,Kqo,n2,lbe,ejo,ojo,tQ,rjo,tjo,ajo,s2,ibe,njo,sjo,aQ,ljo,ijo,djo,l2,dbe,mjo,cjo,nQ,fjo,gjo,hjo,i2,mbe,ujo,pjo,sQ,_jo,bjo,vjo,d2,cbe,Fjo,Tjo,lQ,Mjo,Ejo,Cjo,m2,fbe,wjo,Ajo,iQ,Ljo,yjo,xjo,c2,gbe,$jo,kjo,dQ,Sjo,Rjo,Pjo,f2,hbe,Bjo,Ijo,mQ,Njo,qjo,jjo,g2,ube,Djo,Gjo,cQ,Ojo,Vjo,Xjo,h2,pbe,zjo,Qjo,fQ,Wjo,Ujo,Hjo,u2,_be,Jjo,Yjo,gQ,Zjo,Kjo,eDo,p2,bbe,oDo,rDo,hQ,tDo,aDo,nDo,_2,vbe,sDo,lDo,uQ,iDo,dDo,mDo,b2,Fbe,cDo,fDo,pQ,gDo,hDo,uDo,v2,Tbe,pDo,_Do,_Q,bDo,vDo,FDo,F2,Mbe,TDo,MDo,bQ,EDo,CDo,wDo,T2,Ebe,ADo,LDo,vQ,yDo,xDo,$Do,M2,Cbe,kDo,SDo,FQ,RDo,PDo,BDo,E2,wbe,IDo,NDo,TQ,qDo,jDo,DDo,C2,Abe,GDo,ODo,MQ,VDo,XDo,zDo,w2,Lbe,QDo,WDo,EQ,UDo,HDo,JDo,A2,ybe,YDo,ZDo,CQ,KDo,eGo,oGo,L2,xbe,rGo,tGo,wQ,aGo,nGo,sGo,y2,$be,lGo,iGo,AQ,dGo,mGo,cGo,x2,kbe,fGo,gGo,LQ,hGo,uGo,pGo,$2,Sbe,_Go,bGo,yQ,vGo,FGo,TGo,k2,Rbe,MGo,EGo,xQ,CGo,wGo,AGo,S2,Pbe,LGo,yGo,$Q,xGo,$Go,kGo,R2,Bbe,SGo,RGo,kQ,PGo,BGo,IGo,P2,Ibe,NGo,qGo,SQ,jGo,DGo,GGo,B2,Nbe,OGo,VGo,RQ,XGo,zGo,QGo,I2,qbe,WGo,UGo,PQ,HGo,JGo,YGo,N2,jbe,ZGo,KGo,BQ,eOo,oOo,rOo,q2,Dbe,tOo,aOo,IQ,nOo,sOo,lOo,j2,Gbe,iOo,dOo,NQ,mOo,cOo,fOo,D2,Obe,gOo,hOo,qQ,uOo,pOo,_Oo,G2,Vbe,bOo,vOo,jQ,FOo,TOo,MOo,O2,Xbe,EOo,COo,DQ,wOo,AOo,LOo,V2,zbe,yOo,xOo,GQ,$Oo,kOo,SOo,X2,Qbe,ROo,POo,OQ,BOo,IOo,NOo,z2,Wbe,qOo,jOo,VQ,DOo,GOo,OOo,Q2,Ube,VOo,XOo,XQ,zOo,QOo,WOo,W2,Hbe,UOo,HOo,zQ,JOo,YOo,ZOo,U2,Jbe,KOo,eVo,QQ,oVo,rVo,tVo,H2,Ybe,aVo,nVo,WQ,sVo,lVo,iVo,J2,Zbe,dVo,mVo,UQ,cVo,fVo,gVo,Y2,Kbe,hVo,uVo,HQ,pVo,_Vo,bVo,Z2,eve,vVo,FVo,JQ,TVo,MVo,EVo,K2,ove,CVo,wVo,YQ,AVo,LVo,yVo,eb,xVo,rve,$Vo,kVo,tve,SVo,RVo,ob,Dto,Bd,rb,ave,D$,PVo,nve,BVo,Gto,No,G$,IVo,Id,NVo,ZQ,qVo,jVo,KQ,DVo,GVo,OVo,O$,VVo,sve,XVo,zVo,QVo,Et,V$,WVo,lve,UVo,HVo,Nd,JVo,ive,YVo,ZVo,eW,KVo,eXo,oXo,tb,rXo,eo,X$,tXo,dve,aXo,nXo,sn,sXo,mve,lXo,iXo,cve,dXo,mXo,fve,cXo,fXo,gXo,G,ab,gve,hXo,uXo,oW,pXo,_Xo,bXo,nb,hve,vXo,FXo,rW,TXo,MXo,EXo,sb,uve,CXo,wXo,tW,AXo,LXo,yXo,lb,pve,xXo,$Xo,aW,kXo,SXo,RXo,ib,_ve,PXo,BXo,nW,IXo,NXo,qXo,db,bve,jXo,DXo,sW,GXo,OXo,VXo,mb,vve,XXo,zXo,lW,QXo,WXo,UXo,cb,Fve,HXo,JXo,iW,YXo,ZXo,KXo,fb,Tve,ezo,ozo,dW,rzo,tzo,azo,gb,Mve,nzo,szo,mW,lzo,izo,dzo,hb,Eve,mzo,czo,cW,fzo,gzo,hzo,ub,Cve,uzo,pzo,fW,_zo,bzo,vzo,pb,wve,Fzo,Tzo,gW,Mzo,Ezo,Czo,_b,Ave,wzo,Azo,hW,Lzo,yzo,xzo,bb,Lve,$zo,kzo,uW,Szo,Rzo,Pzo,vb,yve,Bzo,Izo,pW,Nzo,qzo,jzo,Fb,xve,Dzo,Gzo,_W,Ozo,Vzo,Xzo,Tb,$ve,zzo,Qzo,bW,Wzo,Uzo,Hzo,Mb,kve,Jzo,Yzo,vW,Zzo,Kzo,eQo,Eb,Sve,oQo,rQo,FW,tQo,aQo,nQo,Cb,Rve,sQo,lQo,TW,iQo,dQo,mQo,wb,Pve,cQo,fQo,MW,gQo,hQo,uQo,Ab,Bve,pQo,_Qo,EW,bQo,vQo,FQo,Lb,Ive,TQo,MQo,CW,EQo,CQo,wQo,yb,Nve,AQo,LQo,wW,yQo,xQo,$Qo,xb,qve,kQo,SQo,AW,RQo,PQo,BQo,$b,jve,IQo,NQo,LW,qQo,jQo,DQo,kb,Dve,GQo,OQo,yW,VQo,XQo,zQo,Sb,Gve,QQo,WQo,xW,UQo,HQo,JQo,Rb,Ove,YQo,ZQo,$W,KQo,eWo,oWo,Pb,Vve,rWo,tWo,kW,aWo,nWo,sWo,Bb,Xve,lWo,iWo,SW,dWo,mWo,cWo,Ib,zve,fWo,gWo,RW,hWo,uWo,pWo,Nb,Qve,_Wo,bWo,PW,vWo,FWo,TWo,qb,Wve,MWo,EWo,BW,CWo,wWo,AWo,jb,Uve,LWo,yWo,IW,xWo,$Wo,kWo,Db,Hve,SWo,RWo,NW,PWo,BWo,IWo,Gb,Jve,NWo,qWo,qW,jWo,DWo,GWo,Ob,Yve,OWo,VWo,jW,XWo,zWo,QWo,Vb,Zve,WWo,UWo,DW,HWo,JWo,YWo,Xb,Kve,ZWo,KWo,GW,eUo,oUo,rUo,zb,eFe,tUo,aUo,OW,nUo,sUo,lUo,Qb,oFe,iUo,dUo,VW,mUo,cUo,fUo,Wb,rFe,gUo,hUo,XW,uUo,pUo,_Uo,Ub,tFe,bUo,vUo,zW,FUo,TUo,MUo,Hb,aFe,EUo,CUo,QW,wUo,AUo,LUo,Jb,nFe,yUo,xUo,WW,$Uo,kUo,SUo,Yb,sFe,RUo,PUo,UW,BUo,IUo,NUo,Zb,qUo,lFe,jUo,DUo,iFe,GUo,OUo,Kb,Oto,qd,ev,dFe,z$,VUo,mFe,XUo,Vto,qo,Q$,zUo,jd,QUo,HW,WUo,UUo,JW,HUo,JUo,YUo,W$,ZUo,cFe,KUo,eHo,oHo,Ct,U$,rHo,fFe,tHo,aHo,Dd,nHo,gFe,sHo,lHo,YW,iHo,dHo,mHo,ov,cHo,oo,H$,fHo,hFe,gHo,hHo,ln,uHo,uFe,pHo,_Ho,pFe,bHo,vHo,_Fe,FHo,THo,MHo,W,rv,bFe,EHo,CHo,ZW,wHo,AHo,LHo,tv,vFe,yHo,xHo,KW,$Ho,kHo,SHo,av,FFe,RHo,PHo,eU,BHo,IHo,NHo,nv,TFe,qHo,jHo,oU,DHo,GHo,OHo,sv,MFe,VHo,XHo,rU,zHo,QHo,WHo,lv,EFe,UHo,HHo,tU,JHo,YHo,ZHo,iv,CFe,KHo,eJo,aU,oJo,rJo,tJo,dv,wFe,aJo,nJo,nU,sJo,lJo,iJo,mv,AFe,dJo,mJo,sU,cJo,fJo,gJo,cv,LFe,hJo,uJo,lU,pJo,_Jo,bJo,fv,yFe,vJo,FJo,iU,TJo,MJo,EJo,gv,xFe,CJo,wJo,dU,AJo,LJo,yJo,hv,$Fe,xJo,$Jo,mU,kJo,SJo,RJo,uv,kFe,PJo,BJo,cU,IJo,NJo,qJo,pv,SFe,jJo,DJo,fU,GJo,OJo,VJo,_v,RFe,XJo,zJo,gU,QJo,WJo,UJo,bv,PFe,HJo,JJo,hU,YJo,ZJo,KJo,vv,BFe,eYo,oYo,uU,rYo,tYo,aYo,Fv,IFe,nYo,sYo,pU,lYo,iYo,dYo,Tv,NFe,mYo,cYo,_U,fYo,gYo,hYo,Mv,qFe,uYo,pYo,bU,_Yo,bYo,vYo,Ev,jFe,FYo,TYo,vU,MYo,EYo,CYo,Cv,DFe,wYo,AYo,FU,LYo,yYo,xYo,wv,GFe,$Yo,kYo,TU,SYo,RYo,PYo,Av,OFe,BYo,IYo,MU,NYo,qYo,jYo,Lv,VFe,DYo,GYo,EU,OYo,VYo,XYo,yv,XFe,zYo,QYo,CU,WYo,UYo,HYo,xv,zFe,JYo,YYo,wU,ZYo,KYo,eZo,$v,QFe,oZo,rZo,AU,tZo,aZo,nZo,kv,WFe,sZo,lZo,LU,iZo,dZo,mZo,Sv,UFe,cZo,fZo,yU,gZo,hZo,uZo,Rv,HFe,pZo,_Zo,xU,bZo,vZo,FZo,Pv,JFe,TZo,MZo,$U,EZo,CZo,wZo,Bv,YFe,AZo,LZo,kU,yZo,xZo,$Zo,Iv,ZFe,kZo,SZo,SU,RZo,PZo,BZo,Nv,KFe,IZo,NZo,RU,qZo,jZo,DZo,qv,eTe,GZo,OZo,PU,VZo,XZo,zZo,jv,oTe,QZo,WZo,BU,UZo,HZo,JZo,Dv,rTe,YZo,ZZo,IU,KZo,eKo,oKo,Gv,tTe,rKo,tKo,NU,aKo,nKo,sKo,Ov,aTe,lKo,iKo,qU,dKo,mKo,cKo,Vv,nTe,fKo,gKo,jU,hKo,uKo,pKo,Xv,_Ko,sTe,bKo,vKo,lTe,FKo,TKo,zv,Xto,Gd,Qv,iTe,J$,MKo,dTe,EKo,zto,jo,Y$,CKo,Od,wKo,DU,AKo,LKo,GU,yKo,xKo,$Ko,Z$,kKo,mTe,SKo,RKo,PKo,wt,K$,BKo,cTe,IKo,NKo,Vd,qKo,fTe,jKo,DKo,OU,GKo,OKo,VKo,Wv,XKo,ro,ek,zKo,gTe,QKo,WKo,dn,UKo,hTe,HKo,JKo,uTe,YKo,ZKo,pTe,KKo,eer,oer,ok,Uv,_Te,rer,ter,VU,aer,ner,ser,Hv,bTe,ler,ier,XU,der,mer,cer,Jv,fer,vTe,ger,her,FTe,uer,per,Yv,Qto,Xd,Zv,TTe,rk,_er,MTe,ber,Wto,Do,tk,ver,zd,Fer,zU,Ter,Mer,QU,Eer,Cer,wer,ak,Aer,ETe,Ler,yer,xer,At,nk,$er,CTe,ker,Ser,Qd,Rer,wTe,Per,Ber,WU,Ier,Ner,qer,Kv,jer,to,sk,Der,ATe,Ger,Oer,mn,Ver,LTe,Xer,zer,yTe,Qer,Wer,xTe,Uer,Her,Jer,Y,eF,$Te,Yer,Zer,UU,Ker,eor,oor,oF,kTe,ror,tor,HU,aor,nor,sor,rF,STe,lor,ior,JU,dor,mor,cor,tF,RTe,gor,hor,YU,uor,por,_or,aF,PTe,bor,vor,ZU,For,Tor,Mor,nF,BTe,Eor,Cor,KU,wor,Aor,Lor,sF,ITe,yor,xor,eH,$or,kor,Sor,lF,NTe,Ror,Por,oH,Bor,Ior,Nor,iF,qTe,qor,jor,rH,Dor,Gor,Oor,dF,jTe,Vor,Xor,tH,zor,Qor,Wor,mF,DTe,Uor,Hor,aH,Jor,Yor,Zor,cF,GTe,Kor,err,nH,orr,rrr,trr,fF,OTe,arr,nrr,sH,srr,lrr,irr,gF,VTe,drr,mrr,lH,crr,frr,grr,hF,XTe,hrr,urr,iH,prr,_rr,brr,uF,zTe,vrr,Frr,dH,Trr,Mrr,Err,pF,QTe,Crr,wrr,mH,Arr,Lrr,yrr,_F,WTe,xrr,$rr,cH,krr,Srr,Rrr,bF,UTe,Prr,Brr,fH,Irr,Nrr,qrr,vF,HTe,jrr,Drr,gH,Grr,Orr,Vrr,FF,JTe,Xrr,zrr,hH,Qrr,Wrr,Urr,TF,YTe,Hrr,Jrr,uH,Yrr,Zrr,Krr,MF,ZTe,etr,otr,pH,rtr,ttr,atr,EF,KTe,ntr,str,_H,ltr,itr,dtr,CF,eMe,mtr,ctr,bH,ftr,gtr,htr,wF,oMe,utr,ptr,vH,_tr,btr,vtr,AF,rMe,Ftr,Ttr,FH,Mtr,Etr,Ctr,LF,tMe,wtr,Atr,TH,Ltr,ytr,xtr,yF,aMe,$tr,ktr,MH,Str,Rtr,Ptr,xF,nMe,Btr,Itr,EH,Ntr,qtr,jtr,$F,sMe,Dtr,Gtr,CH,Otr,Vtr,Xtr,kF,lMe,ztr,Qtr,wH,Wtr,Utr,Htr,SF,iMe,Jtr,Ytr,AH,Ztr,Ktr,ear,RF,dMe,oar,rar,LH,tar,aar,nar,PF,mMe,sar,lar,cMe,iar,dar,mar,BF,fMe,car,far,yH,gar,har,uar,IF,gMe,par,_ar,xH,bar,Far,Tar,NF,hMe,Mar,Ear,$H,Car,war,Aar,qF,uMe,Lar,yar,kH,xar,$ar,kar,jF,Sar,pMe,Rar,Par,_Me,Bar,Iar,DF,Uto,Wd,GF,bMe,lk,Nar,vMe,qar,Hto,Go,ik,jar,Ud,Dar,SH,Gar,Oar,RH,Var,Xar,zar,dk,Qar,FMe,War,Uar,Har,Lt,mk,Jar,TMe,Yar,Zar,Hd,Kar,MMe,enr,onr,PH,rnr,tnr,anr,OF,nnr,ao,ck,snr,EMe,lnr,inr,cn,dnr,CMe,mnr,cnr,wMe,fnr,gnr,AMe,hnr,unr,pnr,he,VF,LMe,_nr,bnr,BH,vnr,Fnr,Tnr,XF,yMe,Mnr,Enr,IH,Cnr,wnr,Anr,zF,xMe,Lnr,ynr,NH,xnr,$nr,knr,QF,$Me,Snr,Rnr,qH,Pnr,Bnr,Inr,WF,kMe,Nnr,qnr,jH,jnr,Dnr,Gnr,UF,SMe,Onr,Vnr,DH,Xnr,znr,Qnr,HF,RMe,Wnr,Unr,GH,Hnr,Jnr,Ynr,JF,PMe,Znr,Knr,OH,esr,osr,rsr,YF,BMe,tsr,asr,VH,nsr,ssr,lsr,ZF,IMe,isr,dsr,XH,msr,csr,fsr,KF,NMe,gsr,hsr,zH,usr,psr,_sr,eT,qMe,bsr,vsr,QH,Fsr,Tsr,Msr,oT,jMe,Esr,Csr,WH,wsr,Asr,Lsr,rT,DMe,ysr,xsr,UH,$sr,ksr,Ssr,tT,GMe,Rsr,Psr,HH,Bsr,Isr,Nsr,aT,OMe,qsr,jsr,JH,Dsr,Gsr,Osr,nT,VMe,Vsr,Xsr,YH,zsr,Qsr,Wsr,sT,XMe,Usr,Hsr,ZH,Jsr,Ysr,Zsr,lT,zMe,Ksr,elr,KH,olr,rlr,tlr,iT,QMe,alr,nlr,eJ,slr,llr,ilr,dT,dlr,WMe,mlr,clr,UMe,flr,glr,mT,Jto,Jd,cT,HMe,fk,hlr,JMe,ulr,Yto,Oo,gk,plr,Yd,_lr,oJ,blr,vlr,rJ,Flr,Tlr,Mlr,hk,Elr,YMe,Clr,wlr,Alr,yt,uk,Llr,ZMe,ylr,xlr,Zd,$lr,KMe,klr,Slr,tJ,Rlr,Plr,Blr,fT,Ilr,no,pk,Nlr,eEe,qlr,jlr,fn,Dlr,oEe,Glr,Olr,rEe,Vlr,Xlr,tEe,zlr,Qlr,Wlr,j,gT,aEe,Ulr,Hlr,aJ,Jlr,Ylr,Zlr,hT,nEe,Klr,eir,nJ,oir,rir,tir,uT,sEe,air,nir,sJ,sir,lir,iir,pT,lEe,dir,mir,lJ,cir,fir,gir,_T,iEe,hir,uir,iJ,pir,_ir,bir,bT,dEe,vir,Fir,dJ,Tir,Mir,Eir,vT,mEe,Cir,wir,mJ,Air,Lir,yir,FT,cEe,xir,$ir,cJ,kir,Sir,Rir,TT,fEe,Pir,Bir,fJ,Iir,Nir,qir,MT,gEe,jir,Dir,gJ,Gir,Oir,Vir,ET,hEe,Xir,zir,hJ,Qir,Wir,Uir,CT,uEe,Hir,Jir,uJ,Yir,Zir,Kir,wT,pEe,edr,odr,pJ,rdr,tdr,adr,AT,_Ee,ndr,sdr,_J,ldr,idr,ddr,LT,bEe,mdr,cdr,bJ,fdr,gdr,hdr,yT,vEe,udr,pdr,vJ,_dr,bdr,vdr,xT,FEe,Fdr,Tdr,FJ,Mdr,Edr,Cdr,$T,TEe,wdr,Adr,TJ,Ldr,ydr,xdr,kT,MEe,$dr,kdr,MJ,Sdr,Rdr,Pdr,ST,EEe,Bdr,Idr,EJ,Ndr,qdr,jdr,RT,CEe,Ddr,Gdr,CJ,Odr,Vdr,Xdr,PT,wEe,zdr,Qdr,wJ,Wdr,Udr,Hdr,BT,AEe,Jdr,Ydr,AJ,Zdr,Kdr,emr,IT,LEe,omr,rmr,LJ,tmr,amr,nmr,NT,yEe,smr,lmr,yJ,imr,dmr,mmr,qT,xEe,cmr,fmr,xJ,gmr,hmr,umr,jT,$Ee,pmr,_mr,$J,bmr,vmr,Fmr,DT,kEe,Tmr,Mmr,kJ,Emr,Cmr,wmr,GT,SEe,Amr,Lmr,SJ,ymr,xmr,$mr,OT,REe,kmr,Smr,RJ,Rmr,Pmr,Bmr,VT,PEe,Imr,Nmr,PJ,qmr,jmr,Dmr,XT,BEe,Gmr,Omr,BJ,Vmr,Xmr,zmr,zT,IEe,Qmr,Wmr,IJ,Umr,Hmr,Jmr,QT,NEe,Ymr,Zmr,NJ,Kmr,ecr,ocr,WT,qEe,rcr,tcr,qJ,acr,ncr,scr,UT,jEe,lcr,icr,jJ,dcr,mcr,ccr,HT,DEe,fcr,gcr,DJ,hcr,ucr,pcr,JT,GEe,_cr,bcr,GJ,vcr,Fcr,Tcr,YT,OEe,Mcr,Ecr,OJ,Ccr,wcr,Acr,ZT,VEe,Lcr,ycr,VJ,xcr,$cr,kcr,KT,XEe,Scr,Rcr,XJ,Pcr,Bcr,Icr,eM,zEe,Ncr,qcr,zJ,jcr,Dcr,Gcr,oM,QEe,Ocr,Vcr,QJ,Xcr,zcr,Qcr,rM,WEe,Wcr,Ucr,WJ,Hcr,Jcr,Ycr,tM,UEe,Zcr,Kcr,UJ,efr,ofr,rfr,aM,HEe,tfr,afr,HJ,nfr,sfr,lfr,nM,JEe,ifr,dfr,JJ,mfr,cfr,ffr,sM,YEe,gfr,hfr,YJ,ufr,pfr,_fr,lM,ZEe,bfr,vfr,ZJ,Ffr,Tfr,Mfr,iM,KEe,Efr,Cfr,KJ,wfr,Afr,Lfr,dM,e4e,yfr,xfr,eY,$fr,kfr,Sfr,mM,o4e,Rfr,Pfr,oY,Bfr,Ifr,Nfr,cM,r4e,qfr,jfr,rY,Dfr,Gfr,Ofr,fM,t4e,Vfr,Xfr,tY,zfr,Qfr,Wfr,gM,a4e,Ufr,Hfr,aY,Jfr,Yfr,Zfr,hM,n4e,Kfr,egr,nY,ogr,rgr,tgr,uM,agr,s4e,ngr,sgr,l4e,lgr,igr,pM,Zto,Kd,_M,i4e,_k,dgr,d4e,mgr,Kto,Vo,bk,cgr,em,fgr,sY,ggr,hgr,lY,ugr,pgr,_gr,vk,bgr,m4e,vgr,Fgr,Tgr,xt,Fk,Mgr,c4e,Egr,Cgr,om,wgr,f4e,Agr,Lgr,iY,ygr,xgr,$gr,bM,kgr,so,Tk,Sgr,g4e,Rgr,Pgr,gn,Bgr,h4e,Igr,Ngr,u4e,qgr,jgr,p4e,Dgr,Ggr,Ogr,K,vM,_4e,Vgr,Xgr,dY,zgr,Qgr,Wgr,FM,b4e,Ugr,Hgr,mY,Jgr,Ygr,Zgr,TM,v4e,Kgr,ehr,cY,ohr,rhr,thr,MM,F4e,ahr,nhr,fY,shr,lhr,ihr,EM,T4e,dhr,mhr,gY,chr,fhr,ghr,CM,M4e,hhr,uhr,hY,phr,_hr,bhr,wM,E4e,vhr,Fhr,uY,Thr,Mhr,Ehr,AM,C4e,Chr,whr,pY,Ahr,Lhr,yhr,LM,w4e,xhr,$hr,_Y,khr,Shr,Rhr,yM,A4e,Phr,Bhr,bY,Ihr,Nhr,qhr,xM,L4e,jhr,Dhr,vY,Ghr,Ohr,Vhr,$M,y4e,Xhr,zhr,FY,Qhr,Whr,Uhr,kM,x4e,Hhr,Jhr,TY,Yhr,Zhr,Khr,SM,$4e,eur,our,MY,rur,tur,aur,RM,k4e,nur,sur,EY,lur,iur,dur,PM,S4e,mur,cur,CY,fur,gur,hur,BM,R4e,uur,pur,wY,_ur,bur,vur,IM,P4e,Fur,Tur,AY,Mur,Eur,Cur,NM,B4e,wur,Aur,LY,Lur,yur,xur,qM,I4e,$ur,kur,yY,Sur,Rur,Pur,jM,N4e,Bur,Iur,xY,Nur,qur,jur,DM,q4e,Dur,Gur,$Y,Our,Vur,Xur,GM,j4e,zur,Qur,kY,Wur,Uur,Hur,OM,D4e,Jur,Yur,SY,Zur,Kur,epr,VM,G4e,opr,rpr,RY,tpr,apr,npr,XM,O4e,spr,lpr,PY,ipr,dpr,mpr,zM,V4e,cpr,fpr,BY,gpr,hpr,upr,QM,X4e,ppr,_pr,IY,bpr,vpr,Fpr,WM,z4e,Tpr,Mpr,NY,Epr,Cpr,wpr,UM,Q4e,Apr,Lpr,qY,ypr,xpr,$pr,HM,W4e,kpr,Spr,jY,Rpr,Ppr,Bpr,JM,U4e,Ipr,Npr,DY,qpr,jpr,Dpr,YM,Gpr,H4e,Opr,Vpr,J4e,Xpr,zpr,ZM,eao,rm,KM,Y4e,Mk,Qpr,Z4e,Wpr,oao,Xo,Ek,Upr,tm,Hpr,GY,Jpr,Ypr,OY,Zpr,Kpr,e_r,Ck,o_r,K4e,r_r,t_r,a_r,$t,wk,n_r,eCe,s_r,l_r,am,i_r,oCe,d_r,m_r,VY,c_r,f_r,g_r,eE,h_r,lo,Ak,u_r,rCe,p_r,__r,hn,b_r,tCe,v_r,F_r,aCe,T_r,M_r,nCe,E_r,C_r,w_r,Ue,oE,sCe,A_r,L_r,XY,y_r,x_r,$_r,rE,lCe,k_r,S_r,zY,R_r,P_r,B_r,tE,iCe,I_r,N_r,QY,q_r,j_r,D_r,aE,dCe,G_r,O_r,WY,V_r,X_r,z_r,nE,mCe,Q_r,W_r,UY,U_r,H_r,J_r,sE,cCe,Y_r,Z_r,HY,K_r,e1r,o1r,lE,fCe,r1r,t1r,JY,a1r,n1r,s1r,iE,l1r,gCe,i1r,d1r,hCe,m1r,c1r,dE,rao,nm,mE,uCe,Lk,f1r,pCe,g1r,tao,zo,yk,h1r,sm,u1r,YY,p1r,_1r,ZY,b1r,v1r,F1r,xk,T1r,_Ce,M1r,E1r,C1r,kt,$k,w1r,bCe,A1r,L1r,lm,y1r,vCe,x1r,$1r,KY,k1r,S1r,R1r,cE,P1r,io,kk,B1r,FCe,I1r,N1r,un,q1r,TCe,j1r,D1r,MCe,G1r,O1r,ECe,V1r,X1r,z1r,U,fE,CCe,Q1r,W1r,eZ,U1r,H1r,J1r,gE,wCe,Y1r,Z1r,oZ,K1r,e2r,o2r,hE,ACe,r2r,t2r,rZ,a2r,n2r,s2r,uE,LCe,l2r,i2r,tZ,d2r,m2r,c2r,pE,yCe,f2r,g2r,aZ,h2r,u2r,p2r,_E,xCe,_2r,b2r,nZ,v2r,F2r,T2r,bE,$Ce,M2r,E2r,sZ,C2r,w2r,A2r,vE,kCe,L2r,y2r,lZ,x2r,$2r,k2r,FE,SCe,S2r,R2r,iZ,P2r,B2r,I2r,TE,RCe,N2r,q2r,dZ,j2r,D2r,G2r,ME,PCe,O2r,V2r,mZ,X2r,z2r,Q2r,EE,BCe,W2r,U2r,cZ,H2r,J2r,Y2r,CE,ICe,Z2r,K2r,fZ,ebr,obr,rbr,wE,NCe,tbr,abr,gZ,nbr,sbr,lbr,AE,qCe,ibr,dbr,hZ,mbr,cbr,fbr,LE,jCe,gbr,hbr,uZ,ubr,pbr,_br,yE,DCe,bbr,vbr,pZ,Fbr,Tbr,Mbr,xE,GCe,Ebr,Cbr,_Z,wbr,Abr,Lbr,$E,OCe,ybr,xbr,bZ,$br,kbr,Sbr,kE,VCe,Rbr,Pbr,vZ,Bbr,Ibr,Nbr,SE,XCe,qbr,jbr,FZ,Dbr,Gbr,Obr,RE,zCe,Vbr,Xbr,TZ,zbr,Qbr,Wbr,PE,QCe,Ubr,Hbr,MZ,Jbr,Ybr,Zbr,BE,WCe,Kbr,evr,EZ,ovr,rvr,tvr,IE,UCe,avr,nvr,CZ,svr,lvr,ivr,NE,HCe,dvr,mvr,wZ,cvr,fvr,gvr,qE,JCe,hvr,uvr,AZ,pvr,_vr,bvr,jE,YCe,vvr,Fvr,LZ,Tvr,Mvr,Evr,DE,ZCe,Cvr,wvr,yZ,Avr,Lvr,yvr,GE,KCe,xvr,$vr,xZ,kvr,Svr,Rvr,OE,e3e,Pvr,Bvr,$Z,Ivr,Nvr,qvr,VE,o3e,jvr,Dvr,kZ,Gvr,Ovr,Vvr,XE,r3e,Xvr,zvr,SZ,Qvr,Wvr,Uvr,zE,t3e,Hvr,Jvr,RZ,Yvr,Zvr,Kvr,QE,a3e,eFr,oFr,PZ,rFr,tFr,aFr,WE,n3e,nFr,sFr,BZ,lFr,iFr,dFr,UE,s3e,mFr,cFr,IZ,fFr,gFr,hFr,HE,l3e,uFr,pFr,NZ,_Fr,bFr,vFr,JE,i3e,FFr,TFr,qZ,MFr,EFr,CFr,YE,d3e,wFr,AFr,jZ,LFr,yFr,xFr,ZE,m3e,$Fr,kFr,DZ,SFr,RFr,PFr,KE,BFr,c3e,IFr,NFr,f3e,qFr,jFr,e4,aao,im,o4,g3e,Sk,DFr,h3e,GFr,nao,Qo,Rk,OFr,dm,VFr,GZ,XFr,zFr,OZ,QFr,WFr,UFr,Pk,HFr,u3e,JFr,YFr,ZFr,St,Bk,KFr,p3e,eTr,oTr,mm,rTr,_3e,tTr,aTr,VZ,nTr,sTr,lTr,r4,iTr,mo,Ik,dTr,b3e,mTr,cTr,pn,fTr,v3e,gTr,hTr,F3e,uTr,pTr,T3e,_Tr,bTr,vTr,O,t4,M3e,FTr,TTr,XZ,MTr,ETr,CTr,a4,E3e,wTr,ATr,zZ,LTr,yTr,xTr,n4,C3e,$Tr,kTr,QZ,STr,RTr,PTr,s4,w3e,BTr,ITr,WZ,NTr,qTr,jTr,l4,A3e,DTr,GTr,UZ,OTr,VTr,XTr,i4,L3e,zTr,QTr,HZ,WTr,UTr,HTr,d4,y3e,JTr,YTr,JZ,ZTr,KTr,eMr,m4,x3e,oMr,rMr,YZ,tMr,aMr,nMr,c4,$3e,sMr,lMr,ZZ,iMr,dMr,mMr,f4,k3e,cMr,fMr,KZ,gMr,hMr,uMr,g4,S3e,pMr,_Mr,eK,bMr,vMr,FMr,h4,R3e,TMr,MMr,oK,EMr,CMr,wMr,u4,P3e,AMr,LMr,rK,yMr,xMr,$Mr,p4,B3e,kMr,SMr,tK,RMr,PMr,BMr,_4,I3e,IMr,NMr,aK,qMr,jMr,DMr,b4,N3e,GMr,OMr,nK,VMr,XMr,zMr,v4,q3e,QMr,WMr,sK,UMr,HMr,JMr,F4,j3e,YMr,ZMr,lK,KMr,eEr,oEr,T4,D3e,rEr,tEr,iK,aEr,nEr,sEr,M4,G3e,lEr,iEr,dK,dEr,mEr,cEr,E4,O3e,fEr,gEr,mK,hEr,uEr,pEr,C4,V3e,_Er,bEr,cK,vEr,FEr,TEr,w4,X3e,MEr,EEr,fK,CEr,wEr,AEr,A4,z3e,LEr,yEr,gK,xEr,$Er,kEr,L4,Q3e,SEr,REr,hK,PEr,BEr,IEr,y4,W3e,NEr,qEr,uK,jEr,DEr,GEr,x4,U3e,OEr,VEr,pK,XEr,zEr,QEr,$4,H3e,WEr,UEr,_K,HEr,JEr,YEr,k4,J3e,ZEr,KEr,bK,e4r,o4r,r4r,S4,Y3e,t4r,a4r,vK,n4r,s4r,l4r,R4,Z3e,i4r,d4r,FK,m4r,c4r,f4r,P4,K3e,g4r,h4r,TK,u4r,p4r,_4r,B4,e5e,b4r,v4r,MK,F4r,T4r,M4r,I4,o5e,E4r,C4r,EK,w4r,A4r,L4r,N4,r5e,y4r,x4r,CK,$4r,k4r,S4r,q4,t5e,R4r,P4r,wK,B4r,I4r,N4r,j4,a5e,q4r,j4r,AK,D4r,G4r,O4r,D4,n5e,V4r,X4r,LK,z4r,Q4r,W4r,G4,s5e,U4r,H4r,yK,J4r,Y4r,Z4r,O4,l5e,K4r,eCr,xK,oCr,rCr,tCr,V4,i5e,aCr,nCr,$K,sCr,lCr,iCr,X4,d5e,dCr,mCr,kK,cCr,fCr,gCr,z4,m5e,hCr,uCr,SK,pCr,_Cr,bCr,Q4,c5e,vCr,FCr,RK,TCr,MCr,ECr,W4,f5e,CCr,wCr,PK,ACr,LCr,yCr,U4,g5e,xCr,$Cr,BK,kCr,SCr,RCr,H4,h5e,PCr,BCr,IK,ICr,NCr,qCr,J4,u5e,jCr,DCr,NK,GCr,OCr,VCr,Y4,XCr,p5e,zCr,QCr,_5e,WCr,UCr,Z4,sao,cm,K4,b5e,Nk,HCr,v5e,JCr,lao,Wo,qk,YCr,fm,ZCr,qK,KCr,e3r,jK,o3r,r3r,t3r,jk,a3r,F5e,n3r,s3r,l3r,Rt,Dk,i3r,T5e,d3r,m3r,gm,c3r,M5e,f3r,g3r,DK,h3r,u3r,p3r,eC,_3r,co,Gk,b3r,E5e,v3r,F3r,_n,T3r,C5e,M3r,E3r,w5e,C3r,w3r,A5e,A3r,L3r,y3r,L5e,oC,y5e,x3r,$3r,GK,k3r,S3r,R3r,rC,P3r,x5e,B3r,I3r,$5e,N3r,q3r,tC,iao,hm,aC,k5e,Ok,j3r,S5e,D3r,dao,Uo,Vk,G3r,um,O3r,OK,V3r,X3r,VK,z3r,Q3r,W3r,Xk,U3r,R5e,H3r,J3r,Y3r,Pt,zk,Z3r,P5e,K3r,e5r,pm,o5r,B5e,r5r,t5r,XK,a5r,n5r,s5r,nC,l5r,fo,Qk,i5r,I5e,d5r,m5r,bn,c5r,N5e,f5r,g5r,q5e,h5r,u5r,j5e,p5r,_5r,b5r,_m,sC,D5e,v5r,F5r,zK,T5r,M5r,E5r,lC,G5e,C5r,w5r,QK,A5r,L5r,y5r,iC,O5e,x5r,$5r,WK,k5r,S5r,R5r,dC,P5r,V5e,B5r,I5r,X5e,N5r,q5r,mC,mao,bm,cC,z5e,Wk,j5r,Q5e,D5r,cao,Ho,Uk,G5r,vm,O5r,UK,V5r,X5r,HK,z5r,Q5r,W5r,Hk,U5r,W5e,H5r,J5r,Y5r,Bt,Jk,Z5r,U5e,K5r,e0r,Fm,o0r,H5e,r0r,t0r,JK,a0r,n0r,s0r,fC,l0r,go,Yk,i0r,J5e,d0r,m0r,vn,c0r,Y5e,f0r,g0r,Z5e,h0r,u0r,K5e,p0r,_0r,b0r,be,gC,e0e,v0r,F0r,YK,T0r,M0r,E0r,hC,o0e,C0r,w0r,ZK,A0r,L0r,y0r,uC,r0e,x0r,$0r,KK,k0r,S0r,R0r,pC,t0e,P0r,B0r,eee,I0r,N0r,q0r,$l,a0e,j0r,D0r,oee,G0r,O0r,ree,V0r,X0r,z0r,_C,n0e,Q0r,W0r,tee,U0r,H0r,J0r,kl,s0e,Y0r,Z0r,aee,K0r,ewr,nee,owr,rwr,twr,bC,l0e,awr,nwr,see,swr,lwr,iwr,It,i0e,dwr,mwr,lee,cwr,fwr,iee,gwr,hwr,dee,uwr,pwr,_wr,vC,d0e,bwr,vwr,mee,Fwr,Twr,Mwr,FC,m0e,Ewr,Cwr,cee,wwr,Awr,Lwr,TC,c0e,ywr,xwr,fee,$wr,kwr,Swr,MC,f0e,Rwr,Pwr,gee,Bwr,Iwr,Nwr,EC,g0e,qwr,jwr,hee,Dwr,Gwr,Owr,CC,h0e,Vwr,Xwr,uee,zwr,Qwr,Wwr,wC,u0e,Uwr,Hwr,pee,Jwr,Ywr,Zwr,AC,p0e,Kwr,eAr,_ee,oAr,rAr,tAr,LC,_0e,aAr,nAr,bee,sAr,lAr,iAr,yC,dAr,b0e,mAr,cAr,v0e,fAr,gAr,xC,fao,Tm,$C,F0e,Zk,hAr,T0e,uAr,gao,Jo,Kk,pAr,Mm,_Ar,vee,bAr,vAr,Fee,FAr,TAr,MAr,eS,EAr,M0e,CAr,wAr,AAr,Nt,oS,LAr,E0e,yAr,xAr,Em,$Ar,C0e,kAr,SAr,Tee,RAr,PAr,BAr,kC,IAr,ho,rS,NAr,w0e,qAr,jAr,Fn,DAr,A0e,GAr,OAr,L0e,VAr,XAr,y0e,zAr,QAr,WAr,x0e,SC,$0e,UAr,HAr,Mee,JAr,YAr,ZAr,RC,KAr,k0e,e6r,o6r,S0e,r6r,t6r,PC,hao,Cm,BC,R0e,tS,a6r,P0e,n6r,uao,Yo,aS,s6r,wm,l6r,Eee,i6r,d6r,Cee,m6r,c6r,f6r,nS,g6r,B0e,h6r,u6r,p6r,qt,sS,_6r,I0e,b6r,v6r,Am,F6r,N0e,T6r,M6r,wee,E6r,C6r,w6r,IC,A6r,uo,lS,L6r,q0e,y6r,x6r,Tn,$6r,j0e,k6r,S6r,D0e,R6r,P6r,G0e,B6r,I6r,N6r,O0e,NC,V0e,q6r,j6r,Aee,D6r,G6r,O6r,qC,V6r,X0e,X6r,z6r,z0e,Q6r,W6r,jC,pao,Lm,DC,Q0e,iS,U6r,W0e,H6r,_ao,Zo,dS,J6r,ym,Y6r,Lee,Z6r,K6r,yee,e7r,o7r,r7r,mS,t7r,U0e,a7r,n7r,s7r,jt,cS,l7r,H0e,i7r,d7r,xm,m7r,J0e,c7r,f7r,xee,g7r,h7r,u7r,GC,p7r,po,fS,_7r,Y0e,b7r,v7r,Mn,F7r,Z0e,T7r,M7r,K0e,E7r,C7r,ewe,w7r,A7r,L7r,owe,OC,rwe,y7r,x7r,$ee,$7r,k7r,S7r,VC,R7r,twe,P7r,B7r,awe,I7r,N7r,XC,bao,$m,zC,nwe,gS,q7r,swe,j7r,vao,Ko,hS,D7r,km,G7r,kee,O7r,V7r,See,X7r,z7r,Q7r,uS,W7r,lwe,U7r,H7r,J7r,Dt,pS,Y7r,iwe,Z7r,K7r,Sm,e8r,dwe,o8r,r8r,Ree,t8r,a8r,n8r,QC,s8r,_o,_S,l8r,mwe,i8r,d8r,En,m8r,cwe,c8r,f8r,fwe,g8r,h8r,gwe,u8r,p8r,_8r,Be,WC,hwe,b8r,v8r,Pee,F8r,T8r,M8r,UC,uwe,E8r,C8r,Bee,w8r,A8r,L8r,HC,pwe,y8r,x8r,Iee,$8r,k8r,S8r,JC,_we,R8r,P8r,Nee,B8r,I8r,N8r,YC,bwe,q8r,j8r,qee,D8r,G8r,O8r,ZC,vwe,V8r,X8r,jee,z8r,Q8r,W8r,KC,Fwe,U8r,H8r,Dee,J8r,Y8r,Z8r,e3,Twe,K8r,eLr,Gee,oLr,rLr,tLr,o3,Mwe,aLr,nLr,Oee,sLr,lLr,iLr,r3,dLr,Ewe,mLr,cLr,Cwe,fLr,gLr,t3,Fao,Rm,a3,wwe,bS,hLr,Awe,uLr,Tao,er,vS,pLr,Pm,_Lr,Vee,bLr,vLr,Xee,FLr,TLr,MLr,FS,ELr,Lwe,CLr,wLr,ALr,Gt,TS,LLr,ywe,yLr,xLr,Bm,$Lr,xwe,kLr,SLr,zee,RLr,PLr,BLr,n3,ILr,bo,MS,NLr,$we,qLr,jLr,Cn,DLr,kwe,GLr,OLr,Swe,VLr,XLr,Rwe,zLr,QLr,WLr,ut,s3,Pwe,ULr,HLr,Qee,JLr,YLr,ZLr,l3,Bwe,KLr,eyr,Wee,oyr,ryr,tyr,i3,Iwe,ayr,nyr,Uee,syr,lyr,iyr,d3,Nwe,dyr,myr,Hee,cyr,fyr,gyr,m3,qwe,hyr,uyr,Jee,pyr,_yr,byr,c3,vyr,jwe,Fyr,Tyr,Dwe,Myr,Eyr,f3,Mao,Im,g3,Gwe,ES,Cyr,Owe,wyr,Eao,or,CS,Ayr,Nm,Lyr,Yee,yyr,xyr,Zee,$yr,kyr,Syr,wS,Ryr,Vwe,Pyr,Byr,Iyr,Ot,AS,Nyr,Xwe,qyr,jyr,qm,Dyr,zwe,Gyr,Oyr,Kee,Vyr,Xyr,zyr,h3,Qyr,vo,LS,Wyr,Qwe,Uyr,Hyr,wn,Jyr,Wwe,Yyr,Zyr,Uwe,Kyr,e9r,Hwe,o9r,r9r,t9r,Le,u3,Jwe,a9r,n9r,eoe,s9r,l9r,i9r,p3,Ywe,d9r,m9r,ooe,c9r,f9r,g9r,_3,Zwe,h9r,u9r,roe,p9r,_9r,b9r,b3,Kwe,v9r,F9r,toe,T9r,M9r,E9r,v3,eAe,C9r,w9r,aoe,A9r,L9r,y9r,F3,oAe,x9r,$9r,noe,k9r,S9r,R9r,T3,rAe,P9r,B9r,soe,I9r,N9r,q9r,M3,tAe,j9r,D9r,loe,G9r,O9r,V9r,E3,aAe,X9r,z9r,ioe,Q9r,W9r,U9r,C3,nAe,H9r,J9r,doe,Y9r,Z9r,K9r,w3,exr,sAe,oxr,rxr,lAe,txr,axr,A3,Cao,jm,L3,iAe,yS,nxr,dAe,sxr,wao,rr,xS,lxr,Dm,ixr,moe,dxr,mxr,coe,cxr,fxr,gxr,$S,hxr,mAe,uxr,pxr,_xr,Vt,kS,bxr,cAe,vxr,Fxr,Gm,Txr,fAe,Mxr,Exr,foe,Cxr,wxr,Axr,y3,Lxr,Fo,SS,yxr,gAe,xxr,$xr,An,kxr,hAe,Sxr,Rxr,uAe,Pxr,Bxr,pAe,Ixr,Nxr,qxr,Om,x3,_Ae,jxr,Dxr,goe,Gxr,Oxr,Vxr,$3,bAe,Xxr,zxr,hoe,Qxr,Wxr,Uxr,k3,vAe,Hxr,Jxr,uoe,Yxr,Zxr,Kxr,S3,e$r,FAe,o$r,r$r,TAe,t$r,a$r,R3,Aao,Vm,P3,MAe,RS,n$r,EAe,s$r,Lao,tr,PS,l$r,Xm,i$r,poe,d$r,m$r,_oe,c$r,f$r,g$r,BS,h$r,CAe,u$r,p$r,_$r,Xt,IS,b$r,wAe,v$r,F$r,zm,T$r,AAe,M$r,E$r,boe,C$r,w$r,A$r,B3,L$r,To,NS,y$r,LAe,x$r,$$r,Ln,k$r,yAe,S$r,R$r,xAe,P$r,B$r,$Ae,I$r,N$r,q$r,pt,I3,kAe,j$r,D$r,voe,G$r,O$r,V$r,N3,SAe,X$r,z$r,Foe,Q$r,W$r,U$r,q3,RAe,H$r,J$r,Toe,Y$r,Z$r,K$r,j3,PAe,ekr,okr,Moe,rkr,tkr,akr,D3,BAe,nkr,skr,Eoe,lkr,ikr,dkr,G3,mkr,IAe,ckr,fkr,NAe,gkr,hkr,O3,yao,Qm,V3,qAe,qS,ukr,jAe,pkr,xao,ar,jS,_kr,Wm,bkr,Coe,vkr,Fkr,woe,Tkr,Mkr,Ekr,DS,Ckr,DAe,wkr,Akr,Lkr,zt,GS,ykr,GAe,xkr,$kr,Um,kkr,OAe,Skr,Rkr,Aoe,Pkr,Bkr,Ikr,X3,Nkr,Mo,OS,qkr,VAe,jkr,Dkr,yn,Gkr,XAe,Okr,Vkr,zAe,Xkr,zkr,QAe,Qkr,Wkr,Ukr,xn,z3,WAe,Hkr,Jkr,Loe,Ykr,Zkr,Kkr,Q3,UAe,eSr,oSr,yoe,rSr,tSr,aSr,W3,HAe,nSr,sSr,xoe,lSr,iSr,dSr,U3,JAe,mSr,cSr,$oe,fSr,gSr,hSr,H3,uSr,YAe,pSr,_Sr,ZAe,bSr,vSr,J3,$ao,Hm,Y3,KAe,VS,FSr,e6e,TSr,kao,nr,XS,MSr,Jm,ESr,koe,CSr,wSr,Soe,ASr,LSr,ySr,zS,xSr,o6e,$Sr,kSr,SSr,Qt,QS,RSr,r6e,PSr,BSr,Ym,ISr,t6e,NSr,qSr,Roe,jSr,DSr,GSr,Z3,OSr,Eo,WS,VSr,a6e,XSr,zSr,$n,QSr,n6e,WSr,USr,s6e,HSr,JSr,l6e,YSr,ZSr,KSr,_t,K3,i6e,eRr,oRr,Poe,rRr,tRr,aRr,e5,d6e,nRr,sRr,Boe,lRr,iRr,dRr,o5,m6e,mRr,cRr,Ioe,fRr,gRr,hRr,r5,c6e,uRr,pRr,Noe,_Rr,bRr,vRr,t5,f6e,FRr,TRr,qoe,MRr,ERr,CRr,a5,wRr,g6e,ARr,LRr,h6e,yRr,xRr,n5,Sao,Zm,s5,u6e,US,$Rr,p6e,kRr,Rao,sr,HS,SRr,Km,RRr,joe,PRr,BRr,Doe,IRr,NRr,qRr,JS,jRr,_6e,DRr,GRr,ORr,Wt,YS,VRr,b6e,XRr,zRr,ec,QRr,v6e,WRr,URr,Goe,HRr,JRr,YRr,l5,ZRr,Co,ZS,KRr,F6e,ePr,oPr,kn,rPr,T6e,tPr,aPr,M6e,nPr,sPr,E6e,lPr,iPr,dPr,C6e,i5,w6e,mPr,cPr,Ooe,fPr,gPr,hPr,d5,uPr,A6e,pPr,_Pr,L6e,bPr,vPr,m5,Pao,oc,c5,y6e,KS,FPr,x6e,TPr,Bao,lr,eR,MPr,rc,EPr,Voe,CPr,wPr,Xoe,APr,LPr,yPr,oR,xPr,$6e,$Pr,kPr,SPr,Ut,rR,RPr,k6e,PPr,BPr,tc,IPr,S6e,NPr,qPr,zoe,jPr,DPr,GPr,f5,OPr,wo,tR,VPr,R6e,XPr,zPr,Sn,QPr,P6e,WPr,UPr,B6e,HPr,JPr,I6e,YPr,ZPr,KPr,bt,g5,N6e,eBr,oBr,Qoe,rBr,tBr,aBr,h5,q6e,nBr,sBr,Woe,lBr,iBr,dBr,u5,j6e,mBr,cBr,Uoe,fBr,gBr,hBr,p5,D6e,uBr,pBr,Hoe,_Br,bBr,vBr,_5,G6e,FBr,TBr,Joe,MBr,EBr,CBr,b5,wBr,O6e,ABr,LBr,V6e,yBr,xBr,v5,Iao,ac,F5,X6e,aR,$Br,z6e,kBr,Nao,ir,nR,SBr,nc,RBr,Yoe,PBr,BBr,Zoe,IBr,NBr,qBr,sR,jBr,Q6e,DBr,GBr,OBr,Ht,lR,VBr,W6e,XBr,zBr,sc,QBr,U6e,WBr,UBr,Koe,HBr,JBr,YBr,T5,ZBr,Ao,iR,KBr,H6e,eIr,oIr,Rn,rIr,J6e,tIr,aIr,Y6e,nIr,sIr,Z6e,lIr,iIr,dIr,K6e,M5,e7e,mIr,cIr,ere,fIr,gIr,hIr,E5,uIr,o7e,pIr,_Ir,r7e,bIr,vIr,C5,qao,lc,w5,t7e,dR,FIr,a7e,TIr,jao,dr,mR,MIr,ic,EIr,ore,CIr,wIr,rre,AIr,LIr,yIr,cR,xIr,n7e,$Ir,kIr,SIr,Jt,fR,RIr,s7e,PIr,BIr,dc,IIr,l7e,NIr,qIr,tre,jIr,DIr,GIr,A5,OIr,Lo,gR,VIr,i7e,XIr,zIr,Pn,QIr,d7e,WIr,UIr,m7e,HIr,JIr,c7e,YIr,ZIr,KIr,f7e,L5,g7e,eNr,oNr,are,rNr,tNr,aNr,y5,nNr,h7e,sNr,lNr,u7e,iNr,dNr,x5,Dao,mc,$5,p7e,hR,mNr,_7e,cNr,Gao,mr,uR,fNr,cc,gNr,nre,hNr,uNr,sre,pNr,_Nr,bNr,pR,vNr,b7e,FNr,TNr,MNr,Yt,_R,ENr,v7e,CNr,wNr,fc,ANr,F7e,LNr,yNr,lre,xNr,$Nr,kNr,k5,SNr,Dr,bR,RNr,T7e,PNr,BNr,Bn,INr,M7e,NNr,qNr,E7e,jNr,DNr,C7e,GNr,ONr,VNr,P,S5,w7e,XNr,zNr,ire,QNr,WNr,UNr,R5,A7e,HNr,JNr,dre,YNr,ZNr,KNr,P5,L7e,eqr,oqr,mre,rqr,tqr,aqr,B5,y7e,nqr,sqr,cre,lqr,iqr,dqr,I5,x7e,mqr,cqr,fre,fqr,gqr,hqr,N5,$7e,uqr,pqr,gre,_qr,bqr,vqr,q5,k7e,Fqr,Tqr,hre,Mqr,Eqr,Cqr,j5,S7e,wqr,Aqr,ure,Lqr,yqr,xqr,D5,R7e,$qr,kqr,pre,Sqr,Rqr,Pqr,G5,P7e,Bqr,Iqr,_re,Nqr,qqr,jqr,O5,B7e,Dqr,Gqr,bre,Oqr,Vqr,Xqr,V5,I7e,zqr,Qqr,vre,Wqr,Uqr,Hqr,X5,N7e,Jqr,Yqr,Fre,Zqr,Kqr,ejr,z5,q7e,ojr,rjr,Tre,tjr,ajr,njr,Q5,j7e,sjr,ljr,Mre,ijr,djr,mjr,W5,D7e,cjr,fjr,Ere,gjr,hjr,ujr,U5,G7e,pjr,_jr,Cre,bjr,vjr,Fjr,H5,O7e,Tjr,Mjr,wre,Ejr,Cjr,wjr,J5,V7e,Ajr,Ljr,Are,yjr,xjr,$jr,Y5,X7e,kjr,Sjr,Lre,Rjr,Pjr,Bjr,Sl,z7e,Ijr,Njr,yre,qjr,jjr,xre,Djr,Gjr,Ojr,Z5,Q7e,Vjr,Xjr,$re,zjr,Qjr,Wjr,K5,W7e,Ujr,Hjr,kre,Jjr,Yjr,Zjr,e0,U7e,Kjr,eDr,Sre,oDr,rDr,tDr,o0,H7e,aDr,nDr,Rre,sDr,lDr,iDr,r0,J7e,dDr,mDr,Pre,cDr,fDr,gDr,t0,Y7e,hDr,uDr,Bre,pDr,_Dr,bDr,a0,Z7e,vDr,FDr,Ire,TDr,MDr,EDr,n0,K7e,CDr,wDr,Nre,ADr,LDr,yDr,s0,e8e,xDr,$Dr,qre,kDr,SDr,RDr,l0,o8e,PDr,BDr,jre,IDr,NDr,qDr,i0,r8e,jDr,DDr,Dre,GDr,ODr,VDr,d0,t8e,XDr,zDr,Gre,QDr,WDr,UDr,m0,a8e,HDr,JDr,Ore,YDr,ZDr,KDr,c0,n8e,eGr,oGr,Vre,rGr,tGr,aGr,f0,s8e,nGr,sGr,Xre,lGr,iGr,dGr,g0,l8e,mGr,cGr,zre,fGr,gGr,hGr,h0,i8e,uGr,pGr,Qre,_Gr,bGr,vGr,u0,d8e,FGr,TGr,Wre,MGr,EGr,CGr,p0,m8e,wGr,AGr,Ure,LGr,yGr,xGr,_0,c8e,$Gr,kGr,Hre,SGr,RGr,PGr,b0,f8e,BGr,IGr,Jre,NGr,qGr,jGr,v0,g8e,DGr,GGr,Yre,OGr,VGr,XGr,F0,h8e,zGr,QGr,Zre,WGr,UGr,HGr,T0,u8e,JGr,YGr,Kre,ZGr,KGr,eOr,M0,p8e,oOr,rOr,ete,tOr,aOr,nOr,E0,_8e,sOr,lOr,ote,iOr,dOr,mOr,C0,b8e,cOr,fOr,rte,gOr,hOr,uOr,w0,v8e,pOr,_Or,tte,bOr,vOr,FOr,A0,F8e,TOr,MOr,ate,EOr,COr,wOr,L0,T8e,AOr,LOr,nte,yOr,xOr,$Or,y0,M8e,kOr,SOr,ste,ROr,POr,BOr,x0,E8e,IOr,NOr,lte,qOr,jOr,DOr,$0,C8e,GOr,OOr,ite,VOr,XOr,zOr,k0,w8e,QOr,WOr,dte,UOr,HOr,JOr,S0,A8e,YOr,ZOr,mte,KOr,eVr,oVr,R0,L8e,rVr,tVr,cte,aVr,nVr,sVr,P0,y8e,lVr,iVr,fte,dVr,mVr,cVr,B0,Oao,gc,I0,x8e,vR,fVr,$8e,gVr,Vao,cr,FR,hVr,hc,uVr,gte,pVr,_Vr,hte,bVr,vVr,FVr,TR,TVr,k8e,MVr,EVr,CVr,Zt,MR,wVr,S8e,AVr,LVr,uc,yVr,R8e,xVr,$Vr,ute,kVr,SVr,RVr,N0,PVr,Gr,ER,BVr,P8e,IVr,NVr,In,qVr,B8e,jVr,DVr,I8e,GVr,OVr,N8e,VVr,XVr,zVr,se,q0,q8e,QVr,WVr,pte,UVr,HVr,JVr,j0,j8e,YVr,ZVr,_te,KVr,eXr,oXr,D0,D8e,rXr,tXr,bte,aXr,nXr,sXr,G0,G8e,lXr,iXr,vte,dXr,mXr,cXr,O0,O8e,fXr,gXr,Fte,hXr,uXr,pXr,V0,V8e,_Xr,bXr,Tte,vXr,FXr,TXr,X0,X8e,MXr,EXr,Mte,CXr,wXr,AXr,z0,z8e,LXr,yXr,Ete,xXr,$Xr,kXr,Q0,Q8e,SXr,RXr,Cte,PXr,BXr,IXr,W0,W8e,NXr,qXr,wte,jXr,DXr,GXr,U0,U8e,OXr,VXr,Ate,XXr,zXr,QXr,H0,H8e,WXr,UXr,Lte,HXr,JXr,YXr,J0,J8e,ZXr,KXr,yte,ezr,ozr,rzr,Y0,Y8e,tzr,azr,xte,nzr,szr,lzr,Z0,Z8e,izr,dzr,$te,mzr,czr,fzr,K0,K8e,gzr,hzr,kte,uzr,pzr,_zr,ew,eLe,bzr,vzr,Ste,Fzr,Tzr,Mzr,ow,oLe,Ezr,Czr,Rte,wzr,Azr,Lzr,rw,rLe,yzr,xzr,Pte,$zr,kzr,Szr,tw,tLe,Rzr,Pzr,Bte,Bzr,Izr,Nzr,aw,aLe,qzr,jzr,Ite,Dzr,Gzr,Ozr,nw,nLe,Vzr,Xzr,Nte,zzr,Qzr,Wzr,sw,sLe,Uzr,Hzr,qte,Jzr,Yzr,Zzr,lw,Xao,pc,iw,lLe,CR,Kzr,iLe,eQr,zao,fr,wR,oQr,_c,rQr,jte,tQr,aQr,Dte,nQr,sQr,lQr,AR,iQr,dLe,dQr,mQr,cQr,Kt,LR,fQr,mLe,gQr,hQr,bc,uQr,cLe,pQr,_Qr,Gte,bQr,vQr,FQr,dw,TQr,Or,yR,MQr,fLe,EQr,CQr,Nn,wQr,gLe,AQr,LQr,hLe,yQr,xQr,uLe,$Qr,kQr,SQr,Me,mw,pLe,RQr,PQr,Ote,BQr,IQr,NQr,cw,_Le,qQr,jQr,Vte,DQr,GQr,OQr,fw,bLe,VQr,XQr,Xte,zQr,QQr,WQr,gw,vLe,UQr,HQr,zte,JQr,YQr,ZQr,hw,FLe,KQr,eWr,Qte,oWr,rWr,tWr,uw,TLe,aWr,nWr,Wte,sWr,lWr,iWr,pw,MLe,dWr,mWr,Ute,cWr,fWr,gWr,_w,ELe,hWr,uWr,Hte,pWr,_Wr,bWr,bw,CLe,vWr,FWr,Jte,TWr,MWr,EWr,vw,wLe,CWr,wWr,Yte,AWr,LWr,yWr,Fw,ALe,xWr,$Wr,Zte,kWr,SWr,RWr,Tw,LLe,PWr,BWr,Kte,IWr,NWr,qWr,Mw,yLe,jWr,DWr,eae,GWr,OWr,VWr,Ew,xLe,XWr,zWr,oae,QWr,WWr,UWr,Cw,Qao,vc,ww,$Le,xR,HWr,kLe,JWr,Wao,gr,$R,YWr,Fc,ZWr,rae,KWr,eUr,tae,oUr,rUr,tUr,kR,aUr,SLe,nUr,sUr,lUr,ea,SR,iUr,RLe,dUr,mUr,Tc,cUr,PLe,fUr,gUr,aae,hUr,uUr,pUr,Aw,_Ur,Vr,RR,bUr,BLe,vUr,FUr,qn,TUr,ILe,MUr,EUr,NLe,CUr,wUr,qLe,AUr,LUr,yUr,ye,Lw,jLe,xUr,$Ur,nae,kUr,SUr,RUr,yw,DLe,PUr,BUr,sae,IUr,NUr,qUr,xw,GLe,jUr,DUr,lae,GUr,OUr,VUr,Rl,OLe,XUr,zUr,iae,QUr,WUr,dae,UUr,HUr,JUr,$w,VLe,YUr,ZUr,mae,KUr,eHr,oHr,kw,XLe,rHr,tHr,cae,aHr,nHr,sHr,Sw,zLe,lHr,iHr,fae,dHr,mHr,cHr,Rw,QLe,fHr,gHr,gae,hHr,uHr,pHr,Pw,WLe,_Hr,bHr,hae,vHr,FHr,THr,Bw,ULe,MHr,EHr,uae,CHr,wHr,AHr,Iw,Uao,Mc,Nw,HLe,PR,LHr,JLe,yHr,Hao,hr,BR,xHr,Ec,$Hr,pae,kHr,SHr,_ae,RHr,PHr,BHr,IR,IHr,YLe,NHr,qHr,jHr,oa,NR,DHr,ZLe,GHr,OHr,Cc,VHr,KLe,XHr,zHr,bae,QHr,WHr,UHr,qw,HHr,Xr,qR,JHr,eye,YHr,ZHr,jn,KHr,oye,eJr,oJr,rye,rJr,tJr,tye,aJr,nJr,sJr,wc,jw,aye,lJr,iJr,vae,dJr,mJr,cJr,Dw,nye,fJr,gJr,Fae,hJr,uJr,pJr,Gw,sye,_Jr,bJr,Tae,vJr,FJr,TJr,Ow,Jao,Ac,Vw,lye,jR,MJr,iye,EJr,Yao,ur,DR,CJr,Lc,wJr,Mae,AJr,LJr,Eae,yJr,xJr,$Jr,GR,kJr,dye,SJr,RJr,PJr,ra,OR,BJr,mye,IJr,NJr,yc,qJr,cye,jJr,DJr,Cae,GJr,OJr,VJr,Xw,XJr,zr,VR,zJr,fye,QJr,WJr,Dn,UJr,gye,HJr,JJr,hye,YJr,ZJr,uye,KJr,eYr,oYr,me,zw,pye,rYr,tYr,wae,aYr,nYr,sYr,Qw,_ye,lYr,iYr,Aae,dYr,mYr,cYr,Ww,bye,fYr,gYr,Lae,hYr,uYr,pYr,Uw,vye,_Yr,bYr,yae,vYr,FYr,TYr,Hw,Fye,MYr,EYr,xae,CYr,wYr,AYr,Jw,Tye,LYr,yYr,$ae,xYr,$Yr,kYr,Yw,Mye,SYr,RYr,kae,PYr,BYr,IYr,Zw,Eye,NYr,qYr,Sae,jYr,DYr,GYr,Kw,Cye,OYr,VYr,Rae,XYr,zYr,QYr,eA,wye,WYr,UYr,Pae,HYr,JYr,YYr,oA,Aye,ZYr,KYr,Bae,eZr,oZr,rZr,rA,Lye,tZr,aZr,Iae,nZr,sZr,lZr,tA,yye,iZr,dZr,Nae,mZr,cZr,fZr,aA,xye,gZr,hZr,qae,uZr,pZr,_Zr,nA,$ye,bZr,vZr,jae,FZr,TZr,MZr,sA,kye,EZr,CZr,Dae,wZr,AZr,LZr,lA,Sye,yZr,xZr,Gae,$Zr,kZr,SZr,iA,Rye,RZr,PZr,Oae,BZr,IZr,NZr,dA,Pye,qZr,jZr,Vae,DZr,GZr,OZr,mA,Bye,VZr,XZr,Xae,zZr,QZr,WZr,cA,Iye,UZr,HZr,zae,JZr,YZr,ZZr,fA,Zao,xc,gA,Nye,XR,KZr,qye,eKr,Kao,pr,zR,oKr,$c,rKr,Qae,tKr,aKr,Wae,nKr,sKr,lKr,QR,iKr,jye,dKr,mKr,cKr,ta,WR,fKr,Dye,gKr,hKr,kc,uKr,Gye,pKr,_Kr,Uae,bKr,vKr,FKr,hA,TKr,Qr,UR,MKr,Oye,EKr,CKr,Gn,wKr,Vye,AKr,LKr,Xye,yKr,xKr,zye,$Kr,kKr,SKr,xe,uA,Qye,RKr,PKr,Hae,BKr,IKr,NKr,pA,Wye,qKr,jKr,Jae,DKr,GKr,OKr,_A,Uye,VKr,XKr,Yae,zKr,QKr,WKr,bA,Hye,UKr,HKr,Zae,JKr,YKr,ZKr,vA,Jye,KKr,eet,Kae,oet,ret,tet,FA,Yye,aet,net,ene,set,iet,det,TA,Zye,met,cet,one,fet,get,het,MA,Kye,uet,pet,rne,_et,bet,vet,EA,e9e,Fet,Tet,tne,Met,Eet,Cet,CA,o9e,wet,Aet,ane,Let,yet,xet,wA,eno,Sc,AA,r9e,HR,$et,t9e,ket,ono,_r,JR,Set,Rc,Ret,nne,Pet,Bet,sne,Iet,Net,qet,YR,jet,a9e,Det,Get,Oet,aa,ZR,Vet,n9e,Xet,zet,Pc,Qet,s9e,Wet,Uet,lne,Het,Jet,Yet,LA,Zet,Wr,KR,Ket,l9e,eot,oot,On,rot,i9e,tot,aot,d9e,not,sot,m9e,lot,iot,dot,re,yA,c9e,mot,cot,ine,fot,got,hot,xA,f9e,uot,pot,dne,_ot,bot,vot,$A,g9e,Fot,Tot,mne,Mot,Eot,Cot,kA,h9e,wot,Aot,cne,Lot,yot,xot,SA,u9e,$ot,kot,fne,Sot,Rot,Pot,RA,p9e,Bot,Iot,gne,Not,qot,jot,PA,_9e,Dot,Got,hne,Oot,Vot,Xot,BA,b9e,zot,Qot,une,Wot,Uot,Hot,IA,v9e,Jot,Yot,pne,Zot,Kot,ert,NA,F9e,ort,rrt,_ne,trt,art,nrt,qA,T9e,srt,lrt,bne,irt,drt,mrt,jA,M9e,crt,frt,vne,grt,hrt,urt,DA,E9e,prt,_rt,Fne,brt,vrt,Frt,GA,C9e,Trt,Mrt,Tne,Ert,Crt,wrt,OA,w9e,Art,Lrt,Mne,yrt,xrt,$rt,VA,A9e,krt,Srt,Ene,Rrt,Prt,Brt,XA,L9e,Irt,Nrt,Cne,qrt,jrt,Drt,zA,y9e,Grt,Ort,wne,Vrt,Xrt,zrt,QA,x9e,Qrt,Wrt,Ane,Urt,Hrt,Jrt,WA,$9e,Yrt,Zrt,Lne,Krt,ett,ott,UA,k9e,rtt,ttt,yne,att,ntt,stt,HA,S9e,ltt,itt,xne,dtt,mtt,ctt,JA,R9e,ftt,gtt,$ne,htt,utt,ptt,YA,P9e,_tt,btt,kne,vtt,Ftt,Ttt,ZA,B9e,Mtt,Ett,Sne,Ctt,wtt,Att,KA,I9e,Ltt,ytt,Rne,xtt,$tt,ktt,e6,N9e,Stt,Rtt,Pne,Ptt,Btt,Itt,o6,q9e,Ntt,qtt,Bne,jtt,Dtt,Gtt,r6,rno,Bc,t6,j9e,eP,Ott,D9e,Vtt,tno,br,oP,Xtt,Ic,ztt,Ine,Qtt,Wtt,Nne,Utt,Htt,Jtt,rP,Ytt,G9e,Ztt,Ktt,eat,na,tP,oat,O9e,rat,tat,Nc,aat,V9e,nat,sat,qne,lat,iat,dat,a6,mat,Ur,aP,cat,X9e,fat,gat,Vn,hat,z9e,uat,pat,Q9e,_at,bat,W9e,vat,Fat,Tat,ve,n6,U9e,Mat,Eat,jne,Cat,wat,Aat,s6,H9e,Lat,yat,Dne,xat,$at,kat,l6,J9e,Sat,Rat,Gne,Pat,Bat,Iat,i6,Y9e,Nat,qat,One,jat,Dat,Gat,d6,Z9e,Oat,Vat,Vne,Xat,zat,Qat,m6,K9e,Wat,Uat,Xne,Hat,Jat,Yat,c6,exe,Zat,Kat,zne,ent,ont,rnt,f6,oxe,tnt,ant,Qne,nnt,snt,lnt,g6,rxe,int,dnt,Wne,mnt,cnt,fnt,h6,txe,gnt,hnt,Une,unt,pnt,_nt,u6,axe,bnt,vnt,Hne,Fnt,Tnt,Mnt,p6,nxe,Ent,Cnt,Jne,wnt,Ant,Lnt,_6,sxe,ynt,xnt,Yne,$nt,knt,Snt,b6,lxe,Rnt,Pnt,Zne,Bnt,Int,Nnt,v6,ixe,qnt,jnt,Kne,Dnt,Gnt,Ont,F6,dxe,Vnt,Xnt,ese,znt,Qnt,Wnt,T6,mxe,Unt,Hnt,ose,Jnt,Ynt,Znt,M6,ano,qc,E6,cxe,nP,Knt,fxe,est,nno,vr,sP,ost,jc,rst,rse,tst,ast,tse,nst,sst,lst,lP,ist,gxe,dst,mst,cst,sa,iP,fst,hxe,gst,hst,Dc,ust,uxe,pst,_st,ase,bst,vst,Fst,C6,Tst,Hr,dP,Mst,pxe,Est,Cst,Xn,wst,_xe,Ast,Lst,bxe,yst,xst,vxe,$st,kst,Sst,mP,w6,Fxe,Rst,Pst,nse,Bst,Ist,Nst,A6,Txe,qst,jst,sse,Dst,Gst,Ost,L6,sno,Gc,y6,Mxe,cP,Vst,Exe,Xst,lno,Fr,fP,zst,Oc,Qst,lse,Wst,Ust,ise,Hst,Jst,Yst,gP,Zst,Cxe,Kst,elt,olt,la,hP,rlt,wxe,tlt,alt,Vc,nlt,Axe,slt,llt,dse,ilt,dlt,mlt,x6,clt,Jr,uP,flt,Lxe,glt,hlt,zn,ult,yxe,plt,_lt,xxe,blt,vlt,$xe,Flt,Tlt,Mlt,kxe,$6,Sxe,Elt,Clt,mse,wlt,Alt,Llt,k6,ino,Xc,S6,Rxe,pP,ylt,Pxe,xlt,dno,Tr,_P,$lt,zc,klt,cse,Slt,Rlt,fse,Plt,Blt,Ilt,bP,Nlt,Bxe,qlt,jlt,Dlt,ia,vP,Glt,Ixe,Olt,Vlt,Qc,Xlt,Nxe,zlt,Qlt,gse,Wlt,Ult,Hlt,R6,Jlt,Yr,FP,Ylt,qxe,Zlt,Klt,Qn,eit,jxe,oit,rit,Dxe,tit,ait,Gxe,nit,sit,lit,Oxe,P6,Vxe,iit,dit,hse,mit,cit,fit,B6,mno,Wc,I6,Xxe,TP,git,zxe,hit,cno,Mr,MP,uit,Uc,pit,use,_it,bit,pse,vit,Fit,Tit,EP,Mit,Qxe,Eit,Cit,wit,da,CP,Ait,Wxe,Lit,yit,Hc,xit,Uxe,$it,kit,_se,Sit,Rit,Pit,N6,Bit,Zr,wP,Iit,Hxe,Nit,qit,Wn,jit,Jxe,Dit,Git,Yxe,Oit,Vit,Zxe,Xit,zit,Qit,ie,q6,Kxe,Wit,Uit,bse,Hit,Jit,Yit,j6,e$e,Zit,Kit,vse,edt,odt,rdt,D6,o$e,tdt,adt,Fse,ndt,sdt,ldt,G6,r$e,idt,ddt,Tse,mdt,cdt,fdt,O6,t$e,gdt,hdt,Mse,udt,pdt,_dt,V6,a$e,bdt,vdt,Ese,Fdt,Tdt,Mdt,X6,n$e,Edt,Cdt,Cse,wdt,Adt,Ldt,z6,s$e,ydt,xdt,wse,$dt,kdt,Sdt,Q6,l$e,Rdt,Pdt,Ase,Bdt,Idt,Ndt,W6,i$e,qdt,jdt,Lse,Ddt,Gdt,Odt,U6,d$e,Vdt,Xdt,yse,zdt,Qdt,Wdt,H6,m$e,Udt,Hdt,xse,Jdt,Ydt,Zdt,J6,c$e,Kdt,emt,$se,omt,rmt,tmt,Y6,f$e,amt,nmt,kse,smt,lmt,imt,Z6,g$e,dmt,mmt,Sse,cmt,fmt,gmt,K6,h$e,hmt,umt,Rse,pmt,_mt,bmt,e7,u$e,vmt,Fmt,Pse,Tmt,Mmt,Emt,o7,p$e,Cmt,wmt,Bse,Amt,Lmt,ymt,r7,_$e,xmt,$mt,Ise,kmt,Smt,Rmt,t7,b$e,Pmt,Bmt,Nse,Imt,Nmt,qmt,a7,v$e,jmt,Dmt,qse,Gmt,Omt,Vmt,n7,F$e,Xmt,zmt,jse,Qmt,Wmt,Umt,s7,fno,Jc,l7,T$e,AP,Hmt,M$e,Jmt,gno,Er,LP,Ymt,Yc,Zmt,Dse,Kmt,ect,Gse,oct,rct,tct,yP,act,E$e,nct,sct,lct,ma,xP,ict,C$e,dct,mct,Zc,cct,w$e,fct,gct,Ose,hct,uct,pct,i7,_ct,Kr,$P,bct,A$e,vct,Fct,Un,Tct,L$e,Mct,Ect,y$e,Cct,wct,x$e,Act,Lct,yct,ce,d7,$$e,xct,$ct,Vse,kct,Sct,Rct,m7,k$e,Pct,Bct,Xse,Ict,Nct,qct,c7,S$e,jct,Dct,zse,Gct,Oct,Vct,f7,R$e,Xct,zct,Qse,Qct,Wct,Uct,g7,P$e,Hct,Jct,Wse,Yct,Zct,Kct,h7,B$e,eft,oft,Use,rft,tft,aft,u7,I$e,nft,sft,Hse,lft,ift,dft,p7,N$e,mft,cft,Jse,fft,gft,hft,_7,q$e,uft,pft,Yse,_ft,bft,vft,b7,j$e,Fft,Tft,Zse,Mft,Eft,Cft,v7,D$e,wft,Aft,Kse,Lft,yft,xft,F7,G$e,$ft,kft,ele,Sft,Rft,Pft,T7,O$e,Bft,Ift,ole,Nft,qft,jft,M7,V$e,Dft,Gft,rle,Oft,Vft,Xft,E7,X$e,zft,Qft,tle,Wft,Uft,Hft,C7,z$e,Jft,Yft,ale,Zft,Kft,egt,w7,Q$e,ogt,rgt,nle,tgt,agt,ngt,A7,W$e,sgt,lgt,sle,igt,dgt,mgt,L7,U$e,cgt,fgt,lle,ggt,hgt,ugt,y7,H$e,pgt,_gt,ile,bgt,vgt,Fgt,x7,J$e,Tgt,Mgt,dle,Egt,Cgt,wgt,$7,hno,Kc,k7,Y$e,kP,Agt,Z$e,Lgt,uno,Cr,SP,ygt,ef,xgt,mle,$gt,kgt,cle,Sgt,Rgt,Pgt,RP,Bgt,K$e,Igt,Ngt,qgt,ca,PP,jgt,eke,Dgt,Ggt,of,Ogt,oke,Vgt,Xgt,fle,zgt,Qgt,Wgt,S7,Ugt,et,BP,Hgt,rke,Jgt,Ygt,Hn,Zgt,tke,Kgt,eht,ake,oht,rht,nke,tht,aht,nht,ske,R7,lke,sht,lht,gle,iht,dht,mht,P7,pno,rf,B7,ike,IP,cht,dke,fht,_no,wr,NP,ght,tf,hht,hle,uht,pht,ule,_ht,bht,vht,qP,Fht,mke,Tht,Mht,Eht,fa,jP,Cht,cke,wht,Aht,af,Lht,fke,yht,xht,ple,$ht,kht,Sht,I7,Rht,ot,DP,Pht,gke,Bht,Iht,Jn,Nht,hke,qht,jht,uke,Dht,Ght,pke,Oht,Vht,Xht,GP,N7,_ke,zht,Qht,_le,Wht,Uht,Hht,q7,bke,Jht,Yht,ble,Zht,Kht,eut,j7,bno,nf,D7,vke,OP,out,Fke,rut,vno,Ar,VP,tut,sf,aut,vle,nut,sut,Fle,lut,iut,dut,XP,mut,Tke,cut,fut,gut,ga,zP,hut,Mke,uut,put,lf,_ut,Eke,but,vut,Tle,Fut,Tut,Mut,G7,Eut,rt,QP,Cut,Cke,wut,Aut,Yn,Lut,wke,yut,xut,Ake,$ut,kut,Lke,Sut,Rut,Put,te,O7,yke,But,Iut,Mle,Nut,qut,jut,V7,xke,Dut,Gut,Ele,Out,Vut,Xut,X7,$ke,zut,Qut,Cle,Wut,Uut,Hut,z7,kke,Jut,Yut,wle,Zut,Kut,ept,Q7,Ske,opt,rpt,Ale,tpt,apt,npt,W7,Rke,spt,lpt,Lle,ipt,dpt,mpt,U7,Pke,cpt,fpt,yle,gpt,hpt,upt,H7,Bke,ppt,_pt,xle,bpt,vpt,Fpt,J7,Ike,Tpt,Mpt,$le,Ept,Cpt,wpt,Y7,Nke,Apt,Lpt,kle,ypt,xpt,$pt,Z7,qke,kpt,Spt,Sle,Rpt,Ppt,Bpt,K7,jke,Ipt,Npt,Rle,qpt,jpt,Dpt,e8,Dke,Gpt,Opt,Ple,Vpt,Xpt,zpt,o8,Gke,Qpt,Wpt,Ble,Upt,Hpt,Jpt,r8,Oke,Ypt,Zpt,Ile,Kpt,e_t,o_t,t8,Vke,r_t,t_t,Nle,a_t,n_t,s_t,a8,Xke,l_t,i_t,qle,d_t,m_t,c_t,n8,zke,f_t,g_t,jle,h_t,u_t,p_t,s8,Qke,__t,b_t,Dle,v_t,F_t,T_t,l8,Wke,M_t,E_t,Gle,C_t,w_t,A_t,i8,Uke,L_t,y_t,Ole,x_t,$_t,k_t,d8,Hke,S_t,R_t,Vle,P_t,B_t,I_t,m8,Jke,N_t,q_t,Xle,j_t,D_t,G_t,c8,Yke,O_t,V_t,zle,X_t,z_t,Q_t,f8,Zke,W_t,U_t,Qle,H_t,J_t,Y_t,g8,Kke,Z_t,K_t,Wle,e1t,o1t,r1t,h8,eSe,t1t,a1t,Ule,n1t,s1t,l1t,u8,Fno,df,p8,oSe,WP,i1t,rSe,d1t,Tno,Lr,UP,m1t,mf,c1t,Hle,f1t,g1t,Jle,h1t,u1t,p1t,HP,_1t,tSe,b1t,v1t,F1t,ha,JP,T1t,aSe,M1t,E1t,cf,C1t,nSe,w1t,A1t,Yle,L1t,y1t,x1t,_8,$1t,tt,YP,k1t,sSe,S1t,R1t,Zn,P1t,lSe,B1t,I1t,iSe,N1t,q1t,dSe,j1t,D1t,G1t,$e,b8,mSe,O1t,V1t,Zle,X1t,z1t,Q1t,v8,cSe,W1t,U1t,Kle,H1t,J1t,Y1t,F8,fSe,Z1t,K1t,eie,e2t,o2t,r2t,T8,gSe,t2t,a2t,oie,n2t,s2t,l2t,M8,hSe,i2t,d2t,rie,m2t,c2t,f2t,E8,uSe,g2t,h2t,tie,u2t,p2t,_2t,C8,pSe,b2t,v2t,aie,F2t,T2t,M2t,w8,_Se,E2t,C2t,nie,w2t,A2t,L2t,A8,bSe,y2t,x2t,sie,$2t,k2t,S2t,L8,vSe,R2t,P2t,lie,B2t,I2t,N2t,y8,Mno,ff,x8,FSe,ZP,q2t,TSe,j2t,Eno,yr,KP,D2t,gf,G2t,iie,O2t,V2t,die,X2t,z2t,Q2t,eB,W2t,MSe,U2t,H2t,J2t,ua,oB,Y2t,ESe,Z2t,K2t,hf,ebt,CSe,obt,rbt,mie,tbt,abt,nbt,$8,sbt,at,rB,lbt,wSe,ibt,dbt,Kn,mbt,ASe,cbt,fbt,LSe,gbt,hbt,ySe,ubt,pbt,_bt,Ee,k8,xSe,bbt,vbt,cie,Fbt,Tbt,Mbt,S8,$Se,Ebt,Cbt,fie,wbt,Abt,Lbt,R8,kSe,ybt,xbt,gie,$bt,kbt,Sbt,P8,SSe,Rbt,Pbt,hie,Bbt,Ibt,Nbt,B8,RSe,qbt,jbt,uie,Dbt,Gbt,Obt,I8,PSe,Vbt,Xbt,pie,zbt,Qbt,Wbt,N8,BSe,Ubt,Hbt,_ie,Jbt,Ybt,Zbt,q8,ISe,Kbt,evt,bie,ovt,rvt,tvt,j8,NSe,avt,nvt,vie,svt,lvt,ivt,D8,qSe,dvt,mvt,Fie,cvt,fvt,gvt,G8,jSe,hvt,uvt,Tie,pvt,_vt,bvt,O8,DSe,vvt,Fvt,Mie,Tvt,Mvt,Evt,V8,GSe,Cvt,wvt,Eie,Avt,Lvt,yvt,X8,Cno,uf,z8,OSe,tB,xvt,VSe,$vt,wno,xr,aB,kvt,pf,Svt,Cie,Rvt,Pvt,wie,Bvt,Ivt,Nvt,nB,qvt,XSe,jvt,Dvt,Gvt,pa,sB,Ovt,zSe,Vvt,Xvt,_f,zvt,QSe,Qvt,Wvt,Aie,Uvt,Hvt,Jvt,Q8,Yvt,nt,lB,Zvt,WSe,Kvt,eFt,es,oFt,USe,rFt,tFt,HSe,aFt,nFt,JSe,sFt,lFt,iFt,ke,W8,YSe,dFt,mFt,Lie,cFt,fFt,gFt,U8,ZSe,hFt,uFt,yie,pFt,_Ft,bFt,H8,KSe,vFt,FFt,xie,TFt,MFt,EFt,J8,eRe,CFt,wFt,$ie,AFt,LFt,yFt,Y8,oRe,xFt,$Ft,kie,kFt,SFt,RFt,Z8,rRe,PFt,BFt,Sie,IFt,NFt,qFt,K8,tRe,jFt,DFt,Rie,GFt,OFt,VFt,eL,aRe,XFt,zFt,Pie,QFt,WFt,UFt,oL,nRe,HFt,JFt,Bie,YFt,ZFt,KFt,rL,sRe,eTt,oTt,Iie,rTt,tTt,aTt,tL,Ano,bf,aL,lRe,iB,nTt,iRe,sTt,Lno,$r,dB,lTt,vf,iTt,Nie,dTt,mTt,qie,cTt,fTt,gTt,mB,hTt,dRe,uTt,pTt,_Tt,_a,cB,bTt,mRe,vTt,FTt,Ff,TTt,cRe,MTt,ETt,jie,CTt,wTt,ATt,nL,LTt,st,fB,yTt,fRe,xTt,$Tt,os,kTt,gRe,STt,RTt,hRe,PTt,BTt,uRe,ITt,NTt,qTt,Se,sL,pRe,jTt,DTt,Die,GTt,OTt,VTt,lL,_Re,XTt,zTt,Gie,QTt,WTt,UTt,iL,bRe,HTt,JTt,Oie,YTt,ZTt,KTt,dL,vRe,eMt,oMt,Vie,rMt,tMt,aMt,mL,FRe,nMt,sMt,Xie,lMt,iMt,dMt,cL,TRe,mMt,cMt,zie,fMt,gMt,hMt,fL,MRe,uMt,pMt,Qie,_Mt,bMt,vMt,gL,ERe,FMt,TMt,Wie,MMt,EMt,CMt,hL,CRe,wMt,AMt,Uie,LMt,yMt,xMt,uL,wRe,$Mt,kMt,Hie,SMt,RMt,PMt,pL,yno,Tf,_L,ARe,gB,BMt,LRe,IMt,xno,kr,hB,NMt,Mf,qMt,Jie,jMt,DMt,Yie,GMt,OMt,VMt,uB,XMt,yRe,zMt,QMt,WMt,ba,pB,UMt,xRe,HMt,JMt,Ef,YMt,$Re,ZMt,KMt,Zie,eEt,oEt,rEt,bL,tEt,lt,_B,aEt,kRe,nEt,sEt,rs,lEt,SRe,iEt,dEt,RRe,mEt,cEt,PRe,fEt,gEt,hEt,Re,vL,BRe,uEt,pEt,Kie,_Et,bEt,vEt,FL,IRe,FEt,TEt,ede,MEt,EEt,CEt,TL,NRe,wEt,AEt,ode,LEt,yEt,xEt,ML,qRe,$Et,kEt,rde,SEt,REt,PEt,EL,jRe,BEt,IEt,tde,NEt,qEt,jEt,CL,DRe,DEt,GEt,ade,OEt,VEt,XEt,wL,GRe,zEt,QEt,nde,WEt,UEt,HEt,AL,ORe,JEt,YEt,sde,ZEt,KEt,e4t,LL,VRe,o4t,r4t,lde,t4t,a4t,n4t,yL,XRe,s4t,l4t,ide,i4t,d4t,m4t,xL,$no,Cf,$L,zRe,bB,c4t,QRe,f4t,kno,Sr,vB,g4t,wf,h4t,dde,u4t,p4t,mde,_4t,b4t,v4t,FB,F4t,WRe,T4t,M4t,E4t,va,TB,C4t,URe,w4t,A4t,Af,L4t,HRe,y4t,x4t,cde,$4t,k4t,S4t,kL,R4t,it,MB,P4t,JRe,B4t,I4t,ts,N4t,YRe,q4t,j4t,ZRe,D4t,G4t,KRe,O4t,V4t,X4t,Pe,SL,ePe,z4t,Q4t,fde,W4t,U4t,H4t,RL,oPe,J4t,Y4t,gde,Z4t,K4t,eCt,PL,rPe,oCt,rCt,hde,tCt,aCt,nCt,BL,tPe,sCt,lCt,ude,iCt,dCt,mCt,IL,aPe,cCt,fCt,pde,gCt,hCt,uCt,NL,nPe,pCt,_Ct,_de,bCt,vCt,FCt,qL,sPe,TCt,MCt,bde,ECt,CCt,wCt,jL,lPe,ACt,LCt,vde,yCt,xCt,$Ct,DL,iPe,kCt,SCt,Fde,RCt,PCt,BCt,GL,dPe,ICt,NCt,Tde,qCt,jCt,DCt,OL,Sno,Lf,VL,mPe,EB,GCt,cPe,OCt,Rno,Rr,CB,VCt,yf,XCt,Mde,zCt,QCt,Ede,WCt,UCt,HCt,wB,JCt,fPe,YCt,ZCt,KCt,Fa,AB,e3t,gPe,o3t,r3t,xf,t3t,hPe,a3t,n3t,Cde,s3t,l3t,i3t,XL,d3t,dt,LB,m3t,uPe,c3t,f3t,as,g3t,pPe,h3t,u3t,_Pe,p3t,_3t,bPe,b3t,v3t,F3t,ze,zL,vPe,T3t,M3t,wde,E3t,C3t,w3t,QL,FPe,A3t,L3t,Ade,y3t,x3t,$3t,WL,TPe,k3t,S3t,Lde,R3t,P3t,B3t,UL,MPe,I3t,N3t,yde,q3t,j3t,D3t,HL,EPe,G3t,O3t,xde,V3t,X3t,z3t,JL,CPe,Q3t,W3t,$de,U3t,H3t,J3t,YL,wPe,Y3t,Z3t,kde,K3t,e5t,o5t,ZL,APe,r5t,t5t,Sde,a5t,n5t,s5t,KL,Pno,$f,ey,LPe,yB,l5t,yPe,i5t,Bno,Pr,xB,d5t,kf,m5t,Rde,c5t,f5t,Pde,g5t,h5t,u5t,$B,p5t,xPe,_5t,b5t,v5t,Ta,kB,F5t,$Pe,T5t,M5t,Sf,E5t,kPe,C5t,w5t,Bde,A5t,L5t,y5t,oy,x5t,mt,SB,$5t,SPe,k5t,S5t,ns,R5t,RPe,P5t,B5t,PPe,I5t,N5t,BPe,q5t,j5t,D5t,Qe,ry,IPe,G5t,O5t,Ide,V5t,X5t,z5t,ty,NPe,Q5t,W5t,Nde,U5t,H5t,J5t,ay,qPe,Y5t,Z5t,qde,K5t,e0t,o0t,ny,jPe,r0t,t0t,jde,a0t,n0t,s0t,sy,DPe,l0t,i0t,Dde,d0t,m0t,c0t,ly,GPe,f0t,g0t,Gde,h0t,u0t,p0t,iy,OPe,_0t,b0t,Ode,v0t,F0t,T0t,dy,VPe,M0t,E0t,Vde,C0t,w0t,A0t,my,Ino,Rf,cy,XPe,RB,L0t,zPe,y0t,Nno,Br,PB,x0t,Pf,$0t,Xde,k0t,S0t,zde,R0t,P0t,B0t,BB,I0t,QPe,N0t,q0t,j0t,Ma,IB,D0t,WPe,G0t,O0t,Bf,V0t,UPe,X0t,z0t,Qde,Q0t,W0t,U0t,fy,H0t,ct,NB,J0t,HPe,Y0t,Z0t,ss,K0t,JPe,ewt,owt,YPe,rwt,twt,ZPe,awt,nwt,swt,KPe,gy,eBe,lwt,iwt,Wde,dwt,mwt,cwt,hy,qno,If,uy,oBe,qB,fwt,rBe,gwt,jno,Ir,jB,hwt,Nf,uwt,Ude,pwt,_wt,Hde,bwt,vwt,Fwt,DB,Twt,tBe,Mwt,Ewt,Cwt,Ea,GB,wwt,aBe,Awt,Lwt,qf,ywt,nBe,xwt,$wt,Jde,kwt,Swt,Rwt,py,Pwt,ft,OB,Bwt,sBe,Iwt,Nwt,ls,qwt,lBe,jwt,Dwt,iBe,Gwt,Owt,dBe,Vwt,Xwt,zwt,VB,_y,mBe,Qwt,Wwt,Yde,Uwt,Hwt,Jwt,by,cBe,Ywt,Zwt,Zde,Kwt,eAt,oAt,vy,Dno,jf,Fy,fBe,XB,rAt,gBe,tAt,Gno,Nr,zB,aAt,Df,nAt,Kde,sAt,lAt,eme,iAt,dAt,mAt,QB,cAt,hBe,fAt,gAt,hAt,Ca,WB,uAt,uBe,pAt,_At,Gf,bAt,pBe,vAt,FAt,ome,TAt,MAt,EAt,Ty,CAt,gt,UB,wAt,_Be,AAt,LAt,is,yAt,bBe,xAt,$At,vBe,kAt,SAt,FBe,RAt,PAt,BAt,TBe,My,MBe,IAt,NAt,rme,qAt,jAt,DAt,Ey,Ono;return d=new oe({}),on=new B({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),d$=new oe({}),m$=new B({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),Jf=new GAt({props:{warning:!0,$$slots:{default:[y3a]},$$scope:{ctx:$}}}),c$=new oe({}),f$=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L665"}}),u$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L688"}}),wu=new N({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[x3a]},$$scope:{ctx:$}}}),p$=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L811"}}),_$=new oe({}),b$=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L437"}}),T$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/main/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L451"}}),mp=new N({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[$3a]},$$scope:{ctx:$}}}),M$=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L652"}}),E$=new oe({}),C$=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L204"}}),L$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/main/en/internal/image_processing_utils#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L218"}}),t_=new GAt({props:{$$slots:{default:[k3a]},$$scope:{ctx:$}}}),a_=new N({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[S3a]},$$scope:{ctx:$}}}),y$=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L345"}}),x$=new oe({}),$$=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L95"}}),R$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L109"}}),x_=new GAt({props:{$$slots:{default:[R3a]},$$scope:{ctx:$}}}),$_=new N({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[P3a]},$$scope:{ctx:$}}}),P$=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L276"}}),B$=new oe({}),I$=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L887"}}),q$=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel">CodeGenModel</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig">ConditionalDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrModel">ConditionalDetrModel</a> (Conditional DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrModel">DeformableDetrModel</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig">DonutSwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel">DonutSwinModel</a> (DonutSwin model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel">ErnieModel</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmModel">EsmModel</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig">GPTNeoXJapaneseConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel">GPTNeoXJapaneseModel</a> (GPT NeoX Japanese model)</li>
<li><a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel">GroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltModel">LiltModel</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMModel">MarkupLMModel</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel">MobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel">MvpModel</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel">NezhaModel</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel">OwlViTModel</a> (OWL-ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel">PegasusXModel</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model">Swinv2Model</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerConfig">TableTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerModel">TableTransformerModel</a> (Table Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig">TimeSeriesTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel">TimeSeriesTransformerModel</a> (Time Series Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig">ViTMSNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNModel">ViTMSNModel</a> (ViTMSN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel">VideoMAEModel</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperModel">WhisperModel</a> (Whisper model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig">XCLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel">XCLIPModel</a> (X-CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),R_=new N({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[B3a]},$$scope:{ctx:$}}}),j$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),ob=new N({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[I3a]},$$scope:{ctx:$}}}),D$=new oe({}),G$=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L894"}}),V$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining">ErnieForPreTraining</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining">NezhaForPreTraining</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining">VideoMAEForPreTraining</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),tb=new N({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[N3a]},$$scope:{ctx:$}}}),X$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Kb=new N({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[q3a]},$$scope:{ctx:$}}}),z$=new oe({}),Q$=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L909"}}),U$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM">CodeGenForCausalLM</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM">ErnieForCausalLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig">GPTNeoXJapaneseConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM">GPTNeoXJapaneseForCausalLM</a> (GPT NeoX Japanese model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM">MvpForCausalLM</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),ov=new N({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[j3a]},$$scope:{ctx:$}}}),H$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),zv=new N({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[D3a]},$$scope:{ctx:$}}}),J$=new oe({}),Y$=new R({props:{name:"class transformers.AutoModelForDepthEstimation",anchor:"transformers.AutoModelForDepthEstimation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1052"}}),K$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForDepthEstimation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDepthEstimation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTForDepthEstimation">DPTForDepthEstimation</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNForDepthEstimation">GLPNForDepthEstimation</a> (GLPN model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Wv=new N({props:{anchor:"transformers.AutoModelForDepthEstimation.from_config.example",$$slots:{default:[G3a]},$$scope:{ctx:$}}}),ek=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForDepthEstimation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Yv=new N({props:{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.example",$$slots:{default:[O3a]},$$scope:{ctx:$}}}),rk=new oe({}),tk=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L916"}}),nk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM">ErnieForMaskedLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM">NezhaForMaskedLM</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Kv=new N({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[V3a]},$$scope:{ctx:$}}}),sk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),DF=new N({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[X3a]},$$scope:{ctx:$}}}),lk=new oe({}),ik=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L923"}}),mk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration">PegasusXForConditionalGeneration</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),OF=new N({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[z3a]},$$scope:{ctx:$}}}),ck=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),mT=new N({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[Q3a]},$$scope:{ctx:$}}}),fk=new oe({}),gk=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L932"}}),uk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification">ErnieForSequenceClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmForSequenceClassification">EsmForSequenceClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltForSequenceClassification">LiltForSequenceClassification</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification">LukeForSequenceClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification">MarkupLMForSequenceClassification</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification">MvpForSequenceClassification</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification">NezhaForSequenceClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification">OPTForSequenceClassification</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),fT=new N({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[W3a]},$$scope:{ctx:$}}}),pk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),pM=new N({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[U3a]},$$scope:{ctx:$}}}),_k=new oe({}),bk=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L988"}}),Fk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice">ErnieForMultipleChoice</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice">LukeForMultipleChoice</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice">NezhaForMultipleChoice</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),bM=new N({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[H3a]},$$scope:{ctx:$}}}),Tk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),ZM=new N({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[J3a]},$$scope:{ctx:$}}}),Mk=new oe({}),Ek=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L995"}}),wk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction">ErnieForNextSentencePrediction</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction">NezhaForNextSentencePrediction</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),eE=new N({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[Y3a]},$$scope:{ctx:$}}}),Ak=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),dE=new N({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[Z3a]},$$scope:{ctx:$}}}),Lk=new oe({}),yk=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L981"}}),$k=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification">ErnieForTokenClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmForTokenClassification">EsmForTokenClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltForTokenClassification">LiltForTokenClassification</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification">LukeForTokenClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification">MarkupLMForTokenClassification</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification">NezhaForTokenClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),cE=new N({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[K3a]},$$scope:{ctx:$}}}),kk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),e4=new N({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[e5a]},$$scope:{ctx:$}}}),Sk=new oe({}),Rk=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L941"}}),Bk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForQuestionAnswering">BloomForQuestionAnswering</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering">ErnieForQuestionAnswering</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltForQuestionAnswering">LiltForQuestionAnswering</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering">LukeForQuestionAnswering</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering">MarkupLMForQuestionAnswering</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering">MvpForQuestionAnswering</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering">NezhaForQuestionAnswering</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForQuestionAnswering">OPTForQuestionAnswering</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),r4=new N({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[o5a]},$$scope:{ctx:$}}}),Ik=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Z4=new N({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[r5a]},$$scope:{ctx:$}}}),Nk=new oe({}),qk=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L948"}}),Dk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),eC=new N({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[t5a]},$$scope:{ctx:$}}}),Gk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),tC=new N({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[a5a]},$$scope:{ctx:$}}}),Ok=new oe({}),Vk=new R({props:{name:"class transformers.AutoModelForDocumentQuestionAnswering",anchor:"transformers.AutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L970"}}),zk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering">LayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),nC=new N({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[n5a]},$$scope:{ctx:$}}}),Qk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),mC=new N({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[s5a]},$$scope:{ctx:$}}}),Wk=new oe({}),Uk=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1004"}}),Jk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification">MobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification">Swinv2ForImageClassification</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig">ViTMSNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification">ViTMSNForImageClassification</a> (ViTMSN model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),fC=new N({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[l5a]},$$scope:{ctx:$}}}),Yk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),xC=new N({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[i5a]},$$scope:{ctx:$}}}),Zk=new oe({}),Kk=new R({props:{name:"class transformers.AutoModelForVideoClassification",anchor:"transformers.AutoModelForVideoClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1059"}}),oS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVideoClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification">VideoMAEForVideoClassification</a> (VideoMAE model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),kC=new N({props:{anchor:"transformers.AutoModelForVideoClassification.from_config.example",$$slots:{default:[d5a]},$$scope:{ctx:$}}}),rS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVideoClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),PC=new N({props:{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.example",$$slots:{default:[m5a]},$$scope:{ctx:$}}}),tS=new oe({}),aS=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1066"}}),sS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),IC=new N({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[c5a]},$$scope:{ctx:$}}}),lS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),jC=new N({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[f5a]},$$scope:{ctx:$}}}),iS=new oe({}),dS=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L959"}}),cS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),GC=new N({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[g5a]},$$scope:{ctx:$}}}),fS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),XC=new N({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[h5a]},$$scope:{ctx:$}}}),gS=new oe({}),hS=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1073"}}),pS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),QC=new N({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[u5a]},$$scope:{ctx:$}}}),_S=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),t3=new N({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[p5a]},$$scope:{ctx:$}}}),bS=new oe({}),vS=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1096"}}),TS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),n3=new N({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[_5a]},$$scope:{ctx:$}}}),MS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),f3=new N({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[b5a]},$$scope:{ctx:$}}}),ES=new oe({}),CS=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1080"}}),AS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),h3=new N({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[v5a]},$$scope:{ctx:$}}}),LS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),A3=new N({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[F5a]},$$scope:{ctx:$}}}),yS=new oe({}),xS=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1087"}}),kS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperForConditionalGeneration">WhisperForConditionalGeneration</a> (Whisper model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),y3=new N({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[T5a]},$$scope:{ctx:$}}}),SS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),R3=new N({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[M5a]},$$scope:{ctx:$}}}),RS=new oe({}),PS=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1105"}}),IS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),B3=new N({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[E5a]},$$scope:{ctx:$}}}),NS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),O3=new N({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[C5a]},$$scope:{ctx:$}}}),qS=new oe({}),jS=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1112"}}),GS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling">Swinv2ForMaskedImageModeling</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),X3=new N({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[w5a]},$$scope:{ctx:$}}}),OS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),J3=new N({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[A5a]},$$scope:{ctx:$}}}),VS=new oe({}),XS=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1036"}}),QS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig">ConditionalDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection">ConditionalDetrForObjectDetection</a> (Conditional DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection">DeformableDetrForObjectDetection</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerConfig">TableTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerForObjectDetection">TableTransformerForObjectDetection</a> (Table Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Z3=new N({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[L5a]},$$scope:{ctx:$}}}),WS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),n5=new N({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[y5a]},$$scope:{ctx:$}}}),US=new oe({}),HS=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1011"}}),YS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),l5=new N({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[x5a]},$$scope:{ctx:$}}}),ZS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),m5=new N({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[$5a]},$$scope:{ctx:$}}}),KS=new oe({}),eR=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1018"}}),rR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation">MobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),f5=new N({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[k5a]},$$scope:{ctx:$}}}),tR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),v5=new N({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[S5a]},$$scope:{ctx:$}}}),aR=new oe({}),nR=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1027"}}),lR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),T5=new N({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[R5a]},$$scope:{ctx:$}}}),iR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),C5=new N({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[P5a]},$$scope:{ctx:$}}}),dR=new oe({}),mR=new R({props:{name:"class transformers.AutoModelForZeroShotObjectDetection",anchor:"transformers.AutoModelForZeroShotObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1043"}}),fR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTForObjectDetection">OwlViTForObjectDetection</a> (OWL-ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),A5=new N({props:{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config.example",$$slots:{default:[B5a]},$$scope:{ctx:$}}}),gR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),x5=new N({props:{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.example",$$slots:{default:[I5a]},$$scope:{ctx:$}}}),hR=new oe({}),uR=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L444"}}),_R=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtModel">TFCvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel">TFDeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmModel">TFEsmModel</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/groupvit#transformers.TFGroupViTModel">TFGroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model">TFLayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel">TFMobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel">TFRegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel">TFResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel">TFSegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperModel">TFWhisperModel</a> (Whisper model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel">TFXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),k5=new N({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[N5a]},$$scope:{ctx:$}}}),bR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),B0=new N({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[q5a]},$$scope:{ctx:$}}}),vR=new oe({}),FR=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L451"}}),MR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),N0=new N({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[j5a]},$$scope:{ctx:$}}}),ER=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),lw=new N({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[D5a]},$$scope:{ctx:$}}}),CR=new oe({}),wR=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L466"}}),LR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM">TFXGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),dw=new N({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[G5a]},$$scope:{ctx:$}}}),yR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Cw=new N({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[O5a]},$$scope:{ctx:$}}}),xR=new oe({}),$R=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L482"}}),SR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtForImageClassification">TFCvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification">TFDeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher">TFDeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification">TFMobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification">TFRegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification">TFResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification">TFSegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Aw=new N({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[V5a]},$$scope:{ctx:$}}}),RR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Iw=new N({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[X5a]},$$scope:{ctx:$}}}),PR=new oe({}),BR=new R({props:{name:"class transformers.TFAutoModelForSemanticSegmentation",anchor:"transformers.TFAutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L491"}}),NR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation">TFData2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation">TFMobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation">TFSegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),qw=new N({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[z5a]},$$scope:{ctx:$}}}),qR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Ow=new N({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[Q5a]},$$scope:{ctx:$}}}),jR=new oe({}),DR=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L507"}}),OR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForMaskedLM">TFEsmForMaskedLM</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Xw=new N({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[W5a]},$$scope:{ctx:$}}}),VR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),fA=new N({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[U5a]},$$scope:{ctx:$}}}),XR=new oe({}),zR=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L514"}}),WR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),hA=new N({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[H5a]},$$scope:{ctx:$}}}),UR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),wA=new N({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[J5a]},$$scope:{ctx:$}}}),HR=new oe({}),JR=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L523"}}),ZR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForSequenceClassification">TFEsmForSequenceClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification">TFLayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),LA=new N({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[Y5a]},$$scope:{ctx:$}}}),KR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),r6=new N({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[Z5a]},$$scope:{ctx:$}}}),eP=new oe({}),oP=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L570"}}),tP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),a6=new N({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[K5a]},$$scope:{ctx:$}}}),aP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),M6=new N({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[e0a]},$$scope:{ctx:$}}}),nP=new oe({}),sP=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L577"}}),iP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),C6=new N({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[o0a]},$$scope:{ctx:$}}}),dP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),L6=new N({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[r0a]},$$scope:{ctx:$}}}),cP=new oe({}),fP=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L550"}}),hP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),x6=new N({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[t0a]},$$scope:{ctx:$}}}),uP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),k6=new N({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[a0a]},$$scope:{ctx:$}}}),pP=new oe({}),_P=new R({props:{name:"class transformers.TFAutoModelForDocumentQuestionAnswering",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L539"}}),vP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering">TFLayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),R6=new N({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[n0a]},$$scope:{ctx:$}}}),FP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),B6=new N({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[s0a]},$$scope:{ctx:$}}}),TP=new oe({}),MP=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L561"}}),CP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForTokenClassification">TFEsmForTokenClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification">TFLayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),N6=new N({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[l0a]},$$scope:{ctx:$}}}),wP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),s7=new N({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[i0a]},$$scope:{ctx:$}}}),AP=new oe({}),LP=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L532"}}),xP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering">TFLayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),i7=new N({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[d0a]},$$scope:{ctx:$}}}),$P=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),$7=new N({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[m0a]},$$scope:{ctx:$}}}),kP=new oe({}),SP=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L500"}}),PP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),S7=new N({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[c0a]},$$scope:{ctx:$}}}),BP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),P7=new N({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[f0a]},$$scope:{ctx:$}}}),IP=new oe({}),NP=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L586"}}),jP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration">TFWhisperForConditionalGeneration</a> (Whisper model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),I7=new N({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[g0a]},$$scope:{ctx:$}}}),DP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),j7=new N({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[h0a]},$$scope:{ctx:$}}}),OP=new oe({}),VP=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),zP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),G7=new N({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[u0a]},$$scope:{ctx:$}}}),QP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),u8=new N({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[p0a]},$$scope:{ctx:$}}}),WP=new oe({}),UP=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L260"}}),JP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),_8=new N({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[_0a]},$$scope:{ctx:$}}}),YP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),y8=new N({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[b0a]},$$scope:{ctx:$}}}),ZP=new oe({}),KP=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L253"}}),oB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),$8=new N({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[v0a]},$$scope:{ctx:$}}}),rB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),X8=new N({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[F0a]},$$scope:{ctx:$}}}),tB=new oe({}),aB=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L267"}}),sB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Q8=new N({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[T0a]},$$scope:{ctx:$}}}),lB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),tL=new N({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[M0a]},$$scope:{ctx:$}}}),iB=new oe({}),dB=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),cB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),nL=new N({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[E0a]},$$scope:{ctx:$}}}),fB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),pL=new N({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[C0a]},$$scope:{ctx:$}}}),gB=new oe({}),hB=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),pB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),bL=new N({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[w0a]},$$scope:{ctx:$}}}),_B=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),xL=new N({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[A0a]},$$scope:{ctx:$}}}),bB=new oe({}),vB=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),TB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),kL=new N({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[L0a]},$$scope:{ctx:$}}}),MB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),OL=new N({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[y0a]},$$scope:{ctx:$}}}),EB=new oe({}),CB=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),AB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),XL=new N({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[x0a]},$$scope:{ctx:$}}}),LB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),KL=new N({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[$0a]},$$scope:{ctx:$}}}),yB=new oe({}),xB=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L308"}}),kB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),oy=new N({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[k0a]},$$scope:{ctx:$}}}),SB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),my=new N({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[S0a]},$$scope:{ctx:$}}}),RB=new oe({}),PB=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),IB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),fy=new N({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[R0a]},$$scope:{ctx:$}}}),NB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),hy=new N({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[P0a]},$$scope:{ctx:$}}}),qB=new oe({}),jB=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),GB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),py=new N({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[B0a]},$$scope:{ctx:$}}}),OB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),vy=new N({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[I0a]},$$scope:{ctx:$}}}),XB=new oe({}),zB=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),WB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Ty=new N({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[N0a]},$$scope:{ctx:$}}}),UB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Ey=new N({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[q0a]},$$scope:{ctx:$}}}),{c(){g=a("meta"),v=l(),u=a("h1"),f=a("a"),p=a("span"),F(d.$$.fragment),h=l(),$o=a("span"),bd=o("Auto Classes"),zf=l(),Tt=a("p"),vd=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Fd=a("code"),n$=o("from_pretrained()"),Qf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Xe=l(),He=a("p"),Td=o("Instantiating one of "),ms=a("a"),s$=o("AutoConfig"),cs=o(", "),fs=a("a"),l$=o("AutoModel"),Md=o(`, and
`),gs=a("a"),i$=o("AutoTokenizer"),Ed=o(" will directly create a class of the relevant architecture. For instance"),Wf=l(),F(on.$$.fragment),Je=l(),Ae=a("p"),MN=o("will create a model that is an instance of "),Cd=a("a"),EN=o("BertModel"),CN=o("."),ko=l(),rn=a("p"),wN=o("There is one class of "),Uf=a("code"),AN=o("AutoModel"),mio=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),wto=l(),wd=a("h2"),Hf=a("a"),cfe=a("span"),F(d$.$$.fragment),cio=l(),ffe=a("span"),fio=o("Extending the Auto Classes"),Ato=l(),hs=a("p"),gio=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),gfe=a("code"),hio=o("NewModel"),uio=o(", make sure you have a "),hfe=a("code"),pio=o("NewModelConfig"),_io=o(` then you can add those to the auto
classes like this:`),Lto=l(),F(m$.$$.fragment),yto=l(),LN=a("p"),bio=o("You will then be able to use the auto classes like you would usually do!"),xto=l(),F(Jf.$$.fragment),$to=l(),Ad=a("h2"),Yf=a("a"),ufe=a("span"),F(c$.$$.fragment),vio=l(),pfe=a("span"),Fio=o("AutoConfig"),kto=l(),So=a("div"),F(f$.$$.fragment),Tio=l(),g$=a("p"),Mio=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),yN=a("a"),Eio=o("from_pretrained()"),Cio=o(" class method."),wio=l(),h$=a("p"),Aio=o("This class cannot be instantiated directly using "),_fe=a("code"),Lio=o("__init__()"),yio=o(" (throws an error)."),xio=l(),qr=a("div"),F(u$.$$.fragment),$io=l(),bfe=a("p"),kio=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),Sio=l(),Ld=a("p"),Rio=o("The configuration class to instantiate is selected based on the "),vfe=a("code"),Pio=o("model_type"),Bio=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Ffe=a("code"),Iio=o("pretrained_model_name_or_path"),Nio=o(":"),qio=l(),A=a("ul"),Zf=a("li"),Tfe=a("strong"),jio=o("albert"),Dio=o(" \u2014 "),xN=a("a"),Gio=o("AlbertConfig"),Oio=o(" (ALBERT model)"),Vio=l(),Kf=a("li"),Mfe=a("strong"),Xio=o("bart"),zio=o(" \u2014 "),$N=a("a"),Qio=o("BartConfig"),Wio=o(" (BART model)"),Uio=l(),eg=a("li"),Efe=a("strong"),Hio=o("beit"),Jio=o(" \u2014 "),kN=a("a"),Yio=o("BeitConfig"),Zio=o(" (BEiT model)"),Kio=l(),og=a("li"),Cfe=a("strong"),edo=o("bert"),odo=o(" \u2014 "),SN=a("a"),rdo=o("BertConfig"),tdo=o(" (BERT model)"),ado=l(),rg=a("li"),wfe=a("strong"),ndo=o("bert-generation"),sdo=o(" \u2014 "),RN=a("a"),ldo=o("BertGenerationConfig"),ido=o(" (Bert Generation model)"),ddo=l(),tg=a("li"),Afe=a("strong"),mdo=o("big_bird"),cdo=o(" \u2014 "),PN=a("a"),fdo=o("BigBirdConfig"),gdo=o(" (BigBird model)"),hdo=l(),ag=a("li"),Lfe=a("strong"),udo=o("bigbird_pegasus"),pdo=o(" \u2014 "),BN=a("a"),_do=o("BigBirdPegasusConfig"),bdo=o(" (BigBird-Pegasus model)"),vdo=l(),ng=a("li"),yfe=a("strong"),Fdo=o("blenderbot"),Tdo=o(" \u2014 "),IN=a("a"),Mdo=o("BlenderbotConfig"),Edo=o(" (Blenderbot model)"),Cdo=l(),sg=a("li"),xfe=a("strong"),wdo=o("blenderbot-small"),Ado=o(" \u2014 "),NN=a("a"),Ldo=o("BlenderbotSmallConfig"),ydo=o(" (BlenderbotSmall model)"),xdo=l(),lg=a("li"),$fe=a("strong"),$do=o("bloom"),kdo=o(" \u2014 "),qN=a("a"),Sdo=o("BloomConfig"),Rdo=o(" (BLOOM model)"),Pdo=l(),ig=a("li"),kfe=a("strong"),Bdo=o("camembert"),Ido=o(" \u2014 "),jN=a("a"),Ndo=o("CamembertConfig"),qdo=o(" (CamemBERT model)"),jdo=l(),dg=a("li"),Sfe=a("strong"),Ddo=o("canine"),Gdo=o(" \u2014 "),DN=a("a"),Odo=o("CanineConfig"),Vdo=o(" (CANINE model)"),Xdo=l(),mg=a("li"),Rfe=a("strong"),zdo=o("clip"),Qdo=o(" \u2014 "),GN=a("a"),Wdo=o("CLIPConfig"),Udo=o(" (CLIP model)"),Hdo=l(),cg=a("li"),Pfe=a("strong"),Jdo=o("codegen"),Ydo=o(" \u2014 "),ON=a("a"),Zdo=o("CodeGenConfig"),Kdo=o(" (CodeGen model)"),emo=l(),fg=a("li"),Bfe=a("strong"),omo=o("conditional_detr"),rmo=o(" \u2014 "),VN=a("a"),tmo=o("ConditionalDetrConfig"),amo=o(" (Conditional DETR model)"),nmo=l(),gg=a("li"),Ife=a("strong"),smo=o("convbert"),lmo=o(" \u2014 "),XN=a("a"),imo=o("ConvBertConfig"),dmo=o(" (ConvBERT model)"),mmo=l(),hg=a("li"),Nfe=a("strong"),cmo=o("convnext"),fmo=o(" \u2014 "),zN=a("a"),gmo=o("ConvNextConfig"),hmo=o(" (ConvNeXT model)"),umo=l(),ug=a("li"),qfe=a("strong"),pmo=o("ctrl"),_mo=o(" \u2014 "),QN=a("a"),bmo=o("CTRLConfig"),vmo=o(" (CTRL model)"),Fmo=l(),pg=a("li"),jfe=a("strong"),Tmo=o("cvt"),Mmo=o(" \u2014 "),WN=a("a"),Emo=o("CvtConfig"),Cmo=o(" (CvT model)"),wmo=l(),_g=a("li"),Dfe=a("strong"),Amo=o("data2vec-audio"),Lmo=o(" \u2014 "),UN=a("a"),ymo=o("Data2VecAudioConfig"),xmo=o(" (Data2VecAudio model)"),$mo=l(),bg=a("li"),Gfe=a("strong"),kmo=o("data2vec-text"),Smo=o(" \u2014 "),HN=a("a"),Rmo=o("Data2VecTextConfig"),Pmo=o(" (Data2VecText model)"),Bmo=l(),vg=a("li"),Ofe=a("strong"),Imo=o("data2vec-vision"),Nmo=o(" \u2014 "),JN=a("a"),qmo=o("Data2VecVisionConfig"),jmo=o(" (Data2VecVision model)"),Dmo=l(),Fg=a("li"),Vfe=a("strong"),Gmo=o("deberta"),Omo=o(" \u2014 "),YN=a("a"),Vmo=o("DebertaConfig"),Xmo=o(" (DeBERTa model)"),zmo=l(),Tg=a("li"),Xfe=a("strong"),Qmo=o("deberta-v2"),Wmo=o(" \u2014 "),ZN=a("a"),Umo=o("DebertaV2Config"),Hmo=o(" (DeBERTa-v2 model)"),Jmo=l(),Mg=a("li"),zfe=a("strong"),Ymo=o("decision_transformer"),Zmo=o(" \u2014 "),KN=a("a"),Kmo=o("DecisionTransformerConfig"),eco=o(" (Decision Transformer model)"),oco=l(),Eg=a("li"),Qfe=a("strong"),rco=o("deformable_detr"),tco=o(" \u2014 "),eq=a("a"),aco=o("DeformableDetrConfig"),nco=o(" (Deformable DETR model)"),sco=l(),Cg=a("li"),Wfe=a("strong"),lco=o("deit"),ico=o(" \u2014 "),oq=a("a"),dco=o("DeiTConfig"),mco=o(" (DeiT model)"),cco=l(),wg=a("li"),Ufe=a("strong"),fco=o("detr"),gco=o(" \u2014 "),rq=a("a"),hco=o("DetrConfig"),uco=o(" (DETR model)"),pco=l(),Ag=a("li"),Hfe=a("strong"),_co=o("distilbert"),bco=o(" \u2014 "),tq=a("a"),vco=o("DistilBertConfig"),Fco=o(" (DistilBERT model)"),Tco=l(),Lg=a("li"),Jfe=a("strong"),Mco=o("donut-swin"),Eco=o(" \u2014 "),aq=a("a"),Cco=o("DonutSwinConfig"),wco=o(" (DonutSwin model)"),Aco=l(),yg=a("li"),Yfe=a("strong"),Lco=o("dpr"),yco=o(" \u2014 "),nq=a("a"),xco=o("DPRConfig"),$co=o(" (DPR model)"),kco=l(),xg=a("li"),Zfe=a("strong"),Sco=o("dpt"),Rco=o(" \u2014 "),sq=a("a"),Pco=o("DPTConfig"),Bco=o(" (DPT model)"),Ico=l(),$g=a("li"),Kfe=a("strong"),Nco=o("electra"),qco=o(" \u2014 "),lq=a("a"),jco=o("ElectraConfig"),Dco=o(" (ELECTRA model)"),Gco=l(),kg=a("li"),ege=a("strong"),Oco=o("encoder-decoder"),Vco=o(" \u2014 "),iq=a("a"),Xco=o("EncoderDecoderConfig"),zco=o(" (Encoder decoder model)"),Qco=l(),Sg=a("li"),oge=a("strong"),Wco=o("ernie"),Uco=o(" \u2014 "),dq=a("a"),Hco=o("ErnieConfig"),Jco=o(" (ERNIE model)"),Yco=l(),Rg=a("li"),rge=a("strong"),Zco=o("esm"),Kco=o(" \u2014 "),mq=a("a"),efo=o("EsmConfig"),ofo=o(" (ESM model)"),rfo=l(),Pg=a("li"),tge=a("strong"),tfo=o("flaubert"),afo=o(" \u2014 "),cq=a("a"),nfo=o("FlaubertConfig"),sfo=o(" (FlauBERT model)"),lfo=l(),Bg=a("li"),age=a("strong"),ifo=o("flava"),dfo=o(" \u2014 "),fq=a("a"),mfo=o("FlavaConfig"),cfo=o(" (FLAVA model)"),ffo=l(),Ig=a("li"),nge=a("strong"),gfo=o("fnet"),hfo=o(" \u2014 "),gq=a("a"),ufo=o("FNetConfig"),pfo=o(" (FNet model)"),_fo=l(),Ng=a("li"),sge=a("strong"),bfo=o("fsmt"),vfo=o(" \u2014 "),hq=a("a"),Ffo=o("FSMTConfig"),Tfo=o(" (FairSeq Machine-Translation model)"),Mfo=l(),qg=a("li"),lge=a("strong"),Efo=o("funnel"),Cfo=o(" \u2014 "),uq=a("a"),wfo=o("FunnelConfig"),Afo=o(" (Funnel Transformer model)"),Lfo=l(),jg=a("li"),ige=a("strong"),yfo=o("glpn"),xfo=o(" \u2014 "),pq=a("a"),$fo=o("GLPNConfig"),kfo=o(" (GLPN model)"),Sfo=l(),Dg=a("li"),dge=a("strong"),Rfo=o("gpt2"),Pfo=o(" \u2014 "),_q=a("a"),Bfo=o("GPT2Config"),Ifo=o(" (OpenAI GPT-2 model)"),Nfo=l(),Gg=a("li"),mge=a("strong"),qfo=o("gpt_neo"),jfo=o(" \u2014 "),bq=a("a"),Dfo=o("GPTNeoConfig"),Gfo=o(" (GPT Neo model)"),Ofo=l(),Og=a("li"),cge=a("strong"),Vfo=o("gpt_neox"),Xfo=o(" \u2014 "),vq=a("a"),zfo=o("GPTNeoXConfig"),Qfo=o(" (GPT NeoX model)"),Wfo=l(),Vg=a("li"),fge=a("strong"),Ufo=o("gpt_neox_japanese"),Hfo=o(" \u2014 "),Fq=a("a"),Jfo=o("GPTNeoXJapaneseConfig"),Yfo=o(" (GPT NeoX Japanese model)"),Zfo=l(),Xg=a("li"),gge=a("strong"),Kfo=o("gptj"),ego=o(" \u2014 "),Tq=a("a"),ogo=o("GPTJConfig"),rgo=o(" (GPT-J model)"),tgo=l(),zg=a("li"),hge=a("strong"),ago=o("groupvit"),ngo=o(" \u2014 "),Mq=a("a"),sgo=o("GroupViTConfig"),lgo=o(" (GroupViT model)"),igo=l(),Qg=a("li"),uge=a("strong"),dgo=o("hubert"),mgo=o(" \u2014 "),Eq=a("a"),cgo=o("HubertConfig"),fgo=o(" (Hubert model)"),ggo=l(),Wg=a("li"),pge=a("strong"),hgo=o("ibert"),ugo=o(" \u2014 "),Cq=a("a"),pgo=o("IBertConfig"),_go=o(" (I-BERT model)"),bgo=l(),Ug=a("li"),_ge=a("strong"),vgo=o("imagegpt"),Fgo=o(" \u2014 "),wq=a("a"),Tgo=o("ImageGPTConfig"),Mgo=o(" (ImageGPT model)"),Ego=l(),Hg=a("li"),bge=a("strong"),Cgo=o("layoutlm"),wgo=o(" \u2014 "),Aq=a("a"),Ago=o("LayoutLMConfig"),Lgo=o(" (LayoutLM model)"),ygo=l(),Jg=a("li"),vge=a("strong"),xgo=o("layoutlmv2"),$go=o(" \u2014 "),Lq=a("a"),kgo=o("LayoutLMv2Config"),Sgo=o(" (LayoutLMv2 model)"),Rgo=l(),Yg=a("li"),Fge=a("strong"),Pgo=o("layoutlmv3"),Bgo=o(" \u2014 "),yq=a("a"),Igo=o("LayoutLMv3Config"),Ngo=o(" (LayoutLMv3 model)"),qgo=l(),Zg=a("li"),Tge=a("strong"),jgo=o("led"),Dgo=o(" \u2014 "),xq=a("a"),Ggo=o("LEDConfig"),Ogo=o(" (LED model)"),Vgo=l(),Kg=a("li"),Mge=a("strong"),Xgo=o("levit"),zgo=o(" \u2014 "),$q=a("a"),Qgo=o("LevitConfig"),Wgo=o(" (LeViT model)"),Ugo=l(),eh=a("li"),Ege=a("strong"),Hgo=o("lilt"),Jgo=o(" \u2014 "),kq=a("a"),Ygo=o("LiltConfig"),Zgo=o(" (LiLT model)"),Kgo=l(),oh=a("li"),Cge=a("strong"),eho=o("longformer"),oho=o(" \u2014 "),Sq=a("a"),rho=o("LongformerConfig"),tho=o(" (Longformer model)"),aho=l(),rh=a("li"),wge=a("strong"),nho=o("longt5"),sho=o(" \u2014 "),Rq=a("a"),lho=o("LongT5Config"),iho=o(" (LongT5 model)"),dho=l(),th=a("li"),Age=a("strong"),mho=o("luke"),cho=o(" \u2014 "),Pq=a("a"),fho=o("LukeConfig"),gho=o(" (LUKE model)"),hho=l(),ah=a("li"),Lge=a("strong"),uho=o("lxmert"),pho=o(" \u2014 "),Bq=a("a"),_ho=o("LxmertConfig"),bho=o(" (LXMERT model)"),vho=l(),nh=a("li"),yge=a("strong"),Fho=o("m2m_100"),Tho=o(" \u2014 "),Iq=a("a"),Mho=o("M2M100Config"),Eho=o(" (M2M100 model)"),Cho=l(),sh=a("li"),xge=a("strong"),who=o("marian"),Aho=o(" \u2014 "),Nq=a("a"),Lho=o("MarianConfig"),yho=o(" (Marian model)"),xho=l(),lh=a("li"),$ge=a("strong"),$ho=o("markuplm"),kho=o(" \u2014 "),qq=a("a"),Sho=o("MarkupLMConfig"),Rho=o(" (MarkupLM model)"),Pho=l(),ih=a("li"),kge=a("strong"),Bho=o("maskformer"),Iho=o(" \u2014 "),jq=a("a"),Nho=o("MaskFormerConfig"),qho=o(" (MaskFormer model)"),jho=l(),dh=a("li"),Sge=a("strong"),Dho=o("mbart"),Gho=o(" \u2014 "),Dq=a("a"),Oho=o("MBartConfig"),Vho=o(" (mBART model)"),Xho=l(),mh=a("li"),Rge=a("strong"),zho=o("mctct"),Qho=o(" \u2014 "),Gq=a("a"),Who=o("MCTCTConfig"),Uho=o(" (M-CTC-T model)"),Hho=l(),ch=a("li"),Pge=a("strong"),Jho=o("megatron-bert"),Yho=o(" \u2014 "),Oq=a("a"),Zho=o("MegatronBertConfig"),Kho=o(" (Megatron-BERT model)"),euo=l(),fh=a("li"),Bge=a("strong"),ouo=o("mobilebert"),ruo=o(" \u2014 "),Vq=a("a"),tuo=o("MobileBertConfig"),auo=o(" (MobileBERT model)"),nuo=l(),gh=a("li"),Ige=a("strong"),suo=o("mobilevit"),luo=o(" \u2014 "),Xq=a("a"),iuo=o("MobileViTConfig"),duo=o(" (MobileViT model)"),muo=l(),hh=a("li"),Nge=a("strong"),cuo=o("mpnet"),fuo=o(" \u2014 "),zq=a("a"),guo=o("MPNetConfig"),huo=o(" (MPNet model)"),uuo=l(),uh=a("li"),qge=a("strong"),puo=o("mt5"),_uo=o(" \u2014 "),Qq=a("a"),buo=o("MT5Config"),vuo=o(" (MT5 model)"),Fuo=l(),ph=a("li"),jge=a("strong"),Tuo=o("mvp"),Muo=o(" \u2014 "),Wq=a("a"),Euo=o("MvpConfig"),Cuo=o(" (MVP model)"),wuo=l(),_h=a("li"),Dge=a("strong"),Auo=o("nezha"),Luo=o(" \u2014 "),Uq=a("a"),yuo=o("NezhaConfig"),xuo=o(" (Nezha model)"),$uo=l(),bh=a("li"),Gge=a("strong"),kuo=o("nystromformer"),Suo=o(" \u2014 "),Hq=a("a"),Ruo=o("NystromformerConfig"),Puo=o(" (Nystr\xF6mformer model)"),Buo=l(),vh=a("li"),Oge=a("strong"),Iuo=o("openai-gpt"),Nuo=o(" \u2014 "),Jq=a("a"),quo=o("OpenAIGPTConfig"),juo=o(" (OpenAI GPT model)"),Duo=l(),Fh=a("li"),Vge=a("strong"),Guo=o("opt"),Ouo=o(" \u2014 "),Yq=a("a"),Vuo=o("OPTConfig"),Xuo=o(" (OPT model)"),zuo=l(),Th=a("li"),Xge=a("strong"),Quo=o("owlvit"),Wuo=o(" \u2014 "),Zq=a("a"),Uuo=o("OwlViTConfig"),Huo=o(" (OWL-ViT model)"),Juo=l(),Mh=a("li"),zge=a("strong"),Yuo=o("pegasus"),Zuo=o(" \u2014 "),Kq=a("a"),Kuo=o("PegasusConfig"),epo=o(" (Pegasus model)"),opo=l(),Eh=a("li"),Qge=a("strong"),rpo=o("pegasus_x"),tpo=o(" \u2014 "),ej=a("a"),apo=o("PegasusXConfig"),npo=o(" (PEGASUS-X model)"),spo=l(),Ch=a("li"),Wge=a("strong"),lpo=o("perceiver"),ipo=o(" \u2014 "),oj=a("a"),dpo=o("PerceiverConfig"),mpo=o(" (Perceiver model)"),cpo=l(),wh=a("li"),Uge=a("strong"),fpo=o("plbart"),gpo=o(" \u2014 "),rj=a("a"),hpo=o("PLBartConfig"),upo=o(" (PLBart model)"),ppo=l(),Ah=a("li"),Hge=a("strong"),_po=o("poolformer"),bpo=o(" \u2014 "),tj=a("a"),vpo=o("PoolFormerConfig"),Fpo=o(" (PoolFormer model)"),Tpo=l(),Lh=a("li"),Jge=a("strong"),Mpo=o("prophetnet"),Epo=o(" \u2014 "),aj=a("a"),Cpo=o("ProphetNetConfig"),wpo=o(" (ProphetNet model)"),Apo=l(),yh=a("li"),Yge=a("strong"),Lpo=o("qdqbert"),ypo=o(" \u2014 "),nj=a("a"),xpo=o("QDQBertConfig"),$po=o(" (QDQBert model)"),kpo=l(),xh=a("li"),Zge=a("strong"),Spo=o("rag"),Rpo=o(" \u2014 "),sj=a("a"),Ppo=o("RagConfig"),Bpo=o(" (RAG model)"),Ipo=l(),$h=a("li"),Kge=a("strong"),Npo=o("realm"),qpo=o(" \u2014 "),lj=a("a"),jpo=o("RealmConfig"),Dpo=o(" (REALM model)"),Gpo=l(),kh=a("li"),ehe=a("strong"),Opo=o("reformer"),Vpo=o(" \u2014 "),ij=a("a"),Xpo=o("ReformerConfig"),zpo=o(" (Reformer model)"),Qpo=l(),Sh=a("li"),ohe=a("strong"),Wpo=o("regnet"),Upo=o(" \u2014 "),dj=a("a"),Hpo=o("RegNetConfig"),Jpo=o(" (RegNet model)"),Ypo=l(),Rh=a("li"),rhe=a("strong"),Zpo=o("rembert"),Kpo=o(" \u2014 "),mj=a("a"),e_o=o("RemBertConfig"),o_o=o(" (RemBERT model)"),r_o=l(),Ph=a("li"),the=a("strong"),t_o=o("resnet"),a_o=o(" \u2014 "),cj=a("a"),n_o=o("ResNetConfig"),s_o=o(" (ResNet model)"),l_o=l(),Bh=a("li"),ahe=a("strong"),i_o=o("retribert"),d_o=o(" \u2014 "),fj=a("a"),m_o=o("RetriBertConfig"),c_o=o(" (RetriBERT model)"),f_o=l(),Ih=a("li"),nhe=a("strong"),g_o=o("roberta"),h_o=o(" \u2014 "),gj=a("a"),u_o=o("RobertaConfig"),p_o=o(" (RoBERTa model)"),__o=l(),Nh=a("li"),she=a("strong"),b_o=o("roformer"),v_o=o(" \u2014 "),hj=a("a"),F_o=o("RoFormerConfig"),T_o=o(" (RoFormer model)"),M_o=l(),qh=a("li"),lhe=a("strong"),E_o=o("segformer"),C_o=o(" \u2014 "),uj=a("a"),w_o=o("SegformerConfig"),A_o=o(" (SegFormer model)"),L_o=l(),jh=a("li"),ihe=a("strong"),y_o=o("sew"),x_o=o(" \u2014 "),pj=a("a"),$_o=o("SEWConfig"),k_o=o(" (SEW model)"),S_o=l(),Dh=a("li"),dhe=a("strong"),R_o=o("sew-d"),P_o=o(" \u2014 "),_j=a("a"),B_o=o("SEWDConfig"),I_o=o(" (SEW-D model)"),N_o=l(),Gh=a("li"),mhe=a("strong"),q_o=o("speech-encoder-decoder"),j_o=o(" \u2014 "),bj=a("a"),D_o=o("SpeechEncoderDecoderConfig"),G_o=o(" (Speech Encoder decoder model)"),O_o=l(),Oh=a("li"),che=a("strong"),V_o=o("speech_to_text"),X_o=o(" \u2014 "),vj=a("a"),z_o=o("Speech2TextConfig"),Q_o=o(" (Speech2Text model)"),W_o=l(),Vh=a("li"),fhe=a("strong"),U_o=o("speech_to_text_2"),H_o=o(" \u2014 "),Fj=a("a"),J_o=o("Speech2Text2Config"),Y_o=o(" (Speech2Text2 model)"),Z_o=l(),Xh=a("li"),ghe=a("strong"),K_o=o("splinter"),e1o=o(" \u2014 "),Tj=a("a"),o1o=o("SplinterConfig"),r1o=o(" (Splinter model)"),t1o=l(),zh=a("li"),hhe=a("strong"),a1o=o("squeezebert"),n1o=o(" \u2014 "),Mj=a("a"),s1o=o("SqueezeBertConfig"),l1o=o(" (SqueezeBERT model)"),i1o=l(),Qh=a("li"),uhe=a("strong"),d1o=o("swin"),m1o=o(" \u2014 "),Ej=a("a"),c1o=o("SwinConfig"),f1o=o(" (Swin Transformer model)"),g1o=l(),Wh=a("li"),phe=a("strong"),h1o=o("swinv2"),u1o=o(" \u2014 "),Cj=a("a"),p1o=o("Swinv2Config"),_1o=o(" (Swin Transformer V2 model)"),b1o=l(),Uh=a("li"),_he=a("strong"),v1o=o("t5"),F1o=o(" \u2014 "),wj=a("a"),T1o=o("T5Config"),M1o=o(" (T5 model)"),E1o=l(),Hh=a("li"),bhe=a("strong"),C1o=o("table-transformer"),w1o=o(" \u2014 "),Aj=a("a"),A1o=o("TableTransformerConfig"),L1o=o(" (Table Transformer model)"),y1o=l(),Jh=a("li"),vhe=a("strong"),x1o=o("tapas"),$1o=o(" \u2014 "),Lj=a("a"),k1o=o("TapasConfig"),S1o=o(" (TAPAS model)"),R1o=l(),Yh=a("li"),Fhe=a("strong"),P1o=o("time_series_transformer"),B1o=o(" \u2014 "),yj=a("a"),I1o=o("TimeSeriesTransformerConfig"),N1o=o(" (Time Series Transformer model)"),q1o=l(),Zh=a("li"),The=a("strong"),j1o=o("trajectory_transformer"),D1o=o(" \u2014 "),xj=a("a"),G1o=o("TrajectoryTransformerConfig"),O1o=o(" (Trajectory Transformer model)"),V1o=l(),Kh=a("li"),Mhe=a("strong"),X1o=o("transfo-xl"),z1o=o(" \u2014 "),$j=a("a"),Q1o=o("TransfoXLConfig"),W1o=o(" (Transformer-XL model)"),U1o=l(),eu=a("li"),Ehe=a("strong"),H1o=o("trocr"),J1o=o(" \u2014 "),kj=a("a"),Y1o=o("TrOCRConfig"),Z1o=o(" (TrOCR model)"),K1o=l(),ou=a("li"),Che=a("strong"),e2o=o("unispeech"),o2o=o(" \u2014 "),Sj=a("a"),r2o=o("UniSpeechConfig"),t2o=o(" (UniSpeech model)"),a2o=l(),ru=a("li"),whe=a("strong"),n2o=o("unispeech-sat"),s2o=o(" \u2014 "),Rj=a("a"),l2o=o("UniSpeechSatConfig"),i2o=o(" (UniSpeechSat model)"),d2o=l(),tu=a("li"),Ahe=a("strong"),m2o=o("van"),c2o=o(" \u2014 "),Pj=a("a"),f2o=o("VanConfig"),g2o=o(" (VAN model)"),h2o=l(),au=a("li"),Lhe=a("strong"),u2o=o("videomae"),p2o=o(" \u2014 "),Bj=a("a"),_2o=o("VideoMAEConfig"),b2o=o(" (VideoMAE model)"),v2o=l(),nu=a("li"),yhe=a("strong"),F2o=o("vilt"),T2o=o(" \u2014 "),Ij=a("a"),M2o=o("ViltConfig"),E2o=o(" (ViLT model)"),C2o=l(),su=a("li"),xhe=a("strong"),w2o=o("vision-encoder-decoder"),A2o=o(" \u2014 "),Nj=a("a"),L2o=o("VisionEncoderDecoderConfig"),y2o=o(" (Vision Encoder decoder model)"),x2o=l(),lu=a("li"),$he=a("strong"),$2o=o("vision-text-dual-encoder"),k2o=o(" \u2014 "),qj=a("a"),S2o=o("VisionTextDualEncoderConfig"),R2o=o(" (VisionTextDualEncoder model)"),P2o=l(),iu=a("li"),khe=a("strong"),B2o=o("visual_bert"),I2o=o(" \u2014 "),jj=a("a"),N2o=o("VisualBertConfig"),q2o=o(" (VisualBERT model)"),j2o=l(),du=a("li"),She=a("strong"),D2o=o("vit"),G2o=o(" \u2014 "),Dj=a("a"),O2o=o("ViTConfig"),V2o=o(" (ViT model)"),X2o=l(),mu=a("li"),Rhe=a("strong"),z2o=o("vit_mae"),Q2o=o(" \u2014 "),Gj=a("a"),W2o=o("ViTMAEConfig"),U2o=o(" (ViTMAE model)"),H2o=l(),cu=a("li"),Phe=a("strong"),J2o=o("vit_msn"),Y2o=o(" \u2014 "),Oj=a("a"),Z2o=o("ViTMSNConfig"),K2o=o(" (ViTMSN model)"),ebo=l(),fu=a("li"),Bhe=a("strong"),obo=o("wav2vec2"),rbo=o(" \u2014 "),Vj=a("a"),tbo=o("Wav2Vec2Config"),abo=o(" (Wav2Vec2 model)"),nbo=l(),gu=a("li"),Ihe=a("strong"),sbo=o("wav2vec2-conformer"),lbo=o(" \u2014 "),Xj=a("a"),ibo=o("Wav2Vec2ConformerConfig"),dbo=o(" (Wav2Vec2-Conformer model)"),mbo=l(),hu=a("li"),Nhe=a("strong"),cbo=o("wavlm"),fbo=o(" \u2014 "),zj=a("a"),gbo=o("WavLMConfig"),hbo=o(" (WavLM model)"),ubo=l(),uu=a("li"),qhe=a("strong"),pbo=o("whisper"),_bo=o(" \u2014 "),Qj=a("a"),bbo=o("WhisperConfig"),vbo=o(" (Whisper model)"),Fbo=l(),pu=a("li"),jhe=a("strong"),Tbo=o("xclip"),Mbo=o(" \u2014 "),Wj=a("a"),Ebo=o("XCLIPConfig"),Cbo=o(" (X-CLIP model)"),wbo=l(),_u=a("li"),Dhe=a("strong"),Abo=o("xglm"),Lbo=o(" \u2014 "),Uj=a("a"),ybo=o("XGLMConfig"),xbo=o(" (XGLM model)"),$bo=l(),bu=a("li"),Ghe=a("strong"),kbo=o("xlm"),Sbo=o(" \u2014 "),Hj=a("a"),Rbo=o("XLMConfig"),Pbo=o(" (XLM model)"),Bbo=l(),vu=a("li"),Ohe=a("strong"),Ibo=o("xlm-prophetnet"),Nbo=o(" \u2014 "),Jj=a("a"),qbo=o("XLMProphetNetConfig"),jbo=o(" (XLM-ProphetNet model)"),Dbo=l(),Fu=a("li"),Vhe=a("strong"),Gbo=o("xlm-roberta"),Obo=o(" \u2014 "),Yj=a("a"),Vbo=o("XLMRobertaConfig"),Xbo=o(" (XLM-RoBERTa model)"),zbo=l(),Tu=a("li"),Xhe=a("strong"),Qbo=o("xlm-roberta-xl"),Wbo=o(" \u2014 "),Zj=a("a"),Ubo=o("XLMRobertaXLConfig"),Hbo=o(" (XLM-RoBERTa-XL model)"),Jbo=l(),Mu=a("li"),zhe=a("strong"),Ybo=o("xlnet"),Zbo=o(" \u2014 "),Kj=a("a"),Kbo=o("XLNetConfig"),evo=o(" (XLNet model)"),ovo=l(),Eu=a("li"),Qhe=a("strong"),rvo=o("yolos"),tvo=o(" \u2014 "),eD=a("a"),avo=o("YolosConfig"),nvo=o(" (YOLOS model)"),svo=l(),Cu=a("li"),Whe=a("strong"),lvo=o("yoso"),ivo=o(" \u2014 "),oD=a("a"),dvo=o("YosoConfig"),mvo=o(" (YOSO model)"),cvo=l(),F(wu.$$.fragment),fvo=l(),Au=a("div"),F(p$.$$.fragment),gvo=l(),Uhe=a("p"),hvo=o("Register a new configuration for this class."),Sto=l(),yd=a("h2"),Lu=a("a"),Hhe=a("span"),F(_$.$$.fragment),uvo=l(),Jhe=a("span"),pvo=o("AutoTokenizer"),Rto=l(),Ro=a("div"),F(b$.$$.fragment),_vo=l(),v$=a("p"),bvo=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),rD=a("a"),vvo=o("AutoTokenizer.from_pretrained()"),Fvo=o(" class method."),Tvo=l(),F$=a("p"),Mvo=o("This class cannot be instantiated directly using "),Yhe=a("code"),Evo=o("__init__()"),Cvo=o(" (throws an error)."),wvo=l(),jr=a("div"),F(T$.$$.fragment),Avo=l(),Zhe=a("p"),Lvo=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),yvo=l(),tn=a("p"),xvo=o("The tokenizer class to instantiate is selected based on the "),Khe=a("code"),$vo=o("model_type"),kvo=o(` property of the config object (either
passed as an argument or loaded from `),eue=a("code"),Svo=o("pretrained_model_name_or_path"),Rvo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oue=a("code"),Pvo=o("pretrained_model_name_or_path"),Bvo=o(":"),Ivo=l(),k=a("ul"),us=a("li"),rue=a("strong"),Nvo=o("albert"),qvo=o(" \u2014 "),tD=a("a"),jvo=o("AlbertTokenizer"),Dvo=o(" or "),aD=a("a"),Gvo=o("AlbertTokenizerFast"),Ovo=o(" (ALBERT model)"),Vvo=l(),ps=a("li"),tue=a("strong"),Xvo=o("bart"),zvo=o(" \u2014 "),nD=a("a"),Qvo=o("BartTokenizer"),Wvo=o(" or "),sD=a("a"),Uvo=o("BartTokenizerFast"),Hvo=o(" (BART model)"),Jvo=l(),_s=a("li"),aue=a("strong"),Yvo=o("barthez"),Zvo=o(" \u2014 "),lD=a("a"),Kvo=o("BarthezTokenizer"),eFo=o(" or "),iD=a("a"),oFo=o("BarthezTokenizerFast"),rFo=o(" (BARThez model)"),tFo=l(),yu=a("li"),nue=a("strong"),aFo=o("bartpho"),nFo=o(" \u2014 "),dD=a("a"),sFo=o("BartphoTokenizer"),lFo=o(" (BARTpho model)"),iFo=l(),bs=a("li"),sue=a("strong"),dFo=o("bert"),mFo=o(" \u2014 "),mD=a("a"),cFo=o("BertTokenizer"),fFo=o(" or "),cD=a("a"),gFo=o("BertTokenizerFast"),hFo=o(" (BERT model)"),uFo=l(),xu=a("li"),lue=a("strong"),pFo=o("bert-generation"),_Fo=o(" \u2014 "),fD=a("a"),bFo=o("BertGenerationTokenizer"),vFo=o(" (Bert Generation model)"),FFo=l(),$u=a("li"),iue=a("strong"),TFo=o("bert-japanese"),MFo=o(" \u2014 "),gD=a("a"),EFo=o("BertJapaneseTokenizer"),CFo=o(" (BertJapanese model)"),wFo=l(),ku=a("li"),due=a("strong"),AFo=o("bertweet"),LFo=o(" \u2014 "),hD=a("a"),yFo=o("BertweetTokenizer"),xFo=o(" (BERTweet model)"),$Fo=l(),vs=a("li"),mue=a("strong"),kFo=o("big_bird"),SFo=o(" \u2014 "),uD=a("a"),RFo=o("BigBirdTokenizer"),PFo=o(" or "),pD=a("a"),BFo=o("BigBirdTokenizerFast"),IFo=o(" (BigBird model)"),NFo=l(),Fs=a("li"),cue=a("strong"),qFo=o("bigbird_pegasus"),jFo=o(" \u2014 "),_D=a("a"),DFo=o("PegasusTokenizer"),GFo=o(" or "),bD=a("a"),OFo=o("PegasusTokenizerFast"),VFo=o(" (BigBird-Pegasus model)"),XFo=l(),Ts=a("li"),fue=a("strong"),zFo=o("blenderbot"),QFo=o(" \u2014 "),vD=a("a"),WFo=o("BlenderbotTokenizer"),UFo=o(" or "),FD=a("a"),HFo=o("BlenderbotTokenizerFast"),JFo=o(" (Blenderbot model)"),YFo=l(),Su=a("li"),gue=a("strong"),ZFo=o("blenderbot-small"),KFo=o(" \u2014 "),TD=a("a"),eTo=o("BlenderbotSmallTokenizer"),oTo=o(" (BlenderbotSmall model)"),rTo=l(),Ru=a("li"),hue=a("strong"),tTo=o("bloom"),aTo=o(" \u2014 "),MD=a("a"),nTo=o("BloomTokenizerFast"),sTo=o(" (BLOOM model)"),lTo=l(),Pu=a("li"),uue=a("strong"),iTo=o("byt5"),dTo=o(" \u2014 "),ED=a("a"),mTo=o("ByT5Tokenizer"),cTo=o(" (ByT5 model)"),fTo=l(),Ms=a("li"),pue=a("strong"),gTo=o("camembert"),hTo=o(" \u2014 "),CD=a("a"),uTo=o("CamembertTokenizer"),pTo=o(" or "),wD=a("a"),_To=o("CamembertTokenizerFast"),bTo=o(" (CamemBERT model)"),vTo=l(),Bu=a("li"),_ue=a("strong"),FTo=o("canine"),TTo=o(" \u2014 "),AD=a("a"),MTo=o("CanineTokenizer"),ETo=o(" (CANINE model)"),CTo=l(),Es=a("li"),bue=a("strong"),wTo=o("clip"),ATo=o(" \u2014 "),LD=a("a"),LTo=o("CLIPTokenizer"),yTo=o(" or "),yD=a("a"),xTo=o("CLIPTokenizerFast"),$To=o(" (CLIP model)"),kTo=l(),Cs=a("li"),vue=a("strong"),STo=o("codegen"),RTo=o(" \u2014 "),xD=a("a"),PTo=o("CodeGenTokenizer"),BTo=o(" or "),$D=a("a"),ITo=o("CodeGenTokenizerFast"),NTo=o(" (CodeGen model)"),qTo=l(),ws=a("li"),Fue=a("strong"),jTo=o("convbert"),DTo=o(" \u2014 "),kD=a("a"),GTo=o("ConvBertTokenizer"),OTo=o(" or "),SD=a("a"),VTo=o("ConvBertTokenizerFast"),XTo=o(" (ConvBERT model)"),zTo=l(),As=a("li"),Tue=a("strong"),QTo=o("cpm"),WTo=o(" \u2014 "),RD=a("a"),UTo=o("CpmTokenizer"),HTo=o(" or "),PD=a("a"),JTo=o("CpmTokenizerFast"),YTo=o(" (CPM model)"),ZTo=l(),Iu=a("li"),Mue=a("strong"),KTo=o("ctrl"),eMo=o(" \u2014 "),BD=a("a"),oMo=o("CTRLTokenizer"),rMo=o(" (CTRL model)"),tMo=l(),Ls=a("li"),Eue=a("strong"),aMo=o("data2vec-text"),nMo=o(" \u2014 "),ID=a("a"),sMo=o("RobertaTokenizer"),lMo=o(" or "),ND=a("a"),iMo=o("RobertaTokenizerFast"),dMo=o(" (Data2VecText model)"),mMo=l(),ys=a("li"),Cue=a("strong"),cMo=o("deberta"),fMo=o(" \u2014 "),qD=a("a"),gMo=o("DebertaTokenizer"),hMo=o(" or "),jD=a("a"),uMo=o("DebertaTokenizerFast"),pMo=o(" (DeBERTa model)"),_Mo=l(),xs=a("li"),wue=a("strong"),bMo=o("deberta-v2"),vMo=o(" \u2014 "),DD=a("a"),FMo=o("DebertaV2Tokenizer"),TMo=o(" or "),GD=a("a"),MMo=o("DebertaV2TokenizerFast"),EMo=o(" (DeBERTa-v2 model)"),CMo=l(),$s=a("li"),Aue=a("strong"),wMo=o("distilbert"),AMo=o(" \u2014 "),OD=a("a"),LMo=o("DistilBertTokenizer"),yMo=o(" or "),VD=a("a"),xMo=o("DistilBertTokenizerFast"),$Mo=o(" (DistilBERT model)"),kMo=l(),ks=a("li"),Lue=a("strong"),SMo=o("dpr"),RMo=o(" \u2014 "),XD=a("a"),PMo=o("DPRQuestionEncoderTokenizer"),BMo=o(" or "),zD=a("a"),IMo=o("DPRQuestionEncoderTokenizerFast"),NMo=o(" (DPR model)"),qMo=l(),Ss=a("li"),yue=a("strong"),jMo=o("electra"),DMo=o(" \u2014 "),QD=a("a"),GMo=o("ElectraTokenizer"),OMo=o(" or "),WD=a("a"),VMo=o("ElectraTokenizerFast"),XMo=o(" (ELECTRA model)"),zMo=l(),Rs=a("li"),xue=a("strong"),QMo=o("ernie"),WMo=o(" \u2014 "),UD=a("a"),UMo=o("BertTokenizer"),HMo=o(" or "),HD=a("a"),JMo=o("BertTokenizerFast"),YMo=o(" (ERNIE model)"),ZMo=l(),Nu=a("li"),$ue=a("strong"),KMo=o("esm"),eEo=o(" \u2014 "),JD=a("a"),oEo=o("EsmTokenizer"),rEo=o(" (ESM model)"),tEo=l(),qu=a("li"),kue=a("strong"),aEo=o("flaubert"),nEo=o(" \u2014 "),YD=a("a"),sEo=o("FlaubertTokenizer"),lEo=o(" (FlauBERT model)"),iEo=l(),Ps=a("li"),Sue=a("strong"),dEo=o("fnet"),mEo=o(" \u2014 "),ZD=a("a"),cEo=o("FNetTokenizer"),fEo=o(" or "),KD=a("a"),gEo=o("FNetTokenizerFast"),hEo=o(" (FNet model)"),uEo=l(),ju=a("li"),Rue=a("strong"),pEo=o("fsmt"),_Eo=o(" \u2014 "),eG=a("a"),bEo=o("FSMTTokenizer"),vEo=o(" (FairSeq Machine-Translation model)"),FEo=l(),Bs=a("li"),Pue=a("strong"),TEo=o("funnel"),MEo=o(" \u2014 "),oG=a("a"),EEo=o("FunnelTokenizer"),CEo=o(" or "),rG=a("a"),wEo=o("FunnelTokenizerFast"),AEo=o(" (Funnel Transformer model)"),LEo=l(),Is=a("li"),Bue=a("strong"),yEo=o("gpt2"),xEo=o(" \u2014 "),tG=a("a"),$Eo=o("GPT2Tokenizer"),kEo=o(" or "),aG=a("a"),SEo=o("GPT2TokenizerFast"),REo=o(" (OpenAI GPT-2 model)"),PEo=l(),Ns=a("li"),Iue=a("strong"),BEo=o("gpt_neo"),IEo=o(" \u2014 "),nG=a("a"),NEo=o("GPT2Tokenizer"),qEo=o(" or "),sG=a("a"),jEo=o("GPT2TokenizerFast"),DEo=o(" (GPT Neo model)"),GEo=l(),Du=a("li"),Nue=a("strong"),OEo=o("gpt_neox"),VEo=o(" \u2014 "),lG=a("a"),XEo=o("GPTNeoXTokenizerFast"),zEo=o(" (GPT NeoX model)"),QEo=l(),Gu=a("li"),que=a("strong"),WEo=o("gpt_neox_japanese"),UEo=o(" \u2014 "),iG=a("a"),HEo=o("GPTNeoXJapaneseTokenizer"),JEo=o(" (GPT NeoX Japanese model)"),YEo=l(),qs=a("li"),jue=a("strong"),ZEo=o("gptj"),KEo=o(" \u2014 "),dG=a("a"),e4o=o("GPT2Tokenizer"),o4o=o(" or "),mG=a("a"),r4o=o("GPT2TokenizerFast"),t4o=o(" (GPT-J model)"),a4o=l(),js=a("li"),Due=a("strong"),n4o=o("groupvit"),s4o=o(" \u2014 "),cG=a("a"),l4o=o("CLIPTokenizer"),i4o=o(" or "),fG=a("a"),d4o=o("CLIPTokenizerFast"),m4o=o(" (GroupViT model)"),c4o=l(),Ds=a("li"),Gue=a("strong"),f4o=o("herbert"),g4o=o(" \u2014 "),gG=a("a"),h4o=o("HerbertTokenizer"),u4o=o(" or "),hG=a("a"),p4o=o("HerbertTokenizerFast"),_4o=o(" (HerBERT model)"),b4o=l(),Ou=a("li"),Oue=a("strong"),v4o=o("hubert"),F4o=o(" \u2014 "),uG=a("a"),T4o=o("Wav2Vec2CTCTokenizer"),M4o=o(" (Hubert model)"),E4o=l(),Gs=a("li"),Vue=a("strong"),C4o=o("ibert"),w4o=o(" \u2014 "),pG=a("a"),A4o=o("RobertaTokenizer"),L4o=o(" or "),_G=a("a"),y4o=o("RobertaTokenizerFast"),x4o=o(" (I-BERT model)"),$4o=l(),Os=a("li"),Xue=a("strong"),k4o=o("layoutlm"),S4o=o(" \u2014 "),bG=a("a"),R4o=o("LayoutLMTokenizer"),P4o=o(" or "),vG=a("a"),B4o=o("LayoutLMTokenizerFast"),I4o=o(" (LayoutLM model)"),N4o=l(),Vs=a("li"),zue=a("strong"),q4o=o("layoutlmv2"),j4o=o(" \u2014 "),FG=a("a"),D4o=o("LayoutLMv2Tokenizer"),G4o=o(" or "),TG=a("a"),O4o=o("LayoutLMv2TokenizerFast"),V4o=o(" (LayoutLMv2 model)"),X4o=l(),Xs=a("li"),Que=a("strong"),z4o=o("layoutlmv3"),Q4o=o(" \u2014 "),MG=a("a"),W4o=o("LayoutLMv3Tokenizer"),U4o=o(" or "),EG=a("a"),H4o=o("LayoutLMv3TokenizerFast"),J4o=o(" (LayoutLMv3 model)"),Y4o=l(),zs=a("li"),Wue=a("strong"),Z4o=o("layoutxlm"),K4o=o(" \u2014 "),CG=a("a"),eCo=o("LayoutXLMTokenizer"),oCo=o(" or "),wG=a("a"),rCo=o("LayoutXLMTokenizerFast"),tCo=o(" (LayoutXLM model)"),aCo=l(),Qs=a("li"),Uue=a("strong"),nCo=o("led"),sCo=o(" \u2014 "),AG=a("a"),lCo=o("LEDTokenizer"),iCo=o(" or "),LG=a("a"),dCo=o("LEDTokenizerFast"),mCo=o(" (LED model)"),cCo=l(),Ws=a("li"),Hue=a("strong"),fCo=o("lilt"),gCo=o(" \u2014 "),yG=a("a"),hCo=o("LayoutLMv3Tokenizer"),uCo=o(" or "),xG=a("a"),pCo=o("LayoutLMv3TokenizerFast"),_Co=o(" (LiLT model)"),bCo=l(),Us=a("li"),Jue=a("strong"),vCo=o("longformer"),FCo=o(" \u2014 "),$G=a("a"),TCo=o("LongformerTokenizer"),MCo=o(" or "),kG=a("a"),ECo=o("LongformerTokenizerFast"),CCo=o(" (Longformer model)"),wCo=l(),Hs=a("li"),Yue=a("strong"),ACo=o("longt5"),LCo=o(" \u2014 "),SG=a("a"),yCo=o("T5Tokenizer"),xCo=o(" or "),RG=a("a"),$Co=o("T5TokenizerFast"),kCo=o(" (LongT5 model)"),SCo=l(),Vu=a("li"),Zue=a("strong"),RCo=o("luke"),PCo=o(" \u2014 "),PG=a("a"),BCo=o("LukeTokenizer"),ICo=o(" (LUKE model)"),NCo=l(),Js=a("li"),Kue=a("strong"),qCo=o("lxmert"),jCo=o(" \u2014 "),BG=a("a"),DCo=o("LxmertTokenizer"),GCo=o(" or "),IG=a("a"),OCo=o("LxmertTokenizerFast"),VCo=o(" (LXMERT model)"),XCo=l(),Xu=a("li"),epe=a("strong"),zCo=o("m2m_100"),QCo=o(" \u2014 "),NG=a("a"),WCo=o("M2M100Tokenizer"),UCo=o(" (M2M100 model)"),HCo=l(),zu=a("li"),ope=a("strong"),JCo=o("marian"),YCo=o(" \u2014 "),qG=a("a"),ZCo=o("MarianTokenizer"),KCo=o(" (Marian model)"),e3o=l(),Ys=a("li"),rpe=a("strong"),o3o=o("mbart"),r3o=o(" \u2014 "),jG=a("a"),t3o=o("MBartTokenizer"),a3o=o(" or "),DG=a("a"),n3o=o("MBartTokenizerFast"),s3o=o(" (mBART model)"),l3o=l(),Zs=a("li"),tpe=a("strong"),i3o=o("mbart50"),d3o=o(" \u2014 "),GG=a("a"),m3o=o("MBart50Tokenizer"),c3o=o(" or "),OG=a("a"),f3o=o("MBart50TokenizerFast"),g3o=o(" (mBART-50 model)"),h3o=l(),Ks=a("li"),ape=a("strong"),u3o=o("megatron-bert"),p3o=o(" \u2014 "),VG=a("a"),_3o=o("BertTokenizer"),b3o=o(" or "),XG=a("a"),v3o=o("BertTokenizerFast"),F3o=o(" (Megatron-BERT model)"),T3o=l(),Qu=a("li"),npe=a("strong"),M3o=o("mluke"),E3o=o(" \u2014 "),zG=a("a"),C3o=o("MLukeTokenizer"),w3o=o(" (mLUKE model)"),A3o=l(),el=a("li"),spe=a("strong"),L3o=o("mobilebert"),y3o=o(" \u2014 "),QG=a("a"),x3o=o("MobileBertTokenizer"),$3o=o(" or "),WG=a("a"),k3o=o("MobileBertTokenizerFast"),S3o=o(" (MobileBERT model)"),R3o=l(),ol=a("li"),lpe=a("strong"),P3o=o("mpnet"),B3o=o(" \u2014 "),UG=a("a"),I3o=o("MPNetTokenizer"),N3o=o(" or "),HG=a("a"),q3o=o("MPNetTokenizerFast"),j3o=o(" (MPNet model)"),D3o=l(),rl=a("li"),ipe=a("strong"),G3o=o("mt5"),O3o=o(" \u2014 "),JG=a("a"),V3o=o("MT5Tokenizer"),X3o=o(" or "),YG=a("a"),z3o=o("MT5TokenizerFast"),Q3o=o(" (MT5 model)"),W3o=l(),tl=a("li"),dpe=a("strong"),U3o=o("mvp"),H3o=o(" \u2014 "),ZG=a("a"),J3o=o("MvpTokenizer"),Y3o=o(" or "),KG=a("a"),Z3o=o("MvpTokenizerFast"),K3o=o(" (MVP model)"),e5o=l(),al=a("li"),mpe=a("strong"),o5o=o("nezha"),r5o=o(" \u2014 "),eO=a("a"),t5o=o("BertTokenizer"),a5o=o(" or "),oO=a("a"),n5o=o("BertTokenizerFast"),s5o=o(" (Nezha model)"),l5o=l(),nl=a("li"),cpe=a("strong"),i5o=o("nllb"),d5o=o(" \u2014 "),rO=a("a"),m5o=o("NllbTokenizer"),c5o=o(" or "),tO=a("a"),f5o=o("NllbTokenizerFast"),g5o=o(" (NLLB model)"),h5o=l(),sl=a("li"),fpe=a("strong"),u5o=o("nystromformer"),p5o=o(" \u2014 "),aO=a("a"),_5o=o("AlbertTokenizer"),b5o=o(" or "),nO=a("a"),v5o=o("AlbertTokenizerFast"),F5o=o(" (Nystr\xF6mformer model)"),T5o=l(),ll=a("li"),gpe=a("strong"),M5o=o("openai-gpt"),E5o=o(" \u2014 "),sO=a("a"),C5o=o("OpenAIGPTTokenizer"),w5o=o(" or "),lO=a("a"),A5o=o("OpenAIGPTTokenizerFast"),L5o=o(" (OpenAI GPT model)"),y5o=l(),Wu=a("li"),hpe=a("strong"),x5o=o("opt"),$5o=o(" \u2014 "),iO=a("a"),k5o=o("GPT2Tokenizer"),S5o=o(" (OPT model)"),R5o=l(),il=a("li"),upe=a("strong"),P5o=o("owlvit"),B5o=o(" \u2014 "),dO=a("a"),I5o=o("CLIPTokenizer"),N5o=o(" or "),mO=a("a"),q5o=o("CLIPTokenizerFast"),j5o=o(" (OWL-ViT model)"),D5o=l(),dl=a("li"),ppe=a("strong"),G5o=o("pegasus"),O5o=o(" \u2014 "),cO=a("a"),V5o=o("PegasusTokenizer"),X5o=o(" or "),fO=a("a"),z5o=o("PegasusTokenizerFast"),Q5o=o(" (Pegasus model)"),W5o=l(),ml=a("li"),_pe=a("strong"),U5o=o("pegasus_x"),H5o=o(" \u2014 "),gO=a("a"),J5o=o("PegasusTokenizer"),Y5o=o(" or "),hO=a("a"),Z5o=o("PegasusTokenizerFast"),K5o=o(" (PEGASUS-X model)"),e0o=l(),Uu=a("li"),bpe=a("strong"),o0o=o("perceiver"),r0o=o(" \u2014 "),uO=a("a"),t0o=o("PerceiverTokenizer"),a0o=o(" (Perceiver model)"),n0o=l(),Hu=a("li"),vpe=a("strong"),s0o=o("phobert"),l0o=o(" \u2014 "),pO=a("a"),i0o=o("PhobertTokenizer"),d0o=o(" (PhoBERT model)"),m0o=l(),Ju=a("li"),Fpe=a("strong"),c0o=o("plbart"),f0o=o(" \u2014 "),_O=a("a"),g0o=o("PLBartTokenizer"),h0o=o(" (PLBart model)"),u0o=l(),Yu=a("li"),Tpe=a("strong"),p0o=o("prophetnet"),_0o=o(" \u2014 "),bO=a("a"),b0o=o("ProphetNetTokenizer"),v0o=o(" (ProphetNet model)"),F0o=l(),cl=a("li"),Mpe=a("strong"),T0o=o("qdqbert"),M0o=o(" \u2014 "),vO=a("a"),E0o=o("BertTokenizer"),C0o=o(" or "),FO=a("a"),w0o=o("BertTokenizerFast"),A0o=o(" (QDQBert model)"),L0o=l(),Zu=a("li"),Epe=a("strong"),y0o=o("rag"),x0o=o(" \u2014 "),TO=a("a"),$0o=o("RagTokenizer"),k0o=o(" (RAG model)"),S0o=l(),fl=a("li"),Cpe=a("strong"),R0o=o("realm"),P0o=o(" \u2014 "),MO=a("a"),B0o=o("RealmTokenizer"),I0o=o(" or "),EO=a("a"),N0o=o("RealmTokenizerFast"),q0o=o(" (REALM model)"),j0o=l(),gl=a("li"),wpe=a("strong"),D0o=o("reformer"),G0o=o(" \u2014 "),CO=a("a"),O0o=o("ReformerTokenizer"),V0o=o(" or "),wO=a("a"),X0o=o("ReformerTokenizerFast"),z0o=o(" (Reformer model)"),Q0o=l(),hl=a("li"),Ape=a("strong"),W0o=o("rembert"),U0o=o(" \u2014 "),AO=a("a"),H0o=o("RemBertTokenizer"),J0o=o(" or "),LO=a("a"),Y0o=o("RemBertTokenizerFast"),Z0o=o(" (RemBERT model)"),K0o=l(),ul=a("li"),Lpe=a("strong"),ewo=o("retribert"),owo=o(" \u2014 "),yO=a("a"),rwo=o("RetriBertTokenizer"),two=o(" or "),xO=a("a"),awo=o("RetriBertTokenizerFast"),nwo=o(" (RetriBERT model)"),swo=l(),pl=a("li"),ype=a("strong"),lwo=o("roberta"),iwo=o(" \u2014 "),$O=a("a"),dwo=o("RobertaTokenizer"),mwo=o(" or "),kO=a("a"),cwo=o("RobertaTokenizerFast"),fwo=o(" (RoBERTa model)"),gwo=l(),_l=a("li"),xpe=a("strong"),hwo=o("roformer"),uwo=o(" \u2014 "),SO=a("a"),pwo=o("RoFormerTokenizer"),_wo=o(" or "),RO=a("a"),bwo=o("RoFormerTokenizerFast"),vwo=o(" (RoFormer model)"),Fwo=l(),Ku=a("li"),$pe=a("strong"),Two=o("speech_to_text"),Mwo=o(" \u2014 "),PO=a("a"),Ewo=o("Speech2TextTokenizer"),Cwo=o(" (Speech2Text model)"),wwo=l(),ep=a("li"),kpe=a("strong"),Awo=o("speech_to_text_2"),Lwo=o(" \u2014 "),BO=a("a"),ywo=o("Speech2Text2Tokenizer"),xwo=o(" (Speech2Text2 model)"),$wo=l(),bl=a("li"),Spe=a("strong"),kwo=o("splinter"),Swo=o(" \u2014 "),IO=a("a"),Rwo=o("SplinterTokenizer"),Pwo=o(" or "),NO=a("a"),Bwo=o("SplinterTokenizerFast"),Iwo=o(" (Splinter model)"),Nwo=l(),vl=a("li"),Rpe=a("strong"),qwo=o("squeezebert"),jwo=o(" \u2014 "),qO=a("a"),Dwo=o("SqueezeBertTokenizer"),Gwo=o(" or "),jO=a("a"),Owo=o("SqueezeBertTokenizerFast"),Vwo=o(" (SqueezeBERT model)"),Xwo=l(),Fl=a("li"),Ppe=a("strong"),zwo=o("t5"),Qwo=o(" \u2014 "),DO=a("a"),Wwo=o("T5Tokenizer"),Uwo=o(" or "),GO=a("a"),Hwo=o("T5TokenizerFast"),Jwo=o(" (T5 model)"),Ywo=l(),op=a("li"),Bpe=a("strong"),Zwo=o("tapas"),Kwo=o(" \u2014 "),OO=a("a"),eAo=o("TapasTokenizer"),oAo=o(" (TAPAS model)"),rAo=l(),rp=a("li"),Ipe=a("strong"),tAo=o("tapex"),aAo=o(" \u2014 "),VO=a("a"),nAo=o("TapexTokenizer"),sAo=o(" (TAPEX model)"),lAo=l(),tp=a("li"),Npe=a("strong"),iAo=o("transfo-xl"),dAo=o(" \u2014 "),XO=a("a"),mAo=o("TransfoXLTokenizer"),cAo=o(" (Transformer-XL model)"),fAo=l(),Tl=a("li"),qpe=a("strong"),gAo=o("vilt"),hAo=o(" \u2014 "),zO=a("a"),uAo=o("BertTokenizer"),pAo=o(" or "),QO=a("a"),_Ao=o("BertTokenizerFast"),bAo=o(" (ViLT model)"),vAo=l(),Ml=a("li"),jpe=a("strong"),FAo=o("visual_bert"),TAo=o(" \u2014 "),WO=a("a"),MAo=o("BertTokenizer"),EAo=o(" or "),UO=a("a"),CAo=o("BertTokenizerFast"),wAo=o(" (VisualBERT model)"),AAo=l(),ap=a("li"),Dpe=a("strong"),LAo=o("wav2vec2"),yAo=o(" \u2014 "),HO=a("a"),xAo=o("Wav2Vec2CTCTokenizer"),$Ao=o(" (Wav2Vec2 model)"),kAo=l(),np=a("li"),Gpe=a("strong"),SAo=o("wav2vec2-conformer"),RAo=o(" \u2014 "),JO=a("a"),PAo=o("Wav2Vec2CTCTokenizer"),BAo=o(" (Wav2Vec2-Conformer model)"),IAo=l(),sp=a("li"),Ope=a("strong"),NAo=o("wav2vec2_phoneme"),qAo=o(" \u2014 "),YO=a("a"),jAo=o("Wav2Vec2PhonemeCTCTokenizer"),DAo=o(" (Wav2Vec2Phoneme model)"),GAo=l(),lp=a("li"),Vpe=a("strong"),OAo=o("whisper"),VAo=o(" \u2014 "),ZO=a("a"),XAo=o("WhisperTokenizer"),zAo=o(" (Whisper model)"),QAo=l(),El=a("li"),Xpe=a("strong"),WAo=o("xclip"),UAo=o(" \u2014 "),KO=a("a"),HAo=o("CLIPTokenizer"),JAo=o(" or "),eV=a("a"),YAo=o("CLIPTokenizerFast"),ZAo=o(" (X-CLIP model)"),KAo=l(),Cl=a("li"),zpe=a("strong"),e6o=o("xglm"),o6o=o(" \u2014 "),oV=a("a"),r6o=o("XGLMTokenizer"),t6o=o(" or "),rV=a("a"),a6o=o("XGLMTokenizerFast"),n6o=o(" (XGLM model)"),s6o=l(),ip=a("li"),Qpe=a("strong"),l6o=o("xlm"),i6o=o(" \u2014 "),tV=a("a"),d6o=o("XLMTokenizer"),m6o=o(" (XLM model)"),c6o=l(),dp=a("li"),Wpe=a("strong"),f6o=o("xlm-prophetnet"),g6o=o(" \u2014 "),aV=a("a"),h6o=o("XLMProphetNetTokenizer"),u6o=o(" (XLM-ProphetNet model)"),p6o=l(),wl=a("li"),Upe=a("strong"),_6o=o("xlm-roberta"),b6o=o(" \u2014 "),nV=a("a"),v6o=o("XLMRobertaTokenizer"),F6o=o(" or "),sV=a("a"),T6o=o("XLMRobertaTokenizerFast"),M6o=o(" (XLM-RoBERTa model)"),E6o=l(),Al=a("li"),Hpe=a("strong"),C6o=o("xlm-roberta-xl"),w6o=o(" \u2014 "),lV=a("a"),A6o=o("XLMRobertaTokenizer"),L6o=o(" or "),iV=a("a"),y6o=o("XLMRobertaTokenizerFast"),x6o=o(" (XLM-RoBERTa-XL model)"),$6o=l(),Ll=a("li"),Jpe=a("strong"),k6o=o("xlnet"),S6o=o(" \u2014 "),dV=a("a"),R6o=o("XLNetTokenizer"),P6o=o(" or "),mV=a("a"),B6o=o("XLNetTokenizerFast"),I6o=o(" (XLNet model)"),N6o=l(),yl=a("li"),Ype=a("strong"),q6o=o("yoso"),j6o=o(" \u2014 "),cV=a("a"),D6o=o("AlbertTokenizer"),G6o=o(" or "),fV=a("a"),O6o=o("AlbertTokenizerFast"),V6o=o(" (YOSO model)"),X6o=l(),F(mp.$$.fragment),z6o=l(),cp=a("div"),F(M$.$$.fragment),Q6o=l(),Zpe=a("p"),W6o=o("Register a new tokenizer in this mapping."),Pto=l(),xd=a("h2"),fp=a("a"),Kpe=a("span"),F(E$.$$.fragment),U6o=l(),e_e=a("span"),H6o=o("AutoFeatureExtractor"),Bto=l(),Po=a("div"),F(C$.$$.fragment),J6o=l(),w$=a("p"),Y6o=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),gV=a("a"),Z6o=o("AutoFeatureExtractor.from_pretrained()"),K6o=o(" class method."),e7o=l(),A$=a("p"),o7o=o("This class cannot be instantiated directly using "),o_e=a("code"),r7o=o("__init__()"),t7o=o(" (throws an error)."),a7o=l(),Ye=a("div"),F(L$.$$.fragment),n7o=l(),r_e=a("p"),s7o=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),l7o=l(),an=a("p"),i7o=o("The feature extractor class to instantiate is selected based on the "),t_e=a("code"),d7o=o("model_type"),m7o=o(` property of the config object
(either passed as an argument or loaded from `),a_e=a("code"),c7o=o("pretrained_model_name_or_path"),f7o=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),n_e=a("code"),g7o=o("pretrained_model_name_or_path"),h7o=o(":"),u7o=l(),z=a("ul"),gp=a("li"),s_e=a("strong"),p7o=o("beit"),_7o=o(" \u2014 "),hV=a("a"),b7o=o("BeitFeatureExtractor"),v7o=o(" (BEiT model)"),F7o=l(),hp=a("li"),l_e=a("strong"),T7o=o("clip"),M7o=o(" \u2014 "),uV=a("a"),E7o=o("CLIPFeatureExtractor"),C7o=o(" (CLIP model)"),w7o=l(),up=a("li"),i_e=a("strong"),A7o=o("conditional_detr"),L7o=o(" \u2014 "),pV=a("a"),y7o=o("ConditionalDetrFeatureExtractor"),x7o=o(" (Conditional DETR model)"),$7o=l(),pp=a("li"),d_e=a("strong"),k7o=o("convnext"),S7o=o(" \u2014 "),_V=a("a"),R7o=o("ConvNextFeatureExtractor"),P7o=o(" (ConvNeXT model)"),B7o=l(),_p=a("li"),m_e=a("strong"),I7o=o("cvt"),N7o=o(" \u2014 "),bV=a("a"),q7o=o("ConvNextFeatureExtractor"),j7o=o(" (CvT model)"),D7o=l(),bp=a("li"),c_e=a("strong"),G7o=o("data2vec-audio"),O7o=o(" \u2014 "),vV=a("a"),V7o=o("Wav2Vec2FeatureExtractor"),X7o=o(" (Data2VecAudio model)"),z7o=l(),vp=a("li"),f_e=a("strong"),Q7o=o("data2vec-vision"),W7o=o(" \u2014 "),FV=a("a"),U7o=o("BeitFeatureExtractor"),H7o=o(" (Data2VecVision model)"),J7o=l(),Fp=a("li"),g_e=a("strong"),Y7o=o("deformable_detr"),Z7o=o(" \u2014 "),TV=a("a"),K7o=o("DeformableDetrFeatureExtractor"),e8o=o(" (Deformable DETR model)"),o8o=l(),Tp=a("li"),h_e=a("strong"),r8o=o("deit"),t8o=o(" \u2014 "),MV=a("a"),a8o=o("DeiTFeatureExtractor"),n8o=o(" (DeiT model)"),s8o=l(),Mp=a("li"),u_e=a("strong"),l8o=o("detr"),i8o=o(" \u2014 "),EV=a("a"),d8o=o("DetrFeatureExtractor"),m8o=o(" (DETR model)"),c8o=l(),Ep=a("li"),p_e=a("strong"),f8o=o("donut-swin"),g8o=o(" \u2014 "),CV=a("a"),h8o=o("DonutFeatureExtractor"),u8o=o(" (DonutSwin model)"),p8o=l(),Cp=a("li"),__e=a("strong"),_8o=o("dpt"),b8o=o(" \u2014 "),wV=a("a"),v8o=o("DPTFeatureExtractor"),F8o=o(" (DPT model)"),T8o=l(),wp=a("li"),b_e=a("strong"),M8o=o("flava"),E8o=o(" \u2014 "),AV=a("a"),C8o=o("FlavaFeatureExtractor"),w8o=o(" (FLAVA model)"),A8o=l(),Ap=a("li"),v_e=a("strong"),L8o=o("glpn"),y8o=o(" \u2014 "),LV=a("a"),x8o=o("GLPNFeatureExtractor"),$8o=o(" (GLPN model)"),k8o=l(),Lp=a("li"),F_e=a("strong"),S8o=o("groupvit"),R8o=o(" \u2014 "),yV=a("a"),P8o=o("CLIPFeatureExtractor"),B8o=o(" (GroupViT model)"),I8o=l(),yp=a("li"),T_e=a("strong"),N8o=o("hubert"),q8o=o(" \u2014 "),xV=a("a"),j8o=o("Wav2Vec2FeatureExtractor"),D8o=o(" (Hubert model)"),G8o=l(),xp=a("li"),M_e=a("strong"),O8o=o("imagegpt"),V8o=o(" \u2014 "),$V=a("a"),X8o=o("ImageGPTFeatureExtractor"),z8o=o(" (ImageGPT model)"),Q8o=l(),$p=a("li"),E_e=a("strong"),W8o=o("layoutlmv2"),U8o=o(" \u2014 "),kV=a("a"),H8o=o("LayoutLMv2FeatureExtractor"),J8o=o(" (LayoutLMv2 model)"),Y8o=l(),kp=a("li"),C_e=a("strong"),Z8o=o("layoutlmv3"),K8o=o(" \u2014 "),SV=a("a"),eLo=o("LayoutLMv3FeatureExtractor"),oLo=o(" (LayoutLMv3 model)"),rLo=l(),Sp=a("li"),w_e=a("strong"),tLo=o("levit"),aLo=o(" \u2014 "),RV=a("a"),nLo=o("LevitFeatureExtractor"),sLo=o(" (LeViT model)"),lLo=l(),Rp=a("li"),A_e=a("strong"),iLo=o("maskformer"),dLo=o(" \u2014 "),PV=a("a"),mLo=o("MaskFormerFeatureExtractor"),cLo=o(" (MaskFormer model)"),fLo=l(),Pp=a("li"),L_e=a("strong"),gLo=o("mctct"),hLo=o(" \u2014 "),BV=a("a"),uLo=o("MCTCTFeatureExtractor"),pLo=o(" (M-CTC-T model)"),_Lo=l(),Bp=a("li"),y_e=a("strong"),bLo=o("mobilevit"),vLo=o(" \u2014 "),IV=a("a"),FLo=o("MobileViTFeatureExtractor"),TLo=o(" (MobileViT model)"),MLo=l(),Ip=a("li"),x_e=a("strong"),ELo=o("owlvit"),CLo=o(" \u2014 "),NV=a("a"),wLo=o("OwlViTFeatureExtractor"),ALo=o(" (OWL-ViT model)"),LLo=l(),Np=a("li"),$_e=a("strong"),yLo=o("perceiver"),xLo=o(" \u2014 "),qV=a("a"),$Lo=o("PerceiverFeatureExtractor"),kLo=o(" (Perceiver model)"),SLo=l(),qp=a("li"),k_e=a("strong"),RLo=o("poolformer"),PLo=o(" \u2014 "),jV=a("a"),BLo=o("PoolFormerFeatureExtractor"),ILo=o(" (PoolFormer model)"),NLo=l(),jp=a("li"),S_e=a("strong"),qLo=o("regnet"),jLo=o(" \u2014 "),DV=a("a"),DLo=o("ConvNextFeatureExtractor"),GLo=o(" (RegNet model)"),OLo=l(),Dp=a("li"),R_e=a("strong"),VLo=o("resnet"),XLo=o(" \u2014 "),GV=a("a"),zLo=o("ConvNextFeatureExtractor"),QLo=o(" (ResNet model)"),WLo=l(),Gp=a("li"),P_e=a("strong"),ULo=o("segformer"),HLo=o(" \u2014 "),OV=a("a"),JLo=o("SegformerFeatureExtractor"),YLo=o(" (SegFormer model)"),ZLo=l(),Op=a("li"),B_e=a("strong"),KLo=o("speech_to_text"),eyo=o(" \u2014 "),VV=a("a"),oyo=o("Speech2TextFeatureExtractor"),ryo=o(" (Speech2Text model)"),tyo=l(),Vp=a("li"),I_e=a("strong"),ayo=o("swin"),nyo=o(" \u2014 "),XV=a("a"),syo=o("ViTFeatureExtractor"),lyo=o(" (Swin Transformer model)"),iyo=l(),Xp=a("li"),N_e=a("strong"),dyo=o("swinv2"),myo=o(" \u2014 "),zV=a("a"),cyo=o("ViTFeatureExtractor"),fyo=o(" (Swin Transformer V2 model)"),gyo=l(),zp=a("li"),q_e=a("strong"),hyo=o("table-transformer"),uyo=o(" \u2014 "),QV=a("a"),pyo=o("DetrFeatureExtractor"),_yo=o(" (Table Transformer model)"),byo=l(),Qp=a("li"),j_e=a("strong"),vyo=o("van"),Fyo=o(" \u2014 "),WV=a("a"),Tyo=o("ConvNextFeatureExtractor"),Myo=o(" (VAN model)"),Eyo=l(),Wp=a("li"),D_e=a("strong"),Cyo=o("videomae"),wyo=o(" \u2014 "),UV=a("a"),Ayo=o("VideoMAEFeatureExtractor"),Lyo=o(" (VideoMAE model)"),yyo=l(),Up=a("li"),G_e=a("strong"),xyo=o("vilt"),$yo=o(" \u2014 "),HV=a("a"),kyo=o("ViltFeatureExtractor"),Syo=o(" (ViLT model)"),Ryo=l(),Hp=a("li"),O_e=a("strong"),Pyo=o("vit"),Byo=o(" \u2014 "),JV=a("a"),Iyo=o("ViTFeatureExtractor"),Nyo=o(" (ViT model)"),qyo=l(),Jp=a("li"),V_e=a("strong"),jyo=o("vit_mae"),Dyo=o(" \u2014 "),YV=a("a"),Gyo=o("ViTFeatureExtractor"),Oyo=o(" (ViTMAE model)"),Vyo=l(),Yp=a("li"),X_e=a("strong"),Xyo=o("vit_msn"),zyo=o(" \u2014 "),ZV=a("a"),Qyo=o("ViTFeatureExtractor"),Wyo=o(" (ViTMSN model)"),Uyo=l(),Zp=a("li"),z_e=a("strong"),Hyo=o("wav2vec2"),Jyo=o(" \u2014 "),KV=a("a"),Yyo=o("Wav2Vec2FeatureExtractor"),Zyo=o(" (Wav2Vec2 model)"),Kyo=l(),Kp=a("li"),Q_e=a("strong"),e9o=o("wav2vec2-conformer"),o9o=o(" \u2014 "),eX=a("a"),r9o=o("Wav2Vec2FeatureExtractor"),t9o=o(" (Wav2Vec2-Conformer model)"),a9o=l(),e_=a("li"),W_e=a("strong"),n9o=o("whisper"),s9o=o(" \u2014 "),oX=a("a"),l9o=o("WhisperFeatureExtractor"),i9o=o(" (Whisper model)"),d9o=l(),o_=a("li"),U_e=a("strong"),m9o=o("xclip"),c9o=o(" \u2014 "),rX=a("a"),f9o=o("CLIPFeatureExtractor"),g9o=o(" (X-CLIP model)"),h9o=l(),r_=a("li"),H_e=a("strong"),u9o=o("yolos"),p9o=o(" \u2014 "),tX=a("a"),_9o=o("YolosFeatureExtractor"),b9o=o(" (YOLOS model)"),v9o=l(),F(t_.$$.fragment),F9o=l(),F(a_.$$.fragment),T9o=l(),n_=a("div"),F(y$.$$.fragment),M9o=l(),J_e=a("p"),E9o=o("Register a new feature extractor for this class."),Ito=l(),$d=a("h2"),s_=a("a"),Y_e=a("span"),F(x$.$$.fragment),C9o=l(),Z_e=a("span"),w9o=o("AutoProcessor"),Nto=l(),Bo=a("div"),F($$.$$.fragment),A9o=l(),k$=a("p"),L9o=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),aX=a("a"),y9o=o("AutoProcessor.from_pretrained()"),x9o=o(" class method."),$9o=l(),S$=a("p"),k9o=o("This class cannot be instantiated directly using "),K_e=a("code"),S9o=o("__init__()"),R9o=o(" (throws an error)."),P9o=l(),Ze=a("div"),F(R$.$$.fragment),B9o=l(),e1e=a("p"),I9o=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),N9o=l(),kd=a("p"),q9o=o("The processor class to instantiate is selected based on the "),o1e=a("code"),j9o=o("model_type"),D9o=o(` property of the config object (either
passed as an argument or loaded from `),r1e=a("code"),G9o=o("pretrained_model_name_or_path"),O9o=o(" if possible):"),V9o=l(),le=a("ul"),l_=a("li"),t1e=a("strong"),X9o=o("clip"),z9o=o(" \u2014 "),nX=a("a"),Q9o=o("CLIPProcessor"),W9o=o(" (CLIP model)"),U9o=l(),i_=a("li"),a1e=a("strong"),H9o=o("flava"),J9o=o(" \u2014 "),sX=a("a"),Y9o=o("FlavaProcessor"),Z9o=o(" (FLAVA model)"),K9o=l(),d_=a("li"),n1e=a("strong"),exo=o("groupvit"),oxo=o(" \u2014 "),lX=a("a"),rxo=o("CLIPProcessor"),txo=o(" (GroupViT model)"),axo=l(),m_=a("li"),s1e=a("strong"),nxo=o("layoutlmv2"),sxo=o(" \u2014 "),iX=a("a"),lxo=o("LayoutLMv2Processor"),ixo=o(" (LayoutLMv2 model)"),dxo=l(),c_=a("li"),l1e=a("strong"),mxo=o("layoutlmv3"),cxo=o(" \u2014 "),dX=a("a"),fxo=o("LayoutLMv3Processor"),gxo=o(" (LayoutLMv3 model)"),hxo=l(),f_=a("li"),i1e=a("strong"),uxo=o("layoutxlm"),pxo=o(" \u2014 "),mX=a("a"),_xo=o("LayoutXLMProcessor"),bxo=o(" (LayoutXLM model)"),vxo=l(),g_=a("li"),d1e=a("strong"),Fxo=o("markuplm"),Txo=o(" \u2014 "),cX=a("a"),Mxo=o("MarkupLMProcessor"),Exo=o(" (MarkupLM model)"),Cxo=l(),h_=a("li"),m1e=a("strong"),wxo=o("owlvit"),Axo=o(" \u2014 "),fX=a("a"),Lxo=o("OwlViTProcessor"),yxo=o(" (OWL-ViT model)"),xxo=l(),u_=a("li"),c1e=a("strong"),$xo=o("sew"),kxo=o(" \u2014 "),gX=a("a"),Sxo=o("Wav2Vec2Processor"),Rxo=o(" (SEW model)"),Pxo=l(),p_=a("li"),f1e=a("strong"),Bxo=o("sew-d"),Ixo=o(" \u2014 "),hX=a("a"),Nxo=o("Wav2Vec2Processor"),qxo=o(" (SEW-D model)"),jxo=l(),__=a("li"),g1e=a("strong"),Dxo=o("speech_to_text"),Gxo=o(" \u2014 "),uX=a("a"),Oxo=o("Speech2TextProcessor"),Vxo=o(" (Speech2Text model)"),Xxo=l(),b_=a("li"),h1e=a("strong"),zxo=o("speech_to_text_2"),Qxo=o(" \u2014 "),pX=a("a"),Wxo=o("Speech2Text2Processor"),Uxo=o(" (Speech2Text2 model)"),Hxo=l(),v_=a("li"),u1e=a("strong"),Jxo=o("trocr"),Yxo=o(" \u2014 "),_X=a("a"),Zxo=o("TrOCRProcessor"),Kxo=o(" (TrOCR model)"),e$o=l(),F_=a("li"),p1e=a("strong"),o$o=o("unispeech"),r$o=o(" \u2014 "),bX=a("a"),t$o=o("Wav2Vec2Processor"),a$o=o(" (UniSpeech model)"),n$o=l(),T_=a("li"),_1e=a("strong"),s$o=o("unispeech-sat"),l$o=o(" \u2014 "),vX=a("a"),i$o=o("Wav2Vec2Processor"),d$o=o(" (UniSpeechSat model)"),m$o=l(),M_=a("li"),b1e=a("strong"),c$o=o("vilt"),f$o=o(" \u2014 "),FX=a("a"),g$o=o("ViltProcessor"),h$o=o(" (ViLT model)"),u$o=l(),E_=a("li"),v1e=a("strong"),p$o=o("vision-text-dual-encoder"),_$o=o(" \u2014 "),TX=a("a"),b$o=o("VisionTextDualEncoderProcessor"),v$o=o(" (VisionTextDualEncoder model)"),F$o=l(),C_=a("li"),F1e=a("strong"),T$o=o("wav2vec2"),M$o=o(" \u2014 "),MX=a("a"),E$o=o("Wav2Vec2Processor"),C$o=o(" (Wav2Vec2 model)"),w$o=l(),w_=a("li"),T1e=a("strong"),A$o=o("wav2vec2-conformer"),L$o=o(" \u2014 "),EX=a("a"),y$o=o("Wav2Vec2Processor"),x$o=o(" (Wav2Vec2-Conformer model)"),$$o=l(),A_=a("li"),M1e=a("strong"),k$o=o("wavlm"),S$o=o(" \u2014 "),CX=a("a"),R$o=o("Wav2Vec2Processor"),P$o=o(" (WavLM model)"),B$o=l(),L_=a("li"),E1e=a("strong"),I$o=o("whisper"),N$o=o(" \u2014 "),wX=a("a"),q$o=o("WhisperProcessor"),j$o=o(" (Whisper model)"),D$o=l(),y_=a("li"),C1e=a("strong"),G$o=o("xclip"),O$o=o(" \u2014 "),AX=a("a"),V$o=o("XCLIPProcessor"),X$o=o(" (X-CLIP model)"),z$o=l(),F(x_.$$.fragment),Q$o=l(),F($_.$$.fragment),W$o=l(),k_=a("div"),F(P$.$$.fragment),U$o=l(),w1e=a("p"),H$o=o("Register a new processor for this class."),qto=l(),Sd=a("h2"),S_=a("a"),A1e=a("span"),F(B$.$$.fragment),J$o=l(),L1e=a("span"),Y$o=o("AutoModel"),jto=l(),Io=a("div"),F(I$.$$.fragment),Z$o=l(),Rd=a("p"),K$o=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),LX=a("a"),eko=o("from_pretrained()"),oko=o(" class method or the "),yX=a("a"),rko=o("from_config()"),tko=o(` class
method.`),ako=l(),N$=a("p"),nko=o("This class cannot be instantiated directly using "),y1e=a("code"),sko=o("__init__()"),lko=o(" (throws an error)."),iko=l(),Mt=a("div"),F(q$.$$.fragment),dko=l(),x1e=a("p"),mko=o("Instantiates one of the base model classes of the library from a configuration."),cko=l(),Pd=a("p"),fko=o(`Note:
Loading a model from its configuration file does `),$1e=a("strong"),gko=o("not"),hko=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xX=a("a"),uko=o("from_pretrained()"),pko=o(" to load the model weights."),_ko=l(),F(R_.$$.fragment),bko=l(),Ke=a("div"),F(j$.$$.fragment),vko=l(),k1e=a("p"),Fko=o("Instantiate one of the base model classes of the library from a pretrained model."),Tko=l(),nn=a("p"),Mko=o("The model class to instantiate is selected based on the "),S1e=a("code"),Eko=o("model_type"),Cko=o(` property of the config object (either
passed as an argument or loaded from `),R1e=a("code"),wko=o("pretrained_model_name_or_path"),Ako=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P1e=a("code"),Lko=o("pretrained_model_name_or_path"),yko=o(":"),xko=l(),y=a("ul"),P_=a("li"),B1e=a("strong"),$ko=o("albert"),kko=o(" \u2014 "),$X=a("a"),Sko=o("AlbertModel"),Rko=o(" (ALBERT model)"),Pko=l(),B_=a("li"),I1e=a("strong"),Bko=o("bart"),Iko=o(" \u2014 "),kX=a("a"),Nko=o("BartModel"),qko=o(" (BART model)"),jko=l(),I_=a("li"),N1e=a("strong"),Dko=o("beit"),Gko=o(" \u2014 "),SX=a("a"),Oko=o("BeitModel"),Vko=o(" (BEiT model)"),Xko=l(),N_=a("li"),q1e=a("strong"),zko=o("bert"),Qko=o(" \u2014 "),RX=a("a"),Wko=o("BertModel"),Uko=o(" (BERT model)"),Hko=l(),q_=a("li"),j1e=a("strong"),Jko=o("bert-generation"),Yko=o(" \u2014 "),PX=a("a"),Zko=o("BertGenerationEncoder"),Kko=o(" (Bert Generation model)"),eSo=l(),j_=a("li"),D1e=a("strong"),oSo=o("big_bird"),rSo=o(" \u2014 "),BX=a("a"),tSo=o("BigBirdModel"),aSo=o(" (BigBird model)"),nSo=l(),D_=a("li"),G1e=a("strong"),sSo=o("bigbird_pegasus"),lSo=o(" \u2014 "),IX=a("a"),iSo=o("BigBirdPegasusModel"),dSo=o(" (BigBird-Pegasus model)"),mSo=l(),G_=a("li"),O1e=a("strong"),cSo=o("blenderbot"),fSo=o(" \u2014 "),NX=a("a"),gSo=o("BlenderbotModel"),hSo=o(" (Blenderbot model)"),uSo=l(),O_=a("li"),V1e=a("strong"),pSo=o("blenderbot-small"),_So=o(" \u2014 "),qX=a("a"),bSo=o("BlenderbotSmallModel"),vSo=o(" (BlenderbotSmall model)"),FSo=l(),V_=a("li"),X1e=a("strong"),TSo=o("bloom"),MSo=o(" \u2014 "),jX=a("a"),ESo=o("BloomModel"),CSo=o(" (BLOOM model)"),wSo=l(),X_=a("li"),z1e=a("strong"),ASo=o("camembert"),LSo=o(" \u2014 "),DX=a("a"),ySo=o("CamembertModel"),xSo=o(" (CamemBERT model)"),$So=l(),z_=a("li"),Q1e=a("strong"),kSo=o("canine"),SSo=o(" \u2014 "),GX=a("a"),RSo=o("CanineModel"),PSo=o(" (CANINE model)"),BSo=l(),Q_=a("li"),W1e=a("strong"),ISo=o("clip"),NSo=o(" \u2014 "),OX=a("a"),qSo=o("CLIPModel"),jSo=o(" (CLIP model)"),DSo=l(),W_=a("li"),U1e=a("strong"),GSo=o("codegen"),OSo=o(" \u2014 "),VX=a("a"),VSo=o("CodeGenModel"),XSo=o(" (CodeGen model)"),zSo=l(),U_=a("li"),H1e=a("strong"),QSo=o("conditional_detr"),WSo=o(" \u2014 "),XX=a("a"),USo=o("ConditionalDetrModel"),HSo=o(" (Conditional DETR model)"),JSo=l(),H_=a("li"),J1e=a("strong"),YSo=o("convbert"),ZSo=o(" \u2014 "),zX=a("a"),KSo=o("ConvBertModel"),eRo=o(" (ConvBERT model)"),oRo=l(),J_=a("li"),Y1e=a("strong"),rRo=o("convnext"),tRo=o(" \u2014 "),QX=a("a"),aRo=o("ConvNextModel"),nRo=o(" (ConvNeXT model)"),sRo=l(),Y_=a("li"),Z1e=a("strong"),lRo=o("ctrl"),iRo=o(" \u2014 "),WX=a("a"),dRo=o("CTRLModel"),mRo=o(" (CTRL model)"),cRo=l(),Z_=a("li"),K1e=a("strong"),fRo=o("cvt"),gRo=o(" \u2014 "),UX=a("a"),hRo=o("CvtModel"),uRo=o(" (CvT model)"),pRo=l(),K_=a("li"),e2e=a("strong"),_Ro=o("data2vec-audio"),bRo=o(" \u2014 "),HX=a("a"),vRo=o("Data2VecAudioModel"),FRo=o(" (Data2VecAudio model)"),TRo=l(),e1=a("li"),o2e=a("strong"),MRo=o("data2vec-text"),ERo=o(" \u2014 "),JX=a("a"),CRo=o("Data2VecTextModel"),wRo=o(" (Data2VecText model)"),ARo=l(),o1=a("li"),r2e=a("strong"),LRo=o("data2vec-vision"),yRo=o(" \u2014 "),YX=a("a"),xRo=o("Data2VecVisionModel"),$Ro=o(" (Data2VecVision model)"),kRo=l(),r1=a("li"),t2e=a("strong"),SRo=o("deberta"),RRo=o(" \u2014 "),ZX=a("a"),PRo=o("DebertaModel"),BRo=o(" (DeBERTa model)"),IRo=l(),t1=a("li"),a2e=a("strong"),NRo=o("deberta-v2"),qRo=o(" \u2014 "),KX=a("a"),jRo=o("DebertaV2Model"),DRo=o(" (DeBERTa-v2 model)"),GRo=l(),a1=a("li"),n2e=a("strong"),ORo=o("decision_transformer"),VRo=o(" \u2014 "),ez=a("a"),XRo=o("DecisionTransformerModel"),zRo=o(" (Decision Transformer model)"),QRo=l(),n1=a("li"),s2e=a("strong"),WRo=o("deformable_detr"),URo=o(" \u2014 "),oz=a("a"),HRo=o("DeformableDetrModel"),JRo=o(" (Deformable DETR model)"),YRo=l(),s1=a("li"),l2e=a("strong"),ZRo=o("deit"),KRo=o(" \u2014 "),rz=a("a"),ePo=o("DeiTModel"),oPo=o(" (DeiT model)"),rPo=l(),l1=a("li"),i2e=a("strong"),tPo=o("detr"),aPo=o(" \u2014 "),tz=a("a"),nPo=o("DetrModel"),sPo=o(" (DETR model)"),lPo=l(),i1=a("li"),d2e=a("strong"),iPo=o("distilbert"),dPo=o(" \u2014 "),az=a("a"),mPo=o("DistilBertModel"),cPo=o(" (DistilBERT model)"),fPo=l(),d1=a("li"),m2e=a("strong"),gPo=o("donut-swin"),hPo=o(" \u2014 "),nz=a("a"),uPo=o("DonutSwinModel"),pPo=o(" (DonutSwin model)"),_Po=l(),m1=a("li"),c2e=a("strong"),bPo=o("dpr"),vPo=o(" \u2014 "),sz=a("a"),FPo=o("DPRQuestionEncoder"),TPo=o(" (DPR model)"),MPo=l(),c1=a("li"),f2e=a("strong"),EPo=o("dpt"),CPo=o(" \u2014 "),lz=a("a"),wPo=o("DPTModel"),APo=o(" (DPT model)"),LPo=l(),f1=a("li"),g2e=a("strong"),yPo=o("electra"),xPo=o(" \u2014 "),iz=a("a"),$Po=o("ElectraModel"),kPo=o(" (ELECTRA model)"),SPo=l(),g1=a("li"),h2e=a("strong"),RPo=o("ernie"),PPo=o(" \u2014 "),dz=a("a"),BPo=o("ErnieModel"),IPo=o(" (ERNIE model)"),NPo=l(),h1=a("li"),u2e=a("strong"),qPo=o("esm"),jPo=o(" \u2014 "),mz=a("a"),DPo=o("EsmModel"),GPo=o(" (ESM model)"),OPo=l(),u1=a("li"),p2e=a("strong"),VPo=o("flaubert"),XPo=o(" \u2014 "),cz=a("a"),zPo=o("FlaubertModel"),QPo=o(" (FlauBERT model)"),WPo=l(),p1=a("li"),_2e=a("strong"),UPo=o("flava"),HPo=o(" \u2014 "),fz=a("a"),JPo=o("FlavaModel"),YPo=o(" (FLAVA model)"),ZPo=l(),_1=a("li"),b2e=a("strong"),KPo=o("fnet"),eBo=o(" \u2014 "),gz=a("a"),oBo=o("FNetModel"),rBo=o(" (FNet model)"),tBo=l(),b1=a("li"),v2e=a("strong"),aBo=o("fsmt"),nBo=o(" \u2014 "),hz=a("a"),sBo=o("FSMTModel"),lBo=o(" (FairSeq Machine-Translation model)"),iBo=l(),xl=a("li"),F2e=a("strong"),dBo=o("funnel"),mBo=o(" \u2014 "),uz=a("a"),cBo=o("FunnelModel"),fBo=o(" or "),pz=a("a"),gBo=o("FunnelBaseModel"),hBo=o(" (Funnel Transformer model)"),uBo=l(),v1=a("li"),T2e=a("strong"),pBo=o("glpn"),_Bo=o(" \u2014 "),_z=a("a"),bBo=o("GLPNModel"),vBo=o(" (GLPN model)"),FBo=l(),F1=a("li"),M2e=a("strong"),TBo=o("gpt2"),MBo=o(" \u2014 "),bz=a("a"),EBo=o("GPT2Model"),CBo=o(" (OpenAI GPT-2 model)"),wBo=l(),T1=a("li"),E2e=a("strong"),ABo=o("gpt_neo"),LBo=o(" \u2014 "),vz=a("a"),yBo=o("GPTNeoModel"),xBo=o(" (GPT Neo model)"),$Bo=l(),M1=a("li"),C2e=a("strong"),kBo=o("gpt_neox"),SBo=o(" \u2014 "),Fz=a("a"),RBo=o("GPTNeoXModel"),PBo=o(" (GPT NeoX model)"),BBo=l(),E1=a("li"),w2e=a("strong"),IBo=o("gpt_neox_japanese"),NBo=o(" \u2014 "),Tz=a("a"),qBo=o("GPTNeoXJapaneseModel"),jBo=o(" (GPT NeoX Japanese model)"),DBo=l(),C1=a("li"),A2e=a("strong"),GBo=o("gptj"),OBo=o(" \u2014 "),Mz=a("a"),VBo=o("GPTJModel"),XBo=o(" (GPT-J model)"),zBo=l(),w1=a("li"),L2e=a("strong"),QBo=o("groupvit"),WBo=o(" \u2014 "),Ez=a("a"),UBo=o("GroupViTModel"),HBo=o(" (GroupViT model)"),JBo=l(),A1=a("li"),y2e=a("strong"),YBo=o("hubert"),ZBo=o(" \u2014 "),Cz=a("a"),KBo=o("HubertModel"),eIo=o(" (Hubert model)"),oIo=l(),L1=a("li"),x2e=a("strong"),rIo=o("ibert"),tIo=o(" \u2014 "),wz=a("a"),aIo=o("IBertModel"),nIo=o(" (I-BERT model)"),sIo=l(),y1=a("li"),$2e=a("strong"),lIo=o("imagegpt"),iIo=o(" \u2014 "),Az=a("a"),dIo=o("ImageGPTModel"),mIo=o(" (ImageGPT model)"),cIo=l(),x1=a("li"),k2e=a("strong"),fIo=o("layoutlm"),gIo=o(" \u2014 "),Lz=a("a"),hIo=o("LayoutLMModel"),uIo=o(" (LayoutLM model)"),pIo=l(),$1=a("li"),S2e=a("strong"),_Io=o("layoutlmv2"),bIo=o(" \u2014 "),yz=a("a"),vIo=o("LayoutLMv2Model"),FIo=o(" (LayoutLMv2 model)"),TIo=l(),k1=a("li"),R2e=a("strong"),MIo=o("layoutlmv3"),EIo=o(" \u2014 "),xz=a("a"),CIo=o("LayoutLMv3Model"),wIo=o(" (LayoutLMv3 model)"),AIo=l(),S1=a("li"),P2e=a("strong"),LIo=o("led"),yIo=o(" \u2014 "),$z=a("a"),xIo=o("LEDModel"),$Io=o(" (LED model)"),kIo=l(),R1=a("li"),B2e=a("strong"),SIo=o("levit"),RIo=o(" \u2014 "),kz=a("a"),PIo=o("LevitModel"),BIo=o(" (LeViT model)"),IIo=l(),P1=a("li"),I2e=a("strong"),NIo=o("lilt"),qIo=o(" \u2014 "),Sz=a("a"),jIo=o("LiltModel"),DIo=o(" (LiLT model)"),GIo=l(),B1=a("li"),N2e=a("strong"),OIo=o("longformer"),VIo=o(" \u2014 "),Rz=a("a"),XIo=o("LongformerModel"),zIo=o(" (Longformer model)"),QIo=l(),I1=a("li"),q2e=a("strong"),WIo=o("longt5"),UIo=o(" \u2014 "),Pz=a("a"),HIo=o("LongT5Model"),JIo=o(" (LongT5 model)"),YIo=l(),N1=a("li"),j2e=a("strong"),ZIo=o("luke"),KIo=o(" \u2014 "),Bz=a("a"),eNo=o("LukeModel"),oNo=o(" (LUKE model)"),rNo=l(),q1=a("li"),D2e=a("strong"),tNo=o("lxmert"),aNo=o(" \u2014 "),Iz=a("a"),nNo=o("LxmertModel"),sNo=o(" (LXMERT model)"),lNo=l(),j1=a("li"),G2e=a("strong"),iNo=o("m2m_100"),dNo=o(" \u2014 "),Nz=a("a"),mNo=o("M2M100Model"),cNo=o(" (M2M100 model)"),fNo=l(),D1=a("li"),O2e=a("strong"),gNo=o("marian"),hNo=o(" \u2014 "),qz=a("a"),uNo=o("MarianModel"),pNo=o(" (Marian model)"),_No=l(),G1=a("li"),V2e=a("strong"),bNo=o("markuplm"),vNo=o(" \u2014 "),jz=a("a"),FNo=o("MarkupLMModel"),TNo=o(" (MarkupLM model)"),MNo=l(),O1=a("li"),X2e=a("strong"),ENo=o("maskformer"),CNo=o(" \u2014 "),Dz=a("a"),wNo=o("MaskFormerModel"),ANo=o(" (MaskFormer model)"),LNo=l(),V1=a("li"),z2e=a("strong"),yNo=o("mbart"),xNo=o(" \u2014 "),Gz=a("a"),$No=o("MBartModel"),kNo=o(" (mBART model)"),SNo=l(),X1=a("li"),Q2e=a("strong"),RNo=o("mctct"),PNo=o(" \u2014 "),Oz=a("a"),BNo=o("MCTCTModel"),INo=o(" (M-CTC-T model)"),NNo=l(),z1=a("li"),W2e=a("strong"),qNo=o("megatron-bert"),jNo=o(" \u2014 "),Vz=a("a"),DNo=o("MegatronBertModel"),GNo=o(" (Megatron-BERT model)"),ONo=l(),Q1=a("li"),U2e=a("strong"),VNo=o("mobilebert"),XNo=o(" \u2014 "),Xz=a("a"),zNo=o("MobileBertModel"),QNo=o(" (MobileBERT model)"),WNo=l(),W1=a("li"),H2e=a("strong"),UNo=o("mobilevit"),HNo=o(" \u2014 "),zz=a("a"),JNo=o("MobileViTModel"),YNo=o(" (MobileViT model)"),ZNo=l(),U1=a("li"),J2e=a("strong"),KNo=o("mpnet"),eqo=o(" \u2014 "),Qz=a("a"),oqo=o("MPNetModel"),rqo=o(" (MPNet model)"),tqo=l(),H1=a("li"),Y2e=a("strong"),aqo=o("mt5"),nqo=o(" \u2014 "),Wz=a("a"),sqo=o("MT5Model"),lqo=o(" (MT5 model)"),iqo=l(),J1=a("li"),Z2e=a("strong"),dqo=o("mvp"),mqo=o(" \u2014 "),Uz=a("a"),cqo=o("MvpModel"),fqo=o(" (MVP model)"),gqo=l(),Y1=a("li"),K2e=a("strong"),hqo=o("nezha"),uqo=o(" \u2014 "),Hz=a("a"),pqo=o("NezhaModel"),_qo=o(" (Nezha model)"),bqo=l(),Z1=a("li"),ebe=a("strong"),vqo=o("nllb"),Fqo=o(" \u2014 "),Jz=a("a"),Tqo=o("M2M100Model"),Mqo=o(" (NLLB model)"),Eqo=l(),K1=a("li"),obe=a("strong"),Cqo=o("nystromformer"),wqo=o(" \u2014 "),Yz=a("a"),Aqo=o("NystromformerModel"),Lqo=o(" (Nystr\xF6mformer model)"),yqo=l(),e2=a("li"),rbe=a("strong"),xqo=o("openai-gpt"),$qo=o(" \u2014 "),Zz=a("a"),kqo=o("OpenAIGPTModel"),Sqo=o(" (OpenAI GPT model)"),Rqo=l(),o2=a("li"),tbe=a("strong"),Pqo=o("opt"),Bqo=o(" \u2014 "),Kz=a("a"),Iqo=o("OPTModel"),Nqo=o(" (OPT model)"),qqo=l(),r2=a("li"),abe=a("strong"),jqo=o("owlvit"),Dqo=o(" \u2014 "),eQ=a("a"),Gqo=o("OwlViTModel"),Oqo=o(" (OWL-ViT model)"),Vqo=l(),t2=a("li"),nbe=a("strong"),Xqo=o("pegasus"),zqo=o(" \u2014 "),oQ=a("a"),Qqo=o("PegasusModel"),Wqo=o(" (Pegasus model)"),Uqo=l(),a2=a("li"),sbe=a("strong"),Hqo=o("pegasus_x"),Jqo=o(" \u2014 "),rQ=a("a"),Yqo=o("PegasusXModel"),Zqo=o(" (PEGASUS-X model)"),Kqo=l(),n2=a("li"),lbe=a("strong"),ejo=o("perceiver"),ojo=o(" \u2014 "),tQ=a("a"),rjo=o("PerceiverModel"),tjo=o(" (Perceiver model)"),ajo=l(),s2=a("li"),ibe=a("strong"),njo=o("plbart"),sjo=o(" \u2014 "),aQ=a("a"),ljo=o("PLBartModel"),ijo=o(" (PLBart model)"),djo=l(),l2=a("li"),dbe=a("strong"),mjo=o("poolformer"),cjo=o(" \u2014 "),nQ=a("a"),fjo=o("PoolFormerModel"),gjo=o(" (PoolFormer model)"),hjo=l(),i2=a("li"),mbe=a("strong"),ujo=o("prophetnet"),pjo=o(" \u2014 "),sQ=a("a"),_jo=o("ProphetNetModel"),bjo=o(" (ProphetNet model)"),vjo=l(),d2=a("li"),cbe=a("strong"),Fjo=o("qdqbert"),Tjo=o(" \u2014 "),lQ=a("a"),Mjo=o("QDQBertModel"),Ejo=o(" (QDQBert model)"),Cjo=l(),m2=a("li"),fbe=a("strong"),wjo=o("reformer"),Ajo=o(" \u2014 "),iQ=a("a"),Ljo=o("ReformerModel"),yjo=o(" (Reformer model)"),xjo=l(),c2=a("li"),gbe=a("strong"),$jo=o("regnet"),kjo=o(" \u2014 "),dQ=a("a"),Sjo=o("RegNetModel"),Rjo=o(" (RegNet model)"),Pjo=l(),f2=a("li"),hbe=a("strong"),Bjo=o("rembert"),Ijo=o(" \u2014 "),mQ=a("a"),Njo=o("RemBertModel"),qjo=o(" (RemBERT model)"),jjo=l(),g2=a("li"),ube=a("strong"),Djo=o("resnet"),Gjo=o(" \u2014 "),cQ=a("a"),Ojo=o("ResNetModel"),Vjo=o(" (ResNet model)"),Xjo=l(),h2=a("li"),pbe=a("strong"),zjo=o("retribert"),Qjo=o(" \u2014 "),fQ=a("a"),Wjo=o("RetriBertModel"),Ujo=o(" (RetriBERT model)"),Hjo=l(),u2=a("li"),_be=a("strong"),Jjo=o("roberta"),Yjo=o(" \u2014 "),gQ=a("a"),Zjo=o("RobertaModel"),Kjo=o(" (RoBERTa model)"),eDo=l(),p2=a("li"),bbe=a("strong"),oDo=o("roformer"),rDo=o(" \u2014 "),hQ=a("a"),tDo=o("RoFormerModel"),aDo=o(" (RoFormer model)"),nDo=l(),_2=a("li"),vbe=a("strong"),sDo=o("segformer"),lDo=o(" \u2014 "),uQ=a("a"),iDo=o("SegformerModel"),dDo=o(" (SegFormer model)"),mDo=l(),b2=a("li"),Fbe=a("strong"),cDo=o("sew"),fDo=o(" \u2014 "),pQ=a("a"),gDo=o("SEWModel"),hDo=o(" (SEW model)"),uDo=l(),v2=a("li"),Tbe=a("strong"),pDo=o("sew-d"),_Do=o(" \u2014 "),_Q=a("a"),bDo=o("SEWDModel"),vDo=o(" (SEW-D model)"),FDo=l(),F2=a("li"),Mbe=a("strong"),TDo=o("speech_to_text"),MDo=o(" \u2014 "),bQ=a("a"),EDo=o("Speech2TextModel"),CDo=o(" (Speech2Text model)"),wDo=l(),T2=a("li"),Ebe=a("strong"),ADo=o("splinter"),LDo=o(" \u2014 "),vQ=a("a"),yDo=o("SplinterModel"),xDo=o(" (Splinter model)"),$Do=l(),M2=a("li"),Cbe=a("strong"),kDo=o("squeezebert"),SDo=o(" \u2014 "),FQ=a("a"),RDo=o("SqueezeBertModel"),PDo=o(" (SqueezeBERT model)"),BDo=l(),E2=a("li"),wbe=a("strong"),IDo=o("swin"),NDo=o(" \u2014 "),TQ=a("a"),qDo=o("SwinModel"),jDo=o(" (Swin Transformer model)"),DDo=l(),C2=a("li"),Abe=a("strong"),GDo=o("swinv2"),ODo=o(" \u2014 "),MQ=a("a"),VDo=o("Swinv2Model"),XDo=o(" (Swin Transformer V2 model)"),zDo=l(),w2=a("li"),Lbe=a("strong"),QDo=o("t5"),WDo=o(" \u2014 "),EQ=a("a"),UDo=o("T5Model"),HDo=o(" (T5 model)"),JDo=l(),A2=a("li"),ybe=a("strong"),YDo=o("table-transformer"),ZDo=o(" \u2014 "),CQ=a("a"),KDo=o("TableTransformerModel"),eGo=o(" (Table Transformer model)"),oGo=l(),L2=a("li"),xbe=a("strong"),rGo=o("tapas"),tGo=o(" \u2014 "),wQ=a("a"),aGo=o("TapasModel"),nGo=o(" (TAPAS model)"),sGo=l(),y2=a("li"),$be=a("strong"),lGo=o("time_series_transformer"),iGo=o(" \u2014 "),AQ=a("a"),dGo=o("TimeSeriesTransformerModel"),mGo=o(" (Time Series Transformer model)"),cGo=l(),x2=a("li"),kbe=a("strong"),fGo=o("trajectory_transformer"),gGo=o(" \u2014 "),LQ=a("a"),hGo=o("TrajectoryTransformerModel"),uGo=o(" (Trajectory Transformer model)"),pGo=l(),$2=a("li"),Sbe=a("strong"),_Go=o("transfo-xl"),bGo=o(" \u2014 "),yQ=a("a"),vGo=o("TransfoXLModel"),FGo=o(" (Transformer-XL model)"),TGo=l(),k2=a("li"),Rbe=a("strong"),MGo=o("unispeech"),EGo=o(" \u2014 "),xQ=a("a"),CGo=o("UniSpeechModel"),wGo=o(" (UniSpeech model)"),AGo=l(),S2=a("li"),Pbe=a("strong"),LGo=o("unispeech-sat"),yGo=o(" \u2014 "),$Q=a("a"),xGo=o("UniSpeechSatModel"),$Go=o(" (UniSpeechSat model)"),kGo=l(),R2=a("li"),Bbe=a("strong"),SGo=o("van"),RGo=o(" \u2014 "),kQ=a("a"),PGo=o("VanModel"),BGo=o(" (VAN model)"),IGo=l(),P2=a("li"),Ibe=a("strong"),NGo=o("videomae"),qGo=o(" \u2014 "),SQ=a("a"),jGo=o("VideoMAEModel"),DGo=o(" (VideoMAE model)"),GGo=l(),B2=a("li"),Nbe=a("strong"),OGo=o("vilt"),VGo=o(" \u2014 "),RQ=a("a"),XGo=o("ViltModel"),zGo=o(" (ViLT model)"),QGo=l(),I2=a("li"),qbe=a("strong"),WGo=o("vision-text-dual-encoder"),UGo=o(" \u2014 "),PQ=a("a"),HGo=o("VisionTextDualEncoderModel"),JGo=o(" (VisionTextDualEncoder model)"),YGo=l(),N2=a("li"),jbe=a("strong"),ZGo=o("visual_bert"),KGo=o(" \u2014 "),BQ=a("a"),eOo=o("VisualBertModel"),oOo=o(" (VisualBERT model)"),rOo=l(),q2=a("li"),Dbe=a("strong"),tOo=o("vit"),aOo=o(" \u2014 "),IQ=a("a"),nOo=o("ViTModel"),sOo=o(" (ViT model)"),lOo=l(),j2=a("li"),Gbe=a("strong"),iOo=o("vit_mae"),dOo=o(" \u2014 "),NQ=a("a"),mOo=o("ViTMAEModel"),cOo=o(" (ViTMAE model)"),fOo=l(),D2=a("li"),Obe=a("strong"),gOo=o("vit_msn"),hOo=o(" \u2014 "),qQ=a("a"),uOo=o("ViTMSNModel"),pOo=o(" (ViTMSN model)"),_Oo=l(),G2=a("li"),Vbe=a("strong"),bOo=o("wav2vec2"),vOo=o(" \u2014 "),jQ=a("a"),FOo=o("Wav2Vec2Model"),TOo=o(" (Wav2Vec2 model)"),MOo=l(),O2=a("li"),Xbe=a("strong"),EOo=o("wav2vec2-conformer"),COo=o(" \u2014 "),DQ=a("a"),wOo=o("Wav2Vec2ConformerModel"),AOo=o(" (Wav2Vec2-Conformer model)"),LOo=l(),V2=a("li"),zbe=a("strong"),yOo=o("wavlm"),xOo=o(" \u2014 "),GQ=a("a"),$Oo=o("WavLMModel"),kOo=o(" (WavLM model)"),SOo=l(),X2=a("li"),Qbe=a("strong"),ROo=o("whisper"),POo=o(" \u2014 "),OQ=a("a"),BOo=o("WhisperModel"),IOo=o(" (Whisper model)"),NOo=l(),z2=a("li"),Wbe=a("strong"),qOo=o("xclip"),jOo=o(" \u2014 "),VQ=a("a"),DOo=o("XCLIPModel"),GOo=o(" (X-CLIP model)"),OOo=l(),Q2=a("li"),Ube=a("strong"),VOo=o("xglm"),XOo=o(" \u2014 "),XQ=a("a"),zOo=o("XGLMModel"),QOo=o(" (XGLM model)"),WOo=l(),W2=a("li"),Hbe=a("strong"),UOo=o("xlm"),HOo=o(" \u2014 "),zQ=a("a"),JOo=o("XLMModel"),YOo=o(" (XLM model)"),ZOo=l(),U2=a("li"),Jbe=a("strong"),KOo=o("xlm-prophetnet"),eVo=o(" \u2014 "),QQ=a("a"),oVo=o("XLMProphetNetModel"),rVo=o(" (XLM-ProphetNet model)"),tVo=l(),H2=a("li"),Ybe=a("strong"),aVo=o("xlm-roberta"),nVo=o(" \u2014 "),WQ=a("a"),sVo=o("XLMRobertaModel"),lVo=o(" (XLM-RoBERTa model)"),iVo=l(),J2=a("li"),Zbe=a("strong"),dVo=o("xlm-roberta-xl"),mVo=o(" \u2014 "),UQ=a("a"),cVo=o("XLMRobertaXLModel"),fVo=o(" (XLM-RoBERTa-XL model)"),gVo=l(),Y2=a("li"),Kbe=a("strong"),hVo=o("xlnet"),uVo=o(" \u2014 "),HQ=a("a"),pVo=o("XLNetModel"),_Vo=o(" (XLNet model)"),bVo=l(),Z2=a("li"),eve=a("strong"),vVo=o("yolos"),FVo=o(" \u2014 "),JQ=a("a"),TVo=o("YolosModel"),MVo=o(" (YOLOS model)"),EVo=l(),K2=a("li"),ove=a("strong"),CVo=o("yoso"),wVo=o(" \u2014 "),YQ=a("a"),AVo=o("YosoModel"),LVo=o(" (YOSO model)"),yVo=l(),eb=a("p"),xVo=o("The model is set in evaluation mode by default using "),rve=a("code"),$Vo=o("model.eval()"),kVo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),tve=a("code"),SVo=o("model.train()"),RVo=l(),F(ob.$$.fragment),Dto=l(),Bd=a("h2"),rb=a("a"),ave=a("span"),F(D$.$$.fragment),PVo=l(),nve=a("span"),BVo=o("AutoModelForPreTraining"),Gto=l(),No=a("div"),F(G$.$$.fragment),IVo=l(),Id=a("p"),NVo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),ZQ=a("a"),qVo=o("from_pretrained()"),jVo=o(" class method or the "),KQ=a("a"),DVo=o("from_config()"),GVo=o(` class
method.`),OVo=l(),O$=a("p"),VVo=o("This class cannot be instantiated directly using "),sve=a("code"),XVo=o("__init__()"),zVo=o(" (throws an error)."),QVo=l(),Et=a("div"),F(V$.$$.fragment),WVo=l(),lve=a("p"),UVo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),HVo=l(),Nd=a("p"),JVo=o(`Note:
Loading a model from its configuration file does `),ive=a("strong"),YVo=o("not"),ZVo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eW=a("a"),KVo=o("from_pretrained()"),eXo=o(" to load the model weights."),oXo=l(),F(tb.$$.fragment),rXo=l(),eo=a("div"),F(X$.$$.fragment),tXo=l(),dve=a("p"),aXo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),nXo=l(),sn=a("p"),sXo=o("The model class to instantiate is selected based on the "),mve=a("code"),lXo=o("model_type"),iXo=o(` property of the config object (either
passed as an argument or loaded from `),cve=a("code"),dXo=o("pretrained_model_name_or_path"),mXo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fve=a("code"),cXo=o("pretrained_model_name_or_path"),fXo=o(":"),gXo=l(),G=a("ul"),ab=a("li"),gve=a("strong"),hXo=o("albert"),uXo=o(" \u2014 "),oW=a("a"),pXo=o("AlbertForPreTraining"),_Xo=o(" (ALBERT model)"),bXo=l(),nb=a("li"),hve=a("strong"),vXo=o("bart"),FXo=o(" \u2014 "),rW=a("a"),TXo=o("BartForConditionalGeneration"),MXo=o(" (BART model)"),EXo=l(),sb=a("li"),uve=a("strong"),CXo=o("bert"),wXo=o(" \u2014 "),tW=a("a"),AXo=o("BertForPreTraining"),LXo=o(" (BERT model)"),yXo=l(),lb=a("li"),pve=a("strong"),xXo=o("big_bird"),$Xo=o(" \u2014 "),aW=a("a"),kXo=o("BigBirdForPreTraining"),SXo=o(" (BigBird model)"),RXo=l(),ib=a("li"),_ve=a("strong"),PXo=o("bloom"),BXo=o(" \u2014 "),nW=a("a"),IXo=o("BloomForCausalLM"),NXo=o(" (BLOOM model)"),qXo=l(),db=a("li"),bve=a("strong"),jXo=o("camembert"),DXo=o(" \u2014 "),sW=a("a"),GXo=o("CamembertForMaskedLM"),OXo=o(" (CamemBERT model)"),VXo=l(),mb=a("li"),vve=a("strong"),XXo=o("ctrl"),zXo=o(" \u2014 "),lW=a("a"),QXo=o("CTRLLMHeadModel"),WXo=o(" (CTRL model)"),UXo=l(),cb=a("li"),Fve=a("strong"),HXo=o("data2vec-text"),JXo=o(" \u2014 "),iW=a("a"),YXo=o("Data2VecTextForMaskedLM"),ZXo=o(" (Data2VecText model)"),KXo=l(),fb=a("li"),Tve=a("strong"),ezo=o("deberta"),ozo=o(" \u2014 "),dW=a("a"),rzo=o("DebertaForMaskedLM"),tzo=o(" (DeBERTa model)"),azo=l(),gb=a("li"),Mve=a("strong"),nzo=o("deberta-v2"),szo=o(" \u2014 "),mW=a("a"),lzo=o("DebertaV2ForMaskedLM"),izo=o(" (DeBERTa-v2 model)"),dzo=l(),hb=a("li"),Eve=a("strong"),mzo=o("distilbert"),czo=o(" \u2014 "),cW=a("a"),fzo=o("DistilBertForMaskedLM"),gzo=o(" (DistilBERT model)"),hzo=l(),ub=a("li"),Cve=a("strong"),uzo=o("electra"),pzo=o(" \u2014 "),fW=a("a"),_zo=o("ElectraForPreTraining"),bzo=o(" (ELECTRA model)"),vzo=l(),pb=a("li"),wve=a("strong"),Fzo=o("ernie"),Tzo=o(" \u2014 "),gW=a("a"),Mzo=o("ErnieForPreTraining"),Ezo=o(" (ERNIE model)"),Czo=l(),_b=a("li"),Ave=a("strong"),wzo=o("flaubert"),Azo=o(" \u2014 "),hW=a("a"),Lzo=o("FlaubertWithLMHeadModel"),yzo=o(" (FlauBERT model)"),xzo=l(),bb=a("li"),Lve=a("strong"),$zo=o("flava"),kzo=o(" \u2014 "),uW=a("a"),Szo=o("FlavaForPreTraining"),Rzo=o(" (FLAVA model)"),Pzo=l(),vb=a("li"),yve=a("strong"),Bzo=o("fnet"),Izo=o(" \u2014 "),pW=a("a"),Nzo=o("FNetForPreTraining"),qzo=o(" (FNet model)"),jzo=l(),Fb=a("li"),xve=a("strong"),Dzo=o("fsmt"),Gzo=o(" \u2014 "),_W=a("a"),Ozo=o("FSMTForConditionalGeneration"),Vzo=o(" (FairSeq Machine-Translation model)"),Xzo=l(),Tb=a("li"),$ve=a("strong"),zzo=o("funnel"),Qzo=o(" \u2014 "),bW=a("a"),Wzo=o("FunnelForPreTraining"),Uzo=o(" (Funnel Transformer model)"),Hzo=l(),Mb=a("li"),kve=a("strong"),Jzo=o("gpt2"),Yzo=o(" \u2014 "),vW=a("a"),Zzo=o("GPT2LMHeadModel"),Kzo=o(" (OpenAI GPT-2 model)"),eQo=l(),Eb=a("li"),Sve=a("strong"),oQo=o("ibert"),rQo=o(" \u2014 "),FW=a("a"),tQo=o("IBertForMaskedLM"),aQo=o(" (I-BERT model)"),nQo=l(),Cb=a("li"),Rve=a("strong"),sQo=o("layoutlm"),lQo=o(" \u2014 "),TW=a("a"),iQo=o("LayoutLMForMaskedLM"),dQo=o(" (LayoutLM model)"),mQo=l(),wb=a("li"),Pve=a("strong"),cQo=o("longformer"),fQo=o(" \u2014 "),MW=a("a"),gQo=o("LongformerForMaskedLM"),hQo=o(" (Longformer model)"),uQo=l(),Ab=a("li"),Bve=a("strong"),pQo=o("luke"),_Qo=o(" \u2014 "),EW=a("a"),bQo=o("LukeForMaskedLM"),vQo=o(" (LUKE model)"),FQo=l(),Lb=a("li"),Ive=a("strong"),TQo=o("lxmert"),MQo=o(" \u2014 "),CW=a("a"),EQo=o("LxmertForPreTraining"),CQo=o(" (LXMERT model)"),wQo=l(),yb=a("li"),Nve=a("strong"),AQo=o("megatron-bert"),LQo=o(" \u2014 "),wW=a("a"),yQo=o("MegatronBertForPreTraining"),xQo=o(" (Megatron-BERT model)"),$Qo=l(),xb=a("li"),qve=a("strong"),kQo=o("mobilebert"),SQo=o(" \u2014 "),AW=a("a"),RQo=o("MobileBertForPreTraining"),PQo=o(" (MobileBERT model)"),BQo=l(),$b=a("li"),jve=a("strong"),IQo=o("mpnet"),NQo=o(" \u2014 "),LW=a("a"),qQo=o("MPNetForMaskedLM"),jQo=o(" (MPNet model)"),DQo=l(),kb=a("li"),Dve=a("strong"),GQo=o("mvp"),OQo=o(" \u2014 "),yW=a("a"),VQo=o("MvpForConditionalGeneration"),XQo=o(" (MVP model)"),zQo=l(),Sb=a("li"),Gve=a("strong"),QQo=o("nezha"),WQo=o(" \u2014 "),xW=a("a"),UQo=o("NezhaForPreTraining"),HQo=o(" (Nezha model)"),JQo=l(),Rb=a("li"),Ove=a("strong"),YQo=o("openai-gpt"),ZQo=o(" \u2014 "),$W=a("a"),KQo=o("OpenAIGPTLMHeadModel"),eWo=o(" (OpenAI GPT model)"),oWo=l(),Pb=a("li"),Vve=a("strong"),rWo=o("retribert"),tWo=o(" \u2014 "),kW=a("a"),aWo=o("RetriBertModel"),nWo=o(" (RetriBERT model)"),sWo=l(),Bb=a("li"),Xve=a("strong"),lWo=o("roberta"),iWo=o(" \u2014 "),SW=a("a"),dWo=o("RobertaForMaskedLM"),mWo=o(" (RoBERTa model)"),cWo=l(),Ib=a("li"),zve=a("strong"),fWo=o("splinter"),gWo=o(" \u2014 "),RW=a("a"),hWo=o("SplinterForPreTraining"),uWo=o(" (Splinter model)"),pWo=l(),Nb=a("li"),Qve=a("strong"),_Wo=o("squeezebert"),bWo=o(" \u2014 "),PW=a("a"),vWo=o("SqueezeBertForMaskedLM"),FWo=o(" (SqueezeBERT model)"),TWo=l(),qb=a("li"),Wve=a("strong"),MWo=o("t5"),EWo=o(" \u2014 "),BW=a("a"),CWo=o("T5ForConditionalGeneration"),wWo=o(" (T5 model)"),AWo=l(),jb=a("li"),Uve=a("strong"),LWo=o("tapas"),yWo=o(" \u2014 "),IW=a("a"),xWo=o("TapasForMaskedLM"),$Wo=o(" (TAPAS model)"),kWo=l(),Db=a("li"),Hve=a("strong"),SWo=o("transfo-xl"),RWo=o(" \u2014 "),NW=a("a"),PWo=o("TransfoXLLMHeadModel"),BWo=o(" (Transformer-XL model)"),IWo=l(),Gb=a("li"),Jve=a("strong"),NWo=o("unispeech"),qWo=o(" \u2014 "),qW=a("a"),jWo=o("UniSpeechForPreTraining"),DWo=o(" (UniSpeech model)"),GWo=l(),Ob=a("li"),Yve=a("strong"),OWo=o("unispeech-sat"),VWo=o(" \u2014 "),jW=a("a"),XWo=o("UniSpeechSatForPreTraining"),zWo=o(" (UniSpeechSat model)"),QWo=l(),Vb=a("li"),Zve=a("strong"),WWo=o("videomae"),UWo=o(" \u2014 "),DW=a("a"),HWo=o("VideoMAEForPreTraining"),JWo=o(" (VideoMAE model)"),YWo=l(),Xb=a("li"),Kve=a("strong"),ZWo=o("visual_bert"),KWo=o(" \u2014 "),GW=a("a"),eUo=o("VisualBertForPreTraining"),oUo=o(" (VisualBERT model)"),rUo=l(),zb=a("li"),eFe=a("strong"),tUo=o("vit_mae"),aUo=o(" \u2014 "),OW=a("a"),nUo=o("ViTMAEForPreTraining"),sUo=o(" (ViTMAE model)"),lUo=l(),Qb=a("li"),oFe=a("strong"),iUo=o("wav2vec2"),dUo=o(" \u2014 "),VW=a("a"),mUo=o("Wav2Vec2ForPreTraining"),cUo=o(" (Wav2Vec2 model)"),fUo=l(),Wb=a("li"),rFe=a("strong"),gUo=o("wav2vec2-conformer"),hUo=o(" \u2014 "),XW=a("a"),uUo=o("Wav2Vec2ConformerForPreTraining"),pUo=o(" (Wav2Vec2-Conformer model)"),_Uo=l(),Ub=a("li"),tFe=a("strong"),bUo=o("xlm"),vUo=o(" \u2014 "),zW=a("a"),FUo=o("XLMWithLMHeadModel"),TUo=o(" (XLM model)"),MUo=l(),Hb=a("li"),aFe=a("strong"),EUo=o("xlm-roberta"),CUo=o(" \u2014 "),QW=a("a"),wUo=o("XLMRobertaForMaskedLM"),AUo=o(" (XLM-RoBERTa model)"),LUo=l(),Jb=a("li"),nFe=a("strong"),yUo=o("xlm-roberta-xl"),xUo=o(" \u2014 "),WW=a("a"),$Uo=o("XLMRobertaXLForMaskedLM"),kUo=o(" (XLM-RoBERTa-XL model)"),SUo=l(),Yb=a("li"),sFe=a("strong"),RUo=o("xlnet"),PUo=o(" \u2014 "),UW=a("a"),BUo=o("XLNetLMHeadModel"),IUo=o(" (XLNet model)"),NUo=l(),Zb=a("p"),qUo=o("The model is set in evaluation mode by default using "),lFe=a("code"),jUo=o("model.eval()"),DUo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),iFe=a("code"),GUo=o("model.train()"),OUo=l(),F(Kb.$$.fragment),Oto=l(),qd=a("h2"),ev=a("a"),dFe=a("span"),F(z$.$$.fragment),VUo=l(),mFe=a("span"),XUo=o("AutoModelForCausalLM"),Vto=l(),qo=a("div"),F(Q$.$$.fragment),zUo=l(),jd=a("p"),QUo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),HW=a("a"),WUo=o("from_pretrained()"),UUo=o(" class method or the "),JW=a("a"),HUo=o("from_config()"),JUo=o(` class
method.`),YUo=l(),W$=a("p"),ZUo=o("This class cannot be instantiated directly using "),cFe=a("code"),KUo=o("__init__()"),eHo=o(" (throws an error)."),oHo=l(),Ct=a("div"),F(U$.$$.fragment),rHo=l(),fFe=a("p"),tHo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),aHo=l(),Dd=a("p"),nHo=o(`Note:
Loading a model from its configuration file does `),gFe=a("strong"),sHo=o("not"),lHo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YW=a("a"),iHo=o("from_pretrained()"),dHo=o(" to load the model weights."),mHo=l(),F(ov.$$.fragment),cHo=l(),oo=a("div"),F(H$.$$.fragment),fHo=l(),hFe=a("p"),gHo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),hHo=l(),ln=a("p"),uHo=o("The model class to instantiate is selected based on the "),uFe=a("code"),pHo=o("model_type"),_Ho=o(` property of the config object (either
passed as an argument or loaded from `),pFe=a("code"),bHo=o("pretrained_model_name_or_path"),vHo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_Fe=a("code"),FHo=o("pretrained_model_name_or_path"),THo=o(":"),MHo=l(),W=a("ul"),rv=a("li"),bFe=a("strong"),EHo=o("bart"),CHo=o(" \u2014 "),ZW=a("a"),wHo=o("BartForCausalLM"),AHo=o(" (BART model)"),LHo=l(),tv=a("li"),vFe=a("strong"),yHo=o("bert"),xHo=o(" \u2014 "),KW=a("a"),$Ho=o("BertLMHeadModel"),kHo=o(" (BERT model)"),SHo=l(),av=a("li"),FFe=a("strong"),RHo=o("bert-generation"),PHo=o(" \u2014 "),eU=a("a"),BHo=o("BertGenerationDecoder"),IHo=o(" (Bert Generation model)"),NHo=l(),nv=a("li"),TFe=a("strong"),qHo=o("big_bird"),jHo=o(" \u2014 "),oU=a("a"),DHo=o("BigBirdForCausalLM"),GHo=o(" (BigBird model)"),OHo=l(),sv=a("li"),MFe=a("strong"),VHo=o("bigbird_pegasus"),XHo=o(" \u2014 "),rU=a("a"),zHo=o("BigBirdPegasusForCausalLM"),QHo=o(" (BigBird-Pegasus model)"),WHo=l(),lv=a("li"),EFe=a("strong"),UHo=o("blenderbot"),HHo=o(" \u2014 "),tU=a("a"),JHo=o("BlenderbotForCausalLM"),YHo=o(" (Blenderbot model)"),ZHo=l(),iv=a("li"),CFe=a("strong"),KHo=o("blenderbot-small"),eJo=o(" \u2014 "),aU=a("a"),oJo=o("BlenderbotSmallForCausalLM"),rJo=o(" (BlenderbotSmall model)"),tJo=l(),dv=a("li"),wFe=a("strong"),aJo=o("bloom"),nJo=o(" \u2014 "),nU=a("a"),sJo=o("BloomForCausalLM"),lJo=o(" (BLOOM model)"),iJo=l(),mv=a("li"),AFe=a("strong"),dJo=o("camembert"),mJo=o(" \u2014 "),sU=a("a"),cJo=o("CamembertForCausalLM"),fJo=o(" (CamemBERT model)"),gJo=l(),cv=a("li"),LFe=a("strong"),hJo=o("codegen"),uJo=o(" \u2014 "),lU=a("a"),pJo=o("CodeGenForCausalLM"),_Jo=o(" (CodeGen model)"),bJo=l(),fv=a("li"),yFe=a("strong"),vJo=o("ctrl"),FJo=o(" \u2014 "),iU=a("a"),TJo=o("CTRLLMHeadModel"),MJo=o(" (CTRL model)"),EJo=l(),gv=a("li"),xFe=a("strong"),CJo=o("data2vec-text"),wJo=o(" \u2014 "),dU=a("a"),AJo=o("Data2VecTextForCausalLM"),LJo=o(" (Data2VecText model)"),yJo=l(),hv=a("li"),$Fe=a("strong"),xJo=o("electra"),$Jo=o(" \u2014 "),mU=a("a"),kJo=o("ElectraForCausalLM"),SJo=o(" (ELECTRA model)"),RJo=l(),uv=a("li"),kFe=a("strong"),PJo=o("ernie"),BJo=o(" \u2014 "),cU=a("a"),IJo=o("ErnieForCausalLM"),NJo=o(" (ERNIE model)"),qJo=l(),pv=a("li"),SFe=a("strong"),jJo=o("gpt2"),DJo=o(" \u2014 "),fU=a("a"),GJo=o("GPT2LMHeadModel"),OJo=o(" (OpenAI GPT-2 model)"),VJo=l(),_v=a("li"),RFe=a("strong"),XJo=o("gpt_neo"),zJo=o(" \u2014 "),gU=a("a"),QJo=o("GPTNeoForCausalLM"),WJo=o(" (GPT Neo model)"),UJo=l(),bv=a("li"),PFe=a("strong"),HJo=o("gpt_neox"),JJo=o(" \u2014 "),hU=a("a"),YJo=o("GPTNeoXForCausalLM"),ZJo=o(" (GPT NeoX model)"),KJo=l(),vv=a("li"),BFe=a("strong"),eYo=o("gpt_neox_japanese"),oYo=o(" \u2014 "),uU=a("a"),rYo=o("GPTNeoXJapaneseForCausalLM"),tYo=o(" (GPT NeoX Japanese model)"),aYo=l(),Fv=a("li"),IFe=a("strong"),nYo=o("gptj"),sYo=o(" \u2014 "),pU=a("a"),lYo=o("GPTJForCausalLM"),iYo=o(" (GPT-J model)"),dYo=l(),Tv=a("li"),NFe=a("strong"),mYo=o("marian"),cYo=o(" \u2014 "),_U=a("a"),fYo=o("MarianForCausalLM"),gYo=o(" (Marian model)"),hYo=l(),Mv=a("li"),qFe=a("strong"),uYo=o("mbart"),pYo=o(" \u2014 "),bU=a("a"),_Yo=o("MBartForCausalLM"),bYo=o(" (mBART model)"),vYo=l(),Ev=a("li"),jFe=a("strong"),FYo=o("megatron-bert"),TYo=o(" \u2014 "),vU=a("a"),MYo=o("MegatronBertForCausalLM"),EYo=o(" (Megatron-BERT model)"),CYo=l(),Cv=a("li"),DFe=a("strong"),wYo=o("mvp"),AYo=o(" \u2014 "),FU=a("a"),LYo=o("MvpForCausalLM"),yYo=o(" (MVP model)"),xYo=l(),wv=a("li"),GFe=a("strong"),$Yo=o("openai-gpt"),kYo=o(" \u2014 "),TU=a("a"),SYo=o("OpenAIGPTLMHeadModel"),RYo=o(" (OpenAI GPT model)"),PYo=l(),Av=a("li"),OFe=a("strong"),BYo=o("opt"),IYo=o(" \u2014 "),MU=a("a"),NYo=o("OPTForCausalLM"),qYo=o(" (OPT model)"),jYo=l(),Lv=a("li"),VFe=a("strong"),DYo=o("pegasus"),GYo=o(" \u2014 "),EU=a("a"),OYo=o("PegasusForCausalLM"),VYo=o(" (Pegasus model)"),XYo=l(),yv=a("li"),XFe=a("strong"),zYo=o("plbart"),QYo=o(" \u2014 "),CU=a("a"),WYo=o("PLBartForCausalLM"),UYo=o(" (PLBart model)"),HYo=l(),xv=a("li"),zFe=a("strong"),JYo=o("prophetnet"),YYo=o(" \u2014 "),wU=a("a"),ZYo=o("ProphetNetForCausalLM"),KYo=o(" (ProphetNet model)"),eZo=l(),$v=a("li"),QFe=a("strong"),oZo=o("qdqbert"),rZo=o(" \u2014 "),AU=a("a"),tZo=o("QDQBertLMHeadModel"),aZo=o(" (QDQBert model)"),nZo=l(),kv=a("li"),WFe=a("strong"),sZo=o("reformer"),lZo=o(" \u2014 "),LU=a("a"),iZo=o("ReformerModelWithLMHead"),dZo=o(" (Reformer model)"),mZo=l(),Sv=a("li"),UFe=a("strong"),cZo=o("rembert"),fZo=o(" \u2014 "),yU=a("a"),gZo=o("RemBertForCausalLM"),hZo=o(" (RemBERT model)"),uZo=l(),Rv=a("li"),HFe=a("strong"),pZo=o("roberta"),_Zo=o(" \u2014 "),xU=a("a"),bZo=o("RobertaForCausalLM"),vZo=o(" (RoBERTa model)"),FZo=l(),Pv=a("li"),JFe=a("strong"),TZo=o("roformer"),MZo=o(" \u2014 "),$U=a("a"),EZo=o("RoFormerForCausalLM"),CZo=o(" (RoFormer model)"),wZo=l(),Bv=a("li"),YFe=a("strong"),AZo=o("speech_to_text_2"),LZo=o(" \u2014 "),kU=a("a"),yZo=o("Speech2Text2ForCausalLM"),xZo=o(" (Speech2Text2 model)"),$Zo=l(),Iv=a("li"),ZFe=a("strong"),kZo=o("transfo-xl"),SZo=o(" \u2014 "),SU=a("a"),RZo=o("TransfoXLLMHeadModel"),PZo=o(" (Transformer-XL model)"),BZo=l(),Nv=a("li"),KFe=a("strong"),IZo=o("trocr"),NZo=o(" \u2014 "),RU=a("a"),qZo=o("TrOCRForCausalLM"),jZo=o(" (TrOCR model)"),DZo=l(),qv=a("li"),eTe=a("strong"),GZo=o("xglm"),OZo=o(" \u2014 "),PU=a("a"),VZo=o("XGLMForCausalLM"),XZo=o(" (XGLM model)"),zZo=l(),jv=a("li"),oTe=a("strong"),QZo=o("xlm"),WZo=o(" \u2014 "),BU=a("a"),UZo=o("XLMWithLMHeadModel"),HZo=o(" (XLM model)"),JZo=l(),Dv=a("li"),rTe=a("strong"),YZo=o("xlm-prophetnet"),ZZo=o(" \u2014 "),IU=a("a"),KZo=o("XLMProphetNetForCausalLM"),eKo=o(" (XLM-ProphetNet model)"),oKo=l(),Gv=a("li"),tTe=a("strong"),rKo=o("xlm-roberta"),tKo=o(" \u2014 "),NU=a("a"),aKo=o("XLMRobertaForCausalLM"),nKo=o(" (XLM-RoBERTa model)"),sKo=l(),Ov=a("li"),aTe=a("strong"),lKo=o("xlm-roberta-xl"),iKo=o(" \u2014 "),qU=a("a"),dKo=o("XLMRobertaXLForCausalLM"),mKo=o(" (XLM-RoBERTa-XL model)"),cKo=l(),Vv=a("li"),nTe=a("strong"),fKo=o("xlnet"),gKo=o(" \u2014 "),jU=a("a"),hKo=o("XLNetLMHeadModel"),uKo=o(" (XLNet model)"),pKo=l(),Xv=a("p"),_Ko=o("The model is set in evaluation mode by default using "),sTe=a("code"),bKo=o("model.eval()"),vKo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),lTe=a("code"),FKo=o("model.train()"),TKo=l(),F(zv.$$.fragment),Xto=l(),Gd=a("h2"),Qv=a("a"),iTe=a("span"),F(J$.$$.fragment),MKo=l(),dTe=a("span"),EKo=o("AutoModelForDepthEstimation"),zto=l(),jo=a("div"),F(Y$.$$.fragment),CKo=l(),Od=a("p"),wKo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a depth estimation head) when created
with the `),DU=a("a"),AKo=o("from_pretrained()"),LKo=o(" class method or the "),GU=a("a"),yKo=o("from_config()"),xKo=o(` class
method.`),$Ko=l(),Z$=a("p"),kKo=o("This class cannot be instantiated directly using "),mTe=a("code"),SKo=o("__init__()"),RKo=o(" (throws an error)."),PKo=l(),wt=a("div"),F(K$.$$.fragment),BKo=l(),cTe=a("p"),IKo=o("Instantiates one of the model classes of the library (with a depth estimation head) from a configuration."),NKo=l(),Vd=a("p"),qKo=o(`Note:
Loading a model from its configuration file does `),fTe=a("strong"),jKo=o("not"),DKo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),OU=a("a"),GKo=o("from_pretrained()"),OKo=o(" to load the model weights."),VKo=l(),F(Wv.$$.fragment),XKo=l(),ro=a("div"),F(ek.$$.fragment),zKo=l(),gTe=a("p"),QKo=o("Instantiate one of the model classes of the library (with a depth estimation head) from a pretrained model."),WKo=l(),dn=a("p"),UKo=o("The model class to instantiate is selected based on the "),hTe=a("code"),HKo=o("model_type"),JKo=o(` property of the config object (either
passed as an argument or loaded from `),uTe=a("code"),YKo=o("pretrained_model_name_or_path"),ZKo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pTe=a("code"),KKo=o("pretrained_model_name_or_path"),eer=o(":"),oer=l(),ok=a("ul"),Uv=a("li"),_Te=a("strong"),rer=o("dpt"),ter=o(" \u2014 "),VU=a("a"),aer=o("DPTForDepthEstimation"),ner=o(" (DPT model)"),ser=l(),Hv=a("li"),bTe=a("strong"),ler=o("glpn"),ier=o(" \u2014 "),XU=a("a"),der=o("GLPNForDepthEstimation"),mer=o(" (GLPN model)"),cer=l(),Jv=a("p"),fer=o("The model is set in evaluation mode by default using "),vTe=a("code"),ger=o("model.eval()"),her=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),FTe=a("code"),uer=o("model.train()"),per=l(),F(Yv.$$.fragment),Qto=l(),Xd=a("h2"),Zv=a("a"),TTe=a("span"),F(rk.$$.fragment),_er=l(),MTe=a("span"),ber=o("AutoModelForMaskedLM"),Wto=l(),Do=a("div"),F(tk.$$.fragment),ver=l(),zd=a("p"),Fer=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),zU=a("a"),Ter=o("from_pretrained()"),Mer=o(" class method or the "),QU=a("a"),Eer=o("from_config()"),Cer=o(` class
method.`),wer=l(),ak=a("p"),Aer=o("This class cannot be instantiated directly using "),ETe=a("code"),Ler=o("__init__()"),yer=o(" (throws an error)."),xer=l(),At=a("div"),F(nk.$$.fragment),$er=l(),CTe=a("p"),ker=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Ser=l(),Qd=a("p"),Rer=o(`Note:
Loading a model from its configuration file does `),wTe=a("strong"),Per=o("not"),Ber=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WU=a("a"),Ier=o("from_pretrained()"),Ner=o(" to load the model weights."),qer=l(),F(Kv.$$.fragment),jer=l(),to=a("div"),F(sk.$$.fragment),Der=l(),ATe=a("p"),Ger=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Oer=l(),mn=a("p"),Ver=o("The model class to instantiate is selected based on the "),LTe=a("code"),Xer=o("model_type"),zer=o(` property of the config object (either
passed as an argument or loaded from `),yTe=a("code"),Qer=o("pretrained_model_name_or_path"),Wer=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xTe=a("code"),Uer=o("pretrained_model_name_or_path"),Her=o(":"),Jer=l(),Y=a("ul"),eF=a("li"),$Te=a("strong"),Yer=o("albert"),Zer=o(" \u2014 "),UU=a("a"),Ker=o("AlbertForMaskedLM"),eor=o(" (ALBERT model)"),oor=l(),oF=a("li"),kTe=a("strong"),ror=o("bart"),tor=o(" \u2014 "),HU=a("a"),aor=o("BartForConditionalGeneration"),nor=o(" (BART model)"),sor=l(),rF=a("li"),STe=a("strong"),lor=o("bert"),ior=o(" \u2014 "),JU=a("a"),dor=o("BertForMaskedLM"),mor=o(" (BERT model)"),cor=l(),tF=a("li"),RTe=a("strong"),gor=o("big_bird"),hor=o(" \u2014 "),YU=a("a"),uor=o("BigBirdForMaskedLM"),por=o(" (BigBird model)"),_or=l(),aF=a("li"),PTe=a("strong"),bor=o("camembert"),vor=o(" \u2014 "),ZU=a("a"),For=o("CamembertForMaskedLM"),Tor=o(" (CamemBERT model)"),Mor=l(),nF=a("li"),BTe=a("strong"),Eor=o("convbert"),Cor=o(" \u2014 "),KU=a("a"),wor=o("ConvBertForMaskedLM"),Aor=o(" (ConvBERT model)"),Lor=l(),sF=a("li"),ITe=a("strong"),yor=o("data2vec-text"),xor=o(" \u2014 "),eH=a("a"),$or=o("Data2VecTextForMaskedLM"),kor=o(" (Data2VecText model)"),Sor=l(),lF=a("li"),NTe=a("strong"),Ror=o("deberta"),Por=o(" \u2014 "),oH=a("a"),Bor=o("DebertaForMaskedLM"),Ior=o(" (DeBERTa model)"),Nor=l(),iF=a("li"),qTe=a("strong"),qor=o("deberta-v2"),jor=o(" \u2014 "),rH=a("a"),Dor=o("DebertaV2ForMaskedLM"),Gor=o(" (DeBERTa-v2 model)"),Oor=l(),dF=a("li"),jTe=a("strong"),Vor=o("distilbert"),Xor=o(" \u2014 "),tH=a("a"),zor=o("DistilBertForMaskedLM"),Qor=o(" (DistilBERT model)"),Wor=l(),mF=a("li"),DTe=a("strong"),Uor=o("electra"),Hor=o(" \u2014 "),aH=a("a"),Jor=o("ElectraForMaskedLM"),Yor=o(" (ELECTRA model)"),Zor=l(),cF=a("li"),GTe=a("strong"),Kor=o("ernie"),err=o(" \u2014 "),nH=a("a"),orr=o("ErnieForMaskedLM"),rrr=o(" (ERNIE model)"),trr=l(),fF=a("li"),OTe=a("strong"),arr=o("flaubert"),nrr=o(" \u2014 "),sH=a("a"),srr=o("FlaubertWithLMHeadModel"),lrr=o(" (FlauBERT model)"),irr=l(),gF=a("li"),VTe=a("strong"),drr=o("fnet"),mrr=o(" \u2014 "),lH=a("a"),crr=o("FNetForMaskedLM"),frr=o(" (FNet model)"),grr=l(),hF=a("li"),XTe=a("strong"),hrr=o("funnel"),urr=o(" \u2014 "),iH=a("a"),prr=o("FunnelForMaskedLM"),_rr=o(" (Funnel Transformer model)"),brr=l(),uF=a("li"),zTe=a("strong"),vrr=o("ibert"),Frr=o(" \u2014 "),dH=a("a"),Trr=o("IBertForMaskedLM"),Mrr=o(" (I-BERT model)"),Err=l(),pF=a("li"),QTe=a("strong"),Crr=o("layoutlm"),wrr=o(" \u2014 "),mH=a("a"),Arr=o("LayoutLMForMaskedLM"),Lrr=o(" (LayoutLM model)"),yrr=l(),_F=a("li"),WTe=a("strong"),xrr=o("longformer"),$rr=o(" \u2014 "),cH=a("a"),krr=o("LongformerForMaskedLM"),Srr=o(" (Longformer model)"),Rrr=l(),bF=a("li"),UTe=a("strong"),Prr=o("luke"),Brr=o(" \u2014 "),fH=a("a"),Irr=o("LukeForMaskedLM"),Nrr=o(" (LUKE model)"),qrr=l(),vF=a("li"),HTe=a("strong"),jrr=o("mbart"),Drr=o(" \u2014 "),gH=a("a"),Grr=o("MBartForConditionalGeneration"),Orr=o(" (mBART model)"),Vrr=l(),FF=a("li"),JTe=a("strong"),Xrr=o("megatron-bert"),zrr=o(" \u2014 "),hH=a("a"),Qrr=o("MegatronBertForMaskedLM"),Wrr=o(" (Megatron-BERT model)"),Urr=l(),TF=a("li"),YTe=a("strong"),Hrr=o("mobilebert"),Jrr=o(" \u2014 "),uH=a("a"),Yrr=o("MobileBertForMaskedLM"),Zrr=o(" (MobileBERT model)"),Krr=l(),MF=a("li"),ZTe=a("strong"),etr=o("mpnet"),otr=o(" \u2014 "),pH=a("a"),rtr=o("MPNetForMaskedLM"),ttr=o(" (MPNet model)"),atr=l(),EF=a("li"),KTe=a("strong"),ntr=o("mvp"),str=o(" \u2014 "),_H=a("a"),ltr=o("MvpForConditionalGeneration"),itr=o(" (MVP model)"),dtr=l(),CF=a("li"),eMe=a("strong"),mtr=o("nezha"),ctr=o(" \u2014 "),bH=a("a"),ftr=o("NezhaForMaskedLM"),gtr=o(" (Nezha model)"),htr=l(),wF=a("li"),oMe=a("strong"),utr=o("nystromformer"),ptr=o(" \u2014 "),vH=a("a"),_tr=o("NystromformerForMaskedLM"),btr=o(" (Nystr\xF6mformer model)"),vtr=l(),AF=a("li"),rMe=a("strong"),Ftr=o("perceiver"),Ttr=o(" \u2014 "),FH=a("a"),Mtr=o("PerceiverForMaskedLM"),Etr=o(" (Perceiver model)"),Ctr=l(),LF=a("li"),tMe=a("strong"),wtr=o("qdqbert"),Atr=o(" \u2014 "),TH=a("a"),Ltr=o("QDQBertForMaskedLM"),ytr=o(" (QDQBert model)"),xtr=l(),yF=a("li"),aMe=a("strong"),$tr=o("reformer"),ktr=o(" \u2014 "),MH=a("a"),Str=o("ReformerForMaskedLM"),Rtr=o(" (Reformer model)"),Ptr=l(),xF=a("li"),nMe=a("strong"),Btr=o("rembert"),Itr=o(" \u2014 "),EH=a("a"),Ntr=o("RemBertForMaskedLM"),qtr=o(" (RemBERT model)"),jtr=l(),$F=a("li"),sMe=a("strong"),Dtr=o("roberta"),Gtr=o(" \u2014 "),CH=a("a"),Otr=o("RobertaForMaskedLM"),Vtr=o(" (RoBERTa model)"),Xtr=l(),kF=a("li"),lMe=a("strong"),ztr=o("roformer"),Qtr=o(" \u2014 "),wH=a("a"),Wtr=o("RoFormerForMaskedLM"),Utr=o(" (RoFormer model)"),Htr=l(),SF=a("li"),iMe=a("strong"),Jtr=o("squeezebert"),Ytr=o(" \u2014 "),AH=a("a"),Ztr=o("SqueezeBertForMaskedLM"),Ktr=o(" (SqueezeBERT model)"),ear=l(),RF=a("li"),dMe=a("strong"),oar=o("tapas"),rar=o(" \u2014 "),LH=a("a"),tar=o("TapasForMaskedLM"),aar=o(" (TAPAS model)"),nar=l(),PF=a("li"),mMe=a("strong"),sar=o("wav2vec2"),lar=o(" \u2014 "),cMe=a("code"),iar=o("Wav2Vec2ForMaskedLM"),dar=o(" (Wav2Vec2 model)"),mar=l(),BF=a("li"),fMe=a("strong"),car=o("xlm"),far=o(" \u2014 "),yH=a("a"),gar=o("XLMWithLMHeadModel"),har=o(" (XLM model)"),uar=l(),IF=a("li"),gMe=a("strong"),par=o("xlm-roberta"),_ar=o(" \u2014 "),xH=a("a"),bar=o("XLMRobertaForMaskedLM"),Far=o(" (XLM-RoBERTa model)"),Tar=l(),NF=a("li"),hMe=a("strong"),Mar=o("xlm-roberta-xl"),Ear=o(" \u2014 "),$H=a("a"),Car=o("XLMRobertaXLForMaskedLM"),war=o(" (XLM-RoBERTa-XL model)"),Aar=l(),qF=a("li"),uMe=a("strong"),Lar=o("yoso"),yar=o(" \u2014 "),kH=a("a"),xar=o("YosoForMaskedLM"),$ar=o(" (YOSO model)"),kar=l(),jF=a("p"),Sar=o("The model is set in evaluation mode by default using "),pMe=a("code"),Rar=o("model.eval()"),Par=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_Me=a("code"),Bar=o("model.train()"),Iar=l(),F(DF.$$.fragment),Uto=l(),Wd=a("h2"),GF=a("a"),bMe=a("span"),F(lk.$$.fragment),Nar=l(),vMe=a("span"),qar=o("AutoModelForSeq2SeqLM"),Hto=l(),Go=a("div"),F(ik.$$.fragment),jar=l(),Ud=a("p"),Dar=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),SH=a("a"),Gar=o("from_pretrained()"),Oar=o(" class method or the "),RH=a("a"),Var=o("from_config()"),Xar=o(` class
method.`),zar=l(),dk=a("p"),Qar=o("This class cannot be instantiated directly using "),FMe=a("code"),War=o("__init__()"),Uar=o(" (throws an error)."),Har=l(),Lt=a("div"),F(mk.$$.fragment),Jar=l(),TMe=a("p"),Yar=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Zar=l(),Hd=a("p"),Kar=o(`Note:
Loading a model from its configuration file does `),MMe=a("strong"),enr=o("not"),onr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),PH=a("a"),rnr=o("from_pretrained()"),tnr=o(" to load the model weights."),anr=l(),F(OF.$$.fragment),nnr=l(),ao=a("div"),F(ck.$$.fragment),snr=l(),EMe=a("p"),lnr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),inr=l(),cn=a("p"),dnr=o("The model class to instantiate is selected based on the "),CMe=a("code"),mnr=o("model_type"),cnr=o(` property of the config object (either
passed as an argument or loaded from `),wMe=a("code"),fnr=o("pretrained_model_name_or_path"),gnr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),AMe=a("code"),hnr=o("pretrained_model_name_or_path"),unr=o(":"),pnr=l(),he=a("ul"),VF=a("li"),LMe=a("strong"),_nr=o("bart"),bnr=o(" \u2014 "),BH=a("a"),vnr=o("BartForConditionalGeneration"),Fnr=o(" (BART model)"),Tnr=l(),XF=a("li"),yMe=a("strong"),Mnr=o("bigbird_pegasus"),Enr=o(" \u2014 "),IH=a("a"),Cnr=o("BigBirdPegasusForConditionalGeneration"),wnr=o(" (BigBird-Pegasus model)"),Anr=l(),zF=a("li"),xMe=a("strong"),Lnr=o("blenderbot"),ynr=o(" \u2014 "),NH=a("a"),xnr=o("BlenderbotForConditionalGeneration"),$nr=o(" (Blenderbot model)"),knr=l(),QF=a("li"),$Me=a("strong"),Snr=o("blenderbot-small"),Rnr=o(" \u2014 "),qH=a("a"),Pnr=o("BlenderbotSmallForConditionalGeneration"),Bnr=o(" (BlenderbotSmall model)"),Inr=l(),WF=a("li"),kMe=a("strong"),Nnr=o("encoder-decoder"),qnr=o(" \u2014 "),jH=a("a"),jnr=o("EncoderDecoderModel"),Dnr=o(" (Encoder decoder model)"),Gnr=l(),UF=a("li"),SMe=a("strong"),Onr=o("fsmt"),Vnr=o(" \u2014 "),DH=a("a"),Xnr=o("FSMTForConditionalGeneration"),znr=o(" (FairSeq Machine-Translation model)"),Qnr=l(),HF=a("li"),RMe=a("strong"),Wnr=o("led"),Unr=o(" \u2014 "),GH=a("a"),Hnr=o("LEDForConditionalGeneration"),Jnr=o(" (LED model)"),Ynr=l(),JF=a("li"),PMe=a("strong"),Znr=o("longt5"),Knr=o(" \u2014 "),OH=a("a"),esr=o("LongT5ForConditionalGeneration"),osr=o(" (LongT5 model)"),rsr=l(),YF=a("li"),BMe=a("strong"),tsr=o("m2m_100"),asr=o(" \u2014 "),VH=a("a"),nsr=o("M2M100ForConditionalGeneration"),ssr=o(" (M2M100 model)"),lsr=l(),ZF=a("li"),IMe=a("strong"),isr=o("marian"),dsr=o(" \u2014 "),XH=a("a"),msr=o("MarianMTModel"),csr=o(" (Marian model)"),fsr=l(),KF=a("li"),NMe=a("strong"),gsr=o("mbart"),hsr=o(" \u2014 "),zH=a("a"),usr=o("MBartForConditionalGeneration"),psr=o(" (mBART model)"),_sr=l(),eT=a("li"),qMe=a("strong"),bsr=o("mt5"),vsr=o(" \u2014 "),QH=a("a"),Fsr=o("MT5ForConditionalGeneration"),Tsr=o(" (MT5 model)"),Msr=l(),oT=a("li"),jMe=a("strong"),Esr=o("mvp"),Csr=o(" \u2014 "),WH=a("a"),wsr=o("MvpForConditionalGeneration"),Asr=o(" (MVP model)"),Lsr=l(),rT=a("li"),DMe=a("strong"),ysr=o("nllb"),xsr=o(" \u2014 "),UH=a("a"),$sr=o("M2M100ForConditionalGeneration"),ksr=o(" (NLLB model)"),Ssr=l(),tT=a("li"),GMe=a("strong"),Rsr=o("pegasus"),Psr=o(" \u2014 "),HH=a("a"),Bsr=o("PegasusForConditionalGeneration"),Isr=o(" (Pegasus model)"),Nsr=l(),aT=a("li"),OMe=a("strong"),qsr=o("pegasus_x"),jsr=o(" \u2014 "),JH=a("a"),Dsr=o("PegasusXForConditionalGeneration"),Gsr=o(" (PEGASUS-X model)"),Osr=l(),nT=a("li"),VMe=a("strong"),Vsr=o("plbart"),Xsr=o(" \u2014 "),YH=a("a"),zsr=o("PLBartForConditionalGeneration"),Qsr=o(" (PLBart model)"),Wsr=l(),sT=a("li"),XMe=a("strong"),Usr=o("prophetnet"),Hsr=o(" \u2014 "),ZH=a("a"),Jsr=o("ProphetNetForConditionalGeneration"),Ysr=o(" (ProphetNet model)"),Zsr=l(),lT=a("li"),zMe=a("strong"),Ksr=o("t5"),elr=o(" \u2014 "),KH=a("a"),olr=o("T5ForConditionalGeneration"),rlr=o(" (T5 model)"),tlr=l(),iT=a("li"),QMe=a("strong"),alr=o("xlm-prophetnet"),nlr=o(" \u2014 "),eJ=a("a"),slr=o("XLMProphetNetForConditionalGeneration"),llr=o(" (XLM-ProphetNet model)"),ilr=l(),dT=a("p"),dlr=o("The model is set in evaluation mode by default using "),WMe=a("code"),mlr=o("model.eval()"),clr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),UMe=a("code"),flr=o("model.train()"),glr=l(),F(mT.$$.fragment),Jto=l(),Jd=a("h2"),cT=a("a"),HMe=a("span"),F(fk.$$.fragment),hlr=l(),JMe=a("span"),ulr=o("AutoModelForSequenceClassification"),Yto=l(),Oo=a("div"),F(gk.$$.fragment),plr=l(),Yd=a("p"),_lr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),oJ=a("a"),blr=o("from_pretrained()"),vlr=o(" class method or the "),rJ=a("a"),Flr=o("from_config()"),Tlr=o(` class
method.`),Mlr=l(),hk=a("p"),Elr=o("This class cannot be instantiated directly using "),YMe=a("code"),Clr=o("__init__()"),wlr=o(" (throws an error)."),Alr=l(),yt=a("div"),F(uk.$$.fragment),Llr=l(),ZMe=a("p"),ylr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),xlr=l(),Zd=a("p"),$lr=o(`Note:
Loading a model from its configuration file does `),KMe=a("strong"),klr=o("not"),Slr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tJ=a("a"),Rlr=o("from_pretrained()"),Plr=o(" to load the model weights."),Blr=l(),F(fT.$$.fragment),Ilr=l(),no=a("div"),F(pk.$$.fragment),Nlr=l(),eEe=a("p"),qlr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),jlr=l(),fn=a("p"),Dlr=o("The model class to instantiate is selected based on the "),oEe=a("code"),Glr=o("model_type"),Olr=o(` property of the config object (either
passed as an argument or loaded from `),rEe=a("code"),Vlr=o("pretrained_model_name_or_path"),Xlr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tEe=a("code"),zlr=o("pretrained_model_name_or_path"),Qlr=o(":"),Wlr=l(),j=a("ul"),gT=a("li"),aEe=a("strong"),Ulr=o("albert"),Hlr=o(" \u2014 "),aJ=a("a"),Jlr=o("AlbertForSequenceClassification"),Ylr=o(" (ALBERT model)"),Zlr=l(),hT=a("li"),nEe=a("strong"),Klr=o("bart"),eir=o(" \u2014 "),nJ=a("a"),oir=o("BartForSequenceClassification"),rir=o(" (BART model)"),tir=l(),uT=a("li"),sEe=a("strong"),air=o("bert"),nir=o(" \u2014 "),sJ=a("a"),sir=o("BertForSequenceClassification"),lir=o(" (BERT model)"),iir=l(),pT=a("li"),lEe=a("strong"),dir=o("big_bird"),mir=o(" \u2014 "),lJ=a("a"),cir=o("BigBirdForSequenceClassification"),fir=o(" (BigBird model)"),gir=l(),_T=a("li"),iEe=a("strong"),hir=o("bigbird_pegasus"),uir=o(" \u2014 "),iJ=a("a"),pir=o("BigBirdPegasusForSequenceClassification"),_ir=o(" (BigBird-Pegasus model)"),bir=l(),bT=a("li"),dEe=a("strong"),vir=o("bloom"),Fir=o(" \u2014 "),dJ=a("a"),Tir=o("BloomForSequenceClassification"),Mir=o(" (BLOOM model)"),Eir=l(),vT=a("li"),mEe=a("strong"),Cir=o("camembert"),wir=o(" \u2014 "),mJ=a("a"),Air=o("CamembertForSequenceClassification"),Lir=o(" (CamemBERT model)"),yir=l(),FT=a("li"),cEe=a("strong"),xir=o("canine"),$ir=o(" \u2014 "),cJ=a("a"),kir=o("CanineForSequenceClassification"),Sir=o(" (CANINE model)"),Rir=l(),TT=a("li"),fEe=a("strong"),Pir=o("convbert"),Bir=o(" \u2014 "),fJ=a("a"),Iir=o("ConvBertForSequenceClassification"),Nir=o(" (ConvBERT model)"),qir=l(),MT=a("li"),gEe=a("strong"),jir=o("ctrl"),Dir=o(" \u2014 "),gJ=a("a"),Gir=o("CTRLForSequenceClassification"),Oir=o(" (CTRL model)"),Vir=l(),ET=a("li"),hEe=a("strong"),Xir=o("data2vec-text"),zir=o(" \u2014 "),hJ=a("a"),Qir=o("Data2VecTextForSequenceClassification"),Wir=o(" (Data2VecText model)"),Uir=l(),CT=a("li"),uEe=a("strong"),Hir=o("deberta"),Jir=o(" \u2014 "),uJ=a("a"),Yir=o("DebertaForSequenceClassification"),Zir=o(" (DeBERTa model)"),Kir=l(),wT=a("li"),pEe=a("strong"),edr=o("deberta-v2"),odr=o(" \u2014 "),pJ=a("a"),rdr=o("DebertaV2ForSequenceClassification"),tdr=o(" (DeBERTa-v2 model)"),adr=l(),AT=a("li"),_Ee=a("strong"),ndr=o("distilbert"),sdr=o(" \u2014 "),_J=a("a"),ldr=o("DistilBertForSequenceClassification"),idr=o(" (DistilBERT model)"),ddr=l(),LT=a("li"),bEe=a("strong"),mdr=o("electra"),cdr=o(" \u2014 "),bJ=a("a"),fdr=o("ElectraForSequenceClassification"),gdr=o(" (ELECTRA model)"),hdr=l(),yT=a("li"),vEe=a("strong"),udr=o("ernie"),pdr=o(" \u2014 "),vJ=a("a"),_dr=o("ErnieForSequenceClassification"),bdr=o(" (ERNIE model)"),vdr=l(),xT=a("li"),FEe=a("strong"),Fdr=o("esm"),Tdr=o(" \u2014 "),FJ=a("a"),Mdr=o("EsmForSequenceClassification"),Edr=o(" (ESM model)"),Cdr=l(),$T=a("li"),TEe=a("strong"),wdr=o("flaubert"),Adr=o(" \u2014 "),TJ=a("a"),Ldr=o("FlaubertForSequenceClassification"),ydr=o(" (FlauBERT model)"),xdr=l(),kT=a("li"),MEe=a("strong"),$dr=o("fnet"),kdr=o(" \u2014 "),MJ=a("a"),Sdr=o("FNetForSequenceClassification"),Rdr=o(" (FNet model)"),Pdr=l(),ST=a("li"),EEe=a("strong"),Bdr=o("funnel"),Idr=o(" \u2014 "),EJ=a("a"),Ndr=o("FunnelForSequenceClassification"),qdr=o(" (Funnel Transformer model)"),jdr=l(),RT=a("li"),CEe=a("strong"),Ddr=o("gpt2"),Gdr=o(" \u2014 "),CJ=a("a"),Odr=o("GPT2ForSequenceClassification"),Vdr=o(" (OpenAI GPT-2 model)"),Xdr=l(),PT=a("li"),wEe=a("strong"),zdr=o("gpt_neo"),Qdr=o(" \u2014 "),wJ=a("a"),Wdr=o("GPTNeoForSequenceClassification"),Udr=o(" (GPT Neo model)"),Hdr=l(),BT=a("li"),AEe=a("strong"),Jdr=o("gptj"),Ydr=o(" \u2014 "),AJ=a("a"),Zdr=o("GPTJForSequenceClassification"),Kdr=o(" (GPT-J model)"),emr=l(),IT=a("li"),LEe=a("strong"),omr=o("ibert"),rmr=o(" \u2014 "),LJ=a("a"),tmr=o("IBertForSequenceClassification"),amr=o(" (I-BERT model)"),nmr=l(),NT=a("li"),yEe=a("strong"),smr=o("layoutlm"),lmr=o(" \u2014 "),yJ=a("a"),imr=o("LayoutLMForSequenceClassification"),dmr=o(" (LayoutLM model)"),mmr=l(),qT=a("li"),xEe=a("strong"),cmr=o("layoutlmv2"),fmr=o(" \u2014 "),xJ=a("a"),gmr=o("LayoutLMv2ForSequenceClassification"),hmr=o(" (LayoutLMv2 model)"),umr=l(),jT=a("li"),$Ee=a("strong"),pmr=o("layoutlmv3"),_mr=o(" \u2014 "),$J=a("a"),bmr=o("LayoutLMv3ForSequenceClassification"),vmr=o(" (LayoutLMv3 model)"),Fmr=l(),DT=a("li"),kEe=a("strong"),Tmr=o("led"),Mmr=o(" \u2014 "),kJ=a("a"),Emr=o("LEDForSequenceClassification"),Cmr=o(" (LED model)"),wmr=l(),GT=a("li"),SEe=a("strong"),Amr=o("lilt"),Lmr=o(" \u2014 "),SJ=a("a"),ymr=o("LiltForSequenceClassification"),xmr=o(" (LiLT model)"),$mr=l(),OT=a("li"),REe=a("strong"),kmr=o("longformer"),Smr=o(" \u2014 "),RJ=a("a"),Rmr=o("LongformerForSequenceClassification"),Pmr=o(" (Longformer model)"),Bmr=l(),VT=a("li"),PEe=a("strong"),Imr=o("luke"),Nmr=o(" \u2014 "),PJ=a("a"),qmr=o("LukeForSequenceClassification"),jmr=o(" (LUKE model)"),Dmr=l(),XT=a("li"),BEe=a("strong"),Gmr=o("markuplm"),Omr=o(" \u2014 "),BJ=a("a"),Vmr=o("MarkupLMForSequenceClassification"),Xmr=o(" (MarkupLM model)"),zmr=l(),zT=a("li"),IEe=a("strong"),Qmr=o("mbart"),Wmr=o(" \u2014 "),IJ=a("a"),Umr=o("MBartForSequenceClassification"),Hmr=o(" (mBART model)"),Jmr=l(),QT=a("li"),NEe=a("strong"),Ymr=o("megatron-bert"),Zmr=o(" \u2014 "),NJ=a("a"),Kmr=o("MegatronBertForSequenceClassification"),ecr=o(" (Megatron-BERT model)"),ocr=l(),WT=a("li"),qEe=a("strong"),rcr=o("mobilebert"),tcr=o(" \u2014 "),qJ=a("a"),acr=o("MobileBertForSequenceClassification"),ncr=o(" (MobileBERT model)"),scr=l(),UT=a("li"),jEe=a("strong"),lcr=o("mpnet"),icr=o(" \u2014 "),jJ=a("a"),dcr=o("MPNetForSequenceClassification"),mcr=o(" (MPNet model)"),ccr=l(),HT=a("li"),DEe=a("strong"),fcr=o("mvp"),gcr=o(" \u2014 "),DJ=a("a"),hcr=o("MvpForSequenceClassification"),ucr=o(" (MVP model)"),pcr=l(),JT=a("li"),GEe=a("strong"),_cr=o("nezha"),bcr=o(" \u2014 "),GJ=a("a"),vcr=o("NezhaForSequenceClassification"),Fcr=o(" (Nezha model)"),Tcr=l(),YT=a("li"),OEe=a("strong"),Mcr=o("nystromformer"),Ecr=o(" \u2014 "),OJ=a("a"),Ccr=o("NystromformerForSequenceClassification"),wcr=o(" (Nystr\xF6mformer model)"),Acr=l(),ZT=a("li"),VEe=a("strong"),Lcr=o("openai-gpt"),ycr=o(" \u2014 "),VJ=a("a"),xcr=o("OpenAIGPTForSequenceClassification"),$cr=o(" (OpenAI GPT model)"),kcr=l(),KT=a("li"),XEe=a("strong"),Scr=o("opt"),Rcr=o(" \u2014 "),XJ=a("a"),Pcr=o("OPTForSequenceClassification"),Bcr=o(" (OPT model)"),Icr=l(),eM=a("li"),zEe=a("strong"),Ncr=o("perceiver"),qcr=o(" \u2014 "),zJ=a("a"),jcr=o("PerceiverForSequenceClassification"),Dcr=o(" (Perceiver model)"),Gcr=l(),oM=a("li"),QEe=a("strong"),Ocr=o("plbart"),Vcr=o(" \u2014 "),QJ=a("a"),Xcr=o("PLBartForSequenceClassification"),zcr=o(" (PLBart model)"),Qcr=l(),rM=a("li"),WEe=a("strong"),Wcr=o("qdqbert"),Ucr=o(" \u2014 "),WJ=a("a"),Hcr=o("QDQBertForSequenceClassification"),Jcr=o(" (QDQBert model)"),Ycr=l(),tM=a("li"),UEe=a("strong"),Zcr=o("reformer"),Kcr=o(" \u2014 "),UJ=a("a"),efr=o("ReformerForSequenceClassification"),ofr=o(" (Reformer model)"),rfr=l(),aM=a("li"),HEe=a("strong"),tfr=o("rembert"),afr=o(" \u2014 "),HJ=a("a"),nfr=o("RemBertForSequenceClassification"),sfr=o(" (RemBERT model)"),lfr=l(),nM=a("li"),JEe=a("strong"),ifr=o("roberta"),dfr=o(" \u2014 "),JJ=a("a"),mfr=o("RobertaForSequenceClassification"),cfr=o(" (RoBERTa model)"),ffr=l(),sM=a("li"),YEe=a("strong"),gfr=o("roformer"),hfr=o(" \u2014 "),YJ=a("a"),ufr=o("RoFormerForSequenceClassification"),pfr=o(" (RoFormer model)"),_fr=l(),lM=a("li"),ZEe=a("strong"),bfr=o("squeezebert"),vfr=o(" \u2014 "),ZJ=a("a"),Ffr=o("SqueezeBertForSequenceClassification"),Tfr=o(" (SqueezeBERT model)"),Mfr=l(),iM=a("li"),KEe=a("strong"),Efr=o("tapas"),Cfr=o(" \u2014 "),KJ=a("a"),wfr=o("TapasForSequenceClassification"),Afr=o(" (TAPAS model)"),Lfr=l(),dM=a("li"),e4e=a("strong"),yfr=o("transfo-xl"),xfr=o(" \u2014 "),eY=a("a"),$fr=o("TransfoXLForSequenceClassification"),kfr=o(" (Transformer-XL model)"),Sfr=l(),mM=a("li"),o4e=a("strong"),Rfr=o("xlm"),Pfr=o(" \u2014 "),oY=a("a"),Bfr=o("XLMForSequenceClassification"),Ifr=o(" (XLM model)"),Nfr=l(),cM=a("li"),r4e=a("strong"),qfr=o("xlm-roberta"),jfr=o(" \u2014 "),rY=a("a"),Dfr=o("XLMRobertaForSequenceClassification"),Gfr=o(" (XLM-RoBERTa model)"),Ofr=l(),fM=a("li"),t4e=a("strong"),Vfr=o("xlm-roberta-xl"),Xfr=o(" \u2014 "),tY=a("a"),zfr=o("XLMRobertaXLForSequenceClassification"),Qfr=o(" (XLM-RoBERTa-XL model)"),Wfr=l(),gM=a("li"),a4e=a("strong"),Ufr=o("xlnet"),Hfr=o(" \u2014 "),aY=a("a"),Jfr=o("XLNetForSequenceClassification"),Yfr=o(" (XLNet model)"),Zfr=l(),hM=a("li"),n4e=a("strong"),Kfr=o("yoso"),egr=o(" \u2014 "),nY=a("a"),ogr=o("YosoForSequenceClassification"),rgr=o(" (YOSO model)"),tgr=l(),uM=a("p"),agr=o("The model is set in evaluation mode by default using "),s4e=a("code"),ngr=o("model.eval()"),sgr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),l4e=a("code"),lgr=o("model.train()"),igr=l(),F(pM.$$.fragment),Zto=l(),Kd=a("h2"),_M=a("a"),i4e=a("span"),F(_k.$$.fragment),dgr=l(),d4e=a("span"),mgr=o("AutoModelForMultipleChoice"),Kto=l(),Vo=a("div"),F(bk.$$.fragment),cgr=l(),em=a("p"),fgr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),sY=a("a"),ggr=o("from_pretrained()"),hgr=o(" class method or the "),lY=a("a"),ugr=o("from_config()"),pgr=o(` class
method.`),_gr=l(),vk=a("p"),bgr=o("This class cannot be instantiated directly using "),m4e=a("code"),vgr=o("__init__()"),Fgr=o(" (throws an error)."),Tgr=l(),xt=a("div"),F(Fk.$$.fragment),Mgr=l(),c4e=a("p"),Egr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Cgr=l(),om=a("p"),wgr=o(`Note:
Loading a model from its configuration file does `),f4e=a("strong"),Agr=o("not"),Lgr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iY=a("a"),ygr=o("from_pretrained()"),xgr=o(" to load the model weights."),$gr=l(),F(bM.$$.fragment),kgr=l(),so=a("div"),F(Tk.$$.fragment),Sgr=l(),g4e=a("p"),Rgr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Pgr=l(),gn=a("p"),Bgr=o("The model class to instantiate is selected based on the "),h4e=a("code"),Igr=o("model_type"),Ngr=o(` property of the config object (either
passed as an argument or loaded from `),u4e=a("code"),qgr=o("pretrained_model_name_or_path"),jgr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p4e=a("code"),Dgr=o("pretrained_model_name_or_path"),Ggr=o(":"),Ogr=l(),K=a("ul"),vM=a("li"),_4e=a("strong"),Vgr=o("albert"),Xgr=o(" \u2014 "),dY=a("a"),zgr=o("AlbertForMultipleChoice"),Qgr=o(" (ALBERT model)"),Wgr=l(),FM=a("li"),b4e=a("strong"),Ugr=o("bert"),Hgr=o(" \u2014 "),mY=a("a"),Jgr=o("BertForMultipleChoice"),Ygr=o(" (BERT model)"),Zgr=l(),TM=a("li"),v4e=a("strong"),Kgr=o("big_bird"),ehr=o(" \u2014 "),cY=a("a"),ohr=o("BigBirdForMultipleChoice"),rhr=o(" (BigBird model)"),thr=l(),MM=a("li"),F4e=a("strong"),ahr=o("camembert"),nhr=o(" \u2014 "),fY=a("a"),shr=o("CamembertForMultipleChoice"),lhr=o(" (CamemBERT model)"),ihr=l(),EM=a("li"),T4e=a("strong"),dhr=o("canine"),mhr=o(" \u2014 "),gY=a("a"),chr=o("CanineForMultipleChoice"),fhr=o(" (CANINE model)"),ghr=l(),CM=a("li"),M4e=a("strong"),hhr=o("convbert"),uhr=o(" \u2014 "),hY=a("a"),phr=o("ConvBertForMultipleChoice"),_hr=o(" (ConvBERT model)"),bhr=l(),wM=a("li"),E4e=a("strong"),vhr=o("data2vec-text"),Fhr=o(" \u2014 "),uY=a("a"),Thr=o("Data2VecTextForMultipleChoice"),Mhr=o(" (Data2VecText model)"),Ehr=l(),AM=a("li"),C4e=a("strong"),Chr=o("deberta-v2"),whr=o(" \u2014 "),pY=a("a"),Ahr=o("DebertaV2ForMultipleChoice"),Lhr=o(" (DeBERTa-v2 model)"),yhr=l(),LM=a("li"),w4e=a("strong"),xhr=o("distilbert"),$hr=o(" \u2014 "),_Y=a("a"),khr=o("DistilBertForMultipleChoice"),Shr=o(" (DistilBERT model)"),Rhr=l(),yM=a("li"),A4e=a("strong"),Phr=o("electra"),Bhr=o(" \u2014 "),bY=a("a"),Ihr=o("ElectraForMultipleChoice"),Nhr=o(" (ELECTRA model)"),qhr=l(),xM=a("li"),L4e=a("strong"),jhr=o("ernie"),Dhr=o(" \u2014 "),vY=a("a"),Ghr=o("ErnieForMultipleChoice"),Ohr=o(" (ERNIE model)"),Vhr=l(),$M=a("li"),y4e=a("strong"),Xhr=o("flaubert"),zhr=o(" \u2014 "),FY=a("a"),Qhr=o("FlaubertForMultipleChoice"),Whr=o(" (FlauBERT model)"),Uhr=l(),kM=a("li"),x4e=a("strong"),Hhr=o("fnet"),Jhr=o(" \u2014 "),TY=a("a"),Yhr=o("FNetForMultipleChoice"),Zhr=o(" (FNet model)"),Khr=l(),SM=a("li"),$4e=a("strong"),eur=o("funnel"),our=o(" \u2014 "),MY=a("a"),rur=o("FunnelForMultipleChoice"),tur=o(" (Funnel Transformer model)"),aur=l(),RM=a("li"),k4e=a("strong"),nur=o("ibert"),sur=o(" \u2014 "),EY=a("a"),lur=o("IBertForMultipleChoice"),iur=o(" (I-BERT model)"),dur=l(),PM=a("li"),S4e=a("strong"),mur=o("longformer"),cur=o(" \u2014 "),CY=a("a"),fur=o("LongformerForMultipleChoice"),gur=o(" (Longformer model)"),hur=l(),BM=a("li"),R4e=a("strong"),uur=o("luke"),pur=o(" \u2014 "),wY=a("a"),_ur=o("LukeForMultipleChoice"),bur=o(" (LUKE model)"),vur=l(),IM=a("li"),P4e=a("strong"),Fur=o("megatron-bert"),Tur=o(" \u2014 "),AY=a("a"),Mur=o("MegatronBertForMultipleChoice"),Eur=o(" (Megatron-BERT model)"),Cur=l(),NM=a("li"),B4e=a("strong"),wur=o("mobilebert"),Aur=o(" \u2014 "),LY=a("a"),Lur=o("MobileBertForMultipleChoice"),yur=o(" (MobileBERT model)"),xur=l(),qM=a("li"),I4e=a("strong"),$ur=o("mpnet"),kur=o(" \u2014 "),yY=a("a"),Sur=o("MPNetForMultipleChoice"),Rur=o(" (MPNet model)"),Pur=l(),jM=a("li"),N4e=a("strong"),Bur=o("nezha"),Iur=o(" \u2014 "),xY=a("a"),Nur=o("NezhaForMultipleChoice"),qur=o(" (Nezha model)"),jur=l(),DM=a("li"),q4e=a("strong"),Dur=o("nystromformer"),Gur=o(" \u2014 "),$Y=a("a"),Our=o("NystromformerForMultipleChoice"),Vur=o(" (Nystr\xF6mformer model)"),Xur=l(),GM=a("li"),j4e=a("strong"),zur=o("qdqbert"),Qur=o(" \u2014 "),kY=a("a"),Wur=o("QDQBertForMultipleChoice"),Uur=o(" (QDQBert model)"),Hur=l(),OM=a("li"),D4e=a("strong"),Jur=o("rembert"),Yur=o(" \u2014 "),SY=a("a"),Zur=o("RemBertForMultipleChoice"),Kur=o(" (RemBERT model)"),epr=l(),VM=a("li"),G4e=a("strong"),opr=o("roberta"),rpr=o(" \u2014 "),RY=a("a"),tpr=o("RobertaForMultipleChoice"),apr=o(" (RoBERTa model)"),npr=l(),XM=a("li"),O4e=a("strong"),spr=o("roformer"),lpr=o(" \u2014 "),PY=a("a"),ipr=o("RoFormerForMultipleChoice"),dpr=o(" (RoFormer model)"),mpr=l(),zM=a("li"),V4e=a("strong"),cpr=o("squeezebert"),fpr=o(" \u2014 "),BY=a("a"),gpr=o("SqueezeBertForMultipleChoice"),hpr=o(" (SqueezeBERT model)"),upr=l(),QM=a("li"),X4e=a("strong"),ppr=o("xlm"),_pr=o(" \u2014 "),IY=a("a"),bpr=o("XLMForMultipleChoice"),vpr=o(" (XLM model)"),Fpr=l(),WM=a("li"),z4e=a("strong"),Tpr=o("xlm-roberta"),Mpr=o(" \u2014 "),NY=a("a"),Epr=o("XLMRobertaForMultipleChoice"),Cpr=o(" (XLM-RoBERTa model)"),wpr=l(),UM=a("li"),Q4e=a("strong"),Apr=o("xlm-roberta-xl"),Lpr=o(" \u2014 "),qY=a("a"),ypr=o("XLMRobertaXLForMultipleChoice"),xpr=o(" (XLM-RoBERTa-XL model)"),$pr=l(),HM=a("li"),W4e=a("strong"),kpr=o("xlnet"),Spr=o(" \u2014 "),jY=a("a"),Rpr=o("XLNetForMultipleChoice"),Ppr=o(" (XLNet model)"),Bpr=l(),JM=a("li"),U4e=a("strong"),Ipr=o("yoso"),Npr=o(" \u2014 "),DY=a("a"),qpr=o("YosoForMultipleChoice"),jpr=o(" (YOSO model)"),Dpr=l(),YM=a("p"),Gpr=o("The model is set in evaluation mode by default using "),H4e=a("code"),Opr=o("model.eval()"),Vpr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),J4e=a("code"),Xpr=o("model.train()"),zpr=l(),F(ZM.$$.fragment),eao=l(),rm=a("h2"),KM=a("a"),Y4e=a("span"),F(Mk.$$.fragment),Qpr=l(),Z4e=a("span"),Wpr=o("AutoModelForNextSentencePrediction"),oao=l(),Xo=a("div"),F(Ek.$$.fragment),Upr=l(),tm=a("p"),Hpr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),GY=a("a"),Jpr=o("from_pretrained()"),Ypr=o(" class method or the "),OY=a("a"),Zpr=o("from_config()"),Kpr=o(` class
method.`),e_r=l(),Ck=a("p"),o_r=o("This class cannot be instantiated directly using "),K4e=a("code"),r_r=o("__init__()"),t_r=o(" (throws an error)."),a_r=l(),$t=a("div"),F(wk.$$.fragment),n_r=l(),eCe=a("p"),s_r=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),l_r=l(),am=a("p"),i_r=o(`Note:
Loading a model from its configuration file does `),oCe=a("strong"),d_r=o("not"),m_r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VY=a("a"),c_r=o("from_pretrained()"),f_r=o(" to load the model weights."),g_r=l(),F(eE.$$.fragment),h_r=l(),lo=a("div"),F(Ak.$$.fragment),u_r=l(),rCe=a("p"),p_r=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),__r=l(),hn=a("p"),b_r=o("The model class to instantiate is selected based on the "),tCe=a("code"),v_r=o("model_type"),F_r=o(` property of the config object (either
passed as an argument or loaded from `),aCe=a("code"),T_r=o("pretrained_model_name_or_path"),M_r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nCe=a("code"),E_r=o("pretrained_model_name_or_path"),C_r=o(":"),w_r=l(),Ue=a("ul"),oE=a("li"),sCe=a("strong"),A_r=o("bert"),L_r=o(" \u2014 "),XY=a("a"),y_r=o("BertForNextSentencePrediction"),x_r=o(" (BERT model)"),$_r=l(),rE=a("li"),lCe=a("strong"),k_r=o("ernie"),S_r=o(" \u2014 "),zY=a("a"),R_r=o("ErnieForNextSentencePrediction"),P_r=o(" (ERNIE model)"),B_r=l(),tE=a("li"),iCe=a("strong"),I_r=o("fnet"),N_r=o(" \u2014 "),QY=a("a"),q_r=o("FNetForNextSentencePrediction"),j_r=o(" (FNet model)"),D_r=l(),aE=a("li"),dCe=a("strong"),G_r=o("megatron-bert"),O_r=o(" \u2014 "),WY=a("a"),V_r=o("MegatronBertForNextSentencePrediction"),X_r=o(" (Megatron-BERT model)"),z_r=l(),nE=a("li"),mCe=a("strong"),Q_r=o("mobilebert"),W_r=o(" \u2014 "),UY=a("a"),U_r=o("MobileBertForNextSentencePrediction"),H_r=o(" (MobileBERT model)"),J_r=l(),sE=a("li"),cCe=a("strong"),Y_r=o("nezha"),Z_r=o(" \u2014 "),HY=a("a"),K_r=o("NezhaForNextSentencePrediction"),e1r=o(" (Nezha model)"),o1r=l(),lE=a("li"),fCe=a("strong"),r1r=o("qdqbert"),t1r=o(" \u2014 "),JY=a("a"),a1r=o("QDQBertForNextSentencePrediction"),n1r=o(" (QDQBert model)"),s1r=l(),iE=a("p"),l1r=o("The model is set in evaluation mode by default using "),gCe=a("code"),i1r=o("model.eval()"),d1r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),hCe=a("code"),m1r=o("model.train()"),c1r=l(),F(dE.$$.fragment),rao=l(),nm=a("h2"),mE=a("a"),uCe=a("span"),F(Lk.$$.fragment),f1r=l(),pCe=a("span"),g1r=o("AutoModelForTokenClassification"),tao=l(),zo=a("div"),F(yk.$$.fragment),h1r=l(),sm=a("p"),u1r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),YY=a("a"),p1r=o("from_pretrained()"),_1r=o(" class method or the "),ZY=a("a"),b1r=o("from_config()"),v1r=o(` class
method.`),F1r=l(),xk=a("p"),T1r=o("This class cannot be instantiated directly using "),_Ce=a("code"),M1r=o("__init__()"),E1r=o(" (throws an error)."),C1r=l(),kt=a("div"),F($k.$$.fragment),w1r=l(),bCe=a("p"),A1r=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),L1r=l(),lm=a("p"),y1r=o(`Note:
Loading a model from its configuration file does `),vCe=a("strong"),x1r=o("not"),$1r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),KY=a("a"),k1r=o("from_pretrained()"),S1r=o(" to load the model weights."),R1r=l(),F(cE.$$.fragment),P1r=l(),io=a("div"),F(kk.$$.fragment),B1r=l(),FCe=a("p"),I1r=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),N1r=l(),un=a("p"),q1r=o("The model class to instantiate is selected based on the "),TCe=a("code"),j1r=o("model_type"),D1r=o(` property of the config object (either
passed as an argument or loaded from `),MCe=a("code"),G1r=o("pretrained_model_name_or_path"),O1r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ECe=a("code"),V1r=o("pretrained_model_name_or_path"),X1r=o(":"),z1r=l(),U=a("ul"),fE=a("li"),CCe=a("strong"),Q1r=o("albert"),W1r=o(" \u2014 "),eZ=a("a"),U1r=o("AlbertForTokenClassification"),H1r=o(" (ALBERT model)"),J1r=l(),gE=a("li"),wCe=a("strong"),Y1r=o("bert"),Z1r=o(" \u2014 "),oZ=a("a"),K1r=o("BertForTokenClassification"),e2r=o(" (BERT model)"),o2r=l(),hE=a("li"),ACe=a("strong"),r2r=o("big_bird"),t2r=o(" \u2014 "),rZ=a("a"),a2r=o("BigBirdForTokenClassification"),n2r=o(" (BigBird model)"),s2r=l(),uE=a("li"),LCe=a("strong"),l2r=o("bloom"),i2r=o(" \u2014 "),tZ=a("a"),d2r=o("BloomForTokenClassification"),m2r=o(" (BLOOM model)"),c2r=l(),pE=a("li"),yCe=a("strong"),f2r=o("camembert"),g2r=o(" \u2014 "),aZ=a("a"),h2r=o("CamembertForTokenClassification"),u2r=o(" (CamemBERT model)"),p2r=l(),_E=a("li"),xCe=a("strong"),_2r=o("canine"),b2r=o(" \u2014 "),nZ=a("a"),v2r=o("CanineForTokenClassification"),F2r=o(" (CANINE model)"),T2r=l(),bE=a("li"),$Ce=a("strong"),M2r=o("convbert"),E2r=o(" \u2014 "),sZ=a("a"),C2r=o("ConvBertForTokenClassification"),w2r=o(" (ConvBERT model)"),A2r=l(),vE=a("li"),kCe=a("strong"),L2r=o("data2vec-text"),y2r=o(" \u2014 "),lZ=a("a"),x2r=o("Data2VecTextForTokenClassification"),$2r=o(" (Data2VecText model)"),k2r=l(),FE=a("li"),SCe=a("strong"),S2r=o("deberta"),R2r=o(" \u2014 "),iZ=a("a"),P2r=o("DebertaForTokenClassification"),B2r=o(" (DeBERTa model)"),I2r=l(),TE=a("li"),RCe=a("strong"),N2r=o("deberta-v2"),q2r=o(" \u2014 "),dZ=a("a"),j2r=o("DebertaV2ForTokenClassification"),D2r=o(" (DeBERTa-v2 model)"),G2r=l(),ME=a("li"),PCe=a("strong"),O2r=o("distilbert"),V2r=o(" \u2014 "),mZ=a("a"),X2r=o("DistilBertForTokenClassification"),z2r=o(" (DistilBERT model)"),Q2r=l(),EE=a("li"),BCe=a("strong"),W2r=o("electra"),U2r=o(" \u2014 "),cZ=a("a"),H2r=o("ElectraForTokenClassification"),J2r=o(" (ELECTRA model)"),Y2r=l(),CE=a("li"),ICe=a("strong"),Z2r=o("ernie"),K2r=o(" \u2014 "),fZ=a("a"),ebr=o("ErnieForTokenClassification"),obr=o(" (ERNIE model)"),rbr=l(),wE=a("li"),NCe=a("strong"),tbr=o("esm"),abr=o(" \u2014 "),gZ=a("a"),nbr=o("EsmForTokenClassification"),sbr=o(" (ESM model)"),lbr=l(),AE=a("li"),qCe=a("strong"),ibr=o("flaubert"),dbr=o(" \u2014 "),hZ=a("a"),mbr=o("FlaubertForTokenClassification"),cbr=o(" (FlauBERT model)"),fbr=l(),LE=a("li"),jCe=a("strong"),gbr=o("fnet"),hbr=o(" \u2014 "),uZ=a("a"),ubr=o("FNetForTokenClassification"),pbr=o(" (FNet model)"),_br=l(),yE=a("li"),DCe=a("strong"),bbr=o("funnel"),vbr=o(" \u2014 "),pZ=a("a"),Fbr=o("FunnelForTokenClassification"),Tbr=o(" (Funnel Transformer model)"),Mbr=l(),xE=a("li"),GCe=a("strong"),Ebr=o("gpt2"),Cbr=o(" \u2014 "),_Z=a("a"),wbr=o("GPT2ForTokenClassification"),Abr=o(" (OpenAI GPT-2 model)"),Lbr=l(),$E=a("li"),OCe=a("strong"),ybr=o("ibert"),xbr=o(" \u2014 "),bZ=a("a"),$br=o("IBertForTokenClassification"),kbr=o(" (I-BERT model)"),Sbr=l(),kE=a("li"),VCe=a("strong"),Rbr=o("layoutlm"),Pbr=o(" \u2014 "),vZ=a("a"),Bbr=o("LayoutLMForTokenClassification"),Ibr=o(" (LayoutLM model)"),Nbr=l(),SE=a("li"),XCe=a("strong"),qbr=o("layoutlmv2"),jbr=o(" \u2014 "),FZ=a("a"),Dbr=o("LayoutLMv2ForTokenClassification"),Gbr=o(" (LayoutLMv2 model)"),Obr=l(),RE=a("li"),zCe=a("strong"),Vbr=o("layoutlmv3"),Xbr=o(" \u2014 "),TZ=a("a"),zbr=o("LayoutLMv3ForTokenClassification"),Qbr=o(" (LayoutLMv3 model)"),Wbr=l(),PE=a("li"),QCe=a("strong"),Ubr=o("lilt"),Hbr=o(" \u2014 "),MZ=a("a"),Jbr=o("LiltForTokenClassification"),Ybr=o(" (LiLT model)"),Zbr=l(),BE=a("li"),WCe=a("strong"),Kbr=o("longformer"),evr=o(" \u2014 "),EZ=a("a"),ovr=o("LongformerForTokenClassification"),rvr=o(" (Longformer model)"),tvr=l(),IE=a("li"),UCe=a("strong"),avr=o("luke"),nvr=o(" \u2014 "),CZ=a("a"),svr=o("LukeForTokenClassification"),lvr=o(" (LUKE model)"),ivr=l(),NE=a("li"),HCe=a("strong"),dvr=o("markuplm"),mvr=o(" \u2014 "),wZ=a("a"),cvr=o("MarkupLMForTokenClassification"),fvr=o(" (MarkupLM model)"),gvr=l(),qE=a("li"),JCe=a("strong"),hvr=o("megatron-bert"),uvr=o(" \u2014 "),AZ=a("a"),pvr=o("MegatronBertForTokenClassification"),_vr=o(" (Megatron-BERT model)"),bvr=l(),jE=a("li"),YCe=a("strong"),vvr=o("mobilebert"),Fvr=o(" \u2014 "),LZ=a("a"),Tvr=o("MobileBertForTokenClassification"),Mvr=o(" (MobileBERT model)"),Evr=l(),DE=a("li"),ZCe=a("strong"),Cvr=o("mpnet"),wvr=o(" \u2014 "),yZ=a("a"),Avr=o("MPNetForTokenClassification"),Lvr=o(" (MPNet model)"),yvr=l(),GE=a("li"),KCe=a("strong"),xvr=o("nezha"),$vr=o(" \u2014 "),xZ=a("a"),kvr=o("NezhaForTokenClassification"),Svr=o(" (Nezha model)"),Rvr=l(),OE=a("li"),e3e=a("strong"),Pvr=o("nystromformer"),Bvr=o(" \u2014 "),$Z=a("a"),Ivr=o("NystromformerForTokenClassification"),Nvr=o(" (Nystr\xF6mformer model)"),qvr=l(),VE=a("li"),o3e=a("strong"),jvr=o("qdqbert"),Dvr=o(" \u2014 "),kZ=a("a"),Gvr=o("QDQBertForTokenClassification"),Ovr=o(" (QDQBert model)"),Vvr=l(),XE=a("li"),r3e=a("strong"),Xvr=o("rembert"),zvr=o(" \u2014 "),SZ=a("a"),Qvr=o("RemBertForTokenClassification"),Wvr=o(" (RemBERT model)"),Uvr=l(),zE=a("li"),t3e=a("strong"),Hvr=o("roberta"),Jvr=o(" \u2014 "),RZ=a("a"),Yvr=o("RobertaForTokenClassification"),Zvr=o(" (RoBERTa model)"),Kvr=l(),QE=a("li"),a3e=a("strong"),eFr=o("roformer"),oFr=o(" \u2014 "),PZ=a("a"),rFr=o("RoFormerForTokenClassification"),tFr=o(" (RoFormer model)"),aFr=l(),WE=a("li"),n3e=a("strong"),nFr=o("squeezebert"),sFr=o(" \u2014 "),BZ=a("a"),lFr=o("SqueezeBertForTokenClassification"),iFr=o(" (SqueezeBERT model)"),dFr=l(),UE=a("li"),s3e=a("strong"),mFr=o("xlm"),cFr=o(" \u2014 "),IZ=a("a"),fFr=o("XLMForTokenClassification"),gFr=o(" (XLM model)"),hFr=l(),HE=a("li"),l3e=a("strong"),uFr=o("xlm-roberta"),pFr=o(" \u2014 "),NZ=a("a"),_Fr=o("XLMRobertaForTokenClassification"),bFr=o(" (XLM-RoBERTa model)"),vFr=l(),JE=a("li"),i3e=a("strong"),FFr=o("xlm-roberta-xl"),TFr=o(" \u2014 "),qZ=a("a"),MFr=o("XLMRobertaXLForTokenClassification"),EFr=o(" (XLM-RoBERTa-XL model)"),CFr=l(),YE=a("li"),d3e=a("strong"),wFr=o("xlnet"),AFr=o(" \u2014 "),jZ=a("a"),LFr=o("XLNetForTokenClassification"),yFr=o(" (XLNet model)"),xFr=l(),ZE=a("li"),m3e=a("strong"),$Fr=o("yoso"),kFr=o(" \u2014 "),DZ=a("a"),SFr=o("YosoForTokenClassification"),RFr=o(" (YOSO model)"),PFr=l(),KE=a("p"),BFr=o("The model is set in evaluation mode by default using "),c3e=a("code"),IFr=o("model.eval()"),NFr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),f3e=a("code"),qFr=o("model.train()"),jFr=l(),F(e4.$$.fragment),aao=l(),im=a("h2"),o4=a("a"),g3e=a("span"),F(Sk.$$.fragment),DFr=l(),h3e=a("span"),GFr=o("AutoModelForQuestionAnswering"),nao=l(),Qo=a("div"),F(Rk.$$.fragment),OFr=l(),dm=a("p"),VFr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),GZ=a("a"),XFr=o("from_pretrained()"),zFr=o(" class method or the "),OZ=a("a"),QFr=o("from_config()"),WFr=o(` class
method.`),UFr=l(),Pk=a("p"),HFr=o("This class cannot be instantiated directly using "),u3e=a("code"),JFr=o("__init__()"),YFr=o(" (throws an error)."),ZFr=l(),St=a("div"),F(Bk.$$.fragment),KFr=l(),p3e=a("p"),eTr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),oTr=l(),mm=a("p"),rTr=o(`Note:
Loading a model from its configuration file does `),_3e=a("strong"),tTr=o("not"),aTr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VZ=a("a"),nTr=o("from_pretrained()"),sTr=o(" to load the model weights."),lTr=l(),F(r4.$$.fragment),iTr=l(),mo=a("div"),F(Ik.$$.fragment),dTr=l(),b3e=a("p"),mTr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),cTr=l(),pn=a("p"),fTr=o("The model class to instantiate is selected based on the "),v3e=a("code"),gTr=o("model_type"),hTr=o(` property of the config object (either
passed as an argument or loaded from `),F3e=a("code"),uTr=o("pretrained_model_name_or_path"),pTr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T3e=a("code"),_Tr=o("pretrained_model_name_or_path"),bTr=o(":"),vTr=l(),O=a("ul"),t4=a("li"),M3e=a("strong"),FTr=o("albert"),TTr=o(" \u2014 "),XZ=a("a"),MTr=o("AlbertForQuestionAnswering"),ETr=o(" (ALBERT model)"),CTr=l(),a4=a("li"),E3e=a("strong"),wTr=o("bart"),ATr=o(" \u2014 "),zZ=a("a"),LTr=o("BartForQuestionAnswering"),yTr=o(" (BART model)"),xTr=l(),n4=a("li"),C3e=a("strong"),$Tr=o("bert"),kTr=o(" \u2014 "),QZ=a("a"),STr=o("BertForQuestionAnswering"),RTr=o(" (BERT model)"),PTr=l(),s4=a("li"),w3e=a("strong"),BTr=o("big_bird"),ITr=o(" \u2014 "),WZ=a("a"),NTr=o("BigBirdForQuestionAnswering"),qTr=o(" (BigBird model)"),jTr=l(),l4=a("li"),A3e=a("strong"),DTr=o("bigbird_pegasus"),GTr=o(" \u2014 "),UZ=a("a"),OTr=o("BigBirdPegasusForQuestionAnswering"),VTr=o(" (BigBird-Pegasus model)"),XTr=l(),i4=a("li"),L3e=a("strong"),zTr=o("bloom"),QTr=o(" \u2014 "),HZ=a("a"),WTr=o("BloomForQuestionAnswering"),UTr=o(" (BLOOM model)"),HTr=l(),d4=a("li"),y3e=a("strong"),JTr=o("camembert"),YTr=o(" \u2014 "),JZ=a("a"),ZTr=o("CamembertForQuestionAnswering"),KTr=o(" (CamemBERT model)"),eMr=l(),m4=a("li"),x3e=a("strong"),oMr=o("canine"),rMr=o(" \u2014 "),YZ=a("a"),tMr=o("CanineForQuestionAnswering"),aMr=o(" (CANINE model)"),nMr=l(),c4=a("li"),$3e=a("strong"),sMr=o("convbert"),lMr=o(" \u2014 "),ZZ=a("a"),iMr=o("ConvBertForQuestionAnswering"),dMr=o(" (ConvBERT model)"),mMr=l(),f4=a("li"),k3e=a("strong"),cMr=o("data2vec-text"),fMr=o(" \u2014 "),KZ=a("a"),gMr=o("Data2VecTextForQuestionAnswering"),hMr=o(" (Data2VecText model)"),uMr=l(),g4=a("li"),S3e=a("strong"),pMr=o("deberta"),_Mr=o(" \u2014 "),eK=a("a"),bMr=o("DebertaForQuestionAnswering"),vMr=o(" (DeBERTa model)"),FMr=l(),h4=a("li"),R3e=a("strong"),TMr=o("deberta-v2"),MMr=o(" \u2014 "),oK=a("a"),EMr=o("DebertaV2ForQuestionAnswering"),CMr=o(" (DeBERTa-v2 model)"),wMr=l(),u4=a("li"),P3e=a("strong"),AMr=o("distilbert"),LMr=o(" \u2014 "),rK=a("a"),yMr=o("DistilBertForQuestionAnswering"),xMr=o(" (DistilBERT model)"),$Mr=l(),p4=a("li"),B3e=a("strong"),kMr=o("electra"),SMr=o(" \u2014 "),tK=a("a"),RMr=o("ElectraForQuestionAnswering"),PMr=o(" (ELECTRA model)"),BMr=l(),_4=a("li"),I3e=a("strong"),IMr=o("ernie"),NMr=o(" \u2014 "),aK=a("a"),qMr=o("ErnieForQuestionAnswering"),jMr=o(" (ERNIE model)"),DMr=l(),b4=a("li"),N3e=a("strong"),GMr=o("flaubert"),OMr=o(" \u2014 "),nK=a("a"),VMr=o("FlaubertForQuestionAnsweringSimple"),XMr=o(" (FlauBERT model)"),zMr=l(),v4=a("li"),q3e=a("strong"),QMr=o("fnet"),WMr=o(" \u2014 "),sK=a("a"),UMr=o("FNetForQuestionAnswering"),HMr=o(" (FNet model)"),JMr=l(),F4=a("li"),j3e=a("strong"),YMr=o("funnel"),ZMr=o(" \u2014 "),lK=a("a"),KMr=o("FunnelForQuestionAnswering"),eEr=o(" (Funnel Transformer model)"),oEr=l(),T4=a("li"),D3e=a("strong"),rEr=o("gptj"),tEr=o(" \u2014 "),iK=a("a"),aEr=o("GPTJForQuestionAnswering"),nEr=o(" (GPT-J model)"),sEr=l(),M4=a("li"),G3e=a("strong"),lEr=o("ibert"),iEr=o(" \u2014 "),dK=a("a"),dEr=o("IBertForQuestionAnswering"),mEr=o(" (I-BERT model)"),cEr=l(),E4=a("li"),O3e=a("strong"),fEr=o("layoutlmv2"),gEr=o(" \u2014 "),mK=a("a"),hEr=o("LayoutLMv2ForQuestionAnswering"),uEr=o(" (LayoutLMv2 model)"),pEr=l(),C4=a("li"),V3e=a("strong"),_Er=o("layoutlmv3"),bEr=o(" \u2014 "),cK=a("a"),vEr=o("LayoutLMv3ForQuestionAnswering"),FEr=o(" (LayoutLMv3 model)"),TEr=l(),w4=a("li"),X3e=a("strong"),MEr=o("led"),EEr=o(" \u2014 "),fK=a("a"),CEr=o("LEDForQuestionAnswering"),wEr=o(" (LED model)"),AEr=l(),A4=a("li"),z3e=a("strong"),LEr=o("lilt"),yEr=o(" \u2014 "),gK=a("a"),xEr=o("LiltForQuestionAnswering"),$Er=o(" (LiLT model)"),kEr=l(),L4=a("li"),Q3e=a("strong"),SEr=o("longformer"),REr=o(" \u2014 "),hK=a("a"),PEr=o("LongformerForQuestionAnswering"),BEr=o(" (Longformer model)"),IEr=l(),y4=a("li"),W3e=a("strong"),NEr=o("luke"),qEr=o(" \u2014 "),uK=a("a"),jEr=o("LukeForQuestionAnswering"),DEr=o(" (LUKE model)"),GEr=l(),x4=a("li"),U3e=a("strong"),OEr=o("lxmert"),VEr=o(" \u2014 "),pK=a("a"),XEr=o("LxmertForQuestionAnswering"),zEr=o(" (LXMERT model)"),QEr=l(),$4=a("li"),H3e=a("strong"),WEr=o("markuplm"),UEr=o(" \u2014 "),_K=a("a"),HEr=o("MarkupLMForQuestionAnswering"),JEr=o(" (MarkupLM model)"),YEr=l(),k4=a("li"),J3e=a("strong"),ZEr=o("mbart"),KEr=o(" \u2014 "),bK=a("a"),e4r=o("MBartForQuestionAnswering"),o4r=o(" (mBART model)"),r4r=l(),S4=a("li"),Y3e=a("strong"),t4r=o("megatron-bert"),a4r=o(" \u2014 "),vK=a("a"),n4r=o("MegatronBertForQuestionAnswering"),s4r=o(" (Megatron-BERT model)"),l4r=l(),R4=a("li"),Z3e=a("strong"),i4r=o("mobilebert"),d4r=o(" \u2014 "),FK=a("a"),m4r=o("MobileBertForQuestionAnswering"),c4r=o(" (MobileBERT model)"),f4r=l(),P4=a("li"),K3e=a("strong"),g4r=o("mpnet"),h4r=o(" \u2014 "),TK=a("a"),u4r=o("MPNetForQuestionAnswering"),p4r=o(" (MPNet model)"),_4r=l(),B4=a("li"),e5e=a("strong"),b4r=o("mvp"),v4r=o(" \u2014 "),MK=a("a"),F4r=o("MvpForQuestionAnswering"),T4r=o(" (MVP model)"),M4r=l(),I4=a("li"),o5e=a("strong"),E4r=o("nezha"),C4r=o(" \u2014 "),EK=a("a"),w4r=o("NezhaForQuestionAnswering"),A4r=o(" (Nezha model)"),L4r=l(),N4=a("li"),r5e=a("strong"),y4r=o("nystromformer"),x4r=o(" \u2014 "),CK=a("a"),$4r=o("NystromformerForQuestionAnswering"),k4r=o(" (Nystr\xF6mformer model)"),S4r=l(),q4=a("li"),t5e=a("strong"),R4r=o("opt"),P4r=o(" \u2014 "),wK=a("a"),B4r=o("OPTForQuestionAnswering"),I4r=o(" (OPT model)"),N4r=l(),j4=a("li"),a5e=a("strong"),q4r=o("qdqbert"),j4r=o(" \u2014 "),AK=a("a"),D4r=o("QDQBertForQuestionAnswering"),G4r=o(" (QDQBert model)"),O4r=l(),D4=a("li"),n5e=a("strong"),V4r=o("reformer"),X4r=o(" \u2014 "),LK=a("a"),z4r=o("ReformerForQuestionAnswering"),Q4r=o(" (Reformer model)"),W4r=l(),G4=a("li"),s5e=a("strong"),U4r=o("rembert"),H4r=o(" \u2014 "),yK=a("a"),J4r=o("RemBertForQuestionAnswering"),Y4r=o(" (RemBERT model)"),Z4r=l(),O4=a("li"),l5e=a("strong"),K4r=o("roberta"),eCr=o(" \u2014 "),xK=a("a"),oCr=o("RobertaForQuestionAnswering"),rCr=o(" (RoBERTa model)"),tCr=l(),V4=a("li"),i5e=a("strong"),aCr=o("roformer"),nCr=o(" \u2014 "),$K=a("a"),sCr=o("RoFormerForQuestionAnswering"),lCr=o(" (RoFormer model)"),iCr=l(),X4=a("li"),d5e=a("strong"),dCr=o("splinter"),mCr=o(" \u2014 "),kK=a("a"),cCr=o("SplinterForQuestionAnswering"),fCr=o(" (Splinter model)"),gCr=l(),z4=a("li"),m5e=a("strong"),hCr=o("squeezebert"),uCr=o(" \u2014 "),SK=a("a"),pCr=o("SqueezeBertForQuestionAnswering"),_Cr=o(" (SqueezeBERT model)"),bCr=l(),Q4=a("li"),c5e=a("strong"),vCr=o("xlm"),FCr=o(" \u2014 "),RK=a("a"),TCr=o("XLMForQuestionAnsweringSimple"),MCr=o(" (XLM model)"),ECr=l(),W4=a("li"),f5e=a("strong"),CCr=o("xlm-roberta"),wCr=o(" \u2014 "),PK=a("a"),ACr=o("XLMRobertaForQuestionAnswering"),LCr=o(" (XLM-RoBERTa model)"),yCr=l(),U4=a("li"),g5e=a("strong"),xCr=o("xlm-roberta-xl"),$Cr=o(" \u2014 "),BK=a("a"),kCr=o("XLMRobertaXLForQuestionAnswering"),SCr=o(" (XLM-RoBERTa-XL model)"),RCr=l(),H4=a("li"),h5e=a("strong"),PCr=o("xlnet"),BCr=o(" \u2014 "),IK=a("a"),ICr=o("XLNetForQuestionAnsweringSimple"),NCr=o(" (XLNet model)"),qCr=l(),J4=a("li"),u5e=a("strong"),jCr=o("yoso"),DCr=o(" \u2014 "),NK=a("a"),GCr=o("YosoForQuestionAnswering"),OCr=o(" (YOSO model)"),VCr=l(),Y4=a("p"),XCr=o("The model is set in evaluation mode by default using "),p5e=a("code"),zCr=o("model.eval()"),QCr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_5e=a("code"),WCr=o("model.train()"),UCr=l(),F(Z4.$$.fragment),sao=l(),cm=a("h2"),K4=a("a"),b5e=a("span"),F(Nk.$$.fragment),HCr=l(),v5e=a("span"),JCr=o("AutoModelForTableQuestionAnswering"),lao=l(),Wo=a("div"),F(qk.$$.fragment),YCr=l(),fm=a("p"),ZCr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),qK=a("a"),KCr=o("from_pretrained()"),e3r=o(" class method or the "),jK=a("a"),o3r=o("from_config()"),r3r=o(` class
method.`),t3r=l(),jk=a("p"),a3r=o("This class cannot be instantiated directly using "),F5e=a("code"),n3r=o("__init__()"),s3r=o(" (throws an error)."),l3r=l(),Rt=a("div"),F(Dk.$$.fragment),i3r=l(),T5e=a("p"),d3r=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),m3r=l(),gm=a("p"),c3r=o(`Note:
Loading a model from its configuration file does `),M5e=a("strong"),f3r=o("not"),g3r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),DK=a("a"),h3r=o("from_pretrained()"),u3r=o(" to load the model weights."),p3r=l(),F(eC.$$.fragment),_3r=l(),co=a("div"),F(Gk.$$.fragment),b3r=l(),E5e=a("p"),v3r=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),F3r=l(),_n=a("p"),T3r=o("The model class to instantiate is selected based on the "),C5e=a("code"),M3r=o("model_type"),E3r=o(` property of the config object (either
passed as an argument or loaded from `),w5e=a("code"),C3r=o("pretrained_model_name_or_path"),w3r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),A5e=a("code"),A3r=o("pretrained_model_name_or_path"),L3r=o(":"),y3r=l(),L5e=a("ul"),oC=a("li"),y5e=a("strong"),x3r=o("tapas"),$3r=o(" \u2014 "),GK=a("a"),k3r=o("TapasForQuestionAnswering"),S3r=o(" (TAPAS model)"),R3r=l(),rC=a("p"),P3r=o("The model is set in evaluation mode by default using "),x5e=a("code"),B3r=o("model.eval()"),I3r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$5e=a("code"),N3r=o("model.train()"),q3r=l(),F(tC.$$.fragment),iao=l(),hm=a("h2"),aC=a("a"),k5e=a("span"),F(Ok.$$.fragment),j3r=l(),S5e=a("span"),D3r=o("AutoModelForDocumentQuestionAnswering"),dao=l(),Uo=a("div"),F(Vk.$$.fragment),G3r=l(),um=a("p"),O3r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),OK=a("a"),V3r=o("from_pretrained()"),X3r=o(" class method or the "),VK=a("a"),z3r=o("from_config()"),Q3r=o(` class
method.`),W3r=l(),Xk=a("p"),U3r=o("This class cannot be instantiated directly using "),R5e=a("code"),H3r=o("__init__()"),J3r=o(" (throws an error)."),Y3r=l(),Pt=a("div"),F(zk.$$.fragment),Z3r=l(),P5e=a("p"),K3r=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),e5r=l(),pm=a("p"),o5r=o(`Note:
Loading a model from its configuration file does `),B5e=a("strong"),r5r=o("not"),t5r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),XK=a("a"),a5r=o("from_pretrained()"),n5r=o(" to load the model weights."),s5r=l(),F(nC.$$.fragment),l5r=l(),fo=a("div"),F(Qk.$$.fragment),i5r=l(),I5e=a("p"),d5r=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),m5r=l(),bn=a("p"),c5r=o("The model class to instantiate is selected based on the "),N5e=a("code"),f5r=o("model_type"),g5r=o(` property of the config object (either
passed as an argument or loaded from `),q5e=a("code"),h5r=o("pretrained_model_name_or_path"),u5r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j5e=a("code"),p5r=o("pretrained_model_name_or_path"),_5r=o(":"),b5r=l(),_m=a("ul"),sC=a("li"),D5e=a("strong"),v5r=o("layoutlm"),F5r=o(" \u2014 "),zK=a("a"),T5r=o("LayoutLMForQuestionAnswering"),M5r=o(" (LayoutLM model)"),E5r=l(),lC=a("li"),G5e=a("strong"),C5r=o("layoutlmv2"),w5r=o(" \u2014 "),QK=a("a"),A5r=o("LayoutLMv2ForQuestionAnswering"),L5r=o(" (LayoutLMv2 model)"),y5r=l(),iC=a("li"),O5e=a("strong"),x5r=o("layoutlmv3"),$5r=o(" \u2014 "),WK=a("a"),k5r=o("LayoutLMv3ForQuestionAnswering"),S5r=o(" (LayoutLMv3 model)"),R5r=l(),dC=a("p"),P5r=o("The model is set in evaluation mode by default using "),V5e=a("code"),B5r=o("model.eval()"),I5r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),X5e=a("code"),N5r=o("model.train()"),q5r=l(),F(mC.$$.fragment),mao=l(),bm=a("h2"),cC=a("a"),z5e=a("span"),F(Wk.$$.fragment),j5r=l(),Q5e=a("span"),D5r=o("AutoModelForImageClassification"),cao=l(),Ho=a("div"),F(Uk.$$.fragment),G5r=l(),vm=a("p"),O5r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),UK=a("a"),V5r=o("from_pretrained()"),X5r=o(" class method or the "),HK=a("a"),z5r=o("from_config()"),Q5r=o(` class
method.`),W5r=l(),Hk=a("p"),U5r=o("This class cannot be instantiated directly using "),W5e=a("code"),H5r=o("__init__()"),J5r=o(" (throws an error)."),Y5r=l(),Bt=a("div"),F(Jk.$$.fragment),Z5r=l(),U5e=a("p"),K5r=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),e0r=l(),Fm=a("p"),o0r=o(`Note:
Loading a model from its configuration file does `),H5e=a("strong"),r0r=o("not"),t0r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),JK=a("a"),a0r=o("from_pretrained()"),n0r=o(" to load the model weights."),s0r=l(),F(fC.$$.fragment),l0r=l(),go=a("div"),F(Yk.$$.fragment),i0r=l(),J5e=a("p"),d0r=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),m0r=l(),vn=a("p"),c0r=o("The model class to instantiate is selected based on the "),Y5e=a("code"),f0r=o("model_type"),g0r=o(` property of the config object (either
passed as an argument or loaded from `),Z5e=a("code"),h0r=o("pretrained_model_name_or_path"),u0r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K5e=a("code"),p0r=o("pretrained_model_name_or_path"),_0r=o(":"),b0r=l(),be=a("ul"),gC=a("li"),e0e=a("strong"),v0r=o("beit"),F0r=o(" \u2014 "),YK=a("a"),T0r=o("BeitForImageClassification"),M0r=o(" (BEiT model)"),E0r=l(),hC=a("li"),o0e=a("strong"),C0r=o("convnext"),w0r=o(" \u2014 "),ZK=a("a"),A0r=o("ConvNextForImageClassification"),L0r=o(" (ConvNeXT model)"),y0r=l(),uC=a("li"),r0e=a("strong"),x0r=o("cvt"),$0r=o(" \u2014 "),KK=a("a"),k0r=o("CvtForImageClassification"),S0r=o(" (CvT model)"),R0r=l(),pC=a("li"),t0e=a("strong"),P0r=o("data2vec-vision"),B0r=o(" \u2014 "),eee=a("a"),I0r=o("Data2VecVisionForImageClassification"),N0r=o(" (Data2VecVision model)"),q0r=l(),$l=a("li"),a0e=a("strong"),j0r=o("deit"),D0r=o(" \u2014 "),oee=a("a"),G0r=o("DeiTForImageClassification"),O0r=o(" or "),ree=a("a"),V0r=o("DeiTForImageClassificationWithTeacher"),X0r=o(" (DeiT model)"),z0r=l(),_C=a("li"),n0e=a("strong"),Q0r=o("imagegpt"),W0r=o(" \u2014 "),tee=a("a"),U0r=o("ImageGPTForImageClassification"),H0r=o(" (ImageGPT model)"),J0r=l(),kl=a("li"),s0e=a("strong"),Y0r=o("levit"),Z0r=o(" \u2014 "),aee=a("a"),K0r=o("LevitForImageClassification"),ewr=o(" or "),nee=a("a"),owr=o("LevitForImageClassificationWithTeacher"),rwr=o(" (LeViT model)"),twr=l(),bC=a("li"),l0e=a("strong"),awr=o("mobilevit"),nwr=o(" \u2014 "),see=a("a"),swr=o("MobileViTForImageClassification"),lwr=o(" (MobileViT model)"),iwr=l(),It=a("li"),i0e=a("strong"),dwr=o("perceiver"),mwr=o(" \u2014 "),lee=a("a"),cwr=o("PerceiverForImageClassificationLearned"),fwr=o(" or "),iee=a("a"),gwr=o("PerceiverForImageClassificationFourier"),hwr=o(" or "),dee=a("a"),uwr=o("PerceiverForImageClassificationConvProcessing"),pwr=o(" (Perceiver model)"),_wr=l(),vC=a("li"),d0e=a("strong"),bwr=o("poolformer"),vwr=o(" \u2014 "),mee=a("a"),Fwr=o("PoolFormerForImageClassification"),Twr=o(" (PoolFormer model)"),Mwr=l(),FC=a("li"),m0e=a("strong"),Ewr=o("regnet"),Cwr=o(" \u2014 "),cee=a("a"),wwr=o("RegNetForImageClassification"),Awr=o(" (RegNet model)"),Lwr=l(),TC=a("li"),c0e=a("strong"),ywr=o("resnet"),xwr=o(" \u2014 "),fee=a("a"),$wr=o("ResNetForImageClassification"),kwr=o(" (ResNet model)"),Swr=l(),MC=a("li"),f0e=a("strong"),Rwr=o("segformer"),Pwr=o(" \u2014 "),gee=a("a"),Bwr=o("SegformerForImageClassification"),Iwr=o(" (SegFormer model)"),Nwr=l(),EC=a("li"),g0e=a("strong"),qwr=o("swin"),jwr=o(" \u2014 "),hee=a("a"),Dwr=o("SwinForImageClassification"),Gwr=o(" (Swin Transformer model)"),Owr=l(),CC=a("li"),h0e=a("strong"),Vwr=o("swinv2"),Xwr=o(" \u2014 "),uee=a("a"),zwr=o("Swinv2ForImageClassification"),Qwr=o(" (Swin Transformer V2 model)"),Wwr=l(),wC=a("li"),u0e=a("strong"),Uwr=o("van"),Hwr=o(" \u2014 "),pee=a("a"),Jwr=o("VanForImageClassification"),Ywr=o(" (VAN model)"),Zwr=l(),AC=a("li"),p0e=a("strong"),Kwr=o("vit"),eAr=o(" \u2014 "),_ee=a("a"),oAr=o("ViTForImageClassification"),rAr=o(" (ViT model)"),tAr=l(),LC=a("li"),_0e=a("strong"),aAr=o("vit_msn"),nAr=o(" \u2014 "),bee=a("a"),sAr=o("ViTMSNForImageClassification"),lAr=o(" (ViTMSN model)"),iAr=l(),yC=a("p"),dAr=o("The model is set in evaluation mode by default using "),b0e=a("code"),mAr=o("model.eval()"),cAr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),v0e=a("code"),fAr=o("model.train()"),gAr=l(),F(xC.$$.fragment),fao=l(),Tm=a("h2"),$C=a("a"),F0e=a("span"),F(Zk.$$.fragment),hAr=l(),T0e=a("span"),uAr=o("AutoModelForVideoClassification"),gao=l(),Jo=a("div"),F(Kk.$$.fragment),pAr=l(),Mm=a("p"),_Ar=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),vee=a("a"),bAr=o("from_pretrained()"),vAr=o(" class method or the "),Fee=a("a"),FAr=o("from_config()"),TAr=o(` class
method.`),MAr=l(),eS=a("p"),EAr=o("This class cannot be instantiated directly using "),M0e=a("code"),CAr=o("__init__()"),wAr=o(" (throws an error)."),AAr=l(),Nt=a("div"),F(oS.$$.fragment),LAr=l(),E0e=a("p"),yAr=o("Instantiates one of the model classes of the library (with a video classification head) from a configuration."),xAr=l(),Em=a("p"),$Ar=o(`Note:
Loading a model from its configuration file does `),C0e=a("strong"),kAr=o("not"),SAr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Tee=a("a"),RAr=o("from_pretrained()"),PAr=o(" to load the model weights."),BAr=l(),F(kC.$$.fragment),IAr=l(),ho=a("div"),F(rS.$$.fragment),NAr=l(),w0e=a("p"),qAr=o("Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),jAr=l(),Fn=a("p"),DAr=o("The model class to instantiate is selected based on the "),A0e=a("code"),GAr=o("model_type"),OAr=o(` property of the config object (either
passed as an argument or loaded from `),L0e=a("code"),VAr=o("pretrained_model_name_or_path"),XAr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),y0e=a("code"),zAr=o("pretrained_model_name_or_path"),QAr=o(":"),WAr=l(),x0e=a("ul"),SC=a("li"),$0e=a("strong"),UAr=o("videomae"),HAr=o(" \u2014 "),Mee=a("a"),JAr=o("VideoMAEForVideoClassification"),YAr=o(" (VideoMAE model)"),ZAr=l(),RC=a("p"),KAr=o("The model is set in evaluation mode by default using "),k0e=a("code"),e6r=o("model.eval()"),o6r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),S0e=a("code"),r6r=o("model.train()"),t6r=l(),F(PC.$$.fragment),hao=l(),Cm=a("h2"),BC=a("a"),R0e=a("span"),F(tS.$$.fragment),a6r=l(),P0e=a("span"),n6r=o("AutoModelForVision2Seq"),uao=l(),Yo=a("div"),F(aS.$$.fragment),s6r=l(),wm=a("p"),l6r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Eee=a("a"),i6r=o("from_pretrained()"),d6r=o(" class method or the "),Cee=a("a"),m6r=o("from_config()"),c6r=o(` class
method.`),f6r=l(),nS=a("p"),g6r=o("This class cannot be instantiated directly using "),B0e=a("code"),h6r=o("__init__()"),u6r=o(" (throws an error)."),p6r=l(),qt=a("div"),F(sS.$$.fragment),_6r=l(),I0e=a("p"),b6r=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),v6r=l(),Am=a("p"),F6r=o(`Note:
Loading a model from its configuration file does `),N0e=a("strong"),T6r=o("not"),M6r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wee=a("a"),E6r=o("from_pretrained()"),C6r=o(" to load the model weights."),w6r=l(),F(IC.$$.fragment),A6r=l(),uo=a("div"),F(lS.$$.fragment),L6r=l(),q0e=a("p"),y6r=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),x6r=l(),Tn=a("p"),$6r=o("The model class to instantiate is selected based on the "),j0e=a("code"),k6r=o("model_type"),S6r=o(` property of the config object (either
passed as an argument or loaded from `),D0e=a("code"),R6r=o("pretrained_model_name_or_path"),P6r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G0e=a("code"),B6r=o("pretrained_model_name_or_path"),I6r=o(":"),N6r=l(),O0e=a("ul"),NC=a("li"),V0e=a("strong"),q6r=o("vision-encoder-decoder"),j6r=o(" \u2014 "),Aee=a("a"),D6r=o("VisionEncoderDecoderModel"),G6r=o(" (Vision Encoder decoder model)"),O6r=l(),qC=a("p"),V6r=o("The model is set in evaluation mode by default using "),X0e=a("code"),X6r=o("model.eval()"),z6r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),z0e=a("code"),Q6r=o("model.train()"),W6r=l(),F(jC.$$.fragment),pao=l(),Lm=a("h2"),DC=a("a"),Q0e=a("span"),F(iS.$$.fragment),U6r=l(),W0e=a("span"),H6r=o("AutoModelForVisualQuestionAnswering"),_ao=l(),Zo=a("div"),F(dS.$$.fragment),J6r=l(),ym=a("p"),Y6r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),Lee=a("a"),Z6r=o("from_pretrained()"),K6r=o(" class method or the "),yee=a("a"),e7r=o("from_config()"),o7r=o(` class
method.`),r7r=l(),mS=a("p"),t7r=o("This class cannot be instantiated directly using "),U0e=a("code"),a7r=o("__init__()"),n7r=o(" (throws an error)."),s7r=l(),jt=a("div"),F(cS.$$.fragment),l7r=l(),H0e=a("p"),i7r=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),d7r=l(),xm=a("p"),m7r=o(`Note:
Loading a model from its configuration file does `),J0e=a("strong"),c7r=o("not"),f7r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xee=a("a"),g7r=o("from_pretrained()"),h7r=o(" to load the model weights."),u7r=l(),F(GC.$$.fragment),p7r=l(),po=a("div"),F(fS.$$.fragment),_7r=l(),Y0e=a("p"),b7r=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),v7r=l(),Mn=a("p"),F7r=o("The model class to instantiate is selected based on the "),Z0e=a("code"),T7r=o("model_type"),M7r=o(` property of the config object (either
passed as an argument or loaded from `),K0e=a("code"),E7r=o("pretrained_model_name_or_path"),C7r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ewe=a("code"),w7r=o("pretrained_model_name_or_path"),A7r=o(":"),L7r=l(),owe=a("ul"),OC=a("li"),rwe=a("strong"),y7r=o("vilt"),x7r=o(" \u2014 "),$ee=a("a"),$7r=o("ViltForQuestionAnswering"),k7r=o(" (ViLT model)"),S7r=l(),VC=a("p"),R7r=o("The model is set in evaluation mode by default using "),twe=a("code"),P7r=o("model.eval()"),B7r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),awe=a("code"),I7r=o("model.train()"),N7r=l(),F(XC.$$.fragment),bao=l(),$m=a("h2"),zC=a("a"),nwe=a("span"),F(gS.$$.fragment),q7r=l(),swe=a("span"),j7r=o("AutoModelForAudioClassification"),vao=l(),Ko=a("div"),F(hS.$$.fragment),D7r=l(),km=a("p"),G7r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),kee=a("a"),O7r=o("from_pretrained()"),V7r=o(" class method or the "),See=a("a"),X7r=o("from_config()"),z7r=o(` class
method.`),Q7r=l(),uS=a("p"),W7r=o("This class cannot be instantiated directly using "),lwe=a("code"),U7r=o("__init__()"),H7r=o(" (throws an error)."),J7r=l(),Dt=a("div"),F(pS.$$.fragment),Y7r=l(),iwe=a("p"),Z7r=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),K7r=l(),Sm=a("p"),e8r=o(`Note:
Loading a model from its configuration file does `),dwe=a("strong"),o8r=o("not"),r8r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ree=a("a"),t8r=o("from_pretrained()"),a8r=o(" to load the model weights."),n8r=l(),F(QC.$$.fragment),s8r=l(),_o=a("div"),F(_S.$$.fragment),l8r=l(),mwe=a("p"),i8r=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),d8r=l(),En=a("p"),m8r=o("The model class to instantiate is selected based on the "),cwe=a("code"),c8r=o("model_type"),f8r=o(` property of the config object (either
passed as an argument or loaded from `),fwe=a("code"),g8r=o("pretrained_model_name_or_path"),h8r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gwe=a("code"),u8r=o("pretrained_model_name_or_path"),p8r=o(":"),_8r=l(),Be=a("ul"),WC=a("li"),hwe=a("strong"),b8r=o("data2vec-audio"),v8r=o(" \u2014 "),Pee=a("a"),F8r=o("Data2VecAudioForSequenceClassification"),T8r=o(" (Data2VecAudio model)"),M8r=l(),UC=a("li"),uwe=a("strong"),E8r=o("hubert"),C8r=o(" \u2014 "),Bee=a("a"),w8r=o("HubertForSequenceClassification"),A8r=o(" (Hubert model)"),L8r=l(),HC=a("li"),pwe=a("strong"),y8r=o("sew"),x8r=o(" \u2014 "),Iee=a("a"),$8r=o("SEWForSequenceClassification"),k8r=o(" (SEW model)"),S8r=l(),JC=a("li"),_we=a("strong"),R8r=o("sew-d"),P8r=o(" \u2014 "),Nee=a("a"),B8r=o("SEWDForSequenceClassification"),I8r=o(" (SEW-D model)"),N8r=l(),YC=a("li"),bwe=a("strong"),q8r=o("unispeech"),j8r=o(" \u2014 "),qee=a("a"),D8r=o("UniSpeechForSequenceClassification"),G8r=o(" (UniSpeech model)"),O8r=l(),ZC=a("li"),vwe=a("strong"),V8r=o("unispeech-sat"),X8r=o(" \u2014 "),jee=a("a"),z8r=o("UniSpeechSatForSequenceClassification"),Q8r=o(" (UniSpeechSat model)"),W8r=l(),KC=a("li"),Fwe=a("strong"),U8r=o("wav2vec2"),H8r=o(" \u2014 "),Dee=a("a"),J8r=o("Wav2Vec2ForSequenceClassification"),Y8r=o(" (Wav2Vec2 model)"),Z8r=l(),e3=a("li"),Twe=a("strong"),K8r=o("wav2vec2-conformer"),eLr=o(" \u2014 "),Gee=a("a"),oLr=o("Wav2Vec2ConformerForSequenceClassification"),rLr=o(" (Wav2Vec2-Conformer model)"),tLr=l(),o3=a("li"),Mwe=a("strong"),aLr=o("wavlm"),nLr=o(" \u2014 "),Oee=a("a"),sLr=o("WavLMForSequenceClassification"),lLr=o(" (WavLM model)"),iLr=l(),r3=a("p"),dLr=o("The model is set in evaluation mode by default using "),Ewe=a("code"),mLr=o("model.eval()"),cLr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Cwe=a("code"),fLr=o("model.train()"),gLr=l(),F(t3.$$.fragment),Fao=l(),Rm=a("h2"),a3=a("a"),wwe=a("span"),F(bS.$$.fragment),hLr=l(),Awe=a("span"),uLr=o("AutoModelForAudioFrameClassification"),Tao=l(),er=a("div"),F(vS.$$.fragment),pLr=l(),Pm=a("p"),_Lr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),Vee=a("a"),bLr=o("from_pretrained()"),vLr=o(" class method or the "),Xee=a("a"),FLr=o("from_config()"),TLr=o(` class
method.`),MLr=l(),FS=a("p"),ELr=o("This class cannot be instantiated directly using "),Lwe=a("code"),CLr=o("__init__()"),wLr=o(" (throws an error)."),ALr=l(),Gt=a("div"),F(TS.$$.fragment),LLr=l(),ywe=a("p"),yLr=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),xLr=l(),Bm=a("p"),$Lr=o(`Note:
Loading a model from its configuration file does `),xwe=a("strong"),kLr=o("not"),SLr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zee=a("a"),RLr=o("from_pretrained()"),PLr=o(" to load the model weights."),BLr=l(),F(n3.$$.fragment),ILr=l(),bo=a("div"),F(MS.$$.fragment),NLr=l(),$we=a("p"),qLr=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),jLr=l(),Cn=a("p"),DLr=o("The model class to instantiate is selected based on the "),kwe=a("code"),GLr=o("model_type"),OLr=o(` property of the config object (either
passed as an argument or loaded from `),Swe=a("code"),VLr=o("pretrained_model_name_or_path"),XLr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rwe=a("code"),zLr=o("pretrained_model_name_or_path"),QLr=o(":"),WLr=l(),ut=a("ul"),s3=a("li"),Pwe=a("strong"),ULr=o("data2vec-audio"),HLr=o(" \u2014 "),Qee=a("a"),JLr=o("Data2VecAudioForAudioFrameClassification"),YLr=o(" (Data2VecAudio model)"),ZLr=l(),l3=a("li"),Bwe=a("strong"),KLr=o("unispeech-sat"),eyr=o(" \u2014 "),Wee=a("a"),oyr=o("UniSpeechSatForAudioFrameClassification"),ryr=o(" (UniSpeechSat model)"),tyr=l(),i3=a("li"),Iwe=a("strong"),ayr=o("wav2vec2"),nyr=o(" \u2014 "),Uee=a("a"),syr=o("Wav2Vec2ForAudioFrameClassification"),lyr=o(" (Wav2Vec2 model)"),iyr=l(),d3=a("li"),Nwe=a("strong"),dyr=o("wav2vec2-conformer"),myr=o(" \u2014 "),Hee=a("a"),cyr=o("Wav2Vec2ConformerForAudioFrameClassification"),fyr=o(" (Wav2Vec2-Conformer model)"),gyr=l(),m3=a("li"),qwe=a("strong"),hyr=o("wavlm"),uyr=o(" \u2014 "),Jee=a("a"),pyr=o("WavLMForAudioFrameClassification"),_yr=o(" (WavLM model)"),byr=l(),c3=a("p"),vyr=o("The model is set in evaluation mode by default using "),jwe=a("code"),Fyr=o("model.eval()"),Tyr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Dwe=a("code"),Myr=o("model.train()"),Eyr=l(),F(f3.$$.fragment),Mao=l(),Im=a("h2"),g3=a("a"),Gwe=a("span"),F(ES.$$.fragment),Cyr=l(),Owe=a("span"),wyr=o("AutoModelForCTC"),Eao=l(),or=a("div"),F(CS.$$.fragment),Ayr=l(),Nm=a("p"),Lyr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),Yee=a("a"),yyr=o("from_pretrained()"),xyr=o(" class method or the "),Zee=a("a"),$yr=o("from_config()"),kyr=o(` class
method.`),Syr=l(),wS=a("p"),Ryr=o("This class cannot be instantiated directly using "),Vwe=a("code"),Pyr=o("__init__()"),Byr=o(" (throws an error)."),Iyr=l(),Ot=a("div"),F(AS.$$.fragment),Nyr=l(),Xwe=a("p"),qyr=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),jyr=l(),qm=a("p"),Dyr=o(`Note:
Loading a model from its configuration file does `),zwe=a("strong"),Gyr=o("not"),Oyr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Kee=a("a"),Vyr=o("from_pretrained()"),Xyr=o(" to load the model weights."),zyr=l(),F(h3.$$.fragment),Qyr=l(),vo=a("div"),F(LS.$$.fragment),Wyr=l(),Qwe=a("p"),Uyr=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),Hyr=l(),wn=a("p"),Jyr=o("The model class to instantiate is selected based on the "),Wwe=a("code"),Yyr=o("model_type"),Zyr=o(` property of the config object (either
passed as an argument or loaded from `),Uwe=a("code"),Kyr=o("pretrained_model_name_or_path"),e9r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Hwe=a("code"),o9r=o("pretrained_model_name_or_path"),r9r=o(":"),t9r=l(),Le=a("ul"),u3=a("li"),Jwe=a("strong"),a9r=o("data2vec-audio"),n9r=o(" \u2014 "),eoe=a("a"),s9r=o("Data2VecAudioForCTC"),l9r=o(" (Data2VecAudio model)"),i9r=l(),p3=a("li"),Ywe=a("strong"),d9r=o("hubert"),m9r=o(" \u2014 "),ooe=a("a"),c9r=o("HubertForCTC"),f9r=o(" (Hubert model)"),g9r=l(),_3=a("li"),Zwe=a("strong"),h9r=o("mctct"),u9r=o(" \u2014 "),roe=a("a"),p9r=o("MCTCTForCTC"),_9r=o(" (M-CTC-T model)"),b9r=l(),b3=a("li"),Kwe=a("strong"),v9r=o("sew"),F9r=o(" \u2014 "),toe=a("a"),T9r=o("SEWForCTC"),M9r=o(" (SEW model)"),E9r=l(),v3=a("li"),eAe=a("strong"),C9r=o("sew-d"),w9r=o(" \u2014 "),aoe=a("a"),A9r=o("SEWDForCTC"),L9r=o(" (SEW-D model)"),y9r=l(),F3=a("li"),oAe=a("strong"),x9r=o("unispeech"),$9r=o(" \u2014 "),noe=a("a"),k9r=o("UniSpeechForCTC"),S9r=o(" (UniSpeech model)"),R9r=l(),T3=a("li"),rAe=a("strong"),P9r=o("unispeech-sat"),B9r=o(" \u2014 "),soe=a("a"),I9r=o("UniSpeechSatForCTC"),N9r=o(" (UniSpeechSat model)"),q9r=l(),M3=a("li"),tAe=a("strong"),j9r=o("wav2vec2"),D9r=o(" \u2014 "),loe=a("a"),G9r=o("Wav2Vec2ForCTC"),O9r=o(" (Wav2Vec2 model)"),V9r=l(),E3=a("li"),aAe=a("strong"),X9r=o("wav2vec2-conformer"),z9r=o(" \u2014 "),ioe=a("a"),Q9r=o("Wav2Vec2ConformerForCTC"),W9r=o(" (Wav2Vec2-Conformer model)"),U9r=l(),C3=a("li"),nAe=a("strong"),H9r=o("wavlm"),J9r=o(" \u2014 "),doe=a("a"),Y9r=o("WavLMForCTC"),Z9r=o(" (WavLM model)"),K9r=l(),w3=a("p"),exr=o("The model is set in evaluation mode by default using "),sAe=a("code"),oxr=o("model.eval()"),rxr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),lAe=a("code"),txr=o("model.train()"),axr=l(),F(A3.$$.fragment),Cao=l(),jm=a("h2"),L3=a("a"),iAe=a("span"),F(yS.$$.fragment),nxr=l(),dAe=a("span"),sxr=o("AutoModelForSpeechSeq2Seq"),wao=l(),rr=a("div"),F(xS.$$.fragment),lxr=l(),Dm=a("p"),ixr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),moe=a("a"),dxr=o("from_pretrained()"),mxr=o(" class method or the "),coe=a("a"),cxr=o("from_config()"),fxr=o(` class
method.`),gxr=l(),$S=a("p"),hxr=o("This class cannot be instantiated directly using "),mAe=a("code"),uxr=o("__init__()"),pxr=o(" (throws an error)."),_xr=l(),Vt=a("div"),F(kS.$$.fragment),bxr=l(),cAe=a("p"),vxr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Fxr=l(),Gm=a("p"),Txr=o(`Note:
Loading a model from its configuration file does `),fAe=a("strong"),Mxr=o("not"),Exr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),foe=a("a"),Cxr=o("from_pretrained()"),wxr=o(" to load the model weights."),Axr=l(),F(y3.$$.fragment),Lxr=l(),Fo=a("div"),F(SS.$$.fragment),yxr=l(),gAe=a("p"),xxr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),$xr=l(),An=a("p"),kxr=o("The model class to instantiate is selected based on the "),hAe=a("code"),Sxr=o("model_type"),Rxr=o(` property of the config object (either
passed as an argument or loaded from `),uAe=a("code"),Pxr=o("pretrained_model_name_or_path"),Bxr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pAe=a("code"),Ixr=o("pretrained_model_name_or_path"),Nxr=o(":"),qxr=l(),Om=a("ul"),x3=a("li"),_Ae=a("strong"),jxr=o("speech-encoder-decoder"),Dxr=o(" \u2014 "),goe=a("a"),Gxr=o("SpeechEncoderDecoderModel"),Oxr=o(" (Speech Encoder decoder model)"),Vxr=l(),$3=a("li"),bAe=a("strong"),Xxr=o("speech_to_text"),zxr=o(" \u2014 "),hoe=a("a"),Qxr=o("Speech2TextForConditionalGeneration"),Wxr=o(" (Speech2Text model)"),Uxr=l(),k3=a("li"),vAe=a("strong"),Hxr=o("whisper"),Jxr=o(" \u2014 "),uoe=a("a"),Yxr=o("WhisperForConditionalGeneration"),Zxr=o(" (Whisper model)"),Kxr=l(),S3=a("p"),e$r=o("The model is set in evaluation mode by default using "),FAe=a("code"),o$r=o("model.eval()"),r$r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),TAe=a("code"),t$r=o("model.train()"),a$r=l(),F(R3.$$.fragment),Aao=l(),Vm=a("h2"),P3=a("a"),MAe=a("span"),F(RS.$$.fragment),n$r=l(),EAe=a("span"),s$r=o("AutoModelForAudioXVector"),Lao=l(),tr=a("div"),F(PS.$$.fragment),l$r=l(),Xm=a("p"),i$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),poe=a("a"),d$r=o("from_pretrained()"),m$r=o(" class method or the "),_oe=a("a"),c$r=o("from_config()"),f$r=o(` class
method.`),g$r=l(),BS=a("p"),h$r=o("This class cannot be instantiated directly using "),CAe=a("code"),u$r=o("__init__()"),p$r=o(" (throws an error)."),_$r=l(),Xt=a("div"),F(IS.$$.fragment),b$r=l(),wAe=a("p"),v$r=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),F$r=l(),zm=a("p"),T$r=o(`Note:
Loading a model from its configuration file does `),AAe=a("strong"),M$r=o("not"),E$r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),boe=a("a"),C$r=o("from_pretrained()"),w$r=o(" to load the model weights."),A$r=l(),F(B3.$$.fragment),L$r=l(),To=a("div"),F(NS.$$.fragment),y$r=l(),LAe=a("p"),x$r=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),$$r=l(),Ln=a("p"),k$r=o("The model class to instantiate is selected based on the "),yAe=a("code"),S$r=o("model_type"),R$r=o(` property of the config object (either
passed as an argument or loaded from `),xAe=a("code"),P$r=o("pretrained_model_name_or_path"),B$r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$Ae=a("code"),I$r=o("pretrained_model_name_or_path"),N$r=o(":"),q$r=l(),pt=a("ul"),I3=a("li"),kAe=a("strong"),j$r=o("data2vec-audio"),D$r=o(" \u2014 "),voe=a("a"),G$r=o("Data2VecAudioForXVector"),O$r=o(" (Data2VecAudio model)"),V$r=l(),N3=a("li"),SAe=a("strong"),X$r=o("unispeech-sat"),z$r=o(" \u2014 "),Foe=a("a"),Q$r=o("UniSpeechSatForXVector"),W$r=o(" (UniSpeechSat model)"),U$r=l(),q3=a("li"),RAe=a("strong"),H$r=o("wav2vec2"),J$r=o(" \u2014 "),Toe=a("a"),Y$r=o("Wav2Vec2ForXVector"),Z$r=o(" (Wav2Vec2 model)"),K$r=l(),j3=a("li"),PAe=a("strong"),ekr=o("wav2vec2-conformer"),okr=o(" \u2014 "),Moe=a("a"),rkr=o("Wav2Vec2ConformerForXVector"),tkr=o(" (Wav2Vec2-Conformer model)"),akr=l(),D3=a("li"),BAe=a("strong"),nkr=o("wavlm"),skr=o(" \u2014 "),Eoe=a("a"),lkr=o("WavLMForXVector"),ikr=o(" (WavLM model)"),dkr=l(),G3=a("p"),mkr=o("The model is set in evaluation mode by default using "),IAe=a("code"),ckr=o("model.eval()"),fkr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),NAe=a("code"),gkr=o("model.train()"),hkr=l(),F(O3.$$.fragment),yao=l(),Qm=a("h2"),V3=a("a"),qAe=a("span"),F(qS.$$.fragment),ukr=l(),jAe=a("span"),pkr=o("AutoModelForMaskedImageModeling"),xao=l(),ar=a("div"),F(jS.$$.fragment),_kr=l(),Wm=a("p"),bkr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),Coe=a("a"),vkr=o("from_pretrained()"),Fkr=o(" class method or the "),woe=a("a"),Tkr=o("from_config()"),Mkr=o(` class
method.`),Ekr=l(),DS=a("p"),Ckr=o("This class cannot be instantiated directly using "),DAe=a("code"),wkr=o("__init__()"),Akr=o(" (throws an error)."),Lkr=l(),zt=a("div"),F(GS.$$.fragment),ykr=l(),GAe=a("p"),xkr=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),$kr=l(),Um=a("p"),kkr=o(`Note:
Loading a model from its configuration file does `),OAe=a("strong"),Skr=o("not"),Rkr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Aoe=a("a"),Pkr=o("from_pretrained()"),Bkr=o(" to load the model weights."),Ikr=l(),F(X3.$$.fragment),Nkr=l(),Mo=a("div"),F(OS.$$.fragment),qkr=l(),VAe=a("p"),jkr=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),Dkr=l(),yn=a("p"),Gkr=o("The model class to instantiate is selected based on the "),XAe=a("code"),Okr=o("model_type"),Vkr=o(` property of the config object (either
passed as an argument or loaded from `),zAe=a("code"),Xkr=o("pretrained_model_name_or_path"),zkr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QAe=a("code"),Qkr=o("pretrained_model_name_or_path"),Wkr=o(":"),Ukr=l(),xn=a("ul"),z3=a("li"),WAe=a("strong"),Hkr=o("deit"),Jkr=o(" \u2014 "),Loe=a("a"),Ykr=o("DeiTForMaskedImageModeling"),Zkr=o(" (DeiT model)"),Kkr=l(),Q3=a("li"),UAe=a("strong"),eSr=o("swin"),oSr=o(" \u2014 "),yoe=a("a"),rSr=o("SwinForMaskedImageModeling"),tSr=o(" (Swin Transformer model)"),aSr=l(),W3=a("li"),HAe=a("strong"),nSr=o("swinv2"),sSr=o(" \u2014 "),xoe=a("a"),lSr=o("Swinv2ForMaskedImageModeling"),iSr=o(" (Swin Transformer V2 model)"),dSr=l(),U3=a("li"),JAe=a("strong"),mSr=o("vit"),cSr=o(" \u2014 "),$oe=a("a"),fSr=o("ViTForMaskedImageModeling"),gSr=o(" (ViT model)"),hSr=l(),H3=a("p"),uSr=o("The model is set in evaluation mode by default using "),YAe=a("code"),pSr=o("model.eval()"),_Sr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ZAe=a("code"),bSr=o("model.train()"),vSr=l(),F(J3.$$.fragment),$ao=l(),Hm=a("h2"),Y3=a("a"),KAe=a("span"),F(VS.$$.fragment),FSr=l(),e6e=a("span"),TSr=o("AutoModelForObjectDetection"),kao=l(),nr=a("div"),F(XS.$$.fragment),MSr=l(),Jm=a("p"),ESr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),koe=a("a"),CSr=o("from_pretrained()"),wSr=o(" class method or the "),Soe=a("a"),ASr=o("from_config()"),LSr=o(` class
method.`),ySr=l(),zS=a("p"),xSr=o("This class cannot be instantiated directly using "),o6e=a("code"),$Sr=o("__init__()"),kSr=o(" (throws an error)."),SSr=l(),Qt=a("div"),F(QS.$$.fragment),RSr=l(),r6e=a("p"),PSr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),BSr=l(),Ym=a("p"),ISr=o(`Note:
Loading a model from its configuration file does `),t6e=a("strong"),NSr=o("not"),qSr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Roe=a("a"),jSr=o("from_pretrained()"),DSr=o(" to load the model weights."),GSr=l(),F(Z3.$$.fragment),OSr=l(),Eo=a("div"),F(WS.$$.fragment),VSr=l(),a6e=a("p"),XSr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),zSr=l(),$n=a("p"),QSr=o("The model class to instantiate is selected based on the "),n6e=a("code"),WSr=o("model_type"),USr=o(` property of the config object (either
passed as an argument or loaded from `),s6e=a("code"),HSr=o("pretrained_model_name_or_path"),JSr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l6e=a("code"),YSr=o("pretrained_model_name_or_path"),ZSr=o(":"),KSr=l(),_t=a("ul"),K3=a("li"),i6e=a("strong"),eRr=o("conditional_detr"),oRr=o(" \u2014 "),Poe=a("a"),rRr=o("ConditionalDetrForObjectDetection"),tRr=o(" (Conditional DETR model)"),aRr=l(),e5=a("li"),d6e=a("strong"),nRr=o("deformable_detr"),sRr=o(" \u2014 "),Boe=a("a"),lRr=o("DeformableDetrForObjectDetection"),iRr=o(" (Deformable DETR model)"),dRr=l(),o5=a("li"),m6e=a("strong"),mRr=o("detr"),cRr=o(" \u2014 "),Ioe=a("a"),fRr=o("DetrForObjectDetection"),gRr=o(" (DETR model)"),hRr=l(),r5=a("li"),c6e=a("strong"),uRr=o("table-transformer"),pRr=o(" \u2014 "),Noe=a("a"),_Rr=o("TableTransformerForObjectDetection"),bRr=o(" (Table Transformer model)"),vRr=l(),t5=a("li"),f6e=a("strong"),FRr=o("yolos"),TRr=o(" \u2014 "),qoe=a("a"),MRr=o("YolosForObjectDetection"),ERr=o(" (YOLOS model)"),CRr=l(),a5=a("p"),wRr=o("The model is set in evaluation mode by default using "),g6e=a("code"),ARr=o("model.eval()"),LRr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),h6e=a("code"),yRr=o("model.train()"),xRr=l(),F(n5.$$.fragment),Sao=l(),Zm=a("h2"),s5=a("a"),u6e=a("span"),F(US.$$.fragment),$Rr=l(),p6e=a("span"),kRr=o("AutoModelForImageSegmentation"),Rao=l(),sr=a("div"),F(HS.$$.fragment),SRr=l(),Km=a("p"),RRr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),joe=a("a"),PRr=o("from_pretrained()"),BRr=o(" class method or the "),Doe=a("a"),IRr=o("from_config()"),NRr=o(` class
method.`),qRr=l(),JS=a("p"),jRr=o("This class cannot be instantiated directly using "),_6e=a("code"),DRr=o("__init__()"),GRr=o(" (throws an error)."),ORr=l(),Wt=a("div"),F(YS.$$.fragment),VRr=l(),b6e=a("p"),XRr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),zRr=l(),ec=a("p"),QRr=o(`Note:
Loading a model from its configuration file does `),v6e=a("strong"),WRr=o("not"),URr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Goe=a("a"),HRr=o("from_pretrained()"),JRr=o(" to load the model weights."),YRr=l(),F(l5.$$.fragment),ZRr=l(),Co=a("div"),F(ZS.$$.fragment),KRr=l(),F6e=a("p"),ePr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),oPr=l(),kn=a("p"),rPr=o("The model class to instantiate is selected based on the "),T6e=a("code"),tPr=o("model_type"),aPr=o(` property of the config object (either
passed as an argument or loaded from `),M6e=a("code"),nPr=o("pretrained_model_name_or_path"),sPr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E6e=a("code"),lPr=o("pretrained_model_name_or_path"),iPr=o(":"),dPr=l(),C6e=a("ul"),i5=a("li"),w6e=a("strong"),mPr=o("detr"),cPr=o(" \u2014 "),Ooe=a("a"),fPr=o("DetrForSegmentation"),gPr=o(" (DETR model)"),hPr=l(),d5=a("p"),uPr=o("The model is set in evaluation mode by default using "),A6e=a("code"),pPr=o("model.eval()"),_Pr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),L6e=a("code"),bPr=o("model.train()"),vPr=l(),F(m5.$$.fragment),Pao=l(),oc=a("h2"),c5=a("a"),y6e=a("span"),F(KS.$$.fragment),FPr=l(),x6e=a("span"),TPr=o("AutoModelForSemanticSegmentation"),Bao=l(),lr=a("div"),F(eR.$$.fragment),MPr=l(),rc=a("p"),EPr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),Voe=a("a"),CPr=o("from_pretrained()"),wPr=o(" class method or the "),Xoe=a("a"),APr=o("from_config()"),LPr=o(` class
method.`),yPr=l(),oR=a("p"),xPr=o("This class cannot be instantiated directly using "),$6e=a("code"),$Pr=o("__init__()"),kPr=o(" (throws an error)."),SPr=l(),Ut=a("div"),F(rR.$$.fragment),RPr=l(),k6e=a("p"),PPr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),BPr=l(),tc=a("p"),IPr=o(`Note:
Loading a model from its configuration file does `),S6e=a("strong"),NPr=o("not"),qPr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zoe=a("a"),jPr=o("from_pretrained()"),DPr=o(" to load the model weights."),GPr=l(),F(f5.$$.fragment),OPr=l(),wo=a("div"),F(tR.$$.fragment),VPr=l(),R6e=a("p"),XPr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),zPr=l(),Sn=a("p"),QPr=o("The model class to instantiate is selected based on the "),P6e=a("code"),WPr=o("model_type"),UPr=o(` property of the config object (either
passed as an argument or loaded from `),B6e=a("code"),HPr=o("pretrained_model_name_or_path"),JPr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I6e=a("code"),YPr=o("pretrained_model_name_or_path"),ZPr=o(":"),KPr=l(),bt=a("ul"),g5=a("li"),N6e=a("strong"),eBr=o("beit"),oBr=o(" \u2014 "),Qoe=a("a"),rBr=o("BeitForSemanticSegmentation"),tBr=o(" (BEiT model)"),aBr=l(),h5=a("li"),q6e=a("strong"),nBr=o("data2vec-vision"),sBr=o(" \u2014 "),Woe=a("a"),lBr=o("Data2VecVisionForSemanticSegmentation"),iBr=o(" (Data2VecVision model)"),dBr=l(),u5=a("li"),j6e=a("strong"),mBr=o("dpt"),cBr=o(" \u2014 "),Uoe=a("a"),fBr=o("DPTForSemanticSegmentation"),gBr=o(" (DPT model)"),hBr=l(),p5=a("li"),D6e=a("strong"),uBr=o("mobilevit"),pBr=o(" \u2014 "),Hoe=a("a"),_Br=o("MobileViTForSemanticSegmentation"),bBr=o(" (MobileViT model)"),vBr=l(),_5=a("li"),G6e=a("strong"),FBr=o("segformer"),TBr=o(" \u2014 "),Joe=a("a"),MBr=o("SegformerForSemanticSegmentation"),EBr=o(" (SegFormer model)"),CBr=l(),b5=a("p"),wBr=o("The model is set in evaluation mode by default using "),O6e=a("code"),ABr=o("model.eval()"),LBr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),V6e=a("code"),yBr=o("model.train()"),xBr=l(),F(v5.$$.fragment),Iao=l(),ac=a("h2"),F5=a("a"),X6e=a("span"),F(aR.$$.fragment),$Br=l(),z6e=a("span"),kBr=o("AutoModelForInstanceSegmentation"),Nao=l(),ir=a("div"),F(nR.$$.fragment),SBr=l(),nc=a("p"),RBr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),Yoe=a("a"),PBr=o("from_pretrained()"),BBr=o(" class method or the "),Zoe=a("a"),IBr=o("from_config()"),NBr=o(` class
method.`),qBr=l(),sR=a("p"),jBr=o("This class cannot be instantiated directly using "),Q6e=a("code"),DBr=o("__init__()"),GBr=o(" (throws an error)."),OBr=l(),Ht=a("div"),F(lR.$$.fragment),VBr=l(),W6e=a("p"),XBr=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),zBr=l(),sc=a("p"),QBr=o(`Note:
Loading a model from its configuration file does `),U6e=a("strong"),WBr=o("not"),UBr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Koe=a("a"),HBr=o("from_pretrained()"),JBr=o(" to load the model weights."),YBr=l(),F(T5.$$.fragment),ZBr=l(),Ao=a("div"),F(iR.$$.fragment),KBr=l(),H6e=a("p"),eIr=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),oIr=l(),Rn=a("p"),rIr=o("The model class to instantiate is selected based on the "),J6e=a("code"),tIr=o("model_type"),aIr=o(` property of the config object (either
passed as an argument or loaded from `),Y6e=a("code"),nIr=o("pretrained_model_name_or_path"),sIr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Z6e=a("code"),lIr=o("pretrained_model_name_or_path"),iIr=o(":"),dIr=l(),K6e=a("ul"),M5=a("li"),e7e=a("strong"),mIr=o("maskformer"),cIr=o(" \u2014 "),ere=a("a"),fIr=o("MaskFormerForInstanceSegmentation"),gIr=o(" (MaskFormer model)"),hIr=l(),E5=a("p"),uIr=o("The model is set in evaluation mode by default using "),o7e=a("code"),pIr=o("model.eval()"),_Ir=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),r7e=a("code"),bIr=o("model.train()"),vIr=l(),F(C5.$$.fragment),qao=l(),lc=a("h2"),w5=a("a"),t7e=a("span"),F(dR.$$.fragment),FIr=l(),a7e=a("span"),TIr=o("AutoModelForZeroShotObjectDetection"),jao=l(),dr=a("div"),F(mR.$$.fragment),MIr=l(),ic=a("p"),EIr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a zero-shot object detection head) when created
with the `),ore=a("a"),CIr=o("from_pretrained()"),wIr=o(" class method or the "),rre=a("a"),AIr=o("from_config()"),LIr=o(` class
method.`),yIr=l(),cR=a("p"),xIr=o("This class cannot be instantiated directly using "),n7e=a("code"),$Ir=o("__init__()"),kIr=o(" (throws an error)."),SIr=l(),Jt=a("div"),F(fR.$$.fragment),RIr=l(),s7e=a("p"),PIr=o("Instantiates one of the model classes of the library (with a zero-shot object detection head) from a configuration."),BIr=l(),dc=a("p"),IIr=o(`Note:
Loading a model from its configuration file does `),l7e=a("strong"),NIr=o("not"),qIr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tre=a("a"),jIr=o("from_pretrained()"),DIr=o(" to load the model weights."),GIr=l(),F(A5.$$.fragment),OIr=l(),Lo=a("div"),F(gR.$$.fragment),VIr=l(),i7e=a("p"),XIr=o("Instantiate one of the model classes of the library (with a zero-shot object detection head) from a pretrained model."),zIr=l(),Pn=a("p"),QIr=o("The model class to instantiate is selected based on the "),d7e=a("code"),WIr=o("model_type"),UIr=o(` property of the config object (either
passed as an argument or loaded from `),m7e=a("code"),HIr=o("pretrained_model_name_or_path"),JIr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c7e=a("code"),YIr=o("pretrained_model_name_or_path"),ZIr=o(":"),KIr=l(),f7e=a("ul"),L5=a("li"),g7e=a("strong"),eNr=o("owlvit"),oNr=o(" \u2014 "),are=a("a"),rNr=o("OwlViTForObjectDetection"),tNr=o(" (OWL-ViT model)"),aNr=l(),y5=a("p"),nNr=o("The model is set in evaluation mode by default using "),h7e=a("code"),sNr=o("model.eval()"),lNr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),u7e=a("code"),iNr=o("model.train()"),dNr=l(),F(x5.$$.fragment),Dao=l(),mc=a("h2"),$5=a("a"),p7e=a("span"),F(hR.$$.fragment),mNr=l(),_7e=a("span"),cNr=o("TFAutoModel"),Gao=l(),mr=a("div"),F(uR.$$.fragment),fNr=l(),cc=a("p"),gNr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),nre=a("a"),hNr=o("from_pretrained()"),uNr=o(" class method or the "),sre=a("a"),pNr=o("from_config()"),_Nr=o(` class
method.`),bNr=l(),pR=a("p"),vNr=o("This class cannot be instantiated directly using "),b7e=a("code"),FNr=o("__init__()"),TNr=o(" (throws an error)."),MNr=l(),Yt=a("div"),F(_R.$$.fragment),ENr=l(),v7e=a("p"),CNr=o("Instantiates one of the base model classes of the library from a configuration."),wNr=l(),fc=a("p"),ANr=o(`Note:
Loading a model from its configuration file does `),F7e=a("strong"),LNr=o("not"),yNr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lre=a("a"),xNr=o("from_pretrained()"),$Nr=o(" to load the model weights."),kNr=l(),F(k5.$$.fragment),SNr=l(),Dr=a("div"),F(bR.$$.fragment),RNr=l(),T7e=a("p"),PNr=o("Instantiate one of the base model classes of the library from a pretrained model."),BNr=l(),Bn=a("p"),INr=o("The model class to instantiate is selected based on the "),M7e=a("code"),NNr=o("model_type"),qNr=o(` property of the config object (either
passed as an argument or loaded from `),E7e=a("code"),jNr=o("pretrained_model_name_or_path"),DNr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C7e=a("code"),GNr=o("pretrained_model_name_or_path"),ONr=o(":"),VNr=l(),P=a("ul"),S5=a("li"),w7e=a("strong"),XNr=o("albert"),zNr=o(" \u2014 "),ire=a("a"),QNr=o("TFAlbertModel"),WNr=o(" (ALBERT model)"),UNr=l(),R5=a("li"),A7e=a("strong"),HNr=o("bart"),JNr=o(" \u2014 "),dre=a("a"),YNr=o("TFBartModel"),ZNr=o(" (BART model)"),KNr=l(),P5=a("li"),L7e=a("strong"),eqr=o("bert"),oqr=o(" \u2014 "),mre=a("a"),rqr=o("TFBertModel"),tqr=o(" (BERT model)"),aqr=l(),B5=a("li"),y7e=a("strong"),nqr=o("blenderbot"),sqr=o(" \u2014 "),cre=a("a"),lqr=o("TFBlenderbotModel"),iqr=o(" (Blenderbot model)"),dqr=l(),I5=a("li"),x7e=a("strong"),mqr=o("blenderbot-small"),cqr=o(" \u2014 "),fre=a("a"),fqr=o("TFBlenderbotSmallModel"),gqr=o(" (BlenderbotSmall model)"),hqr=l(),N5=a("li"),$7e=a("strong"),uqr=o("camembert"),pqr=o(" \u2014 "),gre=a("a"),_qr=o("TFCamembertModel"),bqr=o(" (CamemBERT model)"),vqr=l(),q5=a("li"),k7e=a("strong"),Fqr=o("clip"),Tqr=o(" \u2014 "),hre=a("a"),Mqr=o("TFCLIPModel"),Eqr=o(" (CLIP model)"),Cqr=l(),j5=a("li"),S7e=a("strong"),wqr=o("convbert"),Aqr=o(" \u2014 "),ure=a("a"),Lqr=o("TFConvBertModel"),yqr=o(" (ConvBERT model)"),xqr=l(),D5=a("li"),R7e=a("strong"),$qr=o("convnext"),kqr=o(" \u2014 "),pre=a("a"),Sqr=o("TFConvNextModel"),Rqr=o(" (ConvNeXT model)"),Pqr=l(),G5=a("li"),P7e=a("strong"),Bqr=o("ctrl"),Iqr=o(" \u2014 "),_re=a("a"),Nqr=o("TFCTRLModel"),qqr=o(" (CTRL model)"),jqr=l(),O5=a("li"),B7e=a("strong"),Dqr=o("cvt"),Gqr=o(" \u2014 "),bre=a("a"),Oqr=o("TFCvtModel"),Vqr=o(" (CvT model)"),Xqr=l(),V5=a("li"),I7e=a("strong"),zqr=o("data2vec-vision"),Qqr=o(" \u2014 "),vre=a("a"),Wqr=o("TFData2VecVisionModel"),Uqr=o(" (Data2VecVision model)"),Hqr=l(),X5=a("li"),N7e=a("strong"),Jqr=o("deberta"),Yqr=o(" \u2014 "),Fre=a("a"),Zqr=o("TFDebertaModel"),Kqr=o(" (DeBERTa model)"),ejr=l(),z5=a("li"),q7e=a("strong"),ojr=o("deberta-v2"),rjr=o(" \u2014 "),Tre=a("a"),tjr=o("TFDebertaV2Model"),ajr=o(" (DeBERTa-v2 model)"),njr=l(),Q5=a("li"),j7e=a("strong"),sjr=o("deit"),ljr=o(" \u2014 "),Mre=a("a"),ijr=o("TFDeiTModel"),djr=o(" (DeiT model)"),mjr=l(),W5=a("li"),D7e=a("strong"),cjr=o("distilbert"),fjr=o(" \u2014 "),Ere=a("a"),gjr=o("TFDistilBertModel"),hjr=o(" (DistilBERT model)"),ujr=l(),U5=a("li"),G7e=a("strong"),pjr=o("dpr"),_jr=o(" \u2014 "),Cre=a("a"),bjr=o("TFDPRQuestionEncoder"),vjr=o(" (DPR model)"),Fjr=l(),H5=a("li"),O7e=a("strong"),Tjr=o("electra"),Mjr=o(" \u2014 "),wre=a("a"),Ejr=o("TFElectraModel"),Cjr=o(" (ELECTRA model)"),wjr=l(),J5=a("li"),V7e=a("strong"),Ajr=o("esm"),Ljr=o(" \u2014 "),Are=a("a"),yjr=o("TFEsmModel"),xjr=o(" (ESM model)"),$jr=l(),Y5=a("li"),X7e=a("strong"),kjr=o("flaubert"),Sjr=o(" \u2014 "),Lre=a("a"),Rjr=o("TFFlaubertModel"),Pjr=o(" (FlauBERT model)"),Bjr=l(),Sl=a("li"),z7e=a("strong"),Ijr=o("funnel"),Njr=o(" \u2014 "),yre=a("a"),qjr=o("TFFunnelModel"),jjr=o(" or "),xre=a("a"),Djr=o("TFFunnelBaseModel"),Gjr=o(" (Funnel Transformer model)"),Ojr=l(),Z5=a("li"),Q7e=a("strong"),Vjr=o("gpt2"),Xjr=o(" \u2014 "),$re=a("a"),zjr=o("TFGPT2Model"),Qjr=o(" (OpenAI GPT-2 model)"),Wjr=l(),K5=a("li"),W7e=a("strong"),Ujr=o("gptj"),Hjr=o(" \u2014 "),kre=a("a"),Jjr=o("TFGPTJModel"),Yjr=o(" (GPT-J model)"),Zjr=l(),e0=a("li"),U7e=a("strong"),Kjr=o("groupvit"),eDr=o(" \u2014 "),Sre=a("a"),oDr=o("TFGroupViTModel"),rDr=o(" (GroupViT model)"),tDr=l(),o0=a("li"),H7e=a("strong"),aDr=o("hubert"),nDr=o(" \u2014 "),Rre=a("a"),sDr=o("TFHubertModel"),lDr=o(" (Hubert model)"),iDr=l(),r0=a("li"),J7e=a("strong"),dDr=o("layoutlm"),mDr=o(" \u2014 "),Pre=a("a"),cDr=o("TFLayoutLMModel"),fDr=o(" (LayoutLM model)"),gDr=l(),t0=a("li"),Y7e=a("strong"),hDr=o("layoutlmv3"),uDr=o(" \u2014 "),Bre=a("a"),pDr=o("TFLayoutLMv3Model"),_Dr=o(" (LayoutLMv3 model)"),bDr=l(),a0=a("li"),Z7e=a("strong"),vDr=o("led"),FDr=o(" \u2014 "),Ire=a("a"),TDr=o("TFLEDModel"),MDr=o(" (LED model)"),EDr=l(),n0=a("li"),K7e=a("strong"),CDr=o("longformer"),wDr=o(" \u2014 "),Nre=a("a"),ADr=o("TFLongformerModel"),LDr=o(" (Longformer model)"),yDr=l(),s0=a("li"),e8e=a("strong"),xDr=o("lxmert"),$Dr=o(" \u2014 "),qre=a("a"),kDr=o("TFLxmertModel"),SDr=o(" (LXMERT model)"),RDr=l(),l0=a("li"),o8e=a("strong"),PDr=o("marian"),BDr=o(" \u2014 "),jre=a("a"),IDr=o("TFMarianModel"),NDr=o(" (Marian model)"),qDr=l(),i0=a("li"),r8e=a("strong"),jDr=o("mbart"),DDr=o(" \u2014 "),Dre=a("a"),GDr=o("TFMBartModel"),ODr=o(" (mBART model)"),VDr=l(),d0=a("li"),t8e=a("strong"),XDr=o("mobilebert"),zDr=o(" \u2014 "),Gre=a("a"),QDr=o("TFMobileBertModel"),WDr=o(" (MobileBERT model)"),UDr=l(),m0=a("li"),a8e=a("strong"),HDr=o("mobilevit"),JDr=o(" \u2014 "),Ore=a("a"),YDr=o("TFMobileViTModel"),ZDr=o(" (MobileViT model)"),KDr=l(),c0=a("li"),n8e=a("strong"),eGr=o("mpnet"),oGr=o(" \u2014 "),Vre=a("a"),rGr=o("TFMPNetModel"),tGr=o(" (MPNet model)"),aGr=l(),f0=a("li"),s8e=a("strong"),nGr=o("mt5"),sGr=o(" \u2014 "),Xre=a("a"),lGr=o("TFMT5Model"),iGr=o(" (MT5 model)"),dGr=l(),g0=a("li"),l8e=a("strong"),mGr=o("openai-gpt"),cGr=o(" \u2014 "),zre=a("a"),fGr=o("TFOpenAIGPTModel"),gGr=o(" (OpenAI GPT model)"),hGr=l(),h0=a("li"),i8e=a("strong"),uGr=o("opt"),pGr=o(" \u2014 "),Qre=a("a"),_Gr=o("TFOPTModel"),bGr=o(" (OPT model)"),vGr=l(),u0=a("li"),d8e=a("strong"),FGr=o("pegasus"),TGr=o(" \u2014 "),Wre=a("a"),MGr=o("TFPegasusModel"),EGr=o(" (Pegasus model)"),CGr=l(),p0=a("li"),m8e=a("strong"),wGr=o("regnet"),AGr=o(" \u2014 "),Ure=a("a"),LGr=o("TFRegNetModel"),yGr=o(" (RegNet model)"),xGr=l(),_0=a("li"),c8e=a("strong"),$Gr=o("rembert"),kGr=o(" \u2014 "),Hre=a("a"),SGr=o("TFRemBertModel"),RGr=o(" (RemBERT model)"),PGr=l(),b0=a("li"),f8e=a("strong"),BGr=o("resnet"),IGr=o(" \u2014 "),Jre=a("a"),NGr=o("TFResNetModel"),qGr=o(" (ResNet model)"),jGr=l(),v0=a("li"),g8e=a("strong"),DGr=o("roberta"),GGr=o(" \u2014 "),Yre=a("a"),OGr=o("TFRobertaModel"),VGr=o(" (RoBERTa model)"),XGr=l(),F0=a("li"),h8e=a("strong"),zGr=o("roformer"),QGr=o(" \u2014 "),Zre=a("a"),WGr=o("TFRoFormerModel"),UGr=o(" (RoFormer model)"),HGr=l(),T0=a("li"),u8e=a("strong"),JGr=o("segformer"),YGr=o(" \u2014 "),Kre=a("a"),ZGr=o("TFSegformerModel"),KGr=o(" (SegFormer model)"),eOr=l(),M0=a("li"),p8e=a("strong"),oOr=o("speech_to_text"),rOr=o(" \u2014 "),ete=a("a"),tOr=o("TFSpeech2TextModel"),aOr=o(" (Speech2Text model)"),nOr=l(),E0=a("li"),_8e=a("strong"),sOr=o("swin"),lOr=o(" \u2014 "),ote=a("a"),iOr=o("TFSwinModel"),dOr=o(" (Swin Transformer model)"),mOr=l(),C0=a("li"),b8e=a("strong"),cOr=o("t5"),fOr=o(" \u2014 "),rte=a("a"),gOr=o("TFT5Model"),hOr=o(" (T5 model)"),uOr=l(),w0=a("li"),v8e=a("strong"),pOr=o("tapas"),_Or=o(" \u2014 "),tte=a("a"),bOr=o("TFTapasModel"),vOr=o(" (TAPAS model)"),FOr=l(),A0=a("li"),F8e=a("strong"),TOr=o("transfo-xl"),MOr=o(" \u2014 "),ate=a("a"),EOr=o("TFTransfoXLModel"),COr=o(" (Transformer-XL model)"),wOr=l(),L0=a("li"),T8e=a("strong"),AOr=o("vit"),LOr=o(" \u2014 "),nte=a("a"),yOr=o("TFViTModel"),xOr=o(" (ViT model)"),$Or=l(),y0=a("li"),M8e=a("strong"),kOr=o("vit_mae"),SOr=o(" \u2014 "),ste=a("a"),ROr=o("TFViTMAEModel"),POr=o(" (ViTMAE model)"),BOr=l(),x0=a("li"),E8e=a("strong"),IOr=o("wav2vec2"),NOr=o(" \u2014 "),lte=a("a"),qOr=o("TFWav2Vec2Model"),jOr=o(" (Wav2Vec2 model)"),DOr=l(),$0=a("li"),C8e=a("strong"),GOr=o("whisper"),OOr=o(" \u2014 "),ite=a("a"),VOr=o("TFWhisperModel"),XOr=o(" (Whisper model)"),zOr=l(),k0=a("li"),w8e=a("strong"),QOr=o("xglm"),WOr=o(" \u2014 "),dte=a("a"),UOr=o("TFXGLMModel"),HOr=o(" (XGLM model)"),JOr=l(),S0=a("li"),A8e=a("strong"),YOr=o("xlm"),ZOr=o(" \u2014 "),mte=a("a"),KOr=o("TFXLMModel"),eVr=o(" (XLM model)"),oVr=l(),R0=a("li"),L8e=a("strong"),rVr=o("xlm-roberta"),tVr=o(" \u2014 "),cte=a("a"),aVr=o("TFXLMRobertaModel"),nVr=o(" (XLM-RoBERTa model)"),sVr=l(),P0=a("li"),y8e=a("strong"),lVr=o("xlnet"),iVr=o(" \u2014 "),fte=a("a"),dVr=o("TFXLNetModel"),mVr=o(" (XLNet model)"),cVr=l(),F(B0.$$.fragment),Oao=l(),gc=a("h2"),I0=a("a"),x8e=a("span"),F(vR.$$.fragment),fVr=l(),$8e=a("span"),gVr=o("TFAutoModelForPreTraining"),Vao=l(),cr=a("div"),F(FR.$$.fragment),hVr=l(),hc=a("p"),uVr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),gte=a("a"),pVr=o("from_pretrained()"),_Vr=o(" class method or the "),hte=a("a"),bVr=o("from_config()"),vVr=o(` class
method.`),FVr=l(),TR=a("p"),TVr=o("This class cannot be instantiated directly using "),k8e=a("code"),MVr=o("__init__()"),EVr=o(" (throws an error)."),CVr=l(),Zt=a("div"),F(MR.$$.fragment),wVr=l(),S8e=a("p"),AVr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),LVr=l(),uc=a("p"),yVr=o(`Note:
Loading a model from its configuration file does `),R8e=a("strong"),xVr=o("not"),$Vr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ute=a("a"),kVr=o("from_pretrained()"),SVr=o(" to load the model weights."),RVr=l(),F(N0.$$.fragment),PVr=l(),Gr=a("div"),F(ER.$$.fragment),BVr=l(),P8e=a("p"),IVr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),NVr=l(),In=a("p"),qVr=o("The model class to instantiate is selected based on the "),B8e=a("code"),jVr=o("model_type"),DVr=o(` property of the config object (either
passed as an argument or loaded from `),I8e=a("code"),GVr=o("pretrained_model_name_or_path"),OVr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N8e=a("code"),VVr=o("pretrained_model_name_or_path"),XVr=o(":"),zVr=l(),se=a("ul"),q0=a("li"),q8e=a("strong"),QVr=o("albert"),WVr=o(" \u2014 "),pte=a("a"),UVr=o("TFAlbertForPreTraining"),HVr=o(" (ALBERT model)"),JVr=l(),j0=a("li"),j8e=a("strong"),YVr=o("bart"),ZVr=o(" \u2014 "),_te=a("a"),KVr=o("TFBartForConditionalGeneration"),eXr=o(" (BART model)"),oXr=l(),D0=a("li"),D8e=a("strong"),rXr=o("bert"),tXr=o(" \u2014 "),bte=a("a"),aXr=o("TFBertForPreTraining"),nXr=o(" (BERT model)"),sXr=l(),G0=a("li"),G8e=a("strong"),lXr=o("camembert"),iXr=o(" \u2014 "),vte=a("a"),dXr=o("TFCamembertForMaskedLM"),mXr=o(" (CamemBERT model)"),cXr=l(),O0=a("li"),O8e=a("strong"),fXr=o("ctrl"),gXr=o(" \u2014 "),Fte=a("a"),hXr=o("TFCTRLLMHeadModel"),uXr=o(" (CTRL model)"),pXr=l(),V0=a("li"),V8e=a("strong"),_Xr=o("distilbert"),bXr=o(" \u2014 "),Tte=a("a"),vXr=o("TFDistilBertForMaskedLM"),FXr=o(" (DistilBERT model)"),TXr=l(),X0=a("li"),X8e=a("strong"),MXr=o("electra"),EXr=o(" \u2014 "),Mte=a("a"),CXr=o("TFElectraForPreTraining"),wXr=o(" (ELECTRA model)"),AXr=l(),z0=a("li"),z8e=a("strong"),LXr=o("flaubert"),yXr=o(" \u2014 "),Ete=a("a"),xXr=o("TFFlaubertWithLMHeadModel"),$Xr=o(" (FlauBERT model)"),kXr=l(),Q0=a("li"),Q8e=a("strong"),SXr=o("funnel"),RXr=o(" \u2014 "),Cte=a("a"),PXr=o("TFFunnelForPreTraining"),BXr=o(" (Funnel Transformer model)"),IXr=l(),W0=a("li"),W8e=a("strong"),NXr=o("gpt2"),qXr=o(" \u2014 "),wte=a("a"),jXr=o("TFGPT2LMHeadModel"),DXr=o(" (OpenAI GPT-2 model)"),GXr=l(),U0=a("li"),U8e=a("strong"),OXr=o("layoutlm"),VXr=o(" \u2014 "),Ate=a("a"),XXr=o("TFLayoutLMForMaskedLM"),zXr=o(" (LayoutLM model)"),QXr=l(),H0=a("li"),H8e=a("strong"),WXr=o("lxmert"),UXr=o(" \u2014 "),Lte=a("a"),HXr=o("TFLxmertForPreTraining"),JXr=o(" (LXMERT model)"),YXr=l(),J0=a("li"),J8e=a("strong"),ZXr=o("mobilebert"),KXr=o(" \u2014 "),yte=a("a"),ezr=o("TFMobileBertForPreTraining"),ozr=o(" (MobileBERT model)"),rzr=l(),Y0=a("li"),Y8e=a("strong"),tzr=o("mpnet"),azr=o(" \u2014 "),xte=a("a"),nzr=o("TFMPNetForMaskedLM"),szr=o(" (MPNet model)"),lzr=l(),Z0=a("li"),Z8e=a("strong"),izr=o("openai-gpt"),dzr=o(" \u2014 "),$te=a("a"),mzr=o("TFOpenAIGPTLMHeadModel"),czr=o(" (OpenAI GPT model)"),fzr=l(),K0=a("li"),K8e=a("strong"),gzr=o("roberta"),hzr=o(" \u2014 "),kte=a("a"),uzr=o("TFRobertaForMaskedLM"),pzr=o(" (RoBERTa model)"),_zr=l(),ew=a("li"),eLe=a("strong"),bzr=o("t5"),vzr=o(" \u2014 "),Ste=a("a"),Fzr=o("TFT5ForConditionalGeneration"),Tzr=o(" (T5 model)"),Mzr=l(),ow=a("li"),oLe=a("strong"),Ezr=o("tapas"),Czr=o(" \u2014 "),Rte=a("a"),wzr=o("TFTapasForMaskedLM"),Azr=o(" (TAPAS model)"),Lzr=l(),rw=a("li"),rLe=a("strong"),yzr=o("transfo-xl"),xzr=o(" \u2014 "),Pte=a("a"),$zr=o("TFTransfoXLLMHeadModel"),kzr=o(" (Transformer-XL model)"),Szr=l(),tw=a("li"),tLe=a("strong"),Rzr=o("vit_mae"),Pzr=o(" \u2014 "),Bte=a("a"),Bzr=o("TFViTMAEForPreTraining"),Izr=o(" (ViTMAE model)"),Nzr=l(),aw=a("li"),aLe=a("strong"),qzr=o("xlm"),jzr=o(" \u2014 "),Ite=a("a"),Dzr=o("TFXLMWithLMHeadModel"),Gzr=o(" (XLM model)"),Ozr=l(),nw=a("li"),nLe=a("strong"),Vzr=o("xlm-roberta"),Xzr=o(" \u2014 "),Nte=a("a"),zzr=o("TFXLMRobertaForMaskedLM"),Qzr=o(" (XLM-RoBERTa model)"),Wzr=l(),sw=a("li"),sLe=a("strong"),Uzr=o("xlnet"),Hzr=o(" \u2014 "),qte=a("a"),Jzr=o("TFXLNetLMHeadModel"),Yzr=o(" (XLNet model)"),Zzr=l(),F(lw.$$.fragment),Xao=l(),pc=a("h2"),iw=a("a"),lLe=a("span"),F(CR.$$.fragment),Kzr=l(),iLe=a("span"),eQr=o("TFAutoModelForCausalLM"),zao=l(),fr=a("div"),F(wR.$$.fragment),oQr=l(),_c=a("p"),rQr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),jte=a("a"),tQr=o("from_pretrained()"),aQr=o(" class method or the "),Dte=a("a"),nQr=o("from_config()"),sQr=o(` class
method.`),lQr=l(),AR=a("p"),iQr=o("This class cannot be instantiated directly using "),dLe=a("code"),dQr=o("__init__()"),mQr=o(" (throws an error)."),cQr=l(),Kt=a("div"),F(LR.$$.fragment),fQr=l(),mLe=a("p"),gQr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),hQr=l(),bc=a("p"),uQr=o(`Note:
Loading a model from its configuration file does `),cLe=a("strong"),pQr=o("not"),_Qr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Gte=a("a"),bQr=o("from_pretrained()"),vQr=o(" to load the model weights."),FQr=l(),F(dw.$$.fragment),TQr=l(),Or=a("div"),F(yR.$$.fragment),MQr=l(),fLe=a("p"),EQr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),CQr=l(),Nn=a("p"),wQr=o("The model class to instantiate is selected based on the "),gLe=a("code"),AQr=o("model_type"),LQr=o(` property of the config object (either
passed as an argument or loaded from `),hLe=a("code"),yQr=o("pretrained_model_name_or_path"),xQr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uLe=a("code"),$Qr=o("pretrained_model_name_or_path"),kQr=o(":"),SQr=l(),Me=a("ul"),mw=a("li"),pLe=a("strong"),RQr=o("bert"),PQr=o(" \u2014 "),Ote=a("a"),BQr=o("TFBertLMHeadModel"),IQr=o(" (BERT model)"),NQr=l(),cw=a("li"),_Le=a("strong"),qQr=o("camembert"),jQr=o(" \u2014 "),Vte=a("a"),DQr=o("TFCamembertForCausalLM"),GQr=o(" (CamemBERT model)"),OQr=l(),fw=a("li"),bLe=a("strong"),VQr=o("ctrl"),XQr=o(" \u2014 "),Xte=a("a"),zQr=o("TFCTRLLMHeadModel"),QQr=o(" (CTRL model)"),WQr=l(),gw=a("li"),vLe=a("strong"),UQr=o("gpt2"),HQr=o(" \u2014 "),zte=a("a"),JQr=o("TFGPT2LMHeadModel"),YQr=o(" (OpenAI GPT-2 model)"),ZQr=l(),hw=a("li"),FLe=a("strong"),KQr=o("gptj"),eWr=o(" \u2014 "),Qte=a("a"),oWr=o("TFGPTJForCausalLM"),rWr=o(" (GPT-J model)"),tWr=l(),uw=a("li"),TLe=a("strong"),aWr=o("openai-gpt"),nWr=o(" \u2014 "),Wte=a("a"),sWr=o("TFOpenAIGPTLMHeadModel"),lWr=o(" (OpenAI GPT model)"),iWr=l(),pw=a("li"),MLe=a("strong"),dWr=o("opt"),mWr=o(" \u2014 "),Ute=a("a"),cWr=o("TFOPTForCausalLM"),fWr=o(" (OPT model)"),gWr=l(),_w=a("li"),ELe=a("strong"),hWr=o("rembert"),uWr=o(" \u2014 "),Hte=a("a"),pWr=o("TFRemBertForCausalLM"),_Wr=o(" (RemBERT model)"),bWr=l(),bw=a("li"),CLe=a("strong"),vWr=o("roberta"),FWr=o(" \u2014 "),Jte=a("a"),TWr=o("TFRobertaForCausalLM"),MWr=o(" (RoBERTa model)"),EWr=l(),vw=a("li"),wLe=a("strong"),CWr=o("roformer"),wWr=o(" \u2014 "),Yte=a("a"),AWr=o("TFRoFormerForCausalLM"),LWr=o(" (RoFormer model)"),yWr=l(),Fw=a("li"),ALe=a("strong"),xWr=o("transfo-xl"),$Wr=o(" \u2014 "),Zte=a("a"),kWr=o("TFTransfoXLLMHeadModel"),SWr=o(" (Transformer-XL model)"),RWr=l(),Tw=a("li"),LLe=a("strong"),PWr=o("xglm"),BWr=o(" \u2014 "),Kte=a("a"),IWr=o("TFXGLMForCausalLM"),NWr=o(" (XGLM model)"),qWr=l(),Mw=a("li"),yLe=a("strong"),jWr=o("xlm"),DWr=o(" \u2014 "),eae=a("a"),GWr=o("TFXLMWithLMHeadModel"),OWr=o(" (XLM model)"),VWr=l(),Ew=a("li"),xLe=a("strong"),XWr=o("xlnet"),zWr=o(" \u2014 "),oae=a("a"),QWr=o("TFXLNetLMHeadModel"),WWr=o(" (XLNet model)"),UWr=l(),F(Cw.$$.fragment),Qao=l(),vc=a("h2"),ww=a("a"),$Le=a("span"),F(xR.$$.fragment),HWr=l(),kLe=a("span"),JWr=o("TFAutoModelForImageClassification"),Wao=l(),gr=a("div"),F($R.$$.fragment),YWr=l(),Fc=a("p"),ZWr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),rae=a("a"),KWr=o("from_pretrained()"),eUr=o(" class method or the "),tae=a("a"),oUr=o("from_config()"),rUr=o(` class
method.`),tUr=l(),kR=a("p"),aUr=o("This class cannot be instantiated directly using "),SLe=a("code"),nUr=o("__init__()"),sUr=o(" (throws an error)."),lUr=l(),ea=a("div"),F(SR.$$.fragment),iUr=l(),RLe=a("p"),dUr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),mUr=l(),Tc=a("p"),cUr=o(`Note:
Loading a model from its configuration file does `),PLe=a("strong"),fUr=o("not"),gUr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),aae=a("a"),hUr=o("from_pretrained()"),uUr=o(" to load the model weights."),pUr=l(),F(Aw.$$.fragment),_Ur=l(),Vr=a("div"),F(RR.$$.fragment),bUr=l(),BLe=a("p"),vUr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),FUr=l(),qn=a("p"),TUr=o("The model class to instantiate is selected based on the "),ILe=a("code"),MUr=o("model_type"),EUr=o(` property of the config object (either
passed as an argument or loaded from `),NLe=a("code"),CUr=o("pretrained_model_name_or_path"),wUr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qLe=a("code"),AUr=o("pretrained_model_name_or_path"),LUr=o(":"),yUr=l(),ye=a("ul"),Lw=a("li"),jLe=a("strong"),xUr=o("convnext"),$Ur=o(" \u2014 "),nae=a("a"),kUr=o("TFConvNextForImageClassification"),SUr=o(" (ConvNeXT model)"),RUr=l(),yw=a("li"),DLe=a("strong"),PUr=o("cvt"),BUr=o(" \u2014 "),sae=a("a"),IUr=o("TFCvtForImageClassification"),NUr=o(" (CvT model)"),qUr=l(),xw=a("li"),GLe=a("strong"),jUr=o("data2vec-vision"),DUr=o(" \u2014 "),lae=a("a"),GUr=o("TFData2VecVisionForImageClassification"),OUr=o(" (Data2VecVision model)"),VUr=l(),Rl=a("li"),OLe=a("strong"),XUr=o("deit"),zUr=o(" \u2014 "),iae=a("a"),QUr=o("TFDeiTForImageClassification"),WUr=o(" or "),dae=a("a"),UUr=o("TFDeiTForImageClassificationWithTeacher"),HUr=o(" (DeiT model)"),JUr=l(),$w=a("li"),VLe=a("strong"),YUr=o("mobilevit"),ZUr=o(" \u2014 "),mae=a("a"),KUr=o("TFMobileViTForImageClassification"),eHr=o(" (MobileViT model)"),oHr=l(),kw=a("li"),XLe=a("strong"),rHr=o("regnet"),tHr=o(" \u2014 "),cae=a("a"),aHr=o("TFRegNetForImageClassification"),nHr=o(" (RegNet model)"),sHr=l(),Sw=a("li"),zLe=a("strong"),lHr=o("resnet"),iHr=o(" \u2014 "),fae=a("a"),dHr=o("TFResNetForImageClassification"),mHr=o(" (ResNet model)"),cHr=l(),Rw=a("li"),QLe=a("strong"),fHr=o("segformer"),gHr=o(" \u2014 "),gae=a("a"),hHr=o("TFSegformerForImageClassification"),uHr=o(" (SegFormer model)"),pHr=l(),Pw=a("li"),WLe=a("strong"),_Hr=o("swin"),bHr=o(" \u2014 "),hae=a("a"),vHr=o("TFSwinForImageClassification"),FHr=o(" (Swin Transformer model)"),THr=l(),Bw=a("li"),ULe=a("strong"),MHr=o("vit"),EHr=o(" \u2014 "),uae=a("a"),CHr=o("TFViTForImageClassification"),wHr=o(" (ViT model)"),AHr=l(),F(Iw.$$.fragment),Uao=l(),Mc=a("h2"),Nw=a("a"),HLe=a("span"),F(PR.$$.fragment),LHr=l(),JLe=a("span"),yHr=o("TFAutoModelForSemanticSegmentation"),Hao=l(),hr=a("div"),F(BR.$$.fragment),xHr=l(),Ec=a("p"),$Hr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),pae=a("a"),kHr=o("from_pretrained()"),SHr=o(" class method or the "),_ae=a("a"),RHr=o("from_config()"),PHr=o(` class
method.`),BHr=l(),IR=a("p"),IHr=o("This class cannot be instantiated directly using "),YLe=a("code"),NHr=o("__init__()"),qHr=o(" (throws an error)."),jHr=l(),oa=a("div"),F(NR.$$.fragment),DHr=l(),ZLe=a("p"),GHr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),OHr=l(),Cc=a("p"),VHr=o(`Note:
Loading a model from its configuration file does `),KLe=a("strong"),XHr=o("not"),zHr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bae=a("a"),QHr=o("from_pretrained()"),WHr=o(" to load the model weights."),UHr=l(),F(qw.$$.fragment),HHr=l(),Xr=a("div"),F(qR.$$.fragment),JHr=l(),eye=a("p"),YHr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),ZHr=l(),jn=a("p"),KHr=o("The model class to instantiate is selected based on the "),oye=a("code"),eJr=o("model_type"),oJr=o(` property of the config object (either
passed as an argument or loaded from `),rye=a("code"),rJr=o("pretrained_model_name_or_path"),tJr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tye=a("code"),aJr=o("pretrained_model_name_or_path"),nJr=o(":"),sJr=l(),wc=a("ul"),jw=a("li"),aye=a("strong"),lJr=o("data2vec-vision"),iJr=o(" \u2014 "),vae=a("a"),dJr=o("TFData2VecVisionForSemanticSegmentation"),mJr=o(" (Data2VecVision model)"),cJr=l(),Dw=a("li"),nye=a("strong"),fJr=o("mobilevit"),gJr=o(" \u2014 "),Fae=a("a"),hJr=o("TFMobileViTForSemanticSegmentation"),uJr=o(" (MobileViT model)"),pJr=l(),Gw=a("li"),sye=a("strong"),_Jr=o("segformer"),bJr=o(" \u2014 "),Tae=a("a"),vJr=o("TFSegformerForSemanticSegmentation"),FJr=o(" (SegFormer model)"),TJr=l(),F(Ow.$$.fragment),Jao=l(),Ac=a("h2"),Vw=a("a"),lye=a("span"),F(jR.$$.fragment),MJr=l(),iye=a("span"),EJr=o("TFAutoModelForMaskedLM"),Yao=l(),ur=a("div"),F(DR.$$.fragment),CJr=l(),Lc=a("p"),wJr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Mae=a("a"),AJr=o("from_pretrained()"),LJr=o(" class method or the "),Eae=a("a"),yJr=o("from_config()"),xJr=o(` class
method.`),$Jr=l(),GR=a("p"),kJr=o("This class cannot be instantiated directly using "),dye=a("code"),SJr=o("__init__()"),RJr=o(" (throws an error)."),PJr=l(),ra=a("div"),F(OR.$$.fragment),BJr=l(),mye=a("p"),IJr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),NJr=l(),yc=a("p"),qJr=o(`Note:
Loading a model from its configuration file does `),cye=a("strong"),jJr=o("not"),DJr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Cae=a("a"),GJr=o("from_pretrained()"),OJr=o(" to load the model weights."),VJr=l(),F(Xw.$$.fragment),XJr=l(),zr=a("div"),F(VR.$$.fragment),zJr=l(),fye=a("p"),QJr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),WJr=l(),Dn=a("p"),UJr=o("The model class to instantiate is selected based on the "),gye=a("code"),HJr=o("model_type"),JJr=o(` property of the config object (either
passed as an argument or loaded from `),hye=a("code"),YJr=o("pretrained_model_name_or_path"),ZJr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uye=a("code"),KJr=o("pretrained_model_name_or_path"),eYr=o(":"),oYr=l(),me=a("ul"),zw=a("li"),pye=a("strong"),rYr=o("albert"),tYr=o(" \u2014 "),wae=a("a"),aYr=o("TFAlbertForMaskedLM"),nYr=o(" (ALBERT model)"),sYr=l(),Qw=a("li"),_ye=a("strong"),lYr=o("bert"),iYr=o(" \u2014 "),Aae=a("a"),dYr=o("TFBertForMaskedLM"),mYr=o(" (BERT model)"),cYr=l(),Ww=a("li"),bye=a("strong"),fYr=o("camembert"),gYr=o(" \u2014 "),Lae=a("a"),hYr=o("TFCamembertForMaskedLM"),uYr=o(" (CamemBERT model)"),pYr=l(),Uw=a("li"),vye=a("strong"),_Yr=o("convbert"),bYr=o(" \u2014 "),yae=a("a"),vYr=o("TFConvBertForMaskedLM"),FYr=o(" (ConvBERT model)"),TYr=l(),Hw=a("li"),Fye=a("strong"),MYr=o("deberta"),EYr=o(" \u2014 "),xae=a("a"),CYr=o("TFDebertaForMaskedLM"),wYr=o(" (DeBERTa model)"),AYr=l(),Jw=a("li"),Tye=a("strong"),LYr=o("deberta-v2"),yYr=o(" \u2014 "),$ae=a("a"),xYr=o("TFDebertaV2ForMaskedLM"),$Yr=o(" (DeBERTa-v2 model)"),kYr=l(),Yw=a("li"),Mye=a("strong"),SYr=o("distilbert"),RYr=o(" \u2014 "),kae=a("a"),PYr=o("TFDistilBertForMaskedLM"),BYr=o(" (DistilBERT model)"),IYr=l(),Zw=a("li"),Eye=a("strong"),NYr=o("electra"),qYr=o(" \u2014 "),Sae=a("a"),jYr=o("TFElectraForMaskedLM"),DYr=o(" (ELECTRA model)"),GYr=l(),Kw=a("li"),Cye=a("strong"),OYr=o("esm"),VYr=o(" \u2014 "),Rae=a("a"),XYr=o("TFEsmForMaskedLM"),zYr=o(" (ESM model)"),QYr=l(),eA=a("li"),wye=a("strong"),WYr=o("flaubert"),UYr=o(" \u2014 "),Pae=a("a"),HYr=o("TFFlaubertWithLMHeadModel"),JYr=o(" (FlauBERT model)"),YYr=l(),oA=a("li"),Aye=a("strong"),ZYr=o("funnel"),KYr=o(" \u2014 "),Bae=a("a"),eZr=o("TFFunnelForMaskedLM"),oZr=o(" (Funnel Transformer model)"),rZr=l(),rA=a("li"),Lye=a("strong"),tZr=o("layoutlm"),aZr=o(" \u2014 "),Iae=a("a"),nZr=o("TFLayoutLMForMaskedLM"),sZr=o(" (LayoutLM model)"),lZr=l(),tA=a("li"),yye=a("strong"),iZr=o("longformer"),dZr=o(" \u2014 "),Nae=a("a"),mZr=o("TFLongformerForMaskedLM"),cZr=o(" (Longformer model)"),fZr=l(),aA=a("li"),xye=a("strong"),gZr=o("mobilebert"),hZr=o(" \u2014 "),qae=a("a"),uZr=o("TFMobileBertForMaskedLM"),pZr=o(" (MobileBERT model)"),_Zr=l(),nA=a("li"),$ye=a("strong"),bZr=o("mpnet"),vZr=o(" \u2014 "),jae=a("a"),FZr=o("TFMPNetForMaskedLM"),TZr=o(" (MPNet model)"),MZr=l(),sA=a("li"),kye=a("strong"),EZr=o("rembert"),CZr=o(" \u2014 "),Dae=a("a"),wZr=o("TFRemBertForMaskedLM"),AZr=o(" (RemBERT model)"),LZr=l(),lA=a("li"),Sye=a("strong"),yZr=o("roberta"),xZr=o(" \u2014 "),Gae=a("a"),$Zr=o("TFRobertaForMaskedLM"),kZr=o(" (RoBERTa model)"),SZr=l(),iA=a("li"),Rye=a("strong"),RZr=o("roformer"),PZr=o(" \u2014 "),Oae=a("a"),BZr=o("TFRoFormerForMaskedLM"),IZr=o(" (RoFormer model)"),NZr=l(),dA=a("li"),Pye=a("strong"),qZr=o("tapas"),jZr=o(" \u2014 "),Vae=a("a"),DZr=o("TFTapasForMaskedLM"),GZr=o(" (TAPAS model)"),OZr=l(),mA=a("li"),Bye=a("strong"),VZr=o("xlm"),XZr=o(" \u2014 "),Xae=a("a"),zZr=o("TFXLMWithLMHeadModel"),QZr=o(" (XLM model)"),WZr=l(),cA=a("li"),Iye=a("strong"),UZr=o("xlm-roberta"),HZr=o(" \u2014 "),zae=a("a"),JZr=o("TFXLMRobertaForMaskedLM"),YZr=o(" (XLM-RoBERTa model)"),ZZr=l(),F(fA.$$.fragment),Zao=l(),xc=a("h2"),gA=a("a"),Nye=a("span"),F(XR.$$.fragment),KZr=l(),qye=a("span"),eKr=o("TFAutoModelForSeq2SeqLM"),Kao=l(),pr=a("div"),F(zR.$$.fragment),oKr=l(),$c=a("p"),rKr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Qae=a("a"),tKr=o("from_pretrained()"),aKr=o(" class method or the "),Wae=a("a"),nKr=o("from_config()"),sKr=o(` class
method.`),lKr=l(),QR=a("p"),iKr=o("This class cannot be instantiated directly using "),jye=a("code"),dKr=o("__init__()"),mKr=o(" (throws an error)."),cKr=l(),ta=a("div"),F(WR.$$.fragment),fKr=l(),Dye=a("p"),gKr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),hKr=l(),kc=a("p"),uKr=o(`Note:
Loading a model from its configuration file does `),Gye=a("strong"),pKr=o("not"),_Kr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Uae=a("a"),bKr=o("from_pretrained()"),vKr=o(" to load the model weights."),FKr=l(),F(hA.$$.fragment),TKr=l(),Qr=a("div"),F(UR.$$.fragment),MKr=l(),Oye=a("p"),EKr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),CKr=l(),Gn=a("p"),wKr=o("The model class to instantiate is selected based on the "),Vye=a("code"),AKr=o("model_type"),LKr=o(` property of the config object (either
passed as an argument or loaded from `),Xye=a("code"),yKr=o("pretrained_model_name_or_path"),xKr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zye=a("code"),$Kr=o("pretrained_model_name_or_path"),kKr=o(":"),SKr=l(),xe=a("ul"),uA=a("li"),Qye=a("strong"),RKr=o("bart"),PKr=o(" \u2014 "),Hae=a("a"),BKr=o("TFBartForConditionalGeneration"),IKr=o(" (BART model)"),NKr=l(),pA=a("li"),Wye=a("strong"),qKr=o("blenderbot"),jKr=o(" \u2014 "),Jae=a("a"),DKr=o("TFBlenderbotForConditionalGeneration"),GKr=o(" (Blenderbot model)"),OKr=l(),_A=a("li"),Uye=a("strong"),VKr=o("blenderbot-small"),XKr=o(" \u2014 "),Yae=a("a"),zKr=o("TFBlenderbotSmallForConditionalGeneration"),QKr=o(" (BlenderbotSmall model)"),WKr=l(),bA=a("li"),Hye=a("strong"),UKr=o("encoder-decoder"),HKr=o(" \u2014 "),Zae=a("a"),JKr=o("TFEncoderDecoderModel"),YKr=o(" (Encoder decoder model)"),ZKr=l(),vA=a("li"),Jye=a("strong"),KKr=o("led"),eet=o(" \u2014 "),Kae=a("a"),oet=o("TFLEDForConditionalGeneration"),ret=o(" (LED model)"),tet=l(),FA=a("li"),Yye=a("strong"),aet=o("marian"),net=o(" \u2014 "),ene=a("a"),set=o("TFMarianMTModel"),iet=o(" (Marian model)"),det=l(),TA=a("li"),Zye=a("strong"),met=o("mbart"),cet=o(" \u2014 "),one=a("a"),fet=o("TFMBartForConditionalGeneration"),get=o(" (mBART model)"),het=l(),MA=a("li"),Kye=a("strong"),uet=o("mt5"),pet=o(" \u2014 "),rne=a("a"),_et=o("TFMT5ForConditionalGeneration"),bet=o(" (MT5 model)"),vet=l(),EA=a("li"),e9e=a("strong"),Fet=o("pegasus"),Tet=o(" \u2014 "),tne=a("a"),Met=o("TFPegasusForConditionalGeneration"),Eet=o(" (Pegasus model)"),Cet=l(),CA=a("li"),o9e=a("strong"),wet=o("t5"),Aet=o(" \u2014 "),ane=a("a"),Let=o("TFT5ForConditionalGeneration"),yet=o(" (T5 model)"),xet=l(),F(wA.$$.fragment),eno=l(),Sc=a("h2"),AA=a("a"),r9e=a("span"),F(HR.$$.fragment),$et=l(),t9e=a("span"),ket=o("TFAutoModelForSequenceClassification"),ono=l(),_r=a("div"),F(JR.$$.fragment),Set=l(),Rc=a("p"),Ret=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),nne=a("a"),Pet=o("from_pretrained()"),Bet=o(" class method or the "),sne=a("a"),Iet=o("from_config()"),Net=o(` class
method.`),qet=l(),YR=a("p"),jet=o("This class cannot be instantiated directly using "),a9e=a("code"),Det=o("__init__()"),Get=o(" (throws an error)."),Oet=l(),aa=a("div"),F(ZR.$$.fragment),Vet=l(),n9e=a("p"),Xet=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),zet=l(),Pc=a("p"),Qet=o(`Note:
Loading a model from its configuration file does `),s9e=a("strong"),Wet=o("not"),Uet=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lne=a("a"),Het=o("from_pretrained()"),Jet=o(" to load the model weights."),Yet=l(),F(LA.$$.fragment),Zet=l(),Wr=a("div"),F(KR.$$.fragment),Ket=l(),l9e=a("p"),eot=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),oot=l(),On=a("p"),rot=o("The model class to instantiate is selected based on the "),i9e=a("code"),tot=o("model_type"),aot=o(` property of the config object (either
passed as an argument or loaded from `),d9e=a("code"),not=o("pretrained_model_name_or_path"),sot=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m9e=a("code"),lot=o("pretrained_model_name_or_path"),iot=o(":"),dot=l(),re=a("ul"),yA=a("li"),c9e=a("strong"),mot=o("albert"),cot=o(" \u2014 "),ine=a("a"),fot=o("TFAlbertForSequenceClassification"),got=o(" (ALBERT model)"),hot=l(),xA=a("li"),f9e=a("strong"),uot=o("bert"),pot=o(" \u2014 "),dne=a("a"),_ot=o("TFBertForSequenceClassification"),bot=o(" (BERT model)"),vot=l(),$A=a("li"),g9e=a("strong"),Fot=o("camembert"),Tot=o(" \u2014 "),mne=a("a"),Mot=o("TFCamembertForSequenceClassification"),Eot=o(" (CamemBERT model)"),Cot=l(),kA=a("li"),h9e=a("strong"),wot=o("convbert"),Aot=o(" \u2014 "),cne=a("a"),Lot=o("TFConvBertForSequenceClassification"),yot=o(" (ConvBERT model)"),xot=l(),SA=a("li"),u9e=a("strong"),$ot=o("ctrl"),kot=o(" \u2014 "),fne=a("a"),Sot=o("TFCTRLForSequenceClassification"),Rot=o(" (CTRL model)"),Pot=l(),RA=a("li"),p9e=a("strong"),Bot=o("deberta"),Iot=o(" \u2014 "),gne=a("a"),Not=o("TFDebertaForSequenceClassification"),qot=o(" (DeBERTa model)"),jot=l(),PA=a("li"),_9e=a("strong"),Dot=o("deberta-v2"),Got=o(" \u2014 "),hne=a("a"),Oot=o("TFDebertaV2ForSequenceClassification"),Vot=o(" (DeBERTa-v2 model)"),Xot=l(),BA=a("li"),b9e=a("strong"),zot=o("distilbert"),Qot=o(" \u2014 "),une=a("a"),Wot=o("TFDistilBertForSequenceClassification"),Uot=o(" (DistilBERT model)"),Hot=l(),IA=a("li"),v9e=a("strong"),Jot=o("electra"),Yot=o(" \u2014 "),pne=a("a"),Zot=o("TFElectraForSequenceClassification"),Kot=o(" (ELECTRA model)"),ert=l(),NA=a("li"),F9e=a("strong"),ort=o("esm"),rrt=o(" \u2014 "),_ne=a("a"),trt=o("TFEsmForSequenceClassification"),art=o(" (ESM model)"),nrt=l(),qA=a("li"),T9e=a("strong"),srt=o("flaubert"),lrt=o(" \u2014 "),bne=a("a"),irt=o("TFFlaubertForSequenceClassification"),drt=o(" (FlauBERT model)"),mrt=l(),jA=a("li"),M9e=a("strong"),crt=o("funnel"),frt=o(" \u2014 "),vne=a("a"),grt=o("TFFunnelForSequenceClassification"),hrt=o(" (Funnel Transformer model)"),urt=l(),DA=a("li"),E9e=a("strong"),prt=o("gpt2"),_rt=o(" \u2014 "),Fne=a("a"),brt=o("TFGPT2ForSequenceClassification"),vrt=o(" (OpenAI GPT-2 model)"),Frt=l(),GA=a("li"),C9e=a("strong"),Trt=o("gptj"),Mrt=o(" \u2014 "),Tne=a("a"),Ert=o("TFGPTJForSequenceClassification"),Crt=o(" (GPT-J model)"),wrt=l(),OA=a("li"),w9e=a("strong"),Art=o("layoutlm"),Lrt=o(" \u2014 "),Mne=a("a"),yrt=o("TFLayoutLMForSequenceClassification"),xrt=o(" (LayoutLM model)"),$rt=l(),VA=a("li"),A9e=a("strong"),krt=o("layoutlmv3"),Srt=o(" \u2014 "),Ene=a("a"),Rrt=o("TFLayoutLMv3ForSequenceClassification"),Prt=o(" (LayoutLMv3 model)"),Brt=l(),XA=a("li"),L9e=a("strong"),Irt=o("longformer"),Nrt=o(" \u2014 "),Cne=a("a"),qrt=o("TFLongformerForSequenceClassification"),jrt=o(" (Longformer model)"),Drt=l(),zA=a("li"),y9e=a("strong"),Grt=o("mobilebert"),Ort=o(" \u2014 "),wne=a("a"),Vrt=o("TFMobileBertForSequenceClassification"),Xrt=o(" (MobileBERT model)"),zrt=l(),QA=a("li"),x9e=a("strong"),Qrt=o("mpnet"),Wrt=o(" \u2014 "),Ane=a("a"),Urt=o("TFMPNetForSequenceClassification"),Hrt=o(" (MPNet model)"),Jrt=l(),WA=a("li"),$9e=a("strong"),Yrt=o("openai-gpt"),Zrt=o(" \u2014 "),Lne=a("a"),Krt=o("TFOpenAIGPTForSequenceClassification"),ett=o(" (OpenAI GPT model)"),ott=l(),UA=a("li"),k9e=a("strong"),rtt=o("rembert"),ttt=o(" \u2014 "),yne=a("a"),att=o("TFRemBertForSequenceClassification"),ntt=o(" (RemBERT model)"),stt=l(),HA=a("li"),S9e=a("strong"),ltt=o("roberta"),itt=o(" \u2014 "),xne=a("a"),dtt=o("TFRobertaForSequenceClassification"),mtt=o(" (RoBERTa model)"),ctt=l(),JA=a("li"),R9e=a("strong"),ftt=o("roformer"),gtt=o(" \u2014 "),$ne=a("a"),htt=o("TFRoFormerForSequenceClassification"),utt=o(" (RoFormer model)"),ptt=l(),YA=a("li"),P9e=a("strong"),_tt=o("tapas"),btt=o(" \u2014 "),kne=a("a"),vtt=o("TFTapasForSequenceClassification"),Ftt=o(" (TAPAS model)"),Ttt=l(),ZA=a("li"),B9e=a("strong"),Mtt=o("transfo-xl"),Ett=o(" \u2014 "),Sne=a("a"),Ctt=o("TFTransfoXLForSequenceClassification"),wtt=o(" (Transformer-XL model)"),Att=l(),KA=a("li"),I9e=a("strong"),Ltt=o("xlm"),ytt=o(" \u2014 "),Rne=a("a"),xtt=o("TFXLMForSequenceClassification"),$tt=o(" (XLM model)"),ktt=l(),e6=a("li"),N9e=a("strong"),Stt=o("xlm-roberta"),Rtt=o(" \u2014 "),Pne=a("a"),Ptt=o("TFXLMRobertaForSequenceClassification"),Btt=o(" (XLM-RoBERTa model)"),Itt=l(),o6=a("li"),q9e=a("strong"),Ntt=o("xlnet"),qtt=o(" \u2014 "),Bne=a("a"),jtt=o("TFXLNetForSequenceClassification"),Dtt=o(" (XLNet model)"),Gtt=l(),F(r6.$$.fragment),rno=l(),Bc=a("h2"),t6=a("a"),j9e=a("span"),F(eP.$$.fragment),Ott=l(),D9e=a("span"),Vtt=o("TFAutoModelForMultipleChoice"),tno=l(),br=a("div"),F(oP.$$.fragment),Xtt=l(),Ic=a("p"),ztt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Ine=a("a"),Qtt=o("from_pretrained()"),Wtt=o(" class method or the "),Nne=a("a"),Utt=o("from_config()"),Htt=o(` class
method.`),Jtt=l(),rP=a("p"),Ytt=o("This class cannot be instantiated directly using "),G9e=a("code"),Ztt=o("__init__()"),Ktt=o(" (throws an error)."),eat=l(),na=a("div"),F(tP.$$.fragment),oat=l(),O9e=a("p"),rat=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),tat=l(),Nc=a("p"),aat=o(`Note:
Loading a model from its configuration file does `),V9e=a("strong"),nat=o("not"),sat=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qne=a("a"),lat=o("from_pretrained()"),iat=o(" to load the model weights."),dat=l(),F(a6.$$.fragment),mat=l(),Ur=a("div"),F(aP.$$.fragment),cat=l(),X9e=a("p"),fat=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),gat=l(),Vn=a("p"),hat=o("The model class to instantiate is selected based on the "),z9e=a("code"),uat=o("model_type"),pat=o(` property of the config object (either
passed as an argument or loaded from `),Q9e=a("code"),_at=o("pretrained_model_name_or_path"),bat=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W9e=a("code"),vat=o("pretrained_model_name_or_path"),Fat=o(":"),Tat=l(),ve=a("ul"),n6=a("li"),U9e=a("strong"),Mat=o("albert"),Eat=o(" \u2014 "),jne=a("a"),Cat=o("TFAlbertForMultipleChoice"),wat=o(" (ALBERT model)"),Aat=l(),s6=a("li"),H9e=a("strong"),Lat=o("bert"),yat=o(" \u2014 "),Dne=a("a"),xat=o("TFBertForMultipleChoice"),$at=o(" (BERT model)"),kat=l(),l6=a("li"),J9e=a("strong"),Sat=o("camembert"),Rat=o(" \u2014 "),Gne=a("a"),Pat=o("TFCamembertForMultipleChoice"),Bat=o(" (CamemBERT model)"),Iat=l(),i6=a("li"),Y9e=a("strong"),Nat=o("convbert"),qat=o(" \u2014 "),One=a("a"),jat=o("TFConvBertForMultipleChoice"),Dat=o(" (ConvBERT model)"),Gat=l(),d6=a("li"),Z9e=a("strong"),Oat=o("distilbert"),Vat=o(" \u2014 "),Vne=a("a"),Xat=o("TFDistilBertForMultipleChoice"),zat=o(" (DistilBERT model)"),Qat=l(),m6=a("li"),K9e=a("strong"),Wat=o("electra"),Uat=o(" \u2014 "),Xne=a("a"),Hat=o("TFElectraForMultipleChoice"),Jat=o(" (ELECTRA model)"),Yat=l(),c6=a("li"),exe=a("strong"),Zat=o("flaubert"),Kat=o(" \u2014 "),zne=a("a"),ent=o("TFFlaubertForMultipleChoice"),ont=o(" (FlauBERT model)"),rnt=l(),f6=a("li"),oxe=a("strong"),tnt=o("funnel"),ant=o(" \u2014 "),Qne=a("a"),nnt=o("TFFunnelForMultipleChoice"),snt=o(" (Funnel Transformer model)"),lnt=l(),g6=a("li"),rxe=a("strong"),int=o("longformer"),dnt=o(" \u2014 "),Wne=a("a"),mnt=o("TFLongformerForMultipleChoice"),cnt=o(" (Longformer model)"),fnt=l(),h6=a("li"),txe=a("strong"),gnt=o("mobilebert"),hnt=o(" \u2014 "),Une=a("a"),unt=o("TFMobileBertForMultipleChoice"),pnt=o(" (MobileBERT model)"),_nt=l(),u6=a("li"),axe=a("strong"),bnt=o("mpnet"),vnt=o(" \u2014 "),Hne=a("a"),Fnt=o("TFMPNetForMultipleChoice"),Tnt=o(" (MPNet model)"),Mnt=l(),p6=a("li"),nxe=a("strong"),Ent=o("rembert"),Cnt=o(" \u2014 "),Jne=a("a"),wnt=o("TFRemBertForMultipleChoice"),Ant=o(" (RemBERT model)"),Lnt=l(),_6=a("li"),sxe=a("strong"),ynt=o("roberta"),xnt=o(" \u2014 "),Yne=a("a"),$nt=o("TFRobertaForMultipleChoice"),knt=o(" (RoBERTa model)"),Snt=l(),b6=a("li"),lxe=a("strong"),Rnt=o("roformer"),Pnt=o(" \u2014 "),Zne=a("a"),Bnt=o("TFRoFormerForMultipleChoice"),Int=o(" (RoFormer model)"),Nnt=l(),v6=a("li"),ixe=a("strong"),qnt=o("xlm"),jnt=o(" \u2014 "),Kne=a("a"),Dnt=o("TFXLMForMultipleChoice"),Gnt=o(" (XLM model)"),Ont=l(),F6=a("li"),dxe=a("strong"),Vnt=o("xlm-roberta"),Xnt=o(" \u2014 "),ese=a("a"),znt=o("TFXLMRobertaForMultipleChoice"),Qnt=o(" (XLM-RoBERTa model)"),Wnt=l(),T6=a("li"),mxe=a("strong"),Unt=o("xlnet"),Hnt=o(" \u2014 "),ose=a("a"),Jnt=o("TFXLNetForMultipleChoice"),Ynt=o(" (XLNet model)"),Znt=l(),F(M6.$$.fragment),ano=l(),qc=a("h2"),E6=a("a"),cxe=a("span"),F(nP.$$.fragment),Knt=l(),fxe=a("span"),est=o("TFAutoModelForNextSentencePrediction"),nno=l(),vr=a("div"),F(sP.$$.fragment),ost=l(),jc=a("p"),rst=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),rse=a("a"),tst=o("from_pretrained()"),ast=o(" class method or the "),tse=a("a"),nst=o("from_config()"),sst=o(` class
method.`),lst=l(),lP=a("p"),ist=o("This class cannot be instantiated directly using "),gxe=a("code"),dst=o("__init__()"),mst=o(" (throws an error)."),cst=l(),sa=a("div"),F(iP.$$.fragment),fst=l(),hxe=a("p"),gst=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),hst=l(),Dc=a("p"),ust=o(`Note:
Loading a model from its configuration file does `),uxe=a("strong"),pst=o("not"),_st=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ase=a("a"),bst=o("from_pretrained()"),vst=o(" to load the model weights."),Fst=l(),F(C6.$$.fragment),Tst=l(),Hr=a("div"),F(dP.$$.fragment),Mst=l(),pxe=a("p"),Est=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Cst=l(),Xn=a("p"),wst=o("The model class to instantiate is selected based on the "),_xe=a("code"),Ast=o("model_type"),Lst=o(` property of the config object (either
passed as an argument or loaded from `),bxe=a("code"),yst=o("pretrained_model_name_or_path"),xst=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vxe=a("code"),$st=o("pretrained_model_name_or_path"),kst=o(":"),Sst=l(),mP=a("ul"),w6=a("li"),Fxe=a("strong"),Rst=o("bert"),Pst=o(" \u2014 "),nse=a("a"),Bst=o("TFBertForNextSentencePrediction"),Ist=o(" (BERT model)"),Nst=l(),A6=a("li"),Txe=a("strong"),qst=o("mobilebert"),jst=o(" \u2014 "),sse=a("a"),Dst=o("TFMobileBertForNextSentencePrediction"),Gst=o(" (MobileBERT model)"),Ost=l(),F(L6.$$.fragment),sno=l(),Gc=a("h2"),y6=a("a"),Mxe=a("span"),F(cP.$$.fragment),Vst=l(),Exe=a("span"),Xst=o("TFAutoModelForTableQuestionAnswering"),lno=l(),Fr=a("div"),F(fP.$$.fragment),zst=l(),Oc=a("p"),Qst=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),lse=a("a"),Wst=o("from_pretrained()"),Ust=o(" class method or the "),ise=a("a"),Hst=o("from_config()"),Jst=o(` class
method.`),Yst=l(),gP=a("p"),Zst=o("This class cannot be instantiated directly using "),Cxe=a("code"),Kst=o("__init__()"),elt=o(" (throws an error)."),olt=l(),la=a("div"),F(hP.$$.fragment),rlt=l(),wxe=a("p"),tlt=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),alt=l(),Vc=a("p"),nlt=o(`Note:
Loading a model from its configuration file does `),Axe=a("strong"),slt=o("not"),llt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dse=a("a"),ilt=o("from_pretrained()"),dlt=o(" to load the model weights."),mlt=l(),F(x6.$$.fragment),clt=l(),Jr=a("div"),F(uP.$$.fragment),flt=l(),Lxe=a("p"),glt=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),hlt=l(),zn=a("p"),ult=o("The model class to instantiate is selected based on the "),yxe=a("code"),plt=o("model_type"),_lt=o(` property of the config object (either
passed as an argument or loaded from `),xxe=a("code"),blt=o("pretrained_model_name_or_path"),vlt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$xe=a("code"),Flt=o("pretrained_model_name_or_path"),Tlt=o(":"),Mlt=l(),kxe=a("ul"),$6=a("li"),Sxe=a("strong"),Elt=o("tapas"),Clt=o(" \u2014 "),mse=a("a"),wlt=o("TFTapasForQuestionAnswering"),Alt=o(" (TAPAS model)"),Llt=l(),F(k6.$$.fragment),ino=l(),Xc=a("h2"),S6=a("a"),Rxe=a("span"),F(pP.$$.fragment),ylt=l(),Pxe=a("span"),xlt=o("TFAutoModelForDocumentQuestionAnswering"),dno=l(),Tr=a("div"),F(_P.$$.fragment),$lt=l(),zc=a("p"),klt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),cse=a("a"),Slt=o("from_pretrained()"),Rlt=o(" class method or the "),fse=a("a"),Plt=o("from_config()"),Blt=o(` class
method.`),Ilt=l(),bP=a("p"),Nlt=o("This class cannot be instantiated directly using "),Bxe=a("code"),qlt=o("__init__()"),jlt=o(" (throws an error)."),Dlt=l(),ia=a("div"),F(vP.$$.fragment),Glt=l(),Ixe=a("p"),Olt=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),Vlt=l(),Qc=a("p"),Xlt=o(`Note:
Loading a model from its configuration file does `),Nxe=a("strong"),zlt=o("not"),Qlt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gse=a("a"),Wlt=o("from_pretrained()"),Ult=o(" to load the model weights."),Hlt=l(),F(R6.$$.fragment),Jlt=l(),Yr=a("div"),F(FP.$$.fragment),Ylt=l(),qxe=a("p"),Zlt=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),Klt=l(),Qn=a("p"),eit=o("The model class to instantiate is selected based on the "),jxe=a("code"),oit=o("model_type"),rit=o(` property of the config object (either
passed as an argument or loaded from `),Dxe=a("code"),tit=o("pretrained_model_name_or_path"),ait=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gxe=a("code"),nit=o("pretrained_model_name_or_path"),sit=o(":"),lit=l(),Oxe=a("ul"),P6=a("li"),Vxe=a("strong"),iit=o("layoutlm"),dit=o(" \u2014 "),hse=a("a"),mit=o("TFLayoutLMForQuestionAnswering"),cit=o(" (LayoutLM model)"),fit=l(),F(B6.$$.fragment),mno=l(),Wc=a("h2"),I6=a("a"),Xxe=a("span"),F(TP.$$.fragment),git=l(),zxe=a("span"),hit=o("TFAutoModelForTokenClassification"),cno=l(),Mr=a("div"),F(MP.$$.fragment),uit=l(),Uc=a("p"),pit=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),use=a("a"),_it=o("from_pretrained()"),bit=o(" class method or the "),pse=a("a"),vit=o("from_config()"),Fit=o(` class
method.`),Tit=l(),EP=a("p"),Mit=o("This class cannot be instantiated directly using "),Qxe=a("code"),Eit=o("__init__()"),Cit=o(" (throws an error)."),wit=l(),da=a("div"),F(CP.$$.fragment),Ait=l(),Wxe=a("p"),Lit=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),yit=l(),Hc=a("p"),xit=o(`Note:
Loading a model from its configuration file does `),Uxe=a("strong"),$it=o("not"),kit=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_se=a("a"),Sit=o("from_pretrained()"),Rit=o(" to load the model weights."),Pit=l(),F(N6.$$.fragment),Bit=l(),Zr=a("div"),F(wP.$$.fragment),Iit=l(),Hxe=a("p"),Nit=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),qit=l(),Wn=a("p"),jit=o("The model class to instantiate is selected based on the "),Jxe=a("code"),Dit=o("model_type"),Git=o(` property of the config object (either
passed as an argument or loaded from `),Yxe=a("code"),Oit=o("pretrained_model_name_or_path"),Vit=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zxe=a("code"),Xit=o("pretrained_model_name_or_path"),zit=o(":"),Qit=l(),ie=a("ul"),q6=a("li"),Kxe=a("strong"),Wit=o("albert"),Uit=o(" \u2014 "),bse=a("a"),Hit=o("TFAlbertForTokenClassification"),Jit=o(" (ALBERT model)"),Yit=l(),j6=a("li"),e$e=a("strong"),Zit=o("bert"),Kit=o(" \u2014 "),vse=a("a"),edt=o("TFBertForTokenClassification"),odt=o(" (BERT model)"),rdt=l(),D6=a("li"),o$e=a("strong"),tdt=o("camembert"),adt=o(" \u2014 "),Fse=a("a"),ndt=o("TFCamembertForTokenClassification"),sdt=o(" (CamemBERT model)"),ldt=l(),G6=a("li"),r$e=a("strong"),idt=o("convbert"),ddt=o(" \u2014 "),Tse=a("a"),mdt=o("TFConvBertForTokenClassification"),cdt=o(" (ConvBERT model)"),fdt=l(),O6=a("li"),t$e=a("strong"),gdt=o("deberta"),hdt=o(" \u2014 "),Mse=a("a"),udt=o("TFDebertaForTokenClassification"),pdt=o(" (DeBERTa model)"),_dt=l(),V6=a("li"),a$e=a("strong"),bdt=o("deberta-v2"),vdt=o(" \u2014 "),Ese=a("a"),Fdt=o("TFDebertaV2ForTokenClassification"),Tdt=o(" (DeBERTa-v2 model)"),Mdt=l(),X6=a("li"),n$e=a("strong"),Edt=o("distilbert"),Cdt=o(" \u2014 "),Cse=a("a"),wdt=o("TFDistilBertForTokenClassification"),Adt=o(" (DistilBERT model)"),Ldt=l(),z6=a("li"),s$e=a("strong"),ydt=o("electra"),xdt=o(" \u2014 "),wse=a("a"),$dt=o("TFElectraForTokenClassification"),kdt=o(" (ELECTRA model)"),Sdt=l(),Q6=a("li"),l$e=a("strong"),Rdt=o("esm"),Pdt=o(" \u2014 "),Ase=a("a"),Bdt=o("TFEsmForTokenClassification"),Idt=o(" (ESM model)"),Ndt=l(),W6=a("li"),i$e=a("strong"),qdt=o("flaubert"),jdt=o(" \u2014 "),Lse=a("a"),Ddt=o("TFFlaubertForTokenClassification"),Gdt=o(" (FlauBERT model)"),Odt=l(),U6=a("li"),d$e=a("strong"),Vdt=o("funnel"),Xdt=o(" \u2014 "),yse=a("a"),zdt=o("TFFunnelForTokenClassification"),Qdt=o(" (Funnel Transformer model)"),Wdt=l(),H6=a("li"),m$e=a("strong"),Udt=o("layoutlm"),Hdt=o(" \u2014 "),xse=a("a"),Jdt=o("TFLayoutLMForTokenClassification"),Ydt=o(" (LayoutLM model)"),Zdt=l(),J6=a("li"),c$e=a("strong"),Kdt=o("layoutlmv3"),emt=o(" \u2014 "),$se=a("a"),omt=o("TFLayoutLMv3ForTokenClassification"),rmt=o(" (LayoutLMv3 model)"),tmt=l(),Y6=a("li"),f$e=a("strong"),amt=o("longformer"),nmt=o(" \u2014 "),kse=a("a"),smt=o("TFLongformerForTokenClassification"),lmt=o(" (Longformer model)"),imt=l(),Z6=a("li"),g$e=a("strong"),dmt=o("mobilebert"),mmt=o(" \u2014 "),Sse=a("a"),cmt=o("TFMobileBertForTokenClassification"),fmt=o(" (MobileBERT model)"),gmt=l(),K6=a("li"),h$e=a("strong"),hmt=o("mpnet"),umt=o(" \u2014 "),Rse=a("a"),pmt=o("TFMPNetForTokenClassification"),_mt=o(" (MPNet model)"),bmt=l(),e7=a("li"),u$e=a("strong"),vmt=o("rembert"),Fmt=o(" \u2014 "),Pse=a("a"),Tmt=o("TFRemBertForTokenClassification"),Mmt=o(" (RemBERT model)"),Emt=l(),o7=a("li"),p$e=a("strong"),Cmt=o("roberta"),wmt=o(" \u2014 "),Bse=a("a"),Amt=o("TFRobertaForTokenClassification"),Lmt=o(" (RoBERTa model)"),ymt=l(),r7=a("li"),_$e=a("strong"),xmt=o("roformer"),$mt=o(" \u2014 "),Ise=a("a"),kmt=o("TFRoFormerForTokenClassification"),Smt=o(" (RoFormer model)"),Rmt=l(),t7=a("li"),b$e=a("strong"),Pmt=o("xlm"),Bmt=o(" \u2014 "),Nse=a("a"),Imt=o("TFXLMForTokenClassification"),Nmt=o(" (XLM model)"),qmt=l(),a7=a("li"),v$e=a("strong"),jmt=o("xlm-roberta"),Dmt=o(" \u2014 "),qse=a("a"),Gmt=o("TFXLMRobertaForTokenClassification"),Omt=o(" (XLM-RoBERTa model)"),Vmt=l(),n7=a("li"),F$e=a("strong"),Xmt=o("xlnet"),zmt=o(" \u2014 "),jse=a("a"),Qmt=o("TFXLNetForTokenClassification"),Wmt=o(" (XLNet model)"),Umt=l(),F(s7.$$.fragment),fno=l(),Jc=a("h2"),l7=a("a"),T$e=a("span"),F(AP.$$.fragment),Hmt=l(),M$e=a("span"),Jmt=o("TFAutoModelForQuestionAnswering"),gno=l(),Er=a("div"),F(LP.$$.fragment),Ymt=l(),Yc=a("p"),Zmt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Dse=a("a"),Kmt=o("from_pretrained()"),ect=o(" class method or the "),Gse=a("a"),oct=o("from_config()"),rct=o(` class
method.`),tct=l(),yP=a("p"),act=o("This class cannot be instantiated directly using "),E$e=a("code"),nct=o("__init__()"),sct=o(" (throws an error)."),lct=l(),ma=a("div"),F(xP.$$.fragment),ict=l(),C$e=a("p"),dct=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),mct=l(),Zc=a("p"),cct=o(`Note:
Loading a model from its configuration file does `),w$e=a("strong"),fct=o("not"),gct=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ose=a("a"),hct=o("from_pretrained()"),uct=o(" to load the model weights."),pct=l(),F(i7.$$.fragment),_ct=l(),Kr=a("div"),F($P.$$.fragment),bct=l(),A$e=a("p"),vct=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Fct=l(),Un=a("p"),Tct=o("The model class to instantiate is selected based on the "),L$e=a("code"),Mct=o("model_type"),Ect=o(` property of the config object (either
passed as an argument or loaded from `),y$e=a("code"),Cct=o("pretrained_model_name_or_path"),wct=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x$e=a("code"),Act=o("pretrained_model_name_or_path"),Lct=o(":"),yct=l(),ce=a("ul"),d7=a("li"),$$e=a("strong"),xct=o("albert"),$ct=o(" \u2014 "),Vse=a("a"),kct=o("TFAlbertForQuestionAnswering"),Sct=o(" (ALBERT model)"),Rct=l(),m7=a("li"),k$e=a("strong"),Pct=o("bert"),Bct=o(" \u2014 "),Xse=a("a"),Ict=o("TFBertForQuestionAnswering"),Nct=o(" (BERT model)"),qct=l(),c7=a("li"),S$e=a("strong"),jct=o("camembert"),Dct=o(" \u2014 "),zse=a("a"),Gct=o("TFCamembertForQuestionAnswering"),Oct=o(" (CamemBERT model)"),Vct=l(),f7=a("li"),R$e=a("strong"),Xct=o("convbert"),zct=o(" \u2014 "),Qse=a("a"),Qct=o("TFConvBertForQuestionAnswering"),Wct=o(" (ConvBERT model)"),Uct=l(),g7=a("li"),P$e=a("strong"),Hct=o("deberta"),Jct=o(" \u2014 "),Wse=a("a"),Yct=o("TFDebertaForQuestionAnswering"),Zct=o(" (DeBERTa model)"),Kct=l(),h7=a("li"),B$e=a("strong"),eft=o("deberta-v2"),oft=o(" \u2014 "),Use=a("a"),rft=o("TFDebertaV2ForQuestionAnswering"),tft=o(" (DeBERTa-v2 model)"),aft=l(),u7=a("li"),I$e=a("strong"),nft=o("distilbert"),sft=o(" \u2014 "),Hse=a("a"),lft=o("TFDistilBertForQuestionAnswering"),ift=o(" (DistilBERT model)"),dft=l(),p7=a("li"),N$e=a("strong"),mft=o("electra"),cft=o(" \u2014 "),Jse=a("a"),fft=o("TFElectraForQuestionAnswering"),gft=o(" (ELECTRA model)"),hft=l(),_7=a("li"),q$e=a("strong"),uft=o("flaubert"),pft=o(" \u2014 "),Yse=a("a"),_ft=o("TFFlaubertForQuestionAnsweringSimple"),bft=o(" (FlauBERT model)"),vft=l(),b7=a("li"),j$e=a("strong"),Fft=o("funnel"),Tft=o(" \u2014 "),Zse=a("a"),Mft=o("TFFunnelForQuestionAnswering"),Eft=o(" (Funnel Transformer model)"),Cft=l(),v7=a("li"),D$e=a("strong"),wft=o("gptj"),Aft=o(" \u2014 "),Kse=a("a"),Lft=o("TFGPTJForQuestionAnswering"),yft=o(" (GPT-J model)"),xft=l(),F7=a("li"),G$e=a("strong"),$ft=o("layoutlmv3"),kft=o(" \u2014 "),ele=a("a"),Sft=o("TFLayoutLMv3ForQuestionAnswering"),Rft=o(" (LayoutLMv3 model)"),Pft=l(),T7=a("li"),O$e=a("strong"),Bft=o("longformer"),Ift=o(" \u2014 "),ole=a("a"),Nft=o("TFLongformerForQuestionAnswering"),qft=o(" (Longformer model)"),jft=l(),M7=a("li"),V$e=a("strong"),Dft=o("mobilebert"),Gft=o(" \u2014 "),rle=a("a"),Oft=o("TFMobileBertForQuestionAnswering"),Vft=o(" (MobileBERT model)"),Xft=l(),E7=a("li"),X$e=a("strong"),zft=o("mpnet"),Qft=o(" \u2014 "),tle=a("a"),Wft=o("TFMPNetForQuestionAnswering"),Uft=o(" (MPNet model)"),Hft=l(),C7=a("li"),z$e=a("strong"),Jft=o("rembert"),Yft=o(" \u2014 "),ale=a("a"),Zft=o("TFRemBertForQuestionAnswering"),Kft=o(" (RemBERT model)"),egt=l(),w7=a("li"),Q$e=a("strong"),ogt=o("roberta"),rgt=o(" \u2014 "),nle=a("a"),tgt=o("TFRobertaForQuestionAnswering"),agt=o(" (RoBERTa model)"),ngt=l(),A7=a("li"),W$e=a("strong"),sgt=o("roformer"),lgt=o(" \u2014 "),sle=a("a"),igt=o("TFRoFormerForQuestionAnswering"),dgt=o(" (RoFormer model)"),mgt=l(),L7=a("li"),U$e=a("strong"),cgt=o("xlm"),fgt=o(" \u2014 "),lle=a("a"),ggt=o("TFXLMForQuestionAnsweringSimple"),hgt=o(" (XLM model)"),ugt=l(),y7=a("li"),H$e=a("strong"),pgt=o("xlm-roberta"),_gt=o(" \u2014 "),ile=a("a"),bgt=o("TFXLMRobertaForQuestionAnswering"),vgt=o(" (XLM-RoBERTa model)"),Fgt=l(),x7=a("li"),J$e=a("strong"),Tgt=o("xlnet"),Mgt=o(" \u2014 "),dle=a("a"),Egt=o("TFXLNetForQuestionAnsweringSimple"),Cgt=o(" (XLNet model)"),wgt=l(),F($7.$$.fragment),hno=l(),Kc=a("h2"),k7=a("a"),Y$e=a("span"),F(kP.$$.fragment),Agt=l(),Z$e=a("span"),Lgt=o("TFAutoModelForVision2Seq"),uno=l(),Cr=a("div"),F(SP.$$.fragment),ygt=l(),ef=a("p"),xgt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),mle=a("a"),$gt=o("from_pretrained()"),kgt=o(" class method or the "),cle=a("a"),Sgt=o("from_config()"),Rgt=o(` class
method.`),Pgt=l(),RP=a("p"),Bgt=o("This class cannot be instantiated directly using "),K$e=a("code"),Igt=o("__init__()"),Ngt=o(" (throws an error)."),qgt=l(),ca=a("div"),F(PP.$$.fragment),jgt=l(),eke=a("p"),Dgt=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Ggt=l(),of=a("p"),Ogt=o(`Note:
Loading a model from its configuration file does `),oke=a("strong"),Vgt=o("not"),Xgt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),fle=a("a"),zgt=o("from_pretrained()"),Qgt=o(" to load the model weights."),Wgt=l(),F(S7.$$.fragment),Ugt=l(),et=a("div"),F(BP.$$.fragment),Hgt=l(),rke=a("p"),Jgt=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Ygt=l(),Hn=a("p"),Zgt=o("The model class to instantiate is selected based on the "),tke=a("code"),Kgt=o("model_type"),eht=o(` property of the config object (either
passed as an argument or loaded from `),ake=a("code"),oht=o("pretrained_model_name_or_path"),rht=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nke=a("code"),tht=o("pretrained_model_name_or_path"),aht=o(":"),nht=l(),ske=a("ul"),R7=a("li"),lke=a("strong"),sht=o("vision-encoder-decoder"),lht=o(" \u2014 "),gle=a("a"),iht=o("TFVisionEncoderDecoderModel"),dht=o(" (Vision Encoder decoder model)"),mht=l(),F(P7.$$.fragment),pno=l(),rf=a("h2"),B7=a("a"),ike=a("span"),F(IP.$$.fragment),cht=l(),dke=a("span"),fht=o("TFAutoModelForSpeechSeq2Seq"),_no=l(),wr=a("div"),F(NP.$$.fragment),ght=l(),tf=a("p"),hht=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),hle=a("a"),uht=o("from_pretrained()"),pht=o(" class method or the "),ule=a("a"),_ht=o("from_config()"),bht=o(` class
method.`),vht=l(),qP=a("p"),Fht=o("This class cannot be instantiated directly using "),mke=a("code"),Tht=o("__init__()"),Mht=o(" (throws an error)."),Eht=l(),fa=a("div"),F(jP.$$.fragment),Cht=l(),cke=a("p"),wht=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Aht=l(),af=a("p"),Lht=o(`Note:
Loading a model from its configuration file does `),fke=a("strong"),yht=o("not"),xht=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ple=a("a"),$ht=o("from_pretrained()"),kht=o(" to load the model weights."),Sht=l(),F(I7.$$.fragment),Rht=l(),ot=a("div"),F(DP.$$.fragment),Pht=l(),gke=a("p"),Bht=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Iht=l(),Jn=a("p"),Nht=o("The model class to instantiate is selected based on the "),hke=a("code"),qht=o("model_type"),jht=o(` property of the config object (either
passed as an argument or loaded from `),uke=a("code"),Dht=o("pretrained_model_name_or_path"),Ght=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pke=a("code"),Oht=o("pretrained_model_name_or_path"),Vht=o(":"),Xht=l(),GP=a("ul"),N7=a("li"),_ke=a("strong"),zht=o("speech_to_text"),Qht=o(" \u2014 "),_le=a("a"),Wht=o("TFSpeech2TextForConditionalGeneration"),Uht=o(" (Speech2Text model)"),Hht=l(),q7=a("li"),bke=a("strong"),Jht=o("whisper"),Yht=o(" \u2014 "),ble=a("a"),Zht=o("TFWhisperForConditionalGeneration"),Kht=o(" (Whisper model)"),eut=l(),F(j7.$$.fragment),bno=l(),nf=a("h2"),D7=a("a"),vke=a("span"),F(OP.$$.fragment),out=l(),Fke=a("span"),rut=o("FlaxAutoModel"),vno=l(),Ar=a("div"),F(VP.$$.fragment),tut=l(),sf=a("p"),aut=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),vle=a("a"),nut=o("from_pretrained()"),sut=o(" class method or the "),Fle=a("a"),lut=o("from_config()"),iut=o(` class
method.`),dut=l(),XP=a("p"),mut=o("This class cannot be instantiated directly using "),Tke=a("code"),cut=o("__init__()"),fut=o(" (throws an error)."),gut=l(),ga=a("div"),F(zP.$$.fragment),hut=l(),Mke=a("p"),uut=o("Instantiates one of the base model classes of the library from a configuration."),put=l(),lf=a("p"),_ut=o(`Note:
Loading a model from its configuration file does `),Eke=a("strong"),but=o("not"),vut=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Tle=a("a"),Fut=o("from_pretrained()"),Tut=o(" to load the model weights."),Mut=l(),F(G7.$$.fragment),Eut=l(),rt=a("div"),F(QP.$$.fragment),Cut=l(),Cke=a("p"),wut=o("Instantiate one of the base model classes of the library from a pretrained model."),Aut=l(),Yn=a("p"),Lut=o("The model class to instantiate is selected based on the "),wke=a("code"),yut=o("model_type"),xut=o(` property of the config object (either
passed as an argument or loaded from `),Ake=a("code"),$ut=o("pretrained_model_name_or_path"),kut=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Lke=a("code"),Sut=o("pretrained_model_name_or_path"),Rut=o(":"),Put=l(),te=a("ul"),O7=a("li"),yke=a("strong"),But=o("albert"),Iut=o(" \u2014 "),Mle=a("a"),Nut=o("FlaxAlbertModel"),qut=o(" (ALBERT model)"),jut=l(),V7=a("li"),xke=a("strong"),Dut=o("bart"),Gut=o(" \u2014 "),Ele=a("a"),Out=o("FlaxBartModel"),Vut=o(" (BART model)"),Xut=l(),X7=a("li"),$ke=a("strong"),zut=o("beit"),Qut=o(" \u2014 "),Cle=a("a"),Wut=o("FlaxBeitModel"),Uut=o(" (BEiT model)"),Hut=l(),z7=a("li"),kke=a("strong"),Jut=o("bert"),Yut=o(" \u2014 "),wle=a("a"),Zut=o("FlaxBertModel"),Kut=o(" (BERT model)"),ept=l(),Q7=a("li"),Ske=a("strong"),opt=o("big_bird"),rpt=o(" \u2014 "),Ale=a("a"),tpt=o("FlaxBigBirdModel"),apt=o(" (BigBird model)"),npt=l(),W7=a("li"),Rke=a("strong"),spt=o("blenderbot"),lpt=o(" \u2014 "),Lle=a("a"),ipt=o("FlaxBlenderbotModel"),dpt=o(" (Blenderbot model)"),mpt=l(),U7=a("li"),Pke=a("strong"),cpt=o("blenderbot-small"),fpt=o(" \u2014 "),yle=a("a"),gpt=o("FlaxBlenderbotSmallModel"),hpt=o(" (BlenderbotSmall model)"),upt=l(),H7=a("li"),Bke=a("strong"),ppt=o("clip"),_pt=o(" \u2014 "),xle=a("a"),bpt=o("FlaxCLIPModel"),vpt=o(" (CLIP model)"),Fpt=l(),J7=a("li"),Ike=a("strong"),Tpt=o("distilbert"),Mpt=o(" \u2014 "),$le=a("a"),Ept=o("FlaxDistilBertModel"),Cpt=o(" (DistilBERT model)"),wpt=l(),Y7=a("li"),Nke=a("strong"),Apt=o("electra"),Lpt=o(" \u2014 "),kle=a("a"),ypt=o("FlaxElectraModel"),xpt=o(" (ELECTRA model)"),$pt=l(),Z7=a("li"),qke=a("strong"),kpt=o("gpt2"),Spt=o(" \u2014 "),Sle=a("a"),Rpt=o("FlaxGPT2Model"),Ppt=o(" (OpenAI GPT-2 model)"),Bpt=l(),K7=a("li"),jke=a("strong"),Ipt=o("gpt_neo"),Npt=o(" \u2014 "),Rle=a("a"),qpt=o("FlaxGPTNeoModel"),jpt=o(" (GPT Neo model)"),Dpt=l(),e8=a("li"),Dke=a("strong"),Gpt=o("gptj"),Opt=o(" \u2014 "),Ple=a("a"),Vpt=o("FlaxGPTJModel"),Xpt=o(" (GPT-J model)"),zpt=l(),o8=a("li"),Gke=a("strong"),Qpt=o("longt5"),Wpt=o(" \u2014 "),Ble=a("a"),Upt=o("FlaxLongT5Model"),Hpt=o(" (LongT5 model)"),Jpt=l(),r8=a("li"),Oke=a("strong"),Ypt=o("marian"),Zpt=o(" \u2014 "),Ile=a("a"),Kpt=o("FlaxMarianModel"),e_t=o(" (Marian model)"),o_t=l(),t8=a("li"),Vke=a("strong"),r_t=o("mbart"),t_t=o(" \u2014 "),Nle=a("a"),a_t=o("FlaxMBartModel"),n_t=o(" (mBART model)"),s_t=l(),a8=a("li"),Xke=a("strong"),l_t=o("mt5"),i_t=o(" \u2014 "),qle=a("a"),d_t=o("FlaxMT5Model"),m_t=o(" (MT5 model)"),c_t=l(),n8=a("li"),zke=a("strong"),f_t=o("opt"),g_t=o(" \u2014 "),jle=a("a"),h_t=o("FlaxOPTModel"),u_t=o(" (OPT model)"),p_t=l(),s8=a("li"),Qke=a("strong"),__t=o("pegasus"),b_t=o(" \u2014 "),Dle=a("a"),v_t=o("FlaxPegasusModel"),F_t=o(" (Pegasus model)"),T_t=l(),l8=a("li"),Wke=a("strong"),M_t=o("roberta"),E_t=o(" \u2014 "),Gle=a("a"),C_t=o("FlaxRobertaModel"),w_t=o(" (RoBERTa model)"),A_t=l(),i8=a("li"),Uke=a("strong"),L_t=o("roformer"),y_t=o(" \u2014 "),Ole=a("a"),x_t=o("FlaxRoFormerModel"),$_t=o(" (RoFormer model)"),k_t=l(),d8=a("li"),Hke=a("strong"),S_t=o("t5"),R_t=o(" \u2014 "),Vle=a("a"),P_t=o("FlaxT5Model"),B_t=o(" (T5 model)"),I_t=l(),m8=a("li"),Jke=a("strong"),N_t=o("vision-text-dual-encoder"),q_t=o(" \u2014 "),Xle=a("a"),j_t=o("FlaxVisionTextDualEncoderModel"),D_t=o(" (VisionTextDualEncoder model)"),G_t=l(),c8=a("li"),Yke=a("strong"),O_t=o("vit"),V_t=o(" \u2014 "),zle=a("a"),X_t=o("FlaxViTModel"),z_t=o(" (ViT model)"),Q_t=l(),f8=a("li"),Zke=a("strong"),W_t=o("wav2vec2"),U_t=o(" \u2014 "),Qle=a("a"),H_t=o("FlaxWav2Vec2Model"),J_t=o(" (Wav2Vec2 model)"),Y_t=l(),g8=a("li"),Kke=a("strong"),Z_t=o("xglm"),K_t=o(" \u2014 "),Wle=a("a"),e1t=o("FlaxXGLMModel"),o1t=o(" (XGLM model)"),r1t=l(),h8=a("li"),eSe=a("strong"),t1t=o("xlm-roberta"),a1t=o(" \u2014 "),Ule=a("a"),n1t=o("FlaxXLMRobertaModel"),s1t=o(" (XLM-RoBERTa model)"),l1t=l(),F(u8.$$.fragment),Fno=l(),df=a("h2"),p8=a("a"),oSe=a("span"),F(WP.$$.fragment),i1t=l(),rSe=a("span"),d1t=o("FlaxAutoModelForCausalLM"),Tno=l(),Lr=a("div"),F(UP.$$.fragment),m1t=l(),mf=a("p"),c1t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Hle=a("a"),f1t=o("from_pretrained()"),g1t=o(" class method or the "),Jle=a("a"),h1t=o("from_config()"),u1t=o(` class
method.`),p1t=l(),HP=a("p"),_1t=o("This class cannot be instantiated directly using "),tSe=a("code"),b1t=o("__init__()"),v1t=o(" (throws an error)."),F1t=l(),ha=a("div"),F(JP.$$.fragment),T1t=l(),aSe=a("p"),M1t=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),E1t=l(),cf=a("p"),C1t=o(`Note:
Loading a model from its configuration file does `),nSe=a("strong"),w1t=o("not"),A1t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Yle=a("a"),L1t=o("from_pretrained()"),y1t=o(" to load the model weights."),x1t=l(),F(_8.$$.fragment),$1t=l(),tt=a("div"),F(YP.$$.fragment),k1t=l(),sSe=a("p"),S1t=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),R1t=l(),Zn=a("p"),P1t=o("The model class to instantiate is selected based on the "),lSe=a("code"),B1t=o("model_type"),I1t=o(` property of the config object (either
passed as an argument or loaded from `),iSe=a("code"),N1t=o("pretrained_model_name_or_path"),q1t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dSe=a("code"),j1t=o("pretrained_model_name_or_path"),D1t=o(":"),G1t=l(),$e=a("ul"),b8=a("li"),mSe=a("strong"),O1t=o("bart"),V1t=o(" \u2014 "),Zle=a("a"),X1t=o("FlaxBartForCausalLM"),z1t=o(" (BART model)"),Q1t=l(),v8=a("li"),cSe=a("strong"),W1t=o("bert"),U1t=o(" \u2014 "),Kle=a("a"),H1t=o("FlaxBertForCausalLM"),J1t=o(" (BERT model)"),Y1t=l(),F8=a("li"),fSe=a("strong"),Z1t=o("big_bird"),K1t=o(" \u2014 "),eie=a("a"),e2t=o("FlaxBigBirdForCausalLM"),o2t=o(" (BigBird model)"),r2t=l(),T8=a("li"),gSe=a("strong"),t2t=o("electra"),a2t=o(" \u2014 "),oie=a("a"),n2t=o("FlaxElectraForCausalLM"),s2t=o(" (ELECTRA model)"),l2t=l(),M8=a("li"),hSe=a("strong"),i2t=o("gpt2"),d2t=o(" \u2014 "),rie=a("a"),m2t=o("FlaxGPT2LMHeadModel"),c2t=o(" (OpenAI GPT-2 model)"),f2t=l(),E8=a("li"),uSe=a("strong"),g2t=o("gpt_neo"),h2t=o(" \u2014 "),tie=a("a"),u2t=o("FlaxGPTNeoForCausalLM"),p2t=o(" (GPT Neo model)"),_2t=l(),C8=a("li"),pSe=a("strong"),b2t=o("gptj"),v2t=o(" \u2014 "),aie=a("a"),F2t=o("FlaxGPTJForCausalLM"),T2t=o(" (GPT-J model)"),M2t=l(),w8=a("li"),_Se=a("strong"),E2t=o("opt"),C2t=o(" \u2014 "),nie=a("a"),w2t=o("FlaxOPTForCausalLM"),A2t=o(" (OPT model)"),L2t=l(),A8=a("li"),bSe=a("strong"),y2t=o("roberta"),x2t=o(" \u2014 "),sie=a("a"),$2t=o("FlaxRobertaForCausalLM"),k2t=o(" (RoBERTa model)"),S2t=l(),L8=a("li"),vSe=a("strong"),R2t=o("xglm"),P2t=o(" \u2014 "),lie=a("a"),B2t=o("FlaxXGLMForCausalLM"),I2t=o(" (XGLM model)"),N2t=l(),F(y8.$$.fragment),Mno=l(),ff=a("h2"),x8=a("a"),FSe=a("span"),F(ZP.$$.fragment),q2t=l(),TSe=a("span"),j2t=o("FlaxAutoModelForPreTraining"),Eno=l(),yr=a("div"),F(KP.$$.fragment),D2t=l(),gf=a("p"),G2t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),iie=a("a"),O2t=o("from_pretrained()"),V2t=o(" class method or the "),die=a("a"),X2t=o("from_config()"),z2t=o(` class
method.`),Q2t=l(),eB=a("p"),W2t=o("This class cannot be instantiated directly using "),MSe=a("code"),U2t=o("__init__()"),H2t=o(" (throws an error)."),J2t=l(),ua=a("div"),F(oB.$$.fragment),Y2t=l(),ESe=a("p"),Z2t=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),K2t=l(),hf=a("p"),ebt=o(`Note:
Loading a model from its configuration file does `),CSe=a("strong"),obt=o("not"),rbt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mie=a("a"),tbt=o("from_pretrained()"),abt=o(" to load the model weights."),nbt=l(),F($8.$$.fragment),sbt=l(),at=a("div"),F(rB.$$.fragment),lbt=l(),wSe=a("p"),ibt=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),dbt=l(),Kn=a("p"),mbt=o("The model class to instantiate is selected based on the "),ASe=a("code"),cbt=o("model_type"),fbt=o(` property of the config object (either
passed as an argument or loaded from `),LSe=a("code"),gbt=o("pretrained_model_name_or_path"),hbt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ySe=a("code"),ubt=o("pretrained_model_name_or_path"),pbt=o(":"),_bt=l(),Ee=a("ul"),k8=a("li"),xSe=a("strong"),bbt=o("albert"),vbt=o(" \u2014 "),cie=a("a"),Fbt=o("FlaxAlbertForPreTraining"),Tbt=o(" (ALBERT model)"),Mbt=l(),S8=a("li"),$Se=a("strong"),Ebt=o("bart"),Cbt=o(" \u2014 "),fie=a("a"),wbt=o("FlaxBartForConditionalGeneration"),Abt=o(" (BART model)"),Lbt=l(),R8=a("li"),kSe=a("strong"),ybt=o("bert"),xbt=o(" \u2014 "),gie=a("a"),$bt=o("FlaxBertForPreTraining"),kbt=o(" (BERT model)"),Sbt=l(),P8=a("li"),SSe=a("strong"),Rbt=o("big_bird"),Pbt=o(" \u2014 "),hie=a("a"),Bbt=o("FlaxBigBirdForPreTraining"),Ibt=o(" (BigBird model)"),Nbt=l(),B8=a("li"),RSe=a("strong"),qbt=o("electra"),jbt=o(" \u2014 "),uie=a("a"),Dbt=o("FlaxElectraForPreTraining"),Gbt=o(" (ELECTRA model)"),Obt=l(),I8=a("li"),PSe=a("strong"),Vbt=o("longt5"),Xbt=o(" \u2014 "),pie=a("a"),zbt=o("FlaxLongT5ForConditionalGeneration"),Qbt=o(" (LongT5 model)"),Wbt=l(),N8=a("li"),BSe=a("strong"),Ubt=o("mbart"),Hbt=o(" \u2014 "),_ie=a("a"),Jbt=o("FlaxMBartForConditionalGeneration"),Ybt=o(" (mBART model)"),Zbt=l(),q8=a("li"),ISe=a("strong"),Kbt=o("mt5"),evt=o(" \u2014 "),bie=a("a"),ovt=o("FlaxMT5ForConditionalGeneration"),rvt=o(" (MT5 model)"),tvt=l(),j8=a("li"),NSe=a("strong"),avt=o("roberta"),nvt=o(" \u2014 "),vie=a("a"),svt=o("FlaxRobertaForMaskedLM"),lvt=o(" (RoBERTa model)"),ivt=l(),D8=a("li"),qSe=a("strong"),dvt=o("roformer"),mvt=o(" \u2014 "),Fie=a("a"),cvt=o("FlaxRoFormerForMaskedLM"),fvt=o(" (RoFormer model)"),gvt=l(),G8=a("li"),jSe=a("strong"),hvt=o("t5"),uvt=o(" \u2014 "),Tie=a("a"),pvt=o("FlaxT5ForConditionalGeneration"),_vt=o(" (T5 model)"),bvt=l(),O8=a("li"),DSe=a("strong"),vvt=o("wav2vec2"),Fvt=o(" \u2014 "),Mie=a("a"),Tvt=o("FlaxWav2Vec2ForPreTraining"),Mvt=o(" (Wav2Vec2 model)"),Evt=l(),V8=a("li"),GSe=a("strong"),Cvt=o("xlm-roberta"),wvt=o(" \u2014 "),Eie=a("a"),Avt=o("FlaxXLMRobertaForMaskedLM"),Lvt=o(" (XLM-RoBERTa model)"),yvt=l(),F(X8.$$.fragment),Cno=l(),uf=a("h2"),z8=a("a"),OSe=a("span"),F(tB.$$.fragment),xvt=l(),VSe=a("span"),$vt=o("FlaxAutoModelForMaskedLM"),wno=l(),xr=a("div"),F(aB.$$.fragment),kvt=l(),pf=a("p"),Svt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Cie=a("a"),Rvt=o("from_pretrained()"),Pvt=o(" class method or the "),wie=a("a"),Bvt=o("from_config()"),Ivt=o(` class
method.`),Nvt=l(),nB=a("p"),qvt=o("This class cannot be instantiated directly using "),XSe=a("code"),jvt=o("__init__()"),Dvt=o(" (throws an error)."),Gvt=l(),pa=a("div"),F(sB.$$.fragment),Ovt=l(),zSe=a("p"),Vvt=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Xvt=l(),_f=a("p"),zvt=o(`Note:
Loading a model from its configuration file does `),QSe=a("strong"),Qvt=o("not"),Wvt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Aie=a("a"),Uvt=o("from_pretrained()"),Hvt=o(" to load the model weights."),Jvt=l(),F(Q8.$$.fragment),Yvt=l(),nt=a("div"),F(lB.$$.fragment),Zvt=l(),WSe=a("p"),Kvt=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),eFt=l(),es=a("p"),oFt=o("The model class to instantiate is selected based on the "),USe=a("code"),rFt=o("model_type"),tFt=o(` property of the config object (either
passed as an argument or loaded from `),HSe=a("code"),aFt=o("pretrained_model_name_or_path"),nFt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JSe=a("code"),sFt=o("pretrained_model_name_or_path"),lFt=o(":"),iFt=l(),ke=a("ul"),W8=a("li"),YSe=a("strong"),dFt=o("albert"),mFt=o(" \u2014 "),Lie=a("a"),cFt=o("FlaxAlbertForMaskedLM"),fFt=o(" (ALBERT model)"),gFt=l(),U8=a("li"),ZSe=a("strong"),hFt=o("bart"),uFt=o(" \u2014 "),yie=a("a"),pFt=o("FlaxBartForConditionalGeneration"),_Ft=o(" (BART model)"),bFt=l(),H8=a("li"),KSe=a("strong"),vFt=o("bert"),FFt=o(" \u2014 "),xie=a("a"),TFt=o("FlaxBertForMaskedLM"),MFt=o(" (BERT model)"),EFt=l(),J8=a("li"),eRe=a("strong"),CFt=o("big_bird"),wFt=o(" \u2014 "),$ie=a("a"),AFt=o("FlaxBigBirdForMaskedLM"),LFt=o(" (BigBird model)"),yFt=l(),Y8=a("li"),oRe=a("strong"),xFt=o("distilbert"),$Ft=o(" \u2014 "),kie=a("a"),kFt=o("FlaxDistilBertForMaskedLM"),SFt=o(" (DistilBERT model)"),RFt=l(),Z8=a("li"),rRe=a("strong"),PFt=o("electra"),BFt=o(" \u2014 "),Sie=a("a"),IFt=o("FlaxElectraForMaskedLM"),NFt=o(" (ELECTRA model)"),qFt=l(),K8=a("li"),tRe=a("strong"),jFt=o("mbart"),DFt=o(" \u2014 "),Rie=a("a"),GFt=o("FlaxMBartForConditionalGeneration"),OFt=o(" (mBART model)"),VFt=l(),eL=a("li"),aRe=a("strong"),XFt=o("roberta"),zFt=o(" \u2014 "),Pie=a("a"),QFt=o("FlaxRobertaForMaskedLM"),WFt=o(" (RoBERTa model)"),UFt=l(),oL=a("li"),nRe=a("strong"),HFt=o("roformer"),JFt=o(" \u2014 "),Bie=a("a"),YFt=o("FlaxRoFormerForMaskedLM"),ZFt=o(" (RoFormer model)"),KFt=l(),rL=a("li"),sRe=a("strong"),eTt=o("xlm-roberta"),oTt=o(" \u2014 "),Iie=a("a"),rTt=o("FlaxXLMRobertaForMaskedLM"),tTt=o(" (XLM-RoBERTa model)"),aTt=l(),F(tL.$$.fragment),Ano=l(),bf=a("h2"),aL=a("a"),lRe=a("span"),F(iB.$$.fragment),nTt=l(),iRe=a("span"),sTt=o("FlaxAutoModelForSeq2SeqLM"),Lno=l(),$r=a("div"),F(dB.$$.fragment),lTt=l(),vf=a("p"),iTt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Nie=a("a"),dTt=o("from_pretrained()"),mTt=o(" class method or the "),qie=a("a"),cTt=o("from_config()"),fTt=o(` class
method.`),gTt=l(),mB=a("p"),hTt=o("This class cannot be instantiated directly using "),dRe=a("code"),uTt=o("__init__()"),pTt=o(" (throws an error)."),_Tt=l(),_a=a("div"),F(cB.$$.fragment),bTt=l(),mRe=a("p"),vTt=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),FTt=l(),Ff=a("p"),TTt=o(`Note:
Loading a model from its configuration file does `),cRe=a("strong"),MTt=o("not"),ETt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jie=a("a"),CTt=o("from_pretrained()"),wTt=o(" to load the model weights."),ATt=l(),F(nL.$$.fragment),LTt=l(),st=a("div"),F(fB.$$.fragment),yTt=l(),fRe=a("p"),xTt=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),$Tt=l(),os=a("p"),kTt=o("The model class to instantiate is selected based on the "),gRe=a("code"),STt=o("model_type"),RTt=o(` property of the config object (either
passed as an argument or loaded from `),hRe=a("code"),PTt=o("pretrained_model_name_or_path"),BTt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uRe=a("code"),ITt=o("pretrained_model_name_or_path"),NTt=o(":"),qTt=l(),Se=a("ul"),sL=a("li"),pRe=a("strong"),jTt=o("bart"),DTt=o(" \u2014 "),Die=a("a"),GTt=o("FlaxBartForConditionalGeneration"),OTt=o(" (BART model)"),VTt=l(),lL=a("li"),_Re=a("strong"),XTt=o("blenderbot"),zTt=o(" \u2014 "),Gie=a("a"),QTt=o("FlaxBlenderbotForConditionalGeneration"),WTt=o(" (Blenderbot model)"),UTt=l(),iL=a("li"),bRe=a("strong"),HTt=o("blenderbot-small"),JTt=o(" \u2014 "),Oie=a("a"),YTt=o("FlaxBlenderbotSmallForConditionalGeneration"),ZTt=o(" (BlenderbotSmall model)"),KTt=l(),dL=a("li"),vRe=a("strong"),eMt=o("encoder-decoder"),oMt=o(" \u2014 "),Vie=a("a"),rMt=o("FlaxEncoderDecoderModel"),tMt=o(" (Encoder decoder model)"),aMt=l(),mL=a("li"),FRe=a("strong"),nMt=o("longt5"),sMt=o(" \u2014 "),Xie=a("a"),lMt=o("FlaxLongT5ForConditionalGeneration"),iMt=o(" (LongT5 model)"),dMt=l(),cL=a("li"),TRe=a("strong"),mMt=o("marian"),cMt=o(" \u2014 "),zie=a("a"),fMt=o("FlaxMarianMTModel"),gMt=o(" (Marian model)"),hMt=l(),fL=a("li"),MRe=a("strong"),uMt=o("mbart"),pMt=o(" \u2014 "),Qie=a("a"),_Mt=o("FlaxMBartForConditionalGeneration"),bMt=o(" (mBART model)"),vMt=l(),gL=a("li"),ERe=a("strong"),FMt=o("mt5"),TMt=o(" \u2014 "),Wie=a("a"),MMt=o("FlaxMT5ForConditionalGeneration"),EMt=o(" (MT5 model)"),CMt=l(),hL=a("li"),CRe=a("strong"),wMt=o("pegasus"),AMt=o(" \u2014 "),Uie=a("a"),LMt=o("FlaxPegasusForConditionalGeneration"),yMt=o(" (Pegasus model)"),xMt=l(),uL=a("li"),wRe=a("strong"),$Mt=o("t5"),kMt=o(" \u2014 "),Hie=a("a"),SMt=o("FlaxT5ForConditionalGeneration"),RMt=o(" (T5 model)"),PMt=l(),F(pL.$$.fragment),yno=l(),Tf=a("h2"),_L=a("a"),ARe=a("span"),F(gB.$$.fragment),BMt=l(),LRe=a("span"),IMt=o("FlaxAutoModelForSequenceClassification"),xno=l(),kr=a("div"),F(hB.$$.fragment),NMt=l(),Mf=a("p"),qMt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Jie=a("a"),jMt=o("from_pretrained()"),DMt=o(" class method or the "),Yie=a("a"),GMt=o("from_config()"),OMt=o(` class
method.`),VMt=l(),uB=a("p"),XMt=o("This class cannot be instantiated directly using "),yRe=a("code"),zMt=o("__init__()"),QMt=o(" (throws an error)."),WMt=l(),ba=a("div"),F(pB.$$.fragment),UMt=l(),xRe=a("p"),HMt=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),JMt=l(),Ef=a("p"),YMt=o(`Note:
Loading a model from its configuration file does `),$Re=a("strong"),ZMt=o("not"),KMt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Zie=a("a"),eEt=o("from_pretrained()"),oEt=o(" to load the model weights."),rEt=l(),F(bL.$$.fragment),tEt=l(),lt=a("div"),F(_B.$$.fragment),aEt=l(),kRe=a("p"),nEt=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),sEt=l(),rs=a("p"),lEt=o("The model class to instantiate is selected based on the "),SRe=a("code"),iEt=o("model_type"),dEt=o(` property of the config object (either
passed as an argument or loaded from `),RRe=a("code"),mEt=o("pretrained_model_name_or_path"),cEt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),PRe=a("code"),fEt=o("pretrained_model_name_or_path"),gEt=o(":"),hEt=l(),Re=a("ul"),vL=a("li"),BRe=a("strong"),uEt=o("albert"),pEt=o(" \u2014 "),Kie=a("a"),_Et=o("FlaxAlbertForSequenceClassification"),bEt=o(" (ALBERT model)"),vEt=l(),FL=a("li"),IRe=a("strong"),FEt=o("bart"),TEt=o(" \u2014 "),ede=a("a"),MEt=o("FlaxBartForSequenceClassification"),EEt=o(" (BART model)"),CEt=l(),TL=a("li"),NRe=a("strong"),wEt=o("bert"),AEt=o(" \u2014 "),ode=a("a"),LEt=o("FlaxBertForSequenceClassification"),yEt=o(" (BERT model)"),xEt=l(),ML=a("li"),qRe=a("strong"),$Et=o("big_bird"),kEt=o(" \u2014 "),rde=a("a"),SEt=o("FlaxBigBirdForSequenceClassification"),REt=o(" (BigBird model)"),PEt=l(),EL=a("li"),jRe=a("strong"),BEt=o("distilbert"),IEt=o(" \u2014 "),tde=a("a"),NEt=o("FlaxDistilBertForSequenceClassification"),qEt=o(" (DistilBERT model)"),jEt=l(),CL=a("li"),DRe=a("strong"),DEt=o("electra"),GEt=o(" \u2014 "),ade=a("a"),OEt=o("FlaxElectraForSequenceClassification"),VEt=o(" (ELECTRA model)"),XEt=l(),wL=a("li"),GRe=a("strong"),zEt=o("mbart"),QEt=o(" \u2014 "),nde=a("a"),WEt=o("FlaxMBartForSequenceClassification"),UEt=o(" (mBART model)"),HEt=l(),AL=a("li"),ORe=a("strong"),JEt=o("roberta"),YEt=o(" \u2014 "),sde=a("a"),ZEt=o("FlaxRobertaForSequenceClassification"),KEt=o(" (RoBERTa model)"),e4t=l(),LL=a("li"),VRe=a("strong"),o4t=o("roformer"),r4t=o(" \u2014 "),lde=a("a"),t4t=o("FlaxRoFormerForSequenceClassification"),a4t=o(" (RoFormer model)"),n4t=l(),yL=a("li"),XRe=a("strong"),s4t=o("xlm-roberta"),l4t=o(" \u2014 "),ide=a("a"),i4t=o("FlaxXLMRobertaForSequenceClassification"),d4t=o(" (XLM-RoBERTa model)"),m4t=l(),F(xL.$$.fragment),$no=l(),Cf=a("h2"),$L=a("a"),zRe=a("span"),F(bB.$$.fragment),c4t=l(),QRe=a("span"),f4t=o("FlaxAutoModelForQuestionAnswering"),kno=l(),Sr=a("div"),F(vB.$$.fragment),g4t=l(),wf=a("p"),h4t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),dde=a("a"),u4t=o("from_pretrained()"),p4t=o(" class method or the "),mde=a("a"),_4t=o("from_config()"),b4t=o(` class
method.`),v4t=l(),FB=a("p"),F4t=o("This class cannot be instantiated directly using "),WRe=a("code"),T4t=o("__init__()"),M4t=o(" (throws an error)."),E4t=l(),va=a("div"),F(TB.$$.fragment),C4t=l(),URe=a("p"),w4t=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),A4t=l(),Af=a("p"),L4t=o(`Note:
Loading a model from its configuration file does `),HRe=a("strong"),y4t=o("not"),x4t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cde=a("a"),$4t=o("from_pretrained()"),k4t=o(" to load the model weights."),S4t=l(),F(kL.$$.fragment),R4t=l(),it=a("div"),F(MB.$$.fragment),P4t=l(),JRe=a("p"),B4t=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),I4t=l(),ts=a("p"),N4t=o("The model class to instantiate is selected based on the "),YRe=a("code"),q4t=o("model_type"),j4t=o(` property of the config object (either
passed as an argument or loaded from `),ZRe=a("code"),D4t=o("pretrained_model_name_or_path"),G4t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KRe=a("code"),O4t=o("pretrained_model_name_or_path"),V4t=o(":"),X4t=l(),Pe=a("ul"),SL=a("li"),ePe=a("strong"),z4t=o("albert"),Q4t=o(" \u2014 "),fde=a("a"),W4t=o("FlaxAlbertForQuestionAnswering"),U4t=o(" (ALBERT model)"),H4t=l(),RL=a("li"),oPe=a("strong"),J4t=o("bart"),Y4t=o(" \u2014 "),gde=a("a"),Z4t=o("FlaxBartForQuestionAnswering"),K4t=o(" (BART model)"),eCt=l(),PL=a("li"),rPe=a("strong"),oCt=o("bert"),rCt=o(" \u2014 "),hde=a("a"),tCt=o("FlaxBertForQuestionAnswering"),aCt=o(" (BERT model)"),nCt=l(),BL=a("li"),tPe=a("strong"),sCt=o("big_bird"),lCt=o(" \u2014 "),ude=a("a"),iCt=o("FlaxBigBirdForQuestionAnswering"),dCt=o(" (BigBird model)"),mCt=l(),IL=a("li"),aPe=a("strong"),cCt=o("distilbert"),fCt=o(" \u2014 "),pde=a("a"),gCt=o("FlaxDistilBertForQuestionAnswering"),hCt=o(" (DistilBERT model)"),uCt=l(),NL=a("li"),nPe=a("strong"),pCt=o("electra"),_Ct=o(" \u2014 "),_de=a("a"),bCt=o("FlaxElectraForQuestionAnswering"),vCt=o(" (ELECTRA model)"),FCt=l(),qL=a("li"),sPe=a("strong"),TCt=o("mbart"),MCt=o(" \u2014 "),bde=a("a"),ECt=o("FlaxMBartForQuestionAnswering"),CCt=o(" (mBART model)"),wCt=l(),jL=a("li"),lPe=a("strong"),ACt=o("roberta"),LCt=o(" \u2014 "),vde=a("a"),yCt=o("FlaxRobertaForQuestionAnswering"),xCt=o(" (RoBERTa model)"),$Ct=l(),DL=a("li"),iPe=a("strong"),kCt=o("roformer"),SCt=o(" \u2014 "),Fde=a("a"),RCt=o("FlaxRoFormerForQuestionAnswering"),PCt=o(" (RoFormer model)"),BCt=l(),GL=a("li"),dPe=a("strong"),ICt=o("xlm-roberta"),NCt=o(" \u2014 "),Tde=a("a"),qCt=o("FlaxXLMRobertaForQuestionAnswering"),jCt=o(" (XLM-RoBERTa model)"),DCt=l(),F(OL.$$.fragment),Sno=l(),Lf=a("h2"),VL=a("a"),mPe=a("span"),F(EB.$$.fragment),GCt=l(),cPe=a("span"),OCt=o("FlaxAutoModelForTokenClassification"),Rno=l(),Rr=a("div"),F(CB.$$.fragment),VCt=l(),yf=a("p"),XCt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Mde=a("a"),zCt=o("from_pretrained()"),QCt=o(" class method or the "),Ede=a("a"),WCt=o("from_config()"),UCt=o(` class
method.`),HCt=l(),wB=a("p"),JCt=o("This class cannot be instantiated directly using "),fPe=a("code"),YCt=o("__init__()"),ZCt=o(" (throws an error)."),KCt=l(),Fa=a("div"),F(AB.$$.fragment),e3t=l(),gPe=a("p"),o3t=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),r3t=l(),xf=a("p"),t3t=o(`Note:
Loading a model from its configuration file does `),hPe=a("strong"),a3t=o("not"),n3t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Cde=a("a"),s3t=o("from_pretrained()"),l3t=o(" to load the model weights."),i3t=l(),F(XL.$$.fragment),d3t=l(),dt=a("div"),F(LB.$$.fragment),m3t=l(),uPe=a("p"),c3t=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),f3t=l(),as=a("p"),g3t=o("The model class to instantiate is selected based on the "),pPe=a("code"),h3t=o("model_type"),u3t=o(` property of the config object (either
passed as an argument or loaded from `),_Pe=a("code"),p3t=o("pretrained_model_name_or_path"),_3t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bPe=a("code"),b3t=o("pretrained_model_name_or_path"),v3t=o(":"),F3t=l(),ze=a("ul"),zL=a("li"),vPe=a("strong"),T3t=o("albert"),M3t=o(" \u2014 "),wde=a("a"),E3t=o("FlaxAlbertForTokenClassification"),C3t=o(" (ALBERT model)"),w3t=l(),QL=a("li"),FPe=a("strong"),A3t=o("bert"),L3t=o(" \u2014 "),Ade=a("a"),y3t=o("FlaxBertForTokenClassification"),x3t=o(" (BERT model)"),$3t=l(),WL=a("li"),TPe=a("strong"),k3t=o("big_bird"),S3t=o(" \u2014 "),Lde=a("a"),R3t=o("FlaxBigBirdForTokenClassification"),P3t=o(" (BigBird model)"),B3t=l(),UL=a("li"),MPe=a("strong"),I3t=o("distilbert"),N3t=o(" \u2014 "),yde=a("a"),q3t=o("FlaxDistilBertForTokenClassification"),j3t=o(" (DistilBERT model)"),D3t=l(),HL=a("li"),EPe=a("strong"),G3t=o("electra"),O3t=o(" \u2014 "),xde=a("a"),V3t=o("FlaxElectraForTokenClassification"),X3t=o(" (ELECTRA model)"),z3t=l(),JL=a("li"),CPe=a("strong"),Q3t=o("roberta"),W3t=o(" \u2014 "),$de=a("a"),U3t=o("FlaxRobertaForTokenClassification"),H3t=o(" (RoBERTa model)"),J3t=l(),YL=a("li"),wPe=a("strong"),Y3t=o("roformer"),Z3t=o(" \u2014 "),kde=a("a"),K3t=o("FlaxRoFormerForTokenClassification"),e5t=o(" (RoFormer model)"),o5t=l(),ZL=a("li"),APe=a("strong"),r5t=o("xlm-roberta"),t5t=o(" \u2014 "),Sde=a("a"),a5t=o("FlaxXLMRobertaForTokenClassification"),n5t=o(" (XLM-RoBERTa model)"),s5t=l(),F(KL.$$.fragment),Pno=l(),$f=a("h2"),ey=a("a"),LPe=a("span"),F(yB.$$.fragment),l5t=l(),yPe=a("span"),i5t=o("FlaxAutoModelForMultipleChoice"),Bno=l(),Pr=a("div"),F(xB.$$.fragment),d5t=l(),kf=a("p"),m5t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Rde=a("a"),c5t=o("from_pretrained()"),f5t=o(" class method or the "),Pde=a("a"),g5t=o("from_config()"),h5t=o(` class
method.`),u5t=l(),$B=a("p"),p5t=o("This class cannot be instantiated directly using "),xPe=a("code"),_5t=o("__init__()"),b5t=o(" (throws an error)."),v5t=l(),Ta=a("div"),F(kB.$$.fragment),F5t=l(),$Pe=a("p"),T5t=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),M5t=l(),Sf=a("p"),E5t=o(`Note:
Loading a model from its configuration file does `),kPe=a("strong"),C5t=o("not"),w5t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Bde=a("a"),A5t=o("from_pretrained()"),L5t=o(" to load the model weights."),y5t=l(),F(oy.$$.fragment),x5t=l(),mt=a("div"),F(SB.$$.fragment),$5t=l(),SPe=a("p"),k5t=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),S5t=l(),ns=a("p"),R5t=o("The model class to instantiate is selected based on the "),RPe=a("code"),P5t=o("model_type"),B5t=o(` property of the config object (either
passed as an argument or loaded from `),PPe=a("code"),I5t=o("pretrained_model_name_or_path"),N5t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),BPe=a("code"),q5t=o("pretrained_model_name_or_path"),j5t=o(":"),D5t=l(),Qe=a("ul"),ry=a("li"),IPe=a("strong"),G5t=o("albert"),O5t=o(" \u2014 "),Ide=a("a"),V5t=o("FlaxAlbertForMultipleChoice"),X5t=o(" (ALBERT model)"),z5t=l(),ty=a("li"),NPe=a("strong"),Q5t=o("bert"),W5t=o(" \u2014 "),Nde=a("a"),U5t=o("FlaxBertForMultipleChoice"),H5t=o(" (BERT model)"),J5t=l(),ay=a("li"),qPe=a("strong"),Y5t=o("big_bird"),Z5t=o(" \u2014 "),qde=a("a"),K5t=o("FlaxBigBirdForMultipleChoice"),e0t=o(" (BigBird model)"),o0t=l(),ny=a("li"),jPe=a("strong"),r0t=o("distilbert"),t0t=o(" \u2014 "),jde=a("a"),a0t=o("FlaxDistilBertForMultipleChoice"),n0t=o(" (DistilBERT model)"),s0t=l(),sy=a("li"),DPe=a("strong"),l0t=o("electra"),i0t=o(" \u2014 "),Dde=a("a"),d0t=o("FlaxElectraForMultipleChoice"),m0t=o(" (ELECTRA model)"),c0t=l(),ly=a("li"),GPe=a("strong"),f0t=o("roberta"),g0t=o(" \u2014 "),Gde=a("a"),h0t=o("FlaxRobertaForMultipleChoice"),u0t=o(" (RoBERTa model)"),p0t=l(),iy=a("li"),OPe=a("strong"),_0t=o("roformer"),b0t=o(" \u2014 "),Ode=a("a"),v0t=o("FlaxRoFormerForMultipleChoice"),F0t=o(" (RoFormer model)"),T0t=l(),dy=a("li"),VPe=a("strong"),M0t=o("xlm-roberta"),E0t=o(" \u2014 "),Vde=a("a"),C0t=o("FlaxXLMRobertaForMultipleChoice"),w0t=o(" (XLM-RoBERTa model)"),A0t=l(),F(my.$$.fragment),Ino=l(),Rf=a("h2"),cy=a("a"),XPe=a("span"),F(RB.$$.fragment),L0t=l(),zPe=a("span"),y0t=o("FlaxAutoModelForNextSentencePrediction"),Nno=l(),Br=a("div"),F(PB.$$.fragment),x0t=l(),Pf=a("p"),$0t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Xde=a("a"),k0t=o("from_pretrained()"),S0t=o(" class method or the "),zde=a("a"),R0t=o("from_config()"),P0t=o(` class
method.`),B0t=l(),BB=a("p"),I0t=o("This class cannot be instantiated directly using "),QPe=a("code"),N0t=o("__init__()"),q0t=o(" (throws an error)."),j0t=l(),Ma=a("div"),F(IB.$$.fragment),D0t=l(),WPe=a("p"),G0t=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),O0t=l(),Bf=a("p"),V0t=o(`Note:
Loading a model from its configuration file does `),UPe=a("strong"),X0t=o("not"),z0t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Qde=a("a"),Q0t=o("from_pretrained()"),W0t=o(" to load the model weights."),U0t=l(),F(fy.$$.fragment),H0t=l(),ct=a("div"),F(NB.$$.fragment),J0t=l(),HPe=a("p"),Y0t=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Z0t=l(),ss=a("p"),K0t=o("The model class to instantiate is selected based on the "),JPe=a("code"),ewt=o("model_type"),owt=o(` property of the config object (either
passed as an argument or loaded from `),YPe=a("code"),rwt=o("pretrained_model_name_or_path"),twt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ZPe=a("code"),awt=o("pretrained_model_name_or_path"),nwt=o(":"),swt=l(),KPe=a("ul"),gy=a("li"),eBe=a("strong"),lwt=o("bert"),iwt=o(" \u2014 "),Wde=a("a"),dwt=o("FlaxBertForNextSentencePrediction"),mwt=o(" (BERT model)"),cwt=l(),F(hy.$$.fragment),qno=l(),If=a("h2"),uy=a("a"),oBe=a("span"),F(qB.$$.fragment),fwt=l(),rBe=a("span"),gwt=o("FlaxAutoModelForImageClassification"),jno=l(),Ir=a("div"),F(jB.$$.fragment),hwt=l(),Nf=a("p"),uwt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Ude=a("a"),pwt=o("from_pretrained()"),_wt=o(" class method or the "),Hde=a("a"),bwt=o("from_config()"),vwt=o(` class
method.`),Fwt=l(),DB=a("p"),Twt=o("This class cannot be instantiated directly using "),tBe=a("code"),Mwt=o("__init__()"),Ewt=o(" (throws an error)."),Cwt=l(),Ea=a("div"),F(GB.$$.fragment),wwt=l(),aBe=a("p"),Awt=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Lwt=l(),qf=a("p"),ywt=o(`Note:
Loading a model from its configuration file does `),nBe=a("strong"),xwt=o("not"),$wt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Jde=a("a"),kwt=o("from_pretrained()"),Swt=o(" to load the model weights."),Rwt=l(),F(py.$$.fragment),Pwt=l(),ft=a("div"),F(OB.$$.fragment),Bwt=l(),sBe=a("p"),Iwt=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Nwt=l(),ls=a("p"),qwt=o("The model class to instantiate is selected based on the "),lBe=a("code"),jwt=o("model_type"),Dwt=o(` property of the config object (either
passed as an argument or loaded from `),iBe=a("code"),Gwt=o("pretrained_model_name_or_path"),Owt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dBe=a("code"),Vwt=o("pretrained_model_name_or_path"),Xwt=o(":"),zwt=l(),VB=a("ul"),_y=a("li"),mBe=a("strong"),Qwt=o("beit"),Wwt=o(" \u2014 "),Yde=a("a"),Uwt=o("FlaxBeitForImageClassification"),Hwt=o(" (BEiT model)"),Jwt=l(),by=a("li"),cBe=a("strong"),Ywt=o("vit"),Zwt=o(" \u2014 "),Zde=a("a"),Kwt=o("FlaxViTForImageClassification"),eAt=o(" (ViT model)"),oAt=l(),F(vy.$$.fragment),Dno=l(),jf=a("h2"),Fy=a("a"),fBe=a("span"),F(XB.$$.fragment),rAt=l(),gBe=a("span"),tAt=o("FlaxAutoModelForVision2Seq"),Gno=l(),Nr=a("div"),F(zB.$$.fragment),aAt=l(),Df=a("p"),nAt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Kde=a("a"),sAt=o("from_pretrained()"),lAt=o(" class method or the "),eme=a("a"),iAt=o("from_config()"),dAt=o(` class
method.`),mAt=l(),QB=a("p"),cAt=o("This class cannot be instantiated directly using "),hBe=a("code"),fAt=o("__init__()"),gAt=o(" (throws an error)."),hAt=l(),Ca=a("div"),F(WB.$$.fragment),uAt=l(),uBe=a("p"),pAt=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),_At=l(),Gf=a("p"),bAt=o(`Note:
Loading a model from its configuration file does `),pBe=a("strong"),vAt=o("not"),FAt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ome=a("a"),TAt=o("from_pretrained()"),MAt=o(" to load the model weights."),EAt=l(),F(Ty.$$.fragment),CAt=l(),gt=a("div"),F(UB.$$.fragment),wAt=l(),_Be=a("p"),AAt=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),LAt=l(),is=a("p"),yAt=o("The model class to instantiate is selected based on the "),bBe=a("code"),xAt=o("model_type"),$At=o(` property of the config object (either
passed as an argument or loaded from `),vBe=a("code"),kAt=o("pretrained_model_name_or_path"),SAt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),FBe=a("code"),RAt=o("pretrained_model_name_or_path"),PAt=o(":"),BAt=l(),TBe=a("ul"),My=a("li"),MBe=a("strong"),IAt=o("vision-encoder-decoder"),NAt=o(" \u2014 "),rme=a("a"),qAt=o("FlaxVisionEncoderDecoderModel"),jAt=o(" (Vision Encoder decoder model)"),DAt=l(),F(Ey.$$.fragment),this.h()},l(c){const _=A3a('[data-svelte="svelte-1phssyn"]',document.head);g=n(_,"META",{name:!0,content:!0}),_.forEach(t),v=i(c),u=n(c,"H1",{class:!0});var HB=s(u);f=n(HB,"A",{id:!0,class:!0,href:!0});var EBe=s(f);p=n(EBe,"SPAN",{});var CBe=s(p);T(d.$$.fragment,CBe),CBe.forEach(t),EBe.forEach(t),h=i(HB),$o=n(HB,"SPAN",{});var wBe=s($o);bd=r(wBe,"Auto Classes"),wBe.forEach(t),HB.forEach(t),zf=i(c),Tt=n(c,"P",{});var JB=s(Tt);vd=r(JB,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Fd=n(JB,"CODE",{});var ABe=s(Fd);n$=r(ABe,"from_pretrained()"),ABe.forEach(t),Qf=r(JB,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),JB.forEach(t),Xe=i(c),He=n(c,"P",{});var ds=s(He);Td=r(ds,"Instantiating one of "),ms=n(ds,"A",{href:!0});var LBe=s(ms);s$=r(LBe,"AutoConfig"),LBe.forEach(t),cs=r(ds,", "),fs=n(ds,"A",{href:!0});var yBe=s(fs);l$=r(yBe,"AutoModel"),yBe.forEach(t),Md=r(ds,`, and
`),gs=n(ds,"A",{href:!0});var xBe=s(gs);i$=r(xBe,"AutoTokenizer"),xBe.forEach(t),Ed=r(ds," will directly create a class of the relevant architecture. For instance"),ds.forEach(t),Wf=i(c),T(on.$$.fragment,c),Je=i(c),Ae=n(c,"P",{});var YB=s(Ae);MN=r(YB,"will create a model that is an instance of "),Cd=n(YB,"A",{href:!0});var $Be=s(Cd);EN=r($Be,"BertModel"),$Be.forEach(t),CN=r(YB,"."),YB.forEach(t),ko=i(c),rn=n(c,"P",{});var ZB=s(rn);wN=r(ZB,"There is one class of "),Uf=n(ZB,"CODE",{});var kBe=s(Uf);AN=r(kBe,"AutoModel"),kBe.forEach(t),mio=r(ZB," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),ZB.forEach(t),wto=i(c),wd=n(c,"H2",{class:!0});var KB=s(wd);Hf=n(KB,"A",{id:!0,class:!0,href:!0});var SBe=s(Hf);cfe=n(SBe,"SPAN",{});var RBe=s(cfe);T(d$.$$.fragment,RBe),RBe.forEach(t),SBe.forEach(t),cio=i(KB),ffe=n(KB,"SPAN",{});var PBe=s(ffe);fio=r(PBe,"Extending the Auto Classes"),PBe.forEach(t),KB.forEach(t),Ato=i(c),hs=n(c,"P",{});var Of=s(hs);gio=r(Of,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),gfe=n(Of,"CODE",{});var BBe=s(gfe);hio=r(BBe,"NewModel"),BBe.forEach(t),uio=r(Of,", make sure you have a "),hfe=n(Of,"CODE",{});var IBe=s(hfe);pio=r(IBe,"NewModelConfig"),IBe.forEach(t),_io=r(Of,` then you can add those to the auto
classes like this:`),Of.forEach(t),Lto=i(c),T(m$.$$.fragment,c),yto=i(c),LN=n(c,"P",{});var NBe=s(LN);bio=r(NBe,"You will then be able to use the auto classes like you would usually do!"),NBe.forEach(t),xto=i(c),T(Jf.$$.fragment,c),$to=i(c),Ad=n(c,"H2",{class:!0});var eI=s(Ad);Yf=n(eI,"A",{id:!0,class:!0,href:!0});var qBe=s(Yf);ufe=n(qBe,"SPAN",{});var jBe=s(ufe);T(c$.$$.fragment,jBe),jBe.forEach(t),qBe.forEach(t),vio=i(eI),pfe=n(eI,"SPAN",{});var DBe=s(pfe);Fio=r(DBe,"AutoConfig"),DBe.forEach(t),eI.forEach(t),kto=i(c),So=n(c,"DIV",{class:!0});var vt=s(So);T(f$.$$.fragment,vt),Tio=i(vt),g$=n(vt,"P",{});var oI=s(g$);Mio=r(oI,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),yN=n(oI,"A",{href:!0});var GBe=s(yN);Eio=r(GBe,"from_pretrained()"),GBe.forEach(t),Cio=r(oI," class method."),oI.forEach(t),wio=i(vt),h$=n(vt,"P",{});var rI=s(h$);Aio=r(rI,"This class cannot be instantiated directly using "),_fe=n(rI,"CODE",{});var OBe=s(_fe);Lio=r(OBe,"__init__()"),OBe.forEach(t),yio=r(rI," (throws an error)."),rI.forEach(t),xio=i(vt),qr=n(vt,"DIV",{class:!0});var Ft=s(qr);T(u$.$$.fragment,Ft),$io=i(Ft),bfe=n(Ft,"P",{});var VBe=s(bfe);kio=r(VBe,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),VBe.forEach(t),Sio=i(Ft),Ld=n(Ft,"P",{});var Vf=s(Ld);Rio=r(Vf,"The configuration class to instantiate is selected based on the "),vfe=n(Vf,"CODE",{});var XBe=s(vfe);Pio=r(XBe,"model_type"),XBe.forEach(t),Bio=r(Vf,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Ffe=n(Vf,"CODE",{});var zBe=s(Ffe);Iio=r(zBe,"pretrained_model_name_or_path"),zBe.forEach(t),Nio=r(Vf,":"),Vf.forEach(t),qio=i(Ft),A=n(Ft,"UL",{});var L=s(A);Zf=n(L,"LI",{});var Cy=s(Zf);Tfe=n(Cy,"STRONG",{});var QBe=s(Tfe);jio=r(QBe,"albert"),QBe.forEach(t),Dio=r(Cy," \u2014 "),xN=n(Cy,"A",{href:!0});var WBe=s(xN);Gio=r(WBe,"AlbertConfig"),WBe.forEach(t),Oio=r(Cy," (ALBERT model)"),Cy.forEach(t),Vio=i(L),Kf=n(L,"LI",{});var wy=s(Kf);Mfe=n(wy,"STRONG",{});var UBe=s(Mfe);Xio=r(UBe,"bart"),UBe.forEach(t),zio=r(wy," \u2014 "),$N=n(wy,"A",{href:!0});var HBe=s($N);Qio=r(HBe,"BartConfig"),HBe.forEach(t),Wio=r(wy," (BART model)"),wy.forEach(t),Uio=i(L),eg=n(L,"LI",{});var Ay=s(eg);Efe=n(Ay,"STRONG",{});var JBe=s(Efe);Hio=r(JBe,"beit"),JBe.forEach(t),Jio=r(Ay," \u2014 "),kN=n(Ay,"A",{href:!0});var YBe=s(kN);Yio=r(YBe,"BeitConfig"),YBe.forEach(t),Zio=r(Ay," (BEiT model)"),Ay.forEach(t),Kio=i(L),og=n(L,"LI",{});var Ly=s(og);Cfe=n(Ly,"STRONG",{});var ZBe=s(Cfe);edo=r(ZBe,"bert"),ZBe.forEach(t),odo=r(Ly," \u2014 "),SN=n(Ly,"A",{href:!0});var KBe=s(SN);rdo=r(KBe,"BertConfig"),KBe.forEach(t),tdo=r(Ly," (BERT model)"),Ly.forEach(t),ado=i(L),rg=n(L,"LI",{});var yy=s(rg);wfe=n(yy,"STRONG",{});var eIe=s(wfe);ndo=r(eIe,"bert-generation"),eIe.forEach(t),sdo=r(yy," \u2014 "),RN=n(yy,"A",{href:!0});var oIe=s(RN);ldo=r(oIe,"BertGenerationConfig"),oIe.forEach(t),ido=r(yy," (Bert Generation model)"),yy.forEach(t),ddo=i(L),tg=n(L,"LI",{});var xy=s(tg);Afe=n(xy,"STRONG",{});var rIe=s(Afe);mdo=r(rIe,"big_bird"),rIe.forEach(t),cdo=r(xy," \u2014 "),PN=n(xy,"A",{href:!0});var tIe=s(PN);fdo=r(tIe,"BigBirdConfig"),tIe.forEach(t),gdo=r(xy," (BigBird model)"),xy.forEach(t),hdo=i(L),ag=n(L,"LI",{});var $y=s(ag);Lfe=n($y,"STRONG",{});var aIe=s(Lfe);udo=r(aIe,"bigbird_pegasus"),aIe.forEach(t),pdo=r($y," \u2014 "),BN=n($y,"A",{href:!0});var nIe=s(BN);_do=r(nIe,"BigBirdPegasusConfig"),nIe.forEach(t),bdo=r($y," (BigBird-Pegasus model)"),$y.forEach(t),vdo=i(L),ng=n(L,"LI",{});var ky=s(ng);yfe=n(ky,"STRONG",{});var sIe=s(yfe);Fdo=r(sIe,"blenderbot"),sIe.forEach(t),Tdo=r(ky," \u2014 "),IN=n(ky,"A",{href:!0});var lIe=s(IN);Mdo=r(lIe,"BlenderbotConfig"),lIe.forEach(t),Edo=r(ky," (Blenderbot model)"),ky.forEach(t),Cdo=i(L),sg=n(L,"LI",{});var Sy=s(sg);xfe=n(Sy,"STRONG",{});var iIe=s(xfe);wdo=r(iIe,"blenderbot-small"),iIe.forEach(t),Ado=r(Sy," \u2014 "),NN=n(Sy,"A",{href:!0});var dIe=s(NN);Ldo=r(dIe,"BlenderbotSmallConfig"),dIe.forEach(t),ydo=r(Sy," (BlenderbotSmall model)"),Sy.forEach(t),xdo=i(L),lg=n(L,"LI",{});var Ry=s(lg);$fe=n(Ry,"STRONG",{});var mIe=s($fe);$do=r(mIe,"bloom"),mIe.forEach(t),kdo=r(Ry," \u2014 "),qN=n(Ry,"A",{href:!0});var cIe=s(qN);Sdo=r(cIe,"BloomConfig"),cIe.forEach(t),Rdo=r(Ry," (BLOOM model)"),Ry.forEach(t),Pdo=i(L),ig=n(L,"LI",{});var Py=s(ig);kfe=n(Py,"STRONG",{});var fIe=s(kfe);Bdo=r(fIe,"camembert"),fIe.forEach(t),Ido=r(Py," \u2014 "),jN=n(Py,"A",{href:!0});var gIe=s(jN);Ndo=r(gIe,"CamembertConfig"),gIe.forEach(t),qdo=r(Py," (CamemBERT model)"),Py.forEach(t),jdo=i(L),dg=n(L,"LI",{});var By=s(dg);Sfe=n(By,"STRONG",{});var hIe=s(Sfe);Ddo=r(hIe,"canine"),hIe.forEach(t),Gdo=r(By," \u2014 "),DN=n(By,"A",{href:!0});var uIe=s(DN);Odo=r(uIe,"CanineConfig"),uIe.forEach(t),Vdo=r(By," (CANINE model)"),By.forEach(t),Xdo=i(L),mg=n(L,"LI",{});var Iy=s(mg);Rfe=n(Iy,"STRONG",{});var pIe=s(Rfe);zdo=r(pIe,"clip"),pIe.forEach(t),Qdo=r(Iy," \u2014 "),GN=n(Iy,"A",{href:!0});var _Ie=s(GN);Wdo=r(_Ie,"CLIPConfig"),_Ie.forEach(t),Udo=r(Iy," (CLIP model)"),Iy.forEach(t),Hdo=i(L),cg=n(L,"LI",{});var Ny=s(cg);Pfe=n(Ny,"STRONG",{});var bIe=s(Pfe);Jdo=r(bIe,"codegen"),bIe.forEach(t),Ydo=r(Ny," \u2014 "),ON=n(Ny,"A",{href:!0});var vIe=s(ON);Zdo=r(vIe,"CodeGenConfig"),vIe.forEach(t),Kdo=r(Ny," (CodeGen model)"),Ny.forEach(t),emo=i(L),fg=n(L,"LI",{});var qy=s(fg);Bfe=n(qy,"STRONG",{});var FIe=s(Bfe);omo=r(FIe,"conditional_detr"),FIe.forEach(t),rmo=r(qy," \u2014 "),VN=n(qy,"A",{href:!0});var TIe=s(VN);tmo=r(TIe,"ConditionalDetrConfig"),TIe.forEach(t),amo=r(qy," (Conditional DETR model)"),qy.forEach(t),nmo=i(L),gg=n(L,"LI",{});var jy=s(gg);Ife=n(jy,"STRONG",{});var MIe=s(Ife);smo=r(MIe,"convbert"),MIe.forEach(t),lmo=r(jy," \u2014 "),XN=n(jy,"A",{href:!0});var EIe=s(XN);imo=r(EIe,"ConvBertConfig"),EIe.forEach(t),dmo=r(jy," (ConvBERT model)"),jy.forEach(t),mmo=i(L),hg=n(L,"LI",{});var Dy=s(hg);Nfe=n(Dy,"STRONG",{});var CIe=s(Nfe);cmo=r(CIe,"convnext"),CIe.forEach(t),fmo=r(Dy," \u2014 "),zN=n(Dy,"A",{href:!0});var wIe=s(zN);gmo=r(wIe,"ConvNextConfig"),wIe.forEach(t),hmo=r(Dy," (ConvNeXT model)"),Dy.forEach(t),umo=i(L),ug=n(L,"LI",{});var Gy=s(ug);qfe=n(Gy,"STRONG",{});var AIe=s(qfe);pmo=r(AIe,"ctrl"),AIe.forEach(t),_mo=r(Gy," \u2014 "),QN=n(Gy,"A",{href:!0});var LIe=s(QN);bmo=r(LIe,"CTRLConfig"),LIe.forEach(t),vmo=r(Gy," (CTRL model)"),Gy.forEach(t),Fmo=i(L),pg=n(L,"LI",{});var Oy=s(pg);jfe=n(Oy,"STRONG",{});var yIe=s(jfe);Tmo=r(yIe,"cvt"),yIe.forEach(t),Mmo=r(Oy," \u2014 "),WN=n(Oy,"A",{href:!0});var xIe=s(WN);Emo=r(xIe,"CvtConfig"),xIe.forEach(t),Cmo=r(Oy," (CvT model)"),Oy.forEach(t),wmo=i(L),_g=n(L,"LI",{});var Vy=s(_g);Dfe=n(Vy,"STRONG",{});var $Ie=s(Dfe);Amo=r($Ie,"data2vec-audio"),$Ie.forEach(t),Lmo=r(Vy," \u2014 "),UN=n(Vy,"A",{href:!0});var kIe=s(UN);ymo=r(kIe,"Data2VecAudioConfig"),kIe.forEach(t),xmo=r(Vy," (Data2VecAudio model)"),Vy.forEach(t),$mo=i(L),bg=n(L,"LI",{});var Xy=s(bg);Gfe=n(Xy,"STRONG",{});var SIe=s(Gfe);kmo=r(SIe,"data2vec-text"),SIe.forEach(t),Smo=r(Xy," \u2014 "),HN=n(Xy,"A",{href:!0});var RIe=s(HN);Rmo=r(RIe,"Data2VecTextConfig"),RIe.forEach(t),Pmo=r(Xy," (Data2VecText model)"),Xy.forEach(t),Bmo=i(L),vg=n(L,"LI",{});var zy=s(vg);Ofe=n(zy,"STRONG",{});var PIe=s(Ofe);Imo=r(PIe,"data2vec-vision"),PIe.forEach(t),Nmo=r(zy," \u2014 "),JN=n(zy,"A",{href:!0});var BIe=s(JN);qmo=r(BIe,"Data2VecVisionConfig"),BIe.forEach(t),jmo=r(zy," (Data2VecVision model)"),zy.forEach(t),Dmo=i(L),Fg=n(L,"LI",{});var Qy=s(Fg);Vfe=n(Qy,"STRONG",{});var IIe=s(Vfe);Gmo=r(IIe,"deberta"),IIe.forEach(t),Omo=r(Qy," \u2014 "),YN=n(Qy,"A",{href:!0});var NIe=s(YN);Vmo=r(NIe,"DebertaConfig"),NIe.forEach(t),Xmo=r(Qy," (DeBERTa model)"),Qy.forEach(t),zmo=i(L),Tg=n(L,"LI",{});var Wy=s(Tg);Xfe=n(Wy,"STRONG",{});var qIe=s(Xfe);Qmo=r(qIe,"deberta-v2"),qIe.forEach(t),Wmo=r(Wy," \u2014 "),ZN=n(Wy,"A",{href:!0});var jIe=s(ZN);Umo=r(jIe,"DebertaV2Config"),jIe.forEach(t),Hmo=r(Wy," (DeBERTa-v2 model)"),Wy.forEach(t),Jmo=i(L),Mg=n(L,"LI",{});var Uy=s(Mg);zfe=n(Uy,"STRONG",{});var DIe=s(zfe);Ymo=r(DIe,"decision_transformer"),DIe.forEach(t),Zmo=r(Uy," \u2014 "),KN=n(Uy,"A",{href:!0});var GIe=s(KN);Kmo=r(GIe,"DecisionTransformerConfig"),GIe.forEach(t),eco=r(Uy," (Decision Transformer model)"),Uy.forEach(t),oco=i(L),Eg=n(L,"LI",{});var Hy=s(Eg);Qfe=n(Hy,"STRONG",{});var OIe=s(Qfe);rco=r(OIe,"deformable_detr"),OIe.forEach(t),tco=r(Hy," \u2014 "),eq=n(Hy,"A",{href:!0});var VIe=s(eq);aco=r(VIe,"DeformableDetrConfig"),VIe.forEach(t),nco=r(Hy," (Deformable DETR model)"),Hy.forEach(t),sco=i(L),Cg=n(L,"LI",{});var Jy=s(Cg);Wfe=n(Jy,"STRONG",{});var XIe=s(Wfe);lco=r(XIe,"deit"),XIe.forEach(t),ico=r(Jy," \u2014 "),oq=n(Jy,"A",{href:!0});var zIe=s(oq);dco=r(zIe,"DeiTConfig"),zIe.forEach(t),mco=r(Jy," (DeiT model)"),Jy.forEach(t),cco=i(L),wg=n(L,"LI",{});var Yy=s(wg);Ufe=n(Yy,"STRONG",{});var OAt=s(Ufe);fco=r(OAt,"detr"),OAt.forEach(t),gco=r(Yy," \u2014 "),rq=n(Yy,"A",{href:!0});var VAt=s(rq);hco=r(VAt,"DetrConfig"),VAt.forEach(t),uco=r(Yy," (DETR model)"),Yy.forEach(t),pco=i(L),Ag=n(L,"LI",{});var QIe=s(Ag);Hfe=n(QIe,"STRONG",{});var XAt=s(Hfe);_co=r(XAt,"distilbert"),XAt.forEach(t),bco=r(QIe," \u2014 "),tq=n(QIe,"A",{href:!0});var zAt=s(tq);vco=r(zAt,"DistilBertConfig"),zAt.forEach(t),Fco=r(QIe," (DistilBERT model)"),QIe.forEach(t),Tco=i(L),Lg=n(L,"LI",{});var WIe=s(Lg);Jfe=n(WIe,"STRONG",{});var QAt=s(Jfe);Mco=r(QAt,"donut-swin"),QAt.forEach(t),Eco=r(WIe," \u2014 "),aq=n(WIe,"A",{href:!0});var WAt=s(aq);Cco=r(WAt,"DonutSwinConfig"),WAt.forEach(t),wco=r(WIe," (DonutSwin model)"),WIe.forEach(t),Aco=i(L),yg=n(L,"LI",{});var UIe=s(yg);Yfe=n(UIe,"STRONG",{});var UAt=s(Yfe);Lco=r(UAt,"dpr"),UAt.forEach(t),yco=r(UIe," \u2014 "),nq=n(UIe,"A",{href:!0});var HAt=s(nq);xco=r(HAt,"DPRConfig"),HAt.forEach(t),$co=r(UIe," (DPR model)"),UIe.forEach(t),kco=i(L),xg=n(L,"LI",{});var HIe=s(xg);Zfe=n(HIe,"STRONG",{});var JAt=s(Zfe);Sco=r(JAt,"dpt"),JAt.forEach(t),Rco=r(HIe," \u2014 "),sq=n(HIe,"A",{href:!0});var YAt=s(sq);Pco=r(YAt,"DPTConfig"),YAt.forEach(t),Bco=r(HIe," (DPT model)"),HIe.forEach(t),Ico=i(L),$g=n(L,"LI",{});var JIe=s($g);Kfe=n(JIe,"STRONG",{});var ZAt=s(Kfe);Nco=r(ZAt,"electra"),ZAt.forEach(t),qco=r(JIe," \u2014 "),lq=n(JIe,"A",{href:!0});var KAt=s(lq);jco=r(KAt,"ElectraConfig"),KAt.forEach(t),Dco=r(JIe," (ELECTRA model)"),JIe.forEach(t),Gco=i(L),kg=n(L,"LI",{});var YIe=s(kg);ege=n(YIe,"STRONG",{});var e6t=s(ege);Oco=r(e6t,"encoder-decoder"),e6t.forEach(t),Vco=r(YIe," \u2014 "),iq=n(YIe,"A",{href:!0});var o6t=s(iq);Xco=r(o6t,"EncoderDecoderConfig"),o6t.forEach(t),zco=r(YIe," (Encoder decoder model)"),YIe.forEach(t),Qco=i(L),Sg=n(L,"LI",{});var ZIe=s(Sg);oge=n(ZIe,"STRONG",{});var r6t=s(oge);Wco=r(r6t,"ernie"),r6t.forEach(t),Uco=r(ZIe," \u2014 "),dq=n(ZIe,"A",{href:!0});var t6t=s(dq);Hco=r(t6t,"ErnieConfig"),t6t.forEach(t),Jco=r(ZIe," (ERNIE model)"),ZIe.forEach(t),Yco=i(L),Rg=n(L,"LI",{});var KIe=s(Rg);rge=n(KIe,"STRONG",{});var a6t=s(rge);Zco=r(a6t,"esm"),a6t.forEach(t),Kco=r(KIe," \u2014 "),mq=n(KIe,"A",{href:!0});var n6t=s(mq);efo=r(n6t,"EsmConfig"),n6t.forEach(t),ofo=r(KIe," (ESM model)"),KIe.forEach(t),rfo=i(L),Pg=n(L,"LI",{});var eNe=s(Pg);tge=n(eNe,"STRONG",{});var s6t=s(tge);tfo=r(s6t,"flaubert"),s6t.forEach(t),afo=r(eNe," \u2014 "),cq=n(eNe,"A",{href:!0});var l6t=s(cq);nfo=r(l6t,"FlaubertConfig"),l6t.forEach(t),sfo=r(eNe," (FlauBERT model)"),eNe.forEach(t),lfo=i(L),Bg=n(L,"LI",{});var oNe=s(Bg);age=n(oNe,"STRONG",{});var i6t=s(age);ifo=r(i6t,"flava"),i6t.forEach(t),dfo=r(oNe," \u2014 "),fq=n(oNe,"A",{href:!0});var d6t=s(fq);mfo=r(d6t,"FlavaConfig"),d6t.forEach(t),cfo=r(oNe," (FLAVA model)"),oNe.forEach(t),ffo=i(L),Ig=n(L,"LI",{});var rNe=s(Ig);nge=n(rNe,"STRONG",{});var m6t=s(nge);gfo=r(m6t,"fnet"),m6t.forEach(t),hfo=r(rNe," \u2014 "),gq=n(rNe,"A",{href:!0});var c6t=s(gq);ufo=r(c6t,"FNetConfig"),c6t.forEach(t),pfo=r(rNe," (FNet model)"),rNe.forEach(t),_fo=i(L),Ng=n(L,"LI",{});var tNe=s(Ng);sge=n(tNe,"STRONG",{});var f6t=s(sge);bfo=r(f6t,"fsmt"),f6t.forEach(t),vfo=r(tNe," \u2014 "),hq=n(tNe,"A",{href:!0});var g6t=s(hq);Ffo=r(g6t,"FSMTConfig"),g6t.forEach(t),Tfo=r(tNe," (FairSeq Machine-Translation model)"),tNe.forEach(t),Mfo=i(L),qg=n(L,"LI",{});var aNe=s(qg);lge=n(aNe,"STRONG",{});var h6t=s(lge);Efo=r(h6t,"funnel"),h6t.forEach(t),Cfo=r(aNe," \u2014 "),uq=n(aNe,"A",{href:!0});var u6t=s(uq);wfo=r(u6t,"FunnelConfig"),u6t.forEach(t),Afo=r(aNe," (Funnel Transformer model)"),aNe.forEach(t),Lfo=i(L),jg=n(L,"LI",{});var nNe=s(jg);ige=n(nNe,"STRONG",{});var p6t=s(ige);yfo=r(p6t,"glpn"),p6t.forEach(t),xfo=r(nNe," \u2014 "),pq=n(nNe,"A",{href:!0});var _6t=s(pq);$fo=r(_6t,"GLPNConfig"),_6t.forEach(t),kfo=r(nNe," (GLPN model)"),nNe.forEach(t),Sfo=i(L),Dg=n(L,"LI",{});var sNe=s(Dg);dge=n(sNe,"STRONG",{});var b6t=s(dge);Rfo=r(b6t,"gpt2"),b6t.forEach(t),Pfo=r(sNe," \u2014 "),_q=n(sNe,"A",{href:!0});var v6t=s(_q);Bfo=r(v6t,"GPT2Config"),v6t.forEach(t),Ifo=r(sNe," (OpenAI GPT-2 model)"),sNe.forEach(t),Nfo=i(L),Gg=n(L,"LI",{});var lNe=s(Gg);mge=n(lNe,"STRONG",{});var F6t=s(mge);qfo=r(F6t,"gpt_neo"),F6t.forEach(t),jfo=r(lNe," \u2014 "),bq=n(lNe,"A",{href:!0});var T6t=s(bq);Dfo=r(T6t,"GPTNeoConfig"),T6t.forEach(t),Gfo=r(lNe," (GPT Neo model)"),lNe.forEach(t),Ofo=i(L),Og=n(L,"LI",{});var iNe=s(Og);cge=n(iNe,"STRONG",{});var M6t=s(cge);Vfo=r(M6t,"gpt_neox"),M6t.forEach(t),Xfo=r(iNe," \u2014 "),vq=n(iNe,"A",{href:!0});var E6t=s(vq);zfo=r(E6t,"GPTNeoXConfig"),E6t.forEach(t),Qfo=r(iNe," (GPT NeoX model)"),iNe.forEach(t),Wfo=i(L),Vg=n(L,"LI",{});var dNe=s(Vg);fge=n(dNe,"STRONG",{});var C6t=s(fge);Ufo=r(C6t,"gpt_neox_japanese"),C6t.forEach(t),Hfo=r(dNe," \u2014 "),Fq=n(dNe,"A",{href:!0});var w6t=s(Fq);Jfo=r(w6t,"GPTNeoXJapaneseConfig"),w6t.forEach(t),Yfo=r(dNe," (GPT NeoX Japanese model)"),dNe.forEach(t),Zfo=i(L),Xg=n(L,"LI",{});var mNe=s(Xg);gge=n(mNe,"STRONG",{});var A6t=s(gge);Kfo=r(A6t,"gptj"),A6t.forEach(t),ego=r(mNe," \u2014 "),Tq=n(mNe,"A",{href:!0});var L6t=s(Tq);ogo=r(L6t,"GPTJConfig"),L6t.forEach(t),rgo=r(mNe," (GPT-J model)"),mNe.forEach(t),tgo=i(L),zg=n(L,"LI",{});var cNe=s(zg);hge=n(cNe,"STRONG",{});var y6t=s(hge);ago=r(y6t,"groupvit"),y6t.forEach(t),ngo=r(cNe," \u2014 "),Mq=n(cNe,"A",{href:!0});var x6t=s(Mq);sgo=r(x6t,"GroupViTConfig"),x6t.forEach(t),lgo=r(cNe," (GroupViT model)"),cNe.forEach(t),igo=i(L),Qg=n(L,"LI",{});var fNe=s(Qg);uge=n(fNe,"STRONG",{});var $6t=s(uge);dgo=r($6t,"hubert"),$6t.forEach(t),mgo=r(fNe," \u2014 "),Eq=n(fNe,"A",{href:!0});var k6t=s(Eq);cgo=r(k6t,"HubertConfig"),k6t.forEach(t),fgo=r(fNe," (Hubert model)"),fNe.forEach(t),ggo=i(L),Wg=n(L,"LI",{});var gNe=s(Wg);pge=n(gNe,"STRONG",{});var S6t=s(pge);hgo=r(S6t,"ibert"),S6t.forEach(t),ugo=r(gNe," \u2014 "),Cq=n(gNe,"A",{href:!0});var R6t=s(Cq);pgo=r(R6t,"IBertConfig"),R6t.forEach(t),_go=r(gNe," (I-BERT model)"),gNe.forEach(t),bgo=i(L),Ug=n(L,"LI",{});var hNe=s(Ug);_ge=n(hNe,"STRONG",{});var P6t=s(_ge);vgo=r(P6t,"imagegpt"),P6t.forEach(t),Fgo=r(hNe," \u2014 "),wq=n(hNe,"A",{href:!0});var B6t=s(wq);Tgo=r(B6t,"ImageGPTConfig"),B6t.forEach(t),Mgo=r(hNe," (ImageGPT model)"),hNe.forEach(t),Ego=i(L),Hg=n(L,"LI",{});var uNe=s(Hg);bge=n(uNe,"STRONG",{});var I6t=s(bge);Cgo=r(I6t,"layoutlm"),I6t.forEach(t),wgo=r(uNe," \u2014 "),Aq=n(uNe,"A",{href:!0});var N6t=s(Aq);Ago=r(N6t,"LayoutLMConfig"),N6t.forEach(t),Lgo=r(uNe," (LayoutLM model)"),uNe.forEach(t),ygo=i(L),Jg=n(L,"LI",{});var pNe=s(Jg);vge=n(pNe,"STRONG",{});var q6t=s(vge);xgo=r(q6t,"layoutlmv2"),q6t.forEach(t),$go=r(pNe," \u2014 "),Lq=n(pNe,"A",{href:!0});var j6t=s(Lq);kgo=r(j6t,"LayoutLMv2Config"),j6t.forEach(t),Sgo=r(pNe," (LayoutLMv2 model)"),pNe.forEach(t),Rgo=i(L),Yg=n(L,"LI",{});var _Ne=s(Yg);Fge=n(_Ne,"STRONG",{});var D6t=s(Fge);Pgo=r(D6t,"layoutlmv3"),D6t.forEach(t),Bgo=r(_Ne," \u2014 "),yq=n(_Ne,"A",{href:!0});var G6t=s(yq);Igo=r(G6t,"LayoutLMv3Config"),G6t.forEach(t),Ngo=r(_Ne," (LayoutLMv3 model)"),_Ne.forEach(t),qgo=i(L),Zg=n(L,"LI",{});var bNe=s(Zg);Tge=n(bNe,"STRONG",{});var O6t=s(Tge);jgo=r(O6t,"led"),O6t.forEach(t),Dgo=r(bNe," \u2014 "),xq=n(bNe,"A",{href:!0});var V6t=s(xq);Ggo=r(V6t,"LEDConfig"),V6t.forEach(t),Ogo=r(bNe," (LED model)"),bNe.forEach(t),Vgo=i(L),Kg=n(L,"LI",{});var vNe=s(Kg);Mge=n(vNe,"STRONG",{});var X6t=s(Mge);Xgo=r(X6t,"levit"),X6t.forEach(t),zgo=r(vNe," \u2014 "),$q=n(vNe,"A",{href:!0});var z6t=s($q);Qgo=r(z6t,"LevitConfig"),z6t.forEach(t),Wgo=r(vNe," (LeViT model)"),vNe.forEach(t),Ugo=i(L),eh=n(L,"LI",{});var FNe=s(eh);Ege=n(FNe,"STRONG",{});var Q6t=s(Ege);Hgo=r(Q6t,"lilt"),Q6t.forEach(t),Jgo=r(FNe," \u2014 "),kq=n(FNe,"A",{href:!0});var W6t=s(kq);Ygo=r(W6t,"LiltConfig"),W6t.forEach(t),Zgo=r(FNe," (LiLT model)"),FNe.forEach(t),Kgo=i(L),oh=n(L,"LI",{});var TNe=s(oh);Cge=n(TNe,"STRONG",{});var U6t=s(Cge);eho=r(U6t,"longformer"),U6t.forEach(t),oho=r(TNe," \u2014 "),Sq=n(TNe,"A",{href:!0});var H6t=s(Sq);rho=r(H6t,"LongformerConfig"),H6t.forEach(t),tho=r(TNe," (Longformer model)"),TNe.forEach(t),aho=i(L),rh=n(L,"LI",{});var MNe=s(rh);wge=n(MNe,"STRONG",{});var J6t=s(wge);nho=r(J6t,"longt5"),J6t.forEach(t),sho=r(MNe," \u2014 "),Rq=n(MNe,"A",{href:!0});var Y6t=s(Rq);lho=r(Y6t,"LongT5Config"),Y6t.forEach(t),iho=r(MNe," (LongT5 model)"),MNe.forEach(t),dho=i(L),th=n(L,"LI",{});var ENe=s(th);Age=n(ENe,"STRONG",{});var Z6t=s(Age);mho=r(Z6t,"luke"),Z6t.forEach(t),cho=r(ENe," \u2014 "),Pq=n(ENe,"A",{href:!0});var K6t=s(Pq);fho=r(K6t,"LukeConfig"),K6t.forEach(t),gho=r(ENe," (LUKE model)"),ENe.forEach(t),hho=i(L),ah=n(L,"LI",{});var CNe=s(ah);Lge=n(CNe,"STRONG",{});var e7t=s(Lge);uho=r(e7t,"lxmert"),e7t.forEach(t),pho=r(CNe," \u2014 "),Bq=n(CNe,"A",{href:!0});var o7t=s(Bq);_ho=r(o7t,"LxmertConfig"),o7t.forEach(t),bho=r(CNe," (LXMERT model)"),CNe.forEach(t),vho=i(L),nh=n(L,"LI",{});var wNe=s(nh);yge=n(wNe,"STRONG",{});var r7t=s(yge);Fho=r(r7t,"m2m_100"),r7t.forEach(t),Tho=r(wNe," \u2014 "),Iq=n(wNe,"A",{href:!0});var t7t=s(Iq);Mho=r(t7t,"M2M100Config"),t7t.forEach(t),Eho=r(wNe," (M2M100 model)"),wNe.forEach(t),Cho=i(L),sh=n(L,"LI",{});var ANe=s(sh);xge=n(ANe,"STRONG",{});var a7t=s(xge);who=r(a7t,"marian"),a7t.forEach(t),Aho=r(ANe," \u2014 "),Nq=n(ANe,"A",{href:!0});var n7t=s(Nq);Lho=r(n7t,"MarianConfig"),n7t.forEach(t),yho=r(ANe," (Marian model)"),ANe.forEach(t),xho=i(L),lh=n(L,"LI",{});var LNe=s(lh);$ge=n(LNe,"STRONG",{});var s7t=s($ge);$ho=r(s7t,"markuplm"),s7t.forEach(t),kho=r(LNe," \u2014 "),qq=n(LNe,"A",{href:!0});var l7t=s(qq);Sho=r(l7t,"MarkupLMConfig"),l7t.forEach(t),Rho=r(LNe," (MarkupLM model)"),LNe.forEach(t),Pho=i(L),ih=n(L,"LI",{});var yNe=s(ih);kge=n(yNe,"STRONG",{});var i7t=s(kge);Bho=r(i7t,"maskformer"),i7t.forEach(t),Iho=r(yNe," \u2014 "),jq=n(yNe,"A",{href:!0});var d7t=s(jq);Nho=r(d7t,"MaskFormerConfig"),d7t.forEach(t),qho=r(yNe," (MaskFormer model)"),yNe.forEach(t),jho=i(L),dh=n(L,"LI",{});var xNe=s(dh);Sge=n(xNe,"STRONG",{});var m7t=s(Sge);Dho=r(m7t,"mbart"),m7t.forEach(t),Gho=r(xNe," \u2014 "),Dq=n(xNe,"A",{href:!0});var c7t=s(Dq);Oho=r(c7t,"MBartConfig"),c7t.forEach(t),Vho=r(xNe," (mBART model)"),xNe.forEach(t),Xho=i(L),mh=n(L,"LI",{});var $Ne=s(mh);Rge=n($Ne,"STRONG",{});var f7t=s(Rge);zho=r(f7t,"mctct"),f7t.forEach(t),Qho=r($Ne," \u2014 "),Gq=n($Ne,"A",{href:!0});var g7t=s(Gq);Who=r(g7t,"MCTCTConfig"),g7t.forEach(t),Uho=r($Ne," (M-CTC-T model)"),$Ne.forEach(t),Hho=i(L),ch=n(L,"LI",{});var kNe=s(ch);Pge=n(kNe,"STRONG",{});var h7t=s(Pge);Jho=r(h7t,"megatron-bert"),h7t.forEach(t),Yho=r(kNe," \u2014 "),Oq=n(kNe,"A",{href:!0});var u7t=s(Oq);Zho=r(u7t,"MegatronBertConfig"),u7t.forEach(t),Kho=r(kNe," (Megatron-BERT model)"),kNe.forEach(t),euo=i(L),fh=n(L,"LI",{});var SNe=s(fh);Bge=n(SNe,"STRONG",{});var p7t=s(Bge);ouo=r(p7t,"mobilebert"),p7t.forEach(t),ruo=r(SNe," \u2014 "),Vq=n(SNe,"A",{href:!0});var _7t=s(Vq);tuo=r(_7t,"MobileBertConfig"),_7t.forEach(t),auo=r(SNe," (MobileBERT model)"),SNe.forEach(t),nuo=i(L),gh=n(L,"LI",{});var RNe=s(gh);Ige=n(RNe,"STRONG",{});var b7t=s(Ige);suo=r(b7t,"mobilevit"),b7t.forEach(t),luo=r(RNe," \u2014 "),Xq=n(RNe,"A",{href:!0});var v7t=s(Xq);iuo=r(v7t,"MobileViTConfig"),v7t.forEach(t),duo=r(RNe," (MobileViT model)"),RNe.forEach(t),muo=i(L),hh=n(L,"LI",{});var PNe=s(hh);Nge=n(PNe,"STRONG",{});var F7t=s(Nge);cuo=r(F7t,"mpnet"),F7t.forEach(t),fuo=r(PNe," \u2014 "),zq=n(PNe,"A",{href:!0});var T7t=s(zq);guo=r(T7t,"MPNetConfig"),T7t.forEach(t),huo=r(PNe," (MPNet model)"),PNe.forEach(t),uuo=i(L),uh=n(L,"LI",{});var BNe=s(uh);qge=n(BNe,"STRONG",{});var M7t=s(qge);puo=r(M7t,"mt5"),M7t.forEach(t),_uo=r(BNe," \u2014 "),Qq=n(BNe,"A",{href:!0});var E7t=s(Qq);buo=r(E7t,"MT5Config"),E7t.forEach(t),vuo=r(BNe," (MT5 model)"),BNe.forEach(t),Fuo=i(L),ph=n(L,"LI",{});var INe=s(ph);jge=n(INe,"STRONG",{});var C7t=s(jge);Tuo=r(C7t,"mvp"),C7t.forEach(t),Muo=r(INe," \u2014 "),Wq=n(INe,"A",{href:!0});var w7t=s(Wq);Euo=r(w7t,"MvpConfig"),w7t.forEach(t),Cuo=r(INe," (MVP model)"),INe.forEach(t),wuo=i(L),_h=n(L,"LI",{});var NNe=s(_h);Dge=n(NNe,"STRONG",{});var A7t=s(Dge);Auo=r(A7t,"nezha"),A7t.forEach(t),Luo=r(NNe," \u2014 "),Uq=n(NNe,"A",{href:!0});var L7t=s(Uq);yuo=r(L7t,"NezhaConfig"),L7t.forEach(t),xuo=r(NNe," (Nezha model)"),NNe.forEach(t),$uo=i(L),bh=n(L,"LI",{});var qNe=s(bh);Gge=n(qNe,"STRONG",{});var y7t=s(Gge);kuo=r(y7t,"nystromformer"),y7t.forEach(t),Suo=r(qNe," \u2014 "),Hq=n(qNe,"A",{href:!0});var x7t=s(Hq);Ruo=r(x7t,"NystromformerConfig"),x7t.forEach(t),Puo=r(qNe," (Nystr\xF6mformer model)"),qNe.forEach(t),Buo=i(L),vh=n(L,"LI",{});var jNe=s(vh);Oge=n(jNe,"STRONG",{});var $7t=s(Oge);Iuo=r($7t,"openai-gpt"),$7t.forEach(t),Nuo=r(jNe," \u2014 "),Jq=n(jNe,"A",{href:!0});var k7t=s(Jq);quo=r(k7t,"OpenAIGPTConfig"),k7t.forEach(t),juo=r(jNe," (OpenAI GPT model)"),jNe.forEach(t),Duo=i(L),Fh=n(L,"LI",{});var DNe=s(Fh);Vge=n(DNe,"STRONG",{});var S7t=s(Vge);Guo=r(S7t,"opt"),S7t.forEach(t),Ouo=r(DNe," \u2014 "),Yq=n(DNe,"A",{href:!0});var R7t=s(Yq);Vuo=r(R7t,"OPTConfig"),R7t.forEach(t),Xuo=r(DNe," (OPT model)"),DNe.forEach(t),zuo=i(L),Th=n(L,"LI",{});var GNe=s(Th);Xge=n(GNe,"STRONG",{});var P7t=s(Xge);Quo=r(P7t,"owlvit"),P7t.forEach(t),Wuo=r(GNe," \u2014 "),Zq=n(GNe,"A",{href:!0});var B7t=s(Zq);Uuo=r(B7t,"OwlViTConfig"),B7t.forEach(t),Huo=r(GNe," (OWL-ViT model)"),GNe.forEach(t),Juo=i(L),Mh=n(L,"LI",{});var ONe=s(Mh);zge=n(ONe,"STRONG",{});var I7t=s(zge);Yuo=r(I7t,"pegasus"),I7t.forEach(t),Zuo=r(ONe," \u2014 "),Kq=n(ONe,"A",{href:!0});var N7t=s(Kq);Kuo=r(N7t,"PegasusConfig"),N7t.forEach(t),epo=r(ONe," (Pegasus model)"),ONe.forEach(t),opo=i(L),Eh=n(L,"LI",{});var VNe=s(Eh);Qge=n(VNe,"STRONG",{});var q7t=s(Qge);rpo=r(q7t,"pegasus_x"),q7t.forEach(t),tpo=r(VNe," \u2014 "),ej=n(VNe,"A",{href:!0});var j7t=s(ej);apo=r(j7t,"PegasusXConfig"),j7t.forEach(t),npo=r(VNe," (PEGASUS-X model)"),VNe.forEach(t),spo=i(L),Ch=n(L,"LI",{});var XNe=s(Ch);Wge=n(XNe,"STRONG",{});var D7t=s(Wge);lpo=r(D7t,"perceiver"),D7t.forEach(t),ipo=r(XNe," \u2014 "),oj=n(XNe,"A",{href:!0});var G7t=s(oj);dpo=r(G7t,"PerceiverConfig"),G7t.forEach(t),mpo=r(XNe," (Perceiver model)"),XNe.forEach(t),cpo=i(L),wh=n(L,"LI",{});var zNe=s(wh);Uge=n(zNe,"STRONG",{});var O7t=s(Uge);fpo=r(O7t,"plbart"),O7t.forEach(t),gpo=r(zNe," \u2014 "),rj=n(zNe,"A",{href:!0});var V7t=s(rj);hpo=r(V7t,"PLBartConfig"),V7t.forEach(t),upo=r(zNe," (PLBart model)"),zNe.forEach(t),ppo=i(L),Ah=n(L,"LI",{});var QNe=s(Ah);Hge=n(QNe,"STRONG",{});var X7t=s(Hge);_po=r(X7t,"poolformer"),X7t.forEach(t),bpo=r(QNe," \u2014 "),tj=n(QNe,"A",{href:!0});var z7t=s(tj);vpo=r(z7t,"PoolFormerConfig"),z7t.forEach(t),Fpo=r(QNe," (PoolFormer model)"),QNe.forEach(t),Tpo=i(L),Lh=n(L,"LI",{});var WNe=s(Lh);Jge=n(WNe,"STRONG",{});var Q7t=s(Jge);Mpo=r(Q7t,"prophetnet"),Q7t.forEach(t),Epo=r(WNe," \u2014 "),aj=n(WNe,"A",{href:!0});var W7t=s(aj);Cpo=r(W7t,"ProphetNetConfig"),W7t.forEach(t),wpo=r(WNe," (ProphetNet model)"),WNe.forEach(t),Apo=i(L),yh=n(L,"LI",{});var UNe=s(yh);Yge=n(UNe,"STRONG",{});var U7t=s(Yge);Lpo=r(U7t,"qdqbert"),U7t.forEach(t),ypo=r(UNe," \u2014 "),nj=n(UNe,"A",{href:!0});var H7t=s(nj);xpo=r(H7t,"QDQBertConfig"),H7t.forEach(t),$po=r(UNe," (QDQBert model)"),UNe.forEach(t),kpo=i(L),xh=n(L,"LI",{});var HNe=s(xh);Zge=n(HNe,"STRONG",{});var J7t=s(Zge);Spo=r(J7t,"rag"),J7t.forEach(t),Rpo=r(HNe," \u2014 "),sj=n(HNe,"A",{href:!0});var Y7t=s(sj);Ppo=r(Y7t,"RagConfig"),Y7t.forEach(t),Bpo=r(HNe," (RAG model)"),HNe.forEach(t),Ipo=i(L),$h=n(L,"LI",{});var JNe=s($h);Kge=n(JNe,"STRONG",{});var Z7t=s(Kge);Npo=r(Z7t,"realm"),Z7t.forEach(t),qpo=r(JNe," \u2014 "),lj=n(JNe,"A",{href:!0});var K7t=s(lj);jpo=r(K7t,"RealmConfig"),K7t.forEach(t),Dpo=r(JNe," (REALM model)"),JNe.forEach(t),Gpo=i(L),kh=n(L,"LI",{});var YNe=s(kh);ehe=n(YNe,"STRONG",{});var e8t=s(ehe);Opo=r(e8t,"reformer"),e8t.forEach(t),Vpo=r(YNe," \u2014 "),ij=n(YNe,"A",{href:!0});var o8t=s(ij);Xpo=r(o8t,"ReformerConfig"),o8t.forEach(t),zpo=r(YNe," (Reformer model)"),YNe.forEach(t),Qpo=i(L),Sh=n(L,"LI",{});var ZNe=s(Sh);ohe=n(ZNe,"STRONG",{});var r8t=s(ohe);Wpo=r(r8t,"regnet"),r8t.forEach(t),Upo=r(ZNe," \u2014 "),dj=n(ZNe,"A",{href:!0});var t8t=s(dj);Hpo=r(t8t,"RegNetConfig"),t8t.forEach(t),Jpo=r(ZNe," (RegNet model)"),ZNe.forEach(t),Ypo=i(L),Rh=n(L,"LI",{});var KNe=s(Rh);rhe=n(KNe,"STRONG",{});var a8t=s(rhe);Zpo=r(a8t,"rembert"),a8t.forEach(t),Kpo=r(KNe," \u2014 "),mj=n(KNe,"A",{href:!0});var n8t=s(mj);e_o=r(n8t,"RemBertConfig"),n8t.forEach(t),o_o=r(KNe," (RemBERT model)"),KNe.forEach(t),r_o=i(L),Ph=n(L,"LI",{});var eqe=s(Ph);the=n(eqe,"STRONG",{});var s8t=s(the);t_o=r(s8t,"resnet"),s8t.forEach(t),a_o=r(eqe," \u2014 "),cj=n(eqe,"A",{href:!0});var l8t=s(cj);n_o=r(l8t,"ResNetConfig"),l8t.forEach(t),s_o=r(eqe," (ResNet model)"),eqe.forEach(t),l_o=i(L),Bh=n(L,"LI",{});var oqe=s(Bh);ahe=n(oqe,"STRONG",{});var i8t=s(ahe);i_o=r(i8t,"retribert"),i8t.forEach(t),d_o=r(oqe," \u2014 "),fj=n(oqe,"A",{href:!0});var d8t=s(fj);m_o=r(d8t,"RetriBertConfig"),d8t.forEach(t),c_o=r(oqe," (RetriBERT model)"),oqe.forEach(t),f_o=i(L),Ih=n(L,"LI",{});var rqe=s(Ih);nhe=n(rqe,"STRONG",{});var m8t=s(nhe);g_o=r(m8t,"roberta"),m8t.forEach(t),h_o=r(rqe," \u2014 "),gj=n(rqe,"A",{href:!0});var c8t=s(gj);u_o=r(c8t,"RobertaConfig"),c8t.forEach(t),p_o=r(rqe," (RoBERTa model)"),rqe.forEach(t),__o=i(L),Nh=n(L,"LI",{});var tqe=s(Nh);she=n(tqe,"STRONG",{});var f8t=s(she);b_o=r(f8t,"roformer"),f8t.forEach(t),v_o=r(tqe," \u2014 "),hj=n(tqe,"A",{href:!0});var g8t=s(hj);F_o=r(g8t,"RoFormerConfig"),g8t.forEach(t),T_o=r(tqe," (RoFormer model)"),tqe.forEach(t),M_o=i(L),qh=n(L,"LI",{});var aqe=s(qh);lhe=n(aqe,"STRONG",{});var h8t=s(lhe);E_o=r(h8t,"segformer"),h8t.forEach(t),C_o=r(aqe," \u2014 "),uj=n(aqe,"A",{href:!0});var u8t=s(uj);w_o=r(u8t,"SegformerConfig"),u8t.forEach(t),A_o=r(aqe," (SegFormer model)"),aqe.forEach(t),L_o=i(L),jh=n(L,"LI",{});var nqe=s(jh);ihe=n(nqe,"STRONG",{});var p8t=s(ihe);y_o=r(p8t,"sew"),p8t.forEach(t),x_o=r(nqe," \u2014 "),pj=n(nqe,"A",{href:!0});var _8t=s(pj);$_o=r(_8t,"SEWConfig"),_8t.forEach(t),k_o=r(nqe," (SEW model)"),nqe.forEach(t),S_o=i(L),Dh=n(L,"LI",{});var sqe=s(Dh);dhe=n(sqe,"STRONG",{});var b8t=s(dhe);R_o=r(b8t,"sew-d"),b8t.forEach(t),P_o=r(sqe," \u2014 "),_j=n(sqe,"A",{href:!0});var v8t=s(_j);B_o=r(v8t,"SEWDConfig"),v8t.forEach(t),I_o=r(sqe," (SEW-D model)"),sqe.forEach(t),N_o=i(L),Gh=n(L,"LI",{});var lqe=s(Gh);mhe=n(lqe,"STRONG",{});var F8t=s(mhe);q_o=r(F8t,"speech-encoder-decoder"),F8t.forEach(t),j_o=r(lqe," \u2014 "),bj=n(lqe,"A",{href:!0});var T8t=s(bj);D_o=r(T8t,"SpeechEncoderDecoderConfig"),T8t.forEach(t),G_o=r(lqe," (Speech Encoder decoder model)"),lqe.forEach(t),O_o=i(L),Oh=n(L,"LI",{});var iqe=s(Oh);che=n(iqe,"STRONG",{});var M8t=s(che);V_o=r(M8t,"speech_to_text"),M8t.forEach(t),X_o=r(iqe," \u2014 "),vj=n(iqe,"A",{href:!0});var E8t=s(vj);z_o=r(E8t,"Speech2TextConfig"),E8t.forEach(t),Q_o=r(iqe," (Speech2Text model)"),iqe.forEach(t),W_o=i(L),Vh=n(L,"LI",{});var dqe=s(Vh);fhe=n(dqe,"STRONG",{});var C8t=s(fhe);U_o=r(C8t,"speech_to_text_2"),C8t.forEach(t),H_o=r(dqe," \u2014 "),Fj=n(dqe,"A",{href:!0});var w8t=s(Fj);J_o=r(w8t,"Speech2Text2Config"),w8t.forEach(t),Y_o=r(dqe," (Speech2Text2 model)"),dqe.forEach(t),Z_o=i(L),Xh=n(L,"LI",{});var mqe=s(Xh);ghe=n(mqe,"STRONG",{});var A8t=s(ghe);K_o=r(A8t,"splinter"),A8t.forEach(t),e1o=r(mqe," \u2014 "),Tj=n(mqe,"A",{href:!0});var L8t=s(Tj);o1o=r(L8t,"SplinterConfig"),L8t.forEach(t),r1o=r(mqe," (Splinter model)"),mqe.forEach(t),t1o=i(L),zh=n(L,"LI",{});var cqe=s(zh);hhe=n(cqe,"STRONG",{});var y8t=s(hhe);a1o=r(y8t,"squeezebert"),y8t.forEach(t),n1o=r(cqe," \u2014 "),Mj=n(cqe,"A",{href:!0});var x8t=s(Mj);s1o=r(x8t,"SqueezeBertConfig"),x8t.forEach(t),l1o=r(cqe," (SqueezeBERT model)"),cqe.forEach(t),i1o=i(L),Qh=n(L,"LI",{});var fqe=s(Qh);uhe=n(fqe,"STRONG",{});var $8t=s(uhe);d1o=r($8t,"swin"),$8t.forEach(t),m1o=r(fqe," \u2014 "),Ej=n(fqe,"A",{href:!0});var k8t=s(Ej);c1o=r(k8t,"SwinConfig"),k8t.forEach(t),f1o=r(fqe," (Swin Transformer model)"),fqe.forEach(t),g1o=i(L),Wh=n(L,"LI",{});var gqe=s(Wh);phe=n(gqe,"STRONG",{});var S8t=s(phe);h1o=r(S8t,"swinv2"),S8t.forEach(t),u1o=r(gqe," \u2014 "),Cj=n(gqe,"A",{href:!0});var R8t=s(Cj);p1o=r(R8t,"Swinv2Config"),R8t.forEach(t),_1o=r(gqe," (Swin Transformer V2 model)"),gqe.forEach(t),b1o=i(L),Uh=n(L,"LI",{});var hqe=s(Uh);_he=n(hqe,"STRONG",{});var P8t=s(_he);v1o=r(P8t,"t5"),P8t.forEach(t),F1o=r(hqe," \u2014 "),wj=n(hqe,"A",{href:!0});var B8t=s(wj);T1o=r(B8t,"T5Config"),B8t.forEach(t),M1o=r(hqe," (T5 model)"),hqe.forEach(t),E1o=i(L),Hh=n(L,"LI",{});var uqe=s(Hh);bhe=n(uqe,"STRONG",{});var I8t=s(bhe);C1o=r(I8t,"table-transformer"),I8t.forEach(t),w1o=r(uqe," \u2014 "),Aj=n(uqe,"A",{href:!0});var N8t=s(Aj);A1o=r(N8t,"TableTransformerConfig"),N8t.forEach(t),L1o=r(uqe," (Table Transformer model)"),uqe.forEach(t),y1o=i(L),Jh=n(L,"LI",{});var pqe=s(Jh);vhe=n(pqe,"STRONG",{});var q8t=s(vhe);x1o=r(q8t,"tapas"),q8t.forEach(t),$1o=r(pqe," \u2014 "),Lj=n(pqe,"A",{href:!0});var j8t=s(Lj);k1o=r(j8t,"TapasConfig"),j8t.forEach(t),S1o=r(pqe," (TAPAS model)"),pqe.forEach(t),R1o=i(L),Yh=n(L,"LI",{});var _qe=s(Yh);Fhe=n(_qe,"STRONG",{});var D8t=s(Fhe);P1o=r(D8t,"time_series_transformer"),D8t.forEach(t),B1o=r(_qe," \u2014 "),yj=n(_qe,"A",{href:!0});var G8t=s(yj);I1o=r(G8t,"TimeSeriesTransformerConfig"),G8t.forEach(t),N1o=r(_qe," (Time Series Transformer model)"),_qe.forEach(t),q1o=i(L),Zh=n(L,"LI",{});var bqe=s(Zh);The=n(bqe,"STRONG",{});var O8t=s(The);j1o=r(O8t,"trajectory_transformer"),O8t.forEach(t),D1o=r(bqe," \u2014 "),xj=n(bqe,"A",{href:!0});var V8t=s(xj);G1o=r(V8t,"TrajectoryTransformerConfig"),V8t.forEach(t),O1o=r(bqe," (Trajectory Transformer model)"),bqe.forEach(t),V1o=i(L),Kh=n(L,"LI",{});var vqe=s(Kh);Mhe=n(vqe,"STRONG",{});var X8t=s(Mhe);X1o=r(X8t,"transfo-xl"),X8t.forEach(t),z1o=r(vqe," \u2014 "),$j=n(vqe,"A",{href:!0});var z8t=s($j);Q1o=r(z8t,"TransfoXLConfig"),z8t.forEach(t),W1o=r(vqe," (Transformer-XL model)"),vqe.forEach(t),U1o=i(L),eu=n(L,"LI",{});var Fqe=s(eu);Ehe=n(Fqe,"STRONG",{});var Q8t=s(Ehe);H1o=r(Q8t,"trocr"),Q8t.forEach(t),J1o=r(Fqe," \u2014 "),kj=n(Fqe,"A",{href:!0});var W8t=s(kj);Y1o=r(W8t,"TrOCRConfig"),W8t.forEach(t),Z1o=r(Fqe," (TrOCR model)"),Fqe.forEach(t),K1o=i(L),ou=n(L,"LI",{});var Tqe=s(ou);Che=n(Tqe,"STRONG",{});var U8t=s(Che);e2o=r(U8t,"unispeech"),U8t.forEach(t),o2o=r(Tqe," \u2014 "),Sj=n(Tqe,"A",{href:!0});var H8t=s(Sj);r2o=r(H8t,"UniSpeechConfig"),H8t.forEach(t),t2o=r(Tqe," (UniSpeech model)"),Tqe.forEach(t),a2o=i(L),ru=n(L,"LI",{});var Mqe=s(ru);whe=n(Mqe,"STRONG",{});var J8t=s(whe);n2o=r(J8t,"unispeech-sat"),J8t.forEach(t),s2o=r(Mqe," \u2014 "),Rj=n(Mqe,"A",{href:!0});var Y8t=s(Rj);l2o=r(Y8t,"UniSpeechSatConfig"),Y8t.forEach(t),i2o=r(Mqe," (UniSpeechSat model)"),Mqe.forEach(t),d2o=i(L),tu=n(L,"LI",{});var Eqe=s(tu);Ahe=n(Eqe,"STRONG",{});var Z8t=s(Ahe);m2o=r(Z8t,"van"),Z8t.forEach(t),c2o=r(Eqe," \u2014 "),Pj=n(Eqe,"A",{href:!0});var K8t=s(Pj);f2o=r(K8t,"VanConfig"),K8t.forEach(t),g2o=r(Eqe," (VAN model)"),Eqe.forEach(t),h2o=i(L),au=n(L,"LI",{});var Cqe=s(au);Lhe=n(Cqe,"STRONG",{});var eLt=s(Lhe);u2o=r(eLt,"videomae"),eLt.forEach(t),p2o=r(Cqe," \u2014 "),Bj=n(Cqe,"A",{href:!0});var oLt=s(Bj);_2o=r(oLt,"VideoMAEConfig"),oLt.forEach(t),b2o=r(Cqe," (VideoMAE model)"),Cqe.forEach(t),v2o=i(L),nu=n(L,"LI",{});var wqe=s(nu);yhe=n(wqe,"STRONG",{});var rLt=s(yhe);F2o=r(rLt,"vilt"),rLt.forEach(t),T2o=r(wqe," \u2014 "),Ij=n(wqe,"A",{href:!0});var tLt=s(Ij);M2o=r(tLt,"ViltConfig"),tLt.forEach(t),E2o=r(wqe," (ViLT model)"),wqe.forEach(t),C2o=i(L),su=n(L,"LI",{});var Aqe=s(su);xhe=n(Aqe,"STRONG",{});var aLt=s(xhe);w2o=r(aLt,"vision-encoder-decoder"),aLt.forEach(t),A2o=r(Aqe," \u2014 "),Nj=n(Aqe,"A",{href:!0});var nLt=s(Nj);L2o=r(nLt,"VisionEncoderDecoderConfig"),nLt.forEach(t),y2o=r(Aqe," (Vision Encoder decoder model)"),Aqe.forEach(t),x2o=i(L),lu=n(L,"LI",{});var Lqe=s(lu);$he=n(Lqe,"STRONG",{});var sLt=s($he);$2o=r(sLt,"vision-text-dual-encoder"),sLt.forEach(t),k2o=r(Lqe," \u2014 "),qj=n(Lqe,"A",{href:!0});var lLt=s(qj);S2o=r(lLt,"VisionTextDualEncoderConfig"),lLt.forEach(t),R2o=r(Lqe," (VisionTextDualEncoder model)"),Lqe.forEach(t),P2o=i(L),iu=n(L,"LI",{});var yqe=s(iu);khe=n(yqe,"STRONG",{});var iLt=s(khe);B2o=r(iLt,"visual_bert"),iLt.forEach(t),I2o=r(yqe," \u2014 "),jj=n(yqe,"A",{href:!0});var dLt=s(jj);N2o=r(dLt,"VisualBertConfig"),dLt.forEach(t),q2o=r(yqe," (VisualBERT model)"),yqe.forEach(t),j2o=i(L),du=n(L,"LI",{});var xqe=s(du);She=n(xqe,"STRONG",{});var mLt=s(She);D2o=r(mLt,"vit"),mLt.forEach(t),G2o=r(xqe," \u2014 "),Dj=n(xqe,"A",{href:!0});var cLt=s(Dj);O2o=r(cLt,"ViTConfig"),cLt.forEach(t),V2o=r(xqe," (ViT model)"),xqe.forEach(t),X2o=i(L),mu=n(L,"LI",{});var $qe=s(mu);Rhe=n($qe,"STRONG",{});var fLt=s(Rhe);z2o=r(fLt,"vit_mae"),fLt.forEach(t),Q2o=r($qe," \u2014 "),Gj=n($qe,"A",{href:!0});var gLt=s(Gj);W2o=r(gLt,"ViTMAEConfig"),gLt.forEach(t),U2o=r($qe," (ViTMAE model)"),$qe.forEach(t),H2o=i(L),cu=n(L,"LI",{});var kqe=s(cu);Phe=n(kqe,"STRONG",{});var hLt=s(Phe);J2o=r(hLt,"vit_msn"),hLt.forEach(t),Y2o=r(kqe," \u2014 "),Oj=n(kqe,"A",{href:!0});var uLt=s(Oj);Z2o=r(uLt,"ViTMSNConfig"),uLt.forEach(t),K2o=r(kqe," (ViTMSN model)"),kqe.forEach(t),ebo=i(L),fu=n(L,"LI",{});var Sqe=s(fu);Bhe=n(Sqe,"STRONG",{});var pLt=s(Bhe);obo=r(pLt,"wav2vec2"),pLt.forEach(t),rbo=r(Sqe," \u2014 "),Vj=n(Sqe,"A",{href:!0});var _Lt=s(Vj);tbo=r(_Lt,"Wav2Vec2Config"),_Lt.forEach(t),abo=r(Sqe," (Wav2Vec2 model)"),Sqe.forEach(t),nbo=i(L),gu=n(L,"LI",{});var Rqe=s(gu);Ihe=n(Rqe,"STRONG",{});var bLt=s(Ihe);sbo=r(bLt,"wav2vec2-conformer"),bLt.forEach(t),lbo=r(Rqe," \u2014 "),Xj=n(Rqe,"A",{href:!0});var vLt=s(Xj);ibo=r(vLt,"Wav2Vec2ConformerConfig"),vLt.forEach(t),dbo=r(Rqe," (Wav2Vec2-Conformer model)"),Rqe.forEach(t),mbo=i(L),hu=n(L,"LI",{});var Pqe=s(hu);Nhe=n(Pqe,"STRONG",{});var FLt=s(Nhe);cbo=r(FLt,"wavlm"),FLt.forEach(t),fbo=r(Pqe," \u2014 "),zj=n(Pqe,"A",{href:!0});var TLt=s(zj);gbo=r(TLt,"WavLMConfig"),TLt.forEach(t),hbo=r(Pqe," (WavLM model)"),Pqe.forEach(t),ubo=i(L),uu=n(L,"LI",{});var Bqe=s(uu);qhe=n(Bqe,"STRONG",{});var MLt=s(qhe);pbo=r(MLt,"whisper"),MLt.forEach(t),_bo=r(Bqe," \u2014 "),Qj=n(Bqe,"A",{href:!0});var ELt=s(Qj);bbo=r(ELt,"WhisperConfig"),ELt.forEach(t),vbo=r(Bqe," (Whisper model)"),Bqe.forEach(t),Fbo=i(L),pu=n(L,"LI",{});var Iqe=s(pu);jhe=n(Iqe,"STRONG",{});var CLt=s(jhe);Tbo=r(CLt,"xclip"),CLt.forEach(t),Mbo=r(Iqe," \u2014 "),Wj=n(Iqe,"A",{href:!0});var wLt=s(Wj);Ebo=r(wLt,"XCLIPConfig"),wLt.forEach(t),Cbo=r(Iqe," (X-CLIP model)"),Iqe.forEach(t),wbo=i(L),_u=n(L,"LI",{});var Nqe=s(_u);Dhe=n(Nqe,"STRONG",{});var ALt=s(Dhe);Abo=r(ALt,"xglm"),ALt.forEach(t),Lbo=r(Nqe," \u2014 "),Uj=n(Nqe,"A",{href:!0});var LLt=s(Uj);ybo=r(LLt,"XGLMConfig"),LLt.forEach(t),xbo=r(Nqe," (XGLM model)"),Nqe.forEach(t),$bo=i(L),bu=n(L,"LI",{});var qqe=s(bu);Ghe=n(qqe,"STRONG",{});var yLt=s(Ghe);kbo=r(yLt,"xlm"),yLt.forEach(t),Sbo=r(qqe," \u2014 "),Hj=n(qqe,"A",{href:!0});var xLt=s(Hj);Rbo=r(xLt,"XLMConfig"),xLt.forEach(t),Pbo=r(qqe," (XLM model)"),qqe.forEach(t),Bbo=i(L),vu=n(L,"LI",{});var jqe=s(vu);Ohe=n(jqe,"STRONG",{});var $Lt=s(Ohe);Ibo=r($Lt,"xlm-prophetnet"),$Lt.forEach(t),Nbo=r(jqe," \u2014 "),Jj=n(jqe,"A",{href:!0});var kLt=s(Jj);qbo=r(kLt,"XLMProphetNetConfig"),kLt.forEach(t),jbo=r(jqe," (XLM-ProphetNet model)"),jqe.forEach(t),Dbo=i(L),Fu=n(L,"LI",{});var Dqe=s(Fu);Vhe=n(Dqe,"STRONG",{});var SLt=s(Vhe);Gbo=r(SLt,"xlm-roberta"),SLt.forEach(t),Obo=r(Dqe," \u2014 "),Yj=n(Dqe,"A",{href:!0});var RLt=s(Yj);Vbo=r(RLt,"XLMRobertaConfig"),RLt.forEach(t),Xbo=r(Dqe," (XLM-RoBERTa model)"),Dqe.forEach(t),zbo=i(L),Tu=n(L,"LI",{});var Gqe=s(Tu);Xhe=n(Gqe,"STRONG",{});var PLt=s(Xhe);Qbo=r(PLt,"xlm-roberta-xl"),PLt.forEach(t),Wbo=r(Gqe," \u2014 "),Zj=n(Gqe,"A",{href:!0});var BLt=s(Zj);Ubo=r(BLt,"XLMRobertaXLConfig"),BLt.forEach(t),Hbo=r(Gqe," (XLM-RoBERTa-XL model)"),Gqe.forEach(t),Jbo=i(L),Mu=n(L,"LI",{});var Oqe=s(Mu);zhe=n(Oqe,"STRONG",{});var ILt=s(zhe);Ybo=r(ILt,"xlnet"),ILt.forEach(t),Zbo=r(Oqe," \u2014 "),Kj=n(Oqe,"A",{href:!0});var NLt=s(Kj);Kbo=r(NLt,"XLNetConfig"),NLt.forEach(t),evo=r(Oqe," (XLNet model)"),Oqe.forEach(t),ovo=i(L),Eu=n(L,"LI",{});var Vqe=s(Eu);Qhe=n(Vqe,"STRONG",{});var qLt=s(Qhe);rvo=r(qLt,"yolos"),qLt.forEach(t),tvo=r(Vqe," \u2014 "),eD=n(Vqe,"A",{href:!0});var jLt=s(eD);avo=r(jLt,"YolosConfig"),jLt.forEach(t),nvo=r(Vqe," (YOLOS model)"),Vqe.forEach(t),svo=i(L),Cu=n(L,"LI",{});var Xqe=s(Cu);Whe=n(Xqe,"STRONG",{});var DLt=s(Whe);lvo=r(DLt,"yoso"),DLt.forEach(t),ivo=r(Xqe," \u2014 "),oD=n(Xqe,"A",{href:!0});var GLt=s(oD);dvo=r(GLt,"YosoConfig"),GLt.forEach(t),mvo=r(Xqe," (YOSO model)"),Xqe.forEach(t),L.forEach(t),cvo=i(Ft),T(wu.$$.fragment,Ft),Ft.forEach(t),fvo=i(vt),Au=n(vt,"DIV",{class:!0});var Vno=s(Au);T(p$.$$.fragment,Vno),gvo=i(Vno),Uhe=n(Vno,"P",{});var OLt=s(Uhe);hvo=r(OLt,"Register a new configuration for this class."),OLt.forEach(t),Vno.forEach(t),vt.forEach(t),Sto=i(c),yd=n(c,"H2",{class:!0});var Xno=s(yd);Lu=n(Xno,"A",{id:!0,class:!0,href:!0});var VLt=s(Lu);Hhe=n(VLt,"SPAN",{});var XLt=s(Hhe);T(_$.$$.fragment,XLt),XLt.forEach(t),VLt.forEach(t),uvo=i(Xno),Jhe=n(Xno,"SPAN",{});var zLt=s(Jhe);pvo=r(zLt,"AutoTokenizer"),zLt.forEach(t),Xno.forEach(t),Rto=i(c),Ro=n(c,"DIV",{class:!0});var Pl=s(Ro);T(b$.$$.fragment,Pl),_vo=i(Pl),v$=n(Pl,"P",{});var zno=s(v$);bvo=r(zno,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),rD=n(zno,"A",{href:!0});var QLt=s(rD);vvo=r(QLt,"AutoTokenizer.from_pretrained()"),QLt.forEach(t),Fvo=r(zno," class method."),zno.forEach(t),Tvo=i(Pl),F$=n(Pl,"P",{});var Qno=s(F$);Mvo=r(Qno,"This class cannot be instantiated directly using "),Yhe=n(Qno,"CODE",{});var WLt=s(Yhe);Evo=r(WLt,"__init__()"),WLt.forEach(t),Cvo=r(Qno," (throws an error)."),Qno.forEach(t),wvo=i(Pl),jr=n(Pl,"DIV",{class:!0});var Bl=s(jr);T(T$.$$.fragment,Bl),Avo=i(Bl),Zhe=n(Bl,"P",{});var ULt=s(Zhe);Lvo=r(ULt,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),ULt.forEach(t),yvo=i(Bl),tn=n(Bl,"P",{});var Zy=s(tn);xvo=r(Zy,"The tokenizer class to instantiate is selected based on the "),Khe=n(Zy,"CODE",{});var HLt=s(Khe);$vo=r(HLt,"model_type"),HLt.forEach(t),kvo=r(Zy,` property of the config object (either
passed as an argument or loaded from `),eue=n(Zy,"CODE",{});var JLt=s(eue);Svo=r(JLt,"pretrained_model_name_or_path"),JLt.forEach(t),Rvo=r(Zy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oue=n(Zy,"CODE",{});var YLt=s(oue);Pvo=r(YLt,"pretrained_model_name_or_path"),YLt.forEach(t),Bvo=r(Zy,":"),Zy.forEach(t),Ivo=i(Bl),k=n(Bl,"UL",{});var S=s(k);us=n(S,"LI",{});var tI=s(us);rue=n(tI,"STRONG",{});var ZLt=s(rue);Nvo=r(ZLt,"albert"),ZLt.forEach(t),qvo=r(tI," \u2014 "),tD=n(tI,"A",{href:!0});var KLt=s(tD);jvo=r(KLt,"AlbertTokenizer"),KLt.forEach(t),Dvo=r(tI," or "),aD=n(tI,"A",{href:!0});var eyt=s(aD);Gvo=r(eyt,"AlbertTokenizerFast"),eyt.forEach(t),Ovo=r(tI," (ALBERT model)"),tI.forEach(t),Vvo=i(S),ps=n(S,"LI",{});var aI=s(ps);tue=n(aI,"STRONG",{});var oyt=s(tue);Xvo=r(oyt,"bart"),oyt.forEach(t),zvo=r(aI," \u2014 "),nD=n(aI,"A",{href:!0});var ryt=s(nD);Qvo=r(ryt,"BartTokenizer"),ryt.forEach(t),Wvo=r(aI," or "),sD=n(aI,"A",{href:!0});var tyt=s(sD);Uvo=r(tyt,"BartTokenizerFast"),tyt.forEach(t),Hvo=r(aI," (BART model)"),aI.forEach(t),Jvo=i(S),_s=n(S,"LI",{});var nI=s(_s);aue=n(nI,"STRONG",{});var ayt=s(aue);Yvo=r(ayt,"barthez"),ayt.forEach(t),Zvo=r(nI," \u2014 "),lD=n(nI,"A",{href:!0});var nyt=s(lD);Kvo=r(nyt,"BarthezTokenizer"),nyt.forEach(t),eFo=r(nI," or "),iD=n(nI,"A",{href:!0});var syt=s(iD);oFo=r(syt,"BarthezTokenizerFast"),syt.forEach(t),rFo=r(nI," (BARThez model)"),nI.forEach(t),tFo=i(S),yu=n(S,"LI",{});var zqe=s(yu);nue=n(zqe,"STRONG",{});var lyt=s(nue);aFo=r(lyt,"bartpho"),lyt.forEach(t),nFo=r(zqe," \u2014 "),dD=n(zqe,"A",{href:!0});var iyt=s(dD);sFo=r(iyt,"BartphoTokenizer"),iyt.forEach(t),lFo=r(zqe," (BARTpho model)"),zqe.forEach(t),iFo=i(S),bs=n(S,"LI",{});var sI=s(bs);sue=n(sI,"STRONG",{});var dyt=s(sue);dFo=r(dyt,"bert"),dyt.forEach(t),mFo=r(sI," \u2014 "),mD=n(sI,"A",{href:!0});var myt=s(mD);cFo=r(myt,"BertTokenizer"),myt.forEach(t),fFo=r(sI," or "),cD=n(sI,"A",{href:!0});var cyt=s(cD);gFo=r(cyt,"BertTokenizerFast"),cyt.forEach(t),hFo=r(sI," (BERT model)"),sI.forEach(t),uFo=i(S),xu=n(S,"LI",{});var Qqe=s(xu);lue=n(Qqe,"STRONG",{});var fyt=s(lue);pFo=r(fyt,"bert-generation"),fyt.forEach(t),_Fo=r(Qqe," \u2014 "),fD=n(Qqe,"A",{href:!0});var gyt=s(fD);bFo=r(gyt,"BertGenerationTokenizer"),gyt.forEach(t),vFo=r(Qqe," (Bert Generation model)"),Qqe.forEach(t),FFo=i(S),$u=n(S,"LI",{});var Wqe=s($u);iue=n(Wqe,"STRONG",{});var hyt=s(iue);TFo=r(hyt,"bert-japanese"),hyt.forEach(t),MFo=r(Wqe," \u2014 "),gD=n(Wqe,"A",{href:!0});var uyt=s(gD);EFo=r(uyt,"BertJapaneseTokenizer"),uyt.forEach(t),CFo=r(Wqe," (BertJapanese model)"),Wqe.forEach(t),wFo=i(S),ku=n(S,"LI",{});var Uqe=s(ku);due=n(Uqe,"STRONG",{});var pyt=s(due);AFo=r(pyt,"bertweet"),pyt.forEach(t),LFo=r(Uqe," \u2014 "),hD=n(Uqe,"A",{href:!0});var _yt=s(hD);yFo=r(_yt,"BertweetTokenizer"),_yt.forEach(t),xFo=r(Uqe," (BERTweet model)"),Uqe.forEach(t),$Fo=i(S),vs=n(S,"LI",{});var lI=s(vs);mue=n(lI,"STRONG",{});var byt=s(mue);kFo=r(byt,"big_bird"),byt.forEach(t),SFo=r(lI," \u2014 "),uD=n(lI,"A",{href:!0});var vyt=s(uD);RFo=r(vyt,"BigBirdTokenizer"),vyt.forEach(t),PFo=r(lI," or "),pD=n(lI,"A",{href:!0});var Fyt=s(pD);BFo=r(Fyt,"BigBirdTokenizerFast"),Fyt.forEach(t),IFo=r(lI," (BigBird model)"),lI.forEach(t),NFo=i(S),Fs=n(S,"LI",{});var iI=s(Fs);cue=n(iI,"STRONG",{});var Tyt=s(cue);qFo=r(Tyt,"bigbird_pegasus"),Tyt.forEach(t),jFo=r(iI," \u2014 "),_D=n(iI,"A",{href:!0});var Myt=s(_D);DFo=r(Myt,"PegasusTokenizer"),Myt.forEach(t),GFo=r(iI," or "),bD=n(iI,"A",{href:!0});var Eyt=s(bD);OFo=r(Eyt,"PegasusTokenizerFast"),Eyt.forEach(t),VFo=r(iI," (BigBird-Pegasus model)"),iI.forEach(t),XFo=i(S),Ts=n(S,"LI",{});var dI=s(Ts);fue=n(dI,"STRONG",{});var Cyt=s(fue);zFo=r(Cyt,"blenderbot"),Cyt.forEach(t),QFo=r(dI," \u2014 "),vD=n(dI,"A",{href:!0});var wyt=s(vD);WFo=r(wyt,"BlenderbotTokenizer"),wyt.forEach(t),UFo=r(dI," or "),FD=n(dI,"A",{href:!0});var Ayt=s(FD);HFo=r(Ayt,"BlenderbotTokenizerFast"),Ayt.forEach(t),JFo=r(dI," (Blenderbot model)"),dI.forEach(t),YFo=i(S),Su=n(S,"LI",{});var Hqe=s(Su);gue=n(Hqe,"STRONG",{});var Lyt=s(gue);ZFo=r(Lyt,"blenderbot-small"),Lyt.forEach(t),KFo=r(Hqe," \u2014 "),TD=n(Hqe,"A",{href:!0});var yyt=s(TD);eTo=r(yyt,"BlenderbotSmallTokenizer"),yyt.forEach(t),oTo=r(Hqe," (BlenderbotSmall model)"),Hqe.forEach(t),rTo=i(S),Ru=n(S,"LI",{});var Jqe=s(Ru);hue=n(Jqe,"STRONG",{});var xyt=s(hue);tTo=r(xyt,"bloom"),xyt.forEach(t),aTo=r(Jqe," \u2014 "),MD=n(Jqe,"A",{href:!0});var $yt=s(MD);nTo=r($yt,"BloomTokenizerFast"),$yt.forEach(t),sTo=r(Jqe," (BLOOM model)"),Jqe.forEach(t),lTo=i(S),Pu=n(S,"LI",{});var Yqe=s(Pu);uue=n(Yqe,"STRONG",{});var kyt=s(uue);iTo=r(kyt,"byt5"),kyt.forEach(t),dTo=r(Yqe," \u2014 "),ED=n(Yqe,"A",{href:!0});var Syt=s(ED);mTo=r(Syt,"ByT5Tokenizer"),Syt.forEach(t),cTo=r(Yqe," (ByT5 model)"),Yqe.forEach(t),fTo=i(S),Ms=n(S,"LI",{});var mI=s(Ms);pue=n(mI,"STRONG",{});var Ryt=s(pue);gTo=r(Ryt,"camembert"),Ryt.forEach(t),hTo=r(mI," \u2014 "),CD=n(mI,"A",{href:!0});var Pyt=s(CD);uTo=r(Pyt,"CamembertTokenizer"),Pyt.forEach(t),pTo=r(mI," or "),wD=n(mI,"A",{href:!0});var Byt=s(wD);_To=r(Byt,"CamembertTokenizerFast"),Byt.forEach(t),bTo=r(mI," (CamemBERT model)"),mI.forEach(t),vTo=i(S),Bu=n(S,"LI",{});var Zqe=s(Bu);_ue=n(Zqe,"STRONG",{});var Iyt=s(_ue);FTo=r(Iyt,"canine"),Iyt.forEach(t),TTo=r(Zqe," \u2014 "),AD=n(Zqe,"A",{href:!0});var Nyt=s(AD);MTo=r(Nyt,"CanineTokenizer"),Nyt.forEach(t),ETo=r(Zqe," (CANINE model)"),Zqe.forEach(t),CTo=i(S),Es=n(S,"LI",{});var cI=s(Es);bue=n(cI,"STRONG",{});var qyt=s(bue);wTo=r(qyt,"clip"),qyt.forEach(t),ATo=r(cI," \u2014 "),LD=n(cI,"A",{href:!0});var jyt=s(LD);LTo=r(jyt,"CLIPTokenizer"),jyt.forEach(t),yTo=r(cI," or "),yD=n(cI,"A",{href:!0});var Dyt=s(yD);xTo=r(Dyt,"CLIPTokenizerFast"),Dyt.forEach(t),$To=r(cI," (CLIP model)"),cI.forEach(t),kTo=i(S),Cs=n(S,"LI",{});var fI=s(Cs);vue=n(fI,"STRONG",{});var Gyt=s(vue);STo=r(Gyt,"codegen"),Gyt.forEach(t),RTo=r(fI," \u2014 "),xD=n(fI,"A",{href:!0});var Oyt=s(xD);PTo=r(Oyt,"CodeGenTokenizer"),Oyt.forEach(t),BTo=r(fI," or "),$D=n(fI,"A",{href:!0});var Vyt=s($D);ITo=r(Vyt,"CodeGenTokenizerFast"),Vyt.forEach(t),NTo=r(fI," (CodeGen model)"),fI.forEach(t),qTo=i(S),ws=n(S,"LI",{});var gI=s(ws);Fue=n(gI,"STRONG",{});var Xyt=s(Fue);jTo=r(Xyt,"convbert"),Xyt.forEach(t),DTo=r(gI," \u2014 "),kD=n(gI,"A",{href:!0});var zyt=s(kD);GTo=r(zyt,"ConvBertTokenizer"),zyt.forEach(t),OTo=r(gI," or "),SD=n(gI,"A",{href:!0});var Qyt=s(SD);VTo=r(Qyt,"ConvBertTokenizerFast"),Qyt.forEach(t),XTo=r(gI," (ConvBERT model)"),gI.forEach(t),zTo=i(S),As=n(S,"LI",{});var hI=s(As);Tue=n(hI,"STRONG",{});var Wyt=s(Tue);QTo=r(Wyt,"cpm"),Wyt.forEach(t),WTo=r(hI," \u2014 "),RD=n(hI,"A",{href:!0});var Uyt=s(RD);UTo=r(Uyt,"CpmTokenizer"),Uyt.forEach(t),HTo=r(hI," or "),PD=n(hI,"A",{href:!0});var Hyt=s(PD);JTo=r(Hyt,"CpmTokenizerFast"),Hyt.forEach(t),YTo=r(hI," (CPM model)"),hI.forEach(t),ZTo=i(S),Iu=n(S,"LI",{});var Kqe=s(Iu);Mue=n(Kqe,"STRONG",{});var Jyt=s(Mue);KTo=r(Jyt,"ctrl"),Jyt.forEach(t),eMo=r(Kqe," \u2014 "),BD=n(Kqe,"A",{href:!0});var Yyt=s(BD);oMo=r(Yyt,"CTRLTokenizer"),Yyt.forEach(t),rMo=r(Kqe," (CTRL model)"),Kqe.forEach(t),tMo=i(S),Ls=n(S,"LI",{});var uI=s(Ls);Eue=n(uI,"STRONG",{});var Zyt=s(Eue);aMo=r(Zyt,"data2vec-text"),Zyt.forEach(t),nMo=r(uI," \u2014 "),ID=n(uI,"A",{href:!0});var Kyt=s(ID);sMo=r(Kyt,"RobertaTokenizer"),Kyt.forEach(t),lMo=r(uI," or "),ND=n(uI,"A",{href:!0});var e9t=s(ND);iMo=r(e9t,"RobertaTokenizerFast"),e9t.forEach(t),dMo=r(uI," (Data2VecText model)"),uI.forEach(t),mMo=i(S),ys=n(S,"LI",{});var pI=s(ys);Cue=n(pI,"STRONG",{});var o9t=s(Cue);cMo=r(o9t,"deberta"),o9t.forEach(t),fMo=r(pI," \u2014 "),qD=n(pI,"A",{href:!0});var r9t=s(qD);gMo=r(r9t,"DebertaTokenizer"),r9t.forEach(t),hMo=r(pI," or "),jD=n(pI,"A",{href:!0});var t9t=s(jD);uMo=r(t9t,"DebertaTokenizerFast"),t9t.forEach(t),pMo=r(pI," (DeBERTa model)"),pI.forEach(t),_Mo=i(S),xs=n(S,"LI",{});var _I=s(xs);wue=n(_I,"STRONG",{});var a9t=s(wue);bMo=r(a9t,"deberta-v2"),a9t.forEach(t),vMo=r(_I," \u2014 "),DD=n(_I,"A",{href:!0});var n9t=s(DD);FMo=r(n9t,"DebertaV2Tokenizer"),n9t.forEach(t),TMo=r(_I," or "),GD=n(_I,"A",{href:!0});var s9t=s(GD);MMo=r(s9t,"DebertaV2TokenizerFast"),s9t.forEach(t),EMo=r(_I," (DeBERTa-v2 model)"),_I.forEach(t),CMo=i(S),$s=n(S,"LI",{});var bI=s($s);Aue=n(bI,"STRONG",{});var l9t=s(Aue);wMo=r(l9t,"distilbert"),l9t.forEach(t),AMo=r(bI," \u2014 "),OD=n(bI,"A",{href:!0});var i9t=s(OD);LMo=r(i9t,"DistilBertTokenizer"),i9t.forEach(t),yMo=r(bI," or "),VD=n(bI,"A",{href:!0});var d9t=s(VD);xMo=r(d9t,"DistilBertTokenizerFast"),d9t.forEach(t),$Mo=r(bI," (DistilBERT model)"),bI.forEach(t),kMo=i(S),ks=n(S,"LI",{});var vI=s(ks);Lue=n(vI,"STRONG",{});var m9t=s(Lue);SMo=r(m9t,"dpr"),m9t.forEach(t),RMo=r(vI," \u2014 "),XD=n(vI,"A",{href:!0});var c9t=s(XD);PMo=r(c9t,"DPRQuestionEncoderTokenizer"),c9t.forEach(t),BMo=r(vI," or "),zD=n(vI,"A",{href:!0});var f9t=s(zD);IMo=r(f9t,"DPRQuestionEncoderTokenizerFast"),f9t.forEach(t),NMo=r(vI," (DPR model)"),vI.forEach(t),qMo=i(S),Ss=n(S,"LI",{});var FI=s(Ss);yue=n(FI,"STRONG",{});var g9t=s(yue);jMo=r(g9t,"electra"),g9t.forEach(t),DMo=r(FI," \u2014 "),QD=n(FI,"A",{href:!0});var h9t=s(QD);GMo=r(h9t,"ElectraTokenizer"),h9t.forEach(t),OMo=r(FI," or "),WD=n(FI,"A",{href:!0});var u9t=s(WD);VMo=r(u9t,"ElectraTokenizerFast"),u9t.forEach(t),XMo=r(FI," (ELECTRA model)"),FI.forEach(t),zMo=i(S),Rs=n(S,"LI",{});var TI=s(Rs);xue=n(TI,"STRONG",{});var p9t=s(xue);QMo=r(p9t,"ernie"),p9t.forEach(t),WMo=r(TI," \u2014 "),UD=n(TI,"A",{href:!0});var _9t=s(UD);UMo=r(_9t,"BertTokenizer"),_9t.forEach(t),HMo=r(TI," or "),HD=n(TI,"A",{href:!0});var b9t=s(HD);JMo=r(b9t,"BertTokenizerFast"),b9t.forEach(t),YMo=r(TI," (ERNIE model)"),TI.forEach(t),ZMo=i(S),Nu=n(S,"LI",{});var eje=s(Nu);$ue=n(eje,"STRONG",{});var v9t=s($ue);KMo=r(v9t,"esm"),v9t.forEach(t),eEo=r(eje," \u2014 "),JD=n(eje,"A",{href:!0});var F9t=s(JD);oEo=r(F9t,"EsmTokenizer"),F9t.forEach(t),rEo=r(eje," (ESM model)"),eje.forEach(t),tEo=i(S),qu=n(S,"LI",{});var oje=s(qu);kue=n(oje,"STRONG",{});var T9t=s(kue);aEo=r(T9t,"flaubert"),T9t.forEach(t),nEo=r(oje," \u2014 "),YD=n(oje,"A",{href:!0});var M9t=s(YD);sEo=r(M9t,"FlaubertTokenizer"),M9t.forEach(t),lEo=r(oje," (FlauBERT model)"),oje.forEach(t),iEo=i(S),Ps=n(S,"LI",{});var MI=s(Ps);Sue=n(MI,"STRONG",{});var E9t=s(Sue);dEo=r(E9t,"fnet"),E9t.forEach(t),mEo=r(MI," \u2014 "),ZD=n(MI,"A",{href:!0});var C9t=s(ZD);cEo=r(C9t,"FNetTokenizer"),C9t.forEach(t),fEo=r(MI," or "),KD=n(MI,"A",{href:!0});var w9t=s(KD);gEo=r(w9t,"FNetTokenizerFast"),w9t.forEach(t),hEo=r(MI," (FNet model)"),MI.forEach(t),uEo=i(S),ju=n(S,"LI",{});var rje=s(ju);Rue=n(rje,"STRONG",{});var A9t=s(Rue);pEo=r(A9t,"fsmt"),A9t.forEach(t),_Eo=r(rje," \u2014 "),eG=n(rje,"A",{href:!0});var L9t=s(eG);bEo=r(L9t,"FSMTTokenizer"),L9t.forEach(t),vEo=r(rje," (FairSeq Machine-Translation model)"),rje.forEach(t),FEo=i(S),Bs=n(S,"LI",{});var EI=s(Bs);Pue=n(EI,"STRONG",{});var y9t=s(Pue);TEo=r(y9t,"funnel"),y9t.forEach(t),MEo=r(EI," \u2014 "),oG=n(EI,"A",{href:!0});var x9t=s(oG);EEo=r(x9t,"FunnelTokenizer"),x9t.forEach(t),CEo=r(EI," or "),rG=n(EI,"A",{href:!0});var $9t=s(rG);wEo=r($9t,"FunnelTokenizerFast"),$9t.forEach(t),AEo=r(EI," (Funnel Transformer model)"),EI.forEach(t),LEo=i(S),Is=n(S,"LI",{});var CI=s(Is);Bue=n(CI,"STRONG",{});var k9t=s(Bue);yEo=r(k9t,"gpt2"),k9t.forEach(t),xEo=r(CI," \u2014 "),tG=n(CI,"A",{href:!0});var S9t=s(tG);$Eo=r(S9t,"GPT2Tokenizer"),S9t.forEach(t),kEo=r(CI," or "),aG=n(CI,"A",{href:!0});var R9t=s(aG);SEo=r(R9t,"GPT2TokenizerFast"),R9t.forEach(t),REo=r(CI," (OpenAI GPT-2 model)"),CI.forEach(t),PEo=i(S),Ns=n(S,"LI",{});var wI=s(Ns);Iue=n(wI,"STRONG",{});var P9t=s(Iue);BEo=r(P9t,"gpt_neo"),P9t.forEach(t),IEo=r(wI," \u2014 "),nG=n(wI,"A",{href:!0});var B9t=s(nG);NEo=r(B9t,"GPT2Tokenizer"),B9t.forEach(t),qEo=r(wI," or "),sG=n(wI,"A",{href:!0});var I9t=s(sG);jEo=r(I9t,"GPT2TokenizerFast"),I9t.forEach(t),DEo=r(wI," (GPT Neo model)"),wI.forEach(t),GEo=i(S),Du=n(S,"LI",{});var tje=s(Du);Nue=n(tje,"STRONG",{});var N9t=s(Nue);OEo=r(N9t,"gpt_neox"),N9t.forEach(t),VEo=r(tje," \u2014 "),lG=n(tje,"A",{href:!0});var q9t=s(lG);XEo=r(q9t,"GPTNeoXTokenizerFast"),q9t.forEach(t),zEo=r(tje," (GPT NeoX model)"),tje.forEach(t),QEo=i(S),Gu=n(S,"LI",{});var aje=s(Gu);que=n(aje,"STRONG",{});var j9t=s(que);WEo=r(j9t,"gpt_neox_japanese"),j9t.forEach(t),UEo=r(aje," \u2014 "),iG=n(aje,"A",{href:!0});var D9t=s(iG);HEo=r(D9t,"GPTNeoXJapaneseTokenizer"),D9t.forEach(t),JEo=r(aje," (GPT NeoX Japanese model)"),aje.forEach(t),YEo=i(S),qs=n(S,"LI",{});var AI=s(qs);jue=n(AI,"STRONG",{});var G9t=s(jue);ZEo=r(G9t,"gptj"),G9t.forEach(t),KEo=r(AI," \u2014 "),dG=n(AI,"A",{href:!0});var O9t=s(dG);e4o=r(O9t,"GPT2Tokenizer"),O9t.forEach(t),o4o=r(AI," or "),mG=n(AI,"A",{href:!0});var V9t=s(mG);r4o=r(V9t,"GPT2TokenizerFast"),V9t.forEach(t),t4o=r(AI," (GPT-J model)"),AI.forEach(t),a4o=i(S),js=n(S,"LI",{});var LI=s(js);Due=n(LI,"STRONG",{});var X9t=s(Due);n4o=r(X9t,"groupvit"),X9t.forEach(t),s4o=r(LI," \u2014 "),cG=n(LI,"A",{href:!0});var z9t=s(cG);l4o=r(z9t,"CLIPTokenizer"),z9t.forEach(t),i4o=r(LI," or "),fG=n(LI,"A",{href:!0});var Q9t=s(fG);d4o=r(Q9t,"CLIPTokenizerFast"),Q9t.forEach(t),m4o=r(LI," (GroupViT model)"),LI.forEach(t),c4o=i(S),Ds=n(S,"LI",{});var yI=s(Ds);Gue=n(yI,"STRONG",{});var W9t=s(Gue);f4o=r(W9t,"herbert"),W9t.forEach(t),g4o=r(yI," \u2014 "),gG=n(yI,"A",{href:!0});var U9t=s(gG);h4o=r(U9t,"HerbertTokenizer"),U9t.forEach(t),u4o=r(yI," or "),hG=n(yI,"A",{href:!0});var H9t=s(hG);p4o=r(H9t,"HerbertTokenizerFast"),H9t.forEach(t),_4o=r(yI," (HerBERT model)"),yI.forEach(t),b4o=i(S),Ou=n(S,"LI",{});var nje=s(Ou);Oue=n(nje,"STRONG",{});var J9t=s(Oue);v4o=r(J9t,"hubert"),J9t.forEach(t),F4o=r(nje," \u2014 "),uG=n(nje,"A",{href:!0});var Y9t=s(uG);T4o=r(Y9t,"Wav2Vec2CTCTokenizer"),Y9t.forEach(t),M4o=r(nje," (Hubert model)"),nje.forEach(t),E4o=i(S),Gs=n(S,"LI",{});var xI=s(Gs);Vue=n(xI,"STRONG",{});var Z9t=s(Vue);C4o=r(Z9t,"ibert"),Z9t.forEach(t),w4o=r(xI," \u2014 "),pG=n(xI,"A",{href:!0});var K9t=s(pG);A4o=r(K9t,"RobertaTokenizer"),K9t.forEach(t),L4o=r(xI," or "),_G=n(xI,"A",{href:!0});var ext=s(_G);y4o=r(ext,"RobertaTokenizerFast"),ext.forEach(t),x4o=r(xI," (I-BERT model)"),xI.forEach(t),$4o=i(S),Os=n(S,"LI",{});var $I=s(Os);Xue=n($I,"STRONG",{});var oxt=s(Xue);k4o=r(oxt,"layoutlm"),oxt.forEach(t),S4o=r($I," \u2014 "),bG=n($I,"A",{href:!0});var rxt=s(bG);R4o=r(rxt,"LayoutLMTokenizer"),rxt.forEach(t),P4o=r($I," or "),vG=n($I,"A",{href:!0});var txt=s(vG);B4o=r(txt,"LayoutLMTokenizerFast"),txt.forEach(t),I4o=r($I," (LayoutLM model)"),$I.forEach(t),N4o=i(S),Vs=n(S,"LI",{});var kI=s(Vs);zue=n(kI,"STRONG",{});var axt=s(zue);q4o=r(axt,"layoutlmv2"),axt.forEach(t),j4o=r(kI," \u2014 "),FG=n(kI,"A",{href:!0});var nxt=s(FG);D4o=r(nxt,"LayoutLMv2Tokenizer"),nxt.forEach(t),G4o=r(kI," or "),TG=n(kI,"A",{href:!0});var sxt=s(TG);O4o=r(sxt,"LayoutLMv2TokenizerFast"),sxt.forEach(t),V4o=r(kI," (LayoutLMv2 model)"),kI.forEach(t),X4o=i(S),Xs=n(S,"LI",{});var SI=s(Xs);Que=n(SI,"STRONG",{});var lxt=s(Que);z4o=r(lxt,"layoutlmv3"),lxt.forEach(t),Q4o=r(SI," \u2014 "),MG=n(SI,"A",{href:!0});var ixt=s(MG);W4o=r(ixt,"LayoutLMv3Tokenizer"),ixt.forEach(t),U4o=r(SI," or "),EG=n(SI,"A",{href:!0});var dxt=s(EG);H4o=r(dxt,"LayoutLMv3TokenizerFast"),dxt.forEach(t),J4o=r(SI," (LayoutLMv3 model)"),SI.forEach(t),Y4o=i(S),zs=n(S,"LI",{});var RI=s(zs);Wue=n(RI,"STRONG",{});var mxt=s(Wue);Z4o=r(mxt,"layoutxlm"),mxt.forEach(t),K4o=r(RI," \u2014 "),CG=n(RI,"A",{href:!0});var cxt=s(CG);eCo=r(cxt,"LayoutXLMTokenizer"),cxt.forEach(t),oCo=r(RI," or "),wG=n(RI,"A",{href:!0});var fxt=s(wG);rCo=r(fxt,"LayoutXLMTokenizerFast"),fxt.forEach(t),tCo=r(RI," (LayoutXLM model)"),RI.forEach(t),aCo=i(S),Qs=n(S,"LI",{});var PI=s(Qs);Uue=n(PI,"STRONG",{});var gxt=s(Uue);nCo=r(gxt,"led"),gxt.forEach(t),sCo=r(PI," \u2014 "),AG=n(PI,"A",{href:!0});var hxt=s(AG);lCo=r(hxt,"LEDTokenizer"),hxt.forEach(t),iCo=r(PI," or "),LG=n(PI,"A",{href:!0});var uxt=s(LG);dCo=r(uxt,"LEDTokenizerFast"),uxt.forEach(t),mCo=r(PI," (LED model)"),PI.forEach(t),cCo=i(S),Ws=n(S,"LI",{});var BI=s(Ws);Hue=n(BI,"STRONG",{});var pxt=s(Hue);fCo=r(pxt,"lilt"),pxt.forEach(t),gCo=r(BI," \u2014 "),yG=n(BI,"A",{href:!0});var _xt=s(yG);hCo=r(_xt,"LayoutLMv3Tokenizer"),_xt.forEach(t),uCo=r(BI," or "),xG=n(BI,"A",{href:!0});var bxt=s(xG);pCo=r(bxt,"LayoutLMv3TokenizerFast"),bxt.forEach(t),_Co=r(BI," (LiLT model)"),BI.forEach(t),bCo=i(S),Us=n(S,"LI",{});var II=s(Us);Jue=n(II,"STRONG",{});var vxt=s(Jue);vCo=r(vxt,"longformer"),vxt.forEach(t),FCo=r(II," \u2014 "),$G=n(II,"A",{href:!0});var Fxt=s($G);TCo=r(Fxt,"LongformerTokenizer"),Fxt.forEach(t),MCo=r(II," or "),kG=n(II,"A",{href:!0});var Txt=s(kG);ECo=r(Txt,"LongformerTokenizerFast"),Txt.forEach(t),CCo=r(II," (Longformer model)"),II.forEach(t),wCo=i(S),Hs=n(S,"LI",{});var NI=s(Hs);Yue=n(NI,"STRONG",{});var Mxt=s(Yue);ACo=r(Mxt,"longt5"),Mxt.forEach(t),LCo=r(NI," \u2014 "),SG=n(NI,"A",{href:!0});var Ext=s(SG);yCo=r(Ext,"T5Tokenizer"),Ext.forEach(t),xCo=r(NI," or "),RG=n(NI,"A",{href:!0});var Cxt=s(RG);$Co=r(Cxt,"T5TokenizerFast"),Cxt.forEach(t),kCo=r(NI," (LongT5 model)"),NI.forEach(t),SCo=i(S),Vu=n(S,"LI",{});var sje=s(Vu);Zue=n(sje,"STRONG",{});var wxt=s(Zue);RCo=r(wxt,"luke"),wxt.forEach(t),PCo=r(sje," \u2014 "),PG=n(sje,"A",{href:!0});var Axt=s(PG);BCo=r(Axt,"LukeTokenizer"),Axt.forEach(t),ICo=r(sje," (LUKE model)"),sje.forEach(t),NCo=i(S),Js=n(S,"LI",{});var qI=s(Js);Kue=n(qI,"STRONG",{});var Lxt=s(Kue);qCo=r(Lxt,"lxmert"),Lxt.forEach(t),jCo=r(qI," \u2014 "),BG=n(qI,"A",{href:!0});var yxt=s(BG);DCo=r(yxt,"LxmertTokenizer"),yxt.forEach(t),GCo=r(qI," or "),IG=n(qI,"A",{href:!0});var xxt=s(IG);OCo=r(xxt,"LxmertTokenizerFast"),xxt.forEach(t),VCo=r(qI," (LXMERT model)"),qI.forEach(t),XCo=i(S),Xu=n(S,"LI",{});var lje=s(Xu);epe=n(lje,"STRONG",{});var $xt=s(epe);zCo=r($xt,"m2m_100"),$xt.forEach(t),QCo=r(lje," \u2014 "),NG=n(lje,"A",{href:!0});var kxt=s(NG);WCo=r(kxt,"M2M100Tokenizer"),kxt.forEach(t),UCo=r(lje," (M2M100 model)"),lje.forEach(t),HCo=i(S),zu=n(S,"LI",{});var ije=s(zu);ope=n(ije,"STRONG",{});var Sxt=s(ope);JCo=r(Sxt,"marian"),Sxt.forEach(t),YCo=r(ije," \u2014 "),qG=n(ije,"A",{href:!0});var Rxt=s(qG);ZCo=r(Rxt,"MarianTokenizer"),Rxt.forEach(t),KCo=r(ije," (Marian model)"),ije.forEach(t),e3o=i(S),Ys=n(S,"LI",{});var jI=s(Ys);rpe=n(jI,"STRONG",{});var Pxt=s(rpe);o3o=r(Pxt,"mbart"),Pxt.forEach(t),r3o=r(jI," \u2014 "),jG=n(jI,"A",{href:!0});var Bxt=s(jG);t3o=r(Bxt,"MBartTokenizer"),Bxt.forEach(t),a3o=r(jI," or "),DG=n(jI,"A",{href:!0});var Ixt=s(DG);n3o=r(Ixt,"MBartTokenizerFast"),Ixt.forEach(t),s3o=r(jI," (mBART model)"),jI.forEach(t),l3o=i(S),Zs=n(S,"LI",{});var DI=s(Zs);tpe=n(DI,"STRONG",{});var Nxt=s(tpe);i3o=r(Nxt,"mbart50"),Nxt.forEach(t),d3o=r(DI," \u2014 "),GG=n(DI,"A",{href:!0});var qxt=s(GG);m3o=r(qxt,"MBart50Tokenizer"),qxt.forEach(t),c3o=r(DI," or "),OG=n(DI,"A",{href:!0});var jxt=s(OG);f3o=r(jxt,"MBart50TokenizerFast"),jxt.forEach(t),g3o=r(DI," (mBART-50 model)"),DI.forEach(t),h3o=i(S),Ks=n(S,"LI",{});var GI=s(Ks);ape=n(GI,"STRONG",{});var Dxt=s(ape);u3o=r(Dxt,"megatron-bert"),Dxt.forEach(t),p3o=r(GI," \u2014 "),VG=n(GI,"A",{href:!0});var Gxt=s(VG);_3o=r(Gxt,"BertTokenizer"),Gxt.forEach(t),b3o=r(GI," or "),XG=n(GI,"A",{href:!0});var Oxt=s(XG);v3o=r(Oxt,"BertTokenizerFast"),Oxt.forEach(t),F3o=r(GI," (Megatron-BERT model)"),GI.forEach(t),T3o=i(S),Qu=n(S,"LI",{});var dje=s(Qu);npe=n(dje,"STRONG",{});var Vxt=s(npe);M3o=r(Vxt,"mluke"),Vxt.forEach(t),E3o=r(dje," \u2014 "),zG=n(dje,"A",{href:!0});var Xxt=s(zG);C3o=r(Xxt,"MLukeTokenizer"),Xxt.forEach(t),w3o=r(dje," (mLUKE model)"),dje.forEach(t),A3o=i(S),el=n(S,"LI",{});var OI=s(el);spe=n(OI,"STRONG",{});var zxt=s(spe);L3o=r(zxt,"mobilebert"),zxt.forEach(t),y3o=r(OI," \u2014 "),QG=n(OI,"A",{href:!0});var Qxt=s(QG);x3o=r(Qxt,"MobileBertTokenizer"),Qxt.forEach(t),$3o=r(OI," or "),WG=n(OI,"A",{href:!0});var Wxt=s(WG);k3o=r(Wxt,"MobileBertTokenizerFast"),Wxt.forEach(t),S3o=r(OI," (MobileBERT model)"),OI.forEach(t),R3o=i(S),ol=n(S,"LI",{});var VI=s(ol);lpe=n(VI,"STRONG",{});var Uxt=s(lpe);P3o=r(Uxt,"mpnet"),Uxt.forEach(t),B3o=r(VI," \u2014 "),UG=n(VI,"A",{href:!0});var Hxt=s(UG);I3o=r(Hxt,"MPNetTokenizer"),Hxt.forEach(t),N3o=r(VI," or "),HG=n(VI,"A",{href:!0});var Jxt=s(HG);q3o=r(Jxt,"MPNetTokenizerFast"),Jxt.forEach(t),j3o=r(VI," (MPNet model)"),VI.forEach(t),D3o=i(S),rl=n(S,"LI",{});var XI=s(rl);ipe=n(XI,"STRONG",{});var Yxt=s(ipe);G3o=r(Yxt,"mt5"),Yxt.forEach(t),O3o=r(XI," \u2014 "),JG=n(XI,"A",{href:!0});var Zxt=s(JG);V3o=r(Zxt,"MT5Tokenizer"),Zxt.forEach(t),X3o=r(XI," or "),YG=n(XI,"A",{href:!0});var Kxt=s(YG);z3o=r(Kxt,"MT5TokenizerFast"),Kxt.forEach(t),Q3o=r(XI," (MT5 model)"),XI.forEach(t),W3o=i(S),tl=n(S,"LI",{});var zI=s(tl);dpe=n(zI,"STRONG",{});var e$t=s(dpe);U3o=r(e$t,"mvp"),e$t.forEach(t),H3o=r(zI," \u2014 "),ZG=n(zI,"A",{href:!0});var o$t=s(ZG);J3o=r(o$t,"MvpTokenizer"),o$t.forEach(t),Y3o=r(zI," or "),KG=n(zI,"A",{href:!0});var r$t=s(KG);Z3o=r(r$t,"MvpTokenizerFast"),r$t.forEach(t),K3o=r(zI," (MVP model)"),zI.forEach(t),e5o=i(S),al=n(S,"LI",{});var QI=s(al);mpe=n(QI,"STRONG",{});var t$t=s(mpe);o5o=r(t$t,"nezha"),t$t.forEach(t),r5o=r(QI," \u2014 "),eO=n(QI,"A",{href:!0});var a$t=s(eO);t5o=r(a$t,"BertTokenizer"),a$t.forEach(t),a5o=r(QI," or "),oO=n(QI,"A",{href:!0});var n$t=s(oO);n5o=r(n$t,"BertTokenizerFast"),n$t.forEach(t),s5o=r(QI," (Nezha model)"),QI.forEach(t),l5o=i(S),nl=n(S,"LI",{});var WI=s(nl);cpe=n(WI,"STRONG",{});var s$t=s(cpe);i5o=r(s$t,"nllb"),s$t.forEach(t),d5o=r(WI," \u2014 "),rO=n(WI,"A",{href:!0});var l$t=s(rO);m5o=r(l$t,"NllbTokenizer"),l$t.forEach(t),c5o=r(WI," or "),tO=n(WI,"A",{href:!0});var i$t=s(tO);f5o=r(i$t,"NllbTokenizerFast"),i$t.forEach(t),g5o=r(WI," (NLLB model)"),WI.forEach(t),h5o=i(S),sl=n(S,"LI",{});var UI=s(sl);fpe=n(UI,"STRONG",{});var d$t=s(fpe);u5o=r(d$t,"nystromformer"),d$t.forEach(t),p5o=r(UI," \u2014 "),aO=n(UI,"A",{href:!0});var m$t=s(aO);_5o=r(m$t,"AlbertTokenizer"),m$t.forEach(t),b5o=r(UI," or "),nO=n(UI,"A",{href:!0});var c$t=s(nO);v5o=r(c$t,"AlbertTokenizerFast"),c$t.forEach(t),F5o=r(UI," (Nystr\xF6mformer model)"),UI.forEach(t),T5o=i(S),ll=n(S,"LI",{});var HI=s(ll);gpe=n(HI,"STRONG",{});var f$t=s(gpe);M5o=r(f$t,"openai-gpt"),f$t.forEach(t),E5o=r(HI," \u2014 "),sO=n(HI,"A",{href:!0});var g$t=s(sO);C5o=r(g$t,"OpenAIGPTTokenizer"),g$t.forEach(t),w5o=r(HI," or "),lO=n(HI,"A",{href:!0});var h$t=s(lO);A5o=r(h$t,"OpenAIGPTTokenizerFast"),h$t.forEach(t),L5o=r(HI," (OpenAI GPT model)"),HI.forEach(t),y5o=i(S),Wu=n(S,"LI",{});var mje=s(Wu);hpe=n(mje,"STRONG",{});var u$t=s(hpe);x5o=r(u$t,"opt"),u$t.forEach(t),$5o=r(mje," \u2014 "),iO=n(mje,"A",{href:!0});var p$t=s(iO);k5o=r(p$t,"GPT2Tokenizer"),p$t.forEach(t),S5o=r(mje," (OPT model)"),mje.forEach(t),R5o=i(S),il=n(S,"LI",{});var JI=s(il);upe=n(JI,"STRONG",{});var _$t=s(upe);P5o=r(_$t,"owlvit"),_$t.forEach(t),B5o=r(JI," \u2014 "),dO=n(JI,"A",{href:!0});var b$t=s(dO);I5o=r(b$t,"CLIPTokenizer"),b$t.forEach(t),N5o=r(JI," or "),mO=n(JI,"A",{href:!0});var v$t=s(mO);q5o=r(v$t,"CLIPTokenizerFast"),v$t.forEach(t),j5o=r(JI," (OWL-ViT model)"),JI.forEach(t),D5o=i(S),dl=n(S,"LI",{});var YI=s(dl);ppe=n(YI,"STRONG",{});var F$t=s(ppe);G5o=r(F$t,"pegasus"),F$t.forEach(t),O5o=r(YI," \u2014 "),cO=n(YI,"A",{href:!0});var T$t=s(cO);V5o=r(T$t,"PegasusTokenizer"),T$t.forEach(t),X5o=r(YI," or "),fO=n(YI,"A",{href:!0});var M$t=s(fO);z5o=r(M$t,"PegasusTokenizerFast"),M$t.forEach(t),Q5o=r(YI," (Pegasus model)"),YI.forEach(t),W5o=i(S),ml=n(S,"LI",{});var ZI=s(ml);_pe=n(ZI,"STRONG",{});var E$t=s(_pe);U5o=r(E$t,"pegasus_x"),E$t.forEach(t),H5o=r(ZI," \u2014 "),gO=n(ZI,"A",{href:!0});var C$t=s(gO);J5o=r(C$t,"PegasusTokenizer"),C$t.forEach(t),Y5o=r(ZI," or "),hO=n(ZI,"A",{href:!0});var w$t=s(hO);Z5o=r(w$t,"PegasusTokenizerFast"),w$t.forEach(t),K5o=r(ZI," (PEGASUS-X model)"),ZI.forEach(t),e0o=i(S),Uu=n(S,"LI",{});var cje=s(Uu);bpe=n(cje,"STRONG",{});var A$t=s(bpe);o0o=r(A$t,"perceiver"),A$t.forEach(t),r0o=r(cje," \u2014 "),uO=n(cje,"A",{href:!0});var L$t=s(uO);t0o=r(L$t,"PerceiverTokenizer"),L$t.forEach(t),a0o=r(cje," (Perceiver model)"),cje.forEach(t),n0o=i(S),Hu=n(S,"LI",{});var fje=s(Hu);vpe=n(fje,"STRONG",{});var y$t=s(vpe);s0o=r(y$t,"phobert"),y$t.forEach(t),l0o=r(fje," \u2014 "),pO=n(fje,"A",{href:!0});var x$t=s(pO);i0o=r(x$t,"PhobertTokenizer"),x$t.forEach(t),d0o=r(fje," (PhoBERT model)"),fje.forEach(t),m0o=i(S),Ju=n(S,"LI",{});var gje=s(Ju);Fpe=n(gje,"STRONG",{});var $$t=s(Fpe);c0o=r($$t,"plbart"),$$t.forEach(t),f0o=r(gje," \u2014 "),_O=n(gje,"A",{href:!0});var k$t=s(_O);g0o=r(k$t,"PLBartTokenizer"),k$t.forEach(t),h0o=r(gje," (PLBart model)"),gje.forEach(t),u0o=i(S),Yu=n(S,"LI",{});var hje=s(Yu);Tpe=n(hje,"STRONG",{});var S$t=s(Tpe);p0o=r(S$t,"prophetnet"),S$t.forEach(t),_0o=r(hje," \u2014 "),bO=n(hje,"A",{href:!0});var R$t=s(bO);b0o=r(R$t,"ProphetNetTokenizer"),R$t.forEach(t),v0o=r(hje," (ProphetNet model)"),hje.forEach(t),F0o=i(S),cl=n(S,"LI",{});var KI=s(cl);Mpe=n(KI,"STRONG",{});var P$t=s(Mpe);T0o=r(P$t,"qdqbert"),P$t.forEach(t),M0o=r(KI," \u2014 "),vO=n(KI,"A",{href:!0});var B$t=s(vO);E0o=r(B$t,"BertTokenizer"),B$t.forEach(t),C0o=r(KI," or "),FO=n(KI,"A",{href:!0});var I$t=s(FO);w0o=r(I$t,"BertTokenizerFast"),I$t.forEach(t),A0o=r(KI," (QDQBert model)"),KI.forEach(t),L0o=i(S),Zu=n(S,"LI",{});var uje=s(Zu);Epe=n(uje,"STRONG",{});var N$t=s(Epe);y0o=r(N$t,"rag"),N$t.forEach(t),x0o=r(uje," \u2014 "),TO=n(uje,"A",{href:!0});var q$t=s(TO);$0o=r(q$t,"RagTokenizer"),q$t.forEach(t),k0o=r(uje," (RAG model)"),uje.forEach(t),S0o=i(S),fl=n(S,"LI",{});var eN=s(fl);Cpe=n(eN,"STRONG",{});var j$t=s(Cpe);R0o=r(j$t,"realm"),j$t.forEach(t),P0o=r(eN," \u2014 "),MO=n(eN,"A",{href:!0});var D$t=s(MO);B0o=r(D$t,"RealmTokenizer"),D$t.forEach(t),I0o=r(eN," or "),EO=n(eN,"A",{href:!0});var G$t=s(EO);N0o=r(G$t,"RealmTokenizerFast"),G$t.forEach(t),q0o=r(eN," (REALM model)"),eN.forEach(t),j0o=i(S),gl=n(S,"LI",{});var oN=s(gl);wpe=n(oN,"STRONG",{});var O$t=s(wpe);D0o=r(O$t,"reformer"),O$t.forEach(t),G0o=r(oN," \u2014 "),CO=n(oN,"A",{href:!0});var V$t=s(CO);O0o=r(V$t,"ReformerTokenizer"),V$t.forEach(t),V0o=r(oN," or "),wO=n(oN,"A",{href:!0});var X$t=s(wO);X0o=r(X$t,"ReformerTokenizerFast"),X$t.forEach(t),z0o=r(oN," (Reformer model)"),oN.forEach(t),Q0o=i(S),hl=n(S,"LI",{});var rN=s(hl);Ape=n(rN,"STRONG",{});var z$t=s(Ape);W0o=r(z$t,"rembert"),z$t.forEach(t),U0o=r(rN," \u2014 "),AO=n(rN,"A",{href:!0});var Q$t=s(AO);H0o=r(Q$t,"RemBertTokenizer"),Q$t.forEach(t),J0o=r(rN," or "),LO=n(rN,"A",{href:!0});var W$t=s(LO);Y0o=r(W$t,"RemBertTokenizerFast"),W$t.forEach(t),Z0o=r(rN," (RemBERT model)"),rN.forEach(t),K0o=i(S),ul=n(S,"LI",{});var tN=s(ul);Lpe=n(tN,"STRONG",{});var U$t=s(Lpe);ewo=r(U$t,"retribert"),U$t.forEach(t),owo=r(tN," \u2014 "),yO=n(tN,"A",{href:!0});var H$t=s(yO);rwo=r(H$t,"RetriBertTokenizer"),H$t.forEach(t),two=r(tN," or "),xO=n(tN,"A",{href:!0});var J$t=s(xO);awo=r(J$t,"RetriBertTokenizerFast"),J$t.forEach(t),nwo=r(tN," (RetriBERT model)"),tN.forEach(t),swo=i(S),pl=n(S,"LI",{});var aN=s(pl);ype=n(aN,"STRONG",{});var Y$t=s(ype);lwo=r(Y$t,"roberta"),Y$t.forEach(t),iwo=r(aN," \u2014 "),$O=n(aN,"A",{href:!0});var Z$t=s($O);dwo=r(Z$t,"RobertaTokenizer"),Z$t.forEach(t),mwo=r(aN," or "),kO=n(aN,"A",{href:!0});var K$t=s(kO);cwo=r(K$t,"RobertaTokenizerFast"),K$t.forEach(t),fwo=r(aN," (RoBERTa model)"),aN.forEach(t),gwo=i(S),_l=n(S,"LI",{});var nN=s(_l);xpe=n(nN,"STRONG",{});var ekt=s(xpe);hwo=r(ekt,"roformer"),ekt.forEach(t),uwo=r(nN," \u2014 "),SO=n(nN,"A",{href:!0});var okt=s(SO);pwo=r(okt,"RoFormerTokenizer"),okt.forEach(t),_wo=r(nN," or "),RO=n(nN,"A",{href:!0});var rkt=s(RO);bwo=r(rkt,"RoFormerTokenizerFast"),rkt.forEach(t),vwo=r(nN," (RoFormer model)"),nN.forEach(t),Fwo=i(S),Ku=n(S,"LI",{});var pje=s(Ku);$pe=n(pje,"STRONG",{});var tkt=s($pe);Two=r(tkt,"speech_to_text"),tkt.forEach(t),Mwo=r(pje," \u2014 "),PO=n(pje,"A",{href:!0});var akt=s(PO);Ewo=r(akt,"Speech2TextTokenizer"),akt.forEach(t),Cwo=r(pje," (Speech2Text model)"),pje.forEach(t),wwo=i(S),ep=n(S,"LI",{});var _je=s(ep);kpe=n(_je,"STRONG",{});var nkt=s(kpe);Awo=r(nkt,"speech_to_text_2"),nkt.forEach(t),Lwo=r(_je," \u2014 "),BO=n(_je,"A",{href:!0});var skt=s(BO);ywo=r(skt,"Speech2Text2Tokenizer"),skt.forEach(t),xwo=r(_je," (Speech2Text2 model)"),_je.forEach(t),$wo=i(S),bl=n(S,"LI",{});var sN=s(bl);Spe=n(sN,"STRONG",{});var lkt=s(Spe);kwo=r(lkt,"splinter"),lkt.forEach(t),Swo=r(sN," \u2014 "),IO=n(sN,"A",{href:!0});var ikt=s(IO);Rwo=r(ikt,"SplinterTokenizer"),ikt.forEach(t),Pwo=r(sN," or "),NO=n(sN,"A",{href:!0});var dkt=s(NO);Bwo=r(dkt,"SplinterTokenizerFast"),dkt.forEach(t),Iwo=r(sN," (Splinter model)"),sN.forEach(t),Nwo=i(S),vl=n(S,"LI",{});var lN=s(vl);Rpe=n(lN,"STRONG",{});var mkt=s(Rpe);qwo=r(mkt,"squeezebert"),mkt.forEach(t),jwo=r(lN," \u2014 "),qO=n(lN,"A",{href:!0});var ckt=s(qO);Dwo=r(ckt,"SqueezeBertTokenizer"),ckt.forEach(t),Gwo=r(lN," or "),jO=n(lN,"A",{href:!0});var fkt=s(jO);Owo=r(fkt,"SqueezeBertTokenizerFast"),fkt.forEach(t),Vwo=r(lN," (SqueezeBERT model)"),lN.forEach(t),Xwo=i(S),Fl=n(S,"LI",{});var iN=s(Fl);Ppe=n(iN,"STRONG",{});var gkt=s(Ppe);zwo=r(gkt,"t5"),gkt.forEach(t),Qwo=r(iN," \u2014 "),DO=n(iN,"A",{href:!0});var hkt=s(DO);Wwo=r(hkt,"T5Tokenizer"),hkt.forEach(t),Uwo=r(iN," or "),GO=n(iN,"A",{href:!0});var ukt=s(GO);Hwo=r(ukt,"T5TokenizerFast"),ukt.forEach(t),Jwo=r(iN," (T5 model)"),iN.forEach(t),Ywo=i(S),op=n(S,"LI",{});var bje=s(op);Bpe=n(bje,"STRONG",{});var pkt=s(Bpe);Zwo=r(pkt,"tapas"),pkt.forEach(t),Kwo=r(bje," \u2014 "),OO=n(bje,"A",{href:!0});var _kt=s(OO);eAo=r(_kt,"TapasTokenizer"),_kt.forEach(t),oAo=r(bje," (TAPAS model)"),bje.forEach(t),rAo=i(S),rp=n(S,"LI",{});var vje=s(rp);Ipe=n(vje,"STRONG",{});var bkt=s(Ipe);tAo=r(bkt,"tapex"),bkt.forEach(t),aAo=r(vje," \u2014 "),VO=n(vje,"A",{href:!0});var vkt=s(VO);nAo=r(vkt,"TapexTokenizer"),vkt.forEach(t),sAo=r(vje," (TAPEX model)"),vje.forEach(t),lAo=i(S),tp=n(S,"LI",{});var Fje=s(tp);Npe=n(Fje,"STRONG",{});var Fkt=s(Npe);iAo=r(Fkt,"transfo-xl"),Fkt.forEach(t),dAo=r(Fje," \u2014 "),XO=n(Fje,"A",{href:!0});var Tkt=s(XO);mAo=r(Tkt,"TransfoXLTokenizer"),Tkt.forEach(t),cAo=r(Fje," (Transformer-XL model)"),Fje.forEach(t),fAo=i(S),Tl=n(S,"LI",{});var dN=s(Tl);qpe=n(dN,"STRONG",{});var Mkt=s(qpe);gAo=r(Mkt,"vilt"),Mkt.forEach(t),hAo=r(dN," \u2014 "),zO=n(dN,"A",{href:!0});var Ekt=s(zO);uAo=r(Ekt,"BertTokenizer"),Ekt.forEach(t),pAo=r(dN," or "),QO=n(dN,"A",{href:!0});var Ckt=s(QO);_Ao=r(Ckt,"BertTokenizerFast"),Ckt.forEach(t),bAo=r(dN," (ViLT model)"),dN.forEach(t),vAo=i(S),Ml=n(S,"LI",{});var mN=s(Ml);jpe=n(mN,"STRONG",{});var wkt=s(jpe);FAo=r(wkt,"visual_bert"),wkt.forEach(t),TAo=r(mN," \u2014 "),WO=n(mN,"A",{href:!0});var Akt=s(WO);MAo=r(Akt,"BertTokenizer"),Akt.forEach(t),EAo=r(mN," or "),UO=n(mN,"A",{href:!0});var Lkt=s(UO);CAo=r(Lkt,"BertTokenizerFast"),Lkt.forEach(t),wAo=r(mN," (VisualBERT model)"),mN.forEach(t),AAo=i(S),ap=n(S,"LI",{});var Tje=s(ap);Dpe=n(Tje,"STRONG",{});var ykt=s(Dpe);LAo=r(ykt,"wav2vec2"),ykt.forEach(t),yAo=r(Tje," \u2014 "),HO=n(Tje,"A",{href:!0});var xkt=s(HO);xAo=r(xkt,"Wav2Vec2CTCTokenizer"),xkt.forEach(t),$Ao=r(Tje," (Wav2Vec2 model)"),Tje.forEach(t),kAo=i(S),np=n(S,"LI",{});var Mje=s(np);Gpe=n(Mje,"STRONG",{});var $kt=s(Gpe);SAo=r($kt,"wav2vec2-conformer"),$kt.forEach(t),RAo=r(Mje," \u2014 "),JO=n(Mje,"A",{href:!0});var kkt=s(JO);PAo=r(kkt,"Wav2Vec2CTCTokenizer"),kkt.forEach(t),BAo=r(Mje," (Wav2Vec2-Conformer model)"),Mje.forEach(t),IAo=i(S),sp=n(S,"LI",{});var Eje=s(sp);Ope=n(Eje,"STRONG",{});var Skt=s(Ope);NAo=r(Skt,"wav2vec2_phoneme"),Skt.forEach(t),qAo=r(Eje," \u2014 "),YO=n(Eje,"A",{href:!0});var Rkt=s(YO);jAo=r(Rkt,"Wav2Vec2PhonemeCTCTokenizer"),Rkt.forEach(t),DAo=r(Eje," (Wav2Vec2Phoneme model)"),Eje.forEach(t),GAo=i(S),lp=n(S,"LI",{});var Cje=s(lp);Vpe=n(Cje,"STRONG",{});var Pkt=s(Vpe);OAo=r(Pkt,"whisper"),Pkt.forEach(t),VAo=r(Cje," \u2014 "),ZO=n(Cje,"A",{href:!0});var Bkt=s(ZO);XAo=r(Bkt,"WhisperTokenizer"),Bkt.forEach(t),zAo=r(Cje," (Whisper model)"),Cje.forEach(t),QAo=i(S),El=n(S,"LI",{});var cN=s(El);Xpe=n(cN,"STRONG",{});var Ikt=s(Xpe);WAo=r(Ikt,"xclip"),Ikt.forEach(t),UAo=r(cN," \u2014 "),KO=n(cN,"A",{href:!0});var Nkt=s(KO);HAo=r(Nkt,"CLIPTokenizer"),Nkt.forEach(t),JAo=r(cN," or "),eV=n(cN,"A",{href:!0});var qkt=s(eV);YAo=r(qkt,"CLIPTokenizerFast"),qkt.forEach(t),ZAo=r(cN," (X-CLIP model)"),cN.forEach(t),KAo=i(S),Cl=n(S,"LI",{});var fN=s(Cl);zpe=n(fN,"STRONG",{});var jkt=s(zpe);e6o=r(jkt,"xglm"),jkt.forEach(t),o6o=r(fN," \u2014 "),oV=n(fN,"A",{href:!0});var Dkt=s(oV);r6o=r(Dkt,"XGLMTokenizer"),Dkt.forEach(t),t6o=r(fN," or "),rV=n(fN,"A",{href:!0});var Gkt=s(rV);a6o=r(Gkt,"XGLMTokenizerFast"),Gkt.forEach(t),n6o=r(fN," (XGLM model)"),fN.forEach(t),s6o=i(S),ip=n(S,"LI",{});var wje=s(ip);Qpe=n(wje,"STRONG",{});var Okt=s(Qpe);l6o=r(Okt,"xlm"),Okt.forEach(t),i6o=r(wje," \u2014 "),tV=n(wje,"A",{href:!0});var Vkt=s(tV);d6o=r(Vkt,"XLMTokenizer"),Vkt.forEach(t),m6o=r(wje," (XLM model)"),wje.forEach(t),c6o=i(S),dp=n(S,"LI",{});var Aje=s(dp);Wpe=n(Aje,"STRONG",{});var Xkt=s(Wpe);f6o=r(Xkt,"xlm-prophetnet"),Xkt.forEach(t),g6o=r(Aje," \u2014 "),aV=n(Aje,"A",{href:!0});var zkt=s(aV);h6o=r(zkt,"XLMProphetNetTokenizer"),zkt.forEach(t),u6o=r(Aje," (XLM-ProphetNet model)"),Aje.forEach(t),p6o=i(S),wl=n(S,"LI",{});var gN=s(wl);Upe=n(gN,"STRONG",{});var Qkt=s(Upe);_6o=r(Qkt,"xlm-roberta"),Qkt.forEach(t),b6o=r(gN," \u2014 "),nV=n(gN,"A",{href:!0});var Wkt=s(nV);v6o=r(Wkt,"XLMRobertaTokenizer"),Wkt.forEach(t),F6o=r(gN," or "),sV=n(gN,"A",{href:!0});var Ukt=s(sV);T6o=r(Ukt,"XLMRobertaTokenizerFast"),Ukt.forEach(t),M6o=r(gN," (XLM-RoBERTa model)"),gN.forEach(t),E6o=i(S),Al=n(S,"LI",{});var hN=s(Al);Hpe=n(hN,"STRONG",{});var Hkt=s(Hpe);C6o=r(Hkt,"xlm-roberta-xl"),Hkt.forEach(t),w6o=r(hN," \u2014 "),lV=n(hN,"A",{href:!0});var Jkt=s(lV);A6o=r(Jkt,"XLMRobertaTokenizer"),Jkt.forEach(t),L6o=r(hN," or "),iV=n(hN,"A",{href:!0});var Ykt=s(iV);y6o=r(Ykt,"XLMRobertaTokenizerFast"),Ykt.forEach(t),x6o=r(hN," (XLM-RoBERTa-XL model)"),hN.forEach(t),$6o=i(S),Ll=n(S,"LI",{});var uN=s(Ll);Jpe=n(uN,"STRONG",{});var Zkt=s(Jpe);k6o=r(Zkt,"xlnet"),Zkt.forEach(t),S6o=r(uN," \u2014 "),dV=n(uN,"A",{href:!0});var Kkt=s(dV);R6o=r(Kkt,"XLNetTokenizer"),Kkt.forEach(t),P6o=r(uN," or "),mV=n(uN,"A",{href:!0});var eSt=s(mV);B6o=r(eSt,"XLNetTokenizerFast"),eSt.forEach(t),I6o=r(uN," (XLNet model)"),uN.forEach(t),N6o=i(S),yl=n(S,"LI",{});var pN=s(yl);Ype=n(pN,"STRONG",{});var oSt=s(Ype);q6o=r(oSt,"yoso"),oSt.forEach(t),j6o=r(pN," \u2014 "),cV=n(pN,"A",{href:!0});var rSt=s(cV);D6o=r(rSt,"AlbertTokenizer"),rSt.forEach(t),G6o=r(pN," or "),fV=n(pN,"A",{href:!0});var tSt=s(fV);O6o=r(tSt,"AlbertTokenizerFast"),tSt.forEach(t),V6o=r(pN," (YOSO model)"),pN.forEach(t),S.forEach(t),X6o=i(Bl),T(mp.$$.fragment,Bl),Bl.forEach(t),z6o=i(Pl),cp=n(Pl,"DIV",{class:!0});var Wno=s(cp);T(M$.$$.fragment,Wno),Q6o=i(Wno),Zpe=n(Wno,"P",{});var aSt=s(Zpe);W6o=r(aSt,"Register a new tokenizer in this mapping."),aSt.forEach(t),Wno.forEach(t),Pl.forEach(t),Pto=i(c),xd=n(c,"H2",{class:!0});var Uno=s(xd);fp=n(Uno,"A",{id:!0,class:!0,href:!0});var nSt=s(fp);Kpe=n(nSt,"SPAN",{});var sSt=s(Kpe);T(E$.$$.fragment,sSt),sSt.forEach(t),nSt.forEach(t),U6o=i(Uno),e_e=n(Uno,"SPAN",{});var lSt=s(e_e);H6o=r(lSt,"AutoFeatureExtractor"),lSt.forEach(t),Uno.forEach(t),Bto=i(c),Po=n(c,"DIV",{class:!0});var Il=s(Po);T(C$.$$.fragment,Il),J6o=i(Il),w$=n(Il,"P",{});var Hno=s(w$);Y6o=r(Hno,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),gV=n(Hno,"A",{href:!0});var iSt=s(gV);Z6o=r(iSt,"AutoFeatureExtractor.from_pretrained()"),iSt.forEach(t),K6o=r(Hno," class method."),Hno.forEach(t),e7o=i(Il),A$=n(Il,"P",{});var Jno=s(A$);o7o=r(Jno,"This class cannot be instantiated directly using "),o_e=n(Jno,"CODE",{});var dSt=s(o_e);r7o=r(dSt,"__init__()"),dSt.forEach(t),t7o=r(Jno," (throws an error)."),Jno.forEach(t),a7o=i(Il),Ye=n(Il,"DIV",{class:!0});var wa=s(Ye);T(L$.$$.fragment,wa),n7o=i(wa),r_e=n(wa,"P",{});var mSt=s(r_e);s7o=r(mSt,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),mSt.forEach(t),l7o=i(wa),an=n(wa,"P",{});var Ky=s(an);i7o=r(Ky,"The feature extractor class to instantiate is selected based on the "),t_e=n(Ky,"CODE",{});var cSt=s(t_e);d7o=r(cSt,"model_type"),cSt.forEach(t),m7o=r(Ky,` property of the config object
(either passed as an argument or loaded from `),a_e=n(Ky,"CODE",{});var fSt=s(a_e);c7o=r(fSt,"pretrained_model_name_or_path"),fSt.forEach(t),f7o=r(Ky,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),n_e=n(Ky,"CODE",{});var gSt=s(n_e);g7o=r(gSt,"pretrained_model_name_or_path"),gSt.forEach(t),h7o=r(Ky,":"),Ky.forEach(t),u7o=i(wa),z=n(wa,"UL",{});var Q=s(z);gp=n(Q,"LI",{});var Lje=s(gp);s_e=n(Lje,"STRONG",{});var hSt=s(s_e);p7o=r(hSt,"beit"),hSt.forEach(t),_7o=r(Lje," \u2014 "),hV=n(Lje,"A",{href:!0});var uSt=s(hV);b7o=r(uSt,"BeitFeatureExtractor"),uSt.forEach(t),v7o=r(Lje," (BEiT model)"),Lje.forEach(t),F7o=i(Q),hp=n(Q,"LI",{});var yje=s(hp);l_e=n(yje,"STRONG",{});var pSt=s(l_e);T7o=r(pSt,"clip"),pSt.forEach(t),M7o=r(yje," \u2014 "),uV=n(yje,"A",{href:!0});var _St=s(uV);E7o=r(_St,"CLIPFeatureExtractor"),_St.forEach(t),C7o=r(yje," (CLIP model)"),yje.forEach(t),w7o=i(Q),up=n(Q,"LI",{});var xje=s(up);i_e=n(xje,"STRONG",{});var bSt=s(i_e);A7o=r(bSt,"conditional_detr"),bSt.forEach(t),L7o=r(xje," \u2014 "),pV=n(xje,"A",{href:!0});var vSt=s(pV);y7o=r(vSt,"ConditionalDetrFeatureExtractor"),vSt.forEach(t),x7o=r(xje," (Conditional DETR model)"),xje.forEach(t),$7o=i(Q),pp=n(Q,"LI",{});var $je=s(pp);d_e=n($je,"STRONG",{});var FSt=s(d_e);k7o=r(FSt,"convnext"),FSt.forEach(t),S7o=r($je," \u2014 "),_V=n($je,"A",{href:!0});var TSt=s(_V);R7o=r(TSt,"ConvNextFeatureExtractor"),TSt.forEach(t),P7o=r($je," (ConvNeXT model)"),$je.forEach(t),B7o=i(Q),_p=n(Q,"LI",{});var kje=s(_p);m_e=n(kje,"STRONG",{});var MSt=s(m_e);I7o=r(MSt,"cvt"),MSt.forEach(t),N7o=r(kje," \u2014 "),bV=n(kje,"A",{href:!0});var ESt=s(bV);q7o=r(ESt,"ConvNextFeatureExtractor"),ESt.forEach(t),j7o=r(kje," (CvT model)"),kje.forEach(t),D7o=i(Q),bp=n(Q,"LI",{});var Sje=s(bp);c_e=n(Sje,"STRONG",{});var CSt=s(c_e);G7o=r(CSt,"data2vec-audio"),CSt.forEach(t),O7o=r(Sje," \u2014 "),vV=n(Sje,"A",{href:!0});var wSt=s(vV);V7o=r(wSt,"Wav2Vec2FeatureExtractor"),wSt.forEach(t),X7o=r(Sje," (Data2VecAudio model)"),Sje.forEach(t),z7o=i(Q),vp=n(Q,"LI",{});var Rje=s(vp);f_e=n(Rje,"STRONG",{});var ASt=s(f_e);Q7o=r(ASt,"data2vec-vision"),ASt.forEach(t),W7o=r(Rje," \u2014 "),FV=n(Rje,"A",{href:!0});var LSt=s(FV);U7o=r(LSt,"BeitFeatureExtractor"),LSt.forEach(t),H7o=r(Rje," (Data2VecVision model)"),Rje.forEach(t),J7o=i(Q),Fp=n(Q,"LI",{});var Pje=s(Fp);g_e=n(Pje,"STRONG",{});var ySt=s(g_e);Y7o=r(ySt,"deformable_detr"),ySt.forEach(t),Z7o=r(Pje," \u2014 "),TV=n(Pje,"A",{href:!0});var xSt=s(TV);K7o=r(xSt,"DeformableDetrFeatureExtractor"),xSt.forEach(t),e8o=r(Pje," (Deformable DETR model)"),Pje.forEach(t),o8o=i(Q),Tp=n(Q,"LI",{});var Bje=s(Tp);h_e=n(Bje,"STRONG",{});var $St=s(h_e);r8o=r($St,"deit"),$St.forEach(t),t8o=r(Bje," \u2014 "),MV=n(Bje,"A",{href:!0});var kSt=s(MV);a8o=r(kSt,"DeiTFeatureExtractor"),kSt.forEach(t),n8o=r(Bje," (DeiT model)"),Bje.forEach(t),s8o=i(Q),Mp=n(Q,"LI",{});var Ije=s(Mp);u_e=n(Ije,"STRONG",{});var SSt=s(u_e);l8o=r(SSt,"detr"),SSt.forEach(t),i8o=r(Ije," \u2014 "),EV=n(Ije,"A",{href:!0});var RSt=s(EV);d8o=r(RSt,"DetrFeatureExtractor"),RSt.forEach(t),m8o=r(Ije," (DETR model)"),Ije.forEach(t),c8o=i(Q),Ep=n(Q,"LI",{});var Nje=s(Ep);p_e=n(Nje,"STRONG",{});var PSt=s(p_e);f8o=r(PSt,"donut-swin"),PSt.forEach(t),g8o=r(Nje," \u2014 "),CV=n(Nje,"A",{href:!0});var BSt=s(CV);h8o=r(BSt,"DonutFeatureExtractor"),BSt.forEach(t),u8o=r(Nje," (DonutSwin model)"),Nje.forEach(t),p8o=i(Q),Cp=n(Q,"LI",{});var qje=s(Cp);__e=n(qje,"STRONG",{});var ISt=s(__e);_8o=r(ISt,"dpt"),ISt.forEach(t),b8o=r(qje," \u2014 "),wV=n(qje,"A",{href:!0});var NSt=s(wV);v8o=r(NSt,"DPTFeatureExtractor"),NSt.forEach(t),F8o=r(qje," (DPT model)"),qje.forEach(t),T8o=i(Q),wp=n(Q,"LI",{});var jje=s(wp);b_e=n(jje,"STRONG",{});var qSt=s(b_e);M8o=r(qSt,"flava"),qSt.forEach(t),E8o=r(jje," \u2014 "),AV=n(jje,"A",{href:!0});var jSt=s(AV);C8o=r(jSt,"FlavaFeatureExtractor"),jSt.forEach(t),w8o=r(jje," (FLAVA model)"),jje.forEach(t),A8o=i(Q),Ap=n(Q,"LI",{});var Dje=s(Ap);v_e=n(Dje,"STRONG",{});var DSt=s(v_e);L8o=r(DSt,"glpn"),DSt.forEach(t),y8o=r(Dje," \u2014 "),LV=n(Dje,"A",{href:!0});var GSt=s(LV);x8o=r(GSt,"GLPNFeatureExtractor"),GSt.forEach(t),$8o=r(Dje," (GLPN model)"),Dje.forEach(t),k8o=i(Q),Lp=n(Q,"LI",{});var Gje=s(Lp);F_e=n(Gje,"STRONG",{});var OSt=s(F_e);S8o=r(OSt,"groupvit"),OSt.forEach(t),R8o=r(Gje," \u2014 "),yV=n(Gje,"A",{href:!0});var VSt=s(yV);P8o=r(VSt,"CLIPFeatureExtractor"),VSt.forEach(t),B8o=r(Gje," (GroupViT model)"),Gje.forEach(t),I8o=i(Q),yp=n(Q,"LI",{});var Oje=s(yp);T_e=n(Oje,"STRONG",{});var XSt=s(T_e);N8o=r(XSt,"hubert"),XSt.forEach(t),q8o=r(Oje," \u2014 "),xV=n(Oje,"A",{href:!0});var zSt=s(xV);j8o=r(zSt,"Wav2Vec2FeatureExtractor"),zSt.forEach(t),D8o=r(Oje," (Hubert model)"),Oje.forEach(t),G8o=i(Q),xp=n(Q,"LI",{});var Vje=s(xp);M_e=n(Vje,"STRONG",{});var QSt=s(M_e);O8o=r(QSt,"imagegpt"),QSt.forEach(t),V8o=r(Vje," \u2014 "),$V=n(Vje,"A",{href:!0});var WSt=s($V);X8o=r(WSt,"ImageGPTFeatureExtractor"),WSt.forEach(t),z8o=r(Vje," (ImageGPT model)"),Vje.forEach(t),Q8o=i(Q),$p=n(Q,"LI",{});var Xje=s($p);E_e=n(Xje,"STRONG",{});var USt=s(E_e);W8o=r(USt,"layoutlmv2"),USt.forEach(t),U8o=r(Xje," \u2014 "),kV=n(Xje,"A",{href:!0});var HSt=s(kV);H8o=r(HSt,"LayoutLMv2FeatureExtractor"),HSt.forEach(t),J8o=r(Xje," (LayoutLMv2 model)"),Xje.forEach(t),Y8o=i(Q),kp=n(Q,"LI",{});var zje=s(kp);C_e=n(zje,"STRONG",{});var JSt=s(C_e);Z8o=r(JSt,"layoutlmv3"),JSt.forEach(t),K8o=r(zje," \u2014 "),SV=n(zje,"A",{href:!0});var YSt=s(SV);eLo=r(YSt,"LayoutLMv3FeatureExtractor"),YSt.forEach(t),oLo=r(zje," (LayoutLMv3 model)"),zje.forEach(t),rLo=i(Q),Sp=n(Q,"LI",{});var Qje=s(Sp);w_e=n(Qje,"STRONG",{});var ZSt=s(w_e);tLo=r(ZSt,"levit"),ZSt.forEach(t),aLo=r(Qje," \u2014 "),RV=n(Qje,"A",{href:!0});var KSt=s(RV);nLo=r(KSt,"LevitFeatureExtractor"),KSt.forEach(t),sLo=r(Qje," (LeViT model)"),Qje.forEach(t),lLo=i(Q),Rp=n(Q,"LI",{});var Wje=s(Rp);A_e=n(Wje,"STRONG",{});var eRt=s(A_e);iLo=r(eRt,"maskformer"),eRt.forEach(t),dLo=r(Wje," \u2014 "),PV=n(Wje,"A",{href:!0});var oRt=s(PV);mLo=r(oRt,"MaskFormerFeatureExtractor"),oRt.forEach(t),cLo=r(Wje," (MaskFormer model)"),Wje.forEach(t),fLo=i(Q),Pp=n(Q,"LI",{});var Uje=s(Pp);L_e=n(Uje,"STRONG",{});var rRt=s(L_e);gLo=r(rRt,"mctct"),rRt.forEach(t),hLo=r(Uje," \u2014 "),BV=n(Uje,"A",{href:!0});var tRt=s(BV);uLo=r(tRt,"MCTCTFeatureExtractor"),tRt.forEach(t),pLo=r(Uje," (M-CTC-T model)"),Uje.forEach(t),_Lo=i(Q),Bp=n(Q,"LI",{});var Hje=s(Bp);y_e=n(Hje,"STRONG",{});var aRt=s(y_e);bLo=r(aRt,"mobilevit"),aRt.forEach(t),vLo=r(Hje," \u2014 "),IV=n(Hje,"A",{href:!0});var nRt=s(IV);FLo=r(nRt,"MobileViTFeatureExtractor"),nRt.forEach(t),TLo=r(Hje," (MobileViT model)"),Hje.forEach(t),MLo=i(Q),Ip=n(Q,"LI",{});var Jje=s(Ip);x_e=n(Jje,"STRONG",{});var sRt=s(x_e);ELo=r(sRt,"owlvit"),sRt.forEach(t),CLo=r(Jje," \u2014 "),NV=n(Jje,"A",{href:!0});var lRt=s(NV);wLo=r(lRt,"OwlViTFeatureExtractor"),lRt.forEach(t),ALo=r(Jje," (OWL-ViT model)"),Jje.forEach(t),LLo=i(Q),Np=n(Q,"LI",{});var Yje=s(Np);$_e=n(Yje,"STRONG",{});var iRt=s($_e);yLo=r(iRt,"perceiver"),iRt.forEach(t),xLo=r(Yje," \u2014 "),qV=n(Yje,"A",{href:!0});var dRt=s(qV);$Lo=r(dRt,"PerceiverFeatureExtractor"),dRt.forEach(t),kLo=r(Yje," (Perceiver model)"),Yje.forEach(t),SLo=i(Q),qp=n(Q,"LI",{});var Zje=s(qp);k_e=n(Zje,"STRONG",{});var mRt=s(k_e);RLo=r(mRt,"poolformer"),mRt.forEach(t),PLo=r(Zje," \u2014 "),jV=n(Zje,"A",{href:!0});var cRt=s(jV);BLo=r(cRt,"PoolFormerFeatureExtractor"),cRt.forEach(t),ILo=r(Zje," (PoolFormer model)"),Zje.forEach(t),NLo=i(Q),jp=n(Q,"LI",{});var Kje=s(jp);S_e=n(Kje,"STRONG",{});var fRt=s(S_e);qLo=r(fRt,"regnet"),fRt.forEach(t),jLo=r(Kje," \u2014 "),DV=n(Kje,"A",{href:!0});var gRt=s(DV);DLo=r(gRt,"ConvNextFeatureExtractor"),gRt.forEach(t),GLo=r(Kje," (RegNet model)"),Kje.forEach(t),OLo=i(Q),Dp=n(Q,"LI",{});var eDe=s(Dp);R_e=n(eDe,"STRONG",{});var hRt=s(R_e);VLo=r(hRt,"resnet"),hRt.forEach(t),XLo=r(eDe," \u2014 "),GV=n(eDe,"A",{href:!0});var uRt=s(GV);zLo=r(uRt,"ConvNextFeatureExtractor"),uRt.forEach(t),QLo=r(eDe," (ResNet model)"),eDe.forEach(t),WLo=i(Q),Gp=n(Q,"LI",{});var oDe=s(Gp);P_e=n(oDe,"STRONG",{});var pRt=s(P_e);ULo=r(pRt,"segformer"),pRt.forEach(t),HLo=r(oDe," \u2014 "),OV=n(oDe,"A",{href:!0});var _Rt=s(OV);JLo=r(_Rt,"SegformerFeatureExtractor"),_Rt.forEach(t),YLo=r(oDe," (SegFormer model)"),oDe.forEach(t),ZLo=i(Q),Op=n(Q,"LI",{});var rDe=s(Op);B_e=n(rDe,"STRONG",{});var bRt=s(B_e);KLo=r(bRt,"speech_to_text"),bRt.forEach(t),eyo=r(rDe," \u2014 "),VV=n(rDe,"A",{href:!0});var vRt=s(VV);oyo=r(vRt,"Speech2TextFeatureExtractor"),vRt.forEach(t),ryo=r(rDe," (Speech2Text model)"),rDe.forEach(t),tyo=i(Q),Vp=n(Q,"LI",{});var tDe=s(Vp);I_e=n(tDe,"STRONG",{});var FRt=s(I_e);ayo=r(FRt,"swin"),FRt.forEach(t),nyo=r(tDe," \u2014 "),XV=n(tDe,"A",{href:!0});var TRt=s(XV);syo=r(TRt,"ViTFeatureExtractor"),TRt.forEach(t),lyo=r(tDe," (Swin Transformer model)"),tDe.forEach(t),iyo=i(Q),Xp=n(Q,"LI",{});var aDe=s(Xp);N_e=n(aDe,"STRONG",{});var MRt=s(N_e);dyo=r(MRt,"swinv2"),MRt.forEach(t),myo=r(aDe," \u2014 "),zV=n(aDe,"A",{href:!0});var ERt=s(zV);cyo=r(ERt,"ViTFeatureExtractor"),ERt.forEach(t),fyo=r(aDe," (Swin Transformer V2 model)"),aDe.forEach(t),gyo=i(Q),zp=n(Q,"LI",{});var nDe=s(zp);q_e=n(nDe,"STRONG",{});var CRt=s(q_e);hyo=r(CRt,"table-transformer"),CRt.forEach(t),uyo=r(nDe," \u2014 "),QV=n(nDe,"A",{href:!0});var wRt=s(QV);pyo=r(wRt,"DetrFeatureExtractor"),wRt.forEach(t),_yo=r(nDe," (Table Transformer model)"),nDe.forEach(t),byo=i(Q),Qp=n(Q,"LI",{});var sDe=s(Qp);j_e=n(sDe,"STRONG",{});var ARt=s(j_e);vyo=r(ARt,"van"),ARt.forEach(t),Fyo=r(sDe," \u2014 "),WV=n(sDe,"A",{href:!0});var LRt=s(WV);Tyo=r(LRt,"ConvNextFeatureExtractor"),LRt.forEach(t),Myo=r(sDe," (VAN model)"),sDe.forEach(t),Eyo=i(Q),Wp=n(Q,"LI",{});var lDe=s(Wp);D_e=n(lDe,"STRONG",{});var yRt=s(D_e);Cyo=r(yRt,"videomae"),yRt.forEach(t),wyo=r(lDe," \u2014 "),UV=n(lDe,"A",{href:!0});var xRt=s(UV);Ayo=r(xRt,"VideoMAEFeatureExtractor"),xRt.forEach(t),Lyo=r(lDe," (VideoMAE model)"),lDe.forEach(t),yyo=i(Q),Up=n(Q,"LI",{});var iDe=s(Up);G_e=n(iDe,"STRONG",{});var $Rt=s(G_e);xyo=r($Rt,"vilt"),$Rt.forEach(t),$yo=r(iDe," \u2014 "),HV=n(iDe,"A",{href:!0});var kRt=s(HV);kyo=r(kRt,"ViltFeatureExtractor"),kRt.forEach(t),Syo=r(iDe," (ViLT model)"),iDe.forEach(t),Ryo=i(Q),Hp=n(Q,"LI",{});var dDe=s(Hp);O_e=n(dDe,"STRONG",{});var SRt=s(O_e);Pyo=r(SRt,"vit"),SRt.forEach(t),Byo=r(dDe," \u2014 "),JV=n(dDe,"A",{href:!0});var RRt=s(JV);Iyo=r(RRt,"ViTFeatureExtractor"),RRt.forEach(t),Nyo=r(dDe," (ViT model)"),dDe.forEach(t),qyo=i(Q),Jp=n(Q,"LI",{});var mDe=s(Jp);V_e=n(mDe,"STRONG",{});var PRt=s(V_e);jyo=r(PRt,"vit_mae"),PRt.forEach(t),Dyo=r(mDe," \u2014 "),YV=n(mDe,"A",{href:!0});var BRt=s(YV);Gyo=r(BRt,"ViTFeatureExtractor"),BRt.forEach(t),Oyo=r(mDe," (ViTMAE model)"),mDe.forEach(t),Vyo=i(Q),Yp=n(Q,"LI",{});var cDe=s(Yp);X_e=n(cDe,"STRONG",{});var IRt=s(X_e);Xyo=r(IRt,"vit_msn"),IRt.forEach(t),zyo=r(cDe," \u2014 "),ZV=n(cDe,"A",{href:!0});var NRt=s(ZV);Qyo=r(NRt,"ViTFeatureExtractor"),NRt.forEach(t),Wyo=r(cDe," (ViTMSN model)"),cDe.forEach(t),Uyo=i(Q),Zp=n(Q,"LI",{});var fDe=s(Zp);z_e=n(fDe,"STRONG",{});var qRt=s(z_e);Hyo=r(qRt,"wav2vec2"),qRt.forEach(t),Jyo=r(fDe," \u2014 "),KV=n(fDe,"A",{href:!0});var jRt=s(KV);Yyo=r(jRt,"Wav2Vec2FeatureExtractor"),jRt.forEach(t),Zyo=r(fDe," (Wav2Vec2 model)"),fDe.forEach(t),Kyo=i(Q),Kp=n(Q,"LI",{});var gDe=s(Kp);Q_e=n(gDe,"STRONG",{});var DRt=s(Q_e);e9o=r(DRt,"wav2vec2-conformer"),DRt.forEach(t),o9o=r(gDe," \u2014 "),eX=n(gDe,"A",{href:!0});var GRt=s(eX);r9o=r(GRt,"Wav2Vec2FeatureExtractor"),GRt.forEach(t),t9o=r(gDe," (Wav2Vec2-Conformer model)"),gDe.forEach(t),a9o=i(Q),e_=n(Q,"LI",{});var hDe=s(e_);W_e=n(hDe,"STRONG",{});var ORt=s(W_e);n9o=r(ORt,"whisper"),ORt.forEach(t),s9o=r(hDe," \u2014 "),oX=n(hDe,"A",{href:!0});var VRt=s(oX);l9o=r(VRt,"WhisperFeatureExtractor"),VRt.forEach(t),i9o=r(hDe," (Whisper model)"),hDe.forEach(t),d9o=i(Q),o_=n(Q,"LI",{});var uDe=s(o_);U_e=n(uDe,"STRONG",{});var XRt=s(U_e);m9o=r(XRt,"xclip"),XRt.forEach(t),c9o=r(uDe," \u2014 "),rX=n(uDe,"A",{href:!0});var zRt=s(rX);f9o=r(zRt,"CLIPFeatureExtractor"),zRt.forEach(t),g9o=r(uDe," (X-CLIP model)"),uDe.forEach(t),h9o=i(Q),r_=n(Q,"LI",{});var pDe=s(r_);H_e=n(pDe,"STRONG",{});var QRt=s(H_e);u9o=r(QRt,"yolos"),QRt.forEach(t),p9o=r(pDe," \u2014 "),tX=n(pDe,"A",{href:!0});var WRt=s(tX);_9o=r(WRt,"YolosFeatureExtractor"),WRt.forEach(t),b9o=r(pDe," (YOLOS model)"),pDe.forEach(t),Q.forEach(t),v9o=i(wa),T(t_.$$.fragment,wa),F9o=i(wa),T(a_.$$.fragment,wa),wa.forEach(t),T9o=i(Il),n_=n(Il,"DIV",{class:!0});var Yno=s(n_);T(y$.$$.fragment,Yno),M9o=i(Yno),J_e=n(Yno,"P",{});var URt=s(J_e);E9o=r(URt,"Register a new feature extractor for this class."),URt.forEach(t),Yno.forEach(t),Il.forEach(t),Ito=i(c),$d=n(c,"H2",{class:!0});var Zno=s($d);s_=n(Zno,"A",{id:!0,class:!0,href:!0});var HRt=s(s_);Y_e=n(HRt,"SPAN",{});var JRt=s(Y_e);T(x$.$$.fragment,JRt),JRt.forEach(t),HRt.forEach(t),C9o=i(Zno),Z_e=n(Zno,"SPAN",{});var YRt=s(Z_e);w9o=r(YRt,"AutoProcessor"),YRt.forEach(t),Zno.forEach(t),Nto=i(c),Bo=n(c,"DIV",{class:!0});var Nl=s(Bo);T($$.$$.fragment,Nl),A9o=i(Nl),k$=n(Nl,"P",{});var Kno=s(k$);L9o=r(Kno,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),aX=n(Kno,"A",{href:!0});var ZRt=s(aX);y9o=r(ZRt,"AutoProcessor.from_pretrained()"),ZRt.forEach(t),x9o=r(Kno," class method."),Kno.forEach(t),$9o=i(Nl),S$=n(Nl,"P",{});var eso=s(S$);k9o=r(eso,"This class cannot be instantiated directly using "),K_e=n(eso,"CODE",{});var KRt=s(K_e);S9o=r(KRt,"__init__()"),KRt.forEach(t),R9o=r(eso," (throws an error)."),eso.forEach(t),P9o=i(Nl),Ze=n(Nl,"DIV",{class:!0});var Aa=s(Ze);T(R$.$$.fragment,Aa),B9o=i(Aa),e1e=n(Aa,"P",{});var ePt=s(e1e);I9o=r(ePt,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),ePt.forEach(t),N9o=i(Aa),kd=n(Aa,"P",{});var tme=s(kd);q9o=r(tme,"The processor class to instantiate is selected based on the "),o1e=n(tme,"CODE",{});var oPt=s(o1e);j9o=r(oPt,"model_type"),oPt.forEach(t),D9o=r(tme,` property of the config object (either
passed as an argument or loaded from `),r1e=n(tme,"CODE",{});var rPt=s(r1e);G9o=r(rPt,"pretrained_model_name_or_path"),rPt.forEach(t),O9o=r(tme," if possible):"),tme.forEach(t),V9o=i(Aa),le=n(Aa,"UL",{});var fe=s(le);l_=n(fe,"LI",{});var _De=s(l_);t1e=n(_De,"STRONG",{});var tPt=s(t1e);X9o=r(tPt,"clip"),tPt.forEach(t),z9o=r(_De," \u2014 "),nX=n(_De,"A",{href:!0});var aPt=s(nX);Q9o=r(aPt,"CLIPProcessor"),aPt.forEach(t),W9o=r(_De," (CLIP model)"),_De.forEach(t),U9o=i(fe),i_=n(fe,"LI",{});var bDe=s(i_);a1e=n(bDe,"STRONG",{});var nPt=s(a1e);H9o=r(nPt,"flava"),nPt.forEach(t),J9o=r(bDe," \u2014 "),sX=n(bDe,"A",{href:!0});var sPt=s(sX);Y9o=r(sPt,"FlavaProcessor"),sPt.forEach(t),Z9o=r(bDe," (FLAVA model)"),bDe.forEach(t),K9o=i(fe),d_=n(fe,"LI",{});var vDe=s(d_);n1e=n(vDe,"STRONG",{});var lPt=s(n1e);exo=r(lPt,"groupvit"),lPt.forEach(t),oxo=r(vDe," \u2014 "),lX=n(vDe,"A",{href:!0});var iPt=s(lX);rxo=r(iPt,"CLIPProcessor"),iPt.forEach(t),txo=r(vDe," (GroupViT model)"),vDe.forEach(t),axo=i(fe),m_=n(fe,"LI",{});var FDe=s(m_);s1e=n(FDe,"STRONG",{});var dPt=s(s1e);nxo=r(dPt,"layoutlmv2"),dPt.forEach(t),sxo=r(FDe," \u2014 "),iX=n(FDe,"A",{href:!0});var mPt=s(iX);lxo=r(mPt,"LayoutLMv2Processor"),mPt.forEach(t),ixo=r(FDe," (LayoutLMv2 model)"),FDe.forEach(t),dxo=i(fe),c_=n(fe,"LI",{});var TDe=s(c_);l1e=n(TDe,"STRONG",{});var cPt=s(l1e);mxo=r(cPt,"layoutlmv3"),cPt.forEach(t),cxo=r(TDe," \u2014 "),dX=n(TDe,"A",{href:!0});var fPt=s(dX);fxo=r(fPt,"LayoutLMv3Processor"),fPt.forEach(t),gxo=r(TDe," (LayoutLMv3 model)"),TDe.forEach(t),hxo=i(fe),f_=n(fe,"LI",{});var MDe=s(f_);i1e=n(MDe,"STRONG",{});var gPt=s(i1e);uxo=r(gPt,"layoutxlm"),gPt.forEach(t),pxo=r(MDe," \u2014 "),mX=n(MDe,"A",{href:!0});var hPt=s(mX);_xo=r(hPt,"LayoutXLMProcessor"),hPt.forEach(t),bxo=r(MDe," (LayoutXLM model)"),MDe.forEach(t),vxo=i(fe),g_=n(fe,"LI",{});var EDe=s(g_);d1e=n(EDe,"STRONG",{});var uPt=s(d1e);Fxo=r(uPt,"markuplm"),uPt.forEach(t),Txo=r(EDe," \u2014 "),cX=n(EDe,"A",{href:!0});var pPt=s(cX);Mxo=r(pPt,"MarkupLMProcessor"),pPt.forEach(t),Exo=r(EDe," (MarkupLM model)"),EDe.forEach(t),Cxo=i(fe),h_=n(fe,"LI",{});var CDe=s(h_);m1e=n(CDe,"STRONG",{});var _Pt=s(m1e);wxo=r(_Pt,"owlvit"),_Pt.forEach(t),Axo=r(CDe," \u2014 "),fX=n(CDe,"A",{href:!0});var bPt=s(fX);Lxo=r(bPt,"OwlViTProcessor"),bPt.forEach(t),yxo=r(CDe," (OWL-ViT model)"),CDe.forEach(t),xxo=i(fe),u_=n(fe,"LI",{});var wDe=s(u_);c1e=n(wDe,"STRONG",{});var vPt=s(c1e);$xo=r(vPt,"sew"),vPt.forEach(t),kxo=r(wDe," \u2014 "),gX=n(wDe,"A",{href:!0});var FPt=s(gX);Sxo=r(FPt,"Wav2Vec2Processor"),FPt.forEach(t),Rxo=r(wDe," (SEW model)"),wDe.forEach(t),Pxo=i(fe),p_=n(fe,"LI",{});var ADe=s(p_);f1e=n(ADe,"STRONG",{});var TPt=s(f1e);Bxo=r(TPt,"sew-d"),TPt.forEach(t),Ixo=r(ADe," \u2014 "),hX=n(ADe,"A",{href:!0});var MPt=s(hX);Nxo=r(MPt,"Wav2Vec2Processor"),MPt.forEach(t),qxo=r(ADe," (SEW-D model)"),ADe.forEach(t),jxo=i(fe),__=n(fe,"LI",{});var LDe=s(__);g1e=n(LDe,"STRONG",{});var EPt=s(g1e);Dxo=r(EPt,"speech_to_text"),EPt.forEach(t),Gxo=r(LDe," \u2014 "),uX=n(LDe,"A",{href:!0});var CPt=s(uX);Oxo=r(CPt,"Speech2TextProcessor"),CPt.forEach(t),Vxo=r(LDe," (Speech2Text model)"),LDe.forEach(t),Xxo=i(fe),b_=n(fe,"LI",{});var yDe=s(b_);h1e=n(yDe,"STRONG",{});var wPt=s(h1e);zxo=r(wPt,"speech_to_text_2"),wPt.forEach(t),Qxo=r(yDe," \u2014 "),pX=n(yDe,"A",{href:!0});var APt=s(pX);Wxo=r(APt,"Speech2Text2Processor"),APt.forEach(t),Uxo=r(yDe," (Speech2Text2 model)"),yDe.forEach(t),Hxo=i(fe),v_=n(fe,"LI",{});var xDe=s(v_);u1e=n(xDe,"STRONG",{});var LPt=s(u1e);Jxo=r(LPt,"trocr"),LPt.forEach(t),Yxo=r(xDe," \u2014 "),_X=n(xDe,"A",{href:!0});var yPt=s(_X);Zxo=r(yPt,"TrOCRProcessor"),yPt.forEach(t),Kxo=r(xDe," (TrOCR model)"),xDe.forEach(t),e$o=i(fe),F_=n(fe,"LI",{});var $De=s(F_);p1e=n($De,"STRONG",{});var xPt=s(p1e);o$o=r(xPt,"unispeech"),xPt.forEach(t),r$o=r($De," \u2014 "),bX=n($De,"A",{href:!0});var $Pt=s(bX);t$o=r($Pt,"Wav2Vec2Processor"),$Pt.forEach(t),a$o=r($De," (UniSpeech model)"),$De.forEach(t),n$o=i(fe),T_=n(fe,"LI",{});var kDe=s(T_);_1e=n(kDe,"STRONG",{});var kPt=s(_1e);s$o=r(kPt,"unispeech-sat"),kPt.forEach(t),l$o=r(kDe," \u2014 "),vX=n(kDe,"A",{href:!0});var SPt=s(vX);i$o=r(SPt,"Wav2Vec2Processor"),SPt.forEach(t),d$o=r(kDe," (UniSpeechSat model)"),kDe.forEach(t),m$o=i(fe),M_=n(fe,"LI",{});var SDe=s(M_);b1e=n(SDe,"STRONG",{});var RPt=s(b1e);c$o=r(RPt,"vilt"),RPt.forEach(t),f$o=r(SDe," \u2014 "),FX=n(SDe,"A",{href:!0});var PPt=s(FX);g$o=r(PPt,"ViltProcessor"),PPt.forEach(t),h$o=r(SDe," (ViLT model)"),SDe.forEach(t),u$o=i(fe),E_=n(fe,"LI",{});var RDe=s(E_);v1e=n(RDe,"STRONG",{});var BPt=s(v1e);p$o=r(BPt,"vision-text-dual-encoder"),BPt.forEach(t),_$o=r(RDe," \u2014 "),TX=n(RDe,"A",{href:!0});var IPt=s(TX);b$o=r(IPt,"VisionTextDualEncoderProcessor"),IPt.forEach(t),v$o=r(RDe," (VisionTextDualEncoder model)"),RDe.forEach(t),F$o=i(fe),C_=n(fe,"LI",{});var PDe=s(C_);F1e=n(PDe,"STRONG",{});var NPt=s(F1e);T$o=r(NPt,"wav2vec2"),NPt.forEach(t),M$o=r(PDe," \u2014 "),MX=n(PDe,"A",{href:!0});var qPt=s(MX);E$o=r(qPt,"Wav2Vec2Processor"),qPt.forEach(t),C$o=r(PDe," (Wav2Vec2 model)"),PDe.forEach(t),w$o=i(fe),w_=n(fe,"LI",{});var BDe=s(w_);T1e=n(BDe,"STRONG",{});var jPt=s(T1e);A$o=r(jPt,"wav2vec2-conformer"),jPt.forEach(t),L$o=r(BDe," \u2014 "),EX=n(BDe,"A",{href:!0});var DPt=s(EX);y$o=r(DPt,"Wav2Vec2Processor"),DPt.forEach(t),x$o=r(BDe," (Wav2Vec2-Conformer model)"),BDe.forEach(t),$$o=i(fe),A_=n(fe,"LI",{});var IDe=s(A_);M1e=n(IDe,"STRONG",{});var GPt=s(M1e);k$o=r(GPt,"wavlm"),GPt.forEach(t),S$o=r(IDe," \u2014 "),CX=n(IDe,"A",{href:!0});var OPt=s(CX);R$o=r(OPt,"Wav2Vec2Processor"),OPt.forEach(t),P$o=r(IDe," (WavLM model)"),IDe.forEach(t),B$o=i(fe),L_=n(fe,"LI",{});var NDe=s(L_);E1e=n(NDe,"STRONG",{});var VPt=s(E1e);I$o=r(VPt,"whisper"),VPt.forEach(t),N$o=r(NDe," \u2014 "),wX=n(NDe,"A",{href:!0});var XPt=s(wX);q$o=r(XPt,"WhisperProcessor"),XPt.forEach(t),j$o=r(NDe," (Whisper model)"),NDe.forEach(t),D$o=i(fe),y_=n(fe,"LI",{});var qDe=s(y_);C1e=n(qDe,"STRONG",{});var zPt=s(C1e);G$o=r(zPt,"xclip"),zPt.forEach(t),O$o=r(qDe," \u2014 "),AX=n(qDe,"A",{href:!0});var QPt=s(AX);V$o=r(QPt,"XCLIPProcessor"),QPt.forEach(t),X$o=r(qDe," (X-CLIP model)"),qDe.forEach(t),fe.forEach(t),z$o=i(Aa),T(x_.$$.fragment,Aa),Q$o=i(Aa),T($_.$$.fragment,Aa),Aa.forEach(t),W$o=i(Nl),k_=n(Nl,"DIV",{class:!0});var oso=s(k_);T(P$.$$.fragment,oso),U$o=i(oso),w1e=n(oso,"P",{});var WPt=s(w1e);H$o=r(WPt,"Register a new processor for this class."),WPt.forEach(t),oso.forEach(t),Nl.forEach(t),qto=i(c),Sd=n(c,"H2",{class:!0});var rso=s(Sd);S_=n(rso,"A",{id:!0,class:!0,href:!0});var UPt=s(S_);A1e=n(UPt,"SPAN",{});var HPt=s(A1e);T(B$.$$.fragment,HPt),HPt.forEach(t),UPt.forEach(t),J$o=i(rso),L1e=n(rso,"SPAN",{});var JPt=s(L1e);Y$o=r(JPt,"AutoModel"),JPt.forEach(t),rso.forEach(t),jto=i(c),Io=n(c,"DIV",{class:!0});var ql=s(Io);T(I$.$$.fragment,ql),Z$o=i(ql),Rd=n(ql,"P",{});var ame=s(Rd);K$o=r(ame,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),LX=n(ame,"A",{href:!0});var YPt=s(LX);eko=r(YPt,"from_pretrained()"),YPt.forEach(t),oko=r(ame," class method or the "),yX=n(ame,"A",{href:!0});var ZPt=s(yX);rko=r(ZPt,"from_config()"),ZPt.forEach(t),tko=r(ame,` class
method.`),ame.forEach(t),ako=i(ql),N$=n(ql,"P",{});var tso=s(N$);nko=r(tso,"This class cannot be instantiated directly using "),y1e=n(tso,"CODE",{});var KPt=s(y1e);sko=r(KPt,"__init__()"),KPt.forEach(t),lko=r(tso," (throws an error)."),tso.forEach(t),iko=i(ql),Mt=n(ql,"DIV",{class:!0});var e9=s(Mt);T(q$.$$.fragment,e9),dko=i(e9),x1e=n(e9,"P",{});var eBt=s(x1e);mko=r(eBt,"Instantiates one of the base model classes of the library from a configuration."),eBt.forEach(t),cko=i(e9),Pd=n(e9,"P",{});var nme=s(Pd);fko=r(nme,`Note:
Loading a model from its configuration file does `),$1e=n(nme,"STRONG",{});var oBt=s($1e);gko=r(oBt,"not"),oBt.forEach(t),hko=r(nme,` load the model weights. It only affects the
model\u2019s configuration. Use `),xX=n(nme,"A",{href:!0});var rBt=s(xX);uko=r(rBt,"from_pretrained()"),rBt.forEach(t),pko=r(nme," to load the model weights."),nme.forEach(t),_ko=i(e9),T(R_.$$.fragment,e9),e9.forEach(t),bko=i(ql),Ke=n(ql,"DIV",{class:!0});var La=s(Ke);T(j$.$$.fragment,La),vko=i(La),k1e=n(La,"P",{});var tBt=s(k1e);Fko=r(tBt,"Instantiate one of the base model classes of the library from a pretrained model."),tBt.forEach(t),Tko=i(La),nn=n(La,"P",{});var o9=s(nn);Mko=r(o9,"The model class to instantiate is selected based on the "),S1e=n(o9,"CODE",{});var aBt=s(S1e);Eko=r(aBt,"model_type"),aBt.forEach(t),Cko=r(o9,` property of the config object (either
passed as an argument or loaded from `),R1e=n(o9,"CODE",{});var nBt=s(R1e);wko=r(nBt,"pretrained_model_name_or_path"),nBt.forEach(t),Ako=r(o9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P1e=n(o9,"CODE",{});var sBt=s(P1e);Lko=r(sBt,"pretrained_model_name_or_path"),sBt.forEach(t),yko=r(o9,":"),o9.forEach(t),xko=i(La),y=n(La,"UL",{});var x=s(y);P_=n(x,"LI",{});var jDe=s(P_);B1e=n(jDe,"STRONG",{});var lBt=s(B1e);$ko=r(lBt,"albert"),lBt.forEach(t),kko=r(jDe," \u2014 "),$X=n(jDe,"A",{href:!0});var iBt=s($X);Sko=r(iBt,"AlbertModel"),iBt.forEach(t),Rko=r(jDe," (ALBERT model)"),jDe.forEach(t),Pko=i(x),B_=n(x,"LI",{});var DDe=s(B_);I1e=n(DDe,"STRONG",{});var dBt=s(I1e);Bko=r(dBt,"bart"),dBt.forEach(t),Iko=r(DDe," \u2014 "),kX=n(DDe,"A",{href:!0});var mBt=s(kX);Nko=r(mBt,"BartModel"),mBt.forEach(t),qko=r(DDe," (BART model)"),DDe.forEach(t),jko=i(x),I_=n(x,"LI",{});var GDe=s(I_);N1e=n(GDe,"STRONG",{});var cBt=s(N1e);Dko=r(cBt,"beit"),cBt.forEach(t),Gko=r(GDe," \u2014 "),SX=n(GDe,"A",{href:!0});var fBt=s(SX);Oko=r(fBt,"BeitModel"),fBt.forEach(t),Vko=r(GDe," (BEiT model)"),GDe.forEach(t),Xko=i(x),N_=n(x,"LI",{});var ODe=s(N_);q1e=n(ODe,"STRONG",{});var gBt=s(q1e);zko=r(gBt,"bert"),gBt.forEach(t),Qko=r(ODe," \u2014 "),RX=n(ODe,"A",{href:!0});var hBt=s(RX);Wko=r(hBt,"BertModel"),hBt.forEach(t),Uko=r(ODe," (BERT model)"),ODe.forEach(t),Hko=i(x),q_=n(x,"LI",{});var VDe=s(q_);j1e=n(VDe,"STRONG",{});var uBt=s(j1e);Jko=r(uBt,"bert-generation"),uBt.forEach(t),Yko=r(VDe," \u2014 "),PX=n(VDe,"A",{href:!0});var pBt=s(PX);Zko=r(pBt,"BertGenerationEncoder"),pBt.forEach(t),Kko=r(VDe," (Bert Generation model)"),VDe.forEach(t),eSo=i(x),j_=n(x,"LI",{});var XDe=s(j_);D1e=n(XDe,"STRONG",{});var _Bt=s(D1e);oSo=r(_Bt,"big_bird"),_Bt.forEach(t),rSo=r(XDe," \u2014 "),BX=n(XDe,"A",{href:!0});var bBt=s(BX);tSo=r(bBt,"BigBirdModel"),bBt.forEach(t),aSo=r(XDe," (BigBird model)"),XDe.forEach(t),nSo=i(x),D_=n(x,"LI",{});var zDe=s(D_);G1e=n(zDe,"STRONG",{});var vBt=s(G1e);sSo=r(vBt,"bigbird_pegasus"),vBt.forEach(t),lSo=r(zDe," \u2014 "),IX=n(zDe,"A",{href:!0});var FBt=s(IX);iSo=r(FBt,"BigBirdPegasusModel"),FBt.forEach(t),dSo=r(zDe," (BigBird-Pegasus model)"),zDe.forEach(t),mSo=i(x),G_=n(x,"LI",{});var QDe=s(G_);O1e=n(QDe,"STRONG",{});var TBt=s(O1e);cSo=r(TBt,"blenderbot"),TBt.forEach(t),fSo=r(QDe," \u2014 "),NX=n(QDe,"A",{href:!0});var MBt=s(NX);gSo=r(MBt,"BlenderbotModel"),MBt.forEach(t),hSo=r(QDe," (Blenderbot model)"),QDe.forEach(t),uSo=i(x),O_=n(x,"LI",{});var WDe=s(O_);V1e=n(WDe,"STRONG",{});var EBt=s(V1e);pSo=r(EBt,"blenderbot-small"),EBt.forEach(t),_So=r(WDe," \u2014 "),qX=n(WDe,"A",{href:!0});var CBt=s(qX);bSo=r(CBt,"BlenderbotSmallModel"),CBt.forEach(t),vSo=r(WDe," (BlenderbotSmall model)"),WDe.forEach(t),FSo=i(x),V_=n(x,"LI",{});var UDe=s(V_);X1e=n(UDe,"STRONG",{});var wBt=s(X1e);TSo=r(wBt,"bloom"),wBt.forEach(t),MSo=r(UDe," \u2014 "),jX=n(UDe,"A",{href:!0});var ABt=s(jX);ESo=r(ABt,"BloomModel"),ABt.forEach(t),CSo=r(UDe," (BLOOM model)"),UDe.forEach(t),wSo=i(x),X_=n(x,"LI",{});var HDe=s(X_);z1e=n(HDe,"STRONG",{});var LBt=s(z1e);ASo=r(LBt,"camembert"),LBt.forEach(t),LSo=r(HDe," \u2014 "),DX=n(HDe,"A",{href:!0});var yBt=s(DX);ySo=r(yBt,"CamembertModel"),yBt.forEach(t),xSo=r(HDe," (CamemBERT model)"),HDe.forEach(t),$So=i(x),z_=n(x,"LI",{});var JDe=s(z_);Q1e=n(JDe,"STRONG",{});var xBt=s(Q1e);kSo=r(xBt,"canine"),xBt.forEach(t),SSo=r(JDe," \u2014 "),GX=n(JDe,"A",{href:!0});var $Bt=s(GX);RSo=r($Bt,"CanineModel"),$Bt.forEach(t),PSo=r(JDe," (CANINE model)"),JDe.forEach(t),BSo=i(x),Q_=n(x,"LI",{});var YDe=s(Q_);W1e=n(YDe,"STRONG",{});var kBt=s(W1e);ISo=r(kBt,"clip"),kBt.forEach(t),NSo=r(YDe," \u2014 "),OX=n(YDe,"A",{href:!0});var SBt=s(OX);qSo=r(SBt,"CLIPModel"),SBt.forEach(t),jSo=r(YDe," (CLIP model)"),YDe.forEach(t),DSo=i(x),W_=n(x,"LI",{});var ZDe=s(W_);U1e=n(ZDe,"STRONG",{});var RBt=s(U1e);GSo=r(RBt,"codegen"),RBt.forEach(t),OSo=r(ZDe," \u2014 "),VX=n(ZDe,"A",{href:!0});var PBt=s(VX);VSo=r(PBt,"CodeGenModel"),PBt.forEach(t),XSo=r(ZDe," (CodeGen model)"),ZDe.forEach(t),zSo=i(x),U_=n(x,"LI",{});var KDe=s(U_);H1e=n(KDe,"STRONG",{});var BBt=s(H1e);QSo=r(BBt,"conditional_detr"),BBt.forEach(t),WSo=r(KDe," \u2014 "),XX=n(KDe,"A",{href:!0});var IBt=s(XX);USo=r(IBt,"ConditionalDetrModel"),IBt.forEach(t),HSo=r(KDe," (Conditional DETR model)"),KDe.forEach(t),JSo=i(x),H_=n(x,"LI",{});var eGe=s(H_);J1e=n(eGe,"STRONG",{});var NBt=s(J1e);YSo=r(NBt,"convbert"),NBt.forEach(t),ZSo=r(eGe," \u2014 "),zX=n(eGe,"A",{href:!0});var qBt=s(zX);KSo=r(qBt,"ConvBertModel"),qBt.forEach(t),eRo=r(eGe," (ConvBERT model)"),eGe.forEach(t),oRo=i(x),J_=n(x,"LI",{});var oGe=s(J_);Y1e=n(oGe,"STRONG",{});var jBt=s(Y1e);rRo=r(jBt,"convnext"),jBt.forEach(t),tRo=r(oGe," \u2014 "),QX=n(oGe,"A",{href:!0});var DBt=s(QX);aRo=r(DBt,"ConvNextModel"),DBt.forEach(t),nRo=r(oGe," (ConvNeXT model)"),oGe.forEach(t),sRo=i(x),Y_=n(x,"LI",{});var rGe=s(Y_);Z1e=n(rGe,"STRONG",{});var GBt=s(Z1e);lRo=r(GBt,"ctrl"),GBt.forEach(t),iRo=r(rGe," \u2014 "),WX=n(rGe,"A",{href:!0});var OBt=s(WX);dRo=r(OBt,"CTRLModel"),OBt.forEach(t),mRo=r(rGe," (CTRL model)"),rGe.forEach(t),cRo=i(x),Z_=n(x,"LI",{});var tGe=s(Z_);K1e=n(tGe,"STRONG",{});var VBt=s(K1e);fRo=r(VBt,"cvt"),VBt.forEach(t),gRo=r(tGe," \u2014 "),UX=n(tGe,"A",{href:!0});var XBt=s(UX);hRo=r(XBt,"CvtModel"),XBt.forEach(t),uRo=r(tGe," (CvT model)"),tGe.forEach(t),pRo=i(x),K_=n(x,"LI",{});var aGe=s(K_);e2e=n(aGe,"STRONG",{});var zBt=s(e2e);_Ro=r(zBt,"data2vec-audio"),zBt.forEach(t),bRo=r(aGe," \u2014 "),HX=n(aGe,"A",{href:!0});var QBt=s(HX);vRo=r(QBt,"Data2VecAudioModel"),QBt.forEach(t),FRo=r(aGe," (Data2VecAudio model)"),aGe.forEach(t),TRo=i(x),e1=n(x,"LI",{});var nGe=s(e1);o2e=n(nGe,"STRONG",{});var WBt=s(o2e);MRo=r(WBt,"data2vec-text"),WBt.forEach(t),ERo=r(nGe," \u2014 "),JX=n(nGe,"A",{href:!0});var UBt=s(JX);CRo=r(UBt,"Data2VecTextModel"),UBt.forEach(t),wRo=r(nGe," (Data2VecText model)"),nGe.forEach(t),ARo=i(x),o1=n(x,"LI",{});var sGe=s(o1);r2e=n(sGe,"STRONG",{});var HBt=s(r2e);LRo=r(HBt,"data2vec-vision"),HBt.forEach(t),yRo=r(sGe," \u2014 "),YX=n(sGe,"A",{href:!0});var JBt=s(YX);xRo=r(JBt,"Data2VecVisionModel"),JBt.forEach(t),$Ro=r(sGe," (Data2VecVision model)"),sGe.forEach(t),kRo=i(x),r1=n(x,"LI",{});var lGe=s(r1);t2e=n(lGe,"STRONG",{});var YBt=s(t2e);SRo=r(YBt,"deberta"),YBt.forEach(t),RRo=r(lGe," \u2014 "),ZX=n(lGe,"A",{href:!0});var ZBt=s(ZX);PRo=r(ZBt,"DebertaModel"),ZBt.forEach(t),BRo=r(lGe," (DeBERTa model)"),lGe.forEach(t),IRo=i(x),t1=n(x,"LI",{});var iGe=s(t1);a2e=n(iGe,"STRONG",{});var KBt=s(a2e);NRo=r(KBt,"deberta-v2"),KBt.forEach(t),qRo=r(iGe," \u2014 "),KX=n(iGe,"A",{href:!0});var eIt=s(KX);jRo=r(eIt,"DebertaV2Model"),eIt.forEach(t),DRo=r(iGe," (DeBERTa-v2 model)"),iGe.forEach(t),GRo=i(x),a1=n(x,"LI",{});var dGe=s(a1);n2e=n(dGe,"STRONG",{});var oIt=s(n2e);ORo=r(oIt,"decision_transformer"),oIt.forEach(t),VRo=r(dGe," \u2014 "),ez=n(dGe,"A",{href:!0});var rIt=s(ez);XRo=r(rIt,"DecisionTransformerModel"),rIt.forEach(t),zRo=r(dGe," (Decision Transformer model)"),dGe.forEach(t),QRo=i(x),n1=n(x,"LI",{});var mGe=s(n1);s2e=n(mGe,"STRONG",{});var tIt=s(s2e);WRo=r(tIt,"deformable_detr"),tIt.forEach(t),URo=r(mGe," \u2014 "),oz=n(mGe,"A",{href:!0});var aIt=s(oz);HRo=r(aIt,"DeformableDetrModel"),aIt.forEach(t),JRo=r(mGe," (Deformable DETR model)"),mGe.forEach(t),YRo=i(x),s1=n(x,"LI",{});var cGe=s(s1);l2e=n(cGe,"STRONG",{});var nIt=s(l2e);ZRo=r(nIt,"deit"),nIt.forEach(t),KRo=r(cGe," \u2014 "),rz=n(cGe,"A",{href:!0});var sIt=s(rz);ePo=r(sIt,"DeiTModel"),sIt.forEach(t),oPo=r(cGe," (DeiT model)"),cGe.forEach(t),rPo=i(x),l1=n(x,"LI",{});var fGe=s(l1);i2e=n(fGe,"STRONG",{});var lIt=s(i2e);tPo=r(lIt,"detr"),lIt.forEach(t),aPo=r(fGe," \u2014 "),tz=n(fGe,"A",{href:!0});var iIt=s(tz);nPo=r(iIt,"DetrModel"),iIt.forEach(t),sPo=r(fGe," (DETR model)"),fGe.forEach(t),lPo=i(x),i1=n(x,"LI",{});var gGe=s(i1);d2e=n(gGe,"STRONG",{});var dIt=s(d2e);iPo=r(dIt,"distilbert"),dIt.forEach(t),dPo=r(gGe," \u2014 "),az=n(gGe,"A",{href:!0});var mIt=s(az);mPo=r(mIt,"DistilBertModel"),mIt.forEach(t),cPo=r(gGe," (DistilBERT model)"),gGe.forEach(t),fPo=i(x),d1=n(x,"LI",{});var hGe=s(d1);m2e=n(hGe,"STRONG",{});var cIt=s(m2e);gPo=r(cIt,"donut-swin"),cIt.forEach(t),hPo=r(hGe," \u2014 "),nz=n(hGe,"A",{href:!0});var fIt=s(nz);uPo=r(fIt,"DonutSwinModel"),fIt.forEach(t),pPo=r(hGe," (DonutSwin model)"),hGe.forEach(t),_Po=i(x),m1=n(x,"LI",{});var uGe=s(m1);c2e=n(uGe,"STRONG",{});var gIt=s(c2e);bPo=r(gIt,"dpr"),gIt.forEach(t),vPo=r(uGe," \u2014 "),sz=n(uGe,"A",{href:!0});var hIt=s(sz);FPo=r(hIt,"DPRQuestionEncoder"),hIt.forEach(t),TPo=r(uGe," (DPR model)"),uGe.forEach(t),MPo=i(x),c1=n(x,"LI",{});var pGe=s(c1);f2e=n(pGe,"STRONG",{});var uIt=s(f2e);EPo=r(uIt,"dpt"),uIt.forEach(t),CPo=r(pGe," \u2014 "),lz=n(pGe,"A",{href:!0});var pIt=s(lz);wPo=r(pIt,"DPTModel"),pIt.forEach(t),APo=r(pGe," (DPT model)"),pGe.forEach(t),LPo=i(x),f1=n(x,"LI",{});var _Ge=s(f1);g2e=n(_Ge,"STRONG",{});var _It=s(g2e);yPo=r(_It,"electra"),_It.forEach(t),xPo=r(_Ge," \u2014 "),iz=n(_Ge,"A",{href:!0});var bIt=s(iz);$Po=r(bIt,"ElectraModel"),bIt.forEach(t),kPo=r(_Ge," (ELECTRA model)"),_Ge.forEach(t),SPo=i(x),g1=n(x,"LI",{});var bGe=s(g1);h2e=n(bGe,"STRONG",{});var vIt=s(h2e);RPo=r(vIt,"ernie"),vIt.forEach(t),PPo=r(bGe," \u2014 "),dz=n(bGe,"A",{href:!0});var FIt=s(dz);BPo=r(FIt,"ErnieModel"),FIt.forEach(t),IPo=r(bGe," (ERNIE model)"),bGe.forEach(t),NPo=i(x),h1=n(x,"LI",{});var vGe=s(h1);u2e=n(vGe,"STRONG",{});var TIt=s(u2e);qPo=r(TIt,"esm"),TIt.forEach(t),jPo=r(vGe," \u2014 "),mz=n(vGe,"A",{href:!0});var MIt=s(mz);DPo=r(MIt,"EsmModel"),MIt.forEach(t),GPo=r(vGe," (ESM model)"),vGe.forEach(t),OPo=i(x),u1=n(x,"LI",{});var FGe=s(u1);p2e=n(FGe,"STRONG",{});var EIt=s(p2e);VPo=r(EIt,"flaubert"),EIt.forEach(t),XPo=r(FGe," \u2014 "),cz=n(FGe,"A",{href:!0});var CIt=s(cz);zPo=r(CIt,"FlaubertModel"),CIt.forEach(t),QPo=r(FGe," (FlauBERT model)"),FGe.forEach(t),WPo=i(x),p1=n(x,"LI",{});var TGe=s(p1);_2e=n(TGe,"STRONG",{});var wIt=s(_2e);UPo=r(wIt,"flava"),wIt.forEach(t),HPo=r(TGe," \u2014 "),fz=n(TGe,"A",{href:!0});var AIt=s(fz);JPo=r(AIt,"FlavaModel"),AIt.forEach(t),YPo=r(TGe," (FLAVA model)"),TGe.forEach(t),ZPo=i(x),_1=n(x,"LI",{});var MGe=s(_1);b2e=n(MGe,"STRONG",{});var LIt=s(b2e);KPo=r(LIt,"fnet"),LIt.forEach(t),eBo=r(MGe," \u2014 "),gz=n(MGe,"A",{href:!0});var yIt=s(gz);oBo=r(yIt,"FNetModel"),yIt.forEach(t),rBo=r(MGe," (FNet model)"),MGe.forEach(t),tBo=i(x),b1=n(x,"LI",{});var EGe=s(b1);v2e=n(EGe,"STRONG",{});var xIt=s(v2e);aBo=r(xIt,"fsmt"),xIt.forEach(t),nBo=r(EGe," \u2014 "),hz=n(EGe,"A",{href:!0});var $It=s(hz);sBo=r($It,"FSMTModel"),$It.forEach(t),lBo=r(EGe," (FairSeq Machine-Translation model)"),EGe.forEach(t),iBo=i(x),xl=n(x,"LI",{});var _N=s(xl);F2e=n(_N,"STRONG",{});var kIt=s(F2e);dBo=r(kIt,"funnel"),kIt.forEach(t),mBo=r(_N," \u2014 "),uz=n(_N,"A",{href:!0});var SIt=s(uz);cBo=r(SIt,"FunnelModel"),SIt.forEach(t),fBo=r(_N," or "),pz=n(_N,"A",{href:!0});var RIt=s(pz);gBo=r(RIt,"FunnelBaseModel"),RIt.forEach(t),hBo=r(_N," (Funnel Transformer model)"),_N.forEach(t),uBo=i(x),v1=n(x,"LI",{});var CGe=s(v1);T2e=n(CGe,"STRONG",{});var PIt=s(T2e);pBo=r(PIt,"glpn"),PIt.forEach(t),_Bo=r(CGe," \u2014 "),_z=n(CGe,"A",{href:!0});var BIt=s(_z);bBo=r(BIt,"GLPNModel"),BIt.forEach(t),vBo=r(CGe," (GLPN model)"),CGe.forEach(t),FBo=i(x),F1=n(x,"LI",{});var wGe=s(F1);M2e=n(wGe,"STRONG",{});var IIt=s(M2e);TBo=r(IIt,"gpt2"),IIt.forEach(t),MBo=r(wGe," \u2014 "),bz=n(wGe,"A",{href:!0});var NIt=s(bz);EBo=r(NIt,"GPT2Model"),NIt.forEach(t),CBo=r(wGe," (OpenAI GPT-2 model)"),wGe.forEach(t),wBo=i(x),T1=n(x,"LI",{});var AGe=s(T1);E2e=n(AGe,"STRONG",{});var qIt=s(E2e);ABo=r(qIt,"gpt_neo"),qIt.forEach(t),LBo=r(AGe," \u2014 "),vz=n(AGe,"A",{href:!0});var jIt=s(vz);yBo=r(jIt,"GPTNeoModel"),jIt.forEach(t),xBo=r(AGe," (GPT Neo model)"),AGe.forEach(t),$Bo=i(x),M1=n(x,"LI",{});var LGe=s(M1);C2e=n(LGe,"STRONG",{});var DIt=s(C2e);kBo=r(DIt,"gpt_neox"),DIt.forEach(t),SBo=r(LGe," \u2014 "),Fz=n(LGe,"A",{href:!0});var GIt=s(Fz);RBo=r(GIt,"GPTNeoXModel"),GIt.forEach(t),PBo=r(LGe," (GPT NeoX model)"),LGe.forEach(t),BBo=i(x),E1=n(x,"LI",{});var yGe=s(E1);w2e=n(yGe,"STRONG",{});var OIt=s(w2e);IBo=r(OIt,"gpt_neox_japanese"),OIt.forEach(t),NBo=r(yGe," \u2014 "),Tz=n(yGe,"A",{href:!0});var VIt=s(Tz);qBo=r(VIt,"GPTNeoXJapaneseModel"),VIt.forEach(t),jBo=r(yGe," (GPT NeoX Japanese model)"),yGe.forEach(t),DBo=i(x),C1=n(x,"LI",{});var xGe=s(C1);A2e=n(xGe,"STRONG",{});var XIt=s(A2e);GBo=r(XIt,"gptj"),XIt.forEach(t),OBo=r(xGe," \u2014 "),Mz=n(xGe,"A",{href:!0});var zIt=s(Mz);VBo=r(zIt,"GPTJModel"),zIt.forEach(t),XBo=r(xGe," (GPT-J model)"),xGe.forEach(t),zBo=i(x),w1=n(x,"LI",{});var $Ge=s(w1);L2e=n($Ge,"STRONG",{});var QIt=s(L2e);QBo=r(QIt,"groupvit"),QIt.forEach(t),WBo=r($Ge," \u2014 "),Ez=n($Ge,"A",{href:!0});var WIt=s(Ez);UBo=r(WIt,"GroupViTModel"),WIt.forEach(t),HBo=r($Ge," (GroupViT model)"),$Ge.forEach(t),JBo=i(x),A1=n(x,"LI",{});var kGe=s(A1);y2e=n(kGe,"STRONG",{});var UIt=s(y2e);YBo=r(UIt,"hubert"),UIt.forEach(t),ZBo=r(kGe," \u2014 "),Cz=n(kGe,"A",{href:!0});var HIt=s(Cz);KBo=r(HIt,"HubertModel"),HIt.forEach(t),eIo=r(kGe," (Hubert model)"),kGe.forEach(t),oIo=i(x),L1=n(x,"LI",{});var SGe=s(L1);x2e=n(SGe,"STRONG",{});var JIt=s(x2e);rIo=r(JIt,"ibert"),JIt.forEach(t),tIo=r(SGe," \u2014 "),wz=n(SGe,"A",{href:!0});var YIt=s(wz);aIo=r(YIt,"IBertModel"),YIt.forEach(t),nIo=r(SGe," (I-BERT model)"),SGe.forEach(t),sIo=i(x),y1=n(x,"LI",{});var RGe=s(y1);$2e=n(RGe,"STRONG",{});var ZIt=s($2e);lIo=r(ZIt,"imagegpt"),ZIt.forEach(t),iIo=r(RGe," \u2014 "),Az=n(RGe,"A",{href:!0});var KIt=s(Az);dIo=r(KIt,"ImageGPTModel"),KIt.forEach(t),mIo=r(RGe," (ImageGPT model)"),RGe.forEach(t),cIo=i(x),x1=n(x,"LI",{});var PGe=s(x1);k2e=n(PGe,"STRONG",{});var eNt=s(k2e);fIo=r(eNt,"layoutlm"),eNt.forEach(t),gIo=r(PGe," \u2014 "),Lz=n(PGe,"A",{href:!0});var oNt=s(Lz);hIo=r(oNt,"LayoutLMModel"),oNt.forEach(t),uIo=r(PGe," (LayoutLM model)"),PGe.forEach(t),pIo=i(x),$1=n(x,"LI",{});var BGe=s($1);S2e=n(BGe,"STRONG",{});var rNt=s(S2e);_Io=r(rNt,"layoutlmv2"),rNt.forEach(t),bIo=r(BGe," \u2014 "),yz=n(BGe,"A",{href:!0});var tNt=s(yz);vIo=r(tNt,"LayoutLMv2Model"),tNt.forEach(t),FIo=r(BGe," (LayoutLMv2 model)"),BGe.forEach(t),TIo=i(x),k1=n(x,"LI",{});var IGe=s(k1);R2e=n(IGe,"STRONG",{});var aNt=s(R2e);MIo=r(aNt,"layoutlmv3"),aNt.forEach(t),EIo=r(IGe," \u2014 "),xz=n(IGe,"A",{href:!0});var nNt=s(xz);CIo=r(nNt,"LayoutLMv3Model"),nNt.forEach(t),wIo=r(IGe," (LayoutLMv3 model)"),IGe.forEach(t),AIo=i(x),S1=n(x,"LI",{});var NGe=s(S1);P2e=n(NGe,"STRONG",{});var sNt=s(P2e);LIo=r(sNt,"led"),sNt.forEach(t),yIo=r(NGe," \u2014 "),$z=n(NGe,"A",{href:!0});var lNt=s($z);xIo=r(lNt,"LEDModel"),lNt.forEach(t),$Io=r(NGe," (LED model)"),NGe.forEach(t),kIo=i(x),R1=n(x,"LI",{});var qGe=s(R1);B2e=n(qGe,"STRONG",{});var iNt=s(B2e);SIo=r(iNt,"levit"),iNt.forEach(t),RIo=r(qGe," \u2014 "),kz=n(qGe,"A",{href:!0});var dNt=s(kz);PIo=r(dNt,"LevitModel"),dNt.forEach(t),BIo=r(qGe," (LeViT model)"),qGe.forEach(t),IIo=i(x),P1=n(x,"LI",{});var jGe=s(P1);I2e=n(jGe,"STRONG",{});var mNt=s(I2e);NIo=r(mNt,"lilt"),mNt.forEach(t),qIo=r(jGe," \u2014 "),Sz=n(jGe,"A",{href:!0});var cNt=s(Sz);jIo=r(cNt,"LiltModel"),cNt.forEach(t),DIo=r(jGe," (LiLT model)"),jGe.forEach(t),GIo=i(x),B1=n(x,"LI",{});var DGe=s(B1);N2e=n(DGe,"STRONG",{});var fNt=s(N2e);OIo=r(fNt,"longformer"),fNt.forEach(t),VIo=r(DGe," \u2014 "),Rz=n(DGe,"A",{href:!0});var gNt=s(Rz);XIo=r(gNt,"LongformerModel"),gNt.forEach(t),zIo=r(DGe," (Longformer model)"),DGe.forEach(t),QIo=i(x),I1=n(x,"LI",{});var GGe=s(I1);q2e=n(GGe,"STRONG",{});var hNt=s(q2e);WIo=r(hNt,"longt5"),hNt.forEach(t),UIo=r(GGe," \u2014 "),Pz=n(GGe,"A",{href:!0});var uNt=s(Pz);HIo=r(uNt,"LongT5Model"),uNt.forEach(t),JIo=r(GGe," (LongT5 model)"),GGe.forEach(t),YIo=i(x),N1=n(x,"LI",{});var OGe=s(N1);j2e=n(OGe,"STRONG",{});var pNt=s(j2e);ZIo=r(pNt,"luke"),pNt.forEach(t),KIo=r(OGe," \u2014 "),Bz=n(OGe,"A",{href:!0});var _Nt=s(Bz);eNo=r(_Nt,"LukeModel"),_Nt.forEach(t),oNo=r(OGe," (LUKE model)"),OGe.forEach(t),rNo=i(x),q1=n(x,"LI",{});var VGe=s(q1);D2e=n(VGe,"STRONG",{});var bNt=s(D2e);tNo=r(bNt,"lxmert"),bNt.forEach(t),aNo=r(VGe," \u2014 "),Iz=n(VGe,"A",{href:!0});var vNt=s(Iz);nNo=r(vNt,"LxmertModel"),vNt.forEach(t),sNo=r(VGe," (LXMERT model)"),VGe.forEach(t),lNo=i(x),j1=n(x,"LI",{});var XGe=s(j1);G2e=n(XGe,"STRONG",{});var FNt=s(G2e);iNo=r(FNt,"m2m_100"),FNt.forEach(t),dNo=r(XGe," \u2014 "),Nz=n(XGe,"A",{href:!0});var TNt=s(Nz);mNo=r(TNt,"M2M100Model"),TNt.forEach(t),cNo=r(XGe," (M2M100 model)"),XGe.forEach(t),fNo=i(x),D1=n(x,"LI",{});var zGe=s(D1);O2e=n(zGe,"STRONG",{});var MNt=s(O2e);gNo=r(MNt,"marian"),MNt.forEach(t),hNo=r(zGe," \u2014 "),qz=n(zGe,"A",{href:!0});var ENt=s(qz);uNo=r(ENt,"MarianModel"),ENt.forEach(t),pNo=r(zGe," (Marian model)"),zGe.forEach(t),_No=i(x),G1=n(x,"LI",{});var QGe=s(G1);V2e=n(QGe,"STRONG",{});var CNt=s(V2e);bNo=r(CNt,"markuplm"),CNt.forEach(t),vNo=r(QGe," \u2014 "),jz=n(QGe,"A",{href:!0});var wNt=s(jz);FNo=r(wNt,"MarkupLMModel"),wNt.forEach(t),TNo=r(QGe," (MarkupLM model)"),QGe.forEach(t),MNo=i(x),O1=n(x,"LI",{});var WGe=s(O1);X2e=n(WGe,"STRONG",{});var ANt=s(X2e);ENo=r(ANt,"maskformer"),ANt.forEach(t),CNo=r(WGe," \u2014 "),Dz=n(WGe,"A",{href:!0});var LNt=s(Dz);wNo=r(LNt,"MaskFormerModel"),LNt.forEach(t),ANo=r(WGe," (MaskFormer model)"),WGe.forEach(t),LNo=i(x),V1=n(x,"LI",{});var UGe=s(V1);z2e=n(UGe,"STRONG",{});var yNt=s(z2e);yNo=r(yNt,"mbart"),yNt.forEach(t),xNo=r(UGe," \u2014 "),Gz=n(UGe,"A",{href:!0});var xNt=s(Gz);$No=r(xNt,"MBartModel"),xNt.forEach(t),kNo=r(UGe," (mBART model)"),UGe.forEach(t),SNo=i(x),X1=n(x,"LI",{});var HGe=s(X1);Q2e=n(HGe,"STRONG",{});var $Nt=s(Q2e);RNo=r($Nt,"mctct"),$Nt.forEach(t),PNo=r(HGe," \u2014 "),Oz=n(HGe,"A",{href:!0});var kNt=s(Oz);BNo=r(kNt,"MCTCTModel"),kNt.forEach(t),INo=r(HGe," (M-CTC-T model)"),HGe.forEach(t),NNo=i(x),z1=n(x,"LI",{});var JGe=s(z1);W2e=n(JGe,"STRONG",{});var SNt=s(W2e);qNo=r(SNt,"megatron-bert"),SNt.forEach(t),jNo=r(JGe," \u2014 "),Vz=n(JGe,"A",{href:!0});var RNt=s(Vz);DNo=r(RNt,"MegatronBertModel"),RNt.forEach(t),GNo=r(JGe," (Megatron-BERT model)"),JGe.forEach(t),ONo=i(x),Q1=n(x,"LI",{});var YGe=s(Q1);U2e=n(YGe,"STRONG",{});var PNt=s(U2e);VNo=r(PNt,"mobilebert"),PNt.forEach(t),XNo=r(YGe," \u2014 "),Xz=n(YGe,"A",{href:!0});var BNt=s(Xz);zNo=r(BNt,"MobileBertModel"),BNt.forEach(t),QNo=r(YGe," (MobileBERT model)"),YGe.forEach(t),WNo=i(x),W1=n(x,"LI",{});var ZGe=s(W1);H2e=n(ZGe,"STRONG",{});var INt=s(H2e);UNo=r(INt,"mobilevit"),INt.forEach(t),HNo=r(ZGe," \u2014 "),zz=n(ZGe,"A",{href:!0});var NNt=s(zz);JNo=r(NNt,"MobileViTModel"),NNt.forEach(t),YNo=r(ZGe," (MobileViT model)"),ZGe.forEach(t),ZNo=i(x),U1=n(x,"LI",{});var KGe=s(U1);J2e=n(KGe,"STRONG",{});var qNt=s(J2e);KNo=r(qNt,"mpnet"),qNt.forEach(t),eqo=r(KGe," \u2014 "),Qz=n(KGe,"A",{href:!0});var jNt=s(Qz);oqo=r(jNt,"MPNetModel"),jNt.forEach(t),rqo=r(KGe," (MPNet model)"),KGe.forEach(t),tqo=i(x),H1=n(x,"LI",{});var eOe=s(H1);Y2e=n(eOe,"STRONG",{});var DNt=s(Y2e);aqo=r(DNt,"mt5"),DNt.forEach(t),nqo=r(eOe," \u2014 "),Wz=n(eOe,"A",{href:!0});var GNt=s(Wz);sqo=r(GNt,"MT5Model"),GNt.forEach(t),lqo=r(eOe," (MT5 model)"),eOe.forEach(t),iqo=i(x),J1=n(x,"LI",{});var oOe=s(J1);Z2e=n(oOe,"STRONG",{});var ONt=s(Z2e);dqo=r(ONt,"mvp"),ONt.forEach(t),mqo=r(oOe," \u2014 "),Uz=n(oOe,"A",{href:!0});var VNt=s(Uz);cqo=r(VNt,"MvpModel"),VNt.forEach(t),fqo=r(oOe," (MVP model)"),oOe.forEach(t),gqo=i(x),Y1=n(x,"LI",{});var rOe=s(Y1);K2e=n(rOe,"STRONG",{});var XNt=s(K2e);hqo=r(XNt,"nezha"),XNt.forEach(t),uqo=r(rOe," \u2014 "),Hz=n(rOe,"A",{href:!0});var zNt=s(Hz);pqo=r(zNt,"NezhaModel"),zNt.forEach(t),_qo=r(rOe," (Nezha model)"),rOe.forEach(t),bqo=i(x),Z1=n(x,"LI",{});var tOe=s(Z1);ebe=n(tOe,"STRONG",{});var QNt=s(ebe);vqo=r(QNt,"nllb"),QNt.forEach(t),Fqo=r(tOe," \u2014 "),Jz=n(tOe,"A",{href:!0});var WNt=s(Jz);Tqo=r(WNt,"M2M100Model"),WNt.forEach(t),Mqo=r(tOe," (NLLB model)"),tOe.forEach(t),Eqo=i(x),K1=n(x,"LI",{});var aOe=s(K1);obe=n(aOe,"STRONG",{});var UNt=s(obe);Cqo=r(UNt,"nystromformer"),UNt.forEach(t),wqo=r(aOe," \u2014 "),Yz=n(aOe,"A",{href:!0});var HNt=s(Yz);Aqo=r(HNt,"NystromformerModel"),HNt.forEach(t),Lqo=r(aOe," (Nystr\xF6mformer model)"),aOe.forEach(t),yqo=i(x),e2=n(x,"LI",{});var nOe=s(e2);rbe=n(nOe,"STRONG",{});var JNt=s(rbe);xqo=r(JNt,"openai-gpt"),JNt.forEach(t),$qo=r(nOe," \u2014 "),Zz=n(nOe,"A",{href:!0});var YNt=s(Zz);kqo=r(YNt,"OpenAIGPTModel"),YNt.forEach(t),Sqo=r(nOe," (OpenAI GPT model)"),nOe.forEach(t),Rqo=i(x),o2=n(x,"LI",{});var sOe=s(o2);tbe=n(sOe,"STRONG",{});var ZNt=s(tbe);Pqo=r(ZNt,"opt"),ZNt.forEach(t),Bqo=r(sOe," \u2014 "),Kz=n(sOe,"A",{href:!0});var KNt=s(Kz);Iqo=r(KNt,"OPTModel"),KNt.forEach(t),Nqo=r(sOe," (OPT model)"),sOe.forEach(t),qqo=i(x),r2=n(x,"LI",{});var lOe=s(r2);abe=n(lOe,"STRONG",{});var eqt=s(abe);jqo=r(eqt,"owlvit"),eqt.forEach(t),Dqo=r(lOe," \u2014 "),eQ=n(lOe,"A",{href:!0});var oqt=s(eQ);Gqo=r(oqt,"OwlViTModel"),oqt.forEach(t),Oqo=r(lOe," (OWL-ViT model)"),lOe.forEach(t),Vqo=i(x),t2=n(x,"LI",{});var iOe=s(t2);nbe=n(iOe,"STRONG",{});var rqt=s(nbe);Xqo=r(rqt,"pegasus"),rqt.forEach(t),zqo=r(iOe," \u2014 "),oQ=n(iOe,"A",{href:!0});var tqt=s(oQ);Qqo=r(tqt,"PegasusModel"),tqt.forEach(t),Wqo=r(iOe," (Pegasus model)"),iOe.forEach(t),Uqo=i(x),a2=n(x,"LI",{});var dOe=s(a2);sbe=n(dOe,"STRONG",{});var aqt=s(sbe);Hqo=r(aqt,"pegasus_x"),aqt.forEach(t),Jqo=r(dOe," \u2014 "),rQ=n(dOe,"A",{href:!0});var nqt=s(rQ);Yqo=r(nqt,"PegasusXModel"),nqt.forEach(t),Zqo=r(dOe," (PEGASUS-X model)"),dOe.forEach(t),Kqo=i(x),n2=n(x,"LI",{});var mOe=s(n2);lbe=n(mOe,"STRONG",{});var sqt=s(lbe);ejo=r(sqt,"perceiver"),sqt.forEach(t),ojo=r(mOe," \u2014 "),tQ=n(mOe,"A",{href:!0});var lqt=s(tQ);rjo=r(lqt,"PerceiverModel"),lqt.forEach(t),tjo=r(mOe," (Perceiver model)"),mOe.forEach(t),ajo=i(x),s2=n(x,"LI",{});var cOe=s(s2);ibe=n(cOe,"STRONG",{});var iqt=s(ibe);njo=r(iqt,"plbart"),iqt.forEach(t),sjo=r(cOe," \u2014 "),aQ=n(cOe,"A",{href:!0});var dqt=s(aQ);ljo=r(dqt,"PLBartModel"),dqt.forEach(t),ijo=r(cOe," (PLBart model)"),cOe.forEach(t),djo=i(x),l2=n(x,"LI",{});var fOe=s(l2);dbe=n(fOe,"STRONG",{});var mqt=s(dbe);mjo=r(mqt,"poolformer"),mqt.forEach(t),cjo=r(fOe," \u2014 "),nQ=n(fOe,"A",{href:!0});var cqt=s(nQ);fjo=r(cqt,"PoolFormerModel"),cqt.forEach(t),gjo=r(fOe," (PoolFormer model)"),fOe.forEach(t),hjo=i(x),i2=n(x,"LI",{});var gOe=s(i2);mbe=n(gOe,"STRONG",{});var fqt=s(mbe);ujo=r(fqt,"prophetnet"),fqt.forEach(t),pjo=r(gOe," \u2014 "),sQ=n(gOe,"A",{href:!0});var gqt=s(sQ);_jo=r(gqt,"ProphetNetModel"),gqt.forEach(t),bjo=r(gOe," (ProphetNet model)"),gOe.forEach(t),vjo=i(x),d2=n(x,"LI",{});var hOe=s(d2);cbe=n(hOe,"STRONG",{});var hqt=s(cbe);Fjo=r(hqt,"qdqbert"),hqt.forEach(t),Tjo=r(hOe," \u2014 "),lQ=n(hOe,"A",{href:!0});var uqt=s(lQ);Mjo=r(uqt,"QDQBertModel"),uqt.forEach(t),Ejo=r(hOe," (QDQBert model)"),hOe.forEach(t),Cjo=i(x),m2=n(x,"LI",{});var uOe=s(m2);fbe=n(uOe,"STRONG",{});var pqt=s(fbe);wjo=r(pqt,"reformer"),pqt.forEach(t),Ajo=r(uOe," \u2014 "),iQ=n(uOe,"A",{href:!0});var _qt=s(iQ);Ljo=r(_qt,"ReformerModel"),_qt.forEach(t),yjo=r(uOe," (Reformer model)"),uOe.forEach(t),xjo=i(x),c2=n(x,"LI",{});var pOe=s(c2);gbe=n(pOe,"STRONG",{});var bqt=s(gbe);$jo=r(bqt,"regnet"),bqt.forEach(t),kjo=r(pOe," \u2014 "),dQ=n(pOe,"A",{href:!0});var vqt=s(dQ);Sjo=r(vqt,"RegNetModel"),vqt.forEach(t),Rjo=r(pOe," (RegNet model)"),pOe.forEach(t),Pjo=i(x),f2=n(x,"LI",{});var _Oe=s(f2);hbe=n(_Oe,"STRONG",{});var Fqt=s(hbe);Bjo=r(Fqt,"rembert"),Fqt.forEach(t),Ijo=r(_Oe," \u2014 "),mQ=n(_Oe,"A",{href:!0});var Tqt=s(mQ);Njo=r(Tqt,"RemBertModel"),Tqt.forEach(t),qjo=r(_Oe," (RemBERT model)"),_Oe.forEach(t),jjo=i(x),g2=n(x,"LI",{});var bOe=s(g2);ube=n(bOe,"STRONG",{});var Mqt=s(ube);Djo=r(Mqt,"resnet"),Mqt.forEach(t),Gjo=r(bOe," \u2014 "),cQ=n(bOe,"A",{href:!0});var Eqt=s(cQ);Ojo=r(Eqt,"ResNetModel"),Eqt.forEach(t),Vjo=r(bOe," (ResNet model)"),bOe.forEach(t),Xjo=i(x),h2=n(x,"LI",{});var vOe=s(h2);pbe=n(vOe,"STRONG",{});var Cqt=s(pbe);zjo=r(Cqt,"retribert"),Cqt.forEach(t),Qjo=r(vOe," \u2014 "),fQ=n(vOe,"A",{href:!0});var wqt=s(fQ);Wjo=r(wqt,"RetriBertModel"),wqt.forEach(t),Ujo=r(vOe," (RetriBERT model)"),vOe.forEach(t),Hjo=i(x),u2=n(x,"LI",{});var FOe=s(u2);_be=n(FOe,"STRONG",{});var Aqt=s(_be);Jjo=r(Aqt,"roberta"),Aqt.forEach(t),Yjo=r(FOe," \u2014 "),gQ=n(FOe,"A",{href:!0});var Lqt=s(gQ);Zjo=r(Lqt,"RobertaModel"),Lqt.forEach(t),Kjo=r(FOe," (RoBERTa model)"),FOe.forEach(t),eDo=i(x),p2=n(x,"LI",{});var TOe=s(p2);bbe=n(TOe,"STRONG",{});var yqt=s(bbe);oDo=r(yqt,"roformer"),yqt.forEach(t),rDo=r(TOe," \u2014 "),hQ=n(TOe,"A",{href:!0});var xqt=s(hQ);tDo=r(xqt,"RoFormerModel"),xqt.forEach(t),aDo=r(TOe," (RoFormer model)"),TOe.forEach(t),nDo=i(x),_2=n(x,"LI",{});var MOe=s(_2);vbe=n(MOe,"STRONG",{});var $qt=s(vbe);sDo=r($qt,"segformer"),$qt.forEach(t),lDo=r(MOe," \u2014 "),uQ=n(MOe,"A",{href:!0});var kqt=s(uQ);iDo=r(kqt,"SegformerModel"),kqt.forEach(t),dDo=r(MOe," (SegFormer model)"),MOe.forEach(t),mDo=i(x),b2=n(x,"LI",{});var EOe=s(b2);Fbe=n(EOe,"STRONG",{});var Sqt=s(Fbe);cDo=r(Sqt,"sew"),Sqt.forEach(t),fDo=r(EOe," \u2014 "),pQ=n(EOe,"A",{href:!0});var Rqt=s(pQ);gDo=r(Rqt,"SEWModel"),Rqt.forEach(t),hDo=r(EOe," (SEW model)"),EOe.forEach(t),uDo=i(x),v2=n(x,"LI",{});var COe=s(v2);Tbe=n(COe,"STRONG",{});var Pqt=s(Tbe);pDo=r(Pqt,"sew-d"),Pqt.forEach(t),_Do=r(COe," \u2014 "),_Q=n(COe,"A",{href:!0});var Bqt=s(_Q);bDo=r(Bqt,"SEWDModel"),Bqt.forEach(t),vDo=r(COe," (SEW-D model)"),COe.forEach(t),FDo=i(x),F2=n(x,"LI",{});var wOe=s(F2);Mbe=n(wOe,"STRONG",{});var Iqt=s(Mbe);TDo=r(Iqt,"speech_to_text"),Iqt.forEach(t),MDo=r(wOe," \u2014 "),bQ=n(wOe,"A",{href:!0});var Nqt=s(bQ);EDo=r(Nqt,"Speech2TextModel"),Nqt.forEach(t),CDo=r(wOe," (Speech2Text model)"),wOe.forEach(t),wDo=i(x),T2=n(x,"LI",{});var AOe=s(T2);Ebe=n(AOe,"STRONG",{});var qqt=s(Ebe);ADo=r(qqt,"splinter"),qqt.forEach(t),LDo=r(AOe," \u2014 "),vQ=n(AOe,"A",{href:!0});var jqt=s(vQ);yDo=r(jqt,"SplinterModel"),jqt.forEach(t),xDo=r(AOe," (Splinter model)"),AOe.forEach(t),$Do=i(x),M2=n(x,"LI",{});var LOe=s(M2);Cbe=n(LOe,"STRONG",{});var Dqt=s(Cbe);kDo=r(Dqt,"squeezebert"),Dqt.forEach(t),SDo=r(LOe," \u2014 "),FQ=n(LOe,"A",{href:!0});var Gqt=s(FQ);RDo=r(Gqt,"SqueezeBertModel"),Gqt.forEach(t),PDo=r(LOe," (SqueezeBERT model)"),LOe.forEach(t),BDo=i(x),E2=n(x,"LI",{});var yOe=s(E2);wbe=n(yOe,"STRONG",{});var Oqt=s(wbe);IDo=r(Oqt,"swin"),Oqt.forEach(t),NDo=r(yOe," \u2014 "),TQ=n(yOe,"A",{href:!0});var Vqt=s(TQ);qDo=r(Vqt,"SwinModel"),Vqt.forEach(t),jDo=r(yOe," (Swin Transformer model)"),yOe.forEach(t),DDo=i(x),C2=n(x,"LI",{});var xOe=s(C2);Abe=n(xOe,"STRONG",{});var Xqt=s(Abe);GDo=r(Xqt,"swinv2"),Xqt.forEach(t),ODo=r(xOe," \u2014 "),MQ=n(xOe,"A",{href:!0});var zqt=s(MQ);VDo=r(zqt,"Swinv2Model"),zqt.forEach(t),XDo=r(xOe," (Swin Transformer V2 model)"),xOe.forEach(t),zDo=i(x),w2=n(x,"LI",{});var $Oe=s(w2);Lbe=n($Oe,"STRONG",{});var Qqt=s(Lbe);QDo=r(Qqt,"t5"),Qqt.forEach(t),WDo=r($Oe," \u2014 "),EQ=n($Oe,"A",{href:!0});var Wqt=s(EQ);UDo=r(Wqt,"T5Model"),Wqt.forEach(t),HDo=r($Oe," (T5 model)"),$Oe.forEach(t),JDo=i(x),A2=n(x,"LI",{});var kOe=s(A2);ybe=n(kOe,"STRONG",{});var Uqt=s(ybe);YDo=r(Uqt,"table-transformer"),Uqt.forEach(t),ZDo=r(kOe," \u2014 "),CQ=n(kOe,"A",{href:!0});var Hqt=s(CQ);KDo=r(Hqt,"TableTransformerModel"),Hqt.forEach(t),eGo=r(kOe," (Table Transformer model)"),kOe.forEach(t),oGo=i(x),L2=n(x,"LI",{});var SOe=s(L2);xbe=n(SOe,"STRONG",{});var Jqt=s(xbe);rGo=r(Jqt,"tapas"),Jqt.forEach(t),tGo=r(SOe," \u2014 "),wQ=n(SOe,"A",{href:!0});var Yqt=s(wQ);aGo=r(Yqt,"TapasModel"),Yqt.forEach(t),nGo=r(SOe," (TAPAS model)"),SOe.forEach(t),sGo=i(x),y2=n(x,"LI",{});var ROe=s(y2);$be=n(ROe,"STRONG",{});var Zqt=s($be);lGo=r(Zqt,"time_series_transformer"),Zqt.forEach(t),iGo=r(ROe," \u2014 "),AQ=n(ROe,"A",{href:!0});var Kqt=s(AQ);dGo=r(Kqt,"TimeSeriesTransformerModel"),Kqt.forEach(t),mGo=r(ROe," (Time Series Transformer model)"),ROe.forEach(t),cGo=i(x),x2=n(x,"LI",{});var POe=s(x2);kbe=n(POe,"STRONG",{});var ejt=s(kbe);fGo=r(ejt,"trajectory_transformer"),ejt.forEach(t),gGo=r(POe," \u2014 "),LQ=n(POe,"A",{href:!0});var ojt=s(LQ);hGo=r(ojt,"TrajectoryTransformerModel"),ojt.forEach(t),uGo=r(POe," (Trajectory Transformer model)"),POe.forEach(t),pGo=i(x),$2=n(x,"LI",{});var BOe=s($2);Sbe=n(BOe,"STRONG",{});var rjt=s(Sbe);_Go=r(rjt,"transfo-xl"),rjt.forEach(t),bGo=r(BOe," \u2014 "),yQ=n(BOe,"A",{href:!0});var tjt=s(yQ);vGo=r(tjt,"TransfoXLModel"),tjt.forEach(t),FGo=r(BOe," (Transformer-XL model)"),BOe.forEach(t),TGo=i(x),k2=n(x,"LI",{});var IOe=s(k2);Rbe=n(IOe,"STRONG",{});var ajt=s(Rbe);MGo=r(ajt,"unispeech"),ajt.forEach(t),EGo=r(IOe," \u2014 "),xQ=n(IOe,"A",{href:!0});var njt=s(xQ);CGo=r(njt,"UniSpeechModel"),njt.forEach(t),wGo=r(IOe," (UniSpeech model)"),IOe.forEach(t),AGo=i(x),S2=n(x,"LI",{});var NOe=s(S2);Pbe=n(NOe,"STRONG",{});var sjt=s(Pbe);LGo=r(sjt,"unispeech-sat"),sjt.forEach(t),yGo=r(NOe," \u2014 "),$Q=n(NOe,"A",{href:!0});var ljt=s($Q);xGo=r(ljt,"UniSpeechSatModel"),ljt.forEach(t),$Go=r(NOe," (UniSpeechSat model)"),NOe.forEach(t),kGo=i(x),R2=n(x,"LI",{});var qOe=s(R2);Bbe=n(qOe,"STRONG",{});var ijt=s(Bbe);SGo=r(ijt,"van"),ijt.forEach(t),RGo=r(qOe," \u2014 "),kQ=n(qOe,"A",{href:!0});var djt=s(kQ);PGo=r(djt,"VanModel"),djt.forEach(t),BGo=r(qOe," (VAN model)"),qOe.forEach(t),IGo=i(x),P2=n(x,"LI",{});var jOe=s(P2);Ibe=n(jOe,"STRONG",{});var mjt=s(Ibe);NGo=r(mjt,"videomae"),mjt.forEach(t),qGo=r(jOe," \u2014 "),SQ=n(jOe,"A",{href:!0});var cjt=s(SQ);jGo=r(cjt,"VideoMAEModel"),cjt.forEach(t),DGo=r(jOe," (VideoMAE model)"),jOe.forEach(t),GGo=i(x),B2=n(x,"LI",{});var DOe=s(B2);Nbe=n(DOe,"STRONG",{});var fjt=s(Nbe);OGo=r(fjt,"vilt"),fjt.forEach(t),VGo=r(DOe," \u2014 "),RQ=n(DOe,"A",{href:!0});var gjt=s(RQ);XGo=r(gjt,"ViltModel"),gjt.forEach(t),zGo=r(DOe," (ViLT model)"),DOe.forEach(t),QGo=i(x),I2=n(x,"LI",{});var GOe=s(I2);qbe=n(GOe,"STRONG",{});var hjt=s(qbe);WGo=r(hjt,"vision-text-dual-encoder"),hjt.forEach(t),UGo=r(GOe," \u2014 "),PQ=n(GOe,"A",{href:!0});var ujt=s(PQ);HGo=r(ujt,"VisionTextDualEncoderModel"),ujt.forEach(t),JGo=r(GOe," (VisionTextDualEncoder model)"),GOe.forEach(t),YGo=i(x),N2=n(x,"LI",{});var OOe=s(N2);jbe=n(OOe,"STRONG",{});var pjt=s(jbe);ZGo=r(pjt,"visual_bert"),pjt.forEach(t),KGo=r(OOe," \u2014 "),BQ=n(OOe,"A",{href:!0});var _jt=s(BQ);eOo=r(_jt,"VisualBertModel"),_jt.forEach(t),oOo=r(OOe," (VisualBERT model)"),OOe.forEach(t),rOo=i(x),q2=n(x,"LI",{});var VOe=s(q2);Dbe=n(VOe,"STRONG",{});var bjt=s(Dbe);tOo=r(bjt,"vit"),bjt.forEach(t),aOo=r(VOe," \u2014 "),IQ=n(VOe,"A",{href:!0});var vjt=s(IQ);nOo=r(vjt,"ViTModel"),vjt.forEach(t),sOo=r(VOe," (ViT model)"),VOe.forEach(t),lOo=i(x),j2=n(x,"LI",{});var XOe=s(j2);Gbe=n(XOe,"STRONG",{});var Fjt=s(Gbe);iOo=r(Fjt,"vit_mae"),Fjt.forEach(t),dOo=r(XOe," \u2014 "),NQ=n(XOe,"A",{href:!0});var Tjt=s(NQ);mOo=r(Tjt,"ViTMAEModel"),Tjt.forEach(t),cOo=r(XOe," (ViTMAE model)"),XOe.forEach(t),fOo=i(x),D2=n(x,"LI",{});var zOe=s(D2);Obe=n(zOe,"STRONG",{});var Mjt=s(Obe);gOo=r(Mjt,"vit_msn"),Mjt.forEach(t),hOo=r(zOe," \u2014 "),qQ=n(zOe,"A",{href:!0});var Ejt=s(qQ);uOo=r(Ejt,"ViTMSNModel"),Ejt.forEach(t),pOo=r(zOe," (ViTMSN model)"),zOe.forEach(t),_Oo=i(x),G2=n(x,"LI",{});var QOe=s(G2);Vbe=n(QOe,"STRONG",{});var Cjt=s(Vbe);bOo=r(Cjt,"wav2vec2"),Cjt.forEach(t),vOo=r(QOe," \u2014 "),jQ=n(QOe,"A",{href:!0});var wjt=s(jQ);FOo=r(wjt,"Wav2Vec2Model"),wjt.forEach(t),TOo=r(QOe," (Wav2Vec2 model)"),QOe.forEach(t),MOo=i(x),O2=n(x,"LI",{});var WOe=s(O2);Xbe=n(WOe,"STRONG",{});var Ajt=s(Xbe);EOo=r(Ajt,"wav2vec2-conformer"),Ajt.forEach(t),COo=r(WOe," \u2014 "),DQ=n(WOe,"A",{href:!0});var Ljt=s(DQ);wOo=r(Ljt,"Wav2Vec2ConformerModel"),Ljt.forEach(t),AOo=r(WOe," (Wav2Vec2-Conformer model)"),WOe.forEach(t),LOo=i(x),V2=n(x,"LI",{});var UOe=s(V2);zbe=n(UOe,"STRONG",{});var yjt=s(zbe);yOo=r(yjt,"wavlm"),yjt.forEach(t),xOo=r(UOe," \u2014 "),GQ=n(UOe,"A",{href:!0});var xjt=s(GQ);$Oo=r(xjt,"WavLMModel"),xjt.forEach(t),kOo=r(UOe," (WavLM model)"),UOe.forEach(t),SOo=i(x),X2=n(x,"LI",{});var HOe=s(X2);Qbe=n(HOe,"STRONG",{});var $jt=s(Qbe);ROo=r($jt,"whisper"),$jt.forEach(t),POo=r(HOe," \u2014 "),OQ=n(HOe,"A",{href:!0});var kjt=s(OQ);BOo=r(kjt,"WhisperModel"),kjt.forEach(t),IOo=r(HOe," (Whisper model)"),HOe.forEach(t),NOo=i(x),z2=n(x,"LI",{});var JOe=s(z2);Wbe=n(JOe,"STRONG",{});var Sjt=s(Wbe);qOo=r(Sjt,"xclip"),Sjt.forEach(t),jOo=r(JOe," \u2014 "),VQ=n(JOe,"A",{href:!0});var Rjt=s(VQ);DOo=r(Rjt,"XCLIPModel"),Rjt.forEach(t),GOo=r(JOe," (X-CLIP model)"),JOe.forEach(t),OOo=i(x),Q2=n(x,"LI",{});var YOe=s(Q2);Ube=n(YOe,"STRONG",{});var Pjt=s(Ube);VOo=r(Pjt,"xglm"),Pjt.forEach(t),XOo=r(YOe," \u2014 "),XQ=n(YOe,"A",{href:!0});var Bjt=s(XQ);zOo=r(Bjt,"XGLMModel"),Bjt.forEach(t),QOo=r(YOe," (XGLM model)"),YOe.forEach(t),WOo=i(x),W2=n(x,"LI",{});var ZOe=s(W2);Hbe=n(ZOe,"STRONG",{});var Ijt=s(Hbe);UOo=r(Ijt,"xlm"),Ijt.forEach(t),HOo=r(ZOe," \u2014 "),zQ=n(ZOe,"A",{href:!0});var Njt=s(zQ);JOo=r(Njt,"XLMModel"),Njt.forEach(t),YOo=r(ZOe," (XLM model)"),ZOe.forEach(t),ZOo=i(x),U2=n(x,"LI",{});var KOe=s(U2);Jbe=n(KOe,"STRONG",{});var qjt=s(Jbe);KOo=r(qjt,"xlm-prophetnet"),qjt.forEach(t),eVo=r(KOe," \u2014 "),QQ=n(KOe,"A",{href:!0});var jjt=s(QQ);oVo=r(jjt,"XLMProphetNetModel"),jjt.forEach(t),rVo=r(KOe," (XLM-ProphetNet model)"),KOe.forEach(t),tVo=i(x),H2=n(x,"LI",{});var eVe=s(H2);Ybe=n(eVe,"STRONG",{});var Djt=s(Ybe);aVo=r(Djt,"xlm-roberta"),Djt.forEach(t),nVo=r(eVe," \u2014 "),WQ=n(eVe,"A",{href:!0});var Gjt=s(WQ);sVo=r(Gjt,"XLMRobertaModel"),Gjt.forEach(t),lVo=r(eVe," (XLM-RoBERTa model)"),eVe.forEach(t),iVo=i(x),J2=n(x,"LI",{});var oVe=s(J2);Zbe=n(oVe,"STRONG",{});var Ojt=s(Zbe);dVo=r(Ojt,"xlm-roberta-xl"),Ojt.forEach(t),mVo=r(oVe," \u2014 "),UQ=n(oVe,"A",{href:!0});var Vjt=s(UQ);cVo=r(Vjt,"XLMRobertaXLModel"),Vjt.forEach(t),fVo=r(oVe," (XLM-RoBERTa-XL model)"),oVe.forEach(t),gVo=i(x),Y2=n(x,"LI",{});var rVe=s(Y2);Kbe=n(rVe,"STRONG",{});var Xjt=s(Kbe);hVo=r(Xjt,"xlnet"),Xjt.forEach(t),uVo=r(rVe," \u2014 "),HQ=n(rVe,"A",{href:!0});var zjt=s(HQ);pVo=r(zjt,"XLNetModel"),zjt.forEach(t),_Vo=r(rVe," (XLNet model)"),rVe.forEach(t),bVo=i(x),Z2=n(x,"LI",{});var tVe=s(Z2);eve=n(tVe,"STRONG",{});var Qjt=s(eve);vVo=r(Qjt,"yolos"),Qjt.forEach(t),FVo=r(tVe," \u2014 "),JQ=n(tVe,"A",{href:!0});var Wjt=s(JQ);TVo=r(Wjt,"YolosModel"),Wjt.forEach(t),MVo=r(tVe," (YOLOS model)"),tVe.forEach(t),EVo=i(x),K2=n(x,"LI",{});var aVe=s(K2);ove=n(aVe,"STRONG",{});var Ujt=s(ove);CVo=r(Ujt,"yoso"),Ujt.forEach(t),wVo=r(aVe," \u2014 "),YQ=n(aVe,"A",{href:!0});var Hjt=s(YQ);AVo=r(Hjt,"YosoModel"),Hjt.forEach(t),LVo=r(aVe," (YOSO model)"),aVe.forEach(t),x.forEach(t),yVo=i(La),eb=n(La,"P",{});var nVe=s(eb);xVo=r(nVe,"The model is set in evaluation mode by default using "),rve=n(nVe,"CODE",{});var Jjt=s(rve);$Vo=r(Jjt,"model.eval()"),Jjt.forEach(t),kVo=r(nVe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),tve=n(nVe,"CODE",{});var Yjt=s(tve);SVo=r(Yjt,"model.train()"),Yjt.forEach(t),nVe.forEach(t),RVo=i(La),T(ob.$$.fragment,La),La.forEach(t),ql.forEach(t),Dto=i(c),Bd=n(c,"H2",{class:!0});var aso=s(Bd);rb=n(aso,"A",{id:!0,class:!0,href:!0});var Zjt=s(rb);ave=n(Zjt,"SPAN",{});var Kjt=s(ave);T(D$.$$.fragment,Kjt),Kjt.forEach(t),Zjt.forEach(t),PVo=i(aso),nve=n(aso,"SPAN",{});var eDt=s(nve);BVo=r(eDt,"AutoModelForPreTraining"),eDt.forEach(t),aso.forEach(t),Gto=i(c),No=n(c,"DIV",{class:!0});var jl=s(No);T(G$.$$.fragment,jl),IVo=i(jl),Id=n(jl,"P",{});var sme=s(Id);NVo=r(sme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),ZQ=n(sme,"A",{href:!0});var oDt=s(ZQ);qVo=r(oDt,"from_pretrained()"),oDt.forEach(t),jVo=r(sme," class method or the "),KQ=n(sme,"A",{href:!0});var rDt=s(KQ);DVo=r(rDt,"from_config()"),rDt.forEach(t),GVo=r(sme,` class
method.`),sme.forEach(t),OVo=i(jl),O$=n(jl,"P",{});var nso=s(O$);VVo=r(nso,"This class cannot be instantiated directly using "),sve=n(nso,"CODE",{});var tDt=s(sve);XVo=r(tDt,"__init__()"),tDt.forEach(t),zVo=r(nso," (throws an error)."),nso.forEach(t),QVo=i(jl),Et=n(jl,"DIV",{class:!0});var r9=s(Et);T(V$.$$.fragment,r9),WVo=i(r9),lve=n(r9,"P",{});var aDt=s(lve);UVo=r(aDt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),aDt.forEach(t),HVo=i(r9),Nd=n(r9,"P",{});var lme=s(Nd);JVo=r(lme,`Note:
Loading a model from its configuration file does `),ive=n(lme,"STRONG",{});var nDt=s(ive);YVo=r(nDt,"not"),nDt.forEach(t),ZVo=r(lme,` load the model weights. It only affects the
model\u2019s configuration. Use `),eW=n(lme,"A",{href:!0});var sDt=s(eW);KVo=r(sDt,"from_pretrained()"),sDt.forEach(t),eXo=r(lme," to load the model weights."),lme.forEach(t),oXo=i(r9),T(tb.$$.fragment,r9),r9.forEach(t),rXo=i(jl),eo=n(jl,"DIV",{class:!0});var ya=s(eo);T(X$.$$.fragment,ya),tXo=i(ya),dve=n(ya,"P",{});var lDt=s(dve);aXo=r(lDt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),lDt.forEach(t),nXo=i(ya),sn=n(ya,"P",{});var t9=s(sn);sXo=r(t9,"The model class to instantiate is selected based on the "),mve=n(t9,"CODE",{});var iDt=s(mve);lXo=r(iDt,"model_type"),iDt.forEach(t),iXo=r(t9,` property of the config object (either
passed as an argument or loaded from `),cve=n(t9,"CODE",{});var dDt=s(cve);dXo=r(dDt,"pretrained_model_name_or_path"),dDt.forEach(t),mXo=r(t9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fve=n(t9,"CODE",{});var mDt=s(fve);cXo=r(mDt,"pretrained_model_name_or_path"),mDt.forEach(t),fXo=r(t9,":"),t9.forEach(t),gXo=i(ya),G=n(ya,"UL",{});var V=s(G);ab=n(V,"LI",{});var sVe=s(ab);gve=n(sVe,"STRONG",{});var cDt=s(gve);hXo=r(cDt,"albert"),cDt.forEach(t),uXo=r(sVe," \u2014 "),oW=n(sVe,"A",{href:!0});var fDt=s(oW);pXo=r(fDt,"AlbertForPreTraining"),fDt.forEach(t),_Xo=r(sVe," (ALBERT model)"),sVe.forEach(t),bXo=i(V),nb=n(V,"LI",{});var lVe=s(nb);hve=n(lVe,"STRONG",{});var gDt=s(hve);vXo=r(gDt,"bart"),gDt.forEach(t),FXo=r(lVe," \u2014 "),rW=n(lVe,"A",{href:!0});var hDt=s(rW);TXo=r(hDt,"BartForConditionalGeneration"),hDt.forEach(t),MXo=r(lVe," (BART model)"),lVe.forEach(t),EXo=i(V),sb=n(V,"LI",{});var iVe=s(sb);uve=n(iVe,"STRONG",{});var uDt=s(uve);CXo=r(uDt,"bert"),uDt.forEach(t),wXo=r(iVe," \u2014 "),tW=n(iVe,"A",{href:!0});var pDt=s(tW);AXo=r(pDt,"BertForPreTraining"),pDt.forEach(t),LXo=r(iVe," (BERT model)"),iVe.forEach(t),yXo=i(V),lb=n(V,"LI",{});var dVe=s(lb);pve=n(dVe,"STRONG",{});var _Dt=s(pve);xXo=r(_Dt,"big_bird"),_Dt.forEach(t),$Xo=r(dVe," \u2014 "),aW=n(dVe,"A",{href:!0});var bDt=s(aW);kXo=r(bDt,"BigBirdForPreTraining"),bDt.forEach(t),SXo=r(dVe," (BigBird model)"),dVe.forEach(t),RXo=i(V),ib=n(V,"LI",{});var mVe=s(ib);_ve=n(mVe,"STRONG",{});var vDt=s(_ve);PXo=r(vDt,"bloom"),vDt.forEach(t),BXo=r(mVe," \u2014 "),nW=n(mVe,"A",{href:!0});var FDt=s(nW);IXo=r(FDt,"BloomForCausalLM"),FDt.forEach(t),NXo=r(mVe," (BLOOM model)"),mVe.forEach(t),qXo=i(V),db=n(V,"LI",{});var cVe=s(db);bve=n(cVe,"STRONG",{});var TDt=s(bve);jXo=r(TDt,"camembert"),TDt.forEach(t),DXo=r(cVe," \u2014 "),sW=n(cVe,"A",{href:!0});var MDt=s(sW);GXo=r(MDt,"CamembertForMaskedLM"),MDt.forEach(t),OXo=r(cVe," (CamemBERT model)"),cVe.forEach(t),VXo=i(V),mb=n(V,"LI",{});var fVe=s(mb);vve=n(fVe,"STRONG",{});var EDt=s(vve);XXo=r(EDt,"ctrl"),EDt.forEach(t),zXo=r(fVe," \u2014 "),lW=n(fVe,"A",{href:!0});var CDt=s(lW);QXo=r(CDt,"CTRLLMHeadModel"),CDt.forEach(t),WXo=r(fVe," (CTRL model)"),fVe.forEach(t),UXo=i(V),cb=n(V,"LI",{});var gVe=s(cb);Fve=n(gVe,"STRONG",{});var wDt=s(Fve);HXo=r(wDt,"data2vec-text"),wDt.forEach(t),JXo=r(gVe," \u2014 "),iW=n(gVe,"A",{href:!0});var ADt=s(iW);YXo=r(ADt,"Data2VecTextForMaskedLM"),ADt.forEach(t),ZXo=r(gVe," (Data2VecText model)"),gVe.forEach(t),KXo=i(V),fb=n(V,"LI",{});var hVe=s(fb);Tve=n(hVe,"STRONG",{});var LDt=s(Tve);ezo=r(LDt,"deberta"),LDt.forEach(t),ozo=r(hVe," \u2014 "),dW=n(hVe,"A",{href:!0});var yDt=s(dW);rzo=r(yDt,"DebertaForMaskedLM"),yDt.forEach(t),tzo=r(hVe," (DeBERTa model)"),hVe.forEach(t),azo=i(V),gb=n(V,"LI",{});var uVe=s(gb);Mve=n(uVe,"STRONG",{});var xDt=s(Mve);nzo=r(xDt,"deberta-v2"),xDt.forEach(t),szo=r(uVe," \u2014 "),mW=n(uVe,"A",{href:!0});var $Dt=s(mW);lzo=r($Dt,"DebertaV2ForMaskedLM"),$Dt.forEach(t),izo=r(uVe," (DeBERTa-v2 model)"),uVe.forEach(t),dzo=i(V),hb=n(V,"LI",{});var pVe=s(hb);Eve=n(pVe,"STRONG",{});var kDt=s(Eve);mzo=r(kDt,"distilbert"),kDt.forEach(t),czo=r(pVe," \u2014 "),cW=n(pVe,"A",{href:!0});var SDt=s(cW);fzo=r(SDt,"DistilBertForMaskedLM"),SDt.forEach(t),gzo=r(pVe," (DistilBERT model)"),pVe.forEach(t),hzo=i(V),ub=n(V,"LI",{});var _Ve=s(ub);Cve=n(_Ve,"STRONG",{});var RDt=s(Cve);uzo=r(RDt,"electra"),RDt.forEach(t),pzo=r(_Ve," \u2014 "),fW=n(_Ve,"A",{href:!0});var PDt=s(fW);_zo=r(PDt,"ElectraForPreTraining"),PDt.forEach(t),bzo=r(_Ve," (ELECTRA model)"),_Ve.forEach(t),vzo=i(V),pb=n(V,"LI",{});var bVe=s(pb);wve=n(bVe,"STRONG",{});var BDt=s(wve);Fzo=r(BDt,"ernie"),BDt.forEach(t),Tzo=r(bVe," \u2014 "),gW=n(bVe,"A",{href:!0});var IDt=s(gW);Mzo=r(IDt,"ErnieForPreTraining"),IDt.forEach(t),Ezo=r(bVe," (ERNIE model)"),bVe.forEach(t),Czo=i(V),_b=n(V,"LI",{});var vVe=s(_b);Ave=n(vVe,"STRONG",{});var NDt=s(Ave);wzo=r(NDt,"flaubert"),NDt.forEach(t),Azo=r(vVe," \u2014 "),hW=n(vVe,"A",{href:!0});var qDt=s(hW);Lzo=r(qDt,"FlaubertWithLMHeadModel"),qDt.forEach(t),yzo=r(vVe," (FlauBERT model)"),vVe.forEach(t),xzo=i(V),bb=n(V,"LI",{});var FVe=s(bb);Lve=n(FVe,"STRONG",{});var jDt=s(Lve);$zo=r(jDt,"flava"),jDt.forEach(t),kzo=r(FVe," \u2014 "),uW=n(FVe,"A",{href:!0});var DDt=s(uW);Szo=r(DDt,"FlavaForPreTraining"),DDt.forEach(t),Rzo=r(FVe," (FLAVA model)"),FVe.forEach(t),Pzo=i(V),vb=n(V,"LI",{});var TVe=s(vb);yve=n(TVe,"STRONG",{});var GDt=s(yve);Bzo=r(GDt,"fnet"),GDt.forEach(t),Izo=r(TVe," \u2014 "),pW=n(TVe,"A",{href:!0});var ODt=s(pW);Nzo=r(ODt,"FNetForPreTraining"),ODt.forEach(t),qzo=r(TVe," (FNet model)"),TVe.forEach(t),jzo=i(V),Fb=n(V,"LI",{});var MVe=s(Fb);xve=n(MVe,"STRONG",{});var VDt=s(xve);Dzo=r(VDt,"fsmt"),VDt.forEach(t),Gzo=r(MVe," \u2014 "),_W=n(MVe,"A",{href:!0});var XDt=s(_W);Ozo=r(XDt,"FSMTForConditionalGeneration"),XDt.forEach(t),Vzo=r(MVe," (FairSeq Machine-Translation model)"),MVe.forEach(t),Xzo=i(V),Tb=n(V,"LI",{});var EVe=s(Tb);$ve=n(EVe,"STRONG",{});var zDt=s($ve);zzo=r(zDt,"funnel"),zDt.forEach(t),Qzo=r(EVe," \u2014 "),bW=n(EVe,"A",{href:!0});var QDt=s(bW);Wzo=r(QDt,"FunnelForPreTraining"),QDt.forEach(t),Uzo=r(EVe," (Funnel Transformer model)"),EVe.forEach(t),Hzo=i(V),Mb=n(V,"LI",{});var CVe=s(Mb);kve=n(CVe,"STRONG",{});var WDt=s(kve);Jzo=r(WDt,"gpt2"),WDt.forEach(t),Yzo=r(CVe," \u2014 "),vW=n(CVe,"A",{href:!0});var UDt=s(vW);Zzo=r(UDt,"GPT2LMHeadModel"),UDt.forEach(t),Kzo=r(CVe," (OpenAI GPT-2 model)"),CVe.forEach(t),eQo=i(V),Eb=n(V,"LI",{});var wVe=s(Eb);Sve=n(wVe,"STRONG",{});var HDt=s(Sve);oQo=r(HDt,"ibert"),HDt.forEach(t),rQo=r(wVe," \u2014 "),FW=n(wVe,"A",{href:!0});var JDt=s(FW);tQo=r(JDt,"IBertForMaskedLM"),JDt.forEach(t),aQo=r(wVe," (I-BERT model)"),wVe.forEach(t),nQo=i(V),Cb=n(V,"LI",{});var AVe=s(Cb);Rve=n(AVe,"STRONG",{});var YDt=s(Rve);sQo=r(YDt,"layoutlm"),YDt.forEach(t),lQo=r(AVe," \u2014 "),TW=n(AVe,"A",{href:!0});var ZDt=s(TW);iQo=r(ZDt,"LayoutLMForMaskedLM"),ZDt.forEach(t),dQo=r(AVe," (LayoutLM model)"),AVe.forEach(t),mQo=i(V),wb=n(V,"LI",{});var LVe=s(wb);Pve=n(LVe,"STRONG",{});var KDt=s(Pve);cQo=r(KDt,"longformer"),KDt.forEach(t),fQo=r(LVe," \u2014 "),MW=n(LVe,"A",{href:!0});var eGt=s(MW);gQo=r(eGt,"LongformerForMaskedLM"),eGt.forEach(t),hQo=r(LVe," (Longformer model)"),LVe.forEach(t),uQo=i(V),Ab=n(V,"LI",{});var yVe=s(Ab);Bve=n(yVe,"STRONG",{});var oGt=s(Bve);pQo=r(oGt,"luke"),oGt.forEach(t),_Qo=r(yVe," \u2014 "),EW=n(yVe,"A",{href:!0});var rGt=s(EW);bQo=r(rGt,"LukeForMaskedLM"),rGt.forEach(t),vQo=r(yVe," (LUKE model)"),yVe.forEach(t),FQo=i(V),Lb=n(V,"LI",{});var xVe=s(Lb);Ive=n(xVe,"STRONG",{});var tGt=s(Ive);TQo=r(tGt,"lxmert"),tGt.forEach(t),MQo=r(xVe," \u2014 "),CW=n(xVe,"A",{href:!0});var aGt=s(CW);EQo=r(aGt,"LxmertForPreTraining"),aGt.forEach(t),CQo=r(xVe," (LXMERT model)"),xVe.forEach(t),wQo=i(V),yb=n(V,"LI",{});var $Ve=s(yb);Nve=n($Ve,"STRONG",{});var nGt=s(Nve);AQo=r(nGt,"megatron-bert"),nGt.forEach(t),LQo=r($Ve," \u2014 "),wW=n($Ve,"A",{href:!0});var sGt=s(wW);yQo=r(sGt,"MegatronBertForPreTraining"),sGt.forEach(t),xQo=r($Ve," (Megatron-BERT model)"),$Ve.forEach(t),$Qo=i(V),xb=n(V,"LI",{});var kVe=s(xb);qve=n(kVe,"STRONG",{});var lGt=s(qve);kQo=r(lGt,"mobilebert"),lGt.forEach(t),SQo=r(kVe," \u2014 "),AW=n(kVe,"A",{href:!0});var iGt=s(AW);RQo=r(iGt,"MobileBertForPreTraining"),iGt.forEach(t),PQo=r(kVe," (MobileBERT model)"),kVe.forEach(t),BQo=i(V),$b=n(V,"LI",{});var SVe=s($b);jve=n(SVe,"STRONG",{});var dGt=s(jve);IQo=r(dGt,"mpnet"),dGt.forEach(t),NQo=r(SVe," \u2014 "),LW=n(SVe,"A",{href:!0});var mGt=s(LW);qQo=r(mGt,"MPNetForMaskedLM"),mGt.forEach(t),jQo=r(SVe," (MPNet model)"),SVe.forEach(t),DQo=i(V),kb=n(V,"LI",{});var RVe=s(kb);Dve=n(RVe,"STRONG",{});var cGt=s(Dve);GQo=r(cGt,"mvp"),cGt.forEach(t),OQo=r(RVe," \u2014 "),yW=n(RVe,"A",{href:!0});var fGt=s(yW);VQo=r(fGt,"MvpForConditionalGeneration"),fGt.forEach(t),XQo=r(RVe," (MVP model)"),RVe.forEach(t),zQo=i(V),Sb=n(V,"LI",{});var PVe=s(Sb);Gve=n(PVe,"STRONG",{});var gGt=s(Gve);QQo=r(gGt,"nezha"),gGt.forEach(t),WQo=r(PVe," \u2014 "),xW=n(PVe,"A",{href:!0});var hGt=s(xW);UQo=r(hGt,"NezhaForPreTraining"),hGt.forEach(t),HQo=r(PVe," (Nezha model)"),PVe.forEach(t),JQo=i(V),Rb=n(V,"LI",{});var BVe=s(Rb);Ove=n(BVe,"STRONG",{});var uGt=s(Ove);YQo=r(uGt,"openai-gpt"),uGt.forEach(t),ZQo=r(BVe," \u2014 "),$W=n(BVe,"A",{href:!0});var pGt=s($W);KQo=r(pGt,"OpenAIGPTLMHeadModel"),pGt.forEach(t),eWo=r(BVe," (OpenAI GPT model)"),BVe.forEach(t),oWo=i(V),Pb=n(V,"LI",{});var IVe=s(Pb);Vve=n(IVe,"STRONG",{});var _Gt=s(Vve);rWo=r(_Gt,"retribert"),_Gt.forEach(t),tWo=r(IVe," \u2014 "),kW=n(IVe,"A",{href:!0});var bGt=s(kW);aWo=r(bGt,"RetriBertModel"),bGt.forEach(t),nWo=r(IVe," (RetriBERT model)"),IVe.forEach(t),sWo=i(V),Bb=n(V,"LI",{});var NVe=s(Bb);Xve=n(NVe,"STRONG",{});var vGt=s(Xve);lWo=r(vGt,"roberta"),vGt.forEach(t),iWo=r(NVe," \u2014 "),SW=n(NVe,"A",{href:!0});var FGt=s(SW);dWo=r(FGt,"RobertaForMaskedLM"),FGt.forEach(t),mWo=r(NVe," (RoBERTa model)"),NVe.forEach(t),cWo=i(V),Ib=n(V,"LI",{});var qVe=s(Ib);zve=n(qVe,"STRONG",{});var TGt=s(zve);fWo=r(TGt,"splinter"),TGt.forEach(t),gWo=r(qVe," \u2014 "),RW=n(qVe,"A",{href:!0});var MGt=s(RW);hWo=r(MGt,"SplinterForPreTraining"),MGt.forEach(t),uWo=r(qVe," (Splinter model)"),qVe.forEach(t),pWo=i(V),Nb=n(V,"LI",{});var jVe=s(Nb);Qve=n(jVe,"STRONG",{});var EGt=s(Qve);_Wo=r(EGt,"squeezebert"),EGt.forEach(t),bWo=r(jVe," \u2014 "),PW=n(jVe,"A",{href:!0});var CGt=s(PW);vWo=r(CGt,"SqueezeBertForMaskedLM"),CGt.forEach(t),FWo=r(jVe," (SqueezeBERT model)"),jVe.forEach(t),TWo=i(V),qb=n(V,"LI",{});var DVe=s(qb);Wve=n(DVe,"STRONG",{});var wGt=s(Wve);MWo=r(wGt,"t5"),wGt.forEach(t),EWo=r(DVe," \u2014 "),BW=n(DVe,"A",{href:!0});var AGt=s(BW);CWo=r(AGt,"T5ForConditionalGeneration"),AGt.forEach(t),wWo=r(DVe," (T5 model)"),DVe.forEach(t),AWo=i(V),jb=n(V,"LI",{});var GVe=s(jb);Uve=n(GVe,"STRONG",{});var LGt=s(Uve);LWo=r(LGt,"tapas"),LGt.forEach(t),yWo=r(GVe," \u2014 "),IW=n(GVe,"A",{href:!0});var yGt=s(IW);xWo=r(yGt,"TapasForMaskedLM"),yGt.forEach(t),$Wo=r(GVe," (TAPAS model)"),GVe.forEach(t),kWo=i(V),Db=n(V,"LI",{});var OVe=s(Db);Hve=n(OVe,"STRONG",{});var xGt=s(Hve);SWo=r(xGt,"transfo-xl"),xGt.forEach(t),RWo=r(OVe," \u2014 "),NW=n(OVe,"A",{href:!0});var $Gt=s(NW);PWo=r($Gt,"TransfoXLLMHeadModel"),$Gt.forEach(t),BWo=r(OVe," (Transformer-XL model)"),OVe.forEach(t),IWo=i(V),Gb=n(V,"LI",{});var VVe=s(Gb);Jve=n(VVe,"STRONG",{});var kGt=s(Jve);NWo=r(kGt,"unispeech"),kGt.forEach(t),qWo=r(VVe," \u2014 "),qW=n(VVe,"A",{href:!0});var SGt=s(qW);jWo=r(SGt,"UniSpeechForPreTraining"),SGt.forEach(t),DWo=r(VVe," (UniSpeech model)"),VVe.forEach(t),GWo=i(V),Ob=n(V,"LI",{});var XVe=s(Ob);Yve=n(XVe,"STRONG",{});var RGt=s(Yve);OWo=r(RGt,"unispeech-sat"),RGt.forEach(t),VWo=r(XVe," \u2014 "),jW=n(XVe,"A",{href:!0});var PGt=s(jW);XWo=r(PGt,"UniSpeechSatForPreTraining"),PGt.forEach(t),zWo=r(XVe," (UniSpeechSat model)"),XVe.forEach(t),QWo=i(V),Vb=n(V,"LI",{});var zVe=s(Vb);Zve=n(zVe,"STRONG",{});var BGt=s(Zve);WWo=r(BGt,"videomae"),BGt.forEach(t),UWo=r(zVe," \u2014 "),DW=n(zVe,"A",{href:!0});var IGt=s(DW);HWo=r(IGt,"VideoMAEForPreTraining"),IGt.forEach(t),JWo=r(zVe," (VideoMAE model)"),zVe.forEach(t),YWo=i(V),Xb=n(V,"LI",{});var QVe=s(Xb);Kve=n(QVe,"STRONG",{});var NGt=s(Kve);ZWo=r(NGt,"visual_bert"),NGt.forEach(t),KWo=r(QVe," \u2014 "),GW=n(QVe,"A",{href:!0});var qGt=s(GW);eUo=r(qGt,"VisualBertForPreTraining"),qGt.forEach(t),oUo=r(QVe," (VisualBERT model)"),QVe.forEach(t),rUo=i(V),zb=n(V,"LI",{});var WVe=s(zb);eFe=n(WVe,"STRONG",{});var jGt=s(eFe);tUo=r(jGt,"vit_mae"),jGt.forEach(t),aUo=r(WVe," \u2014 "),OW=n(WVe,"A",{href:!0});var DGt=s(OW);nUo=r(DGt,"ViTMAEForPreTraining"),DGt.forEach(t),sUo=r(WVe," (ViTMAE model)"),WVe.forEach(t),lUo=i(V),Qb=n(V,"LI",{});var UVe=s(Qb);oFe=n(UVe,"STRONG",{});var GGt=s(oFe);iUo=r(GGt,"wav2vec2"),GGt.forEach(t),dUo=r(UVe," \u2014 "),VW=n(UVe,"A",{href:!0});var OGt=s(VW);mUo=r(OGt,"Wav2Vec2ForPreTraining"),OGt.forEach(t),cUo=r(UVe," (Wav2Vec2 model)"),UVe.forEach(t),fUo=i(V),Wb=n(V,"LI",{});var HVe=s(Wb);rFe=n(HVe,"STRONG",{});var VGt=s(rFe);gUo=r(VGt,"wav2vec2-conformer"),VGt.forEach(t),hUo=r(HVe," \u2014 "),XW=n(HVe,"A",{href:!0});var XGt=s(XW);uUo=r(XGt,"Wav2Vec2ConformerForPreTraining"),XGt.forEach(t),pUo=r(HVe," (Wav2Vec2-Conformer model)"),HVe.forEach(t),_Uo=i(V),Ub=n(V,"LI",{});var JVe=s(Ub);tFe=n(JVe,"STRONG",{});var zGt=s(tFe);bUo=r(zGt,"xlm"),zGt.forEach(t),vUo=r(JVe," \u2014 "),zW=n(JVe,"A",{href:!0});var QGt=s(zW);FUo=r(QGt,"XLMWithLMHeadModel"),QGt.forEach(t),TUo=r(JVe," (XLM model)"),JVe.forEach(t),MUo=i(V),Hb=n(V,"LI",{});var YVe=s(Hb);aFe=n(YVe,"STRONG",{});var WGt=s(aFe);EUo=r(WGt,"xlm-roberta"),WGt.forEach(t),CUo=r(YVe," \u2014 "),QW=n(YVe,"A",{href:!0});var UGt=s(QW);wUo=r(UGt,"XLMRobertaForMaskedLM"),UGt.forEach(t),AUo=r(YVe," (XLM-RoBERTa model)"),YVe.forEach(t),LUo=i(V),Jb=n(V,"LI",{});var ZVe=s(Jb);nFe=n(ZVe,"STRONG",{});var HGt=s(nFe);yUo=r(HGt,"xlm-roberta-xl"),HGt.forEach(t),xUo=r(ZVe," \u2014 "),WW=n(ZVe,"A",{href:!0});var JGt=s(WW);$Uo=r(JGt,"XLMRobertaXLForMaskedLM"),JGt.forEach(t),kUo=r(ZVe," (XLM-RoBERTa-XL model)"),ZVe.forEach(t),SUo=i(V),Yb=n(V,"LI",{});var KVe=s(Yb);sFe=n(KVe,"STRONG",{});var YGt=s(sFe);RUo=r(YGt,"xlnet"),YGt.forEach(t),PUo=r(KVe," \u2014 "),UW=n(KVe,"A",{href:!0});var ZGt=s(UW);BUo=r(ZGt,"XLNetLMHeadModel"),ZGt.forEach(t),IUo=r(KVe," (XLNet model)"),KVe.forEach(t),V.forEach(t),NUo=i(ya),Zb=n(ya,"P",{});var eXe=s(Zb);qUo=r(eXe,"The model is set in evaluation mode by default using "),lFe=n(eXe,"CODE",{});var KGt=s(lFe);jUo=r(KGt,"model.eval()"),KGt.forEach(t),DUo=r(eXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),iFe=n(eXe,"CODE",{});var eOt=s(iFe);GUo=r(eOt,"model.train()"),eOt.forEach(t),eXe.forEach(t),OUo=i(ya),T(Kb.$$.fragment,ya),ya.forEach(t),jl.forEach(t),Oto=i(c),qd=n(c,"H2",{class:!0});var sso=s(qd);ev=n(sso,"A",{id:!0,class:!0,href:!0});var oOt=s(ev);dFe=n(oOt,"SPAN",{});var rOt=s(dFe);T(z$.$$.fragment,rOt),rOt.forEach(t),oOt.forEach(t),VUo=i(sso),mFe=n(sso,"SPAN",{});var tOt=s(mFe);XUo=r(tOt,"AutoModelForCausalLM"),tOt.forEach(t),sso.forEach(t),Vto=i(c),qo=n(c,"DIV",{class:!0});var Dl=s(qo);T(Q$.$$.fragment,Dl),zUo=i(Dl),jd=n(Dl,"P",{});var ime=s(jd);QUo=r(ime,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),HW=n(ime,"A",{href:!0});var aOt=s(HW);WUo=r(aOt,"from_pretrained()"),aOt.forEach(t),UUo=r(ime," class method or the "),JW=n(ime,"A",{href:!0});var nOt=s(JW);HUo=r(nOt,"from_config()"),nOt.forEach(t),JUo=r(ime,` class
method.`),ime.forEach(t),YUo=i(Dl),W$=n(Dl,"P",{});var lso=s(W$);ZUo=r(lso,"This class cannot be instantiated directly using "),cFe=n(lso,"CODE",{});var sOt=s(cFe);KUo=r(sOt,"__init__()"),sOt.forEach(t),eHo=r(lso," (throws an error)."),lso.forEach(t),oHo=i(Dl),Ct=n(Dl,"DIV",{class:!0});var a9=s(Ct);T(U$.$$.fragment,a9),rHo=i(a9),fFe=n(a9,"P",{});var lOt=s(fFe);tHo=r(lOt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),lOt.forEach(t),aHo=i(a9),Dd=n(a9,"P",{});var dme=s(Dd);nHo=r(dme,`Note:
Loading a model from its configuration file does `),gFe=n(dme,"STRONG",{});var iOt=s(gFe);sHo=r(iOt,"not"),iOt.forEach(t),lHo=r(dme,` load the model weights. It only affects the
model\u2019s configuration. Use `),YW=n(dme,"A",{href:!0});var dOt=s(YW);iHo=r(dOt,"from_pretrained()"),dOt.forEach(t),dHo=r(dme," to load the model weights."),dme.forEach(t),mHo=i(a9),T(ov.$$.fragment,a9),a9.forEach(t),cHo=i(Dl),oo=n(Dl,"DIV",{class:!0});var xa=s(oo);T(H$.$$.fragment,xa),fHo=i(xa),hFe=n(xa,"P",{});var mOt=s(hFe);gHo=r(mOt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),mOt.forEach(t),hHo=i(xa),ln=n(xa,"P",{});var n9=s(ln);uHo=r(n9,"The model class to instantiate is selected based on the "),uFe=n(n9,"CODE",{});var cOt=s(uFe);pHo=r(cOt,"model_type"),cOt.forEach(t),_Ho=r(n9,` property of the config object (either
passed as an argument or loaded from `),pFe=n(n9,"CODE",{});var fOt=s(pFe);bHo=r(fOt,"pretrained_model_name_or_path"),fOt.forEach(t),vHo=r(n9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_Fe=n(n9,"CODE",{});var gOt=s(_Fe);FHo=r(gOt,"pretrained_model_name_or_path"),gOt.forEach(t),THo=r(n9,":"),n9.forEach(t),MHo=i(xa),W=n(xa,"UL",{});var H=s(W);rv=n(H,"LI",{});var oXe=s(rv);bFe=n(oXe,"STRONG",{});var hOt=s(bFe);EHo=r(hOt,"bart"),hOt.forEach(t),CHo=r(oXe," \u2014 "),ZW=n(oXe,"A",{href:!0});var uOt=s(ZW);wHo=r(uOt,"BartForCausalLM"),uOt.forEach(t),AHo=r(oXe," (BART model)"),oXe.forEach(t),LHo=i(H),tv=n(H,"LI",{});var rXe=s(tv);vFe=n(rXe,"STRONG",{});var pOt=s(vFe);yHo=r(pOt,"bert"),pOt.forEach(t),xHo=r(rXe," \u2014 "),KW=n(rXe,"A",{href:!0});var _Ot=s(KW);$Ho=r(_Ot,"BertLMHeadModel"),_Ot.forEach(t),kHo=r(rXe," (BERT model)"),rXe.forEach(t),SHo=i(H),av=n(H,"LI",{});var tXe=s(av);FFe=n(tXe,"STRONG",{});var bOt=s(FFe);RHo=r(bOt,"bert-generation"),bOt.forEach(t),PHo=r(tXe," \u2014 "),eU=n(tXe,"A",{href:!0});var vOt=s(eU);BHo=r(vOt,"BertGenerationDecoder"),vOt.forEach(t),IHo=r(tXe," (Bert Generation model)"),tXe.forEach(t),NHo=i(H),nv=n(H,"LI",{});var aXe=s(nv);TFe=n(aXe,"STRONG",{});var FOt=s(TFe);qHo=r(FOt,"big_bird"),FOt.forEach(t),jHo=r(aXe," \u2014 "),oU=n(aXe,"A",{href:!0});var TOt=s(oU);DHo=r(TOt,"BigBirdForCausalLM"),TOt.forEach(t),GHo=r(aXe," (BigBird model)"),aXe.forEach(t),OHo=i(H),sv=n(H,"LI",{});var nXe=s(sv);MFe=n(nXe,"STRONG",{});var MOt=s(MFe);VHo=r(MOt,"bigbird_pegasus"),MOt.forEach(t),XHo=r(nXe," \u2014 "),rU=n(nXe,"A",{href:!0});var EOt=s(rU);zHo=r(EOt,"BigBirdPegasusForCausalLM"),EOt.forEach(t),QHo=r(nXe," (BigBird-Pegasus model)"),nXe.forEach(t),WHo=i(H),lv=n(H,"LI",{});var sXe=s(lv);EFe=n(sXe,"STRONG",{});var COt=s(EFe);UHo=r(COt,"blenderbot"),COt.forEach(t),HHo=r(sXe," \u2014 "),tU=n(sXe,"A",{href:!0});var wOt=s(tU);JHo=r(wOt,"BlenderbotForCausalLM"),wOt.forEach(t),YHo=r(sXe," (Blenderbot model)"),sXe.forEach(t),ZHo=i(H),iv=n(H,"LI",{});var lXe=s(iv);CFe=n(lXe,"STRONG",{});var AOt=s(CFe);KHo=r(AOt,"blenderbot-small"),AOt.forEach(t),eJo=r(lXe," \u2014 "),aU=n(lXe,"A",{href:!0});var LOt=s(aU);oJo=r(LOt,"BlenderbotSmallForCausalLM"),LOt.forEach(t),rJo=r(lXe," (BlenderbotSmall model)"),lXe.forEach(t),tJo=i(H),dv=n(H,"LI",{});var iXe=s(dv);wFe=n(iXe,"STRONG",{});var yOt=s(wFe);aJo=r(yOt,"bloom"),yOt.forEach(t),nJo=r(iXe," \u2014 "),nU=n(iXe,"A",{href:!0});var xOt=s(nU);sJo=r(xOt,"BloomForCausalLM"),xOt.forEach(t),lJo=r(iXe," (BLOOM model)"),iXe.forEach(t),iJo=i(H),mv=n(H,"LI",{});var dXe=s(mv);AFe=n(dXe,"STRONG",{});var $Ot=s(AFe);dJo=r($Ot,"camembert"),$Ot.forEach(t),mJo=r(dXe," \u2014 "),sU=n(dXe,"A",{href:!0});var kOt=s(sU);cJo=r(kOt,"CamembertForCausalLM"),kOt.forEach(t),fJo=r(dXe," (CamemBERT model)"),dXe.forEach(t),gJo=i(H),cv=n(H,"LI",{});var mXe=s(cv);LFe=n(mXe,"STRONG",{});var SOt=s(LFe);hJo=r(SOt,"codegen"),SOt.forEach(t),uJo=r(mXe," \u2014 "),lU=n(mXe,"A",{href:!0});var ROt=s(lU);pJo=r(ROt,"CodeGenForCausalLM"),ROt.forEach(t),_Jo=r(mXe," (CodeGen model)"),mXe.forEach(t),bJo=i(H),fv=n(H,"LI",{});var cXe=s(fv);yFe=n(cXe,"STRONG",{});var POt=s(yFe);vJo=r(POt,"ctrl"),POt.forEach(t),FJo=r(cXe," \u2014 "),iU=n(cXe,"A",{href:!0});var BOt=s(iU);TJo=r(BOt,"CTRLLMHeadModel"),BOt.forEach(t),MJo=r(cXe," (CTRL model)"),cXe.forEach(t),EJo=i(H),gv=n(H,"LI",{});var fXe=s(gv);xFe=n(fXe,"STRONG",{});var IOt=s(xFe);CJo=r(IOt,"data2vec-text"),IOt.forEach(t),wJo=r(fXe," \u2014 "),dU=n(fXe,"A",{href:!0});var NOt=s(dU);AJo=r(NOt,"Data2VecTextForCausalLM"),NOt.forEach(t),LJo=r(fXe," (Data2VecText model)"),fXe.forEach(t),yJo=i(H),hv=n(H,"LI",{});var gXe=s(hv);$Fe=n(gXe,"STRONG",{});var qOt=s($Fe);xJo=r(qOt,"electra"),qOt.forEach(t),$Jo=r(gXe," \u2014 "),mU=n(gXe,"A",{href:!0});var jOt=s(mU);kJo=r(jOt,"ElectraForCausalLM"),jOt.forEach(t),SJo=r(gXe," (ELECTRA model)"),gXe.forEach(t),RJo=i(H),uv=n(H,"LI",{});var hXe=s(uv);kFe=n(hXe,"STRONG",{});var DOt=s(kFe);PJo=r(DOt,"ernie"),DOt.forEach(t),BJo=r(hXe," \u2014 "),cU=n(hXe,"A",{href:!0});var GOt=s(cU);IJo=r(GOt,"ErnieForCausalLM"),GOt.forEach(t),NJo=r(hXe," (ERNIE model)"),hXe.forEach(t),qJo=i(H),pv=n(H,"LI",{});var uXe=s(pv);SFe=n(uXe,"STRONG",{});var OOt=s(SFe);jJo=r(OOt,"gpt2"),OOt.forEach(t),DJo=r(uXe," \u2014 "),fU=n(uXe,"A",{href:!0});var VOt=s(fU);GJo=r(VOt,"GPT2LMHeadModel"),VOt.forEach(t),OJo=r(uXe," (OpenAI GPT-2 model)"),uXe.forEach(t),VJo=i(H),_v=n(H,"LI",{});var pXe=s(_v);RFe=n(pXe,"STRONG",{});var XOt=s(RFe);XJo=r(XOt,"gpt_neo"),XOt.forEach(t),zJo=r(pXe," \u2014 "),gU=n(pXe,"A",{href:!0});var zOt=s(gU);QJo=r(zOt,"GPTNeoForCausalLM"),zOt.forEach(t),WJo=r(pXe," (GPT Neo model)"),pXe.forEach(t),UJo=i(H),bv=n(H,"LI",{});var _Xe=s(bv);PFe=n(_Xe,"STRONG",{});var QOt=s(PFe);HJo=r(QOt,"gpt_neox"),QOt.forEach(t),JJo=r(_Xe," \u2014 "),hU=n(_Xe,"A",{href:!0});var WOt=s(hU);YJo=r(WOt,"GPTNeoXForCausalLM"),WOt.forEach(t),ZJo=r(_Xe," (GPT NeoX model)"),_Xe.forEach(t),KJo=i(H),vv=n(H,"LI",{});var bXe=s(vv);BFe=n(bXe,"STRONG",{});var UOt=s(BFe);eYo=r(UOt,"gpt_neox_japanese"),UOt.forEach(t),oYo=r(bXe," \u2014 "),uU=n(bXe,"A",{href:!0});var HOt=s(uU);rYo=r(HOt,"GPTNeoXJapaneseForCausalLM"),HOt.forEach(t),tYo=r(bXe," (GPT NeoX Japanese model)"),bXe.forEach(t),aYo=i(H),Fv=n(H,"LI",{});var vXe=s(Fv);IFe=n(vXe,"STRONG",{});var JOt=s(IFe);nYo=r(JOt,"gptj"),JOt.forEach(t),sYo=r(vXe," \u2014 "),pU=n(vXe,"A",{href:!0});var YOt=s(pU);lYo=r(YOt,"GPTJForCausalLM"),YOt.forEach(t),iYo=r(vXe," (GPT-J model)"),vXe.forEach(t),dYo=i(H),Tv=n(H,"LI",{});var FXe=s(Tv);NFe=n(FXe,"STRONG",{});var ZOt=s(NFe);mYo=r(ZOt,"marian"),ZOt.forEach(t),cYo=r(FXe," \u2014 "),_U=n(FXe,"A",{href:!0});var KOt=s(_U);fYo=r(KOt,"MarianForCausalLM"),KOt.forEach(t),gYo=r(FXe," (Marian model)"),FXe.forEach(t),hYo=i(H),Mv=n(H,"LI",{});var TXe=s(Mv);qFe=n(TXe,"STRONG",{});var eVt=s(qFe);uYo=r(eVt,"mbart"),eVt.forEach(t),pYo=r(TXe," \u2014 "),bU=n(TXe,"A",{href:!0});var oVt=s(bU);_Yo=r(oVt,"MBartForCausalLM"),oVt.forEach(t),bYo=r(TXe," (mBART model)"),TXe.forEach(t),vYo=i(H),Ev=n(H,"LI",{});var MXe=s(Ev);jFe=n(MXe,"STRONG",{});var rVt=s(jFe);FYo=r(rVt,"megatron-bert"),rVt.forEach(t),TYo=r(MXe," \u2014 "),vU=n(MXe,"A",{href:!0});var tVt=s(vU);MYo=r(tVt,"MegatronBertForCausalLM"),tVt.forEach(t),EYo=r(MXe," (Megatron-BERT model)"),MXe.forEach(t),CYo=i(H),Cv=n(H,"LI",{});var EXe=s(Cv);DFe=n(EXe,"STRONG",{});var aVt=s(DFe);wYo=r(aVt,"mvp"),aVt.forEach(t),AYo=r(EXe," \u2014 "),FU=n(EXe,"A",{href:!0});var nVt=s(FU);LYo=r(nVt,"MvpForCausalLM"),nVt.forEach(t),yYo=r(EXe," (MVP model)"),EXe.forEach(t),xYo=i(H),wv=n(H,"LI",{});var CXe=s(wv);GFe=n(CXe,"STRONG",{});var sVt=s(GFe);$Yo=r(sVt,"openai-gpt"),sVt.forEach(t),kYo=r(CXe," \u2014 "),TU=n(CXe,"A",{href:!0});var lVt=s(TU);SYo=r(lVt,"OpenAIGPTLMHeadModel"),lVt.forEach(t),RYo=r(CXe," (OpenAI GPT model)"),CXe.forEach(t),PYo=i(H),Av=n(H,"LI",{});var wXe=s(Av);OFe=n(wXe,"STRONG",{});var iVt=s(OFe);BYo=r(iVt,"opt"),iVt.forEach(t),IYo=r(wXe," \u2014 "),MU=n(wXe,"A",{href:!0});var dVt=s(MU);NYo=r(dVt,"OPTForCausalLM"),dVt.forEach(t),qYo=r(wXe," (OPT model)"),wXe.forEach(t),jYo=i(H),Lv=n(H,"LI",{});var AXe=s(Lv);VFe=n(AXe,"STRONG",{});var mVt=s(VFe);DYo=r(mVt,"pegasus"),mVt.forEach(t),GYo=r(AXe," \u2014 "),EU=n(AXe,"A",{href:!0});var cVt=s(EU);OYo=r(cVt,"PegasusForCausalLM"),cVt.forEach(t),VYo=r(AXe," (Pegasus model)"),AXe.forEach(t),XYo=i(H),yv=n(H,"LI",{});var LXe=s(yv);XFe=n(LXe,"STRONG",{});var fVt=s(XFe);zYo=r(fVt,"plbart"),fVt.forEach(t),QYo=r(LXe," \u2014 "),CU=n(LXe,"A",{href:!0});var gVt=s(CU);WYo=r(gVt,"PLBartForCausalLM"),gVt.forEach(t),UYo=r(LXe," (PLBart model)"),LXe.forEach(t),HYo=i(H),xv=n(H,"LI",{});var yXe=s(xv);zFe=n(yXe,"STRONG",{});var hVt=s(zFe);JYo=r(hVt,"prophetnet"),hVt.forEach(t),YYo=r(yXe," \u2014 "),wU=n(yXe,"A",{href:!0});var uVt=s(wU);ZYo=r(uVt,"ProphetNetForCausalLM"),uVt.forEach(t),KYo=r(yXe," (ProphetNet model)"),yXe.forEach(t),eZo=i(H),$v=n(H,"LI",{});var xXe=s($v);QFe=n(xXe,"STRONG",{});var pVt=s(QFe);oZo=r(pVt,"qdqbert"),pVt.forEach(t),rZo=r(xXe," \u2014 "),AU=n(xXe,"A",{href:!0});var _Vt=s(AU);tZo=r(_Vt,"QDQBertLMHeadModel"),_Vt.forEach(t),aZo=r(xXe," (QDQBert model)"),xXe.forEach(t),nZo=i(H),kv=n(H,"LI",{});var $Xe=s(kv);WFe=n($Xe,"STRONG",{});var bVt=s(WFe);sZo=r(bVt,"reformer"),bVt.forEach(t),lZo=r($Xe," \u2014 "),LU=n($Xe,"A",{href:!0});var vVt=s(LU);iZo=r(vVt,"ReformerModelWithLMHead"),vVt.forEach(t),dZo=r($Xe," (Reformer model)"),$Xe.forEach(t),mZo=i(H),Sv=n(H,"LI",{});var kXe=s(Sv);UFe=n(kXe,"STRONG",{});var FVt=s(UFe);cZo=r(FVt,"rembert"),FVt.forEach(t),fZo=r(kXe," \u2014 "),yU=n(kXe,"A",{href:!0});var TVt=s(yU);gZo=r(TVt,"RemBertForCausalLM"),TVt.forEach(t),hZo=r(kXe," (RemBERT model)"),kXe.forEach(t),uZo=i(H),Rv=n(H,"LI",{});var SXe=s(Rv);HFe=n(SXe,"STRONG",{});var MVt=s(HFe);pZo=r(MVt,"roberta"),MVt.forEach(t),_Zo=r(SXe," \u2014 "),xU=n(SXe,"A",{href:!0});var EVt=s(xU);bZo=r(EVt,"RobertaForCausalLM"),EVt.forEach(t),vZo=r(SXe," (RoBERTa model)"),SXe.forEach(t),FZo=i(H),Pv=n(H,"LI",{});var RXe=s(Pv);JFe=n(RXe,"STRONG",{});var CVt=s(JFe);TZo=r(CVt,"roformer"),CVt.forEach(t),MZo=r(RXe," \u2014 "),$U=n(RXe,"A",{href:!0});var wVt=s($U);EZo=r(wVt,"RoFormerForCausalLM"),wVt.forEach(t),CZo=r(RXe," (RoFormer model)"),RXe.forEach(t),wZo=i(H),Bv=n(H,"LI",{});var PXe=s(Bv);YFe=n(PXe,"STRONG",{});var AVt=s(YFe);AZo=r(AVt,"speech_to_text_2"),AVt.forEach(t),LZo=r(PXe," \u2014 "),kU=n(PXe,"A",{href:!0});var LVt=s(kU);yZo=r(LVt,"Speech2Text2ForCausalLM"),LVt.forEach(t),xZo=r(PXe," (Speech2Text2 model)"),PXe.forEach(t),$Zo=i(H),Iv=n(H,"LI",{});var BXe=s(Iv);ZFe=n(BXe,"STRONG",{});var yVt=s(ZFe);kZo=r(yVt,"transfo-xl"),yVt.forEach(t),SZo=r(BXe," \u2014 "),SU=n(BXe,"A",{href:!0});var xVt=s(SU);RZo=r(xVt,"TransfoXLLMHeadModel"),xVt.forEach(t),PZo=r(BXe," (Transformer-XL model)"),BXe.forEach(t),BZo=i(H),Nv=n(H,"LI",{});var IXe=s(Nv);KFe=n(IXe,"STRONG",{});var $Vt=s(KFe);IZo=r($Vt,"trocr"),$Vt.forEach(t),NZo=r(IXe," \u2014 "),RU=n(IXe,"A",{href:!0});var kVt=s(RU);qZo=r(kVt,"TrOCRForCausalLM"),kVt.forEach(t),jZo=r(IXe," (TrOCR model)"),IXe.forEach(t),DZo=i(H),qv=n(H,"LI",{});var NXe=s(qv);eTe=n(NXe,"STRONG",{});var SVt=s(eTe);GZo=r(SVt,"xglm"),SVt.forEach(t),OZo=r(NXe," \u2014 "),PU=n(NXe,"A",{href:!0});var RVt=s(PU);VZo=r(RVt,"XGLMForCausalLM"),RVt.forEach(t),XZo=r(NXe," (XGLM model)"),NXe.forEach(t),zZo=i(H),jv=n(H,"LI",{});var qXe=s(jv);oTe=n(qXe,"STRONG",{});var PVt=s(oTe);QZo=r(PVt,"xlm"),PVt.forEach(t),WZo=r(qXe," \u2014 "),BU=n(qXe,"A",{href:!0});var BVt=s(BU);UZo=r(BVt,"XLMWithLMHeadModel"),BVt.forEach(t),HZo=r(qXe," (XLM model)"),qXe.forEach(t),JZo=i(H),Dv=n(H,"LI",{});var jXe=s(Dv);rTe=n(jXe,"STRONG",{});var IVt=s(rTe);YZo=r(IVt,"xlm-prophetnet"),IVt.forEach(t),ZZo=r(jXe," \u2014 "),IU=n(jXe,"A",{href:!0});var NVt=s(IU);KZo=r(NVt,"XLMProphetNetForCausalLM"),NVt.forEach(t),eKo=r(jXe," (XLM-ProphetNet model)"),jXe.forEach(t),oKo=i(H),Gv=n(H,"LI",{});var DXe=s(Gv);tTe=n(DXe,"STRONG",{});var qVt=s(tTe);rKo=r(qVt,"xlm-roberta"),qVt.forEach(t),tKo=r(DXe," \u2014 "),NU=n(DXe,"A",{href:!0});var jVt=s(NU);aKo=r(jVt,"XLMRobertaForCausalLM"),jVt.forEach(t),nKo=r(DXe," (XLM-RoBERTa model)"),DXe.forEach(t),sKo=i(H),Ov=n(H,"LI",{});var GXe=s(Ov);aTe=n(GXe,"STRONG",{});var DVt=s(aTe);lKo=r(DVt,"xlm-roberta-xl"),DVt.forEach(t),iKo=r(GXe," \u2014 "),qU=n(GXe,"A",{href:!0});var GVt=s(qU);dKo=r(GVt,"XLMRobertaXLForCausalLM"),GVt.forEach(t),mKo=r(GXe," (XLM-RoBERTa-XL model)"),GXe.forEach(t),cKo=i(H),Vv=n(H,"LI",{});var OXe=s(Vv);nTe=n(OXe,"STRONG",{});var OVt=s(nTe);fKo=r(OVt,"xlnet"),OVt.forEach(t),gKo=r(OXe," \u2014 "),jU=n(OXe,"A",{href:!0});var VVt=s(jU);hKo=r(VVt,"XLNetLMHeadModel"),VVt.forEach(t),uKo=r(OXe," (XLNet model)"),OXe.forEach(t),H.forEach(t),pKo=i(xa),Xv=n(xa,"P",{});var VXe=s(Xv);_Ko=r(VXe,"The model is set in evaluation mode by default using "),sTe=n(VXe,"CODE",{});var XVt=s(sTe);bKo=r(XVt,"model.eval()"),XVt.forEach(t),vKo=r(VXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),lTe=n(VXe,"CODE",{});var zVt=s(lTe);FKo=r(zVt,"model.train()"),zVt.forEach(t),VXe.forEach(t),TKo=i(xa),T(zv.$$.fragment,xa),xa.forEach(t),Dl.forEach(t),Xto=i(c),Gd=n(c,"H2",{class:!0});var iso=s(Gd);Qv=n(iso,"A",{id:!0,class:!0,href:!0});var QVt=s(Qv);iTe=n(QVt,"SPAN",{});var WVt=s(iTe);T(J$.$$.fragment,WVt),WVt.forEach(t),QVt.forEach(t),MKo=i(iso),dTe=n(iso,"SPAN",{});var UVt=s(dTe);EKo=r(UVt,"AutoModelForDepthEstimation"),UVt.forEach(t),iso.forEach(t),zto=i(c),jo=n(c,"DIV",{class:!0});var Gl=s(jo);T(Y$.$$.fragment,Gl),CKo=i(Gl),Od=n(Gl,"P",{});var mme=s(Od);wKo=r(mme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a depth estimation head) when created
with the `),DU=n(mme,"A",{href:!0});var HVt=s(DU);AKo=r(HVt,"from_pretrained()"),HVt.forEach(t),LKo=r(mme," class method or the "),GU=n(mme,"A",{href:!0});var JVt=s(GU);yKo=r(JVt,"from_config()"),JVt.forEach(t),xKo=r(mme,` class
method.`),mme.forEach(t),$Ko=i(Gl),Z$=n(Gl,"P",{});var dso=s(Z$);kKo=r(dso,"This class cannot be instantiated directly using "),mTe=n(dso,"CODE",{});var YVt=s(mTe);SKo=r(YVt,"__init__()"),YVt.forEach(t),RKo=r(dso," (throws an error)."),dso.forEach(t),PKo=i(Gl),wt=n(Gl,"DIV",{class:!0});var s9=s(wt);T(K$.$$.fragment,s9),BKo=i(s9),cTe=n(s9,"P",{});var ZVt=s(cTe);IKo=r(ZVt,"Instantiates one of the model classes of the library (with a depth estimation head) from a configuration."),ZVt.forEach(t),NKo=i(s9),Vd=n(s9,"P",{});var cme=s(Vd);qKo=r(cme,`Note:
Loading a model from its configuration file does `),fTe=n(cme,"STRONG",{});var KVt=s(fTe);jKo=r(KVt,"not"),KVt.forEach(t),DKo=r(cme,` load the model weights. It only affects the
model\u2019s configuration. Use `),OU=n(cme,"A",{href:!0});var eXt=s(OU);GKo=r(eXt,"from_pretrained()"),eXt.forEach(t),OKo=r(cme," to load the model weights."),cme.forEach(t),VKo=i(s9),T(Wv.$$.fragment,s9),s9.forEach(t),XKo=i(Gl),ro=n(Gl,"DIV",{class:!0});var $a=s(ro);T(ek.$$.fragment,$a),zKo=i($a),gTe=n($a,"P",{});var oXt=s(gTe);QKo=r(oXt,"Instantiate one of the model classes of the library (with a depth estimation head) from a pretrained model."),oXt.forEach(t),WKo=i($a),dn=n($a,"P",{});var l9=s(dn);UKo=r(l9,"The model class to instantiate is selected based on the "),hTe=n(l9,"CODE",{});var rXt=s(hTe);HKo=r(rXt,"model_type"),rXt.forEach(t),JKo=r(l9,` property of the config object (either
passed as an argument or loaded from `),uTe=n(l9,"CODE",{});var tXt=s(uTe);YKo=r(tXt,"pretrained_model_name_or_path"),tXt.forEach(t),ZKo=r(l9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pTe=n(l9,"CODE",{});var aXt=s(pTe);KKo=r(aXt,"pretrained_model_name_or_path"),aXt.forEach(t),eer=r(l9,":"),l9.forEach(t),oer=i($a),ok=n($a,"UL",{});var mso=s(ok);Uv=n(mso,"LI",{});var XXe=s(Uv);_Te=n(XXe,"STRONG",{});var nXt=s(_Te);rer=r(nXt,"dpt"),nXt.forEach(t),ter=r(XXe," \u2014 "),VU=n(XXe,"A",{href:!0});var sXt=s(VU);aer=r(sXt,"DPTForDepthEstimation"),sXt.forEach(t),ner=r(XXe," (DPT model)"),XXe.forEach(t),ser=i(mso),Hv=n(mso,"LI",{});var zXe=s(Hv);bTe=n(zXe,"STRONG",{});var lXt=s(bTe);ler=r(lXt,"glpn"),lXt.forEach(t),ier=r(zXe," \u2014 "),XU=n(zXe,"A",{href:!0});var iXt=s(XU);der=r(iXt,"GLPNForDepthEstimation"),iXt.forEach(t),mer=r(zXe," (GLPN model)"),zXe.forEach(t),mso.forEach(t),cer=i($a),Jv=n($a,"P",{});var QXe=s(Jv);fer=r(QXe,"The model is set in evaluation mode by default using "),vTe=n(QXe,"CODE",{});var dXt=s(vTe);ger=r(dXt,"model.eval()"),dXt.forEach(t),her=r(QXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),FTe=n(QXe,"CODE",{});var mXt=s(FTe);uer=r(mXt,"model.train()"),mXt.forEach(t),QXe.forEach(t),per=i($a),T(Yv.$$.fragment,$a),$a.forEach(t),Gl.forEach(t),Qto=i(c),Xd=n(c,"H2",{class:!0});var cso=s(Xd);Zv=n(cso,"A",{id:!0,class:!0,href:!0});var cXt=s(Zv);TTe=n(cXt,"SPAN",{});var fXt=s(TTe);T(rk.$$.fragment,fXt),fXt.forEach(t),cXt.forEach(t),_er=i(cso),MTe=n(cso,"SPAN",{});var gXt=s(MTe);ber=r(gXt,"AutoModelForMaskedLM"),gXt.forEach(t),cso.forEach(t),Wto=i(c),Do=n(c,"DIV",{class:!0});var Ol=s(Do);T(tk.$$.fragment,Ol),ver=i(Ol),zd=n(Ol,"P",{});var fme=s(zd);Fer=r(fme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),zU=n(fme,"A",{href:!0});var hXt=s(zU);Ter=r(hXt,"from_pretrained()"),hXt.forEach(t),Mer=r(fme," class method or the "),QU=n(fme,"A",{href:!0});var uXt=s(QU);Eer=r(uXt,"from_config()"),uXt.forEach(t),Cer=r(fme,` class
method.`),fme.forEach(t),wer=i(Ol),ak=n(Ol,"P",{});var fso=s(ak);Aer=r(fso,"This class cannot be instantiated directly using "),ETe=n(fso,"CODE",{});var pXt=s(ETe);Ler=r(pXt,"__init__()"),pXt.forEach(t),yer=r(fso," (throws an error)."),fso.forEach(t),xer=i(Ol),At=n(Ol,"DIV",{class:!0});var i9=s(At);T(nk.$$.fragment,i9),$er=i(i9),CTe=n(i9,"P",{});var _Xt=s(CTe);ker=r(_Xt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),_Xt.forEach(t),Ser=i(i9),Qd=n(i9,"P",{});var gme=s(Qd);Rer=r(gme,`Note:
Loading a model from its configuration file does `),wTe=n(gme,"STRONG",{});var bXt=s(wTe);Per=r(bXt,"not"),bXt.forEach(t),Ber=r(gme,` load the model weights. It only affects the
model\u2019s configuration. Use `),WU=n(gme,"A",{href:!0});var vXt=s(WU);Ier=r(vXt,"from_pretrained()"),vXt.forEach(t),Ner=r(gme," to load the model weights."),gme.forEach(t),qer=i(i9),T(Kv.$$.fragment,i9),i9.forEach(t),jer=i(Ol),to=n(Ol,"DIV",{class:!0});var ka=s(to);T(sk.$$.fragment,ka),Der=i(ka),ATe=n(ka,"P",{});var FXt=s(ATe);Ger=r(FXt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),FXt.forEach(t),Oer=i(ka),mn=n(ka,"P",{});var d9=s(mn);Ver=r(d9,"The model class to instantiate is selected based on the "),LTe=n(d9,"CODE",{});var TXt=s(LTe);Xer=r(TXt,"model_type"),TXt.forEach(t),zer=r(d9,` property of the config object (either
passed as an argument or loaded from `),yTe=n(d9,"CODE",{});var MXt=s(yTe);Qer=r(MXt,"pretrained_model_name_or_path"),MXt.forEach(t),Wer=r(d9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xTe=n(d9,"CODE",{});var EXt=s(xTe);Uer=r(EXt,"pretrained_model_name_or_path"),EXt.forEach(t),Her=r(d9,":"),d9.forEach(t),Jer=i(ka),Y=n(ka,"UL",{});var Z=s(Y);eF=n(Z,"LI",{});var WXe=s(eF);$Te=n(WXe,"STRONG",{});var CXt=s($Te);Yer=r(CXt,"albert"),CXt.forEach(t),Zer=r(WXe," \u2014 "),UU=n(WXe,"A",{href:!0});var wXt=s(UU);Ker=r(wXt,"AlbertForMaskedLM"),wXt.forEach(t),eor=r(WXe," (ALBERT model)"),WXe.forEach(t),oor=i(Z),oF=n(Z,"LI",{});var UXe=s(oF);kTe=n(UXe,"STRONG",{});var AXt=s(kTe);ror=r(AXt,"bart"),AXt.forEach(t),tor=r(UXe," \u2014 "),HU=n(UXe,"A",{href:!0});var LXt=s(HU);aor=r(LXt,"BartForConditionalGeneration"),LXt.forEach(t),nor=r(UXe," (BART model)"),UXe.forEach(t),sor=i(Z),rF=n(Z,"LI",{});var HXe=s(rF);STe=n(HXe,"STRONG",{});var yXt=s(STe);lor=r(yXt,"bert"),yXt.forEach(t),ior=r(HXe," \u2014 "),JU=n(HXe,"A",{href:!0});var xXt=s(JU);dor=r(xXt,"BertForMaskedLM"),xXt.forEach(t),mor=r(HXe," (BERT model)"),HXe.forEach(t),cor=i(Z),tF=n(Z,"LI",{});var JXe=s(tF);RTe=n(JXe,"STRONG",{});var $Xt=s(RTe);gor=r($Xt,"big_bird"),$Xt.forEach(t),hor=r(JXe," \u2014 "),YU=n(JXe,"A",{href:!0});var kXt=s(YU);uor=r(kXt,"BigBirdForMaskedLM"),kXt.forEach(t),por=r(JXe," (BigBird model)"),JXe.forEach(t),_or=i(Z),aF=n(Z,"LI",{});var YXe=s(aF);PTe=n(YXe,"STRONG",{});var SXt=s(PTe);bor=r(SXt,"camembert"),SXt.forEach(t),vor=r(YXe," \u2014 "),ZU=n(YXe,"A",{href:!0});var RXt=s(ZU);For=r(RXt,"CamembertForMaskedLM"),RXt.forEach(t),Tor=r(YXe," (CamemBERT model)"),YXe.forEach(t),Mor=i(Z),nF=n(Z,"LI",{});var ZXe=s(nF);BTe=n(ZXe,"STRONG",{});var PXt=s(BTe);Eor=r(PXt,"convbert"),PXt.forEach(t),Cor=r(ZXe," \u2014 "),KU=n(ZXe,"A",{href:!0});var BXt=s(KU);wor=r(BXt,"ConvBertForMaskedLM"),BXt.forEach(t),Aor=r(ZXe," (ConvBERT model)"),ZXe.forEach(t),Lor=i(Z),sF=n(Z,"LI",{});var KXe=s(sF);ITe=n(KXe,"STRONG",{});var IXt=s(ITe);yor=r(IXt,"data2vec-text"),IXt.forEach(t),xor=r(KXe," \u2014 "),eH=n(KXe,"A",{href:!0});var NXt=s(eH);$or=r(NXt,"Data2VecTextForMaskedLM"),NXt.forEach(t),kor=r(KXe," (Data2VecText model)"),KXe.forEach(t),Sor=i(Z),lF=n(Z,"LI",{});var eze=s(lF);NTe=n(eze,"STRONG",{});var qXt=s(NTe);Ror=r(qXt,"deberta"),qXt.forEach(t),Por=r(eze," \u2014 "),oH=n(eze,"A",{href:!0});var jXt=s(oH);Bor=r(jXt,"DebertaForMaskedLM"),jXt.forEach(t),Ior=r(eze," (DeBERTa model)"),eze.forEach(t),Nor=i(Z),iF=n(Z,"LI",{});var oze=s(iF);qTe=n(oze,"STRONG",{});var DXt=s(qTe);qor=r(DXt,"deberta-v2"),DXt.forEach(t),jor=r(oze," \u2014 "),rH=n(oze,"A",{href:!0});var GXt=s(rH);Dor=r(GXt,"DebertaV2ForMaskedLM"),GXt.forEach(t),Gor=r(oze," (DeBERTa-v2 model)"),oze.forEach(t),Oor=i(Z),dF=n(Z,"LI",{});var rze=s(dF);jTe=n(rze,"STRONG",{});var OXt=s(jTe);Vor=r(OXt,"distilbert"),OXt.forEach(t),Xor=r(rze," \u2014 "),tH=n(rze,"A",{href:!0});var VXt=s(tH);zor=r(VXt,"DistilBertForMaskedLM"),VXt.forEach(t),Qor=r(rze," (DistilBERT model)"),rze.forEach(t),Wor=i(Z),mF=n(Z,"LI",{});var tze=s(mF);DTe=n(tze,"STRONG",{});var XXt=s(DTe);Uor=r(XXt,"electra"),XXt.forEach(t),Hor=r(tze," \u2014 "),aH=n(tze,"A",{href:!0});var zXt=s(aH);Jor=r(zXt,"ElectraForMaskedLM"),zXt.forEach(t),Yor=r(tze," (ELECTRA model)"),tze.forEach(t),Zor=i(Z),cF=n(Z,"LI",{});var aze=s(cF);GTe=n(aze,"STRONG",{});var QXt=s(GTe);Kor=r(QXt,"ernie"),QXt.forEach(t),err=r(aze," \u2014 "),nH=n(aze,"A",{href:!0});var WXt=s(nH);orr=r(WXt,"ErnieForMaskedLM"),WXt.forEach(t),rrr=r(aze," (ERNIE model)"),aze.forEach(t),trr=i(Z),fF=n(Z,"LI",{});var nze=s(fF);OTe=n(nze,"STRONG",{});var UXt=s(OTe);arr=r(UXt,"flaubert"),UXt.forEach(t),nrr=r(nze," \u2014 "),sH=n(nze,"A",{href:!0});var HXt=s(sH);srr=r(HXt,"FlaubertWithLMHeadModel"),HXt.forEach(t),lrr=r(nze," (FlauBERT model)"),nze.forEach(t),irr=i(Z),gF=n(Z,"LI",{});var sze=s(gF);VTe=n(sze,"STRONG",{});var JXt=s(VTe);drr=r(JXt,"fnet"),JXt.forEach(t),mrr=r(sze," \u2014 "),lH=n(sze,"A",{href:!0});var YXt=s(lH);crr=r(YXt,"FNetForMaskedLM"),YXt.forEach(t),frr=r(sze," (FNet model)"),sze.forEach(t),grr=i(Z),hF=n(Z,"LI",{});var lze=s(hF);XTe=n(lze,"STRONG",{});var ZXt=s(XTe);hrr=r(ZXt,"funnel"),ZXt.forEach(t),urr=r(lze," \u2014 "),iH=n(lze,"A",{href:!0});var KXt=s(iH);prr=r(KXt,"FunnelForMaskedLM"),KXt.forEach(t),_rr=r(lze," (Funnel Transformer model)"),lze.forEach(t),brr=i(Z),uF=n(Z,"LI",{});var ize=s(uF);zTe=n(ize,"STRONG",{});var ezt=s(zTe);vrr=r(ezt,"ibert"),ezt.forEach(t),Frr=r(ize," \u2014 "),dH=n(ize,"A",{href:!0});var ozt=s(dH);Trr=r(ozt,"IBertForMaskedLM"),ozt.forEach(t),Mrr=r(ize," (I-BERT model)"),ize.forEach(t),Err=i(Z),pF=n(Z,"LI",{});var dze=s(pF);QTe=n(dze,"STRONG",{});var rzt=s(QTe);Crr=r(rzt,"layoutlm"),rzt.forEach(t),wrr=r(dze," \u2014 "),mH=n(dze,"A",{href:!0});var tzt=s(mH);Arr=r(tzt,"LayoutLMForMaskedLM"),tzt.forEach(t),Lrr=r(dze," (LayoutLM model)"),dze.forEach(t),yrr=i(Z),_F=n(Z,"LI",{});var mze=s(_F);WTe=n(mze,"STRONG",{});var azt=s(WTe);xrr=r(azt,"longformer"),azt.forEach(t),$rr=r(mze," \u2014 "),cH=n(mze,"A",{href:!0});var nzt=s(cH);krr=r(nzt,"LongformerForMaskedLM"),nzt.forEach(t),Srr=r(mze," (Longformer model)"),mze.forEach(t),Rrr=i(Z),bF=n(Z,"LI",{});var cze=s(bF);UTe=n(cze,"STRONG",{});var szt=s(UTe);Prr=r(szt,"luke"),szt.forEach(t),Brr=r(cze," \u2014 "),fH=n(cze,"A",{href:!0});var lzt=s(fH);Irr=r(lzt,"LukeForMaskedLM"),lzt.forEach(t),Nrr=r(cze," (LUKE model)"),cze.forEach(t),qrr=i(Z),vF=n(Z,"LI",{});var fze=s(vF);HTe=n(fze,"STRONG",{});var izt=s(HTe);jrr=r(izt,"mbart"),izt.forEach(t),Drr=r(fze," \u2014 "),gH=n(fze,"A",{href:!0});var dzt=s(gH);Grr=r(dzt,"MBartForConditionalGeneration"),dzt.forEach(t),Orr=r(fze," (mBART model)"),fze.forEach(t),Vrr=i(Z),FF=n(Z,"LI",{});var gze=s(FF);JTe=n(gze,"STRONG",{});var mzt=s(JTe);Xrr=r(mzt,"megatron-bert"),mzt.forEach(t),zrr=r(gze," \u2014 "),hH=n(gze,"A",{href:!0});var czt=s(hH);Qrr=r(czt,"MegatronBertForMaskedLM"),czt.forEach(t),Wrr=r(gze," (Megatron-BERT model)"),gze.forEach(t),Urr=i(Z),TF=n(Z,"LI",{});var hze=s(TF);YTe=n(hze,"STRONG",{});var fzt=s(YTe);Hrr=r(fzt,"mobilebert"),fzt.forEach(t),Jrr=r(hze," \u2014 "),uH=n(hze,"A",{href:!0});var gzt=s(uH);Yrr=r(gzt,"MobileBertForMaskedLM"),gzt.forEach(t),Zrr=r(hze," (MobileBERT model)"),hze.forEach(t),Krr=i(Z),MF=n(Z,"LI",{});var uze=s(MF);ZTe=n(uze,"STRONG",{});var hzt=s(ZTe);etr=r(hzt,"mpnet"),hzt.forEach(t),otr=r(uze," \u2014 "),pH=n(uze,"A",{href:!0});var uzt=s(pH);rtr=r(uzt,"MPNetForMaskedLM"),uzt.forEach(t),ttr=r(uze," (MPNet model)"),uze.forEach(t),atr=i(Z),EF=n(Z,"LI",{});var pze=s(EF);KTe=n(pze,"STRONG",{});var pzt=s(KTe);ntr=r(pzt,"mvp"),pzt.forEach(t),str=r(pze," \u2014 "),_H=n(pze,"A",{href:!0});var _zt=s(_H);ltr=r(_zt,"MvpForConditionalGeneration"),_zt.forEach(t),itr=r(pze," (MVP model)"),pze.forEach(t),dtr=i(Z),CF=n(Z,"LI",{});var _ze=s(CF);eMe=n(_ze,"STRONG",{});var bzt=s(eMe);mtr=r(bzt,"nezha"),bzt.forEach(t),ctr=r(_ze," \u2014 "),bH=n(_ze,"A",{href:!0});var vzt=s(bH);ftr=r(vzt,"NezhaForMaskedLM"),vzt.forEach(t),gtr=r(_ze," (Nezha model)"),_ze.forEach(t),htr=i(Z),wF=n(Z,"LI",{});var bze=s(wF);oMe=n(bze,"STRONG",{});var Fzt=s(oMe);utr=r(Fzt,"nystromformer"),Fzt.forEach(t),ptr=r(bze," \u2014 "),vH=n(bze,"A",{href:!0});var Tzt=s(vH);_tr=r(Tzt,"NystromformerForMaskedLM"),Tzt.forEach(t),btr=r(bze," (Nystr\xF6mformer model)"),bze.forEach(t),vtr=i(Z),AF=n(Z,"LI",{});var vze=s(AF);rMe=n(vze,"STRONG",{});var Mzt=s(rMe);Ftr=r(Mzt,"perceiver"),Mzt.forEach(t),Ttr=r(vze," \u2014 "),FH=n(vze,"A",{href:!0});var Ezt=s(FH);Mtr=r(Ezt,"PerceiverForMaskedLM"),Ezt.forEach(t),Etr=r(vze," (Perceiver model)"),vze.forEach(t),Ctr=i(Z),LF=n(Z,"LI",{});var Fze=s(LF);tMe=n(Fze,"STRONG",{});var Czt=s(tMe);wtr=r(Czt,"qdqbert"),Czt.forEach(t),Atr=r(Fze," \u2014 "),TH=n(Fze,"A",{href:!0});var wzt=s(TH);Ltr=r(wzt,"QDQBertForMaskedLM"),wzt.forEach(t),ytr=r(Fze," (QDQBert model)"),Fze.forEach(t),xtr=i(Z),yF=n(Z,"LI",{});var Tze=s(yF);aMe=n(Tze,"STRONG",{});var Azt=s(aMe);$tr=r(Azt,"reformer"),Azt.forEach(t),ktr=r(Tze," \u2014 "),MH=n(Tze,"A",{href:!0});var Lzt=s(MH);Str=r(Lzt,"ReformerForMaskedLM"),Lzt.forEach(t),Rtr=r(Tze," (Reformer model)"),Tze.forEach(t),Ptr=i(Z),xF=n(Z,"LI",{});var Mze=s(xF);nMe=n(Mze,"STRONG",{});var yzt=s(nMe);Btr=r(yzt,"rembert"),yzt.forEach(t),Itr=r(Mze," \u2014 "),EH=n(Mze,"A",{href:!0});var xzt=s(EH);Ntr=r(xzt,"RemBertForMaskedLM"),xzt.forEach(t),qtr=r(Mze," (RemBERT model)"),Mze.forEach(t),jtr=i(Z),$F=n(Z,"LI",{});var Eze=s($F);sMe=n(Eze,"STRONG",{});var $zt=s(sMe);Dtr=r($zt,"roberta"),$zt.forEach(t),Gtr=r(Eze," \u2014 "),CH=n(Eze,"A",{href:!0});var kzt=s(CH);Otr=r(kzt,"RobertaForMaskedLM"),kzt.forEach(t),Vtr=r(Eze," (RoBERTa model)"),Eze.forEach(t),Xtr=i(Z),kF=n(Z,"LI",{});var Cze=s(kF);lMe=n(Cze,"STRONG",{});var Szt=s(lMe);ztr=r(Szt,"roformer"),Szt.forEach(t),Qtr=r(Cze," \u2014 "),wH=n(Cze,"A",{href:!0});var Rzt=s(wH);Wtr=r(Rzt,"RoFormerForMaskedLM"),Rzt.forEach(t),Utr=r(Cze," (RoFormer model)"),Cze.forEach(t),Htr=i(Z),SF=n(Z,"LI",{});var wze=s(SF);iMe=n(wze,"STRONG",{});var Pzt=s(iMe);Jtr=r(Pzt,"squeezebert"),Pzt.forEach(t),Ytr=r(wze," \u2014 "),AH=n(wze,"A",{href:!0});var Bzt=s(AH);Ztr=r(Bzt,"SqueezeBertForMaskedLM"),Bzt.forEach(t),Ktr=r(wze," (SqueezeBERT model)"),wze.forEach(t),ear=i(Z),RF=n(Z,"LI",{});var Aze=s(RF);dMe=n(Aze,"STRONG",{});var Izt=s(dMe);oar=r(Izt,"tapas"),Izt.forEach(t),rar=r(Aze," \u2014 "),LH=n(Aze,"A",{href:!0});var Nzt=s(LH);tar=r(Nzt,"TapasForMaskedLM"),Nzt.forEach(t),aar=r(Aze," (TAPAS model)"),Aze.forEach(t),nar=i(Z),PF=n(Z,"LI",{});var Lze=s(PF);mMe=n(Lze,"STRONG",{});var qzt=s(mMe);sar=r(qzt,"wav2vec2"),qzt.forEach(t),lar=r(Lze," \u2014 "),cMe=n(Lze,"CODE",{});var jzt=s(cMe);iar=r(jzt,"Wav2Vec2ForMaskedLM"),jzt.forEach(t),dar=r(Lze," (Wav2Vec2 model)"),Lze.forEach(t),mar=i(Z),BF=n(Z,"LI",{});var yze=s(BF);fMe=n(yze,"STRONG",{});var Dzt=s(fMe);car=r(Dzt,"xlm"),Dzt.forEach(t),far=r(yze," \u2014 "),yH=n(yze,"A",{href:!0});var Gzt=s(yH);gar=r(Gzt,"XLMWithLMHeadModel"),Gzt.forEach(t),har=r(yze," (XLM model)"),yze.forEach(t),uar=i(Z),IF=n(Z,"LI",{});var xze=s(IF);gMe=n(xze,"STRONG",{});var Ozt=s(gMe);par=r(Ozt,"xlm-roberta"),Ozt.forEach(t),_ar=r(xze," \u2014 "),xH=n(xze,"A",{href:!0});var Vzt=s(xH);bar=r(Vzt,"XLMRobertaForMaskedLM"),Vzt.forEach(t),Far=r(xze," (XLM-RoBERTa model)"),xze.forEach(t),Tar=i(Z),NF=n(Z,"LI",{});var $ze=s(NF);hMe=n($ze,"STRONG",{});var Xzt=s(hMe);Mar=r(Xzt,"xlm-roberta-xl"),Xzt.forEach(t),Ear=r($ze," \u2014 "),$H=n($ze,"A",{href:!0});var zzt=s($H);Car=r(zzt,"XLMRobertaXLForMaskedLM"),zzt.forEach(t),war=r($ze," (XLM-RoBERTa-XL model)"),$ze.forEach(t),Aar=i(Z),qF=n(Z,"LI",{});var kze=s(qF);uMe=n(kze,"STRONG",{});var Qzt=s(uMe);Lar=r(Qzt,"yoso"),Qzt.forEach(t),yar=r(kze," \u2014 "),kH=n(kze,"A",{href:!0});var Wzt=s(kH);xar=r(Wzt,"YosoForMaskedLM"),Wzt.forEach(t),$ar=r(kze," (YOSO model)"),kze.forEach(t),Z.forEach(t),kar=i(ka),jF=n(ka,"P",{});var Sze=s(jF);Sar=r(Sze,"The model is set in evaluation mode by default using "),pMe=n(Sze,"CODE",{});var Uzt=s(pMe);Rar=r(Uzt,"model.eval()"),Uzt.forEach(t),Par=r(Sze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_Me=n(Sze,"CODE",{});var Hzt=s(_Me);Bar=r(Hzt,"model.train()"),Hzt.forEach(t),Sze.forEach(t),Iar=i(ka),T(DF.$$.fragment,ka),ka.forEach(t),Ol.forEach(t),Uto=i(c),Wd=n(c,"H2",{class:!0});var gso=s(Wd);GF=n(gso,"A",{id:!0,class:!0,href:!0});var Jzt=s(GF);bMe=n(Jzt,"SPAN",{});var Yzt=s(bMe);T(lk.$$.fragment,Yzt),Yzt.forEach(t),Jzt.forEach(t),Nar=i(gso),vMe=n(gso,"SPAN",{});var Zzt=s(vMe);qar=r(Zzt,"AutoModelForSeq2SeqLM"),Zzt.forEach(t),gso.forEach(t),Hto=i(c),Go=n(c,"DIV",{class:!0});var Vl=s(Go);T(ik.$$.fragment,Vl),jar=i(Vl),Ud=n(Vl,"P",{});var hme=s(Ud);Dar=r(hme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),SH=n(hme,"A",{href:!0});var Kzt=s(SH);Gar=r(Kzt,"from_pretrained()"),Kzt.forEach(t),Oar=r(hme," class method or the "),RH=n(hme,"A",{href:!0});var eQt=s(RH);Var=r(eQt,"from_config()"),eQt.forEach(t),Xar=r(hme,` class
method.`),hme.forEach(t),zar=i(Vl),dk=n(Vl,"P",{});var hso=s(dk);Qar=r(hso,"This class cannot be instantiated directly using "),FMe=n(hso,"CODE",{});var oQt=s(FMe);War=r(oQt,"__init__()"),oQt.forEach(t),Uar=r(hso," (throws an error)."),hso.forEach(t),Har=i(Vl),Lt=n(Vl,"DIV",{class:!0});var m9=s(Lt);T(mk.$$.fragment,m9),Jar=i(m9),TMe=n(m9,"P",{});var rQt=s(TMe);Yar=r(rQt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),rQt.forEach(t),Zar=i(m9),Hd=n(m9,"P",{});var ume=s(Hd);Kar=r(ume,`Note:
Loading a model from its configuration file does `),MMe=n(ume,"STRONG",{});var tQt=s(MMe);enr=r(tQt,"not"),tQt.forEach(t),onr=r(ume,` load the model weights. It only affects the
model\u2019s configuration. Use `),PH=n(ume,"A",{href:!0});var aQt=s(PH);rnr=r(aQt,"from_pretrained()"),aQt.forEach(t),tnr=r(ume," to load the model weights."),ume.forEach(t),anr=i(m9),T(OF.$$.fragment,m9),m9.forEach(t),nnr=i(Vl),ao=n(Vl,"DIV",{class:!0});var Sa=s(ao);T(ck.$$.fragment,Sa),snr=i(Sa),EMe=n(Sa,"P",{});var nQt=s(EMe);lnr=r(nQt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),nQt.forEach(t),inr=i(Sa),cn=n(Sa,"P",{});var c9=s(cn);dnr=r(c9,"The model class to instantiate is selected based on the "),CMe=n(c9,"CODE",{});var sQt=s(CMe);mnr=r(sQt,"model_type"),sQt.forEach(t),cnr=r(c9,` property of the config object (either
passed as an argument or loaded from `),wMe=n(c9,"CODE",{});var lQt=s(wMe);fnr=r(lQt,"pretrained_model_name_or_path"),lQt.forEach(t),gnr=r(c9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),AMe=n(c9,"CODE",{});var iQt=s(AMe);hnr=r(iQt,"pretrained_model_name_or_path"),iQt.forEach(t),unr=r(c9,":"),c9.forEach(t),pnr=i(Sa),he=n(Sa,"UL",{});var _e=s(he);VF=n(_e,"LI",{});var Rze=s(VF);LMe=n(Rze,"STRONG",{});var dQt=s(LMe);_nr=r(dQt,"bart"),dQt.forEach(t),bnr=r(Rze," \u2014 "),BH=n(Rze,"A",{href:!0});var mQt=s(BH);vnr=r(mQt,"BartForConditionalGeneration"),mQt.forEach(t),Fnr=r(Rze," (BART model)"),Rze.forEach(t),Tnr=i(_e),XF=n(_e,"LI",{});var Pze=s(XF);yMe=n(Pze,"STRONG",{});var cQt=s(yMe);Mnr=r(cQt,"bigbird_pegasus"),cQt.forEach(t),Enr=r(Pze," \u2014 "),IH=n(Pze,"A",{href:!0});var fQt=s(IH);Cnr=r(fQt,"BigBirdPegasusForConditionalGeneration"),fQt.forEach(t),wnr=r(Pze," (BigBird-Pegasus model)"),Pze.forEach(t),Anr=i(_e),zF=n(_e,"LI",{});var Bze=s(zF);xMe=n(Bze,"STRONG",{});var gQt=s(xMe);Lnr=r(gQt,"blenderbot"),gQt.forEach(t),ynr=r(Bze," \u2014 "),NH=n(Bze,"A",{href:!0});var hQt=s(NH);xnr=r(hQt,"BlenderbotForConditionalGeneration"),hQt.forEach(t),$nr=r(Bze," (Blenderbot model)"),Bze.forEach(t),knr=i(_e),QF=n(_e,"LI",{});var Ize=s(QF);$Me=n(Ize,"STRONG",{});var uQt=s($Me);Snr=r(uQt,"blenderbot-small"),uQt.forEach(t),Rnr=r(Ize," \u2014 "),qH=n(Ize,"A",{href:!0});var pQt=s(qH);Pnr=r(pQt,"BlenderbotSmallForConditionalGeneration"),pQt.forEach(t),Bnr=r(Ize," (BlenderbotSmall model)"),Ize.forEach(t),Inr=i(_e),WF=n(_e,"LI",{});var Nze=s(WF);kMe=n(Nze,"STRONG",{});var _Qt=s(kMe);Nnr=r(_Qt,"encoder-decoder"),_Qt.forEach(t),qnr=r(Nze," \u2014 "),jH=n(Nze,"A",{href:!0});var bQt=s(jH);jnr=r(bQt,"EncoderDecoderModel"),bQt.forEach(t),Dnr=r(Nze," (Encoder decoder model)"),Nze.forEach(t),Gnr=i(_e),UF=n(_e,"LI",{});var qze=s(UF);SMe=n(qze,"STRONG",{});var vQt=s(SMe);Onr=r(vQt,"fsmt"),vQt.forEach(t),Vnr=r(qze," \u2014 "),DH=n(qze,"A",{href:!0});var FQt=s(DH);Xnr=r(FQt,"FSMTForConditionalGeneration"),FQt.forEach(t),znr=r(qze," (FairSeq Machine-Translation model)"),qze.forEach(t),Qnr=i(_e),HF=n(_e,"LI",{});var jze=s(HF);RMe=n(jze,"STRONG",{});var TQt=s(RMe);Wnr=r(TQt,"led"),TQt.forEach(t),Unr=r(jze," \u2014 "),GH=n(jze,"A",{href:!0});var MQt=s(GH);Hnr=r(MQt,"LEDForConditionalGeneration"),MQt.forEach(t),Jnr=r(jze," (LED model)"),jze.forEach(t),Ynr=i(_e),JF=n(_e,"LI",{});var Dze=s(JF);PMe=n(Dze,"STRONG",{});var EQt=s(PMe);Znr=r(EQt,"longt5"),EQt.forEach(t),Knr=r(Dze," \u2014 "),OH=n(Dze,"A",{href:!0});var CQt=s(OH);esr=r(CQt,"LongT5ForConditionalGeneration"),CQt.forEach(t),osr=r(Dze," (LongT5 model)"),Dze.forEach(t),rsr=i(_e),YF=n(_e,"LI",{});var Gze=s(YF);BMe=n(Gze,"STRONG",{});var wQt=s(BMe);tsr=r(wQt,"m2m_100"),wQt.forEach(t),asr=r(Gze," \u2014 "),VH=n(Gze,"A",{href:!0});var AQt=s(VH);nsr=r(AQt,"M2M100ForConditionalGeneration"),AQt.forEach(t),ssr=r(Gze," (M2M100 model)"),Gze.forEach(t),lsr=i(_e),ZF=n(_e,"LI",{});var Oze=s(ZF);IMe=n(Oze,"STRONG",{});var LQt=s(IMe);isr=r(LQt,"marian"),LQt.forEach(t),dsr=r(Oze," \u2014 "),XH=n(Oze,"A",{href:!0});var yQt=s(XH);msr=r(yQt,"MarianMTModel"),yQt.forEach(t),csr=r(Oze," (Marian model)"),Oze.forEach(t),fsr=i(_e),KF=n(_e,"LI",{});var Vze=s(KF);NMe=n(Vze,"STRONG",{});var xQt=s(NMe);gsr=r(xQt,"mbart"),xQt.forEach(t),hsr=r(Vze," \u2014 "),zH=n(Vze,"A",{href:!0});var $Qt=s(zH);usr=r($Qt,"MBartForConditionalGeneration"),$Qt.forEach(t),psr=r(Vze," (mBART model)"),Vze.forEach(t),_sr=i(_e),eT=n(_e,"LI",{});var Xze=s(eT);qMe=n(Xze,"STRONG",{});var kQt=s(qMe);bsr=r(kQt,"mt5"),kQt.forEach(t),vsr=r(Xze," \u2014 "),QH=n(Xze,"A",{href:!0});var SQt=s(QH);Fsr=r(SQt,"MT5ForConditionalGeneration"),SQt.forEach(t),Tsr=r(Xze," (MT5 model)"),Xze.forEach(t),Msr=i(_e),oT=n(_e,"LI",{});var zze=s(oT);jMe=n(zze,"STRONG",{});var RQt=s(jMe);Esr=r(RQt,"mvp"),RQt.forEach(t),Csr=r(zze," \u2014 "),WH=n(zze,"A",{href:!0});var PQt=s(WH);wsr=r(PQt,"MvpForConditionalGeneration"),PQt.forEach(t),Asr=r(zze," (MVP model)"),zze.forEach(t),Lsr=i(_e),rT=n(_e,"LI",{});var Qze=s(rT);DMe=n(Qze,"STRONG",{});var BQt=s(DMe);ysr=r(BQt,"nllb"),BQt.forEach(t),xsr=r(Qze," \u2014 "),UH=n(Qze,"A",{href:!0});var IQt=s(UH);$sr=r(IQt,"M2M100ForConditionalGeneration"),IQt.forEach(t),ksr=r(Qze," (NLLB model)"),Qze.forEach(t),Ssr=i(_e),tT=n(_e,"LI",{});var Wze=s(tT);GMe=n(Wze,"STRONG",{});var NQt=s(GMe);Rsr=r(NQt,"pegasus"),NQt.forEach(t),Psr=r(Wze," \u2014 "),HH=n(Wze,"A",{href:!0});var qQt=s(HH);Bsr=r(qQt,"PegasusForConditionalGeneration"),qQt.forEach(t),Isr=r(Wze," (Pegasus model)"),Wze.forEach(t),Nsr=i(_e),aT=n(_e,"LI",{});var Uze=s(aT);OMe=n(Uze,"STRONG",{});var jQt=s(OMe);qsr=r(jQt,"pegasus_x"),jQt.forEach(t),jsr=r(Uze," \u2014 "),JH=n(Uze,"A",{href:!0});var DQt=s(JH);Dsr=r(DQt,"PegasusXForConditionalGeneration"),DQt.forEach(t),Gsr=r(Uze," (PEGASUS-X model)"),Uze.forEach(t),Osr=i(_e),nT=n(_e,"LI",{});var Hze=s(nT);VMe=n(Hze,"STRONG",{});var GQt=s(VMe);Vsr=r(GQt,"plbart"),GQt.forEach(t),Xsr=r(Hze," \u2014 "),YH=n(Hze,"A",{href:!0});var OQt=s(YH);zsr=r(OQt,"PLBartForConditionalGeneration"),OQt.forEach(t),Qsr=r(Hze," (PLBart model)"),Hze.forEach(t),Wsr=i(_e),sT=n(_e,"LI",{});var Jze=s(sT);XMe=n(Jze,"STRONG",{});var VQt=s(XMe);Usr=r(VQt,"prophetnet"),VQt.forEach(t),Hsr=r(Jze," \u2014 "),ZH=n(Jze,"A",{href:!0});var XQt=s(ZH);Jsr=r(XQt,"ProphetNetForConditionalGeneration"),XQt.forEach(t),Ysr=r(Jze," (ProphetNet model)"),Jze.forEach(t),Zsr=i(_e),lT=n(_e,"LI",{});var Yze=s(lT);zMe=n(Yze,"STRONG",{});var zQt=s(zMe);Ksr=r(zQt,"t5"),zQt.forEach(t),elr=r(Yze," \u2014 "),KH=n(Yze,"A",{href:!0});var QQt=s(KH);olr=r(QQt,"T5ForConditionalGeneration"),QQt.forEach(t),rlr=r(Yze," (T5 model)"),Yze.forEach(t),tlr=i(_e),iT=n(_e,"LI",{});var Zze=s(iT);QMe=n(Zze,"STRONG",{});var WQt=s(QMe);alr=r(WQt,"xlm-prophetnet"),WQt.forEach(t),nlr=r(Zze," \u2014 "),eJ=n(Zze,"A",{href:!0});var UQt=s(eJ);slr=r(UQt,"XLMProphetNetForConditionalGeneration"),UQt.forEach(t),llr=r(Zze," (XLM-ProphetNet model)"),Zze.forEach(t),_e.forEach(t),ilr=i(Sa),dT=n(Sa,"P",{});var Kze=s(dT);dlr=r(Kze,"The model is set in evaluation mode by default using "),WMe=n(Kze,"CODE",{});var HQt=s(WMe);mlr=r(HQt,"model.eval()"),HQt.forEach(t),clr=r(Kze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),UMe=n(Kze,"CODE",{});var JQt=s(UMe);flr=r(JQt,"model.train()"),JQt.forEach(t),Kze.forEach(t),glr=i(Sa),T(mT.$$.fragment,Sa),Sa.forEach(t),Vl.forEach(t),Jto=i(c),Jd=n(c,"H2",{class:!0});var uso=s(Jd);cT=n(uso,"A",{id:!0,class:!0,href:!0});var YQt=s(cT);HMe=n(YQt,"SPAN",{});var ZQt=s(HMe);T(fk.$$.fragment,ZQt),ZQt.forEach(t),YQt.forEach(t),hlr=i(uso),JMe=n(uso,"SPAN",{});var KQt=s(JMe);ulr=r(KQt,"AutoModelForSequenceClassification"),KQt.forEach(t),uso.forEach(t),Yto=i(c),Oo=n(c,"DIV",{class:!0});var Xl=s(Oo);T(gk.$$.fragment,Xl),plr=i(Xl),Yd=n(Xl,"P",{});var pme=s(Yd);_lr=r(pme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),oJ=n(pme,"A",{href:!0});var eWt=s(oJ);blr=r(eWt,"from_pretrained()"),eWt.forEach(t),vlr=r(pme," class method or the "),rJ=n(pme,"A",{href:!0});var oWt=s(rJ);Flr=r(oWt,"from_config()"),oWt.forEach(t),Tlr=r(pme,` class
method.`),pme.forEach(t),Mlr=i(Xl),hk=n(Xl,"P",{});var pso=s(hk);Elr=r(pso,"This class cannot be instantiated directly using "),YMe=n(pso,"CODE",{});var rWt=s(YMe);Clr=r(rWt,"__init__()"),rWt.forEach(t),wlr=r(pso," (throws an error)."),pso.forEach(t),Alr=i(Xl),yt=n(Xl,"DIV",{class:!0});var f9=s(yt);T(uk.$$.fragment,f9),Llr=i(f9),ZMe=n(f9,"P",{});var tWt=s(ZMe);ylr=r(tWt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),tWt.forEach(t),xlr=i(f9),Zd=n(f9,"P",{});var _me=s(Zd);$lr=r(_me,`Note:
Loading a model from its configuration file does `),KMe=n(_me,"STRONG",{});var aWt=s(KMe);klr=r(aWt,"not"),aWt.forEach(t),Slr=r(_me,` load the model weights. It only affects the
model\u2019s configuration. Use `),tJ=n(_me,"A",{href:!0});var nWt=s(tJ);Rlr=r(nWt,"from_pretrained()"),nWt.forEach(t),Plr=r(_me," to load the model weights."),_me.forEach(t),Blr=i(f9),T(fT.$$.fragment,f9),f9.forEach(t),Ilr=i(Xl),no=n(Xl,"DIV",{class:!0});var Ra=s(no);T(pk.$$.fragment,Ra),Nlr=i(Ra),eEe=n(Ra,"P",{});var sWt=s(eEe);qlr=r(sWt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),sWt.forEach(t),jlr=i(Ra),fn=n(Ra,"P",{});var g9=s(fn);Dlr=r(g9,"The model class to instantiate is selected based on the "),oEe=n(g9,"CODE",{});var lWt=s(oEe);Glr=r(lWt,"model_type"),lWt.forEach(t),Olr=r(g9,` property of the config object (either
passed as an argument or loaded from `),rEe=n(g9,"CODE",{});var iWt=s(rEe);Vlr=r(iWt,"pretrained_model_name_or_path"),iWt.forEach(t),Xlr=r(g9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tEe=n(g9,"CODE",{});var dWt=s(tEe);zlr=r(dWt,"pretrained_model_name_or_path"),dWt.forEach(t),Qlr=r(g9,":"),g9.forEach(t),Wlr=i(Ra),j=n(Ra,"UL",{});var D=s(j);gT=n(D,"LI",{});var eQe=s(gT);aEe=n(eQe,"STRONG",{});var mWt=s(aEe);Ulr=r(mWt,"albert"),mWt.forEach(t),Hlr=r(eQe," \u2014 "),aJ=n(eQe,"A",{href:!0});var cWt=s(aJ);Jlr=r(cWt,"AlbertForSequenceClassification"),cWt.forEach(t),Ylr=r(eQe," (ALBERT model)"),eQe.forEach(t),Zlr=i(D),hT=n(D,"LI",{});var oQe=s(hT);nEe=n(oQe,"STRONG",{});var fWt=s(nEe);Klr=r(fWt,"bart"),fWt.forEach(t),eir=r(oQe," \u2014 "),nJ=n(oQe,"A",{href:!0});var gWt=s(nJ);oir=r(gWt,"BartForSequenceClassification"),gWt.forEach(t),rir=r(oQe," (BART model)"),oQe.forEach(t),tir=i(D),uT=n(D,"LI",{});var rQe=s(uT);sEe=n(rQe,"STRONG",{});var hWt=s(sEe);air=r(hWt,"bert"),hWt.forEach(t),nir=r(rQe," \u2014 "),sJ=n(rQe,"A",{href:!0});var uWt=s(sJ);sir=r(uWt,"BertForSequenceClassification"),uWt.forEach(t),lir=r(rQe," (BERT model)"),rQe.forEach(t),iir=i(D),pT=n(D,"LI",{});var tQe=s(pT);lEe=n(tQe,"STRONG",{});var pWt=s(lEe);dir=r(pWt,"big_bird"),pWt.forEach(t),mir=r(tQe," \u2014 "),lJ=n(tQe,"A",{href:!0});var _Wt=s(lJ);cir=r(_Wt,"BigBirdForSequenceClassification"),_Wt.forEach(t),fir=r(tQe," (BigBird model)"),tQe.forEach(t),gir=i(D),_T=n(D,"LI",{});var aQe=s(_T);iEe=n(aQe,"STRONG",{});var bWt=s(iEe);hir=r(bWt,"bigbird_pegasus"),bWt.forEach(t),uir=r(aQe," \u2014 "),iJ=n(aQe,"A",{href:!0});var vWt=s(iJ);pir=r(vWt,"BigBirdPegasusForSequenceClassification"),vWt.forEach(t),_ir=r(aQe," (BigBird-Pegasus model)"),aQe.forEach(t),bir=i(D),bT=n(D,"LI",{});var nQe=s(bT);dEe=n(nQe,"STRONG",{});var FWt=s(dEe);vir=r(FWt,"bloom"),FWt.forEach(t),Fir=r(nQe," \u2014 "),dJ=n(nQe,"A",{href:!0});var TWt=s(dJ);Tir=r(TWt,"BloomForSequenceClassification"),TWt.forEach(t),Mir=r(nQe," (BLOOM model)"),nQe.forEach(t),Eir=i(D),vT=n(D,"LI",{});var sQe=s(vT);mEe=n(sQe,"STRONG",{});var MWt=s(mEe);Cir=r(MWt,"camembert"),MWt.forEach(t),wir=r(sQe," \u2014 "),mJ=n(sQe,"A",{href:!0});var EWt=s(mJ);Air=r(EWt,"CamembertForSequenceClassification"),EWt.forEach(t),Lir=r(sQe," (CamemBERT model)"),sQe.forEach(t),yir=i(D),FT=n(D,"LI",{});var lQe=s(FT);cEe=n(lQe,"STRONG",{});var CWt=s(cEe);xir=r(CWt,"canine"),CWt.forEach(t),$ir=r(lQe," \u2014 "),cJ=n(lQe,"A",{href:!0});var wWt=s(cJ);kir=r(wWt,"CanineForSequenceClassification"),wWt.forEach(t),Sir=r(lQe," (CANINE model)"),lQe.forEach(t),Rir=i(D),TT=n(D,"LI",{});var iQe=s(TT);fEe=n(iQe,"STRONG",{});var AWt=s(fEe);Pir=r(AWt,"convbert"),AWt.forEach(t),Bir=r(iQe," \u2014 "),fJ=n(iQe,"A",{href:!0});var LWt=s(fJ);Iir=r(LWt,"ConvBertForSequenceClassification"),LWt.forEach(t),Nir=r(iQe," (ConvBERT model)"),iQe.forEach(t),qir=i(D),MT=n(D,"LI",{});var dQe=s(MT);gEe=n(dQe,"STRONG",{});var yWt=s(gEe);jir=r(yWt,"ctrl"),yWt.forEach(t),Dir=r(dQe," \u2014 "),gJ=n(dQe,"A",{href:!0});var xWt=s(gJ);Gir=r(xWt,"CTRLForSequenceClassification"),xWt.forEach(t),Oir=r(dQe," (CTRL model)"),dQe.forEach(t),Vir=i(D),ET=n(D,"LI",{});var mQe=s(ET);hEe=n(mQe,"STRONG",{});var $Wt=s(hEe);Xir=r($Wt,"data2vec-text"),$Wt.forEach(t),zir=r(mQe," \u2014 "),hJ=n(mQe,"A",{href:!0});var kWt=s(hJ);Qir=r(kWt,"Data2VecTextForSequenceClassification"),kWt.forEach(t),Wir=r(mQe," (Data2VecText model)"),mQe.forEach(t),Uir=i(D),CT=n(D,"LI",{});var cQe=s(CT);uEe=n(cQe,"STRONG",{});var SWt=s(uEe);Hir=r(SWt,"deberta"),SWt.forEach(t),Jir=r(cQe," \u2014 "),uJ=n(cQe,"A",{href:!0});var RWt=s(uJ);Yir=r(RWt,"DebertaForSequenceClassification"),RWt.forEach(t),Zir=r(cQe," (DeBERTa model)"),cQe.forEach(t),Kir=i(D),wT=n(D,"LI",{});var fQe=s(wT);pEe=n(fQe,"STRONG",{});var PWt=s(pEe);edr=r(PWt,"deberta-v2"),PWt.forEach(t),odr=r(fQe," \u2014 "),pJ=n(fQe,"A",{href:!0});var BWt=s(pJ);rdr=r(BWt,"DebertaV2ForSequenceClassification"),BWt.forEach(t),tdr=r(fQe," (DeBERTa-v2 model)"),fQe.forEach(t),adr=i(D),AT=n(D,"LI",{});var gQe=s(AT);_Ee=n(gQe,"STRONG",{});var IWt=s(_Ee);ndr=r(IWt,"distilbert"),IWt.forEach(t),sdr=r(gQe," \u2014 "),_J=n(gQe,"A",{href:!0});var NWt=s(_J);ldr=r(NWt,"DistilBertForSequenceClassification"),NWt.forEach(t),idr=r(gQe," (DistilBERT model)"),gQe.forEach(t),ddr=i(D),LT=n(D,"LI",{});var hQe=s(LT);bEe=n(hQe,"STRONG",{});var qWt=s(bEe);mdr=r(qWt,"electra"),qWt.forEach(t),cdr=r(hQe," \u2014 "),bJ=n(hQe,"A",{href:!0});var jWt=s(bJ);fdr=r(jWt,"ElectraForSequenceClassification"),jWt.forEach(t),gdr=r(hQe," (ELECTRA model)"),hQe.forEach(t),hdr=i(D),yT=n(D,"LI",{});var uQe=s(yT);vEe=n(uQe,"STRONG",{});var DWt=s(vEe);udr=r(DWt,"ernie"),DWt.forEach(t),pdr=r(uQe," \u2014 "),vJ=n(uQe,"A",{href:!0});var GWt=s(vJ);_dr=r(GWt,"ErnieForSequenceClassification"),GWt.forEach(t),bdr=r(uQe," (ERNIE model)"),uQe.forEach(t),vdr=i(D),xT=n(D,"LI",{});var pQe=s(xT);FEe=n(pQe,"STRONG",{});var OWt=s(FEe);Fdr=r(OWt,"esm"),OWt.forEach(t),Tdr=r(pQe," \u2014 "),FJ=n(pQe,"A",{href:!0});var VWt=s(FJ);Mdr=r(VWt,"EsmForSequenceClassification"),VWt.forEach(t),Edr=r(pQe," (ESM model)"),pQe.forEach(t),Cdr=i(D),$T=n(D,"LI",{});var _Qe=s($T);TEe=n(_Qe,"STRONG",{});var XWt=s(TEe);wdr=r(XWt,"flaubert"),XWt.forEach(t),Adr=r(_Qe," \u2014 "),TJ=n(_Qe,"A",{href:!0});var zWt=s(TJ);Ldr=r(zWt,"FlaubertForSequenceClassification"),zWt.forEach(t),ydr=r(_Qe," (FlauBERT model)"),_Qe.forEach(t),xdr=i(D),kT=n(D,"LI",{});var bQe=s(kT);MEe=n(bQe,"STRONG",{});var QWt=s(MEe);$dr=r(QWt,"fnet"),QWt.forEach(t),kdr=r(bQe," \u2014 "),MJ=n(bQe,"A",{href:!0});var WWt=s(MJ);Sdr=r(WWt,"FNetForSequenceClassification"),WWt.forEach(t),Rdr=r(bQe," (FNet model)"),bQe.forEach(t),Pdr=i(D),ST=n(D,"LI",{});var vQe=s(ST);EEe=n(vQe,"STRONG",{});var UWt=s(EEe);Bdr=r(UWt,"funnel"),UWt.forEach(t),Idr=r(vQe," \u2014 "),EJ=n(vQe,"A",{href:!0});var HWt=s(EJ);Ndr=r(HWt,"FunnelForSequenceClassification"),HWt.forEach(t),qdr=r(vQe," (Funnel Transformer model)"),vQe.forEach(t),jdr=i(D),RT=n(D,"LI",{});var FQe=s(RT);CEe=n(FQe,"STRONG",{});var JWt=s(CEe);Ddr=r(JWt,"gpt2"),JWt.forEach(t),Gdr=r(FQe," \u2014 "),CJ=n(FQe,"A",{href:!0});var YWt=s(CJ);Odr=r(YWt,"GPT2ForSequenceClassification"),YWt.forEach(t),Vdr=r(FQe," (OpenAI GPT-2 model)"),FQe.forEach(t),Xdr=i(D),PT=n(D,"LI",{});var TQe=s(PT);wEe=n(TQe,"STRONG",{});var ZWt=s(wEe);zdr=r(ZWt,"gpt_neo"),ZWt.forEach(t),Qdr=r(TQe," \u2014 "),wJ=n(TQe,"A",{href:!0});var KWt=s(wJ);Wdr=r(KWt,"GPTNeoForSequenceClassification"),KWt.forEach(t),Udr=r(TQe," (GPT Neo model)"),TQe.forEach(t),Hdr=i(D),BT=n(D,"LI",{});var MQe=s(BT);AEe=n(MQe,"STRONG",{});var eUt=s(AEe);Jdr=r(eUt,"gptj"),eUt.forEach(t),Ydr=r(MQe," \u2014 "),AJ=n(MQe,"A",{href:!0});var oUt=s(AJ);Zdr=r(oUt,"GPTJForSequenceClassification"),oUt.forEach(t),Kdr=r(MQe," (GPT-J model)"),MQe.forEach(t),emr=i(D),IT=n(D,"LI",{});var EQe=s(IT);LEe=n(EQe,"STRONG",{});var rUt=s(LEe);omr=r(rUt,"ibert"),rUt.forEach(t),rmr=r(EQe," \u2014 "),LJ=n(EQe,"A",{href:!0});var tUt=s(LJ);tmr=r(tUt,"IBertForSequenceClassification"),tUt.forEach(t),amr=r(EQe," (I-BERT model)"),EQe.forEach(t),nmr=i(D),NT=n(D,"LI",{});var CQe=s(NT);yEe=n(CQe,"STRONG",{});var aUt=s(yEe);smr=r(aUt,"layoutlm"),aUt.forEach(t),lmr=r(CQe," \u2014 "),yJ=n(CQe,"A",{href:!0});var nUt=s(yJ);imr=r(nUt,"LayoutLMForSequenceClassification"),nUt.forEach(t),dmr=r(CQe," (LayoutLM model)"),CQe.forEach(t),mmr=i(D),qT=n(D,"LI",{});var wQe=s(qT);xEe=n(wQe,"STRONG",{});var sUt=s(xEe);cmr=r(sUt,"layoutlmv2"),sUt.forEach(t),fmr=r(wQe," \u2014 "),xJ=n(wQe,"A",{href:!0});var lUt=s(xJ);gmr=r(lUt,"LayoutLMv2ForSequenceClassification"),lUt.forEach(t),hmr=r(wQe," (LayoutLMv2 model)"),wQe.forEach(t),umr=i(D),jT=n(D,"LI",{});var AQe=s(jT);$Ee=n(AQe,"STRONG",{});var iUt=s($Ee);pmr=r(iUt,"layoutlmv3"),iUt.forEach(t),_mr=r(AQe," \u2014 "),$J=n(AQe,"A",{href:!0});var dUt=s($J);bmr=r(dUt,"LayoutLMv3ForSequenceClassification"),dUt.forEach(t),vmr=r(AQe," (LayoutLMv3 model)"),AQe.forEach(t),Fmr=i(D),DT=n(D,"LI",{});var LQe=s(DT);kEe=n(LQe,"STRONG",{});var mUt=s(kEe);Tmr=r(mUt,"led"),mUt.forEach(t),Mmr=r(LQe," \u2014 "),kJ=n(LQe,"A",{href:!0});var cUt=s(kJ);Emr=r(cUt,"LEDForSequenceClassification"),cUt.forEach(t),Cmr=r(LQe," (LED model)"),LQe.forEach(t),wmr=i(D),GT=n(D,"LI",{});var yQe=s(GT);SEe=n(yQe,"STRONG",{});var fUt=s(SEe);Amr=r(fUt,"lilt"),fUt.forEach(t),Lmr=r(yQe," \u2014 "),SJ=n(yQe,"A",{href:!0});var gUt=s(SJ);ymr=r(gUt,"LiltForSequenceClassification"),gUt.forEach(t),xmr=r(yQe," (LiLT model)"),yQe.forEach(t),$mr=i(D),OT=n(D,"LI",{});var xQe=s(OT);REe=n(xQe,"STRONG",{});var hUt=s(REe);kmr=r(hUt,"longformer"),hUt.forEach(t),Smr=r(xQe," \u2014 "),RJ=n(xQe,"A",{href:!0});var uUt=s(RJ);Rmr=r(uUt,"LongformerForSequenceClassification"),uUt.forEach(t),Pmr=r(xQe," (Longformer model)"),xQe.forEach(t),Bmr=i(D),VT=n(D,"LI",{});var $Qe=s(VT);PEe=n($Qe,"STRONG",{});var pUt=s(PEe);Imr=r(pUt,"luke"),pUt.forEach(t),Nmr=r($Qe," \u2014 "),PJ=n($Qe,"A",{href:!0});var _Ut=s(PJ);qmr=r(_Ut,"LukeForSequenceClassification"),_Ut.forEach(t),jmr=r($Qe," (LUKE model)"),$Qe.forEach(t),Dmr=i(D),XT=n(D,"LI",{});var kQe=s(XT);BEe=n(kQe,"STRONG",{});var bUt=s(BEe);Gmr=r(bUt,"markuplm"),bUt.forEach(t),Omr=r(kQe," \u2014 "),BJ=n(kQe,"A",{href:!0});var vUt=s(BJ);Vmr=r(vUt,"MarkupLMForSequenceClassification"),vUt.forEach(t),Xmr=r(kQe," (MarkupLM model)"),kQe.forEach(t),zmr=i(D),zT=n(D,"LI",{});var SQe=s(zT);IEe=n(SQe,"STRONG",{});var FUt=s(IEe);Qmr=r(FUt,"mbart"),FUt.forEach(t),Wmr=r(SQe," \u2014 "),IJ=n(SQe,"A",{href:!0});var TUt=s(IJ);Umr=r(TUt,"MBartForSequenceClassification"),TUt.forEach(t),Hmr=r(SQe," (mBART model)"),SQe.forEach(t),Jmr=i(D),QT=n(D,"LI",{});var RQe=s(QT);NEe=n(RQe,"STRONG",{});var MUt=s(NEe);Ymr=r(MUt,"megatron-bert"),MUt.forEach(t),Zmr=r(RQe," \u2014 "),NJ=n(RQe,"A",{href:!0});var EUt=s(NJ);Kmr=r(EUt,"MegatronBertForSequenceClassification"),EUt.forEach(t),ecr=r(RQe," (Megatron-BERT model)"),RQe.forEach(t),ocr=i(D),WT=n(D,"LI",{});var PQe=s(WT);qEe=n(PQe,"STRONG",{});var CUt=s(qEe);rcr=r(CUt,"mobilebert"),CUt.forEach(t),tcr=r(PQe," \u2014 "),qJ=n(PQe,"A",{href:!0});var wUt=s(qJ);acr=r(wUt,"MobileBertForSequenceClassification"),wUt.forEach(t),ncr=r(PQe," (MobileBERT model)"),PQe.forEach(t),scr=i(D),UT=n(D,"LI",{});var BQe=s(UT);jEe=n(BQe,"STRONG",{});var AUt=s(jEe);lcr=r(AUt,"mpnet"),AUt.forEach(t),icr=r(BQe," \u2014 "),jJ=n(BQe,"A",{href:!0});var LUt=s(jJ);dcr=r(LUt,"MPNetForSequenceClassification"),LUt.forEach(t),mcr=r(BQe," (MPNet model)"),BQe.forEach(t),ccr=i(D),HT=n(D,"LI",{});var IQe=s(HT);DEe=n(IQe,"STRONG",{});var yUt=s(DEe);fcr=r(yUt,"mvp"),yUt.forEach(t),gcr=r(IQe," \u2014 "),DJ=n(IQe,"A",{href:!0});var xUt=s(DJ);hcr=r(xUt,"MvpForSequenceClassification"),xUt.forEach(t),ucr=r(IQe," (MVP model)"),IQe.forEach(t),pcr=i(D),JT=n(D,"LI",{});var NQe=s(JT);GEe=n(NQe,"STRONG",{});var $Ut=s(GEe);_cr=r($Ut,"nezha"),$Ut.forEach(t),bcr=r(NQe," \u2014 "),GJ=n(NQe,"A",{href:!0});var kUt=s(GJ);vcr=r(kUt,"NezhaForSequenceClassification"),kUt.forEach(t),Fcr=r(NQe," (Nezha model)"),NQe.forEach(t),Tcr=i(D),YT=n(D,"LI",{});var qQe=s(YT);OEe=n(qQe,"STRONG",{});var SUt=s(OEe);Mcr=r(SUt,"nystromformer"),SUt.forEach(t),Ecr=r(qQe," \u2014 "),OJ=n(qQe,"A",{href:!0});var RUt=s(OJ);Ccr=r(RUt,"NystromformerForSequenceClassification"),RUt.forEach(t),wcr=r(qQe," (Nystr\xF6mformer model)"),qQe.forEach(t),Acr=i(D),ZT=n(D,"LI",{});var jQe=s(ZT);VEe=n(jQe,"STRONG",{});var PUt=s(VEe);Lcr=r(PUt,"openai-gpt"),PUt.forEach(t),ycr=r(jQe," \u2014 "),VJ=n(jQe,"A",{href:!0});var BUt=s(VJ);xcr=r(BUt,"OpenAIGPTForSequenceClassification"),BUt.forEach(t),$cr=r(jQe," (OpenAI GPT model)"),jQe.forEach(t),kcr=i(D),KT=n(D,"LI",{});var DQe=s(KT);XEe=n(DQe,"STRONG",{});var IUt=s(XEe);Scr=r(IUt,"opt"),IUt.forEach(t),Rcr=r(DQe," \u2014 "),XJ=n(DQe,"A",{href:!0});var NUt=s(XJ);Pcr=r(NUt,"OPTForSequenceClassification"),NUt.forEach(t),Bcr=r(DQe," (OPT model)"),DQe.forEach(t),Icr=i(D),eM=n(D,"LI",{});var GQe=s(eM);zEe=n(GQe,"STRONG",{});var qUt=s(zEe);Ncr=r(qUt,"perceiver"),qUt.forEach(t),qcr=r(GQe," \u2014 "),zJ=n(GQe,"A",{href:!0});var jUt=s(zJ);jcr=r(jUt,"PerceiverForSequenceClassification"),jUt.forEach(t),Dcr=r(GQe," (Perceiver model)"),GQe.forEach(t),Gcr=i(D),oM=n(D,"LI",{});var OQe=s(oM);QEe=n(OQe,"STRONG",{});var DUt=s(QEe);Ocr=r(DUt,"plbart"),DUt.forEach(t),Vcr=r(OQe," \u2014 "),QJ=n(OQe,"A",{href:!0});var GUt=s(QJ);Xcr=r(GUt,"PLBartForSequenceClassification"),GUt.forEach(t),zcr=r(OQe," (PLBart model)"),OQe.forEach(t),Qcr=i(D),rM=n(D,"LI",{});var VQe=s(rM);WEe=n(VQe,"STRONG",{});var OUt=s(WEe);Wcr=r(OUt,"qdqbert"),OUt.forEach(t),Ucr=r(VQe," \u2014 "),WJ=n(VQe,"A",{href:!0});var VUt=s(WJ);Hcr=r(VUt,"QDQBertForSequenceClassification"),VUt.forEach(t),Jcr=r(VQe," (QDQBert model)"),VQe.forEach(t),Ycr=i(D),tM=n(D,"LI",{});var XQe=s(tM);UEe=n(XQe,"STRONG",{});var XUt=s(UEe);Zcr=r(XUt,"reformer"),XUt.forEach(t),Kcr=r(XQe," \u2014 "),UJ=n(XQe,"A",{href:!0});var zUt=s(UJ);efr=r(zUt,"ReformerForSequenceClassification"),zUt.forEach(t),ofr=r(XQe," (Reformer model)"),XQe.forEach(t),rfr=i(D),aM=n(D,"LI",{});var zQe=s(aM);HEe=n(zQe,"STRONG",{});var QUt=s(HEe);tfr=r(QUt,"rembert"),QUt.forEach(t),afr=r(zQe," \u2014 "),HJ=n(zQe,"A",{href:!0});var WUt=s(HJ);nfr=r(WUt,"RemBertForSequenceClassification"),WUt.forEach(t),sfr=r(zQe," (RemBERT model)"),zQe.forEach(t),lfr=i(D),nM=n(D,"LI",{});var QQe=s(nM);JEe=n(QQe,"STRONG",{});var UUt=s(JEe);ifr=r(UUt,"roberta"),UUt.forEach(t),dfr=r(QQe," \u2014 "),JJ=n(QQe,"A",{href:!0});var HUt=s(JJ);mfr=r(HUt,"RobertaForSequenceClassification"),HUt.forEach(t),cfr=r(QQe," (RoBERTa model)"),QQe.forEach(t),ffr=i(D),sM=n(D,"LI",{});var WQe=s(sM);YEe=n(WQe,"STRONG",{});var JUt=s(YEe);gfr=r(JUt,"roformer"),JUt.forEach(t),hfr=r(WQe," \u2014 "),YJ=n(WQe,"A",{href:!0});var YUt=s(YJ);ufr=r(YUt,"RoFormerForSequenceClassification"),YUt.forEach(t),pfr=r(WQe," (RoFormer model)"),WQe.forEach(t),_fr=i(D),lM=n(D,"LI",{});var UQe=s(lM);ZEe=n(UQe,"STRONG",{});var ZUt=s(ZEe);bfr=r(ZUt,"squeezebert"),ZUt.forEach(t),vfr=r(UQe," \u2014 "),ZJ=n(UQe,"A",{href:!0});var KUt=s(ZJ);Ffr=r(KUt,"SqueezeBertForSequenceClassification"),KUt.forEach(t),Tfr=r(UQe," (SqueezeBERT model)"),UQe.forEach(t),Mfr=i(D),iM=n(D,"LI",{});var HQe=s(iM);KEe=n(HQe,"STRONG",{});var eHt=s(KEe);Efr=r(eHt,"tapas"),eHt.forEach(t),Cfr=r(HQe," \u2014 "),KJ=n(HQe,"A",{href:!0});var oHt=s(KJ);wfr=r(oHt,"TapasForSequenceClassification"),oHt.forEach(t),Afr=r(HQe," (TAPAS model)"),HQe.forEach(t),Lfr=i(D),dM=n(D,"LI",{});var JQe=s(dM);e4e=n(JQe,"STRONG",{});var rHt=s(e4e);yfr=r(rHt,"transfo-xl"),rHt.forEach(t),xfr=r(JQe," \u2014 "),eY=n(JQe,"A",{href:!0});var tHt=s(eY);$fr=r(tHt,"TransfoXLForSequenceClassification"),tHt.forEach(t),kfr=r(JQe," (Transformer-XL model)"),JQe.forEach(t),Sfr=i(D),mM=n(D,"LI",{});var YQe=s(mM);o4e=n(YQe,"STRONG",{});var aHt=s(o4e);Rfr=r(aHt,"xlm"),aHt.forEach(t),Pfr=r(YQe," \u2014 "),oY=n(YQe,"A",{href:!0});var nHt=s(oY);Bfr=r(nHt,"XLMForSequenceClassification"),nHt.forEach(t),Ifr=r(YQe," (XLM model)"),YQe.forEach(t),Nfr=i(D),cM=n(D,"LI",{});var ZQe=s(cM);r4e=n(ZQe,"STRONG",{});var sHt=s(r4e);qfr=r(sHt,"xlm-roberta"),sHt.forEach(t),jfr=r(ZQe," \u2014 "),rY=n(ZQe,"A",{href:!0});var lHt=s(rY);Dfr=r(lHt,"XLMRobertaForSequenceClassification"),lHt.forEach(t),Gfr=r(ZQe," (XLM-RoBERTa model)"),ZQe.forEach(t),Ofr=i(D),fM=n(D,"LI",{});var KQe=s(fM);t4e=n(KQe,"STRONG",{});var iHt=s(t4e);Vfr=r(iHt,"xlm-roberta-xl"),iHt.forEach(t),Xfr=r(KQe," \u2014 "),tY=n(KQe,"A",{href:!0});var dHt=s(tY);zfr=r(dHt,"XLMRobertaXLForSequenceClassification"),dHt.forEach(t),Qfr=r(KQe," (XLM-RoBERTa-XL model)"),KQe.forEach(t),Wfr=i(D),gM=n(D,"LI",{});var eWe=s(gM);a4e=n(eWe,"STRONG",{});var mHt=s(a4e);Ufr=r(mHt,"xlnet"),mHt.forEach(t),Hfr=r(eWe," \u2014 "),aY=n(eWe,"A",{href:!0});var cHt=s(aY);Jfr=r(cHt,"XLNetForSequenceClassification"),cHt.forEach(t),Yfr=r(eWe," (XLNet model)"),eWe.forEach(t),Zfr=i(D),hM=n(D,"LI",{});var oWe=s(hM);n4e=n(oWe,"STRONG",{});var fHt=s(n4e);Kfr=r(fHt,"yoso"),fHt.forEach(t),egr=r(oWe," \u2014 "),nY=n(oWe,"A",{href:!0});var gHt=s(nY);ogr=r(gHt,"YosoForSequenceClassification"),gHt.forEach(t),rgr=r(oWe," (YOSO model)"),oWe.forEach(t),D.forEach(t),tgr=i(Ra),uM=n(Ra,"P",{});var rWe=s(uM);agr=r(rWe,"The model is set in evaluation mode by default using "),s4e=n(rWe,"CODE",{});var hHt=s(s4e);ngr=r(hHt,"model.eval()"),hHt.forEach(t),sgr=r(rWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),l4e=n(rWe,"CODE",{});var uHt=s(l4e);lgr=r(uHt,"model.train()"),uHt.forEach(t),rWe.forEach(t),igr=i(Ra),T(pM.$$.fragment,Ra),Ra.forEach(t),Xl.forEach(t),Zto=i(c),Kd=n(c,"H2",{class:!0});var _so=s(Kd);_M=n(_so,"A",{id:!0,class:!0,href:!0});var pHt=s(_M);i4e=n(pHt,"SPAN",{});var _Ht=s(i4e);T(_k.$$.fragment,_Ht),_Ht.forEach(t),pHt.forEach(t),dgr=i(_so),d4e=n(_so,"SPAN",{});var bHt=s(d4e);mgr=r(bHt,"AutoModelForMultipleChoice"),bHt.forEach(t),_so.forEach(t),Kto=i(c),Vo=n(c,"DIV",{class:!0});var zl=s(Vo);T(bk.$$.fragment,zl),cgr=i(zl),em=n(zl,"P",{});var bme=s(em);fgr=r(bme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),sY=n(bme,"A",{href:!0});var vHt=s(sY);ggr=r(vHt,"from_pretrained()"),vHt.forEach(t),hgr=r(bme," class method or the "),lY=n(bme,"A",{href:!0});var FHt=s(lY);ugr=r(FHt,"from_config()"),FHt.forEach(t),pgr=r(bme,` class
method.`),bme.forEach(t),_gr=i(zl),vk=n(zl,"P",{});var bso=s(vk);bgr=r(bso,"This class cannot be instantiated directly using "),m4e=n(bso,"CODE",{});var THt=s(m4e);vgr=r(THt,"__init__()"),THt.forEach(t),Fgr=r(bso," (throws an error)."),bso.forEach(t),Tgr=i(zl),xt=n(zl,"DIV",{class:!0});var h9=s(xt);T(Fk.$$.fragment,h9),Mgr=i(h9),c4e=n(h9,"P",{});var MHt=s(c4e);Egr=r(MHt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),MHt.forEach(t),Cgr=i(h9),om=n(h9,"P",{});var vme=s(om);wgr=r(vme,`Note:
Loading a model from its configuration file does `),f4e=n(vme,"STRONG",{});var EHt=s(f4e);Agr=r(EHt,"not"),EHt.forEach(t),Lgr=r(vme,` load the model weights. It only affects the
model\u2019s configuration. Use `),iY=n(vme,"A",{href:!0});var CHt=s(iY);ygr=r(CHt,"from_pretrained()"),CHt.forEach(t),xgr=r(vme," to load the model weights."),vme.forEach(t),$gr=i(h9),T(bM.$$.fragment,h9),h9.forEach(t),kgr=i(zl),so=n(zl,"DIV",{class:!0});var Pa=s(so);T(Tk.$$.fragment,Pa),Sgr=i(Pa),g4e=n(Pa,"P",{});var wHt=s(g4e);Rgr=r(wHt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),wHt.forEach(t),Pgr=i(Pa),gn=n(Pa,"P",{});var u9=s(gn);Bgr=r(u9,"The model class to instantiate is selected based on the "),h4e=n(u9,"CODE",{});var AHt=s(h4e);Igr=r(AHt,"model_type"),AHt.forEach(t),Ngr=r(u9,` property of the config object (either
passed as an argument or loaded from `),u4e=n(u9,"CODE",{});var LHt=s(u4e);qgr=r(LHt,"pretrained_model_name_or_path"),LHt.forEach(t),jgr=r(u9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p4e=n(u9,"CODE",{});var yHt=s(p4e);Dgr=r(yHt,"pretrained_model_name_or_path"),yHt.forEach(t),Ggr=r(u9,":"),u9.forEach(t),Ogr=i(Pa),K=n(Pa,"UL",{});var ee=s(K);vM=n(ee,"LI",{});var tWe=s(vM);_4e=n(tWe,"STRONG",{});var xHt=s(_4e);Vgr=r(xHt,"albert"),xHt.forEach(t),Xgr=r(tWe," \u2014 "),dY=n(tWe,"A",{href:!0});var $Ht=s(dY);zgr=r($Ht,"AlbertForMultipleChoice"),$Ht.forEach(t),Qgr=r(tWe," (ALBERT model)"),tWe.forEach(t),Wgr=i(ee),FM=n(ee,"LI",{});var aWe=s(FM);b4e=n(aWe,"STRONG",{});var kHt=s(b4e);Ugr=r(kHt,"bert"),kHt.forEach(t),Hgr=r(aWe," \u2014 "),mY=n(aWe,"A",{href:!0});var SHt=s(mY);Jgr=r(SHt,"BertForMultipleChoice"),SHt.forEach(t),Ygr=r(aWe," (BERT model)"),aWe.forEach(t),Zgr=i(ee),TM=n(ee,"LI",{});var nWe=s(TM);v4e=n(nWe,"STRONG",{});var RHt=s(v4e);Kgr=r(RHt,"big_bird"),RHt.forEach(t),ehr=r(nWe," \u2014 "),cY=n(nWe,"A",{href:!0});var PHt=s(cY);ohr=r(PHt,"BigBirdForMultipleChoice"),PHt.forEach(t),rhr=r(nWe," (BigBird model)"),nWe.forEach(t),thr=i(ee),MM=n(ee,"LI",{});var sWe=s(MM);F4e=n(sWe,"STRONG",{});var BHt=s(F4e);ahr=r(BHt,"camembert"),BHt.forEach(t),nhr=r(sWe," \u2014 "),fY=n(sWe,"A",{href:!0});var IHt=s(fY);shr=r(IHt,"CamembertForMultipleChoice"),IHt.forEach(t),lhr=r(sWe," (CamemBERT model)"),sWe.forEach(t),ihr=i(ee),EM=n(ee,"LI",{});var lWe=s(EM);T4e=n(lWe,"STRONG",{});var NHt=s(T4e);dhr=r(NHt,"canine"),NHt.forEach(t),mhr=r(lWe," \u2014 "),gY=n(lWe,"A",{href:!0});var qHt=s(gY);chr=r(qHt,"CanineForMultipleChoice"),qHt.forEach(t),fhr=r(lWe," (CANINE model)"),lWe.forEach(t),ghr=i(ee),CM=n(ee,"LI",{});var iWe=s(CM);M4e=n(iWe,"STRONG",{});var jHt=s(M4e);hhr=r(jHt,"convbert"),jHt.forEach(t),uhr=r(iWe," \u2014 "),hY=n(iWe,"A",{href:!0});var DHt=s(hY);phr=r(DHt,"ConvBertForMultipleChoice"),DHt.forEach(t),_hr=r(iWe," (ConvBERT model)"),iWe.forEach(t),bhr=i(ee),wM=n(ee,"LI",{});var dWe=s(wM);E4e=n(dWe,"STRONG",{});var GHt=s(E4e);vhr=r(GHt,"data2vec-text"),GHt.forEach(t),Fhr=r(dWe," \u2014 "),uY=n(dWe,"A",{href:!0});var OHt=s(uY);Thr=r(OHt,"Data2VecTextForMultipleChoice"),OHt.forEach(t),Mhr=r(dWe," (Data2VecText model)"),dWe.forEach(t),Ehr=i(ee),AM=n(ee,"LI",{});var mWe=s(AM);C4e=n(mWe,"STRONG",{});var VHt=s(C4e);Chr=r(VHt,"deberta-v2"),VHt.forEach(t),whr=r(mWe," \u2014 "),pY=n(mWe,"A",{href:!0});var XHt=s(pY);Ahr=r(XHt,"DebertaV2ForMultipleChoice"),XHt.forEach(t),Lhr=r(mWe," (DeBERTa-v2 model)"),mWe.forEach(t),yhr=i(ee),LM=n(ee,"LI",{});var cWe=s(LM);w4e=n(cWe,"STRONG",{});var zHt=s(w4e);xhr=r(zHt,"distilbert"),zHt.forEach(t),$hr=r(cWe," \u2014 "),_Y=n(cWe,"A",{href:!0});var QHt=s(_Y);khr=r(QHt,"DistilBertForMultipleChoice"),QHt.forEach(t),Shr=r(cWe," (DistilBERT model)"),cWe.forEach(t),Rhr=i(ee),yM=n(ee,"LI",{});var fWe=s(yM);A4e=n(fWe,"STRONG",{});var WHt=s(A4e);Phr=r(WHt,"electra"),WHt.forEach(t),Bhr=r(fWe," \u2014 "),bY=n(fWe,"A",{href:!0});var UHt=s(bY);Ihr=r(UHt,"ElectraForMultipleChoice"),UHt.forEach(t),Nhr=r(fWe," (ELECTRA model)"),fWe.forEach(t),qhr=i(ee),xM=n(ee,"LI",{});var gWe=s(xM);L4e=n(gWe,"STRONG",{});var HHt=s(L4e);jhr=r(HHt,"ernie"),HHt.forEach(t),Dhr=r(gWe," \u2014 "),vY=n(gWe,"A",{href:!0});var JHt=s(vY);Ghr=r(JHt,"ErnieForMultipleChoice"),JHt.forEach(t),Ohr=r(gWe," (ERNIE model)"),gWe.forEach(t),Vhr=i(ee),$M=n(ee,"LI",{});var hWe=s($M);y4e=n(hWe,"STRONG",{});var YHt=s(y4e);Xhr=r(YHt,"flaubert"),YHt.forEach(t),zhr=r(hWe," \u2014 "),FY=n(hWe,"A",{href:!0});var ZHt=s(FY);Qhr=r(ZHt,"FlaubertForMultipleChoice"),ZHt.forEach(t),Whr=r(hWe," (FlauBERT model)"),hWe.forEach(t),Uhr=i(ee),kM=n(ee,"LI",{});var uWe=s(kM);x4e=n(uWe,"STRONG",{});var KHt=s(x4e);Hhr=r(KHt,"fnet"),KHt.forEach(t),Jhr=r(uWe," \u2014 "),TY=n(uWe,"A",{href:!0});var eJt=s(TY);Yhr=r(eJt,"FNetForMultipleChoice"),eJt.forEach(t),Zhr=r(uWe," (FNet model)"),uWe.forEach(t),Khr=i(ee),SM=n(ee,"LI",{});var pWe=s(SM);$4e=n(pWe,"STRONG",{});var oJt=s($4e);eur=r(oJt,"funnel"),oJt.forEach(t),our=r(pWe," \u2014 "),MY=n(pWe,"A",{href:!0});var rJt=s(MY);rur=r(rJt,"FunnelForMultipleChoice"),rJt.forEach(t),tur=r(pWe," (Funnel Transformer model)"),pWe.forEach(t),aur=i(ee),RM=n(ee,"LI",{});var _We=s(RM);k4e=n(_We,"STRONG",{});var tJt=s(k4e);nur=r(tJt,"ibert"),tJt.forEach(t),sur=r(_We," \u2014 "),EY=n(_We,"A",{href:!0});var aJt=s(EY);lur=r(aJt,"IBertForMultipleChoice"),aJt.forEach(t),iur=r(_We," (I-BERT model)"),_We.forEach(t),dur=i(ee),PM=n(ee,"LI",{});var bWe=s(PM);S4e=n(bWe,"STRONG",{});var nJt=s(S4e);mur=r(nJt,"longformer"),nJt.forEach(t),cur=r(bWe," \u2014 "),CY=n(bWe,"A",{href:!0});var sJt=s(CY);fur=r(sJt,"LongformerForMultipleChoice"),sJt.forEach(t),gur=r(bWe," (Longformer model)"),bWe.forEach(t),hur=i(ee),BM=n(ee,"LI",{});var vWe=s(BM);R4e=n(vWe,"STRONG",{});var lJt=s(R4e);uur=r(lJt,"luke"),lJt.forEach(t),pur=r(vWe," \u2014 "),wY=n(vWe,"A",{href:!0});var iJt=s(wY);_ur=r(iJt,"LukeForMultipleChoice"),iJt.forEach(t),bur=r(vWe," (LUKE model)"),vWe.forEach(t),vur=i(ee),IM=n(ee,"LI",{});var FWe=s(IM);P4e=n(FWe,"STRONG",{});var dJt=s(P4e);Fur=r(dJt,"megatron-bert"),dJt.forEach(t),Tur=r(FWe," \u2014 "),AY=n(FWe,"A",{href:!0});var mJt=s(AY);Mur=r(mJt,"MegatronBertForMultipleChoice"),mJt.forEach(t),Eur=r(FWe," (Megatron-BERT model)"),FWe.forEach(t),Cur=i(ee),NM=n(ee,"LI",{});var TWe=s(NM);B4e=n(TWe,"STRONG",{});var cJt=s(B4e);wur=r(cJt,"mobilebert"),cJt.forEach(t),Aur=r(TWe," \u2014 "),LY=n(TWe,"A",{href:!0});var fJt=s(LY);Lur=r(fJt,"MobileBertForMultipleChoice"),fJt.forEach(t),yur=r(TWe," (MobileBERT model)"),TWe.forEach(t),xur=i(ee),qM=n(ee,"LI",{});var MWe=s(qM);I4e=n(MWe,"STRONG",{});var gJt=s(I4e);$ur=r(gJt,"mpnet"),gJt.forEach(t),kur=r(MWe," \u2014 "),yY=n(MWe,"A",{href:!0});var hJt=s(yY);Sur=r(hJt,"MPNetForMultipleChoice"),hJt.forEach(t),Rur=r(MWe," (MPNet model)"),MWe.forEach(t),Pur=i(ee),jM=n(ee,"LI",{});var EWe=s(jM);N4e=n(EWe,"STRONG",{});var uJt=s(N4e);Bur=r(uJt,"nezha"),uJt.forEach(t),Iur=r(EWe," \u2014 "),xY=n(EWe,"A",{href:!0});var pJt=s(xY);Nur=r(pJt,"NezhaForMultipleChoice"),pJt.forEach(t),qur=r(EWe," (Nezha model)"),EWe.forEach(t),jur=i(ee),DM=n(ee,"LI",{});var CWe=s(DM);q4e=n(CWe,"STRONG",{});var _Jt=s(q4e);Dur=r(_Jt,"nystromformer"),_Jt.forEach(t),Gur=r(CWe," \u2014 "),$Y=n(CWe,"A",{href:!0});var bJt=s($Y);Our=r(bJt,"NystromformerForMultipleChoice"),bJt.forEach(t),Vur=r(CWe," (Nystr\xF6mformer model)"),CWe.forEach(t),Xur=i(ee),GM=n(ee,"LI",{});var wWe=s(GM);j4e=n(wWe,"STRONG",{});var vJt=s(j4e);zur=r(vJt,"qdqbert"),vJt.forEach(t),Qur=r(wWe," \u2014 "),kY=n(wWe,"A",{href:!0});var FJt=s(kY);Wur=r(FJt,"QDQBertForMultipleChoice"),FJt.forEach(t),Uur=r(wWe," (QDQBert model)"),wWe.forEach(t),Hur=i(ee),OM=n(ee,"LI",{});var AWe=s(OM);D4e=n(AWe,"STRONG",{});var TJt=s(D4e);Jur=r(TJt,"rembert"),TJt.forEach(t),Yur=r(AWe," \u2014 "),SY=n(AWe,"A",{href:!0});var MJt=s(SY);Zur=r(MJt,"RemBertForMultipleChoice"),MJt.forEach(t),Kur=r(AWe," (RemBERT model)"),AWe.forEach(t),epr=i(ee),VM=n(ee,"LI",{});var LWe=s(VM);G4e=n(LWe,"STRONG",{});var EJt=s(G4e);opr=r(EJt,"roberta"),EJt.forEach(t),rpr=r(LWe," \u2014 "),RY=n(LWe,"A",{href:!0});var CJt=s(RY);tpr=r(CJt,"RobertaForMultipleChoice"),CJt.forEach(t),apr=r(LWe," (RoBERTa model)"),LWe.forEach(t),npr=i(ee),XM=n(ee,"LI",{});var yWe=s(XM);O4e=n(yWe,"STRONG",{});var wJt=s(O4e);spr=r(wJt,"roformer"),wJt.forEach(t),lpr=r(yWe," \u2014 "),PY=n(yWe,"A",{href:!0});var AJt=s(PY);ipr=r(AJt,"RoFormerForMultipleChoice"),AJt.forEach(t),dpr=r(yWe," (RoFormer model)"),yWe.forEach(t),mpr=i(ee),zM=n(ee,"LI",{});var xWe=s(zM);V4e=n(xWe,"STRONG",{});var LJt=s(V4e);cpr=r(LJt,"squeezebert"),LJt.forEach(t),fpr=r(xWe," \u2014 "),BY=n(xWe,"A",{href:!0});var yJt=s(BY);gpr=r(yJt,"SqueezeBertForMultipleChoice"),yJt.forEach(t),hpr=r(xWe," (SqueezeBERT model)"),xWe.forEach(t),upr=i(ee),QM=n(ee,"LI",{});var $We=s(QM);X4e=n($We,"STRONG",{});var xJt=s(X4e);ppr=r(xJt,"xlm"),xJt.forEach(t),_pr=r($We," \u2014 "),IY=n($We,"A",{href:!0});var $Jt=s(IY);bpr=r($Jt,"XLMForMultipleChoice"),$Jt.forEach(t),vpr=r($We," (XLM model)"),$We.forEach(t),Fpr=i(ee),WM=n(ee,"LI",{});var kWe=s(WM);z4e=n(kWe,"STRONG",{});var kJt=s(z4e);Tpr=r(kJt,"xlm-roberta"),kJt.forEach(t),Mpr=r(kWe," \u2014 "),NY=n(kWe,"A",{href:!0});var SJt=s(NY);Epr=r(SJt,"XLMRobertaForMultipleChoice"),SJt.forEach(t),Cpr=r(kWe," (XLM-RoBERTa model)"),kWe.forEach(t),wpr=i(ee),UM=n(ee,"LI",{});var SWe=s(UM);Q4e=n(SWe,"STRONG",{});var RJt=s(Q4e);Apr=r(RJt,"xlm-roberta-xl"),RJt.forEach(t),Lpr=r(SWe," \u2014 "),qY=n(SWe,"A",{href:!0});var PJt=s(qY);ypr=r(PJt,"XLMRobertaXLForMultipleChoice"),PJt.forEach(t),xpr=r(SWe," (XLM-RoBERTa-XL model)"),SWe.forEach(t),$pr=i(ee),HM=n(ee,"LI",{});var RWe=s(HM);W4e=n(RWe,"STRONG",{});var BJt=s(W4e);kpr=r(BJt,"xlnet"),BJt.forEach(t),Spr=r(RWe," \u2014 "),jY=n(RWe,"A",{href:!0});var IJt=s(jY);Rpr=r(IJt,"XLNetForMultipleChoice"),IJt.forEach(t),Ppr=r(RWe," (XLNet model)"),RWe.forEach(t),Bpr=i(ee),JM=n(ee,"LI",{});var PWe=s(JM);U4e=n(PWe,"STRONG",{});var NJt=s(U4e);Ipr=r(NJt,"yoso"),NJt.forEach(t),Npr=r(PWe," \u2014 "),DY=n(PWe,"A",{href:!0});var qJt=s(DY);qpr=r(qJt,"YosoForMultipleChoice"),qJt.forEach(t),jpr=r(PWe," (YOSO model)"),PWe.forEach(t),ee.forEach(t),Dpr=i(Pa),YM=n(Pa,"P",{});var BWe=s(YM);Gpr=r(BWe,"The model is set in evaluation mode by default using "),H4e=n(BWe,"CODE",{});var jJt=s(H4e);Opr=r(jJt,"model.eval()"),jJt.forEach(t),Vpr=r(BWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),J4e=n(BWe,"CODE",{});var DJt=s(J4e);Xpr=r(DJt,"model.train()"),DJt.forEach(t),BWe.forEach(t),zpr=i(Pa),T(ZM.$$.fragment,Pa),Pa.forEach(t),zl.forEach(t),eao=i(c),rm=n(c,"H2",{class:!0});var vso=s(rm);KM=n(vso,"A",{id:!0,class:!0,href:!0});var GJt=s(KM);Y4e=n(GJt,"SPAN",{});var OJt=s(Y4e);T(Mk.$$.fragment,OJt),OJt.forEach(t),GJt.forEach(t),Qpr=i(vso),Z4e=n(vso,"SPAN",{});var VJt=s(Z4e);Wpr=r(VJt,"AutoModelForNextSentencePrediction"),VJt.forEach(t),vso.forEach(t),oao=i(c),Xo=n(c,"DIV",{class:!0});var Ql=s(Xo);T(Ek.$$.fragment,Ql),Upr=i(Ql),tm=n(Ql,"P",{});var Fme=s(tm);Hpr=r(Fme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),GY=n(Fme,"A",{href:!0});var XJt=s(GY);Jpr=r(XJt,"from_pretrained()"),XJt.forEach(t),Ypr=r(Fme," class method or the "),OY=n(Fme,"A",{href:!0});var zJt=s(OY);Zpr=r(zJt,"from_config()"),zJt.forEach(t),Kpr=r(Fme,` class
method.`),Fme.forEach(t),e_r=i(Ql),Ck=n(Ql,"P",{});var Fso=s(Ck);o_r=r(Fso,"This class cannot be instantiated directly using "),K4e=n(Fso,"CODE",{});var QJt=s(K4e);r_r=r(QJt,"__init__()"),QJt.forEach(t),t_r=r(Fso," (throws an error)."),Fso.forEach(t),a_r=i(Ql),$t=n(Ql,"DIV",{class:!0});var p9=s($t);T(wk.$$.fragment,p9),n_r=i(p9),eCe=n(p9,"P",{});var WJt=s(eCe);s_r=r(WJt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),WJt.forEach(t),l_r=i(p9),am=n(p9,"P",{});var Tme=s(am);i_r=r(Tme,`Note:
Loading a model from its configuration file does `),oCe=n(Tme,"STRONG",{});var UJt=s(oCe);d_r=r(UJt,"not"),UJt.forEach(t),m_r=r(Tme,` load the model weights. It only affects the
model\u2019s configuration. Use `),VY=n(Tme,"A",{href:!0});var HJt=s(VY);c_r=r(HJt,"from_pretrained()"),HJt.forEach(t),f_r=r(Tme," to load the model weights."),Tme.forEach(t),g_r=i(p9),T(eE.$$.fragment,p9),p9.forEach(t),h_r=i(Ql),lo=n(Ql,"DIV",{class:!0});var Ba=s(lo);T(Ak.$$.fragment,Ba),u_r=i(Ba),rCe=n(Ba,"P",{});var JJt=s(rCe);p_r=r(JJt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),JJt.forEach(t),__r=i(Ba),hn=n(Ba,"P",{});var _9=s(hn);b_r=r(_9,"The model class to instantiate is selected based on the "),tCe=n(_9,"CODE",{});var YJt=s(tCe);v_r=r(YJt,"model_type"),YJt.forEach(t),F_r=r(_9,` property of the config object (either
passed as an argument or loaded from `),aCe=n(_9,"CODE",{});var ZJt=s(aCe);T_r=r(ZJt,"pretrained_model_name_or_path"),ZJt.forEach(t),M_r=r(_9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nCe=n(_9,"CODE",{});var KJt=s(nCe);E_r=r(KJt,"pretrained_model_name_or_path"),KJt.forEach(t),C_r=r(_9,":"),_9.forEach(t),w_r=i(Ba),Ue=n(Ba,"UL",{});var ht=s(Ue);oE=n(ht,"LI",{});var IWe=s(oE);sCe=n(IWe,"STRONG",{});var eYt=s(sCe);A_r=r(eYt,"bert"),eYt.forEach(t),L_r=r(IWe," \u2014 "),XY=n(IWe,"A",{href:!0});var oYt=s(XY);y_r=r(oYt,"BertForNextSentencePrediction"),oYt.forEach(t),x_r=r(IWe," (BERT model)"),IWe.forEach(t),$_r=i(ht),rE=n(ht,"LI",{});var NWe=s(rE);lCe=n(NWe,"STRONG",{});var rYt=s(lCe);k_r=r(rYt,"ernie"),rYt.forEach(t),S_r=r(NWe," \u2014 "),zY=n(NWe,"A",{href:!0});var tYt=s(zY);R_r=r(tYt,"ErnieForNextSentencePrediction"),tYt.forEach(t),P_r=r(NWe," (ERNIE model)"),NWe.forEach(t),B_r=i(ht),tE=n(ht,"LI",{});var qWe=s(tE);iCe=n(qWe,"STRONG",{});var aYt=s(iCe);I_r=r(aYt,"fnet"),aYt.forEach(t),N_r=r(qWe," \u2014 "),QY=n(qWe,"A",{href:!0});var nYt=s(QY);q_r=r(nYt,"FNetForNextSentencePrediction"),nYt.forEach(t),j_r=r(qWe," (FNet model)"),qWe.forEach(t),D_r=i(ht),aE=n(ht,"LI",{});var jWe=s(aE);dCe=n(jWe,"STRONG",{});var sYt=s(dCe);G_r=r(sYt,"megatron-bert"),sYt.forEach(t),O_r=r(jWe," \u2014 "),WY=n(jWe,"A",{href:!0});var lYt=s(WY);V_r=r(lYt,"MegatronBertForNextSentencePrediction"),lYt.forEach(t),X_r=r(jWe," (Megatron-BERT model)"),jWe.forEach(t),z_r=i(ht),nE=n(ht,"LI",{});var DWe=s(nE);mCe=n(DWe,"STRONG",{});var iYt=s(mCe);Q_r=r(iYt,"mobilebert"),iYt.forEach(t),W_r=r(DWe," \u2014 "),UY=n(DWe,"A",{href:!0});var dYt=s(UY);U_r=r(dYt,"MobileBertForNextSentencePrediction"),dYt.forEach(t),H_r=r(DWe," (MobileBERT model)"),DWe.forEach(t),J_r=i(ht),sE=n(ht,"LI",{});var GWe=s(sE);cCe=n(GWe,"STRONG",{});var mYt=s(cCe);Y_r=r(mYt,"nezha"),mYt.forEach(t),Z_r=r(GWe," \u2014 "),HY=n(GWe,"A",{href:!0});var cYt=s(HY);K_r=r(cYt,"NezhaForNextSentencePrediction"),cYt.forEach(t),e1r=r(GWe," (Nezha model)"),GWe.forEach(t),o1r=i(ht),lE=n(ht,"LI",{});var OWe=s(lE);fCe=n(OWe,"STRONG",{});var fYt=s(fCe);r1r=r(fYt,"qdqbert"),fYt.forEach(t),t1r=r(OWe," \u2014 "),JY=n(OWe,"A",{href:!0});var gYt=s(JY);a1r=r(gYt,"QDQBertForNextSentencePrediction"),gYt.forEach(t),n1r=r(OWe," (QDQBert model)"),OWe.forEach(t),ht.forEach(t),s1r=i(Ba),iE=n(Ba,"P",{});var VWe=s(iE);l1r=r(VWe,"The model is set in evaluation mode by default using "),gCe=n(VWe,"CODE",{});var hYt=s(gCe);i1r=r(hYt,"model.eval()"),hYt.forEach(t),d1r=r(VWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),hCe=n(VWe,"CODE",{});var uYt=s(hCe);m1r=r(uYt,"model.train()"),uYt.forEach(t),VWe.forEach(t),c1r=i(Ba),T(dE.$$.fragment,Ba),Ba.forEach(t),Ql.forEach(t),rao=i(c),nm=n(c,"H2",{class:!0});var Tso=s(nm);mE=n(Tso,"A",{id:!0,class:!0,href:!0});var pYt=s(mE);uCe=n(pYt,"SPAN",{});var _Yt=s(uCe);T(Lk.$$.fragment,_Yt),_Yt.forEach(t),pYt.forEach(t),f1r=i(Tso),pCe=n(Tso,"SPAN",{});var bYt=s(pCe);g1r=r(bYt,"AutoModelForTokenClassification"),bYt.forEach(t),Tso.forEach(t),tao=i(c),zo=n(c,"DIV",{class:!0});var Wl=s(zo);T(yk.$$.fragment,Wl),h1r=i(Wl),sm=n(Wl,"P",{});var Mme=s(sm);u1r=r(Mme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),YY=n(Mme,"A",{href:!0});var vYt=s(YY);p1r=r(vYt,"from_pretrained()"),vYt.forEach(t),_1r=r(Mme," class method or the "),ZY=n(Mme,"A",{href:!0});var FYt=s(ZY);b1r=r(FYt,"from_config()"),FYt.forEach(t),v1r=r(Mme,` class
method.`),Mme.forEach(t),F1r=i(Wl),xk=n(Wl,"P",{});var Mso=s(xk);T1r=r(Mso,"This class cannot be instantiated directly using "),_Ce=n(Mso,"CODE",{});var TYt=s(_Ce);M1r=r(TYt,"__init__()"),TYt.forEach(t),E1r=r(Mso," (throws an error)."),Mso.forEach(t),C1r=i(Wl),kt=n(Wl,"DIV",{class:!0});var b9=s(kt);T($k.$$.fragment,b9),w1r=i(b9),bCe=n(b9,"P",{});var MYt=s(bCe);A1r=r(MYt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),MYt.forEach(t),L1r=i(b9),lm=n(b9,"P",{});var Eme=s(lm);y1r=r(Eme,`Note:
Loading a model from its configuration file does `),vCe=n(Eme,"STRONG",{});var EYt=s(vCe);x1r=r(EYt,"not"),EYt.forEach(t),$1r=r(Eme,` load the model weights. It only affects the
model\u2019s configuration. Use `),KY=n(Eme,"A",{href:!0});var CYt=s(KY);k1r=r(CYt,"from_pretrained()"),CYt.forEach(t),S1r=r(Eme," to load the model weights."),Eme.forEach(t),R1r=i(b9),T(cE.$$.fragment,b9),b9.forEach(t),P1r=i(Wl),io=n(Wl,"DIV",{class:!0});var Ia=s(io);T(kk.$$.fragment,Ia),B1r=i(Ia),FCe=n(Ia,"P",{});var wYt=s(FCe);I1r=r(wYt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),wYt.forEach(t),N1r=i(Ia),un=n(Ia,"P",{});var v9=s(un);q1r=r(v9,"The model class to instantiate is selected based on the "),TCe=n(v9,"CODE",{});var AYt=s(TCe);j1r=r(AYt,"model_type"),AYt.forEach(t),D1r=r(v9,` property of the config object (either
passed as an argument or loaded from `),MCe=n(v9,"CODE",{});var LYt=s(MCe);G1r=r(LYt,"pretrained_model_name_or_path"),LYt.forEach(t),O1r=r(v9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ECe=n(v9,"CODE",{});var yYt=s(ECe);V1r=r(yYt,"pretrained_model_name_or_path"),yYt.forEach(t),X1r=r(v9,":"),v9.forEach(t),z1r=i(Ia),U=n(Ia,"UL",{});var J=s(U);fE=n(J,"LI",{});var XWe=s(fE);CCe=n(XWe,"STRONG",{});var xYt=s(CCe);Q1r=r(xYt,"albert"),xYt.forEach(t),W1r=r(XWe," \u2014 "),eZ=n(XWe,"A",{href:!0});var $Yt=s(eZ);U1r=r($Yt,"AlbertForTokenClassification"),$Yt.forEach(t),H1r=r(XWe," (ALBERT model)"),XWe.forEach(t),J1r=i(J),gE=n(J,"LI",{});var zWe=s(gE);wCe=n(zWe,"STRONG",{});var kYt=s(wCe);Y1r=r(kYt,"bert"),kYt.forEach(t),Z1r=r(zWe," \u2014 "),oZ=n(zWe,"A",{href:!0});var SYt=s(oZ);K1r=r(SYt,"BertForTokenClassification"),SYt.forEach(t),e2r=r(zWe," (BERT model)"),zWe.forEach(t),o2r=i(J),hE=n(J,"LI",{});var QWe=s(hE);ACe=n(QWe,"STRONG",{});var RYt=s(ACe);r2r=r(RYt,"big_bird"),RYt.forEach(t),t2r=r(QWe," \u2014 "),rZ=n(QWe,"A",{href:!0});var PYt=s(rZ);a2r=r(PYt,"BigBirdForTokenClassification"),PYt.forEach(t),n2r=r(QWe," (BigBird model)"),QWe.forEach(t),s2r=i(J),uE=n(J,"LI",{});var WWe=s(uE);LCe=n(WWe,"STRONG",{});var BYt=s(LCe);l2r=r(BYt,"bloom"),BYt.forEach(t),i2r=r(WWe," \u2014 "),tZ=n(WWe,"A",{href:!0});var IYt=s(tZ);d2r=r(IYt,"BloomForTokenClassification"),IYt.forEach(t),m2r=r(WWe," (BLOOM model)"),WWe.forEach(t),c2r=i(J),pE=n(J,"LI",{});var UWe=s(pE);yCe=n(UWe,"STRONG",{});var NYt=s(yCe);f2r=r(NYt,"camembert"),NYt.forEach(t),g2r=r(UWe," \u2014 "),aZ=n(UWe,"A",{href:!0});var qYt=s(aZ);h2r=r(qYt,"CamembertForTokenClassification"),qYt.forEach(t),u2r=r(UWe," (CamemBERT model)"),UWe.forEach(t),p2r=i(J),_E=n(J,"LI",{});var HWe=s(_E);xCe=n(HWe,"STRONG",{});var jYt=s(xCe);_2r=r(jYt,"canine"),jYt.forEach(t),b2r=r(HWe," \u2014 "),nZ=n(HWe,"A",{href:!0});var DYt=s(nZ);v2r=r(DYt,"CanineForTokenClassification"),DYt.forEach(t),F2r=r(HWe," (CANINE model)"),HWe.forEach(t),T2r=i(J),bE=n(J,"LI",{});var JWe=s(bE);$Ce=n(JWe,"STRONG",{});var GYt=s($Ce);M2r=r(GYt,"convbert"),GYt.forEach(t),E2r=r(JWe," \u2014 "),sZ=n(JWe,"A",{href:!0});var OYt=s(sZ);C2r=r(OYt,"ConvBertForTokenClassification"),OYt.forEach(t),w2r=r(JWe," (ConvBERT model)"),JWe.forEach(t),A2r=i(J),vE=n(J,"LI",{});var YWe=s(vE);kCe=n(YWe,"STRONG",{});var VYt=s(kCe);L2r=r(VYt,"data2vec-text"),VYt.forEach(t),y2r=r(YWe," \u2014 "),lZ=n(YWe,"A",{href:!0});var XYt=s(lZ);x2r=r(XYt,"Data2VecTextForTokenClassification"),XYt.forEach(t),$2r=r(YWe," (Data2VecText model)"),YWe.forEach(t),k2r=i(J),FE=n(J,"LI",{});var ZWe=s(FE);SCe=n(ZWe,"STRONG",{});var zYt=s(SCe);S2r=r(zYt,"deberta"),zYt.forEach(t),R2r=r(ZWe," \u2014 "),iZ=n(ZWe,"A",{href:!0});var QYt=s(iZ);P2r=r(QYt,"DebertaForTokenClassification"),QYt.forEach(t),B2r=r(ZWe," (DeBERTa model)"),ZWe.forEach(t),I2r=i(J),TE=n(J,"LI",{});var KWe=s(TE);RCe=n(KWe,"STRONG",{});var WYt=s(RCe);N2r=r(WYt,"deberta-v2"),WYt.forEach(t),q2r=r(KWe," \u2014 "),dZ=n(KWe,"A",{href:!0});var UYt=s(dZ);j2r=r(UYt,"DebertaV2ForTokenClassification"),UYt.forEach(t),D2r=r(KWe," (DeBERTa-v2 model)"),KWe.forEach(t),G2r=i(J),ME=n(J,"LI",{});var eUe=s(ME);PCe=n(eUe,"STRONG",{});var HYt=s(PCe);O2r=r(HYt,"distilbert"),HYt.forEach(t),V2r=r(eUe," \u2014 "),mZ=n(eUe,"A",{href:!0});var JYt=s(mZ);X2r=r(JYt,"DistilBertForTokenClassification"),JYt.forEach(t),z2r=r(eUe," (DistilBERT model)"),eUe.forEach(t),Q2r=i(J),EE=n(J,"LI",{});var oUe=s(EE);BCe=n(oUe,"STRONG",{});var YYt=s(BCe);W2r=r(YYt,"electra"),YYt.forEach(t),U2r=r(oUe," \u2014 "),cZ=n(oUe,"A",{href:!0});var ZYt=s(cZ);H2r=r(ZYt,"ElectraForTokenClassification"),ZYt.forEach(t),J2r=r(oUe," (ELECTRA model)"),oUe.forEach(t),Y2r=i(J),CE=n(J,"LI",{});var rUe=s(CE);ICe=n(rUe,"STRONG",{});var KYt=s(ICe);Z2r=r(KYt,"ernie"),KYt.forEach(t),K2r=r(rUe," \u2014 "),fZ=n(rUe,"A",{href:!0});var eZt=s(fZ);ebr=r(eZt,"ErnieForTokenClassification"),eZt.forEach(t),obr=r(rUe," (ERNIE model)"),rUe.forEach(t),rbr=i(J),wE=n(J,"LI",{});var tUe=s(wE);NCe=n(tUe,"STRONG",{});var oZt=s(NCe);tbr=r(oZt,"esm"),oZt.forEach(t),abr=r(tUe," \u2014 "),gZ=n(tUe,"A",{href:!0});var rZt=s(gZ);nbr=r(rZt,"EsmForTokenClassification"),rZt.forEach(t),sbr=r(tUe," (ESM model)"),tUe.forEach(t),lbr=i(J),AE=n(J,"LI",{});var aUe=s(AE);qCe=n(aUe,"STRONG",{});var tZt=s(qCe);ibr=r(tZt,"flaubert"),tZt.forEach(t),dbr=r(aUe," \u2014 "),hZ=n(aUe,"A",{href:!0});var aZt=s(hZ);mbr=r(aZt,"FlaubertForTokenClassification"),aZt.forEach(t),cbr=r(aUe," (FlauBERT model)"),aUe.forEach(t),fbr=i(J),LE=n(J,"LI",{});var nUe=s(LE);jCe=n(nUe,"STRONG",{});var nZt=s(jCe);gbr=r(nZt,"fnet"),nZt.forEach(t),hbr=r(nUe," \u2014 "),uZ=n(nUe,"A",{href:!0});var sZt=s(uZ);ubr=r(sZt,"FNetForTokenClassification"),sZt.forEach(t),pbr=r(nUe," (FNet model)"),nUe.forEach(t),_br=i(J),yE=n(J,"LI",{});var sUe=s(yE);DCe=n(sUe,"STRONG",{});var lZt=s(DCe);bbr=r(lZt,"funnel"),lZt.forEach(t),vbr=r(sUe," \u2014 "),pZ=n(sUe,"A",{href:!0});var iZt=s(pZ);Fbr=r(iZt,"FunnelForTokenClassification"),iZt.forEach(t),Tbr=r(sUe," (Funnel Transformer model)"),sUe.forEach(t),Mbr=i(J),xE=n(J,"LI",{});var lUe=s(xE);GCe=n(lUe,"STRONG",{});var dZt=s(GCe);Ebr=r(dZt,"gpt2"),dZt.forEach(t),Cbr=r(lUe," \u2014 "),_Z=n(lUe,"A",{href:!0});var mZt=s(_Z);wbr=r(mZt,"GPT2ForTokenClassification"),mZt.forEach(t),Abr=r(lUe," (OpenAI GPT-2 model)"),lUe.forEach(t),Lbr=i(J),$E=n(J,"LI",{});var iUe=s($E);OCe=n(iUe,"STRONG",{});var cZt=s(OCe);ybr=r(cZt,"ibert"),cZt.forEach(t),xbr=r(iUe," \u2014 "),bZ=n(iUe,"A",{href:!0});var fZt=s(bZ);$br=r(fZt,"IBertForTokenClassification"),fZt.forEach(t),kbr=r(iUe," (I-BERT model)"),iUe.forEach(t),Sbr=i(J),kE=n(J,"LI",{});var dUe=s(kE);VCe=n(dUe,"STRONG",{});var gZt=s(VCe);Rbr=r(gZt,"layoutlm"),gZt.forEach(t),Pbr=r(dUe," \u2014 "),vZ=n(dUe,"A",{href:!0});var hZt=s(vZ);Bbr=r(hZt,"LayoutLMForTokenClassification"),hZt.forEach(t),Ibr=r(dUe," (LayoutLM model)"),dUe.forEach(t),Nbr=i(J),SE=n(J,"LI",{});var mUe=s(SE);XCe=n(mUe,"STRONG",{});var uZt=s(XCe);qbr=r(uZt,"layoutlmv2"),uZt.forEach(t),jbr=r(mUe," \u2014 "),FZ=n(mUe,"A",{href:!0});var pZt=s(FZ);Dbr=r(pZt,"LayoutLMv2ForTokenClassification"),pZt.forEach(t),Gbr=r(mUe," (LayoutLMv2 model)"),mUe.forEach(t),Obr=i(J),RE=n(J,"LI",{});var cUe=s(RE);zCe=n(cUe,"STRONG",{});var _Zt=s(zCe);Vbr=r(_Zt,"layoutlmv3"),_Zt.forEach(t),Xbr=r(cUe," \u2014 "),TZ=n(cUe,"A",{href:!0});var bZt=s(TZ);zbr=r(bZt,"LayoutLMv3ForTokenClassification"),bZt.forEach(t),Qbr=r(cUe," (LayoutLMv3 model)"),cUe.forEach(t),Wbr=i(J),PE=n(J,"LI",{});var fUe=s(PE);QCe=n(fUe,"STRONG",{});var vZt=s(QCe);Ubr=r(vZt,"lilt"),vZt.forEach(t),Hbr=r(fUe," \u2014 "),MZ=n(fUe,"A",{href:!0});var FZt=s(MZ);Jbr=r(FZt,"LiltForTokenClassification"),FZt.forEach(t),Ybr=r(fUe," (LiLT model)"),fUe.forEach(t),Zbr=i(J),BE=n(J,"LI",{});var gUe=s(BE);WCe=n(gUe,"STRONG",{});var TZt=s(WCe);Kbr=r(TZt,"longformer"),TZt.forEach(t),evr=r(gUe," \u2014 "),EZ=n(gUe,"A",{href:!0});var MZt=s(EZ);ovr=r(MZt,"LongformerForTokenClassification"),MZt.forEach(t),rvr=r(gUe," (Longformer model)"),gUe.forEach(t),tvr=i(J),IE=n(J,"LI",{});var hUe=s(IE);UCe=n(hUe,"STRONG",{});var EZt=s(UCe);avr=r(EZt,"luke"),EZt.forEach(t),nvr=r(hUe," \u2014 "),CZ=n(hUe,"A",{href:!0});var CZt=s(CZ);svr=r(CZt,"LukeForTokenClassification"),CZt.forEach(t),lvr=r(hUe," (LUKE model)"),hUe.forEach(t),ivr=i(J),NE=n(J,"LI",{});var uUe=s(NE);HCe=n(uUe,"STRONG",{});var wZt=s(HCe);dvr=r(wZt,"markuplm"),wZt.forEach(t),mvr=r(uUe," \u2014 "),wZ=n(uUe,"A",{href:!0});var AZt=s(wZ);cvr=r(AZt,"MarkupLMForTokenClassification"),AZt.forEach(t),fvr=r(uUe," (MarkupLM model)"),uUe.forEach(t),gvr=i(J),qE=n(J,"LI",{});var pUe=s(qE);JCe=n(pUe,"STRONG",{});var LZt=s(JCe);hvr=r(LZt,"megatron-bert"),LZt.forEach(t),uvr=r(pUe," \u2014 "),AZ=n(pUe,"A",{href:!0});var yZt=s(AZ);pvr=r(yZt,"MegatronBertForTokenClassification"),yZt.forEach(t),_vr=r(pUe," (Megatron-BERT model)"),pUe.forEach(t),bvr=i(J),jE=n(J,"LI",{});var _Ue=s(jE);YCe=n(_Ue,"STRONG",{});var xZt=s(YCe);vvr=r(xZt,"mobilebert"),xZt.forEach(t),Fvr=r(_Ue," \u2014 "),LZ=n(_Ue,"A",{href:!0});var $Zt=s(LZ);Tvr=r($Zt,"MobileBertForTokenClassification"),$Zt.forEach(t),Mvr=r(_Ue," (MobileBERT model)"),_Ue.forEach(t),Evr=i(J),DE=n(J,"LI",{});var bUe=s(DE);ZCe=n(bUe,"STRONG",{});var kZt=s(ZCe);Cvr=r(kZt,"mpnet"),kZt.forEach(t),wvr=r(bUe," \u2014 "),yZ=n(bUe,"A",{href:!0});var SZt=s(yZ);Avr=r(SZt,"MPNetForTokenClassification"),SZt.forEach(t),Lvr=r(bUe," (MPNet model)"),bUe.forEach(t),yvr=i(J),GE=n(J,"LI",{});var vUe=s(GE);KCe=n(vUe,"STRONG",{});var RZt=s(KCe);xvr=r(RZt,"nezha"),RZt.forEach(t),$vr=r(vUe," \u2014 "),xZ=n(vUe,"A",{href:!0});var PZt=s(xZ);kvr=r(PZt,"NezhaForTokenClassification"),PZt.forEach(t),Svr=r(vUe," (Nezha model)"),vUe.forEach(t),Rvr=i(J),OE=n(J,"LI",{});var FUe=s(OE);e3e=n(FUe,"STRONG",{});var BZt=s(e3e);Pvr=r(BZt,"nystromformer"),BZt.forEach(t),Bvr=r(FUe," \u2014 "),$Z=n(FUe,"A",{href:!0});var IZt=s($Z);Ivr=r(IZt,"NystromformerForTokenClassification"),IZt.forEach(t),Nvr=r(FUe," (Nystr\xF6mformer model)"),FUe.forEach(t),qvr=i(J),VE=n(J,"LI",{});var TUe=s(VE);o3e=n(TUe,"STRONG",{});var NZt=s(o3e);jvr=r(NZt,"qdqbert"),NZt.forEach(t),Dvr=r(TUe," \u2014 "),kZ=n(TUe,"A",{href:!0});var qZt=s(kZ);Gvr=r(qZt,"QDQBertForTokenClassification"),qZt.forEach(t),Ovr=r(TUe," (QDQBert model)"),TUe.forEach(t),Vvr=i(J),XE=n(J,"LI",{});var MUe=s(XE);r3e=n(MUe,"STRONG",{});var jZt=s(r3e);Xvr=r(jZt,"rembert"),jZt.forEach(t),zvr=r(MUe," \u2014 "),SZ=n(MUe,"A",{href:!0});var DZt=s(SZ);Qvr=r(DZt,"RemBertForTokenClassification"),DZt.forEach(t),Wvr=r(MUe," (RemBERT model)"),MUe.forEach(t),Uvr=i(J),zE=n(J,"LI",{});var EUe=s(zE);t3e=n(EUe,"STRONG",{});var GZt=s(t3e);Hvr=r(GZt,"roberta"),GZt.forEach(t),Jvr=r(EUe," \u2014 "),RZ=n(EUe,"A",{href:!0});var OZt=s(RZ);Yvr=r(OZt,"RobertaForTokenClassification"),OZt.forEach(t),Zvr=r(EUe," (RoBERTa model)"),EUe.forEach(t),Kvr=i(J),QE=n(J,"LI",{});var CUe=s(QE);a3e=n(CUe,"STRONG",{});var VZt=s(a3e);eFr=r(VZt,"roformer"),VZt.forEach(t),oFr=r(CUe," \u2014 "),PZ=n(CUe,"A",{href:!0});var XZt=s(PZ);rFr=r(XZt,"RoFormerForTokenClassification"),XZt.forEach(t),tFr=r(CUe," (RoFormer model)"),CUe.forEach(t),aFr=i(J),WE=n(J,"LI",{});var wUe=s(WE);n3e=n(wUe,"STRONG",{});var zZt=s(n3e);nFr=r(zZt,"squeezebert"),zZt.forEach(t),sFr=r(wUe," \u2014 "),BZ=n(wUe,"A",{href:!0});var QZt=s(BZ);lFr=r(QZt,"SqueezeBertForTokenClassification"),QZt.forEach(t),iFr=r(wUe," (SqueezeBERT model)"),wUe.forEach(t),dFr=i(J),UE=n(J,"LI",{});var AUe=s(UE);s3e=n(AUe,"STRONG",{});var WZt=s(s3e);mFr=r(WZt,"xlm"),WZt.forEach(t),cFr=r(AUe," \u2014 "),IZ=n(AUe,"A",{href:!0});var UZt=s(IZ);fFr=r(UZt,"XLMForTokenClassification"),UZt.forEach(t),gFr=r(AUe," (XLM model)"),AUe.forEach(t),hFr=i(J),HE=n(J,"LI",{});var LUe=s(HE);l3e=n(LUe,"STRONG",{});var HZt=s(l3e);uFr=r(HZt,"xlm-roberta"),HZt.forEach(t),pFr=r(LUe," \u2014 "),NZ=n(LUe,"A",{href:!0});var JZt=s(NZ);_Fr=r(JZt,"XLMRobertaForTokenClassification"),JZt.forEach(t),bFr=r(LUe," (XLM-RoBERTa model)"),LUe.forEach(t),vFr=i(J),JE=n(J,"LI",{});var yUe=s(JE);i3e=n(yUe,"STRONG",{});var YZt=s(i3e);FFr=r(YZt,"xlm-roberta-xl"),YZt.forEach(t),TFr=r(yUe," \u2014 "),qZ=n(yUe,"A",{href:!0});var ZZt=s(qZ);MFr=r(ZZt,"XLMRobertaXLForTokenClassification"),ZZt.forEach(t),EFr=r(yUe," (XLM-RoBERTa-XL model)"),yUe.forEach(t),CFr=i(J),YE=n(J,"LI",{});var xUe=s(YE);d3e=n(xUe,"STRONG",{});var KZt=s(d3e);wFr=r(KZt,"xlnet"),KZt.forEach(t),AFr=r(xUe," \u2014 "),jZ=n(xUe,"A",{href:!0});var eKt=s(jZ);LFr=r(eKt,"XLNetForTokenClassification"),eKt.forEach(t),yFr=r(xUe," (XLNet model)"),xUe.forEach(t),xFr=i(J),ZE=n(J,"LI",{});var $Ue=s(ZE);m3e=n($Ue,"STRONG",{});var oKt=s(m3e);$Fr=r(oKt,"yoso"),oKt.forEach(t),kFr=r($Ue," \u2014 "),DZ=n($Ue,"A",{href:!0});var rKt=s(DZ);SFr=r(rKt,"YosoForTokenClassification"),rKt.forEach(t),RFr=r($Ue," (YOSO model)"),$Ue.forEach(t),J.forEach(t),PFr=i(Ia),KE=n(Ia,"P",{});var kUe=s(KE);BFr=r(kUe,"The model is set in evaluation mode by default using "),c3e=n(kUe,"CODE",{});var tKt=s(c3e);IFr=r(tKt,"model.eval()"),tKt.forEach(t),NFr=r(kUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),f3e=n(kUe,"CODE",{});var aKt=s(f3e);qFr=r(aKt,"model.train()"),aKt.forEach(t),kUe.forEach(t),jFr=i(Ia),T(e4.$$.fragment,Ia),Ia.forEach(t),Wl.forEach(t),aao=i(c),im=n(c,"H2",{class:!0});var Eso=s(im);o4=n(Eso,"A",{id:!0,class:!0,href:!0});var nKt=s(o4);g3e=n(nKt,"SPAN",{});var sKt=s(g3e);T(Sk.$$.fragment,sKt),sKt.forEach(t),nKt.forEach(t),DFr=i(Eso),h3e=n(Eso,"SPAN",{});var lKt=s(h3e);GFr=r(lKt,"AutoModelForQuestionAnswering"),lKt.forEach(t),Eso.forEach(t),nao=i(c),Qo=n(c,"DIV",{class:!0});var Ul=s(Qo);T(Rk.$$.fragment,Ul),OFr=i(Ul),dm=n(Ul,"P",{});var Cme=s(dm);VFr=r(Cme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),GZ=n(Cme,"A",{href:!0});var iKt=s(GZ);XFr=r(iKt,"from_pretrained()"),iKt.forEach(t),zFr=r(Cme," class method or the "),OZ=n(Cme,"A",{href:!0});var dKt=s(OZ);QFr=r(dKt,"from_config()"),dKt.forEach(t),WFr=r(Cme,` class
method.`),Cme.forEach(t),UFr=i(Ul),Pk=n(Ul,"P",{});var Cso=s(Pk);HFr=r(Cso,"This class cannot be instantiated directly using "),u3e=n(Cso,"CODE",{});var mKt=s(u3e);JFr=r(mKt,"__init__()"),mKt.forEach(t),YFr=r(Cso," (throws an error)."),Cso.forEach(t),ZFr=i(Ul),St=n(Ul,"DIV",{class:!0});var F9=s(St);T(Bk.$$.fragment,F9),KFr=i(F9),p3e=n(F9,"P",{});var cKt=s(p3e);eTr=r(cKt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),cKt.forEach(t),oTr=i(F9),mm=n(F9,"P",{});var wme=s(mm);rTr=r(wme,`Note:
Loading a model from its configuration file does `),_3e=n(wme,"STRONG",{});var fKt=s(_3e);tTr=r(fKt,"not"),fKt.forEach(t),aTr=r(wme,` load the model weights. It only affects the
model\u2019s configuration. Use `),VZ=n(wme,"A",{href:!0});var gKt=s(VZ);nTr=r(gKt,"from_pretrained()"),gKt.forEach(t),sTr=r(wme," to load the model weights."),wme.forEach(t),lTr=i(F9),T(r4.$$.fragment,F9),F9.forEach(t),iTr=i(Ul),mo=n(Ul,"DIV",{class:!0});var Na=s(mo);T(Ik.$$.fragment,Na),dTr=i(Na),b3e=n(Na,"P",{});var hKt=s(b3e);mTr=r(hKt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),hKt.forEach(t),cTr=i(Na),pn=n(Na,"P",{});var T9=s(pn);fTr=r(T9,"The model class to instantiate is selected based on the "),v3e=n(T9,"CODE",{});var uKt=s(v3e);gTr=r(uKt,"model_type"),uKt.forEach(t),hTr=r(T9,` property of the config object (either
passed as an argument or loaded from `),F3e=n(T9,"CODE",{});var pKt=s(F3e);uTr=r(pKt,"pretrained_model_name_or_path"),pKt.forEach(t),pTr=r(T9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T3e=n(T9,"CODE",{});var _Kt=s(T3e);_Tr=r(_Kt,"pretrained_model_name_or_path"),_Kt.forEach(t),bTr=r(T9,":"),T9.forEach(t),vTr=i(Na),O=n(Na,"UL",{});var X=s(O);t4=n(X,"LI",{});var SUe=s(t4);M3e=n(SUe,"STRONG",{});var bKt=s(M3e);FTr=r(bKt,"albert"),bKt.forEach(t),TTr=r(SUe," \u2014 "),XZ=n(SUe,"A",{href:!0});var vKt=s(XZ);MTr=r(vKt,"AlbertForQuestionAnswering"),vKt.forEach(t),ETr=r(SUe," (ALBERT model)"),SUe.forEach(t),CTr=i(X),a4=n(X,"LI",{});var RUe=s(a4);E3e=n(RUe,"STRONG",{});var FKt=s(E3e);wTr=r(FKt,"bart"),FKt.forEach(t),ATr=r(RUe," \u2014 "),zZ=n(RUe,"A",{href:!0});var TKt=s(zZ);LTr=r(TKt,"BartForQuestionAnswering"),TKt.forEach(t),yTr=r(RUe," (BART model)"),RUe.forEach(t),xTr=i(X),n4=n(X,"LI",{});var PUe=s(n4);C3e=n(PUe,"STRONG",{});var MKt=s(C3e);$Tr=r(MKt,"bert"),MKt.forEach(t),kTr=r(PUe," \u2014 "),QZ=n(PUe,"A",{href:!0});var EKt=s(QZ);STr=r(EKt,"BertForQuestionAnswering"),EKt.forEach(t),RTr=r(PUe," (BERT model)"),PUe.forEach(t),PTr=i(X),s4=n(X,"LI",{});var BUe=s(s4);w3e=n(BUe,"STRONG",{});var CKt=s(w3e);BTr=r(CKt,"big_bird"),CKt.forEach(t),ITr=r(BUe," \u2014 "),WZ=n(BUe,"A",{href:!0});var wKt=s(WZ);NTr=r(wKt,"BigBirdForQuestionAnswering"),wKt.forEach(t),qTr=r(BUe," (BigBird model)"),BUe.forEach(t),jTr=i(X),l4=n(X,"LI",{});var IUe=s(l4);A3e=n(IUe,"STRONG",{});var AKt=s(A3e);DTr=r(AKt,"bigbird_pegasus"),AKt.forEach(t),GTr=r(IUe," \u2014 "),UZ=n(IUe,"A",{href:!0});var LKt=s(UZ);OTr=r(LKt,"BigBirdPegasusForQuestionAnswering"),LKt.forEach(t),VTr=r(IUe," (BigBird-Pegasus model)"),IUe.forEach(t),XTr=i(X),i4=n(X,"LI",{});var NUe=s(i4);L3e=n(NUe,"STRONG",{});var yKt=s(L3e);zTr=r(yKt,"bloom"),yKt.forEach(t),QTr=r(NUe," \u2014 "),HZ=n(NUe,"A",{href:!0});var xKt=s(HZ);WTr=r(xKt,"BloomForQuestionAnswering"),xKt.forEach(t),UTr=r(NUe," (BLOOM model)"),NUe.forEach(t),HTr=i(X),d4=n(X,"LI",{});var qUe=s(d4);y3e=n(qUe,"STRONG",{});var $Kt=s(y3e);JTr=r($Kt,"camembert"),$Kt.forEach(t),YTr=r(qUe," \u2014 "),JZ=n(qUe,"A",{href:!0});var kKt=s(JZ);ZTr=r(kKt,"CamembertForQuestionAnswering"),kKt.forEach(t),KTr=r(qUe," (CamemBERT model)"),qUe.forEach(t),eMr=i(X),m4=n(X,"LI",{});var jUe=s(m4);x3e=n(jUe,"STRONG",{});var SKt=s(x3e);oMr=r(SKt,"canine"),SKt.forEach(t),rMr=r(jUe," \u2014 "),YZ=n(jUe,"A",{href:!0});var RKt=s(YZ);tMr=r(RKt,"CanineForQuestionAnswering"),RKt.forEach(t),aMr=r(jUe," (CANINE model)"),jUe.forEach(t),nMr=i(X),c4=n(X,"LI",{});var DUe=s(c4);$3e=n(DUe,"STRONG",{});var PKt=s($3e);sMr=r(PKt,"convbert"),PKt.forEach(t),lMr=r(DUe," \u2014 "),ZZ=n(DUe,"A",{href:!0});var BKt=s(ZZ);iMr=r(BKt,"ConvBertForQuestionAnswering"),BKt.forEach(t),dMr=r(DUe," (ConvBERT model)"),DUe.forEach(t),mMr=i(X),f4=n(X,"LI",{});var GUe=s(f4);k3e=n(GUe,"STRONG",{});var IKt=s(k3e);cMr=r(IKt,"data2vec-text"),IKt.forEach(t),fMr=r(GUe," \u2014 "),KZ=n(GUe,"A",{href:!0});var NKt=s(KZ);gMr=r(NKt,"Data2VecTextForQuestionAnswering"),NKt.forEach(t),hMr=r(GUe," (Data2VecText model)"),GUe.forEach(t),uMr=i(X),g4=n(X,"LI",{});var OUe=s(g4);S3e=n(OUe,"STRONG",{});var qKt=s(S3e);pMr=r(qKt,"deberta"),qKt.forEach(t),_Mr=r(OUe," \u2014 "),eK=n(OUe,"A",{href:!0});var jKt=s(eK);bMr=r(jKt,"DebertaForQuestionAnswering"),jKt.forEach(t),vMr=r(OUe," (DeBERTa model)"),OUe.forEach(t),FMr=i(X),h4=n(X,"LI",{});var VUe=s(h4);R3e=n(VUe,"STRONG",{});var DKt=s(R3e);TMr=r(DKt,"deberta-v2"),DKt.forEach(t),MMr=r(VUe," \u2014 "),oK=n(VUe,"A",{href:!0});var GKt=s(oK);EMr=r(GKt,"DebertaV2ForQuestionAnswering"),GKt.forEach(t),CMr=r(VUe," (DeBERTa-v2 model)"),VUe.forEach(t),wMr=i(X),u4=n(X,"LI",{});var XUe=s(u4);P3e=n(XUe,"STRONG",{});var OKt=s(P3e);AMr=r(OKt,"distilbert"),OKt.forEach(t),LMr=r(XUe," \u2014 "),rK=n(XUe,"A",{href:!0});var VKt=s(rK);yMr=r(VKt,"DistilBertForQuestionAnswering"),VKt.forEach(t),xMr=r(XUe," (DistilBERT model)"),XUe.forEach(t),$Mr=i(X),p4=n(X,"LI",{});var zUe=s(p4);B3e=n(zUe,"STRONG",{});var XKt=s(B3e);kMr=r(XKt,"electra"),XKt.forEach(t),SMr=r(zUe," \u2014 "),tK=n(zUe,"A",{href:!0});var zKt=s(tK);RMr=r(zKt,"ElectraForQuestionAnswering"),zKt.forEach(t),PMr=r(zUe," (ELECTRA model)"),zUe.forEach(t),BMr=i(X),_4=n(X,"LI",{});var QUe=s(_4);I3e=n(QUe,"STRONG",{});var QKt=s(I3e);IMr=r(QKt,"ernie"),QKt.forEach(t),NMr=r(QUe," \u2014 "),aK=n(QUe,"A",{href:!0});var WKt=s(aK);qMr=r(WKt,"ErnieForQuestionAnswering"),WKt.forEach(t),jMr=r(QUe," (ERNIE model)"),QUe.forEach(t),DMr=i(X),b4=n(X,"LI",{});var WUe=s(b4);N3e=n(WUe,"STRONG",{});var UKt=s(N3e);GMr=r(UKt,"flaubert"),UKt.forEach(t),OMr=r(WUe," \u2014 "),nK=n(WUe,"A",{href:!0});var HKt=s(nK);VMr=r(HKt,"FlaubertForQuestionAnsweringSimple"),HKt.forEach(t),XMr=r(WUe," (FlauBERT model)"),WUe.forEach(t),zMr=i(X),v4=n(X,"LI",{});var UUe=s(v4);q3e=n(UUe,"STRONG",{});var JKt=s(q3e);QMr=r(JKt,"fnet"),JKt.forEach(t),WMr=r(UUe," \u2014 "),sK=n(UUe,"A",{href:!0});var YKt=s(sK);UMr=r(YKt,"FNetForQuestionAnswering"),YKt.forEach(t),HMr=r(UUe," (FNet model)"),UUe.forEach(t),JMr=i(X),F4=n(X,"LI",{});var HUe=s(F4);j3e=n(HUe,"STRONG",{});var ZKt=s(j3e);YMr=r(ZKt,"funnel"),ZKt.forEach(t),ZMr=r(HUe," \u2014 "),lK=n(HUe,"A",{href:!0});var KKt=s(lK);KMr=r(KKt,"FunnelForQuestionAnswering"),KKt.forEach(t),eEr=r(HUe," (Funnel Transformer model)"),HUe.forEach(t),oEr=i(X),T4=n(X,"LI",{});var JUe=s(T4);D3e=n(JUe,"STRONG",{});var eea=s(D3e);rEr=r(eea,"gptj"),eea.forEach(t),tEr=r(JUe," \u2014 "),iK=n(JUe,"A",{href:!0});var oea=s(iK);aEr=r(oea,"GPTJForQuestionAnswering"),oea.forEach(t),nEr=r(JUe," (GPT-J model)"),JUe.forEach(t),sEr=i(X),M4=n(X,"LI",{});var YUe=s(M4);G3e=n(YUe,"STRONG",{});var rea=s(G3e);lEr=r(rea,"ibert"),rea.forEach(t),iEr=r(YUe," \u2014 "),dK=n(YUe,"A",{href:!0});var tea=s(dK);dEr=r(tea,"IBertForQuestionAnswering"),tea.forEach(t),mEr=r(YUe," (I-BERT model)"),YUe.forEach(t),cEr=i(X),E4=n(X,"LI",{});var ZUe=s(E4);O3e=n(ZUe,"STRONG",{});var aea=s(O3e);fEr=r(aea,"layoutlmv2"),aea.forEach(t),gEr=r(ZUe," \u2014 "),mK=n(ZUe,"A",{href:!0});var nea=s(mK);hEr=r(nea,"LayoutLMv2ForQuestionAnswering"),nea.forEach(t),uEr=r(ZUe," (LayoutLMv2 model)"),ZUe.forEach(t),pEr=i(X),C4=n(X,"LI",{});var KUe=s(C4);V3e=n(KUe,"STRONG",{});var sea=s(V3e);_Er=r(sea,"layoutlmv3"),sea.forEach(t),bEr=r(KUe," \u2014 "),cK=n(KUe,"A",{href:!0});var lea=s(cK);vEr=r(lea,"LayoutLMv3ForQuestionAnswering"),lea.forEach(t),FEr=r(KUe," (LayoutLMv3 model)"),KUe.forEach(t),TEr=i(X),w4=n(X,"LI",{});var eHe=s(w4);X3e=n(eHe,"STRONG",{});var iea=s(X3e);MEr=r(iea,"led"),iea.forEach(t),EEr=r(eHe," \u2014 "),fK=n(eHe,"A",{href:!0});var dea=s(fK);CEr=r(dea,"LEDForQuestionAnswering"),dea.forEach(t),wEr=r(eHe," (LED model)"),eHe.forEach(t),AEr=i(X),A4=n(X,"LI",{});var oHe=s(A4);z3e=n(oHe,"STRONG",{});var mea=s(z3e);LEr=r(mea,"lilt"),mea.forEach(t),yEr=r(oHe," \u2014 "),gK=n(oHe,"A",{href:!0});var cea=s(gK);xEr=r(cea,"LiltForQuestionAnswering"),cea.forEach(t),$Er=r(oHe," (LiLT model)"),oHe.forEach(t),kEr=i(X),L4=n(X,"LI",{});var rHe=s(L4);Q3e=n(rHe,"STRONG",{});var fea=s(Q3e);SEr=r(fea,"longformer"),fea.forEach(t),REr=r(rHe," \u2014 "),hK=n(rHe,"A",{href:!0});var gea=s(hK);PEr=r(gea,"LongformerForQuestionAnswering"),gea.forEach(t),BEr=r(rHe," (Longformer model)"),rHe.forEach(t),IEr=i(X),y4=n(X,"LI",{});var tHe=s(y4);W3e=n(tHe,"STRONG",{});var hea=s(W3e);NEr=r(hea,"luke"),hea.forEach(t),qEr=r(tHe," \u2014 "),uK=n(tHe,"A",{href:!0});var uea=s(uK);jEr=r(uea,"LukeForQuestionAnswering"),uea.forEach(t),DEr=r(tHe," (LUKE model)"),tHe.forEach(t),GEr=i(X),x4=n(X,"LI",{});var aHe=s(x4);U3e=n(aHe,"STRONG",{});var pea=s(U3e);OEr=r(pea,"lxmert"),pea.forEach(t),VEr=r(aHe," \u2014 "),pK=n(aHe,"A",{href:!0});var _ea=s(pK);XEr=r(_ea,"LxmertForQuestionAnswering"),_ea.forEach(t),zEr=r(aHe," (LXMERT model)"),aHe.forEach(t),QEr=i(X),$4=n(X,"LI",{});var nHe=s($4);H3e=n(nHe,"STRONG",{});var bea=s(H3e);WEr=r(bea,"markuplm"),bea.forEach(t),UEr=r(nHe," \u2014 "),_K=n(nHe,"A",{href:!0});var vea=s(_K);HEr=r(vea,"MarkupLMForQuestionAnswering"),vea.forEach(t),JEr=r(nHe," (MarkupLM model)"),nHe.forEach(t),YEr=i(X),k4=n(X,"LI",{});var sHe=s(k4);J3e=n(sHe,"STRONG",{});var Fea=s(J3e);ZEr=r(Fea,"mbart"),Fea.forEach(t),KEr=r(sHe," \u2014 "),bK=n(sHe,"A",{href:!0});var Tea=s(bK);e4r=r(Tea,"MBartForQuestionAnswering"),Tea.forEach(t),o4r=r(sHe," (mBART model)"),sHe.forEach(t),r4r=i(X),S4=n(X,"LI",{});var lHe=s(S4);Y3e=n(lHe,"STRONG",{});var Mea=s(Y3e);t4r=r(Mea,"megatron-bert"),Mea.forEach(t),a4r=r(lHe," \u2014 "),vK=n(lHe,"A",{href:!0});var Eea=s(vK);n4r=r(Eea,"MegatronBertForQuestionAnswering"),Eea.forEach(t),s4r=r(lHe," (Megatron-BERT model)"),lHe.forEach(t),l4r=i(X),R4=n(X,"LI",{});var iHe=s(R4);Z3e=n(iHe,"STRONG",{});var Cea=s(Z3e);i4r=r(Cea,"mobilebert"),Cea.forEach(t),d4r=r(iHe," \u2014 "),FK=n(iHe,"A",{href:!0});var wea=s(FK);m4r=r(wea,"MobileBertForQuestionAnswering"),wea.forEach(t),c4r=r(iHe," (MobileBERT model)"),iHe.forEach(t),f4r=i(X),P4=n(X,"LI",{});var dHe=s(P4);K3e=n(dHe,"STRONG",{});var Aea=s(K3e);g4r=r(Aea,"mpnet"),Aea.forEach(t),h4r=r(dHe," \u2014 "),TK=n(dHe,"A",{href:!0});var Lea=s(TK);u4r=r(Lea,"MPNetForQuestionAnswering"),Lea.forEach(t),p4r=r(dHe," (MPNet model)"),dHe.forEach(t),_4r=i(X),B4=n(X,"LI",{});var mHe=s(B4);e5e=n(mHe,"STRONG",{});var yea=s(e5e);b4r=r(yea,"mvp"),yea.forEach(t),v4r=r(mHe," \u2014 "),MK=n(mHe,"A",{href:!0});var xea=s(MK);F4r=r(xea,"MvpForQuestionAnswering"),xea.forEach(t),T4r=r(mHe," (MVP model)"),mHe.forEach(t),M4r=i(X),I4=n(X,"LI",{});var cHe=s(I4);o5e=n(cHe,"STRONG",{});var $ea=s(o5e);E4r=r($ea,"nezha"),$ea.forEach(t),C4r=r(cHe," \u2014 "),EK=n(cHe,"A",{href:!0});var kea=s(EK);w4r=r(kea,"NezhaForQuestionAnswering"),kea.forEach(t),A4r=r(cHe," (Nezha model)"),cHe.forEach(t),L4r=i(X),N4=n(X,"LI",{});var fHe=s(N4);r5e=n(fHe,"STRONG",{});var Sea=s(r5e);y4r=r(Sea,"nystromformer"),Sea.forEach(t),x4r=r(fHe," \u2014 "),CK=n(fHe,"A",{href:!0});var Rea=s(CK);$4r=r(Rea,"NystromformerForQuestionAnswering"),Rea.forEach(t),k4r=r(fHe," (Nystr\xF6mformer model)"),fHe.forEach(t),S4r=i(X),q4=n(X,"LI",{});var gHe=s(q4);t5e=n(gHe,"STRONG",{});var Pea=s(t5e);R4r=r(Pea,"opt"),Pea.forEach(t),P4r=r(gHe," \u2014 "),wK=n(gHe,"A",{href:!0});var Bea=s(wK);B4r=r(Bea,"OPTForQuestionAnswering"),Bea.forEach(t),I4r=r(gHe," (OPT model)"),gHe.forEach(t),N4r=i(X),j4=n(X,"LI",{});var hHe=s(j4);a5e=n(hHe,"STRONG",{});var Iea=s(a5e);q4r=r(Iea,"qdqbert"),Iea.forEach(t),j4r=r(hHe," \u2014 "),AK=n(hHe,"A",{href:!0});var Nea=s(AK);D4r=r(Nea,"QDQBertForQuestionAnswering"),Nea.forEach(t),G4r=r(hHe," (QDQBert model)"),hHe.forEach(t),O4r=i(X),D4=n(X,"LI",{});var uHe=s(D4);n5e=n(uHe,"STRONG",{});var qea=s(n5e);V4r=r(qea,"reformer"),qea.forEach(t),X4r=r(uHe," \u2014 "),LK=n(uHe,"A",{href:!0});var jea=s(LK);z4r=r(jea,"ReformerForQuestionAnswering"),jea.forEach(t),Q4r=r(uHe," (Reformer model)"),uHe.forEach(t),W4r=i(X),G4=n(X,"LI",{});var pHe=s(G4);s5e=n(pHe,"STRONG",{});var Dea=s(s5e);U4r=r(Dea,"rembert"),Dea.forEach(t),H4r=r(pHe," \u2014 "),yK=n(pHe,"A",{href:!0});var Gea=s(yK);J4r=r(Gea,"RemBertForQuestionAnswering"),Gea.forEach(t),Y4r=r(pHe," (RemBERT model)"),pHe.forEach(t),Z4r=i(X),O4=n(X,"LI",{});var _He=s(O4);l5e=n(_He,"STRONG",{});var Oea=s(l5e);K4r=r(Oea,"roberta"),Oea.forEach(t),eCr=r(_He," \u2014 "),xK=n(_He,"A",{href:!0});var Vea=s(xK);oCr=r(Vea,"RobertaForQuestionAnswering"),Vea.forEach(t),rCr=r(_He," (RoBERTa model)"),_He.forEach(t),tCr=i(X),V4=n(X,"LI",{});var bHe=s(V4);i5e=n(bHe,"STRONG",{});var Xea=s(i5e);aCr=r(Xea,"roformer"),Xea.forEach(t),nCr=r(bHe," \u2014 "),$K=n(bHe,"A",{href:!0});var zea=s($K);sCr=r(zea,"RoFormerForQuestionAnswering"),zea.forEach(t),lCr=r(bHe," (RoFormer model)"),bHe.forEach(t),iCr=i(X),X4=n(X,"LI",{});var vHe=s(X4);d5e=n(vHe,"STRONG",{});var Qea=s(d5e);dCr=r(Qea,"splinter"),Qea.forEach(t),mCr=r(vHe," \u2014 "),kK=n(vHe,"A",{href:!0});var Wea=s(kK);cCr=r(Wea,"SplinterForQuestionAnswering"),Wea.forEach(t),fCr=r(vHe," (Splinter model)"),vHe.forEach(t),gCr=i(X),z4=n(X,"LI",{});var FHe=s(z4);m5e=n(FHe,"STRONG",{});var Uea=s(m5e);hCr=r(Uea,"squeezebert"),Uea.forEach(t),uCr=r(FHe," \u2014 "),SK=n(FHe,"A",{href:!0});var Hea=s(SK);pCr=r(Hea,"SqueezeBertForQuestionAnswering"),Hea.forEach(t),_Cr=r(FHe," (SqueezeBERT model)"),FHe.forEach(t),bCr=i(X),Q4=n(X,"LI",{});var THe=s(Q4);c5e=n(THe,"STRONG",{});var Jea=s(c5e);vCr=r(Jea,"xlm"),Jea.forEach(t),FCr=r(THe," \u2014 "),RK=n(THe,"A",{href:!0});var Yea=s(RK);TCr=r(Yea,"XLMForQuestionAnsweringSimple"),Yea.forEach(t),MCr=r(THe," (XLM model)"),THe.forEach(t),ECr=i(X),W4=n(X,"LI",{});var MHe=s(W4);f5e=n(MHe,"STRONG",{});var Zea=s(f5e);CCr=r(Zea,"xlm-roberta"),Zea.forEach(t),wCr=r(MHe," \u2014 "),PK=n(MHe,"A",{href:!0});var Kea=s(PK);ACr=r(Kea,"XLMRobertaForQuestionAnswering"),Kea.forEach(t),LCr=r(MHe," (XLM-RoBERTa model)"),MHe.forEach(t),yCr=i(X),U4=n(X,"LI",{});var EHe=s(U4);g5e=n(EHe,"STRONG",{});var eoa=s(g5e);xCr=r(eoa,"xlm-roberta-xl"),eoa.forEach(t),$Cr=r(EHe," \u2014 "),BK=n(EHe,"A",{href:!0});var ooa=s(BK);kCr=r(ooa,"XLMRobertaXLForQuestionAnswering"),ooa.forEach(t),SCr=r(EHe," (XLM-RoBERTa-XL model)"),EHe.forEach(t),RCr=i(X),H4=n(X,"LI",{});var CHe=s(H4);h5e=n(CHe,"STRONG",{});var roa=s(h5e);PCr=r(roa,"xlnet"),roa.forEach(t),BCr=r(CHe," \u2014 "),IK=n(CHe,"A",{href:!0});var toa=s(IK);ICr=r(toa,"XLNetForQuestionAnsweringSimple"),toa.forEach(t),NCr=r(CHe," (XLNet model)"),CHe.forEach(t),qCr=i(X),J4=n(X,"LI",{});var wHe=s(J4);u5e=n(wHe,"STRONG",{});var aoa=s(u5e);jCr=r(aoa,"yoso"),aoa.forEach(t),DCr=r(wHe," \u2014 "),NK=n(wHe,"A",{href:!0});var noa=s(NK);GCr=r(noa,"YosoForQuestionAnswering"),noa.forEach(t),OCr=r(wHe," (YOSO model)"),wHe.forEach(t),X.forEach(t),VCr=i(Na),Y4=n(Na,"P",{});var AHe=s(Y4);XCr=r(AHe,"The model is set in evaluation mode by default using "),p5e=n(AHe,"CODE",{});var soa=s(p5e);zCr=r(soa,"model.eval()"),soa.forEach(t),QCr=r(AHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_5e=n(AHe,"CODE",{});var loa=s(_5e);WCr=r(loa,"model.train()"),loa.forEach(t),AHe.forEach(t),UCr=i(Na),T(Z4.$$.fragment,Na),Na.forEach(t),Ul.forEach(t),sao=i(c),cm=n(c,"H2",{class:!0});var wso=s(cm);K4=n(wso,"A",{id:!0,class:!0,href:!0});var ioa=s(K4);b5e=n(ioa,"SPAN",{});var doa=s(b5e);T(Nk.$$.fragment,doa),doa.forEach(t),ioa.forEach(t),HCr=i(wso),v5e=n(wso,"SPAN",{});var moa=s(v5e);JCr=r(moa,"AutoModelForTableQuestionAnswering"),moa.forEach(t),wso.forEach(t),lao=i(c),Wo=n(c,"DIV",{class:!0});var Hl=s(Wo);T(qk.$$.fragment,Hl),YCr=i(Hl),fm=n(Hl,"P",{});var Ame=s(fm);ZCr=r(Ame,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),qK=n(Ame,"A",{href:!0});var coa=s(qK);KCr=r(coa,"from_pretrained()"),coa.forEach(t),e3r=r(Ame," class method or the "),jK=n(Ame,"A",{href:!0});var foa=s(jK);o3r=r(foa,"from_config()"),foa.forEach(t),r3r=r(Ame,` class
method.`),Ame.forEach(t),t3r=i(Hl),jk=n(Hl,"P",{});var Aso=s(jk);a3r=r(Aso,"This class cannot be instantiated directly using "),F5e=n(Aso,"CODE",{});var goa=s(F5e);n3r=r(goa,"__init__()"),goa.forEach(t),s3r=r(Aso," (throws an error)."),Aso.forEach(t),l3r=i(Hl),Rt=n(Hl,"DIV",{class:!0});var M9=s(Rt);T(Dk.$$.fragment,M9),i3r=i(M9),T5e=n(M9,"P",{});var hoa=s(T5e);d3r=r(hoa,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),hoa.forEach(t),m3r=i(M9),gm=n(M9,"P",{});var Lme=s(gm);c3r=r(Lme,`Note:
Loading a model from its configuration file does `),M5e=n(Lme,"STRONG",{});var uoa=s(M5e);f3r=r(uoa,"not"),uoa.forEach(t),g3r=r(Lme,` load the model weights. It only affects the
model\u2019s configuration. Use `),DK=n(Lme,"A",{href:!0});var poa=s(DK);h3r=r(poa,"from_pretrained()"),poa.forEach(t),u3r=r(Lme," to load the model weights."),Lme.forEach(t),p3r=i(M9),T(eC.$$.fragment,M9),M9.forEach(t),_3r=i(Hl),co=n(Hl,"DIV",{class:!0});var qa=s(co);T(Gk.$$.fragment,qa),b3r=i(qa),E5e=n(qa,"P",{});var _oa=s(E5e);v3r=r(_oa,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),_oa.forEach(t),F3r=i(qa),_n=n(qa,"P",{});var E9=s(_n);T3r=r(E9,"The model class to instantiate is selected based on the "),C5e=n(E9,"CODE",{});var boa=s(C5e);M3r=r(boa,"model_type"),boa.forEach(t),E3r=r(E9,` property of the config object (either
passed as an argument or loaded from `),w5e=n(E9,"CODE",{});var voa=s(w5e);C3r=r(voa,"pretrained_model_name_or_path"),voa.forEach(t),w3r=r(E9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),A5e=n(E9,"CODE",{});var Foa=s(A5e);A3r=r(Foa,"pretrained_model_name_or_path"),Foa.forEach(t),L3r=r(E9,":"),E9.forEach(t),y3r=i(qa),L5e=n(qa,"UL",{});var Toa=s(L5e);oC=n(Toa,"LI",{});var LHe=s(oC);y5e=n(LHe,"STRONG",{});var Moa=s(y5e);x3r=r(Moa,"tapas"),Moa.forEach(t),$3r=r(LHe," \u2014 "),GK=n(LHe,"A",{href:!0});var Eoa=s(GK);k3r=r(Eoa,"TapasForQuestionAnswering"),Eoa.forEach(t),S3r=r(LHe," (TAPAS model)"),LHe.forEach(t),Toa.forEach(t),R3r=i(qa),rC=n(qa,"P",{});var yHe=s(rC);P3r=r(yHe,"The model is set in evaluation mode by default using "),x5e=n(yHe,"CODE",{});var Coa=s(x5e);B3r=r(Coa,"model.eval()"),Coa.forEach(t),I3r=r(yHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$5e=n(yHe,"CODE",{});var woa=s($5e);N3r=r(woa,"model.train()"),woa.forEach(t),yHe.forEach(t),q3r=i(qa),T(tC.$$.fragment,qa),qa.forEach(t),Hl.forEach(t),iao=i(c),hm=n(c,"H2",{class:!0});var Lso=s(hm);aC=n(Lso,"A",{id:!0,class:!0,href:!0});var Aoa=s(aC);k5e=n(Aoa,"SPAN",{});var Loa=s(k5e);T(Ok.$$.fragment,Loa),Loa.forEach(t),Aoa.forEach(t),j3r=i(Lso),S5e=n(Lso,"SPAN",{});var yoa=s(S5e);D3r=r(yoa,"AutoModelForDocumentQuestionAnswering"),yoa.forEach(t),Lso.forEach(t),dao=i(c),Uo=n(c,"DIV",{class:!0});var Jl=s(Uo);T(Vk.$$.fragment,Jl),G3r=i(Jl),um=n(Jl,"P",{});var yme=s(um);O3r=r(yme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),OK=n(yme,"A",{href:!0});var xoa=s(OK);V3r=r(xoa,"from_pretrained()"),xoa.forEach(t),X3r=r(yme," class method or the "),VK=n(yme,"A",{href:!0});var $oa=s(VK);z3r=r($oa,"from_config()"),$oa.forEach(t),Q3r=r(yme,` class
method.`),yme.forEach(t),W3r=i(Jl),Xk=n(Jl,"P",{});var yso=s(Xk);U3r=r(yso,"This class cannot be instantiated directly using "),R5e=n(yso,"CODE",{});var koa=s(R5e);H3r=r(koa,"__init__()"),koa.forEach(t),J3r=r(yso," (throws an error)."),yso.forEach(t),Y3r=i(Jl),Pt=n(Jl,"DIV",{class:!0});var C9=s(Pt);T(zk.$$.fragment,C9),Z3r=i(C9),P5e=n(C9,"P",{});var Soa=s(P5e);K3r=r(Soa,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),Soa.forEach(t),e5r=i(C9),pm=n(C9,"P",{});var xme=s(pm);o5r=r(xme,`Note:
Loading a model from its configuration file does `),B5e=n(xme,"STRONG",{});var Roa=s(B5e);r5r=r(Roa,"not"),Roa.forEach(t),t5r=r(xme,` load the model weights. It only affects the
model\u2019s configuration. Use `),XK=n(xme,"A",{href:!0});var Poa=s(XK);a5r=r(Poa,"from_pretrained()"),Poa.forEach(t),n5r=r(xme," to load the model weights."),xme.forEach(t),s5r=i(C9),T(nC.$$.fragment,C9),C9.forEach(t),l5r=i(Jl),fo=n(Jl,"DIV",{class:!0});var ja=s(fo);T(Qk.$$.fragment,ja),i5r=i(ja),I5e=n(ja,"P",{});var Boa=s(I5e);d5r=r(Boa,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),Boa.forEach(t),m5r=i(ja),bn=n(ja,"P",{});var w9=s(bn);c5r=r(w9,"The model class to instantiate is selected based on the "),N5e=n(w9,"CODE",{});var Ioa=s(N5e);f5r=r(Ioa,"model_type"),Ioa.forEach(t),g5r=r(w9,` property of the config object (either
passed as an argument or loaded from `),q5e=n(w9,"CODE",{});var Noa=s(q5e);h5r=r(Noa,"pretrained_model_name_or_path"),Noa.forEach(t),u5r=r(w9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j5e=n(w9,"CODE",{});var qoa=s(j5e);p5r=r(qoa,"pretrained_model_name_or_path"),qoa.forEach(t),_5r=r(w9,":"),w9.forEach(t),b5r=i(ja),_m=n(ja,"UL",{});var $me=s(_m);sC=n($me,"LI",{});var xHe=s(sC);D5e=n(xHe,"STRONG",{});var joa=s(D5e);v5r=r(joa,"layoutlm"),joa.forEach(t),F5r=r(xHe," \u2014 "),zK=n(xHe,"A",{href:!0});var Doa=s(zK);T5r=r(Doa,"LayoutLMForQuestionAnswering"),Doa.forEach(t),M5r=r(xHe," (LayoutLM model)"),xHe.forEach(t),E5r=i($me),lC=n($me,"LI",{});var $He=s(lC);G5e=n($He,"STRONG",{});var Goa=s(G5e);C5r=r(Goa,"layoutlmv2"),Goa.forEach(t),w5r=r($He," \u2014 "),QK=n($He,"A",{href:!0});var Ooa=s(QK);A5r=r(Ooa,"LayoutLMv2ForQuestionAnswering"),Ooa.forEach(t),L5r=r($He," (LayoutLMv2 model)"),$He.forEach(t),y5r=i($me),iC=n($me,"LI",{});var kHe=s(iC);O5e=n(kHe,"STRONG",{});var Voa=s(O5e);x5r=r(Voa,"layoutlmv3"),Voa.forEach(t),$5r=r(kHe," \u2014 "),WK=n(kHe,"A",{href:!0});var Xoa=s(WK);k5r=r(Xoa,"LayoutLMv3ForQuestionAnswering"),Xoa.forEach(t),S5r=r(kHe," (LayoutLMv3 model)"),kHe.forEach(t),$me.forEach(t),R5r=i(ja),dC=n(ja,"P",{});var SHe=s(dC);P5r=r(SHe,"The model is set in evaluation mode by default using "),V5e=n(SHe,"CODE",{});var zoa=s(V5e);B5r=r(zoa,"model.eval()"),zoa.forEach(t),I5r=r(SHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),X5e=n(SHe,"CODE",{});var Qoa=s(X5e);N5r=r(Qoa,"model.train()"),Qoa.forEach(t),SHe.forEach(t),q5r=i(ja),T(mC.$$.fragment,ja),ja.forEach(t),Jl.forEach(t),mao=i(c),bm=n(c,"H2",{class:!0});var xso=s(bm);cC=n(xso,"A",{id:!0,class:!0,href:!0});var Woa=s(cC);z5e=n(Woa,"SPAN",{});var Uoa=s(z5e);T(Wk.$$.fragment,Uoa),Uoa.forEach(t),Woa.forEach(t),j5r=i(xso),Q5e=n(xso,"SPAN",{});var Hoa=s(Q5e);D5r=r(Hoa,"AutoModelForImageClassification"),Hoa.forEach(t),xso.forEach(t),cao=i(c),Ho=n(c,"DIV",{class:!0});var Yl=s(Ho);T(Uk.$$.fragment,Yl),G5r=i(Yl),vm=n(Yl,"P",{});var kme=s(vm);O5r=r(kme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),UK=n(kme,"A",{href:!0});var Joa=s(UK);V5r=r(Joa,"from_pretrained()"),Joa.forEach(t),X5r=r(kme," class method or the "),HK=n(kme,"A",{href:!0});var Yoa=s(HK);z5r=r(Yoa,"from_config()"),Yoa.forEach(t),Q5r=r(kme,` class
method.`),kme.forEach(t),W5r=i(Yl),Hk=n(Yl,"P",{});var $so=s(Hk);U5r=r($so,"This class cannot be instantiated directly using "),W5e=n($so,"CODE",{});var Zoa=s(W5e);H5r=r(Zoa,"__init__()"),Zoa.forEach(t),J5r=r($so," (throws an error)."),$so.forEach(t),Y5r=i(Yl),Bt=n(Yl,"DIV",{class:!0});var A9=s(Bt);T(Jk.$$.fragment,A9),Z5r=i(A9),U5e=n(A9,"P",{});var Koa=s(U5e);K5r=r(Koa,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Koa.forEach(t),e0r=i(A9),Fm=n(A9,"P",{});var Sme=s(Fm);o0r=r(Sme,`Note:
Loading a model from its configuration file does `),H5e=n(Sme,"STRONG",{});var era=s(H5e);r0r=r(era,"not"),era.forEach(t),t0r=r(Sme,` load the model weights. It only affects the
model\u2019s configuration. Use `),JK=n(Sme,"A",{href:!0});var ora=s(JK);a0r=r(ora,"from_pretrained()"),ora.forEach(t),n0r=r(Sme," to load the model weights."),Sme.forEach(t),s0r=i(A9),T(fC.$$.fragment,A9),A9.forEach(t),l0r=i(Yl),go=n(Yl,"DIV",{class:!0});var Da=s(go);T(Yk.$$.fragment,Da),i0r=i(Da),J5e=n(Da,"P",{});var rra=s(J5e);d0r=r(rra,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),rra.forEach(t),m0r=i(Da),vn=n(Da,"P",{});var L9=s(vn);c0r=r(L9,"The model class to instantiate is selected based on the "),Y5e=n(L9,"CODE",{});var tra=s(Y5e);f0r=r(tra,"model_type"),tra.forEach(t),g0r=r(L9,` property of the config object (either
passed as an argument or loaded from `),Z5e=n(L9,"CODE",{});var ara=s(Z5e);h0r=r(ara,"pretrained_model_name_or_path"),ara.forEach(t),u0r=r(L9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K5e=n(L9,"CODE",{});var nra=s(K5e);p0r=r(nra,"pretrained_model_name_or_path"),nra.forEach(t),_0r=r(L9,":"),L9.forEach(t),b0r=i(Da),be=n(Da,"UL",{});var Fe=s(be);gC=n(Fe,"LI",{});var RHe=s(gC);e0e=n(RHe,"STRONG",{});var sra=s(e0e);v0r=r(sra,"beit"),sra.forEach(t),F0r=r(RHe," \u2014 "),YK=n(RHe,"A",{href:!0});var lra=s(YK);T0r=r(lra,"BeitForImageClassification"),lra.forEach(t),M0r=r(RHe," (BEiT model)"),RHe.forEach(t),E0r=i(Fe),hC=n(Fe,"LI",{});var PHe=s(hC);o0e=n(PHe,"STRONG",{});var ira=s(o0e);C0r=r(ira,"convnext"),ira.forEach(t),w0r=r(PHe," \u2014 "),ZK=n(PHe,"A",{href:!0});var dra=s(ZK);A0r=r(dra,"ConvNextForImageClassification"),dra.forEach(t),L0r=r(PHe," (ConvNeXT model)"),PHe.forEach(t),y0r=i(Fe),uC=n(Fe,"LI",{});var BHe=s(uC);r0e=n(BHe,"STRONG",{});var mra=s(r0e);x0r=r(mra,"cvt"),mra.forEach(t),$0r=r(BHe," \u2014 "),KK=n(BHe,"A",{href:!0});var cra=s(KK);k0r=r(cra,"CvtForImageClassification"),cra.forEach(t),S0r=r(BHe," (CvT model)"),BHe.forEach(t),R0r=i(Fe),pC=n(Fe,"LI",{});var IHe=s(pC);t0e=n(IHe,"STRONG",{});var fra=s(t0e);P0r=r(fra,"data2vec-vision"),fra.forEach(t),B0r=r(IHe," \u2014 "),eee=n(IHe,"A",{href:!0});var gra=s(eee);I0r=r(gra,"Data2VecVisionForImageClassification"),gra.forEach(t),N0r=r(IHe," (Data2VecVision model)"),IHe.forEach(t),q0r=i(Fe),$l=n(Fe,"LI",{});var bN=s($l);a0e=n(bN,"STRONG",{});var hra=s(a0e);j0r=r(hra,"deit"),hra.forEach(t),D0r=r(bN," \u2014 "),oee=n(bN,"A",{href:!0});var ura=s(oee);G0r=r(ura,"DeiTForImageClassification"),ura.forEach(t),O0r=r(bN," or "),ree=n(bN,"A",{href:!0});var pra=s(ree);V0r=r(pra,"DeiTForImageClassificationWithTeacher"),pra.forEach(t),X0r=r(bN," (DeiT model)"),bN.forEach(t),z0r=i(Fe),_C=n(Fe,"LI",{});var NHe=s(_C);n0e=n(NHe,"STRONG",{});var _ra=s(n0e);Q0r=r(_ra,"imagegpt"),_ra.forEach(t),W0r=r(NHe," \u2014 "),tee=n(NHe,"A",{href:!0});var bra=s(tee);U0r=r(bra,"ImageGPTForImageClassification"),bra.forEach(t),H0r=r(NHe," (ImageGPT model)"),NHe.forEach(t),J0r=i(Fe),kl=n(Fe,"LI",{});var vN=s(kl);s0e=n(vN,"STRONG",{});var vra=s(s0e);Y0r=r(vra,"levit"),vra.forEach(t),Z0r=r(vN," \u2014 "),aee=n(vN,"A",{href:!0});var Fra=s(aee);K0r=r(Fra,"LevitForImageClassification"),Fra.forEach(t),ewr=r(vN," or "),nee=n(vN,"A",{href:!0});var Tra=s(nee);owr=r(Tra,"LevitForImageClassificationWithTeacher"),Tra.forEach(t),rwr=r(vN," (LeViT model)"),vN.forEach(t),twr=i(Fe),bC=n(Fe,"LI",{});var qHe=s(bC);l0e=n(qHe,"STRONG",{});var Mra=s(l0e);awr=r(Mra,"mobilevit"),Mra.forEach(t),nwr=r(qHe," \u2014 "),see=n(qHe,"A",{href:!0});var Era=s(see);swr=r(Era,"MobileViTForImageClassification"),Era.forEach(t),lwr=r(qHe," (MobileViT model)"),qHe.forEach(t),iwr=i(Fe),It=n(Fe,"LI",{});var Xf=s(It);i0e=n(Xf,"STRONG",{});var Cra=s(i0e);dwr=r(Cra,"perceiver"),Cra.forEach(t),mwr=r(Xf," \u2014 "),lee=n(Xf,"A",{href:!0});var wra=s(lee);cwr=r(wra,"PerceiverForImageClassificationLearned"),wra.forEach(t),fwr=r(Xf," or "),iee=n(Xf,"A",{href:!0});var Ara=s(iee);gwr=r(Ara,"PerceiverForImageClassificationFourier"),Ara.forEach(t),hwr=r(Xf," or "),dee=n(Xf,"A",{href:!0});var Lra=s(dee);uwr=r(Lra,"PerceiverForImageClassificationConvProcessing"),Lra.forEach(t),pwr=r(Xf," (Perceiver model)"),Xf.forEach(t),_wr=i(Fe),vC=n(Fe,"LI",{});var jHe=s(vC);d0e=n(jHe,"STRONG",{});var yra=s(d0e);bwr=r(yra,"poolformer"),yra.forEach(t),vwr=r(jHe," \u2014 "),mee=n(jHe,"A",{href:!0});var xra=s(mee);Fwr=r(xra,"PoolFormerForImageClassification"),xra.forEach(t),Twr=r(jHe," (PoolFormer model)"),jHe.forEach(t),Mwr=i(Fe),FC=n(Fe,"LI",{});var DHe=s(FC);m0e=n(DHe,"STRONG",{});var $ra=s(m0e);Ewr=r($ra,"regnet"),$ra.forEach(t),Cwr=r(DHe," \u2014 "),cee=n(DHe,"A",{href:!0});var kra=s(cee);wwr=r(kra,"RegNetForImageClassification"),kra.forEach(t),Awr=r(DHe," (RegNet model)"),DHe.forEach(t),Lwr=i(Fe),TC=n(Fe,"LI",{});var GHe=s(TC);c0e=n(GHe,"STRONG",{});var Sra=s(c0e);ywr=r(Sra,"resnet"),Sra.forEach(t),xwr=r(GHe," \u2014 "),fee=n(GHe,"A",{href:!0});var Rra=s(fee);$wr=r(Rra,"ResNetForImageClassification"),Rra.forEach(t),kwr=r(GHe," (ResNet model)"),GHe.forEach(t),Swr=i(Fe),MC=n(Fe,"LI",{});var OHe=s(MC);f0e=n(OHe,"STRONG",{});var Pra=s(f0e);Rwr=r(Pra,"segformer"),Pra.forEach(t),Pwr=r(OHe," \u2014 "),gee=n(OHe,"A",{href:!0});var Bra=s(gee);Bwr=r(Bra,"SegformerForImageClassification"),Bra.forEach(t),Iwr=r(OHe," (SegFormer model)"),OHe.forEach(t),Nwr=i(Fe),EC=n(Fe,"LI",{});var VHe=s(EC);g0e=n(VHe,"STRONG",{});var Ira=s(g0e);qwr=r(Ira,"swin"),Ira.forEach(t),jwr=r(VHe," \u2014 "),hee=n(VHe,"A",{href:!0});var Nra=s(hee);Dwr=r(Nra,"SwinForImageClassification"),Nra.forEach(t),Gwr=r(VHe," (Swin Transformer model)"),VHe.forEach(t),Owr=i(Fe),CC=n(Fe,"LI",{});var XHe=s(CC);h0e=n(XHe,"STRONG",{});var qra=s(h0e);Vwr=r(qra,"swinv2"),qra.forEach(t),Xwr=r(XHe," \u2014 "),uee=n(XHe,"A",{href:!0});var jra=s(uee);zwr=r(jra,"Swinv2ForImageClassification"),jra.forEach(t),Qwr=r(XHe," (Swin Transformer V2 model)"),XHe.forEach(t),Wwr=i(Fe),wC=n(Fe,"LI",{});var zHe=s(wC);u0e=n(zHe,"STRONG",{});var Dra=s(u0e);Uwr=r(Dra,"van"),Dra.forEach(t),Hwr=r(zHe," \u2014 "),pee=n(zHe,"A",{href:!0});var Gra=s(pee);Jwr=r(Gra,"VanForImageClassification"),Gra.forEach(t),Ywr=r(zHe," (VAN model)"),zHe.forEach(t),Zwr=i(Fe),AC=n(Fe,"LI",{});var QHe=s(AC);p0e=n(QHe,"STRONG",{});var Ora=s(p0e);Kwr=r(Ora,"vit"),Ora.forEach(t),eAr=r(QHe," \u2014 "),_ee=n(QHe,"A",{href:!0});var Vra=s(_ee);oAr=r(Vra,"ViTForImageClassification"),Vra.forEach(t),rAr=r(QHe," (ViT model)"),QHe.forEach(t),tAr=i(Fe),LC=n(Fe,"LI",{});var WHe=s(LC);_0e=n(WHe,"STRONG",{});var Xra=s(_0e);aAr=r(Xra,"vit_msn"),Xra.forEach(t),nAr=r(WHe," \u2014 "),bee=n(WHe,"A",{href:!0});var zra=s(bee);sAr=r(zra,"ViTMSNForImageClassification"),zra.forEach(t),lAr=r(WHe," (ViTMSN model)"),WHe.forEach(t),Fe.forEach(t),iAr=i(Da),yC=n(Da,"P",{});var UHe=s(yC);dAr=r(UHe,"The model is set in evaluation mode by default using "),b0e=n(UHe,"CODE",{});var Qra=s(b0e);mAr=r(Qra,"model.eval()"),Qra.forEach(t),cAr=r(UHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),v0e=n(UHe,"CODE",{});var Wra=s(v0e);fAr=r(Wra,"model.train()"),Wra.forEach(t),UHe.forEach(t),gAr=i(Da),T(xC.$$.fragment,Da),Da.forEach(t),Yl.forEach(t),fao=i(c),Tm=n(c,"H2",{class:!0});var kso=s(Tm);$C=n(kso,"A",{id:!0,class:!0,href:!0});var Ura=s($C);F0e=n(Ura,"SPAN",{});var Hra=s(F0e);T(Zk.$$.fragment,Hra),Hra.forEach(t),Ura.forEach(t),hAr=i(kso),T0e=n(kso,"SPAN",{});var Jra=s(T0e);uAr=r(Jra,"AutoModelForVideoClassification"),Jra.forEach(t),kso.forEach(t),gao=i(c),Jo=n(c,"DIV",{class:!0});var Zl=s(Jo);T(Kk.$$.fragment,Zl),pAr=i(Zl),Mm=n(Zl,"P",{});var Rme=s(Mm);_Ar=r(Rme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),vee=n(Rme,"A",{href:!0});var Yra=s(vee);bAr=r(Yra,"from_pretrained()"),Yra.forEach(t),vAr=r(Rme," class method or the "),Fee=n(Rme,"A",{href:!0});var Zra=s(Fee);FAr=r(Zra,"from_config()"),Zra.forEach(t),TAr=r(Rme,` class
method.`),Rme.forEach(t),MAr=i(Zl),eS=n(Zl,"P",{});var Sso=s(eS);EAr=r(Sso,"This class cannot be instantiated directly using "),M0e=n(Sso,"CODE",{});var Kra=s(M0e);CAr=r(Kra,"__init__()"),Kra.forEach(t),wAr=r(Sso," (throws an error)."),Sso.forEach(t),AAr=i(Zl),Nt=n(Zl,"DIV",{class:!0});var y9=s(Nt);T(oS.$$.fragment,y9),LAr=i(y9),E0e=n(y9,"P",{});var eta=s(E0e);yAr=r(eta,"Instantiates one of the model classes of the library (with a video classification head) from a configuration."),eta.forEach(t),xAr=i(y9),Em=n(y9,"P",{});var Pme=s(Em);$Ar=r(Pme,`Note:
Loading a model from its configuration file does `),C0e=n(Pme,"STRONG",{});var ota=s(C0e);kAr=r(ota,"not"),ota.forEach(t),SAr=r(Pme,` load the model weights. It only affects the
model\u2019s configuration. Use `),Tee=n(Pme,"A",{href:!0});var rta=s(Tee);RAr=r(rta,"from_pretrained()"),rta.forEach(t),PAr=r(Pme," to load the model weights."),Pme.forEach(t),BAr=i(y9),T(kC.$$.fragment,y9),y9.forEach(t),IAr=i(Zl),ho=n(Zl,"DIV",{class:!0});var Ga=s(ho);T(rS.$$.fragment,Ga),NAr=i(Ga),w0e=n(Ga,"P",{});var tta=s(w0e);qAr=r(tta,"Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),tta.forEach(t),jAr=i(Ga),Fn=n(Ga,"P",{});var x9=s(Fn);DAr=r(x9,"The model class to instantiate is selected based on the "),A0e=n(x9,"CODE",{});var ata=s(A0e);GAr=r(ata,"model_type"),ata.forEach(t),OAr=r(x9,` property of the config object (either
passed as an argument or loaded from `),L0e=n(x9,"CODE",{});var nta=s(L0e);VAr=r(nta,"pretrained_model_name_or_path"),nta.forEach(t),XAr=r(x9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),y0e=n(x9,"CODE",{});var sta=s(y0e);zAr=r(sta,"pretrained_model_name_or_path"),sta.forEach(t),QAr=r(x9,":"),x9.forEach(t),WAr=i(Ga),x0e=n(Ga,"UL",{});var lta=s(x0e);SC=n(lta,"LI",{});var HHe=s(SC);$0e=n(HHe,"STRONG",{});var ita=s($0e);UAr=r(ita,"videomae"),ita.forEach(t),HAr=r(HHe," \u2014 "),Mee=n(HHe,"A",{href:!0});var dta=s(Mee);JAr=r(dta,"VideoMAEForVideoClassification"),dta.forEach(t),YAr=r(HHe," (VideoMAE model)"),HHe.forEach(t),lta.forEach(t),ZAr=i(Ga),RC=n(Ga,"P",{});var JHe=s(RC);KAr=r(JHe,"The model is set in evaluation mode by default using "),k0e=n(JHe,"CODE",{});var mta=s(k0e);e6r=r(mta,"model.eval()"),mta.forEach(t),o6r=r(JHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),S0e=n(JHe,"CODE",{});var cta=s(S0e);r6r=r(cta,"model.train()"),cta.forEach(t),JHe.forEach(t),t6r=i(Ga),T(PC.$$.fragment,Ga),Ga.forEach(t),Zl.forEach(t),hao=i(c),Cm=n(c,"H2",{class:!0});var Rso=s(Cm);BC=n(Rso,"A",{id:!0,class:!0,href:!0});var fta=s(BC);R0e=n(fta,"SPAN",{});var gta=s(R0e);T(tS.$$.fragment,gta),gta.forEach(t),fta.forEach(t),a6r=i(Rso),P0e=n(Rso,"SPAN",{});var hta=s(P0e);n6r=r(hta,"AutoModelForVision2Seq"),hta.forEach(t),Rso.forEach(t),uao=i(c),Yo=n(c,"DIV",{class:!0});var Kl=s(Yo);T(aS.$$.fragment,Kl),s6r=i(Kl),wm=n(Kl,"P",{});var Bme=s(wm);l6r=r(Bme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Eee=n(Bme,"A",{href:!0});var uta=s(Eee);i6r=r(uta,"from_pretrained()"),uta.forEach(t),d6r=r(Bme," class method or the "),Cee=n(Bme,"A",{href:!0});var pta=s(Cee);m6r=r(pta,"from_config()"),pta.forEach(t),c6r=r(Bme,` class
method.`),Bme.forEach(t),f6r=i(Kl),nS=n(Kl,"P",{});var Pso=s(nS);g6r=r(Pso,"This class cannot be instantiated directly using "),B0e=n(Pso,"CODE",{});var _ta=s(B0e);h6r=r(_ta,"__init__()"),_ta.forEach(t),u6r=r(Pso," (throws an error)."),Pso.forEach(t),p6r=i(Kl),qt=n(Kl,"DIV",{class:!0});var $9=s(qt);T(sS.$$.fragment,$9),_6r=i($9),I0e=n($9,"P",{});var bta=s(I0e);b6r=r(bta,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),bta.forEach(t),v6r=i($9),Am=n($9,"P",{});var Ime=s(Am);F6r=r(Ime,`Note:
Loading a model from its configuration file does `),N0e=n(Ime,"STRONG",{});var vta=s(N0e);T6r=r(vta,"not"),vta.forEach(t),M6r=r(Ime,` load the model weights. It only affects the
model\u2019s configuration. Use `),wee=n(Ime,"A",{href:!0});var Fta=s(wee);E6r=r(Fta,"from_pretrained()"),Fta.forEach(t),C6r=r(Ime," to load the model weights."),Ime.forEach(t),w6r=i($9),T(IC.$$.fragment,$9),$9.forEach(t),A6r=i(Kl),uo=n(Kl,"DIV",{class:!0});var Oa=s(uo);T(lS.$$.fragment,Oa),L6r=i(Oa),q0e=n(Oa,"P",{});var Tta=s(q0e);y6r=r(Tta,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Tta.forEach(t),x6r=i(Oa),Tn=n(Oa,"P",{});var k9=s(Tn);$6r=r(k9,"The model class to instantiate is selected based on the "),j0e=n(k9,"CODE",{});var Mta=s(j0e);k6r=r(Mta,"model_type"),Mta.forEach(t),S6r=r(k9,` property of the config object (either
passed as an argument or loaded from `),D0e=n(k9,"CODE",{});var Eta=s(D0e);R6r=r(Eta,"pretrained_model_name_or_path"),Eta.forEach(t),P6r=r(k9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G0e=n(k9,"CODE",{});var Cta=s(G0e);B6r=r(Cta,"pretrained_model_name_or_path"),Cta.forEach(t),I6r=r(k9,":"),k9.forEach(t),N6r=i(Oa),O0e=n(Oa,"UL",{});var wta=s(O0e);NC=n(wta,"LI",{});var YHe=s(NC);V0e=n(YHe,"STRONG",{});var Ata=s(V0e);q6r=r(Ata,"vision-encoder-decoder"),Ata.forEach(t),j6r=r(YHe," \u2014 "),Aee=n(YHe,"A",{href:!0});var Lta=s(Aee);D6r=r(Lta,"VisionEncoderDecoderModel"),Lta.forEach(t),G6r=r(YHe," (Vision Encoder decoder model)"),YHe.forEach(t),wta.forEach(t),O6r=i(Oa),qC=n(Oa,"P",{});var ZHe=s(qC);V6r=r(ZHe,"The model is set in evaluation mode by default using "),X0e=n(ZHe,"CODE",{});var yta=s(X0e);X6r=r(yta,"model.eval()"),yta.forEach(t),z6r=r(ZHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),z0e=n(ZHe,"CODE",{});var xta=s(z0e);Q6r=r(xta,"model.train()"),xta.forEach(t),ZHe.forEach(t),W6r=i(Oa),T(jC.$$.fragment,Oa),Oa.forEach(t),Kl.forEach(t),pao=i(c),Lm=n(c,"H2",{class:!0});var Bso=s(Lm);DC=n(Bso,"A",{id:!0,class:!0,href:!0});var $ta=s(DC);Q0e=n($ta,"SPAN",{});var kta=s(Q0e);T(iS.$$.fragment,kta),kta.forEach(t),$ta.forEach(t),U6r=i(Bso),W0e=n(Bso,"SPAN",{});var Sta=s(W0e);H6r=r(Sta,"AutoModelForVisualQuestionAnswering"),Sta.forEach(t),Bso.forEach(t),_ao=i(c),Zo=n(c,"DIV",{class:!0});var ei=s(Zo);T(dS.$$.fragment,ei),J6r=i(ei),ym=n(ei,"P",{});var Nme=s(ym);Y6r=r(Nme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),Lee=n(Nme,"A",{href:!0});var Rta=s(Lee);Z6r=r(Rta,"from_pretrained()"),Rta.forEach(t),K6r=r(Nme," class method or the "),yee=n(Nme,"A",{href:!0});var Pta=s(yee);e7r=r(Pta,"from_config()"),Pta.forEach(t),o7r=r(Nme,` class
method.`),Nme.forEach(t),r7r=i(ei),mS=n(ei,"P",{});var Iso=s(mS);t7r=r(Iso,"This class cannot be instantiated directly using "),U0e=n(Iso,"CODE",{});var Bta=s(U0e);a7r=r(Bta,"__init__()"),Bta.forEach(t),n7r=r(Iso," (throws an error)."),Iso.forEach(t),s7r=i(ei),jt=n(ei,"DIV",{class:!0});var S9=s(jt);T(cS.$$.fragment,S9),l7r=i(S9),H0e=n(S9,"P",{});var Ita=s(H0e);i7r=r(Ita,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),Ita.forEach(t),d7r=i(S9),xm=n(S9,"P",{});var qme=s(xm);m7r=r(qme,`Note:
Loading a model from its configuration file does `),J0e=n(qme,"STRONG",{});var Nta=s(J0e);c7r=r(Nta,"not"),Nta.forEach(t),f7r=r(qme,` load the model weights. It only affects the
model\u2019s configuration. Use `),xee=n(qme,"A",{href:!0});var qta=s(xee);g7r=r(qta,"from_pretrained()"),qta.forEach(t),h7r=r(qme," to load the model weights."),qme.forEach(t),u7r=i(S9),T(GC.$$.fragment,S9),S9.forEach(t),p7r=i(ei),po=n(ei,"DIV",{class:!0});var Va=s(po);T(fS.$$.fragment,Va),_7r=i(Va),Y0e=n(Va,"P",{});var jta=s(Y0e);b7r=r(jta,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),jta.forEach(t),v7r=i(Va),Mn=n(Va,"P",{});var R9=s(Mn);F7r=r(R9,"The model class to instantiate is selected based on the "),Z0e=n(R9,"CODE",{});var Dta=s(Z0e);T7r=r(Dta,"model_type"),Dta.forEach(t),M7r=r(R9,` property of the config object (either
passed as an argument or loaded from `),K0e=n(R9,"CODE",{});var Gta=s(K0e);E7r=r(Gta,"pretrained_model_name_or_path"),Gta.forEach(t),C7r=r(R9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ewe=n(R9,"CODE",{});var Ota=s(ewe);w7r=r(Ota,"pretrained_model_name_or_path"),Ota.forEach(t),A7r=r(R9,":"),R9.forEach(t),L7r=i(Va),owe=n(Va,"UL",{});var Vta=s(owe);OC=n(Vta,"LI",{});var KHe=s(OC);rwe=n(KHe,"STRONG",{});var Xta=s(rwe);y7r=r(Xta,"vilt"),Xta.forEach(t),x7r=r(KHe," \u2014 "),$ee=n(KHe,"A",{href:!0});var zta=s($ee);$7r=r(zta,"ViltForQuestionAnswering"),zta.forEach(t),k7r=r(KHe," (ViLT model)"),KHe.forEach(t),Vta.forEach(t),S7r=i(Va),VC=n(Va,"P",{});var eJe=s(VC);R7r=r(eJe,"The model is set in evaluation mode by default using "),twe=n(eJe,"CODE",{});var Qta=s(twe);P7r=r(Qta,"model.eval()"),Qta.forEach(t),B7r=r(eJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),awe=n(eJe,"CODE",{});var Wta=s(awe);I7r=r(Wta,"model.train()"),Wta.forEach(t),eJe.forEach(t),N7r=i(Va),T(XC.$$.fragment,Va),Va.forEach(t),ei.forEach(t),bao=i(c),$m=n(c,"H2",{class:!0});var Nso=s($m);zC=n(Nso,"A",{id:!0,class:!0,href:!0});var Uta=s(zC);nwe=n(Uta,"SPAN",{});var Hta=s(nwe);T(gS.$$.fragment,Hta),Hta.forEach(t),Uta.forEach(t),q7r=i(Nso),swe=n(Nso,"SPAN",{});var Jta=s(swe);j7r=r(Jta,"AutoModelForAudioClassification"),Jta.forEach(t),Nso.forEach(t),vao=i(c),Ko=n(c,"DIV",{class:!0});var oi=s(Ko);T(hS.$$.fragment,oi),D7r=i(oi),km=n(oi,"P",{});var jme=s(km);G7r=r(jme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),kee=n(jme,"A",{href:!0});var Yta=s(kee);O7r=r(Yta,"from_pretrained()"),Yta.forEach(t),V7r=r(jme," class method or the "),See=n(jme,"A",{href:!0});var Zta=s(See);X7r=r(Zta,"from_config()"),Zta.forEach(t),z7r=r(jme,` class
method.`),jme.forEach(t),Q7r=i(oi),uS=n(oi,"P",{});var qso=s(uS);W7r=r(qso,"This class cannot be instantiated directly using "),lwe=n(qso,"CODE",{});var Kta=s(lwe);U7r=r(Kta,"__init__()"),Kta.forEach(t),H7r=r(qso," (throws an error)."),qso.forEach(t),J7r=i(oi),Dt=n(oi,"DIV",{class:!0});var P9=s(Dt);T(pS.$$.fragment,P9),Y7r=i(P9),iwe=n(P9,"P",{});var eaa=s(iwe);Z7r=r(eaa,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),eaa.forEach(t),K7r=i(P9),Sm=n(P9,"P",{});var Dme=s(Sm);e8r=r(Dme,`Note:
Loading a model from its configuration file does `),dwe=n(Dme,"STRONG",{});var oaa=s(dwe);o8r=r(oaa,"not"),oaa.forEach(t),r8r=r(Dme,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ree=n(Dme,"A",{href:!0});var raa=s(Ree);t8r=r(raa,"from_pretrained()"),raa.forEach(t),a8r=r(Dme," to load the model weights."),Dme.forEach(t),n8r=i(P9),T(QC.$$.fragment,P9),P9.forEach(t),s8r=i(oi),_o=n(oi,"DIV",{class:!0});var Xa=s(_o);T(_S.$$.fragment,Xa),l8r=i(Xa),mwe=n(Xa,"P",{});var taa=s(mwe);i8r=r(taa,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),taa.forEach(t),d8r=i(Xa),En=n(Xa,"P",{});var B9=s(En);m8r=r(B9,"The model class to instantiate is selected based on the "),cwe=n(B9,"CODE",{});var aaa=s(cwe);c8r=r(aaa,"model_type"),aaa.forEach(t),f8r=r(B9,` property of the config object (either
passed as an argument or loaded from `),fwe=n(B9,"CODE",{});var naa=s(fwe);g8r=r(naa,"pretrained_model_name_or_path"),naa.forEach(t),h8r=r(B9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gwe=n(B9,"CODE",{});var saa=s(gwe);u8r=r(saa,"pretrained_model_name_or_path"),saa.forEach(t),p8r=r(B9,":"),B9.forEach(t),_8r=i(Xa),Be=n(Xa,"UL",{});var We=s(Be);WC=n(We,"LI",{});var oJe=s(WC);hwe=n(oJe,"STRONG",{});var laa=s(hwe);b8r=r(laa,"data2vec-audio"),laa.forEach(t),v8r=r(oJe," \u2014 "),Pee=n(oJe,"A",{href:!0});var iaa=s(Pee);F8r=r(iaa,"Data2VecAudioForSequenceClassification"),iaa.forEach(t),T8r=r(oJe," (Data2VecAudio model)"),oJe.forEach(t),M8r=i(We),UC=n(We,"LI",{});var rJe=s(UC);uwe=n(rJe,"STRONG",{});var daa=s(uwe);E8r=r(daa,"hubert"),daa.forEach(t),C8r=r(rJe," \u2014 "),Bee=n(rJe,"A",{href:!0});var maa=s(Bee);w8r=r(maa,"HubertForSequenceClassification"),maa.forEach(t),A8r=r(rJe," (Hubert model)"),rJe.forEach(t),L8r=i(We),HC=n(We,"LI",{});var tJe=s(HC);pwe=n(tJe,"STRONG",{});var caa=s(pwe);y8r=r(caa,"sew"),caa.forEach(t),x8r=r(tJe," \u2014 "),Iee=n(tJe,"A",{href:!0});var faa=s(Iee);$8r=r(faa,"SEWForSequenceClassification"),faa.forEach(t),k8r=r(tJe," (SEW model)"),tJe.forEach(t),S8r=i(We),JC=n(We,"LI",{});var aJe=s(JC);_we=n(aJe,"STRONG",{});var gaa=s(_we);R8r=r(gaa,"sew-d"),gaa.forEach(t),P8r=r(aJe," \u2014 "),Nee=n(aJe,"A",{href:!0});var haa=s(Nee);B8r=r(haa,"SEWDForSequenceClassification"),haa.forEach(t),I8r=r(aJe," (SEW-D model)"),aJe.forEach(t),N8r=i(We),YC=n(We,"LI",{});var nJe=s(YC);bwe=n(nJe,"STRONG",{});var uaa=s(bwe);q8r=r(uaa,"unispeech"),uaa.forEach(t),j8r=r(nJe," \u2014 "),qee=n(nJe,"A",{href:!0});var paa=s(qee);D8r=r(paa,"UniSpeechForSequenceClassification"),paa.forEach(t),G8r=r(nJe," (UniSpeech model)"),nJe.forEach(t),O8r=i(We),ZC=n(We,"LI",{});var sJe=s(ZC);vwe=n(sJe,"STRONG",{});var _aa=s(vwe);V8r=r(_aa,"unispeech-sat"),_aa.forEach(t),X8r=r(sJe," \u2014 "),jee=n(sJe,"A",{href:!0});var baa=s(jee);z8r=r(baa,"UniSpeechSatForSequenceClassification"),baa.forEach(t),Q8r=r(sJe," (UniSpeechSat model)"),sJe.forEach(t),W8r=i(We),KC=n(We,"LI",{});var lJe=s(KC);Fwe=n(lJe,"STRONG",{});var vaa=s(Fwe);U8r=r(vaa,"wav2vec2"),vaa.forEach(t),H8r=r(lJe," \u2014 "),Dee=n(lJe,"A",{href:!0});var Faa=s(Dee);J8r=r(Faa,"Wav2Vec2ForSequenceClassification"),Faa.forEach(t),Y8r=r(lJe," (Wav2Vec2 model)"),lJe.forEach(t),Z8r=i(We),e3=n(We,"LI",{});var iJe=s(e3);Twe=n(iJe,"STRONG",{});var Taa=s(Twe);K8r=r(Taa,"wav2vec2-conformer"),Taa.forEach(t),eLr=r(iJe," \u2014 "),Gee=n(iJe,"A",{href:!0});var Maa=s(Gee);oLr=r(Maa,"Wav2Vec2ConformerForSequenceClassification"),Maa.forEach(t),rLr=r(iJe," (Wav2Vec2-Conformer model)"),iJe.forEach(t),tLr=i(We),o3=n(We,"LI",{});var dJe=s(o3);Mwe=n(dJe,"STRONG",{});var Eaa=s(Mwe);aLr=r(Eaa,"wavlm"),Eaa.forEach(t),nLr=r(dJe," \u2014 "),Oee=n(dJe,"A",{href:!0});var Caa=s(Oee);sLr=r(Caa,"WavLMForSequenceClassification"),Caa.forEach(t),lLr=r(dJe," (WavLM model)"),dJe.forEach(t),We.forEach(t),iLr=i(Xa),r3=n(Xa,"P",{});var mJe=s(r3);dLr=r(mJe,"The model is set in evaluation mode by default using "),Ewe=n(mJe,"CODE",{});var waa=s(Ewe);mLr=r(waa,"model.eval()"),waa.forEach(t),cLr=r(mJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Cwe=n(mJe,"CODE",{});var Aaa=s(Cwe);fLr=r(Aaa,"model.train()"),Aaa.forEach(t),mJe.forEach(t),gLr=i(Xa),T(t3.$$.fragment,Xa),Xa.forEach(t),oi.forEach(t),Fao=i(c),Rm=n(c,"H2",{class:!0});var jso=s(Rm);a3=n(jso,"A",{id:!0,class:!0,href:!0});var Laa=s(a3);wwe=n(Laa,"SPAN",{});var yaa=s(wwe);T(bS.$$.fragment,yaa),yaa.forEach(t),Laa.forEach(t),hLr=i(jso),Awe=n(jso,"SPAN",{});var xaa=s(Awe);uLr=r(xaa,"AutoModelForAudioFrameClassification"),xaa.forEach(t),jso.forEach(t),Tao=i(c),er=n(c,"DIV",{class:!0});var ri=s(er);T(vS.$$.fragment,ri),pLr=i(ri),Pm=n(ri,"P",{});var Gme=s(Pm);_Lr=r(Gme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),Vee=n(Gme,"A",{href:!0});var $aa=s(Vee);bLr=r($aa,"from_pretrained()"),$aa.forEach(t),vLr=r(Gme," class method or the "),Xee=n(Gme,"A",{href:!0});var kaa=s(Xee);FLr=r(kaa,"from_config()"),kaa.forEach(t),TLr=r(Gme,` class
method.`),Gme.forEach(t),MLr=i(ri),FS=n(ri,"P",{});var Dso=s(FS);ELr=r(Dso,"This class cannot be instantiated directly using "),Lwe=n(Dso,"CODE",{});var Saa=s(Lwe);CLr=r(Saa,"__init__()"),Saa.forEach(t),wLr=r(Dso," (throws an error)."),Dso.forEach(t),ALr=i(ri),Gt=n(ri,"DIV",{class:!0});var I9=s(Gt);T(TS.$$.fragment,I9),LLr=i(I9),ywe=n(I9,"P",{});var Raa=s(ywe);yLr=r(Raa,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),Raa.forEach(t),xLr=i(I9),Bm=n(I9,"P",{});var Ome=s(Bm);$Lr=r(Ome,`Note:
Loading a model from its configuration file does `),xwe=n(Ome,"STRONG",{});var Paa=s(xwe);kLr=r(Paa,"not"),Paa.forEach(t),SLr=r(Ome,` load the model weights. It only affects the
model\u2019s configuration. Use `),zee=n(Ome,"A",{href:!0});var Baa=s(zee);RLr=r(Baa,"from_pretrained()"),Baa.forEach(t),PLr=r(Ome," to load the model weights."),Ome.forEach(t),BLr=i(I9),T(n3.$$.fragment,I9),I9.forEach(t),ILr=i(ri),bo=n(ri,"DIV",{class:!0});var za=s(bo);T(MS.$$.fragment,za),NLr=i(za),$we=n(za,"P",{});var Iaa=s($we);qLr=r(Iaa,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),Iaa.forEach(t),jLr=i(za),Cn=n(za,"P",{});var N9=s(Cn);DLr=r(N9,"The model class to instantiate is selected based on the "),kwe=n(N9,"CODE",{});var Naa=s(kwe);GLr=r(Naa,"model_type"),Naa.forEach(t),OLr=r(N9,` property of the config object (either
passed as an argument or loaded from `),Swe=n(N9,"CODE",{});var qaa=s(Swe);VLr=r(qaa,"pretrained_model_name_or_path"),qaa.forEach(t),XLr=r(N9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rwe=n(N9,"CODE",{});var jaa=s(Rwe);zLr=r(jaa,"pretrained_model_name_or_path"),jaa.forEach(t),QLr=r(N9,":"),N9.forEach(t),WLr=i(za),ut=n(za,"UL",{});var ti=s(ut);s3=n(ti,"LI",{});var cJe=s(s3);Pwe=n(cJe,"STRONG",{});var Daa=s(Pwe);ULr=r(Daa,"data2vec-audio"),Daa.forEach(t),HLr=r(cJe," \u2014 "),Qee=n(cJe,"A",{href:!0});var Gaa=s(Qee);JLr=r(Gaa,"Data2VecAudioForAudioFrameClassification"),Gaa.forEach(t),YLr=r(cJe," (Data2VecAudio model)"),cJe.forEach(t),ZLr=i(ti),l3=n(ti,"LI",{});var fJe=s(l3);Bwe=n(fJe,"STRONG",{});var Oaa=s(Bwe);KLr=r(Oaa,"unispeech-sat"),Oaa.forEach(t),eyr=r(fJe," \u2014 "),Wee=n(fJe,"A",{href:!0});var Vaa=s(Wee);oyr=r(Vaa,"UniSpeechSatForAudioFrameClassification"),Vaa.forEach(t),ryr=r(fJe," (UniSpeechSat model)"),fJe.forEach(t),tyr=i(ti),i3=n(ti,"LI",{});var gJe=s(i3);Iwe=n(gJe,"STRONG",{});var Xaa=s(Iwe);ayr=r(Xaa,"wav2vec2"),Xaa.forEach(t),nyr=r(gJe," \u2014 "),Uee=n(gJe,"A",{href:!0});var zaa=s(Uee);syr=r(zaa,"Wav2Vec2ForAudioFrameClassification"),zaa.forEach(t),lyr=r(gJe," (Wav2Vec2 model)"),gJe.forEach(t),iyr=i(ti),d3=n(ti,"LI",{});var hJe=s(d3);Nwe=n(hJe,"STRONG",{});var Qaa=s(Nwe);dyr=r(Qaa,"wav2vec2-conformer"),Qaa.forEach(t),myr=r(hJe," \u2014 "),Hee=n(hJe,"A",{href:!0});var Waa=s(Hee);cyr=r(Waa,"Wav2Vec2ConformerForAudioFrameClassification"),Waa.forEach(t),fyr=r(hJe," (Wav2Vec2-Conformer model)"),hJe.forEach(t),gyr=i(ti),m3=n(ti,"LI",{});var uJe=s(m3);qwe=n(uJe,"STRONG",{});var Uaa=s(qwe);hyr=r(Uaa,"wavlm"),Uaa.forEach(t),uyr=r(uJe," \u2014 "),Jee=n(uJe,"A",{href:!0});var Haa=s(Jee);pyr=r(Haa,"WavLMForAudioFrameClassification"),Haa.forEach(t),_yr=r(uJe," (WavLM model)"),uJe.forEach(t),ti.forEach(t),byr=i(za),c3=n(za,"P",{});var pJe=s(c3);vyr=r(pJe,"The model is set in evaluation mode by default using "),jwe=n(pJe,"CODE",{});var Jaa=s(jwe);Fyr=r(Jaa,"model.eval()"),Jaa.forEach(t),Tyr=r(pJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Dwe=n(pJe,"CODE",{});var Yaa=s(Dwe);Myr=r(Yaa,"model.train()"),Yaa.forEach(t),pJe.forEach(t),Eyr=i(za),T(f3.$$.fragment,za),za.forEach(t),ri.forEach(t),Mao=i(c),Im=n(c,"H2",{class:!0});var Gso=s(Im);g3=n(Gso,"A",{id:!0,class:!0,href:!0});var Zaa=s(g3);Gwe=n(Zaa,"SPAN",{});var Kaa=s(Gwe);T(ES.$$.fragment,Kaa),Kaa.forEach(t),Zaa.forEach(t),Cyr=i(Gso),Owe=n(Gso,"SPAN",{});var ena=s(Owe);wyr=r(ena,"AutoModelForCTC"),ena.forEach(t),Gso.forEach(t),Eao=i(c),or=n(c,"DIV",{class:!0});var ai=s(or);T(CS.$$.fragment,ai),Ayr=i(ai),Nm=n(ai,"P",{});var Vme=s(Nm);Lyr=r(Vme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),Yee=n(Vme,"A",{href:!0});var ona=s(Yee);yyr=r(ona,"from_pretrained()"),ona.forEach(t),xyr=r(Vme," class method or the "),Zee=n(Vme,"A",{href:!0});var rna=s(Zee);$yr=r(rna,"from_config()"),rna.forEach(t),kyr=r(Vme,` class
method.`),Vme.forEach(t),Syr=i(ai),wS=n(ai,"P",{});var Oso=s(wS);Ryr=r(Oso,"This class cannot be instantiated directly using "),Vwe=n(Oso,"CODE",{});var tna=s(Vwe);Pyr=r(tna,"__init__()"),tna.forEach(t),Byr=r(Oso," (throws an error)."),Oso.forEach(t),Iyr=i(ai),Ot=n(ai,"DIV",{class:!0});var q9=s(Ot);T(AS.$$.fragment,q9),Nyr=i(q9),Xwe=n(q9,"P",{});var ana=s(Xwe);qyr=r(ana,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),ana.forEach(t),jyr=i(q9),qm=n(q9,"P",{});var Xme=s(qm);Dyr=r(Xme,`Note:
Loading a model from its configuration file does `),zwe=n(Xme,"STRONG",{});var nna=s(zwe);Gyr=r(nna,"not"),nna.forEach(t),Oyr=r(Xme,` load the model weights. It only affects the
model\u2019s configuration. Use `),Kee=n(Xme,"A",{href:!0});var sna=s(Kee);Vyr=r(sna,"from_pretrained()"),sna.forEach(t),Xyr=r(Xme," to load the model weights."),Xme.forEach(t),zyr=i(q9),T(h3.$$.fragment,q9),q9.forEach(t),Qyr=i(ai),vo=n(ai,"DIV",{class:!0});var Qa=s(vo);T(LS.$$.fragment,Qa),Wyr=i(Qa),Qwe=n(Qa,"P",{});var lna=s(Qwe);Uyr=r(lna,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),lna.forEach(t),Hyr=i(Qa),wn=n(Qa,"P",{});var j9=s(wn);Jyr=r(j9,"The model class to instantiate is selected based on the "),Wwe=n(j9,"CODE",{});var ina=s(Wwe);Yyr=r(ina,"model_type"),ina.forEach(t),Zyr=r(j9,` property of the config object (either
passed as an argument or loaded from `),Uwe=n(j9,"CODE",{});var dna=s(Uwe);Kyr=r(dna,"pretrained_model_name_or_path"),dna.forEach(t),e9r=r(j9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Hwe=n(j9,"CODE",{});var mna=s(Hwe);o9r=r(mna,"pretrained_model_name_or_path"),mna.forEach(t),r9r=r(j9,":"),j9.forEach(t),t9r=i(Qa),Le=n(Qa,"UL",{});var Ie=s(Le);u3=n(Ie,"LI",{});var _Je=s(u3);Jwe=n(_Je,"STRONG",{});var cna=s(Jwe);a9r=r(cna,"data2vec-audio"),cna.forEach(t),n9r=r(_Je," \u2014 "),eoe=n(_Je,"A",{href:!0});var fna=s(eoe);s9r=r(fna,"Data2VecAudioForCTC"),fna.forEach(t),l9r=r(_Je," (Data2VecAudio model)"),_Je.forEach(t),i9r=i(Ie),p3=n(Ie,"LI",{});var bJe=s(p3);Ywe=n(bJe,"STRONG",{});var gna=s(Ywe);d9r=r(gna,"hubert"),gna.forEach(t),m9r=r(bJe," \u2014 "),ooe=n(bJe,"A",{href:!0});var hna=s(ooe);c9r=r(hna,"HubertForCTC"),hna.forEach(t),f9r=r(bJe," (Hubert model)"),bJe.forEach(t),g9r=i(Ie),_3=n(Ie,"LI",{});var vJe=s(_3);Zwe=n(vJe,"STRONG",{});var una=s(Zwe);h9r=r(una,"mctct"),una.forEach(t),u9r=r(vJe," \u2014 "),roe=n(vJe,"A",{href:!0});var pna=s(roe);p9r=r(pna,"MCTCTForCTC"),pna.forEach(t),_9r=r(vJe," (M-CTC-T model)"),vJe.forEach(t),b9r=i(Ie),b3=n(Ie,"LI",{});var FJe=s(b3);Kwe=n(FJe,"STRONG",{});var _na=s(Kwe);v9r=r(_na,"sew"),_na.forEach(t),F9r=r(FJe," \u2014 "),toe=n(FJe,"A",{href:!0});var bna=s(toe);T9r=r(bna,"SEWForCTC"),bna.forEach(t),M9r=r(FJe," (SEW model)"),FJe.forEach(t),E9r=i(Ie),v3=n(Ie,"LI",{});var TJe=s(v3);eAe=n(TJe,"STRONG",{});var vna=s(eAe);C9r=r(vna,"sew-d"),vna.forEach(t),w9r=r(TJe," \u2014 "),aoe=n(TJe,"A",{href:!0});var Fna=s(aoe);A9r=r(Fna,"SEWDForCTC"),Fna.forEach(t),L9r=r(TJe," (SEW-D model)"),TJe.forEach(t),y9r=i(Ie),F3=n(Ie,"LI",{});var MJe=s(F3);oAe=n(MJe,"STRONG",{});var Tna=s(oAe);x9r=r(Tna,"unispeech"),Tna.forEach(t),$9r=r(MJe," \u2014 "),noe=n(MJe,"A",{href:!0});var Mna=s(noe);k9r=r(Mna,"UniSpeechForCTC"),Mna.forEach(t),S9r=r(MJe," (UniSpeech model)"),MJe.forEach(t),R9r=i(Ie),T3=n(Ie,"LI",{});var EJe=s(T3);rAe=n(EJe,"STRONG",{});var Ena=s(rAe);P9r=r(Ena,"unispeech-sat"),Ena.forEach(t),B9r=r(EJe," \u2014 "),soe=n(EJe,"A",{href:!0});var Cna=s(soe);I9r=r(Cna,"UniSpeechSatForCTC"),Cna.forEach(t),N9r=r(EJe," (UniSpeechSat model)"),EJe.forEach(t),q9r=i(Ie),M3=n(Ie,"LI",{});var CJe=s(M3);tAe=n(CJe,"STRONG",{});var wna=s(tAe);j9r=r(wna,"wav2vec2"),wna.forEach(t),D9r=r(CJe," \u2014 "),loe=n(CJe,"A",{href:!0});var Ana=s(loe);G9r=r(Ana,"Wav2Vec2ForCTC"),Ana.forEach(t),O9r=r(CJe," (Wav2Vec2 model)"),CJe.forEach(t),V9r=i(Ie),E3=n(Ie,"LI",{});var wJe=s(E3);aAe=n(wJe,"STRONG",{});var Lna=s(aAe);X9r=r(Lna,"wav2vec2-conformer"),Lna.forEach(t),z9r=r(wJe," \u2014 "),ioe=n(wJe,"A",{href:!0});var yna=s(ioe);Q9r=r(yna,"Wav2Vec2ConformerForCTC"),yna.forEach(t),W9r=r(wJe," (Wav2Vec2-Conformer model)"),wJe.forEach(t),U9r=i(Ie),C3=n(Ie,"LI",{});var AJe=s(C3);nAe=n(AJe,"STRONG",{});var xna=s(nAe);H9r=r(xna,"wavlm"),xna.forEach(t),J9r=r(AJe," \u2014 "),doe=n(AJe,"A",{href:!0});var $na=s(doe);Y9r=r($na,"WavLMForCTC"),$na.forEach(t),Z9r=r(AJe," (WavLM model)"),AJe.forEach(t),Ie.forEach(t),K9r=i(Qa),w3=n(Qa,"P",{});var LJe=s(w3);exr=r(LJe,"The model is set in evaluation mode by default using "),sAe=n(LJe,"CODE",{});var kna=s(sAe);oxr=r(kna,"model.eval()"),kna.forEach(t),rxr=r(LJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),lAe=n(LJe,"CODE",{});var Sna=s(lAe);txr=r(Sna,"model.train()"),Sna.forEach(t),LJe.forEach(t),axr=i(Qa),T(A3.$$.fragment,Qa),Qa.forEach(t),ai.forEach(t),Cao=i(c),jm=n(c,"H2",{class:!0});var Vso=s(jm);L3=n(Vso,"A",{id:!0,class:!0,href:!0});var Rna=s(L3);iAe=n(Rna,"SPAN",{});var Pna=s(iAe);T(yS.$$.fragment,Pna),Pna.forEach(t),Rna.forEach(t),nxr=i(Vso),dAe=n(Vso,"SPAN",{});var Bna=s(dAe);sxr=r(Bna,"AutoModelForSpeechSeq2Seq"),Bna.forEach(t),Vso.forEach(t),wao=i(c),rr=n(c,"DIV",{class:!0});var ni=s(rr);T(xS.$$.fragment,ni),lxr=i(ni),Dm=n(ni,"P",{});var zme=s(Dm);ixr=r(zme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),moe=n(zme,"A",{href:!0});var Ina=s(moe);dxr=r(Ina,"from_pretrained()"),Ina.forEach(t),mxr=r(zme," class method or the "),coe=n(zme,"A",{href:!0});var Nna=s(coe);cxr=r(Nna,"from_config()"),Nna.forEach(t),fxr=r(zme,` class
method.`),zme.forEach(t),gxr=i(ni),$S=n(ni,"P",{});var Xso=s($S);hxr=r(Xso,"This class cannot be instantiated directly using "),mAe=n(Xso,"CODE",{});var qna=s(mAe);uxr=r(qna,"__init__()"),qna.forEach(t),pxr=r(Xso," (throws an error)."),Xso.forEach(t),_xr=i(ni),Vt=n(ni,"DIV",{class:!0});var D9=s(Vt);T(kS.$$.fragment,D9),bxr=i(D9),cAe=n(D9,"P",{});var jna=s(cAe);vxr=r(jna,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),jna.forEach(t),Fxr=i(D9),Gm=n(D9,"P",{});var Qme=s(Gm);Txr=r(Qme,`Note:
Loading a model from its configuration file does `),fAe=n(Qme,"STRONG",{});var Dna=s(fAe);Mxr=r(Dna,"not"),Dna.forEach(t),Exr=r(Qme,` load the model weights. It only affects the
model\u2019s configuration. Use `),foe=n(Qme,"A",{href:!0});var Gna=s(foe);Cxr=r(Gna,"from_pretrained()"),Gna.forEach(t),wxr=r(Qme," to load the model weights."),Qme.forEach(t),Axr=i(D9),T(y3.$$.fragment,D9),D9.forEach(t),Lxr=i(ni),Fo=n(ni,"DIV",{class:!0});var Wa=s(Fo);T(SS.$$.fragment,Wa),yxr=i(Wa),gAe=n(Wa,"P",{});var Ona=s(gAe);xxr=r(Ona,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Ona.forEach(t),$xr=i(Wa),An=n(Wa,"P",{});var G9=s(An);kxr=r(G9,"The model class to instantiate is selected based on the "),hAe=n(G9,"CODE",{});var Vna=s(hAe);Sxr=r(Vna,"model_type"),Vna.forEach(t),Rxr=r(G9,` property of the config object (either
passed as an argument or loaded from `),uAe=n(G9,"CODE",{});var Xna=s(uAe);Pxr=r(Xna,"pretrained_model_name_or_path"),Xna.forEach(t),Bxr=r(G9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pAe=n(G9,"CODE",{});var zna=s(pAe);Ixr=r(zna,"pretrained_model_name_or_path"),zna.forEach(t),Nxr=r(G9,":"),G9.forEach(t),qxr=i(Wa),Om=n(Wa,"UL",{});var Wme=s(Om);x3=n(Wme,"LI",{});var yJe=s(x3);_Ae=n(yJe,"STRONG",{});var Qna=s(_Ae);jxr=r(Qna,"speech-encoder-decoder"),Qna.forEach(t),Dxr=r(yJe," \u2014 "),goe=n(yJe,"A",{href:!0});var Wna=s(goe);Gxr=r(Wna,"SpeechEncoderDecoderModel"),Wna.forEach(t),Oxr=r(yJe," (Speech Encoder decoder model)"),yJe.forEach(t),Vxr=i(Wme),$3=n(Wme,"LI",{});var xJe=s($3);bAe=n(xJe,"STRONG",{});var Una=s(bAe);Xxr=r(Una,"speech_to_text"),Una.forEach(t),zxr=r(xJe," \u2014 "),hoe=n(xJe,"A",{href:!0});var Hna=s(hoe);Qxr=r(Hna,"Speech2TextForConditionalGeneration"),Hna.forEach(t),Wxr=r(xJe," (Speech2Text model)"),xJe.forEach(t),Uxr=i(Wme),k3=n(Wme,"LI",{});var $Je=s(k3);vAe=n($Je,"STRONG",{});var Jna=s(vAe);Hxr=r(Jna,"whisper"),Jna.forEach(t),Jxr=r($Je," \u2014 "),uoe=n($Je,"A",{href:!0});var Yna=s(uoe);Yxr=r(Yna,"WhisperForConditionalGeneration"),Yna.forEach(t),Zxr=r($Je," (Whisper model)"),$Je.forEach(t),Wme.forEach(t),Kxr=i(Wa),S3=n(Wa,"P",{});var kJe=s(S3);e$r=r(kJe,"The model is set in evaluation mode by default using "),FAe=n(kJe,"CODE",{});var Zna=s(FAe);o$r=r(Zna,"model.eval()"),Zna.forEach(t),r$r=r(kJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),TAe=n(kJe,"CODE",{});var Kna=s(TAe);t$r=r(Kna,"model.train()"),Kna.forEach(t),kJe.forEach(t),a$r=i(Wa),T(R3.$$.fragment,Wa),Wa.forEach(t),ni.forEach(t),Aao=i(c),Vm=n(c,"H2",{class:!0});var zso=s(Vm);P3=n(zso,"A",{id:!0,class:!0,href:!0});var esa=s(P3);MAe=n(esa,"SPAN",{});var osa=s(MAe);T(RS.$$.fragment,osa),osa.forEach(t),esa.forEach(t),n$r=i(zso),EAe=n(zso,"SPAN",{});var rsa=s(EAe);s$r=r(rsa,"AutoModelForAudioXVector"),rsa.forEach(t),zso.forEach(t),Lao=i(c),tr=n(c,"DIV",{class:!0});var si=s(tr);T(PS.$$.fragment,si),l$r=i(si),Xm=n(si,"P",{});var Ume=s(Xm);i$r=r(Ume,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),poe=n(Ume,"A",{href:!0});var tsa=s(poe);d$r=r(tsa,"from_pretrained()"),tsa.forEach(t),m$r=r(Ume," class method or the "),_oe=n(Ume,"A",{href:!0});var asa=s(_oe);c$r=r(asa,"from_config()"),asa.forEach(t),f$r=r(Ume,` class
method.`),Ume.forEach(t),g$r=i(si),BS=n(si,"P",{});var Qso=s(BS);h$r=r(Qso,"This class cannot be instantiated directly using "),CAe=n(Qso,"CODE",{});var nsa=s(CAe);u$r=r(nsa,"__init__()"),nsa.forEach(t),p$r=r(Qso," (throws an error)."),Qso.forEach(t),_$r=i(si),Xt=n(si,"DIV",{class:!0});var O9=s(Xt);T(IS.$$.fragment,O9),b$r=i(O9),wAe=n(O9,"P",{});var ssa=s(wAe);v$r=r(ssa,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),ssa.forEach(t),F$r=i(O9),zm=n(O9,"P",{});var Hme=s(zm);T$r=r(Hme,`Note:
Loading a model from its configuration file does `),AAe=n(Hme,"STRONG",{});var lsa=s(AAe);M$r=r(lsa,"not"),lsa.forEach(t),E$r=r(Hme,` load the model weights. It only affects the
model\u2019s configuration. Use `),boe=n(Hme,"A",{href:!0});var isa=s(boe);C$r=r(isa,"from_pretrained()"),isa.forEach(t),w$r=r(Hme," to load the model weights."),Hme.forEach(t),A$r=i(O9),T(B3.$$.fragment,O9),O9.forEach(t),L$r=i(si),To=n(si,"DIV",{class:!0});var Ua=s(To);T(NS.$$.fragment,Ua),y$r=i(Ua),LAe=n(Ua,"P",{});var dsa=s(LAe);x$r=r(dsa,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),dsa.forEach(t),$$r=i(Ua),Ln=n(Ua,"P",{});var V9=s(Ln);k$r=r(V9,"The model class to instantiate is selected based on the "),yAe=n(V9,"CODE",{});var msa=s(yAe);S$r=r(msa,"model_type"),msa.forEach(t),R$r=r(V9,` property of the config object (either
passed as an argument or loaded from `),xAe=n(V9,"CODE",{});var csa=s(xAe);P$r=r(csa,"pretrained_model_name_or_path"),csa.forEach(t),B$r=r(V9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$Ae=n(V9,"CODE",{});var fsa=s($Ae);I$r=r(fsa,"pretrained_model_name_or_path"),fsa.forEach(t),N$r=r(V9,":"),V9.forEach(t),q$r=i(Ua),pt=n(Ua,"UL",{});var li=s(pt);I3=n(li,"LI",{});var SJe=s(I3);kAe=n(SJe,"STRONG",{});var gsa=s(kAe);j$r=r(gsa,"data2vec-audio"),gsa.forEach(t),D$r=r(SJe," \u2014 "),voe=n(SJe,"A",{href:!0});var hsa=s(voe);G$r=r(hsa,"Data2VecAudioForXVector"),hsa.forEach(t),O$r=r(SJe," (Data2VecAudio model)"),SJe.forEach(t),V$r=i(li),N3=n(li,"LI",{});var RJe=s(N3);SAe=n(RJe,"STRONG",{});var usa=s(SAe);X$r=r(usa,"unispeech-sat"),usa.forEach(t),z$r=r(RJe," \u2014 "),Foe=n(RJe,"A",{href:!0});var psa=s(Foe);Q$r=r(psa,"UniSpeechSatForXVector"),psa.forEach(t),W$r=r(RJe," (UniSpeechSat model)"),RJe.forEach(t),U$r=i(li),q3=n(li,"LI",{});var PJe=s(q3);RAe=n(PJe,"STRONG",{});var _sa=s(RAe);H$r=r(_sa,"wav2vec2"),_sa.forEach(t),J$r=r(PJe," \u2014 "),Toe=n(PJe,"A",{href:!0});var bsa=s(Toe);Y$r=r(bsa,"Wav2Vec2ForXVector"),bsa.forEach(t),Z$r=r(PJe," (Wav2Vec2 model)"),PJe.forEach(t),K$r=i(li),j3=n(li,"LI",{});var BJe=s(j3);PAe=n(BJe,"STRONG",{});var vsa=s(PAe);ekr=r(vsa,"wav2vec2-conformer"),vsa.forEach(t),okr=r(BJe," \u2014 "),Moe=n(BJe,"A",{href:!0});var Fsa=s(Moe);rkr=r(Fsa,"Wav2Vec2ConformerForXVector"),Fsa.forEach(t),tkr=r(BJe," (Wav2Vec2-Conformer model)"),BJe.forEach(t),akr=i(li),D3=n(li,"LI",{});var IJe=s(D3);BAe=n(IJe,"STRONG",{});var Tsa=s(BAe);nkr=r(Tsa,"wavlm"),Tsa.forEach(t),skr=r(IJe," \u2014 "),Eoe=n(IJe,"A",{href:!0});var Msa=s(Eoe);lkr=r(Msa,"WavLMForXVector"),Msa.forEach(t),ikr=r(IJe," (WavLM model)"),IJe.forEach(t),li.forEach(t),dkr=i(Ua),G3=n(Ua,"P",{});var NJe=s(G3);mkr=r(NJe,"The model is set in evaluation mode by default using "),IAe=n(NJe,"CODE",{});var Esa=s(IAe);ckr=r(Esa,"model.eval()"),Esa.forEach(t),fkr=r(NJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),NAe=n(NJe,"CODE",{});var Csa=s(NAe);gkr=r(Csa,"model.train()"),Csa.forEach(t),NJe.forEach(t),hkr=i(Ua),T(O3.$$.fragment,Ua),Ua.forEach(t),si.forEach(t),yao=i(c),Qm=n(c,"H2",{class:!0});var Wso=s(Qm);V3=n(Wso,"A",{id:!0,class:!0,href:!0});var wsa=s(V3);qAe=n(wsa,"SPAN",{});var Asa=s(qAe);T(qS.$$.fragment,Asa),Asa.forEach(t),wsa.forEach(t),ukr=i(Wso),jAe=n(Wso,"SPAN",{});var Lsa=s(jAe);pkr=r(Lsa,"AutoModelForMaskedImageModeling"),Lsa.forEach(t),Wso.forEach(t),xao=i(c),ar=n(c,"DIV",{class:!0});var ii=s(ar);T(jS.$$.fragment,ii),_kr=i(ii),Wm=n(ii,"P",{});var Jme=s(Wm);bkr=r(Jme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),Coe=n(Jme,"A",{href:!0});var ysa=s(Coe);vkr=r(ysa,"from_pretrained()"),ysa.forEach(t),Fkr=r(Jme," class method or the "),woe=n(Jme,"A",{href:!0});var xsa=s(woe);Tkr=r(xsa,"from_config()"),xsa.forEach(t),Mkr=r(Jme,` class
method.`),Jme.forEach(t),Ekr=i(ii),DS=n(ii,"P",{});var Uso=s(DS);Ckr=r(Uso,"This class cannot be instantiated directly using "),DAe=n(Uso,"CODE",{});var $sa=s(DAe);wkr=r($sa,"__init__()"),$sa.forEach(t),Akr=r(Uso," (throws an error)."),Uso.forEach(t),Lkr=i(ii),zt=n(ii,"DIV",{class:!0});var X9=s(zt);T(GS.$$.fragment,X9),ykr=i(X9),GAe=n(X9,"P",{});var ksa=s(GAe);xkr=r(ksa,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),ksa.forEach(t),$kr=i(X9),Um=n(X9,"P",{});var Yme=s(Um);kkr=r(Yme,`Note:
Loading a model from its configuration file does `),OAe=n(Yme,"STRONG",{});var Ssa=s(OAe);Skr=r(Ssa,"not"),Ssa.forEach(t),Rkr=r(Yme,` load the model weights. It only affects the
model\u2019s configuration. Use `),Aoe=n(Yme,"A",{href:!0});var Rsa=s(Aoe);Pkr=r(Rsa,"from_pretrained()"),Rsa.forEach(t),Bkr=r(Yme," to load the model weights."),Yme.forEach(t),Ikr=i(X9),T(X3.$$.fragment,X9),X9.forEach(t),Nkr=i(ii),Mo=n(ii,"DIV",{class:!0});var Ha=s(Mo);T(OS.$$.fragment,Ha),qkr=i(Ha),VAe=n(Ha,"P",{});var Psa=s(VAe);jkr=r(Psa,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),Psa.forEach(t),Dkr=i(Ha),yn=n(Ha,"P",{});var z9=s(yn);Gkr=r(z9,"The model class to instantiate is selected based on the "),XAe=n(z9,"CODE",{});var Bsa=s(XAe);Okr=r(Bsa,"model_type"),Bsa.forEach(t),Vkr=r(z9,` property of the config object (either
passed as an argument or loaded from `),zAe=n(z9,"CODE",{});var Isa=s(zAe);Xkr=r(Isa,"pretrained_model_name_or_path"),Isa.forEach(t),zkr=r(z9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QAe=n(z9,"CODE",{});var Nsa=s(QAe);Qkr=r(Nsa,"pretrained_model_name_or_path"),Nsa.forEach(t),Wkr=r(z9,":"),z9.forEach(t),Ukr=i(Ha),xn=n(Ha,"UL",{});var Q9=s(xn);z3=n(Q9,"LI",{});var qJe=s(z3);WAe=n(qJe,"STRONG",{});var qsa=s(WAe);Hkr=r(qsa,"deit"),qsa.forEach(t),Jkr=r(qJe," \u2014 "),Loe=n(qJe,"A",{href:!0});var jsa=s(Loe);Ykr=r(jsa,"DeiTForMaskedImageModeling"),jsa.forEach(t),Zkr=r(qJe," (DeiT model)"),qJe.forEach(t),Kkr=i(Q9),Q3=n(Q9,"LI",{});var jJe=s(Q3);UAe=n(jJe,"STRONG",{});var Dsa=s(UAe);eSr=r(Dsa,"swin"),Dsa.forEach(t),oSr=r(jJe," \u2014 "),yoe=n(jJe,"A",{href:!0});var Gsa=s(yoe);rSr=r(Gsa,"SwinForMaskedImageModeling"),Gsa.forEach(t),tSr=r(jJe," (Swin Transformer model)"),jJe.forEach(t),aSr=i(Q9),W3=n(Q9,"LI",{});var DJe=s(W3);HAe=n(DJe,"STRONG",{});var Osa=s(HAe);nSr=r(Osa,"swinv2"),Osa.forEach(t),sSr=r(DJe," \u2014 "),xoe=n(DJe,"A",{href:!0});var Vsa=s(xoe);lSr=r(Vsa,"Swinv2ForMaskedImageModeling"),Vsa.forEach(t),iSr=r(DJe," (Swin Transformer V2 model)"),DJe.forEach(t),dSr=i(Q9),U3=n(Q9,"LI",{});var GJe=s(U3);JAe=n(GJe,"STRONG",{});var Xsa=s(JAe);mSr=r(Xsa,"vit"),Xsa.forEach(t),cSr=r(GJe," \u2014 "),$oe=n(GJe,"A",{href:!0});var zsa=s($oe);fSr=r(zsa,"ViTForMaskedImageModeling"),zsa.forEach(t),gSr=r(GJe," (ViT model)"),GJe.forEach(t),Q9.forEach(t),hSr=i(Ha),H3=n(Ha,"P",{});var OJe=s(H3);uSr=r(OJe,"The model is set in evaluation mode by default using "),YAe=n(OJe,"CODE",{});var Qsa=s(YAe);pSr=r(Qsa,"model.eval()"),Qsa.forEach(t),_Sr=r(OJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ZAe=n(OJe,"CODE",{});var Wsa=s(ZAe);bSr=r(Wsa,"model.train()"),Wsa.forEach(t),OJe.forEach(t),vSr=i(Ha),T(J3.$$.fragment,Ha),Ha.forEach(t),ii.forEach(t),$ao=i(c),Hm=n(c,"H2",{class:!0});var Hso=s(Hm);Y3=n(Hso,"A",{id:!0,class:!0,href:!0});var Usa=s(Y3);KAe=n(Usa,"SPAN",{});var Hsa=s(KAe);T(VS.$$.fragment,Hsa),Hsa.forEach(t),Usa.forEach(t),FSr=i(Hso),e6e=n(Hso,"SPAN",{});var Jsa=s(e6e);TSr=r(Jsa,"AutoModelForObjectDetection"),Jsa.forEach(t),Hso.forEach(t),kao=i(c),nr=n(c,"DIV",{class:!0});var di=s(nr);T(XS.$$.fragment,di),MSr=i(di),Jm=n(di,"P",{});var Zme=s(Jm);ESr=r(Zme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),koe=n(Zme,"A",{href:!0});var Ysa=s(koe);CSr=r(Ysa,"from_pretrained()"),Ysa.forEach(t),wSr=r(Zme," class method or the "),Soe=n(Zme,"A",{href:!0});var Zsa=s(Soe);ASr=r(Zsa,"from_config()"),Zsa.forEach(t),LSr=r(Zme,` class
method.`),Zme.forEach(t),ySr=i(di),zS=n(di,"P",{});var Jso=s(zS);xSr=r(Jso,"This class cannot be instantiated directly using "),o6e=n(Jso,"CODE",{});var Ksa=s(o6e);$Sr=r(Ksa,"__init__()"),Ksa.forEach(t),kSr=r(Jso," (throws an error)."),Jso.forEach(t),SSr=i(di),Qt=n(di,"DIV",{class:!0});var W9=s(Qt);T(QS.$$.fragment,W9),RSr=i(W9),r6e=n(W9,"P",{});var ela=s(r6e);PSr=r(ela,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),ela.forEach(t),BSr=i(W9),Ym=n(W9,"P",{});var Kme=s(Ym);ISr=r(Kme,`Note:
Loading a model from its configuration file does `),t6e=n(Kme,"STRONG",{});var ola=s(t6e);NSr=r(ola,"not"),ola.forEach(t),qSr=r(Kme,` load the model weights. It only affects the
model\u2019s configuration. Use `),Roe=n(Kme,"A",{href:!0});var rla=s(Roe);jSr=r(rla,"from_pretrained()"),rla.forEach(t),DSr=r(Kme," to load the model weights."),Kme.forEach(t),GSr=i(W9),T(Z3.$$.fragment,W9),W9.forEach(t),OSr=i(di),Eo=n(di,"DIV",{class:!0});var Ja=s(Eo);T(WS.$$.fragment,Ja),VSr=i(Ja),a6e=n(Ja,"P",{});var tla=s(a6e);XSr=r(tla,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),tla.forEach(t),zSr=i(Ja),$n=n(Ja,"P",{});var U9=s($n);QSr=r(U9,"The model class to instantiate is selected based on the "),n6e=n(U9,"CODE",{});var ala=s(n6e);WSr=r(ala,"model_type"),ala.forEach(t),USr=r(U9,` property of the config object (either
passed as an argument or loaded from `),s6e=n(U9,"CODE",{});var nla=s(s6e);HSr=r(nla,"pretrained_model_name_or_path"),nla.forEach(t),JSr=r(U9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l6e=n(U9,"CODE",{});var sla=s(l6e);YSr=r(sla,"pretrained_model_name_or_path"),sla.forEach(t),ZSr=r(U9,":"),U9.forEach(t),KSr=i(Ja),_t=n(Ja,"UL",{});var mi=s(_t);K3=n(mi,"LI",{});var VJe=s(K3);i6e=n(VJe,"STRONG",{});var lla=s(i6e);eRr=r(lla,"conditional_detr"),lla.forEach(t),oRr=r(VJe," \u2014 "),Poe=n(VJe,"A",{href:!0});var ila=s(Poe);rRr=r(ila,"ConditionalDetrForObjectDetection"),ila.forEach(t),tRr=r(VJe," (Conditional DETR model)"),VJe.forEach(t),aRr=i(mi),e5=n(mi,"LI",{});var XJe=s(e5);d6e=n(XJe,"STRONG",{});var dla=s(d6e);nRr=r(dla,"deformable_detr"),dla.forEach(t),sRr=r(XJe," \u2014 "),Boe=n(XJe,"A",{href:!0});var mla=s(Boe);lRr=r(mla,"DeformableDetrForObjectDetection"),mla.forEach(t),iRr=r(XJe," (Deformable DETR model)"),XJe.forEach(t),dRr=i(mi),o5=n(mi,"LI",{});var zJe=s(o5);m6e=n(zJe,"STRONG",{});var cla=s(m6e);mRr=r(cla,"detr"),cla.forEach(t),cRr=r(zJe," \u2014 "),Ioe=n(zJe,"A",{href:!0});var fla=s(Ioe);fRr=r(fla,"DetrForObjectDetection"),fla.forEach(t),gRr=r(zJe," (DETR model)"),zJe.forEach(t),hRr=i(mi),r5=n(mi,"LI",{});var QJe=s(r5);c6e=n(QJe,"STRONG",{});var gla=s(c6e);uRr=r(gla,"table-transformer"),gla.forEach(t),pRr=r(QJe," \u2014 "),Noe=n(QJe,"A",{href:!0});var hla=s(Noe);_Rr=r(hla,"TableTransformerForObjectDetection"),hla.forEach(t),bRr=r(QJe," (Table Transformer model)"),QJe.forEach(t),vRr=i(mi),t5=n(mi,"LI",{});var WJe=s(t5);f6e=n(WJe,"STRONG",{});var ula=s(f6e);FRr=r(ula,"yolos"),ula.forEach(t),TRr=r(WJe," \u2014 "),qoe=n(WJe,"A",{href:!0});var pla=s(qoe);MRr=r(pla,"YolosForObjectDetection"),pla.forEach(t),ERr=r(WJe," (YOLOS model)"),WJe.forEach(t),mi.forEach(t),CRr=i(Ja),a5=n(Ja,"P",{});var UJe=s(a5);wRr=r(UJe,"The model is set in evaluation mode by default using "),g6e=n(UJe,"CODE",{});var _la=s(g6e);ARr=r(_la,"model.eval()"),_la.forEach(t),LRr=r(UJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),h6e=n(UJe,"CODE",{});var bla=s(h6e);yRr=r(bla,"model.train()"),bla.forEach(t),UJe.forEach(t),xRr=i(Ja),T(n5.$$.fragment,Ja),Ja.forEach(t),di.forEach(t),Sao=i(c),Zm=n(c,"H2",{class:!0});var Yso=s(Zm);s5=n(Yso,"A",{id:!0,class:!0,href:!0});var vla=s(s5);u6e=n(vla,"SPAN",{});var Fla=s(u6e);T(US.$$.fragment,Fla),Fla.forEach(t),vla.forEach(t),$Rr=i(Yso),p6e=n(Yso,"SPAN",{});var Tla=s(p6e);kRr=r(Tla,"AutoModelForImageSegmentation"),Tla.forEach(t),Yso.forEach(t),Rao=i(c),sr=n(c,"DIV",{class:!0});var ci=s(sr);T(HS.$$.fragment,ci),SRr=i(ci),Km=n(ci,"P",{});var ece=s(Km);RRr=r(ece,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),joe=n(ece,"A",{href:!0});var Mla=s(joe);PRr=r(Mla,"from_pretrained()"),Mla.forEach(t),BRr=r(ece," class method or the "),Doe=n(ece,"A",{href:!0});var Ela=s(Doe);IRr=r(Ela,"from_config()"),Ela.forEach(t),NRr=r(ece,` class
method.`),ece.forEach(t),qRr=i(ci),JS=n(ci,"P",{});var Zso=s(JS);jRr=r(Zso,"This class cannot be instantiated directly using "),_6e=n(Zso,"CODE",{});var Cla=s(_6e);DRr=r(Cla,"__init__()"),Cla.forEach(t),GRr=r(Zso," (throws an error)."),Zso.forEach(t),ORr=i(ci),Wt=n(ci,"DIV",{class:!0});var H9=s(Wt);T(YS.$$.fragment,H9),VRr=i(H9),b6e=n(H9,"P",{});var wla=s(b6e);XRr=r(wla,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),wla.forEach(t),zRr=i(H9),ec=n(H9,"P",{});var oce=s(ec);QRr=r(oce,`Note:
Loading a model from its configuration file does `),v6e=n(oce,"STRONG",{});var Ala=s(v6e);WRr=r(Ala,"not"),Ala.forEach(t),URr=r(oce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Goe=n(oce,"A",{href:!0});var Lla=s(Goe);HRr=r(Lla,"from_pretrained()"),Lla.forEach(t),JRr=r(oce," to load the model weights."),oce.forEach(t),YRr=i(H9),T(l5.$$.fragment,H9),H9.forEach(t),ZRr=i(ci),Co=n(ci,"DIV",{class:!0});var Ya=s(Co);T(ZS.$$.fragment,Ya),KRr=i(Ya),F6e=n(Ya,"P",{});var yla=s(F6e);ePr=r(yla,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),yla.forEach(t),oPr=i(Ya),kn=n(Ya,"P",{});var J9=s(kn);rPr=r(J9,"The model class to instantiate is selected based on the "),T6e=n(J9,"CODE",{});var xla=s(T6e);tPr=r(xla,"model_type"),xla.forEach(t),aPr=r(J9,` property of the config object (either
passed as an argument or loaded from `),M6e=n(J9,"CODE",{});var $la=s(M6e);nPr=r($la,"pretrained_model_name_or_path"),$la.forEach(t),sPr=r(J9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E6e=n(J9,"CODE",{});var kla=s(E6e);lPr=r(kla,"pretrained_model_name_or_path"),kla.forEach(t),iPr=r(J9,":"),J9.forEach(t),dPr=i(Ya),C6e=n(Ya,"UL",{});var Sla=s(C6e);i5=n(Sla,"LI",{});var HJe=s(i5);w6e=n(HJe,"STRONG",{});var Rla=s(w6e);mPr=r(Rla,"detr"),Rla.forEach(t),cPr=r(HJe," \u2014 "),Ooe=n(HJe,"A",{href:!0});var Pla=s(Ooe);fPr=r(Pla,"DetrForSegmentation"),Pla.forEach(t),gPr=r(HJe," (DETR model)"),HJe.forEach(t),Sla.forEach(t),hPr=i(Ya),d5=n(Ya,"P",{});var JJe=s(d5);uPr=r(JJe,"The model is set in evaluation mode by default using "),A6e=n(JJe,"CODE",{});var Bla=s(A6e);pPr=r(Bla,"model.eval()"),Bla.forEach(t),_Pr=r(JJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),L6e=n(JJe,"CODE",{});var Ila=s(L6e);bPr=r(Ila,"model.train()"),Ila.forEach(t),JJe.forEach(t),vPr=i(Ya),T(m5.$$.fragment,Ya),Ya.forEach(t),ci.forEach(t),Pao=i(c),oc=n(c,"H2",{class:!0});var Kso=s(oc);c5=n(Kso,"A",{id:!0,class:!0,href:!0});var Nla=s(c5);y6e=n(Nla,"SPAN",{});var qla=s(y6e);T(KS.$$.fragment,qla),qla.forEach(t),Nla.forEach(t),FPr=i(Kso),x6e=n(Kso,"SPAN",{});var jla=s(x6e);TPr=r(jla,"AutoModelForSemanticSegmentation"),jla.forEach(t),Kso.forEach(t),Bao=i(c),lr=n(c,"DIV",{class:!0});var fi=s(lr);T(eR.$$.fragment,fi),MPr=i(fi),rc=n(fi,"P",{});var rce=s(rc);EPr=r(rce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),Voe=n(rce,"A",{href:!0});var Dla=s(Voe);CPr=r(Dla,"from_pretrained()"),Dla.forEach(t),wPr=r(rce," class method or the "),Xoe=n(rce,"A",{href:!0});var Gla=s(Xoe);APr=r(Gla,"from_config()"),Gla.forEach(t),LPr=r(rce,` class
method.`),rce.forEach(t),yPr=i(fi),oR=n(fi,"P",{});var elo=s(oR);xPr=r(elo,"This class cannot be instantiated directly using "),$6e=n(elo,"CODE",{});var Ola=s($6e);$Pr=r(Ola,"__init__()"),Ola.forEach(t),kPr=r(elo," (throws an error)."),elo.forEach(t),SPr=i(fi),Ut=n(fi,"DIV",{class:!0});var Y9=s(Ut);T(rR.$$.fragment,Y9),RPr=i(Y9),k6e=n(Y9,"P",{});var Vla=s(k6e);PPr=r(Vla,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),Vla.forEach(t),BPr=i(Y9),tc=n(Y9,"P",{});var tce=s(tc);IPr=r(tce,`Note:
Loading a model from its configuration file does `),S6e=n(tce,"STRONG",{});var Xla=s(S6e);NPr=r(Xla,"not"),Xla.forEach(t),qPr=r(tce,` load the model weights. It only affects the
model\u2019s configuration. Use `),zoe=n(tce,"A",{href:!0});var zla=s(zoe);jPr=r(zla,"from_pretrained()"),zla.forEach(t),DPr=r(tce," to load the model weights."),tce.forEach(t),GPr=i(Y9),T(f5.$$.fragment,Y9),Y9.forEach(t),OPr=i(fi),wo=n(fi,"DIV",{class:!0});var Za=s(wo);T(tR.$$.fragment,Za),VPr=i(Za),R6e=n(Za,"P",{});var Qla=s(R6e);XPr=r(Qla,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Qla.forEach(t),zPr=i(Za),Sn=n(Za,"P",{});var Z9=s(Sn);QPr=r(Z9,"The model class to instantiate is selected based on the "),P6e=n(Z9,"CODE",{});var Wla=s(P6e);WPr=r(Wla,"model_type"),Wla.forEach(t),UPr=r(Z9,` property of the config object (either
passed as an argument or loaded from `),B6e=n(Z9,"CODE",{});var Ula=s(B6e);HPr=r(Ula,"pretrained_model_name_or_path"),Ula.forEach(t),JPr=r(Z9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I6e=n(Z9,"CODE",{});var Hla=s(I6e);YPr=r(Hla,"pretrained_model_name_or_path"),Hla.forEach(t),ZPr=r(Z9,":"),Z9.forEach(t),KPr=i(Za),bt=n(Za,"UL",{});var gi=s(bt);g5=n(gi,"LI",{});var YJe=s(g5);N6e=n(YJe,"STRONG",{});var Jla=s(N6e);eBr=r(Jla,"beit"),Jla.forEach(t),oBr=r(YJe," \u2014 "),Qoe=n(YJe,"A",{href:!0});var Yla=s(Qoe);rBr=r(Yla,"BeitForSemanticSegmentation"),Yla.forEach(t),tBr=r(YJe," (BEiT model)"),YJe.forEach(t),aBr=i(gi),h5=n(gi,"LI",{});var ZJe=s(h5);q6e=n(ZJe,"STRONG",{});var Zla=s(q6e);nBr=r(Zla,"data2vec-vision"),Zla.forEach(t),sBr=r(ZJe," \u2014 "),Woe=n(ZJe,"A",{href:!0});var Kla=s(Woe);lBr=r(Kla,"Data2VecVisionForSemanticSegmentation"),Kla.forEach(t),iBr=r(ZJe," (Data2VecVision model)"),ZJe.forEach(t),dBr=i(gi),u5=n(gi,"LI",{});var KJe=s(u5);j6e=n(KJe,"STRONG",{});var eia=s(j6e);mBr=r(eia,"dpt"),eia.forEach(t),cBr=r(KJe," \u2014 "),Uoe=n(KJe,"A",{href:!0});var oia=s(Uoe);fBr=r(oia,"DPTForSemanticSegmentation"),oia.forEach(t),gBr=r(KJe," (DPT model)"),KJe.forEach(t),hBr=i(gi),p5=n(gi,"LI",{});var eYe=s(p5);D6e=n(eYe,"STRONG",{});var ria=s(D6e);uBr=r(ria,"mobilevit"),ria.forEach(t),pBr=r(eYe," \u2014 "),Hoe=n(eYe,"A",{href:!0});var tia=s(Hoe);_Br=r(tia,"MobileViTForSemanticSegmentation"),tia.forEach(t),bBr=r(eYe," (MobileViT model)"),eYe.forEach(t),vBr=i(gi),_5=n(gi,"LI",{});var oYe=s(_5);G6e=n(oYe,"STRONG",{});var aia=s(G6e);FBr=r(aia,"segformer"),aia.forEach(t),TBr=r(oYe," \u2014 "),Joe=n(oYe,"A",{href:!0});var nia=s(Joe);MBr=r(nia,"SegformerForSemanticSegmentation"),nia.forEach(t),EBr=r(oYe," (SegFormer model)"),oYe.forEach(t),gi.forEach(t),CBr=i(Za),b5=n(Za,"P",{});var rYe=s(b5);wBr=r(rYe,"The model is set in evaluation mode by default using "),O6e=n(rYe,"CODE",{});var sia=s(O6e);ABr=r(sia,"model.eval()"),sia.forEach(t),LBr=r(rYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),V6e=n(rYe,"CODE",{});var lia=s(V6e);yBr=r(lia,"model.train()"),lia.forEach(t),rYe.forEach(t),xBr=i(Za),T(v5.$$.fragment,Za),Za.forEach(t),fi.forEach(t),Iao=i(c),ac=n(c,"H2",{class:!0});var olo=s(ac);F5=n(olo,"A",{id:!0,class:!0,href:!0});var iia=s(F5);X6e=n(iia,"SPAN",{});var dia=s(X6e);T(aR.$$.fragment,dia),dia.forEach(t),iia.forEach(t),$Br=i(olo),z6e=n(olo,"SPAN",{});var mia=s(z6e);kBr=r(mia,"AutoModelForInstanceSegmentation"),mia.forEach(t),olo.forEach(t),Nao=i(c),ir=n(c,"DIV",{class:!0});var hi=s(ir);T(nR.$$.fragment,hi),SBr=i(hi),nc=n(hi,"P",{});var ace=s(nc);RBr=r(ace,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),Yoe=n(ace,"A",{href:!0});var cia=s(Yoe);PBr=r(cia,"from_pretrained()"),cia.forEach(t),BBr=r(ace," class method or the "),Zoe=n(ace,"A",{href:!0});var fia=s(Zoe);IBr=r(fia,"from_config()"),fia.forEach(t),NBr=r(ace,` class
method.`),ace.forEach(t),qBr=i(hi),sR=n(hi,"P",{});var rlo=s(sR);jBr=r(rlo,"This class cannot be instantiated directly using "),Q6e=n(rlo,"CODE",{});var gia=s(Q6e);DBr=r(gia,"__init__()"),gia.forEach(t),GBr=r(rlo," (throws an error)."),rlo.forEach(t),OBr=i(hi),Ht=n(hi,"DIV",{class:!0});var K9=s(Ht);T(lR.$$.fragment,K9),VBr=i(K9),W6e=n(K9,"P",{});var hia=s(W6e);XBr=r(hia,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),hia.forEach(t),zBr=i(K9),sc=n(K9,"P",{});var nce=s(sc);QBr=r(nce,`Note:
Loading a model from its configuration file does `),U6e=n(nce,"STRONG",{});var uia=s(U6e);WBr=r(uia,"not"),uia.forEach(t),UBr=r(nce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Koe=n(nce,"A",{href:!0});var pia=s(Koe);HBr=r(pia,"from_pretrained()"),pia.forEach(t),JBr=r(nce," to load the model weights."),nce.forEach(t),YBr=i(K9),T(T5.$$.fragment,K9),K9.forEach(t),ZBr=i(hi),Ao=n(hi,"DIV",{class:!0});var Ka=s(Ao);T(iR.$$.fragment,Ka),KBr=i(Ka),H6e=n(Ka,"P",{});var _ia=s(H6e);eIr=r(_ia,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),_ia.forEach(t),oIr=i(Ka),Rn=n(Ka,"P",{});var ex=s(Rn);rIr=r(ex,"The model class to instantiate is selected based on the "),J6e=n(ex,"CODE",{});var bia=s(J6e);tIr=r(bia,"model_type"),bia.forEach(t),aIr=r(ex,` property of the config object (either
passed as an argument or loaded from `),Y6e=n(ex,"CODE",{});var via=s(Y6e);nIr=r(via,"pretrained_model_name_or_path"),via.forEach(t),sIr=r(ex,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Z6e=n(ex,"CODE",{});var Fia=s(Z6e);lIr=r(Fia,"pretrained_model_name_or_path"),Fia.forEach(t),iIr=r(ex,":"),ex.forEach(t),dIr=i(Ka),K6e=n(Ka,"UL",{});var Tia=s(K6e);M5=n(Tia,"LI",{});var tYe=s(M5);e7e=n(tYe,"STRONG",{});var Mia=s(e7e);mIr=r(Mia,"maskformer"),Mia.forEach(t),cIr=r(tYe," \u2014 "),ere=n(tYe,"A",{href:!0});var Eia=s(ere);fIr=r(Eia,"MaskFormerForInstanceSegmentation"),Eia.forEach(t),gIr=r(tYe," (MaskFormer model)"),tYe.forEach(t),Tia.forEach(t),hIr=i(Ka),E5=n(Ka,"P",{});var aYe=s(E5);uIr=r(aYe,"The model is set in evaluation mode by default using "),o7e=n(aYe,"CODE",{});var Cia=s(o7e);pIr=r(Cia,"model.eval()"),Cia.forEach(t),_Ir=r(aYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),r7e=n(aYe,"CODE",{});var wia=s(r7e);bIr=r(wia,"model.train()"),wia.forEach(t),aYe.forEach(t),vIr=i(Ka),T(C5.$$.fragment,Ka),Ka.forEach(t),hi.forEach(t),qao=i(c),lc=n(c,"H2",{class:!0});var tlo=s(lc);w5=n(tlo,"A",{id:!0,class:!0,href:!0});var Aia=s(w5);t7e=n(Aia,"SPAN",{});var Lia=s(t7e);T(dR.$$.fragment,Lia),Lia.forEach(t),Aia.forEach(t),FIr=i(tlo),a7e=n(tlo,"SPAN",{});var yia=s(a7e);TIr=r(yia,"AutoModelForZeroShotObjectDetection"),yia.forEach(t),tlo.forEach(t),jao=i(c),dr=n(c,"DIV",{class:!0});var ui=s(dr);T(mR.$$.fragment,ui),MIr=i(ui),ic=n(ui,"P",{});var sce=s(ic);EIr=r(sce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a zero-shot object detection head) when created
with the `),ore=n(sce,"A",{href:!0});var xia=s(ore);CIr=r(xia,"from_pretrained()"),xia.forEach(t),wIr=r(sce," class method or the "),rre=n(sce,"A",{href:!0});var $ia=s(rre);AIr=r($ia,"from_config()"),$ia.forEach(t),LIr=r(sce,` class
method.`),sce.forEach(t),yIr=i(ui),cR=n(ui,"P",{});var alo=s(cR);xIr=r(alo,"This class cannot be instantiated directly using "),n7e=n(alo,"CODE",{});var kia=s(n7e);$Ir=r(kia,"__init__()"),kia.forEach(t),kIr=r(alo," (throws an error)."),alo.forEach(t),SIr=i(ui),Jt=n(ui,"DIV",{class:!0});var ox=s(Jt);T(fR.$$.fragment,ox),RIr=i(ox),s7e=n(ox,"P",{});var Sia=s(s7e);PIr=r(Sia,"Instantiates one of the model classes of the library (with a zero-shot object detection head) from a configuration."),Sia.forEach(t),BIr=i(ox),dc=n(ox,"P",{});var lce=s(dc);IIr=r(lce,`Note:
Loading a model from its configuration file does `),l7e=n(lce,"STRONG",{});var Ria=s(l7e);NIr=r(Ria,"not"),Ria.forEach(t),qIr=r(lce,` load the model weights. It only affects the
model\u2019s configuration. Use `),tre=n(lce,"A",{href:!0});var Pia=s(tre);jIr=r(Pia,"from_pretrained()"),Pia.forEach(t),DIr=r(lce," to load the model weights."),lce.forEach(t),GIr=i(ox),T(A5.$$.fragment,ox),ox.forEach(t),OIr=i(ui),Lo=n(ui,"DIV",{class:!0});var en=s(Lo);T(gR.$$.fragment,en),VIr=i(en),i7e=n(en,"P",{});var Bia=s(i7e);XIr=r(Bia,"Instantiate one of the model classes of the library (with a zero-shot object detection head) from a pretrained model."),Bia.forEach(t),zIr=i(en),Pn=n(en,"P",{});var rx=s(Pn);QIr=r(rx,"The model class to instantiate is selected based on the "),d7e=n(rx,"CODE",{});var Iia=s(d7e);WIr=r(Iia,"model_type"),Iia.forEach(t),UIr=r(rx,` property of the config object (either
passed as an argument or loaded from `),m7e=n(rx,"CODE",{});var Nia=s(m7e);HIr=r(Nia,"pretrained_model_name_or_path"),Nia.forEach(t),JIr=r(rx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c7e=n(rx,"CODE",{});var qia=s(c7e);YIr=r(qia,"pretrained_model_name_or_path"),qia.forEach(t),ZIr=r(rx,":"),rx.forEach(t),KIr=i(en),f7e=n(en,"UL",{});var jia=s(f7e);L5=n(jia,"LI",{});var nYe=s(L5);g7e=n(nYe,"STRONG",{});var Dia=s(g7e);eNr=r(Dia,"owlvit"),Dia.forEach(t),oNr=r(nYe," \u2014 "),are=n(nYe,"A",{href:!0});var Gia=s(are);rNr=r(Gia,"OwlViTForObjectDetection"),Gia.forEach(t),tNr=r(nYe," (OWL-ViT model)"),nYe.forEach(t),jia.forEach(t),aNr=i(en),y5=n(en,"P",{});var sYe=s(y5);nNr=r(sYe,"The model is set in evaluation mode by default using "),h7e=n(sYe,"CODE",{});var Oia=s(h7e);sNr=r(Oia,"model.eval()"),Oia.forEach(t),lNr=r(sYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),u7e=n(sYe,"CODE",{});var Via=s(u7e);iNr=r(Via,"model.train()"),Via.forEach(t),sYe.forEach(t),dNr=i(en),T(x5.$$.fragment,en),en.forEach(t),ui.forEach(t),Dao=i(c),mc=n(c,"H2",{class:!0});var nlo=s(mc);$5=n(nlo,"A",{id:!0,class:!0,href:!0});var Xia=s($5);p7e=n(Xia,"SPAN",{});var zia=s(p7e);T(hR.$$.fragment,zia),zia.forEach(t),Xia.forEach(t),mNr=i(nlo),_7e=n(nlo,"SPAN",{});var Qia=s(_7e);cNr=r(Qia,"TFAutoModel"),Qia.forEach(t),nlo.forEach(t),Gao=i(c),mr=n(c,"DIV",{class:!0});var pi=s(mr);T(uR.$$.fragment,pi),fNr=i(pi),cc=n(pi,"P",{});var ice=s(cc);gNr=r(ice,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),nre=n(ice,"A",{href:!0});var Wia=s(nre);hNr=r(Wia,"from_pretrained()"),Wia.forEach(t),uNr=r(ice," class method or the "),sre=n(ice,"A",{href:!0});var Uia=s(sre);pNr=r(Uia,"from_config()"),Uia.forEach(t),_Nr=r(ice,` class
method.`),ice.forEach(t),bNr=i(pi),pR=n(pi,"P",{});var slo=s(pR);vNr=r(slo,"This class cannot be instantiated directly using "),b7e=n(slo,"CODE",{});var Hia=s(b7e);FNr=r(Hia,"__init__()"),Hia.forEach(t),TNr=r(slo," (throws an error)."),slo.forEach(t),MNr=i(pi),Yt=n(pi,"DIV",{class:!0});var tx=s(Yt);T(_R.$$.fragment,tx),ENr=i(tx),v7e=n(tx,"P",{});var Jia=s(v7e);CNr=r(Jia,"Instantiates one of the base model classes of the library from a configuration."),Jia.forEach(t),wNr=i(tx),fc=n(tx,"P",{});var dce=s(fc);ANr=r(dce,`Note:
Loading a model from its configuration file does `),F7e=n(dce,"STRONG",{});var Yia=s(F7e);LNr=r(Yia,"not"),Yia.forEach(t),yNr=r(dce,` load the model weights. It only affects the
model\u2019s configuration. Use `),lre=n(dce,"A",{href:!0});var Zia=s(lre);xNr=r(Zia,"from_pretrained()"),Zia.forEach(t),$Nr=r(dce," to load the model weights."),dce.forEach(t),kNr=i(tx),T(k5.$$.fragment,tx),tx.forEach(t),SNr=i(pi),Dr=n(pi,"DIV",{class:!0});var _i=s(Dr);T(bR.$$.fragment,_i),RNr=i(_i),T7e=n(_i,"P",{});var Kia=s(T7e);PNr=r(Kia,"Instantiate one of the base model classes of the library from a pretrained model."),Kia.forEach(t),BNr=i(_i),Bn=n(_i,"P",{});var ax=s(Bn);INr=r(ax,"The model class to instantiate is selected based on the "),M7e=n(ax,"CODE",{});var eda=s(M7e);NNr=r(eda,"model_type"),eda.forEach(t),qNr=r(ax,` property of the config object (either
passed as an argument or loaded from `),E7e=n(ax,"CODE",{});var oda=s(E7e);jNr=r(oda,"pretrained_model_name_or_path"),oda.forEach(t),DNr=r(ax,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C7e=n(ax,"CODE",{});var rda=s(C7e);GNr=r(rda,"pretrained_model_name_or_path"),rda.forEach(t),ONr=r(ax,":"),ax.forEach(t),VNr=i(_i),P=n(_i,"UL",{});var I=s(P);S5=n(I,"LI",{});var lYe=s(S5);w7e=n(lYe,"STRONG",{});var tda=s(w7e);XNr=r(tda,"albert"),tda.forEach(t),zNr=r(lYe," \u2014 "),ire=n(lYe,"A",{href:!0});var ada=s(ire);QNr=r(ada,"TFAlbertModel"),ada.forEach(t),WNr=r(lYe," (ALBERT model)"),lYe.forEach(t),UNr=i(I),R5=n(I,"LI",{});var iYe=s(R5);A7e=n(iYe,"STRONG",{});var nda=s(A7e);HNr=r(nda,"bart"),nda.forEach(t),JNr=r(iYe," \u2014 "),dre=n(iYe,"A",{href:!0});var sda=s(dre);YNr=r(sda,"TFBartModel"),sda.forEach(t),ZNr=r(iYe," (BART model)"),iYe.forEach(t),KNr=i(I),P5=n(I,"LI",{});var dYe=s(P5);L7e=n(dYe,"STRONG",{});var lda=s(L7e);eqr=r(lda,"bert"),lda.forEach(t),oqr=r(dYe," \u2014 "),mre=n(dYe,"A",{href:!0});var ida=s(mre);rqr=r(ida,"TFBertModel"),ida.forEach(t),tqr=r(dYe," (BERT model)"),dYe.forEach(t),aqr=i(I),B5=n(I,"LI",{});var mYe=s(B5);y7e=n(mYe,"STRONG",{});var dda=s(y7e);nqr=r(dda,"blenderbot"),dda.forEach(t),sqr=r(mYe," \u2014 "),cre=n(mYe,"A",{href:!0});var mda=s(cre);lqr=r(mda,"TFBlenderbotModel"),mda.forEach(t),iqr=r(mYe," (Blenderbot model)"),mYe.forEach(t),dqr=i(I),I5=n(I,"LI",{});var cYe=s(I5);x7e=n(cYe,"STRONG",{});var cda=s(x7e);mqr=r(cda,"blenderbot-small"),cda.forEach(t),cqr=r(cYe," \u2014 "),fre=n(cYe,"A",{href:!0});var fda=s(fre);fqr=r(fda,"TFBlenderbotSmallModel"),fda.forEach(t),gqr=r(cYe," (BlenderbotSmall model)"),cYe.forEach(t),hqr=i(I),N5=n(I,"LI",{});var fYe=s(N5);$7e=n(fYe,"STRONG",{});var gda=s($7e);uqr=r(gda,"camembert"),gda.forEach(t),pqr=r(fYe," \u2014 "),gre=n(fYe,"A",{href:!0});var hda=s(gre);_qr=r(hda,"TFCamembertModel"),hda.forEach(t),bqr=r(fYe," (CamemBERT model)"),fYe.forEach(t),vqr=i(I),q5=n(I,"LI",{});var gYe=s(q5);k7e=n(gYe,"STRONG",{});var uda=s(k7e);Fqr=r(uda,"clip"),uda.forEach(t),Tqr=r(gYe," \u2014 "),hre=n(gYe,"A",{href:!0});var pda=s(hre);Mqr=r(pda,"TFCLIPModel"),pda.forEach(t),Eqr=r(gYe," (CLIP model)"),gYe.forEach(t),Cqr=i(I),j5=n(I,"LI",{});var hYe=s(j5);S7e=n(hYe,"STRONG",{});var _da=s(S7e);wqr=r(_da,"convbert"),_da.forEach(t),Aqr=r(hYe," \u2014 "),ure=n(hYe,"A",{href:!0});var bda=s(ure);Lqr=r(bda,"TFConvBertModel"),bda.forEach(t),yqr=r(hYe," (ConvBERT model)"),hYe.forEach(t),xqr=i(I),D5=n(I,"LI",{});var uYe=s(D5);R7e=n(uYe,"STRONG",{});var vda=s(R7e);$qr=r(vda,"convnext"),vda.forEach(t),kqr=r(uYe," \u2014 "),pre=n(uYe,"A",{href:!0});var Fda=s(pre);Sqr=r(Fda,"TFConvNextModel"),Fda.forEach(t),Rqr=r(uYe," (ConvNeXT model)"),uYe.forEach(t),Pqr=i(I),G5=n(I,"LI",{});var pYe=s(G5);P7e=n(pYe,"STRONG",{});var Tda=s(P7e);Bqr=r(Tda,"ctrl"),Tda.forEach(t),Iqr=r(pYe," \u2014 "),_re=n(pYe,"A",{href:!0});var Mda=s(_re);Nqr=r(Mda,"TFCTRLModel"),Mda.forEach(t),qqr=r(pYe," (CTRL model)"),pYe.forEach(t),jqr=i(I),O5=n(I,"LI",{});var _Ye=s(O5);B7e=n(_Ye,"STRONG",{});var Eda=s(B7e);Dqr=r(Eda,"cvt"),Eda.forEach(t),Gqr=r(_Ye," \u2014 "),bre=n(_Ye,"A",{href:!0});var Cda=s(bre);Oqr=r(Cda,"TFCvtModel"),Cda.forEach(t),Vqr=r(_Ye," (CvT model)"),_Ye.forEach(t),Xqr=i(I),V5=n(I,"LI",{});var bYe=s(V5);I7e=n(bYe,"STRONG",{});var wda=s(I7e);zqr=r(wda,"data2vec-vision"),wda.forEach(t),Qqr=r(bYe," \u2014 "),vre=n(bYe,"A",{href:!0});var Ada=s(vre);Wqr=r(Ada,"TFData2VecVisionModel"),Ada.forEach(t),Uqr=r(bYe," (Data2VecVision model)"),bYe.forEach(t),Hqr=i(I),X5=n(I,"LI",{});var vYe=s(X5);N7e=n(vYe,"STRONG",{});var Lda=s(N7e);Jqr=r(Lda,"deberta"),Lda.forEach(t),Yqr=r(vYe," \u2014 "),Fre=n(vYe,"A",{href:!0});var yda=s(Fre);Zqr=r(yda,"TFDebertaModel"),yda.forEach(t),Kqr=r(vYe," (DeBERTa model)"),vYe.forEach(t),ejr=i(I),z5=n(I,"LI",{});var FYe=s(z5);q7e=n(FYe,"STRONG",{});var xda=s(q7e);ojr=r(xda,"deberta-v2"),xda.forEach(t),rjr=r(FYe," \u2014 "),Tre=n(FYe,"A",{href:!0});var $da=s(Tre);tjr=r($da,"TFDebertaV2Model"),$da.forEach(t),ajr=r(FYe," (DeBERTa-v2 model)"),FYe.forEach(t),njr=i(I),Q5=n(I,"LI",{});var TYe=s(Q5);j7e=n(TYe,"STRONG",{});var kda=s(j7e);sjr=r(kda,"deit"),kda.forEach(t),ljr=r(TYe," \u2014 "),Mre=n(TYe,"A",{href:!0});var Sda=s(Mre);ijr=r(Sda,"TFDeiTModel"),Sda.forEach(t),djr=r(TYe," (DeiT model)"),TYe.forEach(t),mjr=i(I),W5=n(I,"LI",{});var MYe=s(W5);D7e=n(MYe,"STRONG",{});var Rda=s(D7e);cjr=r(Rda,"distilbert"),Rda.forEach(t),fjr=r(MYe," \u2014 "),Ere=n(MYe,"A",{href:!0});var Pda=s(Ere);gjr=r(Pda,"TFDistilBertModel"),Pda.forEach(t),hjr=r(MYe," (DistilBERT model)"),MYe.forEach(t),ujr=i(I),U5=n(I,"LI",{});var EYe=s(U5);G7e=n(EYe,"STRONG",{});var Bda=s(G7e);pjr=r(Bda,"dpr"),Bda.forEach(t),_jr=r(EYe," \u2014 "),Cre=n(EYe,"A",{href:!0});var Ida=s(Cre);bjr=r(Ida,"TFDPRQuestionEncoder"),Ida.forEach(t),vjr=r(EYe," (DPR model)"),EYe.forEach(t),Fjr=i(I),H5=n(I,"LI",{});var CYe=s(H5);O7e=n(CYe,"STRONG",{});var Nda=s(O7e);Tjr=r(Nda,"electra"),Nda.forEach(t),Mjr=r(CYe," \u2014 "),wre=n(CYe,"A",{href:!0});var qda=s(wre);Ejr=r(qda,"TFElectraModel"),qda.forEach(t),Cjr=r(CYe," (ELECTRA model)"),CYe.forEach(t),wjr=i(I),J5=n(I,"LI",{});var wYe=s(J5);V7e=n(wYe,"STRONG",{});var jda=s(V7e);Ajr=r(jda,"esm"),jda.forEach(t),Ljr=r(wYe," \u2014 "),Are=n(wYe,"A",{href:!0});var Dda=s(Are);yjr=r(Dda,"TFEsmModel"),Dda.forEach(t),xjr=r(wYe," (ESM model)"),wYe.forEach(t),$jr=i(I),Y5=n(I,"LI",{});var AYe=s(Y5);X7e=n(AYe,"STRONG",{});var Gda=s(X7e);kjr=r(Gda,"flaubert"),Gda.forEach(t),Sjr=r(AYe," \u2014 "),Lre=n(AYe,"A",{href:!0});var Oda=s(Lre);Rjr=r(Oda,"TFFlaubertModel"),Oda.forEach(t),Pjr=r(AYe," (FlauBERT model)"),AYe.forEach(t),Bjr=i(I),Sl=n(I,"LI",{});var FN=s(Sl);z7e=n(FN,"STRONG",{});var Vda=s(z7e);Ijr=r(Vda,"funnel"),Vda.forEach(t),Njr=r(FN," \u2014 "),yre=n(FN,"A",{href:!0});var Xda=s(yre);qjr=r(Xda,"TFFunnelModel"),Xda.forEach(t),jjr=r(FN," or "),xre=n(FN,"A",{href:!0});var zda=s(xre);Djr=r(zda,"TFFunnelBaseModel"),zda.forEach(t),Gjr=r(FN," (Funnel Transformer model)"),FN.forEach(t),Ojr=i(I),Z5=n(I,"LI",{});var LYe=s(Z5);Q7e=n(LYe,"STRONG",{});var Qda=s(Q7e);Vjr=r(Qda,"gpt2"),Qda.forEach(t),Xjr=r(LYe," \u2014 "),$re=n(LYe,"A",{href:!0});var Wda=s($re);zjr=r(Wda,"TFGPT2Model"),Wda.forEach(t),Qjr=r(LYe," (OpenAI GPT-2 model)"),LYe.forEach(t),Wjr=i(I),K5=n(I,"LI",{});var yYe=s(K5);W7e=n(yYe,"STRONG",{});var Uda=s(W7e);Ujr=r(Uda,"gptj"),Uda.forEach(t),Hjr=r(yYe," \u2014 "),kre=n(yYe,"A",{href:!0});var Hda=s(kre);Jjr=r(Hda,"TFGPTJModel"),Hda.forEach(t),Yjr=r(yYe," (GPT-J model)"),yYe.forEach(t),Zjr=i(I),e0=n(I,"LI",{});var xYe=s(e0);U7e=n(xYe,"STRONG",{});var Jda=s(U7e);Kjr=r(Jda,"groupvit"),Jda.forEach(t),eDr=r(xYe," \u2014 "),Sre=n(xYe,"A",{href:!0});var Yda=s(Sre);oDr=r(Yda,"TFGroupViTModel"),Yda.forEach(t),rDr=r(xYe," (GroupViT model)"),xYe.forEach(t),tDr=i(I),o0=n(I,"LI",{});var $Ye=s(o0);H7e=n($Ye,"STRONG",{});var Zda=s(H7e);aDr=r(Zda,"hubert"),Zda.forEach(t),nDr=r($Ye," \u2014 "),Rre=n($Ye,"A",{href:!0});var Kda=s(Rre);sDr=r(Kda,"TFHubertModel"),Kda.forEach(t),lDr=r($Ye," (Hubert model)"),$Ye.forEach(t),iDr=i(I),r0=n(I,"LI",{});var kYe=s(r0);J7e=n(kYe,"STRONG",{});var ema=s(J7e);dDr=r(ema,"layoutlm"),ema.forEach(t),mDr=r(kYe," \u2014 "),Pre=n(kYe,"A",{href:!0});var oma=s(Pre);cDr=r(oma,"TFLayoutLMModel"),oma.forEach(t),fDr=r(kYe," (LayoutLM model)"),kYe.forEach(t),gDr=i(I),t0=n(I,"LI",{});var SYe=s(t0);Y7e=n(SYe,"STRONG",{});var rma=s(Y7e);hDr=r(rma,"layoutlmv3"),rma.forEach(t),uDr=r(SYe," \u2014 "),Bre=n(SYe,"A",{href:!0});var tma=s(Bre);pDr=r(tma,"TFLayoutLMv3Model"),tma.forEach(t),_Dr=r(SYe," (LayoutLMv3 model)"),SYe.forEach(t),bDr=i(I),a0=n(I,"LI",{});var RYe=s(a0);Z7e=n(RYe,"STRONG",{});var ama=s(Z7e);vDr=r(ama,"led"),ama.forEach(t),FDr=r(RYe," \u2014 "),Ire=n(RYe,"A",{href:!0});var nma=s(Ire);TDr=r(nma,"TFLEDModel"),nma.forEach(t),MDr=r(RYe," (LED model)"),RYe.forEach(t),EDr=i(I),n0=n(I,"LI",{});var PYe=s(n0);K7e=n(PYe,"STRONG",{});var sma=s(K7e);CDr=r(sma,"longformer"),sma.forEach(t),wDr=r(PYe," \u2014 "),Nre=n(PYe,"A",{href:!0});var lma=s(Nre);ADr=r(lma,"TFLongformerModel"),lma.forEach(t),LDr=r(PYe," (Longformer model)"),PYe.forEach(t),yDr=i(I),s0=n(I,"LI",{});var BYe=s(s0);e8e=n(BYe,"STRONG",{});var ima=s(e8e);xDr=r(ima,"lxmert"),ima.forEach(t),$Dr=r(BYe," \u2014 "),qre=n(BYe,"A",{href:!0});var dma=s(qre);kDr=r(dma,"TFLxmertModel"),dma.forEach(t),SDr=r(BYe," (LXMERT model)"),BYe.forEach(t),RDr=i(I),l0=n(I,"LI",{});var IYe=s(l0);o8e=n(IYe,"STRONG",{});var mma=s(o8e);PDr=r(mma,"marian"),mma.forEach(t),BDr=r(IYe," \u2014 "),jre=n(IYe,"A",{href:!0});var cma=s(jre);IDr=r(cma,"TFMarianModel"),cma.forEach(t),NDr=r(IYe," (Marian model)"),IYe.forEach(t),qDr=i(I),i0=n(I,"LI",{});var NYe=s(i0);r8e=n(NYe,"STRONG",{});var fma=s(r8e);jDr=r(fma,"mbart"),fma.forEach(t),DDr=r(NYe," \u2014 "),Dre=n(NYe,"A",{href:!0});var gma=s(Dre);GDr=r(gma,"TFMBartModel"),gma.forEach(t),ODr=r(NYe," (mBART model)"),NYe.forEach(t),VDr=i(I),d0=n(I,"LI",{});var qYe=s(d0);t8e=n(qYe,"STRONG",{});var hma=s(t8e);XDr=r(hma,"mobilebert"),hma.forEach(t),zDr=r(qYe," \u2014 "),Gre=n(qYe,"A",{href:!0});var uma=s(Gre);QDr=r(uma,"TFMobileBertModel"),uma.forEach(t),WDr=r(qYe," (MobileBERT model)"),qYe.forEach(t),UDr=i(I),m0=n(I,"LI",{});var jYe=s(m0);a8e=n(jYe,"STRONG",{});var pma=s(a8e);HDr=r(pma,"mobilevit"),pma.forEach(t),JDr=r(jYe," \u2014 "),Ore=n(jYe,"A",{href:!0});var _ma=s(Ore);YDr=r(_ma,"TFMobileViTModel"),_ma.forEach(t),ZDr=r(jYe," (MobileViT model)"),jYe.forEach(t),KDr=i(I),c0=n(I,"LI",{});var DYe=s(c0);n8e=n(DYe,"STRONG",{});var bma=s(n8e);eGr=r(bma,"mpnet"),bma.forEach(t),oGr=r(DYe," \u2014 "),Vre=n(DYe,"A",{href:!0});var vma=s(Vre);rGr=r(vma,"TFMPNetModel"),vma.forEach(t),tGr=r(DYe," (MPNet model)"),DYe.forEach(t),aGr=i(I),f0=n(I,"LI",{});var GYe=s(f0);s8e=n(GYe,"STRONG",{});var Fma=s(s8e);nGr=r(Fma,"mt5"),Fma.forEach(t),sGr=r(GYe," \u2014 "),Xre=n(GYe,"A",{href:!0});var Tma=s(Xre);lGr=r(Tma,"TFMT5Model"),Tma.forEach(t),iGr=r(GYe," (MT5 model)"),GYe.forEach(t),dGr=i(I),g0=n(I,"LI",{});var OYe=s(g0);l8e=n(OYe,"STRONG",{});var Mma=s(l8e);mGr=r(Mma,"openai-gpt"),Mma.forEach(t),cGr=r(OYe," \u2014 "),zre=n(OYe,"A",{href:!0});var Ema=s(zre);fGr=r(Ema,"TFOpenAIGPTModel"),Ema.forEach(t),gGr=r(OYe," (OpenAI GPT model)"),OYe.forEach(t),hGr=i(I),h0=n(I,"LI",{});var VYe=s(h0);i8e=n(VYe,"STRONG",{});var Cma=s(i8e);uGr=r(Cma,"opt"),Cma.forEach(t),pGr=r(VYe," \u2014 "),Qre=n(VYe,"A",{href:!0});var wma=s(Qre);_Gr=r(wma,"TFOPTModel"),wma.forEach(t),bGr=r(VYe," (OPT model)"),VYe.forEach(t),vGr=i(I),u0=n(I,"LI",{});var XYe=s(u0);d8e=n(XYe,"STRONG",{});var Ama=s(d8e);FGr=r(Ama,"pegasus"),Ama.forEach(t),TGr=r(XYe," \u2014 "),Wre=n(XYe,"A",{href:!0});var Lma=s(Wre);MGr=r(Lma,"TFPegasusModel"),Lma.forEach(t),EGr=r(XYe," (Pegasus model)"),XYe.forEach(t),CGr=i(I),p0=n(I,"LI",{});var zYe=s(p0);m8e=n(zYe,"STRONG",{});var yma=s(m8e);wGr=r(yma,"regnet"),yma.forEach(t),AGr=r(zYe," \u2014 "),Ure=n(zYe,"A",{href:!0});var xma=s(Ure);LGr=r(xma,"TFRegNetModel"),xma.forEach(t),yGr=r(zYe," (RegNet model)"),zYe.forEach(t),xGr=i(I),_0=n(I,"LI",{});var QYe=s(_0);c8e=n(QYe,"STRONG",{});var $ma=s(c8e);$Gr=r($ma,"rembert"),$ma.forEach(t),kGr=r(QYe," \u2014 "),Hre=n(QYe,"A",{href:!0});var kma=s(Hre);SGr=r(kma,"TFRemBertModel"),kma.forEach(t),RGr=r(QYe," (RemBERT model)"),QYe.forEach(t),PGr=i(I),b0=n(I,"LI",{});var WYe=s(b0);f8e=n(WYe,"STRONG",{});var Sma=s(f8e);BGr=r(Sma,"resnet"),Sma.forEach(t),IGr=r(WYe," \u2014 "),Jre=n(WYe,"A",{href:!0});var Rma=s(Jre);NGr=r(Rma,"TFResNetModel"),Rma.forEach(t),qGr=r(WYe," (ResNet model)"),WYe.forEach(t),jGr=i(I),v0=n(I,"LI",{});var UYe=s(v0);g8e=n(UYe,"STRONG",{});var Pma=s(g8e);DGr=r(Pma,"roberta"),Pma.forEach(t),GGr=r(UYe," \u2014 "),Yre=n(UYe,"A",{href:!0});var Bma=s(Yre);OGr=r(Bma,"TFRobertaModel"),Bma.forEach(t),VGr=r(UYe," (RoBERTa model)"),UYe.forEach(t),XGr=i(I),F0=n(I,"LI",{});var HYe=s(F0);h8e=n(HYe,"STRONG",{});var Ima=s(h8e);zGr=r(Ima,"roformer"),Ima.forEach(t),QGr=r(HYe," \u2014 "),Zre=n(HYe,"A",{href:!0});var Nma=s(Zre);WGr=r(Nma,"TFRoFormerModel"),Nma.forEach(t),UGr=r(HYe," (RoFormer model)"),HYe.forEach(t),HGr=i(I),T0=n(I,"LI",{});var JYe=s(T0);u8e=n(JYe,"STRONG",{});var qma=s(u8e);JGr=r(qma,"segformer"),qma.forEach(t),YGr=r(JYe," \u2014 "),Kre=n(JYe,"A",{href:!0});var jma=s(Kre);ZGr=r(jma,"TFSegformerModel"),jma.forEach(t),KGr=r(JYe," (SegFormer model)"),JYe.forEach(t),eOr=i(I),M0=n(I,"LI",{});var YYe=s(M0);p8e=n(YYe,"STRONG",{});var Dma=s(p8e);oOr=r(Dma,"speech_to_text"),Dma.forEach(t),rOr=r(YYe," \u2014 "),ete=n(YYe,"A",{href:!0});var Gma=s(ete);tOr=r(Gma,"TFSpeech2TextModel"),Gma.forEach(t),aOr=r(YYe," (Speech2Text model)"),YYe.forEach(t),nOr=i(I),E0=n(I,"LI",{});var ZYe=s(E0);_8e=n(ZYe,"STRONG",{});var Oma=s(_8e);sOr=r(Oma,"swin"),Oma.forEach(t),lOr=r(ZYe," \u2014 "),ote=n(ZYe,"A",{href:!0});var Vma=s(ote);iOr=r(Vma,"TFSwinModel"),Vma.forEach(t),dOr=r(ZYe," (Swin Transformer model)"),ZYe.forEach(t),mOr=i(I),C0=n(I,"LI",{});var KYe=s(C0);b8e=n(KYe,"STRONG",{});var Xma=s(b8e);cOr=r(Xma,"t5"),Xma.forEach(t),fOr=r(KYe," \u2014 "),rte=n(KYe,"A",{href:!0});var zma=s(rte);gOr=r(zma,"TFT5Model"),zma.forEach(t),hOr=r(KYe," (T5 model)"),KYe.forEach(t),uOr=i(I),w0=n(I,"LI",{});var eZe=s(w0);v8e=n(eZe,"STRONG",{});var Qma=s(v8e);pOr=r(Qma,"tapas"),Qma.forEach(t),_Or=r(eZe," \u2014 "),tte=n(eZe,"A",{href:!0});var Wma=s(tte);bOr=r(Wma,"TFTapasModel"),Wma.forEach(t),vOr=r(eZe," (TAPAS model)"),eZe.forEach(t),FOr=i(I),A0=n(I,"LI",{});var oZe=s(A0);F8e=n(oZe,"STRONG",{});var Uma=s(F8e);TOr=r(Uma,"transfo-xl"),Uma.forEach(t),MOr=r(oZe," \u2014 "),ate=n(oZe,"A",{href:!0});var Hma=s(ate);EOr=r(Hma,"TFTransfoXLModel"),Hma.forEach(t),COr=r(oZe," (Transformer-XL model)"),oZe.forEach(t),wOr=i(I),L0=n(I,"LI",{});var rZe=s(L0);T8e=n(rZe,"STRONG",{});var Jma=s(T8e);AOr=r(Jma,"vit"),Jma.forEach(t),LOr=r(rZe," \u2014 "),nte=n(rZe,"A",{href:!0});var Yma=s(nte);yOr=r(Yma,"TFViTModel"),Yma.forEach(t),xOr=r(rZe," (ViT model)"),rZe.forEach(t),$Or=i(I),y0=n(I,"LI",{});var tZe=s(y0);M8e=n(tZe,"STRONG",{});var Zma=s(M8e);kOr=r(Zma,"vit_mae"),Zma.forEach(t),SOr=r(tZe," \u2014 "),ste=n(tZe,"A",{href:!0});var Kma=s(ste);ROr=r(Kma,"TFViTMAEModel"),Kma.forEach(t),POr=r(tZe," (ViTMAE model)"),tZe.forEach(t),BOr=i(I),x0=n(I,"LI",{});var aZe=s(x0);E8e=n(aZe,"STRONG",{});var eca=s(E8e);IOr=r(eca,"wav2vec2"),eca.forEach(t),NOr=r(aZe," \u2014 "),lte=n(aZe,"A",{href:!0});var oca=s(lte);qOr=r(oca,"TFWav2Vec2Model"),oca.forEach(t),jOr=r(aZe," (Wav2Vec2 model)"),aZe.forEach(t),DOr=i(I),$0=n(I,"LI",{});var nZe=s($0);C8e=n(nZe,"STRONG",{});var rca=s(C8e);GOr=r(rca,"whisper"),rca.forEach(t),OOr=r(nZe," \u2014 "),ite=n(nZe,"A",{href:!0});var tca=s(ite);VOr=r(tca,"TFWhisperModel"),tca.forEach(t),XOr=r(nZe," (Whisper model)"),nZe.forEach(t),zOr=i(I),k0=n(I,"LI",{});var sZe=s(k0);w8e=n(sZe,"STRONG",{});var aca=s(w8e);QOr=r(aca,"xglm"),aca.forEach(t),WOr=r(sZe," \u2014 "),dte=n(sZe,"A",{href:!0});var nca=s(dte);UOr=r(nca,"TFXGLMModel"),nca.forEach(t),HOr=r(sZe," (XGLM model)"),sZe.forEach(t),JOr=i(I),S0=n(I,"LI",{});var lZe=s(S0);A8e=n(lZe,"STRONG",{});var sca=s(A8e);YOr=r(sca,"xlm"),sca.forEach(t),ZOr=r(lZe," \u2014 "),mte=n(lZe,"A",{href:!0});var lca=s(mte);KOr=r(lca,"TFXLMModel"),lca.forEach(t),eVr=r(lZe," (XLM model)"),lZe.forEach(t),oVr=i(I),R0=n(I,"LI",{});var iZe=s(R0);L8e=n(iZe,"STRONG",{});var ica=s(L8e);rVr=r(ica,"xlm-roberta"),ica.forEach(t),tVr=r(iZe," \u2014 "),cte=n(iZe,"A",{href:!0});var dca=s(cte);aVr=r(dca,"TFXLMRobertaModel"),dca.forEach(t),nVr=r(iZe," (XLM-RoBERTa model)"),iZe.forEach(t),sVr=i(I),P0=n(I,"LI",{});var dZe=s(P0);y8e=n(dZe,"STRONG",{});var mca=s(y8e);lVr=r(mca,"xlnet"),mca.forEach(t),iVr=r(dZe," \u2014 "),fte=n(dZe,"A",{href:!0});var cca=s(fte);dVr=r(cca,"TFXLNetModel"),cca.forEach(t),mVr=r(dZe," (XLNet model)"),dZe.forEach(t),I.forEach(t),cVr=i(_i),T(B0.$$.fragment,_i),_i.forEach(t),pi.forEach(t),Oao=i(c),gc=n(c,"H2",{class:!0});var llo=s(gc);I0=n(llo,"A",{id:!0,class:!0,href:!0});var fca=s(I0);x8e=n(fca,"SPAN",{});var gca=s(x8e);T(vR.$$.fragment,gca),gca.forEach(t),fca.forEach(t),fVr=i(llo),$8e=n(llo,"SPAN",{});var hca=s($8e);gVr=r(hca,"TFAutoModelForPreTraining"),hca.forEach(t),llo.forEach(t),Vao=i(c),cr=n(c,"DIV",{class:!0});var bi=s(cr);T(FR.$$.fragment,bi),hVr=i(bi),hc=n(bi,"P",{});var mce=s(hc);uVr=r(mce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),gte=n(mce,"A",{href:!0});var uca=s(gte);pVr=r(uca,"from_pretrained()"),uca.forEach(t),_Vr=r(mce," class method or the "),hte=n(mce,"A",{href:!0});var pca=s(hte);bVr=r(pca,"from_config()"),pca.forEach(t),vVr=r(mce,` class
method.`),mce.forEach(t),FVr=i(bi),TR=n(bi,"P",{});var ilo=s(TR);TVr=r(ilo,"This class cannot be instantiated directly using "),k8e=n(ilo,"CODE",{});var _ca=s(k8e);MVr=r(_ca,"__init__()"),_ca.forEach(t),EVr=r(ilo," (throws an error)."),ilo.forEach(t),CVr=i(bi),Zt=n(bi,"DIV",{class:!0});var nx=s(Zt);T(MR.$$.fragment,nx),wVr=i(nx),S8e=n(nx,"P",{});var bca=s(S8e);AVr=r(bca,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),bca.forEach(t),LVr=i(nx),uc=n(nx,"P",{});var cce=s(uc);yVr=r(cce,`Note:
Loading a model from its configuration file does `),R8e=n(cce,"STRONG",{});var vca=s(R8e);xVr=r(vca,"not"),vca.forEach(t),$Vr=r(cce,` load the model weights. It only affects the
model\u2019s configuration. Use `),ute=n(cce,"A",{href:!0});var Fca=s(ute);kVr=r(Fca,"from_pretrained()"),Fca.forEach(t),SVr=r(cce," to load the model weights."),cce.forEach(t),RVr=i(nx),T(N0.$$.fragment,nx),nx.forEach(t),PVr=i(bi),Gr=n(bi,"DIV",{class:!0});var vi=s(Gr);T(ER.$$.fragment,vi),BVr=i(vi),P8e=n(vi,"P",{});var Tca=s(P8e);IVr=r(Tca,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Tca.forEach(t),NVr=i(vi),In=n(vi,"P",{});var sx=s(In);qVr=r(sx,"The model class to instantiate is selected based on the "),B8e=n(sx,"CODE",{});var Mca=s(B8e);jVr=r(Mca,"model_type"),Mca.forEach(t),DVr=r(sx,` property of the config object (either
passed as an argument or loaded from `),I8e=n(sx,"CODE",{});var Eca=s(I8e);GVr=r(Eca,"pretrained_model_name_or_path"),Eca.forEach(t),OVr=r(sx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N8e=n(sx,"CODE",{});var Cca=s(N8e);VVr=r(Cca,"pretrained_model_name_or_path"),Cca.forEach(t),XVr=r(sx,":"),sx.forEach(t),zVr=i(vi),se=n(vi,"UL",{});var de=s(se);q0=n(de,"LI",{});var mZe=s(q0);q8e=n(mZe,"STRONG",{});var wca=s(q8e);QVr=r(wca,"albert"),wca.forEach(t),WVr=r(mZe," \u2014 "),pte=n(mZe,"A",{href:!0});var Aca=s(pte);UVr=r(Aca,"TFAlbertForPreTraining"),Aca.forEach(t),HVr=r(mZe," (ALBERT model)"),mZe.forEach(t),JVr=i(de),j0=n(de,"LI",{});var cZe=s(j0);j8e=n(cZe,"STRONG",{});var Lca=s(j8e);YVr=r(Lca,"bart"),Lca.forEach(t),ZVr=r(cZe," \u2014 "),_te=n(cZe,"A",{href:!0});var yca=s(_te);KVr=r(yca,"TFBartForConditionalGeneration"),yca.forEach(t),eXr=r(cZe," (BART model)"),cZe.forEach(t),oXr=i(de),D0=n(de,"LI",{});var fZe=s(D0);D8e=n(fZe,"STRONG",{});var xca=s(D8e);rXr=r(xca,"bert"),xca.forEach(t),tXr=r(fZe," \u2014 "),bte=n(fZe,"A",{href:!0});var $ca=s(bte);aXr=r($ca,"TFBertForPreTraining"),$ca.forEach(t),nXr=r(fZe," (BERT model)"),fZe.forEach(t),sXr=i(de),G0=n(de,"LI",{});var gZe=s(G0);G8e=n(gZe,"STRONG",{});var kca=s(G8e);lXr=r(kca,"camembert"),kca.forEach(t),iXr=r(gZe," \u2014 "),vte=n(gZe,"A",{href:!0});var Sca=s(vte);dXr=r(Sca,"TFCamembertForMaskedLM"),Sca.forEach(t),mXr=r(gZe," (CamemBERT model)"),gZe.forEach(t),cXr=i(de),O0=n(de,"LI",{});var hZe=s(O0);O8e=n(hZe,"STRONG",{});var Rca=s(O8e);fXr=r(Rca,"ctrl"),Rca.forEach(t),gXr=r(hZe," \u2014 "),Fte=n(hZe,"A",{href:!0});var Pca=s(Fte);hXr=r(Pca,"TFCTRLLMHeadModel"),Pca.forEach(t),uXr=r(hZe," (CTRL model)"),hZe.forEach(t),pXr=i(de),V0=n(de,"LI",{});var uZe=s(V0);V8e=n(uZe,"STRONG",{});var Bca=s(V8e);_Xr=r(Bca,"distilbert"),Bca.forEach(t),bXr=r(uZe," \u2014 "),Tte=n(uZe,"A",{href:!0});var Ica=s(Tte);vXr=r(Ica,"TFDistilBertForMaskedLM"),Ica.forEach(t),FXr=r(uZe," (DistilBERT model)"),uZe.forEach(t),TXr=i(de),X0=n(de,"LI",{});var pZe=s(X0);X8e=n(pZe,"STRONG",{});var Nca=s(X8e);MXr=r(Nca,"electra"),Nca.forEach(t),EXr=r(pZe," \u2014 "),Mte=n(pZe,"A",{href:!0});var qca=s(Mte);CXr=r(qca,"TFElectraForPreTraining"),qca.forEach(t),wXr=r(pZe," (ELECTRA model)"),pZe.forEach(t),AXr=i(de),z0=n(de,"LI",{});var _Ze=s(z0);z8e=n(_Ze,"STRONG",{});var jca=s(z8e);LXr=r(jca,"flaubert"),jca.forEach(t),yXr=r(_Ze," \u2014 "),Ete=n(_Ze,"A",{href:!0});var Dca=s(Ete);xXr=r(Dca,"TFFlaubertWithLMHeadModel"),Dca.forEach(t),$Xr=r(_Ze," (FlauBERT model)"),_Ze.forEach(t),kXr=i(de),Q0=n(de,"LI",{});var bZe=s(Q0);Q8e=n(bZe,"STRONG",{});var Gca=s(Q8e);SXr=r(Gca,"funnel"),Gca.forEach(t),RXr=r(bZe," \u2014 "),Cte=n(bZe,"A",{href:!0});var Oca=s(Cte);PXr=r(Oca,"TFFunnelForPreTraining"),Oca.forEach(t),BXr=r(bZe," (Funnel Transformer model)"),bZe.forEach(t),IXr=i(de),W0=n(de,"LI",{});var vZe=s(W0);W8e=n(vZe,"STRONG",{});var Vca=s(W8e);NXr=r(Vca,"gpt2"),Vca.forEach(t),qXr=r(vZe," \u2014 "),wte=n(vZe,"A",{href:!0});var Xca=s(wte);jXr=r(Xca,"TFGPT2LMHeadModel"),Xca.forEach(t),DXr=r(vZe," (OpenAI GPT-2 model)"),vZe.forEach(t),GXr=i(de),U0=n(de,"LI",{});var FZe=s(U0);U8e=n(FZe,"STRONG",{});var zca=s(U8e);OXr=r(zca,"layoutlm"),zca.forEach(t),VXr=r(FZe," \u2014 "),Ate=n(FZe,"A",{href:!0});var Qca=s(Ate);XXr=r(Qca,"TFLayoutLMForMaskedLM"),Qca.forEach(t),zXr=r(FZe," (LayoutLM model)"),FZe.forEach(t),QXr=i(de),H0=n(de,"LI",{});var TZe=s(H0);H8e=n(TZe,"STRONG",{});var Wca=s(H8e);WXr=r(Wca,"lxmert"),Wca.forEach(t),UXr=r(TZe," \u2014 "),Lte=n(TZe,"A",{href:!0});var Uca=s(Lte);HXr=r(Uca,"TFLxmertForPreTraining"),Uca.forEach(t),JXr=r(TZe," (LXMERT model)"),TZe.forEach(t),YXr=i(de),J0=n(de,"LI",{});var MZe=s(J0);J8e=n(MZe,"STRONG",{});var Hca=s(J8e);ZXr=r(Hca,"mobilebert"),Hca.forEach(t),KXr=r(MZe," \u2014 "),yte=n(MZe,"A",{href:!0});var Jca=s(yte);ezr=r(Jca,"TFMobileBertForPreTraining"),Jca.forEach(t),ozr=r(MZe," (MobileBERT model)"),MZe.forEach(t),rzr=i(de),Y0=n(de,"LI",{});var EZe=s(Y0);Y8e=n(EZe,"STRONG",{});var Yca=s(Y8e);tzr=r(Yca,"mpnet"),Yca.forEach(t),azr=r(EZe," \u2014 "),xte=n(EZe,"A",{href:!0});var Zca=s(xte);nzr=r(Zca,"TFMPNetForMaskedLM"),Zca.forEach(t),szr=r(EZe," (MPNet model)"),EZe.forEach(t),lzr=i(de),Z0=n(de,"LI",{});var CZe=s(Z0);Z8e=n(CZe,"STRONG",{});var Kca=s(Z8e);izr=r(Kca,"openai-gpt"),Kca.forEach(t),dzr=r(CZe," \u2014 "),$te=n(CZe,"A",{href:!0});var efa=s($te);mzr=r(efa,"TFOpenAIGPTLMHeadModel"),efa.forEach(t),czr=r(CZe," (OpenAI GPT model)"),CZe.forEach(t),fzr=i(de),K0=n(de,"LI",{});var wZe=s(K0);K8e=n(wZe,"STRONG",{});var ofa=s(K8e);gzr=r(ofa,"roberta"),ofa.forEach(t),hzr=r(wZe," \u2014 "),kte=n(wZe,"A",{href:!0});var rfa=s(kte);uzr=r(rfa,"TFRobertaForMaskedLM"),rfa.forEach(t),pzr=r(wZe," (RoBERTa model)"),wZe.forEach(t),_zr=i(de),ew=n(de,"LI",{});var AZe=s(ew);eLe=n(AZe,"STRONG",{});var tfa=s(eLe);bzr=r(tfa,"t5"),tfa.forEach(t),vzr=r(AZe," \u2014 "),Ste=n(AZe,"A",{href:!0});var afa=s(Ste);Fzr=r(afa,"TFT5ForConditionalGeneration"),afa.forEach(t),Tzr=r(AZe," (T5 model)"),AZe.forEach(t),Mzr=i(de),ow=n(de,"LI",{});var LZe=s(ow);oLe=n(LZe,"STRONG",{});var nfa=s(oLe);Ezr=r(nfa,"tapas"),nfa.forEach(t),Czr=r(LZe," \u2014 "),Rte=n(LZe,"A",{href:!0});var sfa=s(Rte);wzr=r(sfa,"TFTapasForMaskedLM"),sfa.forEach(t),Azr=r(LZe," (TAPAS model)"),LZe.forEach(t),Lzr=i(de),rw=n(de,"LI",{});var yZe=s(rw);rLe=n(yZe,"STRONG",{});var lfa=s(rLe);yzr=r(lfa,"transfo-xl"),lfa.forEach(t),xzr=r(yZe," \u2014 "),Pte=n(yZe,"A",{href:!0});var ifa=s(Pte);$zr=r(ifa,"TFTransfoXLLMHeadModel"),ifa.forEach(t),kzr=r(yZe," (Transformer-XL model)"),yZe.forEach(t),Szr=i(de),tw=n(de,"LI",{});var xZe=s(tw);tLe=n(xZe,"STRONG",{});var dfa=s(tLe);Rzr=r(dfa,"vit_mae"),dfa.forEach(t),Pzr=r(xZe," \u2014 "),Bte=n(xZe,"A",{href:!0});var mfa=s(Bte);Bzr=r(mfa,"TFViTMAEForPreTraining"),mfa.forEach(t),Izr=r(xZe," (ViTMAE model)"),xZe.forEach(t),Nzr=i(de),aw=n(de,"LI",{});var $Ze=s(aw);aLe=n($Ze,"STRONG",{});var cfa=s(aLe);qzr=r(cfa,"xlm"),cfa.forEach(t),jzr=r($Ze," \u2014 "),Ite=n($Ze,"A",{href:!0});var ffa=s(Ite);Dzr=r(ffa,"TFXLMWithLMHeadModel"),ffa.forEach(t),Gzr=r($Ze," (XLM model)"),$Ze.forEach(t),Ozr=i(de),nw=n(de,"LI",{});var kZe=s(nw);nLe=n(kZe,"STRONG",{});var gfa=s(nLe);Vzr=r(gfa,"xlm-roberta"),gfa.forEach(t),Xzr=r(kZe," \u2014 "),Nte=n(kZe,"A",{href:!0});var hfa=s(Nte);zzr=r(hfa,"TFXLMRobertaForMaskedLM"),hfa.forEach(t),Qzr=r(kZe," (XLM-RoBERTa model)"),kZe.forEach(t),Wzr=i(de),sw=n(de,"LI",{});var SZe=s(sw);sLe=n(SZe,"STRONG",{});var ufa=s(sLe);Uzr=r(ufa,"xlnet"),ufa.forEach(t),Hzr=r(SZe," \u2014 "),qte=n(SZe,"A",{href:!0});var pfa=s(qte);Jzr=r(pfa,"TFXLNetLMHeadModel"),pfa.forEach(t),Yzr=r(SZe," (XLNet model)"),SZe.forEach(t),de.forEach(t),Zzr=i(vi),T(lw.$$.fragment,vi),vi.forEach(t),bi.forEach(t),Xao=i(c),pc=n(c,"H2",{class:!0});var dlo=s(pc);iw=n(dlo,"A",{id:!0,class:!0,href:!0});var _fa=s(iw);lLe=n(_fa,"SPAN",{});var bfa=s(lLe);T(CR.$$.fragment,bfa),bfa.forEach(t),_fa.forEach(t),Kzr=i(dlo),iLe=n(dlo,"SPAN",{});var vfa=s(iLe);eQr=r(vfa,"TFAutoModelForCausalLM"),vfa.forEach(t),dlo.forEach(t),zao=i(c),fr=n(c,"DIV",{class:!0});var Fi=s(fr);T(wR.$$.fragment,Fi),oQr=i(Fi),_c=n(Fi,"P",{});var fce=s(_c);rQr=r(fce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),jte=n(fce,"A",{href:!0});var Ffa=s(jte);tQr=r(Ffa,"from_pretrained()"),Ffa.forEach(t),aQr=r(fce," class method or the "),Dte=n(fce,"A",{href:!0});var Tfa=s(Dte);nQr=r(Tfa,"from_config()"),Tfa.forEach(t),sQr=r(fce,` class
method.`),fce.forEach(t),lQr=i(Fi),AR=n(Fi,"P",{});var mlo=s(AR);iQr=r(mlo,"This class cannot be instantiated directly using "),dLe=n(mlo,"CODE",{});var Mfa=s(dLe);dQr=r(Mfa,"__init__()"),Mfa.forEach(t),mQr=r(mlo," (throws an error)."),mlo.forEach(t),cQr=i(Fi),Kt=n(Fi,"DIV",{class:!0});var lx=s(Kt);T(LR.$$.fragment,lx),fQr=i(lx),mLe=n(lx,"P",{});var Efa=s(mLe);gQr=r(Efa,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Efa.forEach(t),hQr=i(lx),bc=n(lx,"P",{});var gce=s(bc);uQr=r(gce,`Note:
Loading a model from its configuration file does `),cLe=n(gce,"STRONG",{});var Cfa=s(cLe);pQr=r(Cfa,"not"),Cfa.forEach(t),_Qr=r(gce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Gte=n(gce,"A",{href:!0});var wfa=s(Gte);bQr=r(wfa,"from_pretrained()"),wfa.forEach(t),vQr=r(gce," to load the model weights."),gce.forEach(t),FQr=i(lx),T(dw.$$.fragment,lx),lx.forEach(t),TQr=i(Fi),Or=n(Fi,"DIV",{class:!0});var Ti=s(Or);T(yR.$$.fragment,Ti),MQr=i(Ti),fLe=n(Ti,"P",{});var Afa=s(fLe);EQr=r(Afa,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Afa.forEach(t),CQr=i(Ti),Nn=n(Ti,"P",{});var ix=s(Nn);wQr=r(ix,"The model class to instantiate is selected based on the "),gLe=n(ix,"CODE",{});var Lfa=s(gLe);AQr=r(Lfa,"model_type"),Lfa.forEach(t),LQr=r(ix,` property of the config object (either
passed as an argument or loaded from `),hLe=n(ix,"CODE",{});var yfa=s(hLe);yQr=r(yfa,"pretrained_model_name_or_path"),yfa.forEach(t),xQr=r(ix,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uLe=n(ix,"CODE",{});var xfa=s(uLe);$Qr=r(xfa,"pretrained_model_name_or_path"),xfa.forEach(t),kQr=r(ix,":"),ix.forEach(t),SQr=i(Ti),Me=n(Ti,"UL",{});var Ce=s(Me);mw=n(Ce,"LI",{});var RZe=s(mw);pLe=n(RZe,"STRONG",{});var $fa=s(pLe);RQr=r($fa,"bert"),$fa.forEach(t),PQr=r(RZe," \u2014 "),Ote=n(RZe,"A",{href:!0});var kfa=s(Ote);BQr=r(kfa,"TFBertLMHeadModel"),kfa.forEach(t),IQr=r(RZe," (BERT model)"),RZe.forEach(t),NQr=i(Ce),cw=n(Ce,"LI",{});var PZe=s(cw);_Le=n(PZe,"STRONG",{});var Sfa=s(_Le);qQr=r(Sfa,"camembert"),Sfa.forEach(t),jQr=r(PZe," \u2014 "),Vte=n(PZe,"A",{href:!0});var Rfa=s(Vte);DQr=r(Rfa,"TFCamembertForCausalLM"),Rfa.forEach(t),GQr=r(PZe," (CamemBERT model)"),PZe.forEach(t),OQr=i(Ce),fw=n(Ce,"LI",{});var BZe=s(fw);bLe=n(BZe,"STRONG",{});var Pfa=s(bLe);VQr=r(Pfa,"ctrl"),Pfa.forEach(t),XQr=r(BZe," \u2014 "),Xte=n(BZe,"A",{href:!0});var Bfa=s(Xte);zQr=r(Bfa,"TFCTRLLMHeadModel"),Bfa.forEach(t),QQr=r(BZe," (CTRL model)"),BZe.forEach(t),WQr=i(Ce),gw=n(Ce,"LI",{});var IZe=s(gw);vLe=n(IZe,"STRONG",{});var Ifa=s(vLe);UQr=r(Ifa,"gpt2"),Ifa.forEach(t),HQr=r(IZe," \u2014 "),zte=n(IZe,"A",{href:!0});var Nfa=s(zte);JQr=r(Nfa,"TFGPT2LMHeadModel"),Nfa.forEach(t),YQr=r(IZe," (OpenAI GPT-2 model)"),IZe.forEach(t),ZQr=i(Ce),hw=n(Ce,"LI",{});var NZe=s(hw);FLe=n(NZe,"STRONG",{});var qfa=s(FLe);KQr=r(qfa,"gptj"),qfa.forEach(t),eWr=r(NZe," \u2014 "),Qte=n(NZe,"A",{href:!0});var jfa=s(Qte);oWr=r(jfa,"TFGPTJForCausalLM"),jfa.forEach(t),rWr=r(NZe," (GPT-J model)"),NZe.forEach(t),tWr=i(Ce),uw=n(Ce,"LI",{});var qZe=s(uw);TLe=n(qZe,"STRONG",{});var Dfa=s(TLe);aWr=r(Dfa,"openai-gpt"),Dfa.forEach(t),nWr=r(qZe," \u2014 "),Wte=n(qZe,"A",{href:!0});var Gfa=s(Wte);sWr=r(Gfa,"TFOpenAIGPTLMHeadModel"),Gfa.forEach(t),lWr=r(qZe," (OpenAI GPT model)"),qZe.forEach(t),iWr=i(Ce),pw=n(Ce,"LI",{});var jZe=s(pw);MLe=n(jZe,"STRONG",{});var Ofa=s(MLe);dWr=r(Ofa,"opt"),Ofa.forEach(t),mWr=r(jZe," \u2014 "),Ute=n(jZe,"A",{href:!0});var Vfa=s(Ute);cWr=r(Vfa,"TFOPTForCausalLM"),Vfa.forEach(t),fWr=r(jZe," (OPT model)"),jZe.forEach(t),gWr=i(Ce),_w=n(Ce,"LI",{});var DZe=s(_w);ELe=n(DZe,"STRONG",{});var Xfa=s(ELe);hWr=r(Xfa,"rembert"),Xfa.forEach(t),uWr=r(DZe," \u2014 "),Hte=n(DZe,"A",{href:!0});var zfa=s(Hte);pWr=r(zfa,"TFRemBertForCausalLM"),zfa.forEach(t),_Wr=r(DZe," (RemBERT model)"),DZe.forEach(t),bWr=i(Ce),bw=n(Ce,"LI",{});var GZe=s(bw);CLe=n(GZe,"STRONG",{});var Qfa=s(CLe);vWr=r(Qfa,"roberta"),Qfa.forEach(t),FWr=r(GZe," \u2014 "),Jte=n(GZe,"A",{href:!0});var Wfa=s(Jte);TWr=r(Wfa,"TFRobertaForCausalLM"),Wfa.forEach(t),MWr=r(GZe," (RoBERTa model)"),GZe.forEach(t),EWr=i(Ce),vw=n(Ce,"LI",{});var OZe=s(vw);wLe=n(OZe,"STRONG",{});var Ufa=s(wLe);CWr=r(Ufa,"roformer"),Ufa.forEach(t),wWr=r(OZe," \u2014 "),Yte=n(OZe,"A",{href:!0});var Hfa=s(Yte);AWr=r(Hfa,"TFRoFormerForCausalLM"),Hfa.forEach(t),LWr=r(OZe," (RoFormer model)"),OZe.forEach(t),yWr=i(Ce),Fw=n(Ce,"LI",{});var VZe=s(Fw);ALe=n(VZe,"STRONG",{});var Jfa=s(ALe);xWr=r(Jfa,"transfo-xl"),Jfa.forEach(t),$Wr=r(VZe," \u2014 "),Zte=n(VZe,"A",{href:!0});var Yfa=s(Zte);kWr=r(Yfa,"TFTransfoXLLMHeadModel"),Yfa.forEach(t),SWr=r(VZe," (Transformer-XL model)"),VZe.forEach(t),RWr=i(Ce),Tw=n(Ce,"LI",{});var XZe=s(Tw);LLe=n(XZe,"STRONG",{});var Zfa=s(LLe);PWr=r(Zfa,"xglm"),Zfa.forEach(t),BWr=r(XZe," \u2014 "),Kte=n(XZe,"A",{href:!0});var Kfa=s(Kte);IWr=r(Kfa,"TFXGLMForCausalLM"),Kfa.forEach(t),NWr=r(XZe," (XGLM model)"),XZe.forEach(t),qWr=i(Ce),Mw=n(Ce,"LI",{});var zZe=s(Mw);yLe=n(zZe,"STRONG",{});var ega=s(yLe);jWr=r(ega,"xlm"),ega.forEach(t),DWr=r(zZe," \u2014 "),eae=n(zZe,"A",{href:!0});var oga=s(eae);GWr=r(oga,"TFXLMWithLMHeadModel"),oga.forEach(t),OWr=r(zZe," (XLM model)"),zZe.forEach(t),VWr=i(Ce),Ew=n(Ce,"LI",{});var QZe=s(Ew);xLe=n(QZe,"STRONG",{});var rga=s(xLe);XWr=r(rga,"xlnet"),rga.forEach(t),zWr=r(QZe," \u2014 "),oae=n(QZe,"A",{href:!0});var tga=s(oae);QWr=r(tga,"TFXLNetLMHeadModel"),tga.forEach(t),WWr=r(QZe," (XLNet model)"),QZe.forEach(t),Ce.forEach(t),UWr=i(Ti),T(Cw.$$.fragment,Ti),Ti.forEach(t),Fi.forEach(t),Qao=i(c),vc=n(c,"H2",{class:!0});var clo=s(vc);ww=n(clo,"A",{id:!0,class:!0,href:!0});var aga=s(ww);$Le=n(aga,"SPAN",{});var nga=s($Le);T(xR.$$.fragment,nga),nga.forEach(t),aga.forEach(t),HWr=i(clo),kLe=n(clo,"SPAN",{});var sga=s(kLe);JWr=r(sga,"TFAutoModelForImageClassification"),sga.forEach(t),clo.forEach(t),Wao=i(c),gr=n(c,"DIV",{class:!0});var Mi=s(gr);T($R.$$.fragment,Mi),YWr=i(Mi),Fc=n(Mi,"P",{});var hce=s(Fc);ZWr=r(hce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),rae=n(hce,"A",{href:!0});var lga=s(rae);KWr=r(lga,"from_pretrained()"),lga.forEach(t),eUr=r(hce," class method or the "),tae=n(hce,"A",{href:!0});var iga=s(tae);oUr=r(iga,"from_config()"),iga.forEach(t),rUr=r(hce,` class
method.`),hce.forEach(t),tUr=i(Mi),kR=n(Mi,"P",{});var flo=s(kR);aUr=r(flo,"This class cannot be instantiated directly using "),SLe=n(flo,"CODE",{});var dga=s(SLe);nUr=r(dga,"__init__()"),dga.forEach(t),sUr=r(flo," (throws an error)."),flo.forEach(t),lUr=i(Mi),ea=n(Mi,"DIV",{class:!0});var dx=s(ea);T(SR.$$.fragment,dx),iUr=i(dx),RLe=n(dx,"P",{});var mga=s(RLe);dUr=r(mga,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),mga.forEach(t),mUr=i(dx),Tc=n(dx,"P",{});var uce=s(Tc);cUr=r(uce,`Note:
Loading a model from its configuration file does `),PLe=n(uce,"STRONG",{});var cga=s(PLe);fUr=r(cga,"not"),cga.forEach(t),gUr=r(uce,` load the model weights. It only affects the
model\u2019s configuration. Use `),aae=n(uce,"A",{href:!0});var fga=s(aae);hUr=r(fga,"from_pretrained()"),fga.forEach(t),uUr=r(uce," to load the model weights."),uce.forEach(t),pUr=i(dx),T(Aw.$$.fragment,dx),dx.forEach(t),_Ur=i(Mi),Vr=n(Mi,"DIV",{class:!0});var Ei=s(Vr);T(RR.$$.fragment,Ei),bUr=i(Ei),BLe=n(Ei,"P",{});var gga=s(BLe);vUr=r(gga,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),gga.forEach(t),FUr=i(Ei),qn=n(Ei,"P",{});var mx=s(qn);TUr=r(mx,"The model class to instantiate is selected based on the "),ILe=n(mx,"CODE",{});var hga=s(ILe);MUr=r(hga,"model_type"),hga.forEach(t),EUr=r(mx,` property of the config object (either
passed as an argument or loaded from `),NLe=n(mx,"CODE",{});var uga=s(NLe);CUr=r(uga,"pretrained_model_name_or_path"),uga.forEach(t),wUr=r(mx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qLe=n(mx,"CODE",{});var pga=s(qLe);AUr=r(pga,"pretrained_model_name_or_path"),pga.forEach(t),LUr=r(mx,":"),mx.forEach(t),yUr=i(Ei),ye=n(Ei,"UL",{});var Ne=s(ye);Lw=n(Ne,"LI",{});var WZe=s(Lw);jLe=n(WZe,"STRONG",{});var _ga=s(jLe);xUr=r(_ga,"convnext"),_ga.forEach(t),$Ur=r(WZe," \u2014 "),nae=n(WZe,"A",{href:!0});var bga=s(nae);kUr=r(bga,"TFConvNextForImageClassification"),bga.forEach(t),SUr=r(WZe," (ConvNeXT model)"),WZe.forEach(t),RUr=i(Ne),yw=n(Ne,"LI",{});var UZe=s(yw);DLe=n(UZe,"STRONG",{});var vga=s(DLe);PUr=r(vga,"cvt"),vga.forEach(t),BUr=r(UZe," \u2014 "),sae=n(UZe,"A",{href:!0});var Fga=s(sae);IUr=r(Fga,"TFCvtForImageClassification"),Fga.forEach(t),NUr=r(UZe," (CvT model)"),UZe.forEach(t),qUr=i(Ne),xw=n(Ne,"LI",{});var HZe=s(xw);GLe=n(HZe,"STRONG",{});var Tga=s(GLe);jUr=r(Tga,"data2vec-vision"),Tga.forEach(t),DUr=r(HZe," \u2014 "),lae=n(HZe,"A",{href:!0});var Mga=s(lae);GUr=r(Mga,"TFData2VecVisionForImageClassification"),Mga.forEach(t),OUr=r(HZe," (Data2VecVision model)"),HZe.forEach(t),VUr=i(Ne),Rl=n(Ne,"LI",{});var TN=s(Rl);OLe=n(TN,"STRONG",{});var Ega=s(OLe);XUr=r(Ega,"deit"),Ega.forEach(t),zUr=r(TN," \u2014 "),iae=n(TN,"A",{href:!0});var Cga=s(iae);QUr=r(Cga,"TFDeiTForImageClassification"),Cga.forEach(t),WUr=r(TN," or "),dae=n(TN,"A",{href:!0});var wga=s(dae);UUr=r(wga,"TFDeiTForImageClassificationWithTeacher"),wga.forEach(t),HUr=r(TN," (DeiT model)"),TN.forEach(t),JUr=i(Ne),$w=n(Ne,"LI",{});var JZe=s($w);VLe=n(JZe,"STRONG",{});var Aga=s(VLe);YUr=r(Aga,"mobilevit"),Aga.forEach(t),ZUr=r(JZe," \u2014 "),mae=n(JZe,"A",{href:!0});var Lga=s(mae);KUr=r(Lga,"TFMobileViTForImageClassification"),Lga.forEach(t),eHr=r(JZe," (MobileViT model)"),JZe.forEach(t),oHr=i(Ne),kw=n(Ne,"LI",{});var YZe=s(kw);XLe=n(YZe,"STRONG",{});var yga=s(XLe);rHr=r(yga,"regnet"),yga.forEach(t),tHr=r(YZe," \u2014 "),cae=n(YZe,"A",{href:!0});var xga=s(cae);aHr=r(xga,"TFRegNetForImageClassification"),xga.forEach(t),nHr=r(YZe," (RegNet model)"),YZe.forEach(t),sHr=i(Ne),Sw=n(Ne,"LI",{});var ZZe=s(Sw);zLe=n(ZZe,"STRONG",{});var $ga=s(zLe);lHr=r($ga,"resnet"),$ga.forEach(t),iHr=r(ZZe," \u2014 "),fae=n(ZZe,"A",{href:!0});var kga=s(fae);dHr=r(kga,"TFResNetForImageClassification"),kga.forEach(t),mHr=r(ZZe," (ResNet model)"),ZZe.forEach(t),cHr=i(Ne),Rw=n(Ne,"LI",{});var KZe=s(Rw);QLe=n(KZe,"STRONG",{});var Sga=s(QLe);fHr=r(Sga,"segformer"),Sga.forEach(t),gHr=r(KZe," \u2014 "),gae=n(KZe,"A",{href:!0});var Rga=s(gae);hHr=r(Rga,"TFSegformerForImageClassification"),Rga.forEach(t),uHr=r(KZe," (SegFormer model)"),KZe.forEach(t),pHr=i(Ne),Pw=n(Ne,"LI",{});var eKe=s(Pw);WLe=n(eKe,"STRONG",{});var Pga=s(WLe);_Hr=r(Pga,"swin"),Pga.forEach(t),bHr=r(eKe," \u2014 "),hae=n(eKe,"A",{href:!0});var Bga=s(hae);vHr=r(Bga,"TFSwinForImageClassification"),Bga.forEach(t),FHr=r(eKe," (Swin Transformer model)"),eKe.forEach(t),THr=i(Ne),Bw=n(Ne,"LI",{});var oKe=s(Bw);ULe=n(oKe,"STRONG",{});var Iga=s(ULe);MHr=r(Iga,"vit"),Iga.forEach(t),EHr=r(oKe," \u2014 "),uae=n(oKe,"A",{href:!0});var Nga=s(uae);CHr=r(Nga,"TFViTForImageClassification"),Nga.forEach(t),wHr=r(oKe," (ViT model)"),oKe.forEach(t),Ne.forEach(t),AHr=i(Ei),T(Iw.$$.fragment,Ei),Ei.forEach(t),Mi.forEach(t),Uao=i(c),Mc=n(c,"H2",{class:!0});var glo=s(Mc);Nw=n(glo,"A",{id:!0,class:!0,href:!0});var qga=s(Nw);HLe=n(qga,"SPAN",{});var jga=s(HLe);T(PR.$$.fragment,jga),jga.forEach(t),qga.forEach(t),LHr=i(glo),JLe=n(glo,"SPAN",{});var Dga=s(JLe);yHr=r(Dga,"TFAutoModelForSemanticSegmentation"),Dga.forEach(t),glo.forEach(t),Hao=i(c),hr=n(c,"DIV",{class:!0});var Ci=s(hr);T(BR.$$.fragment,Ci),xHr=i(Ci),Ec=n(Ci,"P",{});var pce=s(Ec);$Hr=r(pce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),pae=n(pce,"A",{href:!0});var Gga=s(pae);kHr=r(Gga,"from_pretrained()"),Gga.forEach(t),SHr=r(pce," class method or the "),_ae=n(pce,"A",{href:!0});var Oga=s(_ae);RHr=r(Oga,"from_config()"),Oga.forEach(t),PHr=r(pce,` class
method.`),pce.forEach(t),BHr=i(Ci),IR=n(Ci,"P",{});var hlo=s(IR);IHr=r(hlo,"This class cannot be instantiated directly using "),YLe=n(hlo,"CODE",{});var Vga=s(YLe);NHr=r(Vga,"__init__()"),Vga.forEach(t),qHr=r(hlo," (throws an error)."),hlo.forEach(t),jHr=i(Ci),oa=n(Ci,"DIV",{class:!0});var cx=s(oa);T(NR.$$.fragment,cx),DHr=i(cx),ZLe=n(cx,"P",{});var Xga=s(ZLe);GHr=r(Xga,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),Xga.forEach(t),OHr=i(cx),Cc=n(cx,"P",{});var _ce=s(Cc);VHr=r(_ce,`Note:
Loading a model from its configuration file does `),KLe=n(_ce,"STRONG",{});var zga=s(KLe);XHr=r(zga,"not"),zga.forEach(t),zHr=r(_ce,` load the model weights. It only affects the
model\u2019s configuration. Use `),bae=n(_ce,"A",{href:!0});var Qga=s(bae);QHr=r(Qga,"from_pretrained()"),Qga.forEach(t),WHr=r(_ce," to load the model weights."),_ce.forEach(t),UHr=i(cx),T(qw.$$.fragment,cx),cx.forEach(t),HHr=i(Ci),Xr=n(Ci,"DIV",{class:!0});var wi=s(Xr);T(qR.$$.fragment,wi),JHr=i(wi),eye=n(wi,"P",{});var Wga=s(eye);YHr=r(Wga,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Wga.forEach(t),ZHr=i(wi),jn=n(wi,"P",{});var fx=s(jn);KHr=r(fx,"The model class to instantiate is selected based on the "),oye=n(fx,"CODE",{});var Uga=s(oye);eJr=r(Uga,"model_type"),Uga.forEach(t),oJr=r(fx,` property of the config object (either
passed as an argument or loaded from `),rye=n(fx,"CODE",{});var Hga=s(rye);rJr=r(Hga,"pretrained_model_name_or_path"),Hga.forEach(t),tJr=r(fx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tye=n(fx,"CODE",{});var Jga=s(tye);aJr=r(Jga,"pretrained_model_name_or_path"),Jga.forEach(t),nJr=r(fx,":"),fx.forEach(t),sJr=i(wi),wc=n(wi,"UL",{});var bce=s(wc);jw=n(bce,"LI",{});var rKe=s(jw);aye=n(rKe,"STRONG",{});var Yga=s(aye);lJr=r(Yga,"data2vec-vision"),Yga.forEach(t),iJr=r(rKe," \u2014 "),vae=n(rKe,"A",{href:!0});var Zga=s(vae);dJr=r(Zga,"TFData2VecVisionForSemanticSegmentation"),Zga.forEach(t),mJr=r(rKe," (Data2VecVision model)"),rKe.forEach(t),cJr=i(bce),Dw=n(bce,"LI",{});var tKe=s(Dw);nye=n(tKe,"STRONG",{});var Kga=s(nye);fJr=r(Kga,"mobilevit"),Kga.forEach(t),gJr=r(tKe," \u2014 "),Fae=n(tKe,"A",{href:!0});var eha=s(Fae);hJr=r(eha,"TFMobileViTForSemanticSegmentation"),eha.forEach(t),uJr=r(tKe," (MobileViT model)"),tKe.forEach(t),pJr=i(bce),Gw=n(bce,"LI",{});var aKe=s(Gw);sye=n(aKe,"STRONG",{});var oha=s(sye);_Jr=r(oha,"segformer"),oha.forEach(t),bJr=r(aKe," \u2014 "),Tae=n(aKe,"A",{href:!0});var rha=s(Tae);vJr=r(rha,"TFSegformerForSemanticSegmentation"),rha.forEach(t),FJr=r(aKe," (SegFormer model)"),aKe.forEach(t),bce.forEach(t),TJr=i(wi),T(Ow.$$.fragment,wi),wi.forEach(t),Ci.forEach(t),Jao=i(c),Ac=n(c,"H2",{class:!0});var ulo=s(Ac);Vw=n(ulo,"A",{id:!0,class:!0,href:!0});var tha=s(Vw);lye=n(tha,"SPAN",{});var aha=s(lye);T(jR.$$.fragment,aha),aha.forEach(t),tha.forEach(t),MJr=i(ulo),iye=n(ulo,"SPAN",{});var nha=s(iye);EJr=r(nha,"TFAutoModelForMaskedLM"),nha.forEach(t),ulo.forEach(t),Yao=i(c),ur=n(c,"DIV",{class:!0});var Ai=s(ur);T(DR.$$.fragment,Ai),CJr=i(Ai),Lc=n(Ai,"P",{});var vce=s(Lc);wJr=r(vce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Mae=n(vce,"A",{href:!0});var sha=s(Mae);AJr=r(sha,"from_pretrained()"),sha.forEach(t),LJr=r(vce," class method or the "),Eae=n(vce,"A",{href:!0});var lha=s(Eae);yJr=r(lha,"from_config()"),lha.forEach(t),xJr=r(vce,` class
method.`),vce.forEach(t),$Jr=i(Ai),GR=n(Ai,"P",{});var plo=s(GR);kJr=r(plo,"This class cannot be instantiated directly using "),dye=n(plo,"CODE",{});var iha=s(dye);SJr=r(iha,"__init__()"),iha.forEach(t),RJr=r(plo," (throws an error)."),plo.forEach(t),PJr=i(Ai),ra=n(Ai,"DIV",{class:!0});var gx=s(ra);T(OR.$$.fragment,gx),BJr=i(gx),mye=n(gx,"P",{});var dha=s(mye);IJr=r(dha,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),dha.forEach(t),NJr=i(gx),yc=n(gx,"P",{});var Fce=s(yc);qJr=r(Fce,`Note:
Loading a model from its configuration file does `),cye=n(Fce,"STRONG",{});var mha=s(cye);jJr=r(mha,"not"),mha.forEach(t),DJr=r(Fce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Cae=n(Fce,"A",{href:!0});var cha=s(Cae);GJr=r(cha,"from_pretrained()"),cha.forEach(t),OJr=r(Fce," to load the model weights."),Fce.forEach(t),VJr=i(gx),T(Xw.$$.fragment,gx),gx.forEach(t),XJr=i(Ai),zr=n(Ai,"DIV",{class:!0});var Li=s(zr);T(VR.$$.fragment,Li),zJr=i(Li),fye=n(Li,"P",{});var fha=s(fye);QJr=r(fha,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),fha.forEach(t),WJr=i(Li),Dn=n(Li,"P",{});var hx=s(Dn);UJr=r(hx,"The model class to instantiate is selected based on the "),gye=n(hx,"CODE",{});var gha=s(gye);HJr=r(gha,"model_type"),gha.forEach(t),JJr=r(hx,` property of the config object (either
passed as an argument or loaded from `),hye=n(hx,"CODE",{});var hha=s(hye);YJr=r(hha,"pretrained_model_name_or_path"),hha.forEach(t),ZJr=r(hx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uye=n(hx,"CODE",{});var uha=s(uye);KJr=r(uha,"pretrained_model_name_or_path"),uha.forEach(t),eYr=r(hx,":"),hx.forEach(t),oYr=i(Li),me=n(Li,"UL",{});var ue=s(me);zw=n(ue,"LI",{});var nKe=s(zw);pye=n(nKe,"STRONG",{});var pha=s(pye);rYr=r(pha,"albert"),pha.forEach(t),tYr=r(nKe," \u2014 "),wae=n(nKe,"A",{href:!0});var _ha=s(wae);aYr=r(_ha,"TFAlbertForMaskedLM"),_ha.forEach(t),nYr=r(nKe," (ALBERT model)"),nKe.forEach(t),sYr=i(ue),Qw=n(ue,"LI",{});var sKe=s(Qw);_ye=n(sKe,"STRONG",{});var bha=s(_ye);lYr=r(bha,"bert"),bha.forEach(t),iYr=r(sKe," \u2014 "),Aae=n(sKe,"A",{href:!0});var vha=s(Aae);dYr=r(vha,"TFBertForMaskedLM"),vha.forEach(t),mYr=r(sKe," (BERT model)"),sKe.forEach(t),cYr=i(ue),Ww=n(ue,"LI",{});var lKe=s(Ww);bye=n(lKe,"STRONG",{});var Fha=s(bye);fYr=r(Fha,"camembert"),Fha.forEach(t),gYr=r(lKe," \u2014 "),Lae=n(lKe,"A",{href:!0});var Tha=s(Lae);hYr=r(Tha,"TFCamembertForMaskedLM"),Tha.forEach(t),uYr=r(lKe," (CamemBERT model)"),lKe.forEach(t),pYr=i(ue),Uw=n(ue,"LI",{});var iKe=s(Uw);vye=n(iKe,"STRONG",{});var Mha=s(vye);_Yr=r(Mha,"convbert"),Mha.forEach(t),bYr=r(iKe," \u2014 "),yae=n(iKe,"A",{href:!0});var Eha=s(yae);vYr=r(Eha,"TFConvBertForMaskedLM"),Eha.forEach(t),FYr=r(iKe," (ConvBERT model)"),iKe.forEach(t),TYr=i(ue),Hw=n(ue,"LI",{});var dKe=s(Hw);Fye=n(dKe,"STRONG",{});var Cha=s(Fye);MYr=r(Cha,"deberta"),Cha.forEach(t),EYr=r(dKe," \u2014 "),xae=n(dKe,"A",{href:!0});var wha=s(xae);CYr=r(wha,"TFDebertaForMaskedLM"),wha.forEach(t),wYr=r(dKe," (DeBERTa model)"),dKe.forEach(t),AYr=i(ue),Jw=n(ue,"LI",{});var mKe=s(Jw);Tye=n(mKe,"STRONG",{});var Aha=s(Tye);LYr=r(Aha,"deberta-v2"),Aha.forEach(t),yYr=r(mKe," \u2014 "),$ae=n(mKe,"A",{href:!0});var Lha=s($ae);xYr=r(Lha,"TFDebertaV2ForMaskedLM"),Lha.forEach(t),$Yr=r(mKe," (DeBERTa-v2 model)"),mKe.forEach(t),kYr=i(ue),Yw=n(ue,"LI",{});var cKe=s(Yw);Mye=n(cKe,"STRONG",{});var yha=s(Mye);SYr=r(yha,"distilbert"),yha.forEach(t),RYr=r(cKe," \u2014 "),kae=n(cKe,"A",{href:!0});var xha=s(kae);PYr=r(xha,"TFDistilBertForMaskedLM"),xha.forEach(t),BYr=r(cKe," (DistilBERT model)"),cKe.forEach(t),IYr=i(ue),Zw=n(ue,"LI",{});var fKe=s(Zw);Eye=n(fKe,"STRONG",{});var $ha=s(Eye);NYr=r($ha,"electra"),$ha.forEach(t),qYr=r(fKe," \u2014 "),Sae=n(fKe,"A",{href:!0});var kha=s(Sae);jYr=r(kha,"TFElectraForMaskedLM"),kha.forEach(t),DYr=r(fKe," (ELECTRA model)"),fKe.forEach(t),GYr=i(ue),Kw=n(ue,"LI",{});var gKe=s(Kw);Cye=n(gKe,"STRONG",{});var Sha=s(Cye);OYr=r(Sha,"esm"),Sha.forEach(t),VYr=r(gKe," \u2014 "),Rae=n(gKe,"A",{href:!0});var Rha=s(Rae);XYr=r(Rha,"TFEsmForMaskedLM"),Rha.forEach(t),zYr=r(gKe," (ESM model)"),gKe.forEach(t),QYr=i(ue),eA=n(ue,"LI",{});var hKe=s(eA);wye=n(hKe,"STRONG",{});var Pha=s(wye);WYr=r(Pha,"flaubert"),Pha.forEach(t),UYr=r(hKe," \u2014 "),Pae=n(hKe,"A",{href:!0});var Bha=s(Pae);HYr=r(Bha,"TFFlaubertWithLMHeadModel"),Bha.forEach(t),JYr=r(hKe," (FlauBERT model)"),hKe.forEach(t),YYr=i(ue),oA=n(ue,"LI",{});var uKe=s(oA);Aye=n(uKe,"STRONG",{});var Iha=s(Aye);ZYr=r(Iha,"funnel"),Iha.forEach(t),KYr=r(uKe," \u2014 "),Bae=n(uKe,"A",{href:!0});var Nha=s(Bae);eZr=r(Nha,"TFFunnelForMaskedLM"),Nha.forEach(t),oZr=r(uKe," (Funnel Transformer model)"),uKe.forEach(t),rZr=i(ue),rA=n(ue,"LI",{});var pKe=s(rA);Lye=n(pKe,"STRONG",{});var qha=s(Lye);tZr=r(qha,"layoutlm"),qha.forEach(t),aZr=r(pKe," \u2014 "),Iae=n(pKe,"A",{href:!0});var jha=s(Iae);nZr=r(jha,"TFLayoutLMForMaskedLM"),jha.forEach(t),sZr=r(pKe," (LayoutLM model)"),pKe.forEach(t),lZr=i(ue),tA=n(ue,"LI",{});var _Ke=s(tA);yye=n(_Ke,"STRONG",{});var Dha=s(yye);iZr=r(Dha,"longformer"),Dha.forEach(t),dZr=r(_Ke," \u2014 "),Nae=n(_Ke,"A",{href:!0});var Gha=s(Nae);mZr=r(Gha,"TFLongformerForMaskedLM"),Gha.forEach(t),cZr=r(_Ke," (Longformer model)"),_Ke.forEach(t),fZr=i(ue),aA=n(ue,"LI",{});var bKe=s(aA);xye=n(bKe,"STRONG",{});var Oha=s(xye);gZr=r(Oha,"mobilebert"),Oha.forEach(t),hZr=r(bKe," \u2014 "),qae=n(bKe,"A",{href:!0});var Vha=s(qae);uZr=r(Vha,"TFMobileBertForMaskedLM"),Vha.forEach(t),pZr=r(bKe," (MobileBERT model)"),bKe.forEach(t),_Zr=i(ue),nA=n(ue,"LI",{});var vKe=s(nA);$ye=n(vKe,"STRONG",{});var Xha=s($ye);bZr=r(Xha,"mpnet"),Xha.forEach(t),vZr=r(vKe," \u2014 "),jae=n(vKe,"A",{href:!0});var zha=s(jae);FZr=r(zha,"TFMPNetForMaskedLM"),zha.forEach(t),TZr=r(vKe," (MPNet model)"),vKe.forEach(t),MZr=i(ue),sA=n(ue,"LI",{});var FKe=s(sA);kye=n(FKe,"STRONG",{});var Qha=s(kye);EZr=r(Qha,"rembert"),Qha.forEach(t),CZr=r(FKe," \u2014 "),Dae=n(FKe,"A",{href:!0});var Wha=s(Dae);wZr=r(Wha,"TFRemBertForMaskedLM"),Wha.forEach(t),AZr=r(FKe," (RemBERT model)"),FKe.forEach(t),LZr=i(ue),lA=n(ue,"LI",{});var TKe=s(lA);Sye=n(TKe,"STRONG",{});var Uha=s(Sye);yZr=r(Uha,"roberta"),Uha.forEach(t),xZr=r(TKe," \u2014 "),Gae=n(TKe,"A",{href:!0});var Hha=s(Gae);$Zr=r(Hha,"TFRobertaForMaskedLM"),Hha.forEach(t),kZr=r(TKe," (RoBERTa model)"),TKe.forEach(t),SZr=i(ue),iA=n(ue,"LI",{});var MKe=s(iA);Rye=n(MKe,"STRONG",{});var Jha=s(Rye);RZr=r(Jha,"roformer"),Jha.forEach(t),PZr=r(MKe," \u2014 "),Oae=n(MKe,"A",{href:!0});var Yha=s(Oae);BZr=r(Yha,"TFRoFormerForMaskedLM"),Yha.forEach(t),IZr=r(MKe," (RoFormer model)"),MKe.forEach(t),NZr=i(ue),dA=n(ue,"LI",{});var EKe=s(dA);Pye=n(EKe,"STRONG",{});var Zha=s(Pye);qZr=r(Zha,"tapas"),Zha.forEach(t),jZr=r(EKe," \u2014 "),Vae=n(EKe,"A",{href:!0});var Kha=s(Vae);DZr=r(Kha,"TFTapasForMaskedLM"),Kha.forEach(t),GZr=r(EKe," (TAPAS model)"),EKe.forEach(t),OZr=i(ue),mA=n(ue,"LI",{});var CKe=s(mA);Bye=n(CKe,"STRONG",{});var eua=s(Bye);VZr=r(eua,"xlm"),eua.forEach(t),XZr=r(CKe," \u2014 "),Xae=n(CKe,"A",{href:!0});var oua=s(Xae);zZr=r(oua,"TFXLMWithLMHeadModel"),oua.forEach(t),QZr=r(CKe," (XLM model)"),CKe.forEach(t),WZr=i(ue),cA=n(ue,"LI",{});var wKe=s(cA);Iye=n(wKe,"STRONG",{});var rua=s(Iye);UZr=r(rua,"xlm-roberta"),rua.forEach(t),HZr=r(wKe," \u2014 "),zae=n(wKe,"A",{href:!0});var tua=s(zae);JZr=r(tua,"TFXLMRobertaForMaskedLM"),tua.forEach(t),YZr=r(wKe," (XLM-RoBERTa model)"),wKe.forEach(t),ue.forEach(t),ZZr=i(Li),T(fA.$$.fragment,Li),Li.forEach(t),Ai.forEach(t),Zao=i(c),xc=n(c,"H2",{class:!0});var _lo=s(xc);gA=n(_lo,"A",{id:!0,class:!0,href:!0});var aua=s(gA);Nye=n(aua,"SPAN",{});var nua=s(Nye);T(XR.$$.fragment,nua),nua.forEach(t),aua.forEach(t),KZr=i(_lo),qye=n(_lo,"SPAN",{});var sua=s(qye);eKr=r(sua,"TFAutoModelForSeq2SeqLM"),sua.forEach(t),_lo.forEach(t),Kao=i(c),pr=n(c,"DIV",{class:!0});var yi=s(pr);T(zR.$$.fragment,yi),oKr=i(yi),$c=n(yi,"P",{});var Tce=s($c);rKr=r(Tce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Qae=n(Tce,"A",{href:!0});var lua=s(Qae);tKr=r(lua,"from_pretrained()"),lua.forEach(t),aKr=r(Tce," class method or the "),Wae=n(Tce,"A",{href:!0});var iua=s(Wae);nKr=r(iua,"from_config()"),iua.forEach(t),sKr=r(Tce,` class
method.`),Tce.forEach(t),lKr=i(yi),QR=n(yi,"P",{});var blo=s(QR);iKr=r(blo,"This class cannot be instantiated directly using "),jye=n(blo,"CODE",{});var dua=s(jye);dKr=r(dua,"__init__()"),dua.forEach(t),mKr=r(blo," (throws an error)."),blo.forEach(t),cKr=i(yi),ta=n(yi,"DIV",{class:!0});var ux=s(ta);T(WR.$$.fragment,ux),fKr=i(ux),Dye=n(ux,"P",{});var mua=s(Dye);gKr=r(mua,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),mua.forEach(t),hKr=i(ux),kc=n(ux,"P",{});var Mce=s(kc);uKr=r(Mce,`Note:
Loading a model from its configuration file does `),Gye=n(Mce,"STRONG",{});var cua=s(Gye);pKr=r(cua,"not"),cua.forEach(t),_Kr=r(Mce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Uae=n(Mce,"A",{href:!0});var fua=s(Uae);bKr=r(fua,"from_pretrained()"),fua.forEach(t),vKr=r(Mce," to load the model weights."),Mce.forEach(t),FKr=i(ux),T(hA.$$.fragment,ux),ux.forEach(t),TKr=i(yi),Qr=n(yi,"DIV",{class:!0});var xi=s(Qr);T(UR.$$.fragment,xi),MKr=i(xi),Oye=n(xi,"P",{});var gua=s(Oye);EKr=r(gua,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),gua.forEach(t),CKr=i(xi),Gn=n(xi,"P",{});var px=s(Gn);wKr=r(px,"The model class to instantiate is selected based on the "),Vye=n(px,"CODE",{});var hua=s(Vye);AKr=r(hua,"model_type"),hua.forEach(t),LKr=r(px,` property of the config object (either
passed as an argument or loaded from `),Xye=n(px,"CODE",{});var uua=s(Xye);yKr=r(uua,"pretrained_model_name_or_path"),uua.forEach(t),xKr=r(px,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zye=n(px,"CODE",{});var pua=s(zye);$Kr=r(pua,"pretrained_model_name_or_path"),pua.forEach(t),kKr=r(px,":"),px.forEach(t),SKr=i(xi),xe=n(xi,"UL",{});var qe=s(xe);uA=n(qe,"LI",{});var AKe=s(uA);Qye=n(AKe,"STRONG",{});var _ua=s(Qye);RKr=r(_ua,"bart"),_ua.forEach(t),PKr=r(AKe," \u2014 "),Hae=n(AKe,"A",{href:!0});var bua=s(Hae);BKr=r(bua,"TFBartForConditionalGeneration"),bua.forEach(t),IKr=r(AKe," (BART model)"),AKe.forEach(t),NKr=i(qe),pA=n(qe,"LI",{});var LKe=s(pA);Wye=n(LKe,"STRONG",{});var vua=s(Wye);qKr=r(vua,"blenderbot"),vua.forEach(t),jKr=r(LKe," \u2014 "),Jae=n(LKe,"A",{href:!0});var Fua=s(Jae);DKr=r(Fua,"TFBlenderbotForConditionalGeneration"),Fua.forEach(t),GKr=r(LKe," (Blenderbot model)"),LKe.forEach(t),OKr=i(qe),_A=n(qe,"LI",{});var yKe=s(_A);Uye=n(yKe,"STRONG",{});var Tua=s(Uye);VKr=r(Tua,"blenderbot-small"),Tua.forEach(t),XKr=r(yKe," \u2014 "),Yae=n(yKe,"A",{href:!0});var Mua=s(Yae);zKr=r(Mua,"TFBlenderbotSmallForConditionalGeneration"),Mua.forEach(t),QKr=r(yKe," (BlenderbotSmall model)"),yKe.forEach(t),WKr=i(qe),bA=n(qe,"LI",{});var xKe=s(bA);Hye=n(xKe,"STRONG",{});var Eua=s(Hye);UKr=r(Eua,"encoder-decoder"),Eua.forEach(t),HKr=r(xKe," \u2014 "),Zae=n(xKe,"A",{href:!0});var Cua=s(Zae);JKr=r(Cua,"TFEncoderDecoderModel"),Cua.forEach(t),YKr=r(xKe," (Encoder decoder model)"),xKe.forEach(t),ZKr=i(qe),vA=n(qe,"LI",{});var $Ke=s(vA);Jye=n($Ke,"STRONG",{});var wua=s(Jye);KKr=r(wua,"led"),wua.forEach(t),eet=r($Ke," \u2014 "),Kae=n($Ke,"A",{href:!0});var Aua=s(Kae);oet=r(Aua,"TFLEDForConditionalGeneration"),Aua.forEach(t),ret=r($Ke," (LED model)"),$Ke.forEach(t),tet=i(qe),FA=n(qe,"LI",{});var kKe=s(FA);Yye=n(kKe,"STRONG",{});var Lua=s(Yye);aet=r(Lua,"marian"),Lua.forEach(t),net=r(kKe," \u2014 "),ene=n(kKe,"A",{href:!0});var yua=s(ene);set=r(yua,"TFMarianMTModel"),yua.forEach(t),iet=r(kKe," (Marian model)"),kKe.forEach(t),det=i(qe),TA=n(qe,"LI",{});var SKe=s(TA);Zye=n(SKe,"STRONG",{});var xua=s(Zye);met=r(xua,"mbart"),xua.forEach(t),cet=r(SKe," \u2014 "),one=n(SKe,"A",{href:!0});var $ua=s(one);fet=r($ua,"TFMBartForConditionalGeneration"),$ua.forEach(t),get=r(SKe," (mBART model)"),SKe.forEach(t),het=i(qe),MA=n(qe,"LI",{});var RKe=s(MA);Kye=n(RKe,"STRONG",{});var kua=s(Kye);uet=r(kua,"mt5"),kua.forEach(t),pet=r(RKe," \u2014 "),rne=n(RKe,"A",{href:!0});var Sua=s(rne);_et=r(Sua,"TFMT5ForConditionalGeneration"),Sua.forEach(t),bet=r(RKe," (MT5 model)"),RKe.forEach(t),vet=i(qe),EA=n(qe,"LI",{});var PKe=s(EA);e9e=n(PKe,"STRONG",{});var Rua=s(e9e);Fet=r(Rua,"pegasus"),Rua.forEach(t),Tet=r(PKe," \u2014 "),tne=n(PKe,"A",{href:!0});var Pua=s(tne);Met=r(Pua,"TFPegasusForConditionalGeneration"),Pua.forEach(t),Eet=r(PKe," (Pegasus model)"),PKe.forEach(t),Cet=i(qe),CA=n(qe,"LI",{});var BKe=s(CA);o9e=n(BKe,"STRONG",{});var Bua=s(o9e);wet=r(Bua,"t5"),Bua.forEach(t),Aet=r(BKe," \u2014 "),ane=n(BKe,"A",{href:!0});var Iua=s(ane);Let=r(Iua,"TFT5ForConditionalGeneration"),Iua.forEach(t),yet=r(BKe," (T5 model)"),BKe.forEach(t),qe.forEach(t),xet=i(xi),T(wA.$$.fragment,xi),xi.forEach(t),yi.forEach(t),eno=i(c),Sc=n(c,"H2",{class:!0});var vlo=s(Sc);AA=n(vlo,"A",{id:!0,class:!0,href:!0});var Nua=s(AA);r9e=n(Nua,"SPAN",{});var qua=s(r9e);T(HR.$$.fragment,qua),qua.forEach(t),Nua.forEach(t),$et=i(vlo),t9e=n(vlo,"SPAN",{});var jua=s(t9e);ket=r(jua,"TFAutoModelForSequenceClassification"),jua.forEach(t),vlo.forEach(t),ono=i(c),_r=n(c,"DIV",{class:!0});var $i=s(_r);T(JR.$$.fragment,$i),Set=i($i),Rc=n($i,"P",{});var Ece=s(Rc);Ret=r(Ece,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),nne=n(Ece,"A",{href:!0});var Dua=s(nne);Pet=r(Dua,"from_pretrained()"),Dua.forEach(t),Bet=r(Ece," class method or the "),sne=n(Ece,"A",{href:!0});var Gua=s(sne);Iet=r(Gua,"from_config()"),Gua.forEach(t),Net=r(Ece,` class
method.`),Ece.forEach(t),qet=i($i),YR=n($i,"P",{});var Flo=s(YR);jet=r(Flo,"This class cannot be instantiated directly using "),a9e=n(Flo,"CODE",{});var Oua=s(a9e);Det=r(Oua,"__init__()"),Oua.forEach(t),Get=r(Flo," (throws an error)."),Flo.forEach(t),Oet=i($i),aa=n($i,"DIV",{class:!0});var _x=s(aa);T(ZR.$$.fragment,_x),Vet=i(_x),n9e=n(_x,"P",{});var Vua=s(n9e);Xet=r(Vua,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Vua.forEach(t),zet=i(_x),Pc=n(_x,"P",{});var Cce=s(Pc);Qet=r(Cce,`Note:
Loading a model from its configuration file does `),s9e=n(Cce,"STRONG",{});var Xua=s(s9e);Wet=r(Xua,"not"),Xua.forEach(t),Uet=r(Cce,` load the model weights. It only affects the
model\u2019s configuration. Use `),lne=n(Cce,"A",{href:!0});var zua=s(lne);Het=r(zua,"from_pretrained()"),zua.forEach(t),Jet=r(Cce," to load the model weights."),Cce.forEach(t),Yet=i(_x),T(LA.$$.fragment,_x),_x.forEach(t),Zet=i($i),Wr=n($i,"DIV",{class:!0});var ki=s(Wr);T(KR.$$.fragment,ki),Ket=i(ki),l9e=n(ki,"P",{});var Qua=s(l9e);eot=r(Qua,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Qua.forEach(t),oot=i(ki),On=n(ki,"P",{});var bx=s(On);rot=r(bx,"The model class to instantiate is selected based on the "),i9e=n(bx,"CODE",{});var Wua=s(i9e);tot=r(Wua,"model_type"),Wua.forEach(t),aot=r(bx,` property of the config object (either
passed as an argument or loaded from `),d9e=n(bx,"CODE",{});var Uua=s(d9e);not=r(Uua,"pretrained_model_name_or_path"),Uua.forEach(t),sot=r(bx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m9e=n(bx,"CODE",{});var Hua=s(m9e);lot=r(Hua,"pretrained_model_name_or_path"),Hua.forEach(t),iot=r(bx,":"),bx.forEach(t),dot=i(ki),re=n(ki,"UL",{});var ae=s(re);yA=n(ae,"LI",{});var IKe=s(yA);c9e=n(IKe,"STRONG",{});var Jua=s(c9e);mot=r(Jua,"albert"),Jua.forEach(t),cot=r(IKe," \u2014 "),ine=n(IKe,"A",{href:!0});var Yua=s(ine);fot=r(Yua,"TFAlbertForSequenceClassification"),Yua.forEach(t),got=r(IKe," (ALBERT model)"),IKe.forEach(t),hot=i(ae),xA=n(ae,"LI",{});var NKe=s(xA);f9e=n(NKe,"STRONG",{});var Zua=s(f9e);uot=r(Zua,"bert"),Zua.forEach(t),pot=r(NKe," \u2014 "),dne=n(NKe,"A",{href:!0});var Kua=s(dne);_ot=r(Kua,"TFBertForSequenceClassification"),Kua.forEach(t),bot=r(NKe," (BERT model)"),NKe.forEach(t),vot=i(ae),$A=n(ae,"LI",{});var qKe=s($A);g9e=n(qKe,"STRONG",{});var epa=s(g9e);Fot=r(epa,"camembert"),epa.forEach(t),Tot=r(qKe," \u2014 "),mne=n(qKe,"A",{href:!0});var opa=s(mne);Mot=r(opa,"TFCamembertForSequenceClassification"),opa.forEach(t),Eot=r(qKe," (CamemBERT model)"),qKe.forEach(t),Cot=i(ae),kA=n(ae,"LI",{});var jKe=s(kA);h9e=n(jKe,"STRONG",{});var rpa=s(h9e);wot=r(rpa,"convbert"),rpa.forEach(t),Aot=r(jKe," \u2014 "),cne=n(jKe,"A",{href:!0});var tpa=s(cne);Lot=r(tpa,"TFConvBertForSequenceClassification"),tpa.forEach(t),yot=r(jKe," (ConvBERT model)"),jKe.forEach(t),xot=i(ae),SA=n(ae,"LI",{});var DKe=s(SA);u9e=n(DKe,"STRONG",{});var apa=s(u9e);$ot=r(apa,"ctrl"),apa.forEach(t),kot=r(DKe," \u2014 "),fne=n(DKe,"A",{href:!0});var npa=s(fne);Sot=r(npa,"TFCTRLForSequenceClassification"),npa.forEach(t),Rot=r(DKe," (CTRL model)"),DKe.forEach(t),Pot=i(ae),RA=n(ae,"LI",{});var GKe=s(RA);p9e=n(GKe,"STRONG",{});var spa=s(p9e);Bot=r(spa,"deberta"),spa.forEach(t),Iot=r(GKe," \u2014 "),gne=n(GKe,"A",{href:!0});var lpa=s(gne);Not=r(lpa,"TFDebertaForSequenceClassification"),lpa.forEach(t),qot=r(GKe," (DeBERTa model)"),GKe.forEach(t),jot=i(ae),PA=n(ae,"LI",{});var OKe=s(PA);_9e=n(OKe,"STRONG",{});var ipa=s(_9e);Dot=r(ipa,"deberta-v2"),ipa.forEach(t),Got=r(OKe," \u2014 "),hne=n(OKe,"A",{href:!0});var dpa=s(hne);Oot=r(dpa,"TFDebertaV2ForSequenceClassification"),dpa.forEach(t),Vot=r(OKe," (DeBERTa-v2 model)"),OKe.forEach(t),Xot=i(ae),BA=n(ae,"LI",{});var VKe=s(BA);b9e=n(VKe,"STRONG",{});var mpa=s(b9e);zot=r(mpa,"distilbert"),mpa.forEach(t),Qot=r(VKe," \u2014 "),une=n(VKe,"A",{href:!0});var cpa=s(une);Wot=r(cpa,"TFDistilBertForSequenceClassification"),cpa.forEach(t),Uot=r(VKe," (DistilBERT model)"),VKe.forEach(t),Hot=i(ae),IA=n(ae,"LI",{});var XKe=s(IA);v9e=n(XKe,"STRONG",{});var fpa=s(v9e);Jot=r(fpa,"electra"),fpa.forEach(t),Yot=r(XKe," \u2014 "),pne=n(XKe,"A",{href:!0});var gpa=s(pne);Zot=r(gpa,"TFElectraForSequenceClassification"),gpa.forEach(t),Kot=r(XKe," (ELECTRA model)"),XKe.forEach(t),ert=i(ae),NA=n(ae,"LI",{});var zKe=s(NA);F9e=n(zKe,"STRONG",{});var hpa=s(F9e);ort=r(hpa,"esm"),hpa.forEach(t),rrt=r(zKe," \u2014 "),_ne=n(zKe,"A",{href:!0});var upa=s(_ne);trt=r(upa,"TFEsmForSequenceClassification"),upa.forEach(t),art=r(zKe," (ESM model)"),zKe.forEach(t),nrt=i(ae),qA=n(ae,"LI",{});var QKe=s(qA);T9e=n(QKe,"STRONG",{});var ppa=s(T9e);srt=r(ppa,"flaubert"),ppa.forEach(t),lrt=r(QKe," \u2014 "),bne=n(QKe,"A",{href:!0});var _pa=s(bne);irt=r(_pa,"TFFlaubertForSequenceClassification"),_pa.forEach(t),drt=r(QKe," (FlauBERT model)"),QKe.forEach(t),mrt=i(ae),jA=n(ae,"LI",{});var WKe=s(jA);M9e=n(WKe,"STRONG",{});var bpa=s(M9e);crt=r(bpa,"funnel"),bpa.forEach(t),frt=r(WKe," \u2014 "),vne=n(WKe,"A",{href:!0});var vpa=s(vne);grt=r(vpa,"TFFunnelForSequenceClassification"),vpa.forEach(t),hrt=r(WKe," (Funnel Transformer model)"),WKe.forEach(t),urt=i(ae),DA=n(ae,"LI",{});var UKe=s(DA);E9e=n(UKe,"STRONG",{});var Fpa=s(E9e);prt=r(Fpa,"gpt2"),Fpa.forEach(t),_rt=r(UKe," \u2014 "),Fne=n(UKe,"A",{href:!0});var Tpa=s(Fne);brt=r(Tpa,"TFGPT2ForSequenceClassification"),Tpa.forEach(t),vrt=r(UKe," (OpenAI GPT-2 model)"),UKe.forEach(t),Frt=i(ae),GA=n(ae,"LI",{});var HKe=s(GA);C9e=n(HKe,"STRONG",{});var Mpa=s(C9e);Trt=r(Mpa,"gptj"),Mpa.forEach(t),Mrt=r(HKe," \u2014 "),Tne=n(HKe,"A",{href:!0});var Epa=s(Tne);Ert=r(Epa,"TFGPTJForSequenceClassification"),Epa.forEach(t),Crt=r(HKe," (GPT-J model)"),HKe.forEach(t),wrt=i(ae),OA=n(ae,"LI",{});var JKe=s(OA);w9e=n(JKe,"STRONG",{});var Cpa=s(w9e);Art=r(Cpa,"layoutlm"),Cpa.forEach(t),Lrt=r(JKe," \u2014 "),Mne=n(JKe,"A",{href:!0});var wpa=s(Mne);yrt=r(wpa,"TFLayoutLMForSequenceClassification"),wpa.forEach(t),xrt=r(JKe," (LayoutLM model)"),JKe.forEach(t),$rt=i(ae),VA=n(ae,"LI",{});var YKe=s(VA);A9e=n(YKe,"STRONG",{});var Apa=s(A9e);krt=r(Apa,"layoutlmv3"),Apa.forEach(t),Srt=r(YKe," \u2014 "),Ene=n(YKe,"A",{href:!0});var Lpa=s(Ene);Rrt=r(Lpa,"TFLayoutLMv3ForSequenceClassification"),Lpa.forEach(t),Prt=r(YKe," (LayoutLMv3 model)"),YKe.forEach(t),Brt=i(ae),XA=n(ae,"LI",{});var ZKe=s(XA);L9e=n(ZKe,"STRONG",{});var ypa=s(L9e);Irt=r(ypa,"longformer"),ypa.forEach(t),Nrt=r(ZKe," \u2014 "),Cne=n(ZKe,"A",{href:!0});var xpa=s(Cne);qrt=r(xpa,"TFLongformerForSequenceClassification"),xpa.forEach(t),jrt=r(ZKe," (Longformer model)"),ZKe.forEach(t),Drt=i(ae),zA=n(ae,"LI",{});var KKe=s(zA);y9e=n(KKe,"STRONG",{});var $pa=s(y9e);Grt=r($pa,"mobilebert"),$pa.forEach(t),Ort=r(KKe," \u2014 "),wne=n(KKe,"A",{href:!0});var kpa=s(wne);Vrt=r(kpa,"TFMobileBertForSequenceClassification"),kpa.forEach(t),Xrt=r(KKe," (MobileBERT model)"),KKe.forEach(t),zrt=i(ae),QA=n(ae,"LI",{});var eeo=s(QA);x9e=n(eeo,"STRONG",{});var Spa=s(x9e);Qrt=r(Spa,"mpnet"),Spa.forEach(t),Wrt=r(eeo," \u2014 "),Ane=n(eeo,"A",{href:!0});var Rpa=s(Ane);Urt=r(Rpa,"TFMPNetForSequenceClassification"),Rpa.forEach(t),Hrt=r(eeo," (MPNet model)"),eeo.forEach(t),Jrt=i(ae),WA=n(ae,"LI",{});var oeo=s(WA);$9e=n(oeo,"STRONG",{});var Ppa=s($9e);Yrt=r(Ppa,"openai-gpt"),Ppa.forEach(t),Zrt=r(oeo," \u2014 "),Lne=n(oeo,"A",{href:!0});var Bpa=s(Lne);Krt=r(Bpa,"TFOpenAIGPTForSequenceClassification"),Bpa.forEach(t),ett=r(oeo," (OpenAI GPT model)"),oeo.forEach(t),ott=i(ae),UA=n(ae,"LI",{});var reo=s(UA);k9e=n(reo,"STRONG",{});var Ipa=s(k9e);rtt=r(Ipa,"rembert"),Ipa.forEach(t),ttt=r(reo," \u2014 "),yne=n(reo,"A",{href:!0});var Npa=s(yne);att=r(Npa,"TFRemBertForSequenceClassification"),Npa.forEach(t),ntt=r(reo," (RemBERT model)"),reo.forEach(t),stt=i(ae),HA=n(ae,"LI",{});var teo=s(HA);S9e=n(teo,"STRONG",{});var qpa=s(S9e);ltt=r(qpa,"roberta"),qpa.forEach(t),itt=r(teo," \u2014 "),xne=n(teo,"A",{href:!0});var jpa=s(xne);dtt=r(jpa,"TFRobertaForSequenceClassification"),jpa.forEach(t),mtt=r(teo," (RoBERTa model)"),teo.forEach(t),ctt=i(ae),JA=n(ae,"LI",{});var aeo=s(JA);R9e=n(aeo,"STRONG",{});var Dpa=s(R9e);ftt=r(Dpa,"roformer"),Dpa.forEach(t),gtt=r(aeo," \u2014 "),$ne=n(aeo,"A",{href:!0});var Gpa=s($ne);htt=r(Gpa,"TFRoFormerForSequenceClassification"),Gpa.forEach(t),utt=r(aeo," (RoFormer model)"),aeo.forEach(t),ptt=i(ae),YA=n(ae,"LI",{});var neo=s(YA);P9e=n(neo,"STRONG",{});var Opa=s(P9e);_tt=r(Opa,"tapas"),Opa.forEach(t),btt=r(neo," \u2014 "),kne=n(neo,"A",{href:!0});var Vpa=s(kne);vtt=r(Vpa,"TFTapasForSequenceClassification"),Vpa.forEach(t),Ftt=r(neo," (TAPAS model)"),neo.forEach(t),Ttt=i(ae),ZA=n(ae,"LI",{});var seo=s(ZA);B9e=n(seo,"STRONG",{});var Xpa=s(B9e);Mtt=r(Xpa,"transfo-xl"),Xpa.forEach(t),Ett=r(seo," \u2014 "),Sne=n(seo,"A",{href:!0});var zpa=s(Sne);Ctt=r(zpa,"TFTransfoXLForSequenceClassification"),zpa.forEach(t),wtt=r(seo," (Transformer-XL model)"),seo.forEach(t),Att=i(ae),KA=n(ae,"LI",{});var leo=s(KA);I9e=n(leo,"STRONG",{});var Qpa=s(I9e);Ltt=r(Qpa,"xlm"),Qpa.forEach(t),ytt=r(leo," \u2014 "),Rne=n(leo,"A",{href:!0});var Wpa=s(Rne);xtt=r(Wpa,"TFXLMForSequenceClassification"),Wpa.forEach(t),$tt=r(leo," (XLM model)"),leo.forEach(t),ktt=i(ae),e6=n(ae,"LI",{});var ieo=s(e6);N9e=n(ieo,"STRONG",{});var Upa=s(N9e);Stt=r(Upa,"xlm-roberta"),Upa.forEach(t),Rtt=r(ieo," \u2014 "),Pne=n(ieo,"A",{href:!0});var Hpa=s(Pne);Ptt=r(Hpa,"TFXLMRobertaForSequenceClassification"),Hpa.forEach(t),Btt=r(ieo," (XLM-RoBERTa model)"),ieo.forEach(t),Itt=i(ae),o6=n(ae,"LI",{});var deo=s(o6);q9e=n(deo,"STRONG",{});var Jpa=s(q9e);Ntt=r(Jpa,"xlnet"),Jpa.forEach(t),qtt=r(deo," \u2014 "),Bne=n(deo,"A",{href:!0});var Ypa=s(Bne);jtt=r(Ypa,"TFXLNetForSequenceClassification"),Ypa.forEach(t),Dtt=r(deo," (XLNet model)"),deo.forEach(t),ae.forEach(t),Gtt=i(ki),T(r6.$$.fragment,ki),ki.forEach(t),$i.forEach(t),rno=i(c),Bc=n(c,"H2",{class:!0});var Tlo=s(Bc);t6=n(Tlo,"A",{id:!0,class:!0,href:!0});var Zpa=s(t6);j9e=n(Zpa,"SPAN",{});var Kpa=s(j9e);T(eP.$$.fragment,Kpa),Kpa.forEach(t),Zpa.forEach(t),Ott=i(Tlo),D9e=n(Tlo,"SPAN",{});var e_a=s(D9e);Vtt=r(e_a,"TFAutoModelForMultipleChoice"),e_a.forEach(t),Tlo.forEach(t),tno=i(c),br=n(c,"DIV",{class:!0});var Si=s(br);T(oP.$$.fragment,Si),Xtt=i(Si),Ic=n(Si,"P",{});var wce=s(Ic);ztt=r(wce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Ine=n(wce,"A",{href:!0});var o_a=s(Ine);Qtt=r(o_a,"from_pretrained()"),o_a.forEach(t),Wtt=r(wce," class method or the "),Nne=n(wce,"A",{href:!0});var r_a=s(Nne);Utt=r(r_a,"from_config()"),r_a.forEach(t),Htt=r(wce,` class
method.`),wce.forEach(t),Jtt=i(Si),rP=n(Si,"P",{});var Mlo=s(rP);Ytt=r(Mlo,"This class cannot be instantiated directly using "),G9e=n(Mlo,"CODE",{});var t_a=s(G9e);Ztt=r(t_a,"__init__()"),t_a.forEach(t),Ktt=r(Mlo," (throws an error)."),Mlo.forEach(t),eat=i(Si),na=n(Si,"DIV",{class:!0});var vx=s(na);T(tP.$$.fragment,vx),oat=i(vx),O9e=n(vx,"P",{});var a_a=s(O9e);rat=r(a_a,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),a_a.forEach(t),tat=i(vx),Nc=n(vx,"P",{});var Ace=s(Nc);aat=r(Ace,`Note:
Loading a model from its configuration file does `),V9e=n(Ace,"STRONG",{});var n_a=s(V9e);nat=r(n_a,"not"),n_a.forEach(t),sat=r(Ace,` load the model weights. It only affects the
model\u2019s configuration. Use `),qne=n(Ace,"A",{href:!0});var s_a=s(qne);lat=r(s_a,"from_pretrained()"),s_a.forEach(t),iat=r(Ace," to load the model weights."),Ace.forEach(t),dat=i(vx),T(a6.$$.fragment,vx),vx.forEach(t),mat=i(Si),Ur=n(Si,"DIV",{class:!0});var Ri=s(Ur);T(aP.$$.fragment,Ri),cat=i(Ri),X9e=n(Ri,"P",{});var l_a=s(X9e);fat=r(l_a,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),l_a.forEach(t),gat=i(Ri),Vn=n(Ri,"P",{});var Fx=s(Vn);hat=r(Fx,"The model class to instantiate is selected based on the "),z9e=n(Fx,"CODE",{});var i_a=s(z9e);uat=r(i_a,"model_type"),i_a.forEach(t),pat=r(Fx,` property of the config object (either
passed as an argument or loaded from `),Q9e=n(Fx,"CODE",{});var d_a=s(Q9e);_at=r(d_a,"pretrained_model_name_or_path"),d_a.forEach(t),bat=r(Fx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W9e=n(Fx,"CODE",{});var m_a=s(W9e);vat=r(m_a,"pretrained_model_name_or_path"),m_a.forEach(t),Fat=r(Fx,":"),Fx.forEach(t),Tat=i(Ri),ve=n(Ri,"UL",{});var Te=s(ve);n6=n(Te,"LI",{});var meo=s(n6);U9e=n(meo,"STRONG",{});var c_a=s(U9e);Mat=r(c_a,"albert"),c_a.forEach(t),Eat=r(meo," \u2014 "),jne=n(meo,"A",{href:!0});var f_a=s(jne);Cat=r(f_a,"TFAlbertForMultipleChoice"),f_a.forEach(t),wat=r(meo," (ALBERT model)"),meo.forEach(t),Aat=i(Te),s6=n(Te,"LI",{});var ceo=s(s6);H9e=n(ceo,"STRONG",{});var g_a=s(H9e);Lat=r(g_a,"bert"),g_a.forEach(t),yat=r(ceo," \u2014 "),Dne=n(ceo,"A",{href:!0});var h_a=s(Dne);xat=r(h_a,"TFBertForMultipleChoice"),h_a.forEach(t),$at=r(ceo," (BERT model)"),ceo.forEach(t),kat=i(Te),l6=n(Te,"LI",{});var feo=s(l6);J9e=n(feo,"STRONG",{});var u_a=s(J9e);Sat=r(u_a,"camembert"),u_a.forEach(t),Rat=r(feo," \u2014 "),Gne=n(feo,"A",{href:!0});var p_a=s(Gne);Pat=r(p_a,"TFCamembertForMultipleChoice"),p_a.forEach(t),Bat=r(feo," (CamemBERT model)"),feo.forEach(t),Iat=i(Te),i6=n(Te,"LI",{});var geo=s(i6);Y9e=n(geo,"STRONG",{});var __a=s(Y9e);Nat=r(__a,"convbert"),__a.forEach(t),qat=r(geo," \u2014 "),One=n(geo,"A",{href:!0});var b_a=s(One);jat=r(b_a,"TFConvBertForMultipleChoice"),b_a.forEach(t),Dat=r(geo," (ConvBERT model)"),geo.forEach(t),Gat=i(Te),d6=n(Te,"LI",{});var heo=s(d6);Z9e=n(heo,"STRONG",{});var v_a=s(Z9e);Oat=r(v_a,"distilbert"),v_a.forEach(t),Vat=r(heo," \u2014 "),Vne=n(heo,"A",{href:!0});var F_a=s(Vne);Xat=r(F_a,"TFDistilBertForMultipleChoice"),F_a.forEach(t),zat=r(heo," (DistilBERT model)"),heo.forEach(t),Qat=i(Te),m6=n(Te,"LI",{});var ueo=s(m6);K9e=n(ueo,"STRONG",{});var T_a=s(K9e);Wat=r(T_a,"electra"),T_a.forEach(t),Uat=r(ueo," \u2014 "),Xne=n(ueo,"A",{href:!0});var M_a=s(Xne);Hat=r(M_a,"TFElectraForMultipleChoice"),M_a.forEach(t),Jat=r(ueo," (ELECTRA model)"),ueo.forEach(t),Yat=i(Te),c6=n(Te,"LI",{});var peo=s(c6);exe=n(peo,"STRONG",{});var E_a=s(exe);Zat=r(E_a,"flaubert"),E_a.forEach(t),Kat=r(peo," \u2014 "),zne=n(peo,"A",{href:!0});var C_a=s(zne);ent=r(C_a,"TFFlaubertForMultipleChoice"),C_a.forEach(t),ont=r(peo," (FlauBERT model)"),peo.forEach(t),rnt=i(Te),f6=n(Te,"LI",{});var _eo=s(f6);oxe=n(_eo,"STRONG",{});var w_a=s(oxe);tnt=r(w_a,"funnel"),w_a.forEach(t),ant=r(_eo," \u2014 "),Qne=n(_eo,"A",{href:!0});var A_a=s(Qne);nnt=r(A_a,"TFFunnelForMultipleChoice"),A_a.forEach(t),snt=r(_eo," (Funnel Transformer model)"),_eo.forEach(t),lnt=i(Te),g6=n(Te,"LI",{});var beo=s(g6);rxe=n(beo,"STRONG",{});var L_a=s(rxe);int=r(L_a,"longformer"),L_a.forEach(t),dnt=r(beo," \u2014 "),Wne=n(beo,"A",{href:!0});var y_a=s(Wne);mnt=r(y_a,"TFLongformerForMultipleChoice"),y_a.forEach(t),cnt=r(beo," (Longformer model)"),beo.forEach(t),fnt=i(Te),h6=n(Te,"LI",{});var veo=s(h6);txe=n(veo,"STRONG",{});var x_a=s(txe);gnt=r(x_a,"mobilebert"),x_a.forEach(t),hnt=r(veo," \u2014 "),Une=n(veo,"A",{href:!0});var $_a=s(Une);unt=r($_a,"TFMobileBertForMultipleChoice"),$_a.forEach(t),pnt=r(veo," (MobileBERT model)"),veo.forEach(t),_nt=i(Te),u6=n(Te,"LI",{});var Feo=s(u6);axe=n(Feo,"STRONG",{});var k_a=s(axe);bnt=r(k_a,"mpnet"),k_a.forEach(t),vnt=r(Feo," \u2014 "),Hne=n(Feo,"A",{href:!0});var S_a=s(Hne);Fnt=r(S_a,"TFMPNetForMultipleChoice"),S_a.forEach(t),Tnt=r(Feo," (MPNet model)"),Feo.forEach(t),Mnt=i(Te),p6=n(Te,"LI",{});var Teo=s(p6);nxe=n(Teo,"STRONG",{});var R_a=s(nxe);Ent=r(R_a,"rembert"),R_a.forEach(t),Cnt=r(Teo," \u2014 "),Jne=n(Teo,"A",{href:!0});var P_a=s(Jne);wnt=r(P_a,"TFRemBertForMultipleChoice"),P_a.forEach(t),Ant=r(Teo," (RemBERT model)"),Teo.forEach(t),Lnt=i(Te),_6=n(Te,"LI",{});var Meo=s(_6);sxe=n(Meo,"STRONG",{});var B_a=s(sxe);ynt=r(B_a,"roberta"),B_a.forEach(t),xnt=r(Meo," \u2014 "),Yne=n(Meo,"A",{href:!0});var I_a=s(Yne);$nt=r(I_a,"TFRobertaForMultipleChoice"),I_a.forEach(t),knt=r(Meo," (RoBERTa model)"),Meo.forEach(t),Snt=i(Te),b6=n(Te,"LI",{});var Eeo=s(b6);lxe=n(Eeo,"STRONG",{});var N_a=s(lxe);Rnt=r(N_a,"roformer"),N_a.forEach(t),Pnt=r(Eeo," \u2014 "),Zne=n(Eeo,"A",{href:!0});var q_a=s(Zne);Bnt=r(q_a,"TFRoFormerForMultipleChoice"),q_a.forEach(t),Int=r(Eeo," (RoFormer model)"),Eeo.forEach(t),Nnt=i(Te),v6=n(Te,"LI",{});var Ceo=s(v6);ixe=n(Ceo,"STRONG",{});var j_a=s(ixe);qnt=r(j_a,"xlm"),j_a.forEach(t),jnt=r(Ceo," \u2014 "),Kne=n(Ceo,"A",{href:!0});var D_a=s(Kne);Dnt=r(D_a,"TFXLMForMultipleChoice"),D_a.forEach(t),Gnt=r(Ceo," (XLM model)"),Ceo.forEach(t),Ont=i(Te),F6=n(Te,"LI",{});var weo=s(F6);dxe=n(weo,"STRONG",{});var G_a=s(dxe);Vnt=r(G_a,"xlm-roberta"),G_a.forEach(t),Xnt=r(weo," \u2014 "),ese=n(weo,"A",{href:!0});var O_a=s(ese);znt=r(O_a,"TFXLMRobertaForMultipleChoice"),O_a.forEach(t),Qnt=r(weo," (XLM-RoBERTa model)"),weo.forEach(t),Wnt=i(Te),T6=n(Te,"LI",{});var Aeo=s(T6);mxe=n(Aeo,"STRONG",{});var V_a=s(mxe);Unt=r(V_a,"xlnet"),V_a.forEach(t),Hnt=r(Aeo," \u2014 "),ose=n(Aeo,"A",{href:!0});var X_a=s(ose);Jnt=r(X_a,"TFXLNetForMultipleChoice"),X_a.forEach(t),Ynt=r(Aeo," (XLNet model)"),Aeo.forEach(t),Te.forEach(t),Znt=i(Ri),T(M6.$$.fragment,Ri),Ri.forEach(t),Si.forEach(t),ano=i(c),qc=n(c,"H2",{class:!0});var Elo=s(qc);E6=n(Elo,"A",{id:!0,class:!0,href:!0});var z_a=s(E6);cxe=n(z_a,"SPAN",{});var Q_a=s(cxe);T(nP.$$.fragment,Q_a),Q_a.forEach(t),z_a.forEach(t),Knt=i(Elo),fxe=n(Elo,"SPAN",{});var W_a=s(fxe);est=r(W_a,"TFAutoModelForNextSentencePrediction"),W_a.forEach(t),Elo.forEach(t),nno=i(c),vr=n(c,"DIV",{class:!0});var Pi=s(vr);T(sP.$$.fragment,Pi),ost=i(Pi),jc=n(Pi,"P",{});var Lce=s(jc);rst=r(Lce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),rse=n(Lce,"A",{href:!0});var U_a=s(rse);tst=r(U_a,"from_pretrained()"),U_a.forEach(t),ast=r(Lce," class method or the "),tse=n(Lce,"A",{href:!0});var H_a=s(tse);nst=r(H_a,"from_config()"),H_a.forEach(t),sst=r(Lce,` class
method.`),Lce.forEach(t),lst=i(Pi),lP=n(Pi,"P",{});var Clo=s(lP);ist=r(Clo,"This class cannot be instantiated directly using "),gxe=n(Clo,"CODE",{});var J_a=s(gxe);dst=r(J_a,"__init__()"),J_a.forEach(t),mst=r(Clo," (throws an error)."),Clo.forEach(t),cst=i(Pi),sa=n(Pi,"DIV",{class:!0});var Tx=s(sa);T(iP.$$.fragment,Tx),fst=i(Tx),hxe=n(Tx,"P",{});var Y_a=s(hxe);gst=r(Y_a,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Y_a.forEach(t),hst=i(Tx),Dc=n(Tx,"P",{});var yce=s(Dc);ust=r(yce,`Note:
Loading a model from its configuration file does `),uxe=n(yce,"STRONG",{});var Z_a=s(uxe);pst=r(Z_a,"not"),Z_a.forEach(t),_st=r(yce,` load the model weights. It only affects the
model\u2019s configuration. Use `),ase=n(yce,"A",{href:!0});var K_a=s(ase);bst=r(K_a,"from_pretrained()"),K_a.forEach(t),vst=r(yce," to load the model weights."),yce.forEach(t),Fst=i(Tx),T(C6.$$.fragment,Tx),Tx.forEach(t),Tst=i(Pi),Hr=n(Pi,"DIV",{class:!0});var Bi=s(Hr);T(dP.$$.fragment,Bi),Mst=i(Bi),pxe=n(Bi,"P",{});var e1a=s(pxe);Est=r(e1a,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),e1a.forEach(t),Cst=i(Bi),Xn=n(Bi,"P",{});var Mx=s(Xn);wst=r(Mx,"The model class to instantiate is selected based on the "),_xe=n(Mx,"CODE",{});var o1a=s(_xe);Ast=r(o1a,"model_type"),o1a.forEach(t),Lst=r(Mx,` property of the config object (either
passed as an argument or loaded from `),bxe=n(Mx,"CODE",{});var r1a=s(bxe);yst=r(r1a,"pretrained_model_name_or_path"),r1a.forEach(t),xst=r(Mx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vxe=n(Mx,"CODE",{});var t1a=s(vxe);$st=r(t1a,"pretrained_model_name_or_path"),t1a.forEach(t),kst=r(Mx,":"),Mx.forEach(t),Sst=i(Bi),mP=n(Bi,"UL",{});var wlo=s(mP);w6=n(wlo,"LI",{});var Leo=s(w6);Fxe=n(Leo,"STRONG",{});var a1a=s(Fxe);Rst=r(a1a,"bert"),a1a.forEach(t),Pst=r(Leo," \u2014 "),nse=n(Leo,"A",{href:!0});var n1a=s(nse);Bst=r(n1a,"TFBertForNextSentencePrediction"),n1a.forEach(t),Ist=r(Leo," (BERT model)"),Leo.forEach(t),Nst=i(wlo),A6=n(wlo,"LI",{});var yeo=s(A6);Txe=n(yeo,"STRONG",{});var s1a=s(Txe);qst=r(s1a,"mobilebert"),s1a.forEach(t),jst=r(yeo," \u2014 "),sse=n(yeo,"A",{href:!0});var l1a=s(sse);Dst=r(l1a,"TFMobileBertForNextSentencePrediction"),l1a.forEach(t),Gst=r(yeo," (MobileBERT model)"),yeo.forEach(t),wlo.forEach(t),Ost=i(Bi),T(L6.$$.fragment,Bi),Bi.forEach(t),Pi.forEach(t),sno=i(c),Gc=n(c,"H2",{class:!0});var Alo=s(Gc);y6=n(Alo,"A",{id:!0,class:!0,href:!0});var i1a=s(y6);Mxe=n(i1a,"SPAN",{});var d1a=s(Mxe);T(cP.$$.fragment,d1a),d1a.forEach(t),i1a.forEach(t),Vst=i(Alo),Exe=n(Alo,"SPAN",{});var m1a=s(Exe);Xst=r(m1a,"TFAutoModelForTableQuestionAnswering"),m1a.forEach(t),Alo.forEach(t),lno=i(c),Fr=n(c,"DIV",{class:!0});var Ii=s(Fr);T(fP.$$.fragment,Ii),zst=i(Ii),Oc=n(Ii,"P",{});var xce=s(Oc);Qst=r(xce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),lse=n(xce,"A",{href:!0});var c1a=s(lse);Wst=r(c1a,"from_pretrained()"),c1a.forEach(t),Ust=r(xce," class method or the "),ise=n(xce,"A",{href:!0});var f1a=s(ise);Hst=r(f1a,"from_config()"),f1a.forEach(t),Jst=r(xce,` class
method.`),xce.forEach(t),Yst=i(Ii),gP=n(Ii,"P",{});var Llo=s(gP);Zst=r(Llo,"This class cannot be instantiated directly using "),Cxe=n(Llo,"CODE",{});var g1a=s(Cxe);Kst=r(g1a,"__init__()"),g1a.forEach(t),elt=r(Llo," (throws an error)."),Llo.forEach(t),olt=i(Ii),la=n(Ii,"DIV",{class:!0});var Ex=s(la);T(hP.$$.fragment,Ex),rlt=i(Ex),wxe=n(Ex,"P",{});var h1a=s(wxe);tlt=r(h1a,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),h1a.forEach(t),alt=i(Ex),Vc=n(Ex,"P",{});var $ce=s(Vc);nlt=r($ce,`Note:
Loading a model from its configuration file does `),Axe=n($ce,"STRONG",{});var u1a=s(Axe);slt=r(u1a,"not"),u1a.forEach(t),llt=r($ce,` load the model weights. It only affects the
model\u2019s configuration. Use `),dse=n($ce,"A",{href:!0});var p1a=s(dse);ilt=r(p1a,"from_pretrained()"),p1a.forEach(t),dlt=r($ce," to load the model weights."),$ce.forEach(t),mlt=i(Ex),T(x6.$$.fragment,Ex),Ex.forEach(t),clt=i(Ii),Jr=n(Ii,"DIV",{class:!0});var Ni=s(Jr);T(uP.$$.fragment,Ni),flt=i(Ni),Lxe=n(Ni,"P",{});var _1a=s(Lxe);glt=r(_1a,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),_1a.forEach(t),hlt=i(Ni),zn=n(Ni,"P",{});var Cx=s(zn);ult=r(Cx,"The model class to instantiate is selected based on the "),yxe=n(Cx,"CODE",{});var b1a=s(yxe);plt=r(b1a,"model_type"),b1a.forEach(t),_lt=r(Cx,` property of the config object (either
passed as an argument or loaded from `),xxe=n(Cx,"CODE",{});var v1a=s(xxe);blt=r(v1a,"pretrained_model_name_or_path"),v1a.forEach(t),vlt=r(Cx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$xe=n(Cx,"CODE",{});var F1a=s($xe);Flt=r(F1a,"pretrained_model_name_or_path"),F1a.forEach(t),Tlt=r(Cx,":"),Cx.forEach(t),Mlt=i(Ni),kxe=n(Ni,"UL",{});var T1a=s(kxe);$6=n(T1a,"LI",{});var xeo=s($6);Sxe=n(xeo,"STRONG",{});var M1a=s(Sxe);Elt=r(M1a,"tapas"),M1a.forEach(t),Clt=r(xeo," \u2014 "),mse=n(xeo,"A",{href:!0});var E1a=s(mse);wlt=r(E1a,"TFTapasForQuestionAnswering"),E1a.forEach(t),Alt=r(xeo," (TAPAS model)"),xeo.forEach(t),T1a.forEach(t),Llt=i(Ni),T(k6.$$.fragment,Ni),Ni.forEach(t),Ii.forEach(t),ino=i(c),Xc=n(c,"H2",{class:!0});var ylo=s(Xc);S6=n(ylo,"A",{id:!0,class:!0,href:!0});var C1a=s(S6);Rxe=n(C1a,"SPAN",{});var w1a=s(Rxe);T(pP.$$.fragment,w1a),w1a.forEach(t),C1a.forEach(t),ylt=i(ylo),Pxe=n(ylo,"SPAN",{});var A1a=s(Pxe);xlt=r(A1a,"TFAutoModelForDocumentQuestionAnswering"),A1a.forEach(t),ylo.forEach(t),dno=i(c),Tr=n(c,"DIV",{class:!0});var qi=s(Tr);T(_P.$$.fragment,qi),$lt=i(qi),zc=n(qi,"P",{});var kce=s(zc);klt=r(kce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),cse=n(kce,"A",{href:!0});var L1a=s(cse);Slt=r(L1a,"from_pretrained()"),L1a.forEach(t),Rlt=r(kce," class method or the "),fse=n(kce,"A",{href:!0});var y1a=s(fse);Plt=r(y1a,"from_config()"),y1a.forEach(t),Blt=r(kce,` class
method.`),kce.forEach(t),Ilt=i(qi),bP=n(qi,"P",{});var xlo=s(bP);Nlt=r(xlo,"This class cannot be instantiated directly using "),Bxe=n(xlo,"CODE",{});var x1a=s(Bxe);qlt=r(x1a,"__init__()"),x1a.forEach(t),jlt=r(xlo," (throws an error)."),xlo.forEach(t),Dlt=i(qi),ia=n(qi,"DIV",{class:!0});var wx=s(ia);T(vP.$$.fragment,wx),Glt=i(wx),Ixe=n(wx,"P",{});var $1a=s(Ixe);Olt=r($1a,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),$1a.forEach(t),Vlt=i(wx),Qc=n(wx,"P",{});var Sce=s(Qc);Xlt=r(Sce,`Note:
Loading a model from its configuration file does `),Nxe=n(Sce,"STRONG",{});var k1a=s(Nxe);zlt=r(k1a,"not"),k1a.forEach(t),Qlt=r(Sce,` load the model weights. It only affects the
model\u2019s configuration. Use `),gse=n(Sce,"A",{href:!0});var S1a=s(gse);Wlt=r(S1a,"from_pretrained()"),S1a.forEach(t),Ult=r(Sce," to load the model weights."),Sce.forEach(t),Hlt=i(wx),T(R6.$$.fragment,wx),wx.forEach(t),Jlt=i(qi),Yr=n(qi,"DIV",{class:!0});var ji=s(Yr);T(FP.$$.fragment,ji),Ylt=i(ji),qxe=n(ji,"P",{});var R1a=s(qxe);Zlt=r(R1a,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),R1a.forEach(t),Klt=i(ji),Qn=n(ji,"P",{});var Ax=s(Qn);eit=r(Ax,"The model class to instantiate is selected based on the "),jxe=n(Ax,"CODE",{});var P1a=s(jxe);oit=r(P1a,"model_type"),P1a.forEach(t),rit=r(Ax,` property of the config object (either
passed as an argument or loaded from `),Dxe=n(Ax,"CODE",{});var B1a=s(Dxe);tit=r(B1a,"pretrained_model_name_or_path"),B1a.forEach(t),ait=r(Ax,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gxe=n(Ax,"CODE",{});var I1a=s(Gxe);nit=r(I1a,"pretrained_model_name_or_path"),I1a.forEach(t),sit=r(Ax,":"),Ax.forEach(t),lit=i(ji),Oxe=n(ji,"UL",{});var N1a=s(Oxe);P6=n(N1a,"LI",{});var $eo=s(P6);Vxe=n($eo,"STRONG",{});var q1a=s(Vxe);iit=r(q1a,"layoutlm"),q1a.forEach(t),dit=r($eo," \u2014 "),hse=n($eo,"A",{href:!0});var j1a=s(hse);mit=r(j1a,"TFLayoutLMForQuestionAnswering"),j1a.forEach(t),cit=r($eo," (LayoutLM model)"),$eo.forEach(t),N1a.forEach(t),fit=i(ji),T(B6.$$.fragment,ji),ji.forEach(t),qi.forEach(t),mno=i(c),Wc=n(c,"H2",{class:!0});var $lo=s(Wc);I6=n($lo,"A",{id:!0,class:!0,href:!0});var D1a=s(I6);Xxe=n(D1a,"SPAN",{});var G1a=s(Xxe);T(TP.$$.fragment,G1a),G1a.forEach(t),D1a.forEach(t),git=i($lo),zxe=n($lo,"SPAN",{});var O1a=s(zxe);hit=r(O1a,"TFAutoModelForTokenClassification"),O1a.forEach(t),$lo.forEach(t),cno=i(c),Mr=n(c,"DIV",{class:!0});var Di=s(Mr);T(MP.$$.fragment,Di),uit=i(Di),Uc=n(Di,"P",{});var Rce=s(Uc);pit=r(Rce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),use=n(Rce,"A",{href:!0});var V1a=s(use);_it=r(V1a,"from_pretrained()"),V1a.forEach(t),bit=r(Rce," class method or the "),pse=n(Rce,"A",{href:!0});var X1a=s(pse);vit=r(X1a,"from_config()"),X1a.forEach(t),Fit=r(Rce,` class
method.`),Rce.forEach(t),Tit=i(Di),EP=n(Di,"P",{});var klo=s(EP);Mit=r(klo,"This class cannot be instantiated directly using "),Qxe=n(klo,"CODE",{});var z1a=s(Qxe);Eit=r(z1a,"__init__()"),z1a.forEach(t),Cit=r(klo," (throws an error)."),klo.forEach(t),wit=i(Di),da=n(Di,"DIV",{class:!0});var Lx=s(da);T(CP.$$.fragment,Lx),Ait=i(Lx),Wxe=n(Lx,"P",{});var Q1a=s(Wxe);Lit=r(Q1a,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Q1a.forEach(t),yit=i(Lx),Hc=n(Lx,"P",{});var Pce=s(Hc);xit=r(Pce,`Note:
Loading a model from its configuration file does `),Uxe=n(Pce,"STRONG",{});var W1a=s(Uxe);$it=r(W1a,"not"),W1a.forEach(t),kit=r(Pce,` load the model weights. It only affects the
model\u2019s configuration. Use `),_se=n(Pce,"A",{href:!0});var U1a=s(_se);Sit=r(U1a,"from_pretrained()"),U1a.forEach(t),Rit=r(Pce," to load the model weights."),Pce.forEach(t),Pit=i(Lx),T(N6.$$.fragment,Lx),Lx.forEach(t),Bit=i(Di),Zr=n(Di,"DIV",{class:!0});var Gi=s(Zr);T(wP.$$.fragment,Gi),Iit=i(Gi),Hxe=n(Gi,"P",{});var H1a=s(Hxe);Nit=r(H1a,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),H1a.forEach(t),qit=i(Gi),Wn=n(Gi,"P",{});var yx=s(Wn);jit=r(yx,"The model class to instantiate is selected based on the "),Jxe=n(yx,"CODE",{});var J1a=s(Jxe);Dit=r(J1a,"model_type"),J1a.forEach(t),Git=r(yx,` property of the config object (either
passed as an argument or loaded from `),Yxe=n(yx,"CODE",{});var Y1a=s(Yxe);Oit=r(Y1a,"pretrained_model_name_or_path"),Y1a.forEach(t),Vit=r(yx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zxe=n(yx,"CODE",{});var Z1a=s(Zxe);Xit=r(Z1a,"pretrained_model_name_or_path"),Z1a.forEach(t),zit=r(yx,":"),yx.forEach(t),Qit=i(Gi),ie=n(Gi,"UL",{});var ge=s(ie);q6=n(ge,"LI",{});var keo=s(q6);Kxe=n(keo,"STRONG",{});var K1a=s(Kxe);Wit=r(K1a,"albert"),K1a.forEach(t),Uit=r(keo," \u2014 "),bse=n(keo,"A",{href:!0});var e2a=s(bse);Hit=r(e2a,"TFAlbertForTokenClassification"),e2a.forEach(t),Jit=r(keo," (ALBERT model)"),keo.forEach(t),Yit=i(ge),j6=n(ge,"LI",{});var Seo=s(j6);e$e=n(Seo,"STRONG",{});var o2a=s(e$e);Zit=r(o2a,"bert"),o2a.forEach(t),Kit=r(Seo," \u2014 "),vse=n(Seo,"A",{href:!0});var r2a=s(vse);edt=r(r2a,"TFBertForTokenClassification"),r2a.forEach(t),odt=r(Seo," (BERT model)"),Seo.forEach(t),rdt=i(ge),D6=n(ge,"LI",{});var Reo=s(D6);o$e=n(Reo,"STRONG",{});var t2a=s(o$e);tdt=r(t2a,"camembert"),t2a.forEach(t),adt=r(Reo," \u2014 "),Fse=n(Reo,"A",{href:!0});var a2a=s(Fse);ndt=r(a2a,"TFCamembertForTokenClassification"),a2a.forEach(t),sdt=r(Reo," (CamemBERT model)"),Reo.forEach(t),ldt=i(ge),G6=n(ge,"LI",{});var Peo=s(G6);r$e=n(Peo,"STRONG",{});var n2a=s(r$e);idt=r(n2a,"convbert"),n2a.forEach(t),ddt=r(Peo," \u2014 "),Tse=n(Peo,"A",{href:!0});var s2a=s(Tse);mdt=r(s2a,"TFConvBertForTokenClassification"),s2a.forEach(t),cdt=r(Peo," (ConvBERT model)"),Peo.forEach(t),fdt=i(ge),O6=n(ge,"LI",{});var Beo=s(O6);t$e=n(Beo,"STRONG",{});var l2a=s(t$e);gdt=r(l2a,"deberta"),l2a.forEach(t),hdt=r(Beo," \u2014 "),Mse=n(Beo,"A",{href:!0});var i2a=s(Mse);udt=r(i2a,"TFDebertaForTokenClassification"),i2a.forEach(t),pdt=r(Beo," (DeBERTa model)"),Beo.forEach(t),_dt=i(ge),V6=n(ge,"LI",{});var Ieo=s(V6);a$e=n(Ieo,"STRONG",{});var d2a=s(a$e);bdt=r(d2a,"deberta-v2"),d2a.forEach(t),vdt=r(Ieo," \u2014 "),Ese=n(Ieo,"A",{href:!0});var m2a=s(Ese);Fdt=r(m2a,"TFDebertaV2ForTokenClassification"),m2a.forEach(t),Tdt=r(Ieo," (DeBERTa-v2 model)"),Ieo.forEach(t),Mdt=i(ge),X6=n(ge,"LI",{});var Neo=s(X6);n$e=n(Neo,"STRONG",{});var c2a=s(n$e);Edt=r(c2a,"distilbert"),c2a.forEach(t),Cdt=r(Neo," \u2014 "),Cse=n(Neo,"A",{href:!0});var f2a=s(Cse);wdt=r(f2a,"TFDistilBertForTokenClassification"),f2a.forEach(t),Adt=r(Neo," (DistilBERT model)"),Neo.forEach(t),Ldt=i(ge),z6=n(ge,"LI",{});var qeo=s(z6);s$e=n(qeo,"STRONG",{});var g2a=s(s$e);ydt=r(g2a,"electra"),g2a.forEach(t),xdt=r(qeo," \u2014 "),wse=n(qeo,"A",{href:!0});var h2a=s(wse);$dt=r(h2a,"TFElectraForTokenClassification"),h2a.forEach(t),kdt=r(qeo," (ELECTRA model)"),qeo.forEach(t),Sdt=i(ge),Q6=n(ge,"LI",{});var jeo=s(Q6);l$e=n(jeo,"STRONG",{});var u2a=s(l$e);Rdt=r(u2a,"esm"),u2a.forEach(t),Pdt=r(jeo," \u2014 "),Ase=n(jeo,"A",{href:!0});var p2a=s(Ase);Bdt=r(p2a,"TFEsmForTokenClassification"),p2a.forEach(t),Idt=r(jeo," (ESM model)"),jeo.forEach(t),Ndt=i(ge),W6=n(ge,"LI",{});var Deo=s(W6);i$e=n(Deo,"STRONG",{});var _2a=s(i$e);qdt=r(_2a,"flaubert"),_2a.forEach(t),jdt=r(Deo," \u2014 "),Lse=n(Deo,"A",{href:!0});var b2a=s(Lse);Ddt=r(b2a,"TFFlaubertForTokenClassification"),b2a.forEach(t),Gdt=r(Deo," (FlauBERT model)"),Deo.forEach(t),Odt=i(ge),U6=n(ge,"LI",{});var Geo=s(U6);d$e=n(Geo,"STRONG",{});var v2a=s(d$e);Vdt=r(v2a,"funnel"),v2a.forEach(t),Xdt=r(Geo," \u2014 "),yse=n(Geo,"A",{href:!0});var F2a=s(yse);zdt=r(F2a,"TFFunnelForTokenClassification"),F2a.forEach(t),Qdt=r(Geo," (Funnel Transformer model)"),Geo.forEach(t),Wdt=i(ge),H6=n(ge,"LI",{});var Oeo=s(H6);m$e=n(Oeo,"STRONG",{});var T2a=s(m$e);Udt=r(T2a,"layoutlm"),T2a.forEach(t),Hdt=r(Oeo," \u2014 "),xse=n(Oeo,"A",{href:!0});var M2a=s(xse);Jdt=r(M2a,"TFLayoutLMForTokenClassification"),M2a.forEach(t),Ydt=r(Oeo," (LayoutLM model)"),Oeo.forEach(t),Zdt=i(ge),J6=n(ge,"LI",{});var Veo=s(J6);c$e=n(Veo,"STRONG",{});var E2a=s(c$e);Kdt=r(E2a,"layoutlmv3"),E2a.forEach(t),emt=r(Veo," \u2014 "),$se=n(Veo,"A",{href:!0});var C2a=s($se);omt=r(C2a,"TFLayoutLMv3ForTokenClassification"),C2a.forEach(t),rmt=r(Veo," (LayoutLMv3 model)"),Veo.forEach(t),tmt=i(ge),Y6=n(ge,"LI",{});var Xeo=s(Y6);f$e=n(Xeo,"STRONG",{});var w2a=s(f$e);amt=r(w2a,"longformer"),w2a.forEach(t),nmt=r(Xeo," \u2014 "),kse=n(Xeo,"A",{href:!0});var A2a=s(kse);smt=r(A2a,"TFLongformerForTokenClassification"),A2a.forEach(t),lmt=r(Xeo," (Longformer model)"),Xeo.forEach(t),imt=i(ge),Z6=n(ge,"LI",{});var zeo=s(Z6);g$e=n(zeo,"STRONG",{});var L2a=s(g$e);dmt=r(L2a,"mobilebert"),L2a.forEach(t),mmt=r(zeo," \u2014 "),Sse=n(zeo,"A",{href:!0});var y2a=s(Sse);cmt=r(y2a,"TFMobileBertForTokenClassification"),y2a.forEach(t),fmt=r(zeo," (MobileBERT model)"),zeo.forEach(t),gmt=i(ge),K6=n(ge,"LI",{});var Qeo=s(K6);h$e=n(Qeo,"STRONG",{});var x2a=s(h$e);hmt=r(x2a,"mpnet"),x2a.forEach(t),umt=r(Qeo," \u2014 "),Rse=n(Qeo,"A",{href:!0});var $2a=s(Rse);pmt=r($2a,"TFMPNetForTokenClassification"),$2a.forEach(t),_mt=r(Qeo," (MPNet model)"),Qeo.forEach(t),bmt=i(ge),e7=n(ge,"LI",{});var Weo=s(e7);u$e=n(Weo,"STRONG",{});var k2a=s(u$e);vmt=r(k2a,"rembert"),k2a.forEach(t),Fmt=r(Weo," \u2014 "),Pse=n(Weo,"A",{href:!0});var S2a=s(Pse);Tmt=r(S2a,"TFRemBertForTokenClassification"),S2a.forEach(t),Mmt=r(Weo," (RemBERT model)"),Weo.forEach(t),Emt=i(ge),o7=n(ge,"LI",{});var Ueo=s(o7);p$e=n(Ueo,"STRONG",{});var R2a=s(p$e);Cmt=r(R2a,"roberta"),R2a.forEach(t),wmt=r(Ueo," \u2014 "),Bse=n(Ueo,"A",{href:!0});var P2a=s(Bse);Amt=r(P2a,"TFRobertaForTokenClassification"),P2a.forEach(t),Lmt=r(Ueo," (RoBERTa model)"),Ueo.forEach(t),ymt=i(ge),r7=n(ge,"LI",{});var Heo=s(r7);_$e=n(Heo,"STRONG",{});var B2a=s(_$e);xmt=r(B2a,"roformer"),B2a.forEach(t),$mt=r(Heo," \u2014 "),Ise=n(Heo,"A",{href:!0});var I2a=s(Ise);kmt=r(I2a,"TFRoFormerForTokenClassification"),I2a.forEach(t),Smt=r(Heo," (RoFormer model)"),Heo.forEach(t),Rmt=i(ge),t7=n(ge,"LI",{});var Jeo=s(t7);b$e=n(Jeo,"STRONG",{});var N2a=s(b$e);Pmt=r(N2a,"xlm"),N2a.forEach(t),Bmt=r(Jeo," \u2014 "),Nse=n(Jeo,"A",{href:!0});var q2a=s(Nse);Imt=r(q2a,"TFXLMForTokenClassification"),q2a.forEach(t),Nmt=r(Jeo," (XLM model)"),Jeo.forEach(t),qmt=i(ge),a7=n(ge,"LI",{});var Yeo=s(a7);v$e=n(Yeo,"STRONG",{});var j2a=s(v$e);jmt=r(j2a,"xlm-roberta"),j2a.forEach(t),Dmt=r(Yeo," \u2014 "),qse=n(Yeo,"A",{href:!0});var D2a=s(qse);Gmt=r(D2a,"TFXLMRobertaForTokenClassification"),D2a.forEach(t),Omt=r(Yeo," (XLM-RoBERTa model)"),Yeo.forEach(t),Vmt=i(ge),n7=n(ge,"LI",{});var Zeo=s(n7);F$e=n(Zeo,"STRONG",{});var G2a=s(F$e);Xmt=r(G2a,"xlnet"),G2a.forEach(t),zmt=r(Zeo," \u2014 "),jse=n(Zeo,"A",{href:!0});var O2a=s(jse);Qmt=r(O2a,"TFXLNetForTokenClassification"),O2a.forEach(t),Wmt=r(Zeo," (XLNet model)"),Zeo.forEach(t),ge.forEach(t),Umt=i(Gi),T(s7.$$.fragment,Gi),Gi.forEach(t),Di.forEach(t),fno=i(c),Jc=n(c,"H2",{class:!0});var Slo=s(Jc);l7=n(Slo,"A",{id:!0,class:!0,href:!0});var V2a=s(l7);T$e=n(V2a,"SPAN",{});var X2a=s(T$e);T(AP.$$.fragment,X2a),X2a.forEach(t),V2a.forEach(t),Hmt=i(Slo),M$e=n(Slo,"SPAN",{});var z2a=s(M$e);Jmt=r(z2a,"TFAutoModelForQuestionAnswering"),z2a.forEach(t),Slo.forEach(t),gno=i(c),Er=n(c,"DIV",{class:!0});var Oi=s(Er);T(LP.$$.fragment,Oi),Ymt=i(Oi),Yc=n(Oi,"P",{});var Bce=s(Yc);Zmt=r(Bce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Dse=n(Bce,"A",{href:!0});var Q2a=s(Dse);Kmt=r(Q2a,"from_pretrained()"),Q2a.forEach(t),ect=r(Bce," class method or the "),Gse=n(Bce,"A",{href:!0});var W2a=s(Gse);oct=r(W2a,"from_config()"),W2a.forEach(t),rct=r(Bce,` class
method.`),Bce.forEach(t),tct=i(Oi),yP=n(Oi,"P",{});var Rlo=s(yP);act=r(Rlo,"This class cannot be instantiated directly using "),E$e=n(Rlo,"CODE",{});var U2a=s(E$e);nct=r(U2a,"__init__()"),U2a.forEach(t),sct=r(Rlo," (throws an error)."),Rlo.forEach(t),lct=i(Oi),ma=n(Oi,"DIV",{class:!0});var xx=s(ma);T(xP.$$.fragment,xx),ict=i(xx),C$e=n(xx,"P",{});var H2a=s(C$e);dct=r(H2a,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),H2a.forEach(t),mct=i(xx),Zc=n(xx,"P",{});var Ice=s(Zc);cct=r(Ice,`Note:
Loading a model from its configuration file does `),w$e=n(Ice,"STRONG",{});var J2a=s(w$e);fct=r(J2a,"not"),J2a.forEach(t),gct=r(Ice,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ose=n(Ice,"A",{href:!0});var Y2a=s(Ose);hct=r(Y2a,"from_pretrained()"),Y2a.forEach(t),uct=r(Ice," to load the model weights."),Ice.forEach(t),pct=i(xx),T(i7.$$.fragment,xx),xx.forEach(t),_ct=i(Oi),Kr=n(Oi,"DIV",{class:!0});var Vi=s(Kr);T($P.$$.fragment,Vi),bct=i(Vi),A$e=n(Vi,"P",{});var Z2a=s(A$e);vct=r(Z2a,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Z2a.forEach(t),Fct=i(Vi),Un=n(Vi,"P",{});var $x=s(Un);Tct=r($x,"The model class to instantiate is selected based on the "),L$e=n($x,"CODE",{});var K2a=s(L$e);Mct=r(K2a,"model_type"),K2a.forEach(t),Ect=r($x,` property of the config object (either
passed as an argument or loaded from `),y$e=n($x,"CODE",{});var eba=s(y$e);Cct=r(eba,"pretrained_model_name_or_path"),eba.forEach(t),wct=r($x,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x$e=n($x,"CODE",{});var oba=s(x$e);Act=r(oba,"pretrained_model_name_or_path"),oba.forEach(t),Lct=r($x,":"),$x.forEach(t),yct=i(Vi),ce=n(Vi,"UL",{});var pe=s(ce);d7=n(pe,"LI",{});var Keo=s(d7);$$e=n(Keo,"STRONG",{});var rba=s($$e);xct=r(rba,"albert"),rba.forEach(t),$ct=r(Keo," \u2014 "),Vse=n(Keo,"A",{href:!0});var tba=s(Vse);kct=r(tba,"TFAlbertForQuestionAnswering"),tba.forEach(t),Sct=r(Keo," (ALBERT model)"),Keo.forEach(t),Rct=i(pe),m7=n(pe,"LI",{});var eoo=s(m7);k$e=n(eoo,"STRONG",{});var aba=s(k$e);Pct=r(aba,"bert"),aba.forEach(t),Bct=r(eoo," \u2014 "),Xse=n(eoo,"A",{href:!0});var nba=s(Xse);Ict=r(nba,"TFBertForQuestionAnswering"),nba.forEach(t),Nct=r(eoo," (BERT model)"),eoo.forEach(t),qct=i(pe),c7=n(pe,"LI",{});var ooo=s(c7);S$e=n(ooo,"STRONG",{});var sba=s(S$e);jct=r(sba,"camembert"),sba.forEach(t),Dct=r(ooo," \u2014 "),zse=n(ooo,"A",{href:!0});var lba=s(zse);Gct=r(lba,"TFCamembertForQuestionAnswering"),lba.forEach(t),Oct=r(ooo," (CamemBERT model)"),ooo.forEach(t),Vct=i(pe),f7=n(pe,"LI",{});var roo=s(f7);R$e=n(roo,"STRONG",{});var iba=s(R$e);Xct=r(iba,"convbert"),iba.forEach(t),zct=r(roo," \u2014 "),Qse=n(roo,"A",{href:!0});var dba=s(Qse);Qct=r(dba,"TFConvBertForQuestionAnswering"),dba.forEach(t),Wct=r(roo," (ConvBERT model)"),roo.forEach(t),Uct=i(pe),g7=n(pe,"LI",{});var too=s(g7);P$e=n(too,"STRONG",{});var mba=s(P$e);Hct=r(mba,"deberta"),mba.forEach(t),Jct=r(too," \u2014 "),Wse=n(too,"A",{href:!0});var cba=s(Wse);Yct=r(cba,"TFDebertaForQuestionAnswering"),cba.forEach(t),Zct=r(too," (DeBERTa model)"),too.forEach(t),Kct=i(pe),h7=n(pe,"LI",{});var aoo=s(h7);B$e=n(aoo,"STRONG",{});var fba=s(B$e);eft=r(fba,"deberta-v2"),fba.forEach(t),oft=r(aoo," \u2014 "),Use=n(aoo,"A",{href:!0});var gba=s(Use);rft=r(gba,"TFDebertaV2ForQuestionAnswering"),gba.forEach(t),tft=r(aoo," (DeBERTa-v2 model)"),aoo.forEach(t),aft=i(pe),u7=n(pe,"LI",{});var noo=s(u7);I$e=n(noo,"STRONG",{});var hba=s(I$e);nft=r(hba,"distilbert"),hba.forEach(t),sft=r(noo," \u2014 "),Hse=n(noo,"A",{href:!0});var uba=s(Hse);lft=r(uba,"TFDistilBertForQuestionAnswering"),uba.forEach(t),ift=r(noo," (DistilBERT model)"),noo.forEach(t),dft=i(pe),p7=n(pe,"LI",{});var soo=s(p7);N$e=n(soo,"STRONG",{});var pba=s(N$e);mft=r(pba,"electra"),pba.forEach(t),cft=r(soo," \u2014 "),Jse=n(soo,"A",{href:!0});var _ba=s(Jse);fft=r(_ba,"TFElectraForQuestionAnswering"),_ba.forEach(t),gft=r(soo," (ELECTRA model)"),soo.forEach(t),hft=i(pe),_7=n(pe,"LI",{});var loo=s(_7);q$e=n(loo,"STRONG",{});var bba=s(q$e);uft=r(bba,"flaubert"),bba.forEach(t),pft=r(loo," \u2014 "),Yse=n(loo,"A",{href:!0});var vba=s(Yse);_ft=r(vba,"TFFlaubertForQuestionAnsweringSimple"),vba.forEach(t),bft=r(loo," (FlauBERT model)"),loo.forEach(t),vft=i(pe),b7=n(pe,"LI",{});var ioo=s(b7);j$e=n(ioo,"STRONG",{});var Fba=s(j$e);Fft=r(Fba,"funnel"),Fba.forEach(t),Tft=r(ioo," \u2014 "),Zse=n(ioo,"A",{href:!0});var Tba=s(Zse);Mft=r(Tba,"TFFunnelForQuestionAnswering"),Tba.forEach(t),Eft=r(ioo," (Funnel Transformer model)"),ioo.forEach(t),Cft=i(pe),v7=n(pe,"LI",{});var doo=s(v7);D$e=n(doo,"STRONG",{});var Mba=s(D$e);wft=r(Mba,"gptj"),Mba.forEach(t),Aft=r(doo," \u2014 "),Kse=n(doo,"A",{href:!0});var Eba=s(Kse);Lft=r(Eba,"TFGPTJForQuestionAnswering"),Eba.forEach(t),yft=r(doo," (GPT-J model)"),doo.forEach(t),xft=i(pe),F7=n(pe,"LI",{});var moo=s(F7);G$e=n(moo,"STRONG",{});var Cba=s(G$e);$ft=r(Cba,"layoutlmv3"),Cba.forEach(t),kft=r(moo," \u2014 "),ele=n(moo,"A",{href:!0});var wba=s(ele);Sft=r(wba,"TFLayoutLMv3ForQuestionAnswering"),wba.forEach(t),Rft=r(moo," (LayoutLMv3 model)"),moo.forEach(t),Pft=i(pe),T7=n(pe,"LI",{});var coo=s(T7);O$e=n(coo,"STRONG",{});var Aba=s(O$e);Bft=r(Aba,"longformer"),Aba.forEach(t),Ift=r(coo," \u2014 "),ole=n(coo,"A",{href:!0});var Lba=s(ole);Nft=r(Lba,"TFLongformerForQuestionAnswering"),Lba.forEach(t),qft=r(coo," (Longformer model)"),coo.forEach(t),jft=i(pe),M7=n(pe,"LI",{});var foo=s(M7);V$e=n(foo,"STRONG",{});var yba=s(V$e);Dft=r(yba,"mobilebert"),yba.forEach(t),Gft=r(foo," \u2014 "),rle=n(foo,"A",{href:!0});var xba=s(rle);Oft=r(xba,"TFMobileBertForQuestionAnswering"),xba.forEach(t),Vft=r(foo," (MobileBERT model)"),foo.forEach(t),Xft=i(pe),E7=n(pe,"LI",{});var goo=s(E7);X$e=n(goo,"STRONG",{});var $ba=s(X$e);zft=r($ba,"mpnet"),$ba.forEach(t),Qft=r(goo," \u2014 "),tle=n(goo,"A",{href:!0});var kba=s(tle);Wft=r(kba,"TFMPNetForQuestionAnswering"),kba.forEach(t),Uft=r(goo," (MPNet model)"),goo.forEach(t),Hft=i(pe),C7=n(pe,"LI",{});var hoo=s(C7);z$e=n(hoo,"STRONG",{});var Sba=s(z$e);Jft=r(Sba,"rembert"),Sba.forEach(t),Yft=r(hoo," \u2014 "),ale=n(hoo,"A",{href:!0});var Rba=s(ale);Zft=r(Rba,"TFRemBertForQuestionAnswering"),Rba.forEach(t),Kft=r(hoo," (RemBERT model)"),hoo.forEach(t),egt=i(pe),w7=n(pe,"LI",{});var uoo=s(w7);Q$e=n(uoo,"STRONG",{});var Pba=s(Q$e);ogt=r(Pba,"roberta"),Pba.forEach(t),rgt=r(uoo," \u2014 "),nle=n(uoo,"A",{href:!0});var Bba=s(nle);tgt=r(Bba,"TFRobertaForQuestionAnswering"),Bba.forEach(t),agt=r(uoo," (RoBERTa model)"),uoo.forEach(t),ngt=i(pe),A7=n(pe,"LI",{});var poo=s(A7);W$e=n(poo,"STRONG",{});var Iba=s(W$e);sgt=r(Iba,"roformer"),Iba.forEach(t),lgt=r(poo," \u2014 "),sle=n(poo,"A",{href:!0});var Nba=s(sle);igt=r(Nba,"TFRoFormerForQuestionAnswering"),Nba.forEach(t),dgt=r(poo," (RoFormer model)"),poo.forEach(t),mgt=i(pe),L7=n(pe,"LI",{});var _oo=s(L7);U$e=n(_oo,"STRONG",{});var qba=s(U$e);cgt=r(qba,"xlm"),qba.forEach(t),fgt=r(_oo," \u2014 "),lle=n(_oo,"A",{href:!0});var jba=s(lle);ggt=r(jba,"TFXLMForQuestionAnsweringSimple"),jba.forEach(t),hgt=r(_oo," (XLM model)"),_oo.forEach(t),ugt=i(pe),y7=n(pe,"LI",{});var boo=s(y7);H$e=n(boo,"STRONG",{});var Dba=s(H$e);pgt=r(Dba,"xlm-roberta"),Dba.forEach(t),_gt=r(boo," \u2014 "),ile=n(boo,"A",{href:!0});var Gba=s(ile);bgt=r(Gba,"TFXLMRobertaForQuestionAnswering"),Gba.forEach(t),vgt=r(boo," (XLM-RoBERTa model)"),boo.forEach(t),Fgt=i(pe),x7=n(pe,"LI",{});var voo=s(x7);J$e=n(voo,"STRONG",{});var Oba=s(J$e);Tgt=r(Oba,"xlnet"),Oba.forEach(t),Mgt=r(voo," \u2014 "),dle=n(voo,"A",{href:!0});var Vba=s(dle);Egt=r(Vba,"TFXLNetForQuestionAnsweringSimple"),Vba.forEach(t),Cgt=r(voo," (XLNet model)"),voo.forEach(t),pe.forEach(t),wgt=i(Vi),T($7.$$.fragment,Vi),Vi.forEach(t),Oi.forEach(t),hno=i(c),Kc=n(c,"H2",{class:!0});var Plo=s(Kc);k7=n(Plo,"A",{id:!0,class:!0,href:!0});var Xba=s(k7);Y$e=n(Xba,"SPAN",{});var zba=s(Y$e);T(kP.$$.fragment,zba),zba.forEach(t),Xba.forEach(t),Agt=i(Plo),Z$e=n(Plo,"SPAN",{});var Qba=s(Z$e);Lgt=r(Qba,"TFAutoModelForVision2Seq"),Qba.forEach(t),Plo.forEach(t),uno=i(c),Cr=n(c,"DIV",{class:!0});var Xi=s(Cr);T(SP.$$.fragment,Xi),ygt=i(Xi),ef=n(Xi,"P",{});var Nce=s(ef);xgt=r(Nce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),mle=n(Nce,"A",{href:!0});var Wba=s(mle);$gt=r(Wba,"from_pretrained()"),Wba.forEach(t),kgt=r(Nce," class method or the "),cle=n(Nce,"A",{href:!0});var Uba=s(cle);Sgt=r(Uba,"from_config()"),Uba.forEach(t),Rgt=r(Nce,` class
method.`),Nce.forEach(t),Pgt=i(Xi),RP=n(Xi,"P",{});var Blo=s(RP);Bgt=r(Blo,"This class cannot be instantiated directly using "),K$e=n(Blo,"CODE",{});var Hba=s(K$e);Igt=r(Hba,"__init__()"),Hba.forEach(t),Ngt=r(Blo," (throws an error)."),Blo.forEach(t),qgt=i(Xi),ca=n(Xi,"DIV",{class:!0});var kx=s(ca);T(PP.$$.fragment,kx),jgt=i(kx),eke=n(kx,"P",{});var Jba=s(eke);Dgt=r(Jba,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Jba.forEach(t),Ggt=i(kx),of=n(kx,"P",{});var qce=s(of);Ogt=r(qce,`Note:
Loading a model from its configuration file does `),oke=n(qce,"STRONG",{});var Yba=s(oke);Vgt=r(Yba,"not"),Yba.forEach(t),Xgt=r(qce,` load the model weights. It only affects the
model\u2019s configuration. Use `),fle=n(qce,"A",{href:!0});var Zba=s(fle);zgt=r(Zba,"from_pretrained()"),Zba.forEach(t),Qgt=r(qce," to load the model weights."),qce.forEach(t),Wgt=i(kx),T(S7.$$.fragment,kx),kx.forEach(t),Ugt=i(Xi),et=n(Xi,"DIV",{class:!0});var zi=s(et);T(BP.$$.fragment,zi),Hgt=i(zi),rke=n(zi,"P",{});var Kba=s(rke);Jgt=r(Kba,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Kba.forEach(t),Ygt=i(zi),Hn=n(zi,"P",{});var Sx=s(Hn);Zgt=r(Sx,"The model class to instantiate is selected based on the "),tke=n(Sx,"CODE",{});var eva=s(tke);Kgt=r(eva,"model_type"),eva.forEach(t),eht=r(Sx,` property of the config object (either
passed as an argument or loaded from `),ake=n(Sx,"CODE",{});var ova=s(ake);oht=r(ova,"pretrained_model_name_or_path"),ova.forEach(t),rht=r(Sx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nke=n(Sx,"CODE",{});var rva=s(nke);tht=r(rva,"pretrained_model_name_or_path"),rva.forEach(t),aht=r(Sx,":"),Sx.forEach(t),nht=i(zi),ske=n(zi,"UL",{});var tva=s(ske);R7=n(tva,"LI",{});var Foo=s(R7);lke=n(Foo,"STRONG",{});var ava=s(lke);sht=r(ava,"vision-encoder-decoder"),ava.forEach(t),lht=r(Foo," \u2014 "),gle=n(Foo,"A",{href:!0});var nva=s(gle);iht=r(nva,"TFVisionEncoderDecoderModel"),nva.forEach(t),dht=r(Foo," (Vision Encoder decoder model)"),Foo.forEach(t),tva.forEach(t),mht=i(zi),T(P7.$$.fragment,zi),zi.forEach(t),Xi.forEach(t),pno=i(c),rf=n(c,"H2",{class:!0});var Ilo=s(rf);B7=n(Ilo,"A",{id:!0,class:!0,href:!0});var sva=s(B7);ike=n(sva,"SPAN",{});var lva=s(ike);T(IP.$$.fragment,lva),lva.forEach(t),sva.forEach(t),cht=i(Ilo),dke=n(Ilo,"SPAN",{});var iva=s(dke);fht=r(iva,"TFAutoModelForSpeechSeq2Seq"),iva.forEach(t),Ilo.forEach(t),_no=i(c),wr=n(c,"DIV",{class:!0});var Qi=s(wr);T(NP.$$.fragment,Qi),ght=i(Qi),tf=n(Qi,"P",{});var jce=s(tf);hht=r(jce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),hle=n(jce,"A",{href:!0});var dva=s(hle);uht=r(dva,"from_pretrained()"),dva.forEach(t),pht=r(jce," class method or the "),ule=n(jce,"A",{href:!0});var mva=s(ule);_ht=r(mva,"from_config()"),mva.forEach(t),bht=r(jce,` class
method.`),jce.forEach(t),vht=i(Qi),qP=n(Qi,"P",{});var Nlo=s(qP);Fht=r(Nlo,"This class cannot be instantiated directly using "),mke=n(Nlo,"CODE",{});var cva=s(mke);Tht=r(cva,"__init__()"),cva.forEach(t),Mht=r(Nlo," (throws an error)."),Nlo.forEach(t),Eht=i(Qi),fa=n(Qi,"DIV",{class:!0});var Rx=s(fa);T(jP.$$.fragment,Rx),Cht=i(Rx),cke=n(Rx,"P",{});var fva=s(cke);wht=r(fva,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),fva.forEach(t),Aht=i(Rx),af=n(Rx,"P",{});var Dce=s(af);Lht=r(Dce,`Note:
Loading a model from its configuration file does `),fke=n(Dce,"STRONG",{});var gva=s(fke);yht=r(gva,"not"),gva.forEach(t),xht=r(Dce,` load the model weights. It only affects the
model\u2019s configuration. Use `),ple=n(Dce,"A",{href:!0});var hva=s(ple);$ht=r(hva,"from_pretrained()"),hva.forEach(t),kht=r(Dce," to load the model weights."),Dce.forEach(t),Sht=i(Rx),T(I7.$$.fragment,Rx),Rx.forEach(t),Rht=i(Qi),ot=n(Qi,"DIV",{class:!0});var Wi=s(ot);T(DP.$$.fragment,Wi),Pht=i(Wi),gke=n(Wi,"P",{});var uva=s(gke);Bht=r(uva,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),uva.forEach(t),Iht=i(Wi),Jn=n(Wi,"P",{});var Px=s(Jn);Nht=r(Px,"The model class to instantiate is selected based on the "),hke=n(Px,"CODE",{});var pva=s(hke);qht=r(pva,"model_type"),pva.forEach(t),jht=r(Px,` property of the config object (either
passed as an argument or loaded from `),uke=n(Px,"CODE",{});var _va=s(uke);Dht=r(_va,"pretrained_model_name_or_path"),_va.forEach(t),Ght=r(Px,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pke=n(Px,"CODE",{});var bva=s(pke);Oht=r(bva,"pretrained_model_name_or_path"),bva.forEach(t),Vht=r(Px,":"),Px.forEach(t),Xht=i(Wi),GP=n(Wi,"UL",{});var qlo=s(GP);N7=n(qlo,"LI",{});var Too=s(N7);_ke=n(Too,"STRONG",{});var vva=s(_ke);zht=r(vva,"speech_to_text"),vva.forEach(t),Qht=r(Too," \u2014 "),_le=n(Too,"A",{href:!0});var Fva=s(_le);Wht=r(Fva,"TFSpeech2TextForConditionalGeneration"),Fva.forEach(t),Uht=r(Too," (Speech2Text model)"),Too.forEach(t),Hht=i(qlo),q7=n(qlo,"LI",{});var Moo=s(q7);bke=n(Moo,"STRONG",{});var Tva=s(bke);Jht=r(Tva,"whisper"),Tva.forEach(t),Yht=r(Moo," \u2014 "),ble=n(Moo,"A",{href:!0});var Mva=s(ble);Zht=r(Mva,"TFWhisperForConditionalGeneration"),Mva.forEach(t),Kht=r(Moo," (Whisper model)"),Moo.forEach(t),qlo.forEach(t),eut=i(Wi),T(j7.$$.fragment,Wi),Wi.forEach(t),Qi.forEach(t),bno=i(c),nf=n(c,"H2",{class:!0});var jlo=s(nf);D7=n(jlo,"A",{id:!0,class:!0,href:!0});var Eva=s(D7);vke=n(Eva,"SPAN",{});var Cva=s(vke);T(OP.$$.fragment,Cva),Cva.forEach(t),Eva.forEach(t),out=i(jlo),Fke=n(jlo,"SPAN",{});var wva=s(Fke);rut=r(wva,"FlaxAutoModel"),wva.forEach(t),jlo.forEach(t),vno=i(c),Ar=n(c,"DIV",{class:!0});var Ui=s(Ar);T(VP.$$.fragment,Ui),tut=i(Ui),sf=n(Ui,"P",{});var Gce=s(sf);aut=r(Gce,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),vle=n(Gce,"A",{href:!0});var Ava=s(vle);nut=r(Ava,"from_pretrained()"),Ava.forEach(t),sut=r(Gce," class method or the "),Fle=n(Gce,"A",{href:!0});var Lva=s(Fle);lut=r(Lva,"from_config()"),Lva.forEach(t),iut=r(Gce,` class
method.`),Gce.forEach(t),dut=i(Ui),XP=n(Ui,"P",{});var Dlo=s(XP);mut=r(Dlo,"This class cannot be instantiated directly using "),Tke=n(Dlo,"CODE",{});var yva=s(Tke);cut=r(yva,"__init__()"),yva.forEach(t),fut=r(Dlo," (throws an error)."),Dlo.forEach(t),gut=i(Ui),ga=n(Ui,"DIV",{class:!0});var Bx=s(ga);T(zP.$$.fragment,Bx),hut=i(Bx),Mke=n(Bx,"P",{});var xva=s(Mke);uut=r(xva,"Instantiates one of the base model classes of the library from a configuration."),xva.forEach(t),put=i(Bx),lf=n(Bx,"P",{});var Oce=s(lf);_ut=r(Oce,`Note:
Loading a model from its configuration file does `),Eke=n(Oce,"STRONG",{});var $va=s(Eke);but=r($va,"not"),$va.forEach(t),vut=r(Oce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Tle=n(Oce,"A",{href:!0});var kva=s(Tle);Fut=r(kva,"from_pretrained()"),kva.forEach(t),Tut=r(Oce," to load the model weights."),Oce.forEach(t),Mut=i(Bx),T(G7.$$.fragment,Bx),Bx.forEach(t),Eut=i(Ui),rt=n(Ui,"DIV",{class:!0});var Hi=s(rt);T(QP.$$.fragment,Hi),Cut=i(Hi),Cke=n(Hi,"P",{});var Sva=s(Cke);wut=r(Sva,"Instantiate one of the base model classes of the library from a pretrained model."),Sva.forEach(t),Aut=i(Hi),Yn=n(Hi,"P",{});var Ix=s(Yn);Lut=r(Ix,"The model class to instantiate is selected based on the "),wke=n(Ix,"CODE",{});var Rva=s(wke);yut=r(Rva,"model_type"),Rva.forEach(t),xut=r(Ix,` property of the config object (either
passed as an argument or loaded from `),Ake=n(Ix,"CODE",{});var Pva=s(Ake);$ut=r(Pva,"pretrained_model_name_or_path"),Pva.forEach(t),kut=r(Ix,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Lke=n(Ix,"CODE",{});var Bva=s(Lke);Sut=r(Bva,"pretrained_model_name_or_path"),Bva.forEach(t),Rut=r(Ix,":"),Ix.forEach(t),Put=i(Hi),te=n(Hi,"UL",{});var ne=s(te);O7=n(ne,"LI",{});var Eoo=s(O7);yke=n(Eoo,"STRONG",{});var Iva=s(yke);But=r(Iva,"albert"),Iva.forEach(t),Iut=r(Eoo," \u2014 "),Mle=n(Eoo,"A",{href:!0});var Nva=s(Mle);Nut=r(Nva,"FlaxAlbertModel"),Nva.forEach(t),qut=r(Eoo," (ALBERT model)"),Eoo.forEach(t),jut=i(ne),V7=n(ne,"LI",{});var Coo=s(V7);xke=n(Coo,"STRONG",{});var qva=s(xke);Dut=r(qva,"bart"),qva.forEach(t),Gut=r(Coo," \u2014 "),Ele=n(Coo,"A",{href:!0});var jva=s(Ele);Out=r(jva,"FlaxBartModel"),jva.forEach(t),Vut=r(Coo," (BART model)"),Coo.forEach(t),Xut=i(ne),X7=n(ne,"LI",{});var woo=s(X7);$ke=n(woo,"STRONG",{});var Dva=s($ke);zut=r(Dva,"beit"),Dva.forEach(t),Qut=r(woo," \u2014 "),Cle=n(woo,"A",{href:!0});var Gva=s(Cle);Wut=r(Gva,"FlaxBeitModel"),Gva.forEach(t),Uut=r(woo," (BEiT model)"),woo.forEach(t),Hut=i(ne),z7=n(ne,"LI",{});var Aoo=s(z7);kke=n(Aoo,"STRONG",{});var Ova=s(kke);Jut=r(Ova,"bert"),Ova.forEach(t),Yut=r(Aoo," \u2014 "),wle=n(Aoo,"A",{href:!0});var Vva=s(wle);Zut=r(Vva,"FlaxBertModel"),Vva.forEach(t),Kut=r(Aoo," (BERT model)"),Aoo.forEach(t),ept=i(ne),Q7=n(ne,"LI",{});var Loo=s(Q7);Ske=n(Loo,"STRONG",{});var Xva=s(Ske);opt=r(Xva,"big_bird"),Xva.forEach(t),rpt=r(Loo," \u2014 "),Ale=n(Loo,"A",{href:!0});var zva=s(Ale);tpt=r(zva,"FlaxBigBirdModel"),zva.forEach(t),apt=r(Loo," (BigBird model)"),Loo.forEach(t),npt=i(ne),W7=n(ne,"LI",{});var yoo=s(W7);Rke=n(yoo,"STRONG",{});var Qva=s(Rke);spt=r(Qva,"blenderbot"),Qva.forEach(t),lpt=r(yoo," \u2014 "),Lle=n(yoo,"A",{href:!0});var Wva=s(Lle);ipt=r(Wva,"FlaxBlenderbotModel"),Wva.forEach(t),dpt=r(yoo," (Blenderbot model)"),yoo.forEach(t),mpt=i(ne),U7=n(ne,"LI",{});var xoo=s(U7);Pke=n(xoo,"STRONG",{});var Uva=s(Pke);cpt=r(Uva,"blenderbot-small"),Uva.forEach(t),fpt=r(xoo," \u2014 "),yle=n(xoo,"A",{href:!0});var Hva=s(yle);gpt=r(Hva,"FlaxBlenderbotSmallModel"),Hva.forEach(t),hpt=r(xoo," (BlenderbotSmall model)"),xoo.forEach(t),upt=i(ne),H7=n(ne,"LI",{});var $oo=s(H7);Bke=n($oo,"STRONG",{});var Jva=s(Bke);ppt=r(Jva,"clip"),Jva.forEach(t),_pt=r($oo," \u2014 "),xle=n($oo,"A",{href:!0});var Yva=s(xle);bpt=r(Yva,"FlaxCLIPModel"),Yva.forEach(t),vpt=r($oo," (CLIP model)"),$oo.forEach(t),Fpt=i(ne),J7=n(ne,"LI",{});var koo=s(J7);Ike=n(koo,"STRONG",{});var Zva=s(Ike);Tpt=r(Zva,"distilbert"),Zva.forEach(t),Mpt=r(koo," \u2014 "),$le=n(koo,"A",{href:!0});var Kva=s($le);Ept=r(Kva,"FlaxDistilBertModel"),Kva.forEach(t),Cpt=r(koo," (DistilBERT model)"),koo.forEach(t),wpt=i(ne),Y7=n(ne,"LI",{});var Soo=s(Y7);Nke=n(Soo,"STRONG",{});var eFa=s(Nke);Apt=r(eFa,"electra"),eFa.forEach(t),Lpt=r(Soo," \u2014 "),kle=n(Soo,"A",{href:!0});var oFa=s(kle);ypt=r(oFa,"FlaxElectraModel"),oFa.forEach(t),xpt=r(Soo," (ELECTRA model)"),Soo.forEach(t),$pt=i(ne),Z7=n(ne,"LI",{});var Roo=s(Z7);qke=n(Roo,"STRONG",{});var rFa=s(qke);kpt=r(rFa,"gpt2"),rFa.forEach(t),Spt=r(Roo," \u2014 "),Sle=n(Roo,"A",{href:!0});var tFa=s(Sle);Rpt=r(tFa,"FlaxGPT2Model"),tFa.forEach(t),Ppt=r(Roo," (OpenAI GPT-2 model)"),Roo.forEach(t),Bpt=i(ne),K7=n(ne,"LI",{});var Poo=s(K7);jke=n(Poo,"STRONG",{});var aFa=s(jke);Ipt=r(aFa,"gpt_neo"),aFa.forEach(t),Npt=r(Poo," \u2014 "),Rle=n(Poo,"A",{href:!0});var nFa=s(Rle);qpt=r(nFa,"FlaxGPTNeoModel"),nFa.forEach(t),jpt=r(Poo," (GPT Neo model)"),Poo.forEach(t),Dpt=i(ne),e8=n(ne,"LI",{});var Boo=s(e8);Dke=n(Boo,"STRONG",{});var sFa=s(Dke);Gpt=r(sFa,"gptj"),sFa.forEach(t),Opt=r(Boo," \u2014 "),Ple=n(Boo,"A",{href:!0});var lFa=s(Ple);Vpt=r(lFa,"FlaxGPTJModel"),lFa.forEach(t),Xpt=r(Boo," (GPT-J model)"),Boo.forEach(t),zpt=i(ne),o8=n(ne,"LI",{});var Ioo=s(o8);Gke=n(Ioo,"STRONG",{});var iFa=s(Gke);Qpt=r(iFa,"longt5"),iFa.forEach(t),Wpt=r(Ioo," \u2014 "),Ble=n(Ioo,"A",{href:!0});var dFa=s(Ble);Upt=r(dFa,"FlaxLongT5Model"),dFa.forEach(t),Hpt=r(Ioo," (LongT5 model)"),Ioo.forEach(t),Jpt=i(ne),r8=n(ne,"LI",{});var Noo=s(r8);Oke=n(Noo,"STRONG",{});var mFa=s(Oke);Ypt=r(mFa,"marian"),mFa.forEach(t),Zpt=r(Noo," \u2014 "),Ile=n(Noo,"A",{href:!0});var cFa=s(Ile);Kpt=r(cFa,"FlaxMarianModel"),cFa.forEach(t),e_t=r(Noo," (Marian model)"),Noo.forEach(t),o_t=i(ne),t8=n(ne,"LI",{});var qoo=s(t8);Vke=n(qoo,"STRONG",{});var fFa=s(Vke);r_t=r(fFa,"mbart"),fFa.forEach(t),t_t=r(qoo," \u2014 "),Nle=n(qoo,"A",{href:!0});var gFa=s(Nle);a_t=r(gFa,"FlaxMBartModel"),gFa.forEach(t),n_t=r(qoo," (mBART model)"),qoo.forEach(t),s_t=i(ne),a8=n(ne,"LI",{});var joo=s(a8);Xke=n(joo,"STRONG",{});var hFa=s(Xke);l_t=r(hFa,"mt5"),hFa.forEach(t),i_t=r(joo," \u2014 "),qle=n(joo,"A",{href:!0});var uFa=s(qle);d_t=r(uFa,"FlaxMT5Model"),uFa.forEach(t),m_t=r(joo," (MT5 model)"),joo.forEach(t),c_t=i(ne),n8=n(ne,"LI",{});var Doo=s(n8);zke=n(Doo,"STRONG",{});var pFa=s(zke);f_t=r(pFa,"opt"),pFa.forEach(t),g_t=r(Doo," \u2014 "),jle=n(Doo,"A",{href:!0});var _Fa=s(jle);h_t=r(_Fa,"FlaxOPTModel"),_Fa.forEach(t),u_t=r(Doo," (OPT model)"),Doo.forEach(t),p_t=i(ne),s8=n(ne,"LI",{});var Goo=s(s8);Qke=n(Goo,"STRONG",{});var bFa=s(Qke);__t=r(bFa,"pegasus"),bFa.forEach(t),b_t=r(Goo," \u2014 "),Dle=n(Goo,"A",{href:!0});var vFa=s(Dle);v_t=r(vFa,"FlaxPegasusModel"),vFa.forEach(t),F_t=r(Goo," (Pegasus model)"),Goo.forEach(t),T_t=i(ne),l8=n(ne,"LI",{});var Ooo=s(l8);Wke=n(Ooo,"STRONG",{});var FFa=s(Wke);M_t=r(FFa,"roberta"),FFa.forEach(t),E_t=r(Ooo," \u2014 "),Gle=n(Ooo,"A",{href:!0});var TFa=s(Gle);C_t=r(TFa,"FlaxRobertaModel"),TFa.forEach(t),w_t=r(Ooo," (RoBERTa model)"),Ooo.forEach(t),A_t=i(ne),i8=n(ne,"LI",{});var Voo=s(i8);Uke=n(Voo,"STRONG",{});var MFa=s(Uke);L_t=r(MFa,"roformer"),MFa.forEach(t),y_t=r(Voo," \u2014 "),Ole=n(Voo,"A",{href:!0});var EFa=s(Ole);x_t=r(EFa,"FlaxRoFormerModel"),EFa.forEach(t),$_t=r(Voo," (RoFormer model)"),Voo.forEach(t),k_t=i(ne),d8=n(ne,"LI",{});var Xoo=s(d8);Hke=n(Xoo,"STRONG",{});var CFa=s(Hke);S_t=r(CFa,"t5"),CFa.forEach(t),R_t=r(Xoo," \u2014 "),Vle=n(Xoo,"A",{href:!0});var wFa=s(Vle);P_t=r(wFa,"FlaxT5Model"),wFa.forEach(t),B_t=r(Xoo," (T5 model)"),Xoo.forEach(t),I_t=i(ne),m8=n(ne,"LI",{});var zoo=s(m8);Jke=n(zoo,"STRONG",{});var AFa=s(Jke);N_t=r(AFa,"vision-text-dual-encoder"),AFa.forEach(t),q_t=r(zoo," \u2014 "),Xle=n(zoo,"A",{href:!0});var LFa=s(Xle);j_t=r(LFa,"FlaxVisionTextDualEncoderModel"),LFa.forEach(t),D_t=r(zoo," (VisionTextDualEncoder model)"),zoo.forEach(t),G_t=i(ne),c8=n(ne,"LI",{});var Qoo=s(c8);Yke=n(Qoo,"STRONG",{});var yFa=s(Yke);O_t=r(yFa,"vit"),yFa.forEach(t),V_t=r(Qoo," \u2014 "),zle=n(Qoo,"A",{href:!0});var xFa=s(zle);X_t=r(xFa,"FlaxViTModel"),xFa.forEach(t),z_t=r(Qoo," (ViT model)"),Qoo.forEach(t),Q_t=i(ne),f8=n(ne,"LI",{});var Woo=s(f8);Zke=n(Woo,"STRONG",{});var $Fa=s(Zke);W_t=r($Fa,"wav2vec2"),$Fa.forEach(t),U_t=r(Woo," \u2014 "),Qle=n(Woo,"A",{href:!0});var kFa=s(Qle);H_t=r(kFa,"FlaxWav2Vec2Model"),kFa.forEach(t),J_t=r(Woo," (Wav2Vec2 model)"),Woo.forEach(t),Y_t=i(ne),g8=n(ne,"LI",{});var Uoo=s(g8);Kke=n(Uoo,"STRONG",{});var SFa=s(Kke);Z_t=r(SFa,"xglm"),SFa.forEach(t),K_t=r(Uoo," \u2014 "),Wle=n(Uoo,"A",{href:!0});var RFa=s(Wle);e1t=r(RFa,"FlaxXGLMModel"),RFa.forEach(t),o1t=r(Uoo," (XGLM model)"),Uoo.forEach(t),r1t=i(ne),h8=n(ne,"LI",{});var Hoo=s(h8);eSe=n(Hoo,"STRONG",{});var PFa=s(eSe);t1t=r(PFa,"xlm-roberta"),PFa.forEach(t),a1t=r(Hoo," \u2014 "),Ule=n(Hoo,"A",{href:!0});var BFa=s(Ule);n1t=r(BFa,"FlaxXLMRobertaModel"),BFa.forEach(t),s1t=r(Hoo," (XLM-RoBERTa model)"),Hoo.forEach(t),ne.forEach(t),l1t=i(Hi),T(u8.$$.fragment,Hi),Hi.forEach(t),Ui.forEach(t),Fno=i(c),df=n(c,"H2",{class:!0});var Glo=s(df);p8=n(Glo,"A",{id:!0,class:!0,href:!0});var IFa=s(p8);oSe=n(IFa,"SPAN",{});var NFa=s(oSe);T(WP.$$.fragment,NFa),NFa.forEach(t),IFa.forEach(t),i1t=i(Glo),rSe=n(Glo,"SPAN",{});var qFa=s(rSe);d1t=r(qFa,"FlaxAutoModelForCausalLM"),qFa.forEach(t),Glo.forEach(t),Tno=i(c),Lr=n(c,"DIV",{class:!0});var Ji=s(Lr);T(UP.$$.fragment,Ji),m1t=i(Ji),mf=n(Ji,"P",{});var Vce=s(mf);c1t=r(Vce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Hle=n(Vce,"A",{href:!0});var jFa=s(Hle);f1t=r(jFa,"from_pretrained()"),jFa.forEach(t),g1t=r(Vce," class method or the "),Jle=n(Vce,"A",{href:!0});var DFa=s(Jle);h1t=r(DFa,"from_config()"),DFa.forEach(t),u1t=r(Vce,` class
method.`),Vce.forEach(t),p1t=i(Ji),HP=n(Ji,"P",{});var Olo=s(HP);_1t=r(Olo,"This class cannot be instantiated directly using "),tSe=n(Olo,"CODE",{});var GFa=s(tSe);b1t=r(GFa,"__init__()"),GFa.forEach(t),v1t=r(Olo," (throws an error)."),Olo.forEach(t),F1t=i(Ji),ha=n(Ji,"DIV",{class:!0});var Nx=s(ha);T(JP.$$.fragment,Nx),T1t=i(Nx),aSe=n(Nx,"P",{});var OFa=s(aSe);M1t=r(OFa,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),OFa.forEach(t),E1t=i(Nx),cf=n(Nx,"P",{});var Xce=s(cf);C1t=r(Xce,`Note:
Loading a model from its configuration file does `),nSe=n(Xce,"STRONG",{});var VFa=s(nSe);w1t=r(VFa,"not"),VFa.forEach(t),A1t=r(Xce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Yle=n(Xce,"A",{href:!0});var XFa=s(Yle);L1t=r(XFa,"from_pretrained()"),XFa.forEach(t),y1t=r(Xce," to load the model weights."),Xce.forEach(t),x1t=i(Nx),T(_8.$$.fragment,Nx),Nx.forEach(t),$1t=i(Ji),tt=n(Ji,"DIV",{class:!0});var Yi=s(tt);T(YP.$$.fragment,Yi),k1t=i(Yi),sSe=n(Yi,"P",{});var zFa=s(sSe);S1t=r(zFa,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),zFa.forEach(t),R1t=i(Yi),Zn=n(Yi,"P",{});var qx=s(Zn);P1t=r(qx,"The model class to instantiate is selected based on the "),lSe=n(qx,"CODE",{});var QFa=s(lSe);B1t=r(QFa,"model_type"),QFa.forEach(t),I1t=r(qx,` property of the config object (either
passed as an argument or loaded from `),iSe=n(qx,"CODE",{});var WFa=s(iSe);N1t=r(WFa,"pretrained_model_name_or_path"),WFa.forEach(t),q1t=r(qx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dSe=n(qx,"CODE",{});var UFa=s(dSe);j1t=r(UFa,"pretrained_model_name_or_path"),UFa.forEach(t),D1t=r(qx,":"),qx.forEach(t),G1t=i(Yi),$e=n(Yi,"UL",{});var je=s($e);b8=n(je,"LI",{});var Joo=s(b8);mSe=n(Joo,"STRONG",{});var HFa=s(mSe);O1t=r(HFa,"bart"),HFa.forEach(t),V1t=r(Joo," \u2014 "),Zle=n(Joo,"A",{href:!0});var JFa=s(Zle);X1t=r(JFa,"FlaxBartForCausalLM"),JFa.forEach(t),z1t=r(Joo," (BART model)"),Joo.forEach(t),Q1t=i(je),v8=n(je,"LI",{});var Yoo=s(v8);cSe=n(Yoo,"STRONG",{});var YFa=s(cSe);W1t=r(YFa,"bert"),YFa.forEach(t),U1t=r(Yoo," \u2014 "),Kle=n(Yoo,"A",{href:!0});var ZFa=s(Kle);H1t=r(ZFa,"FlaxBertForCausalLM"),ZFa.forEach(t),J1t=r(Yoo," (BERT model)"),Yoo.forEach(t),Y1t=i(je),F8=n(je,"LI",{});var Zoo=s(F8);fSe=n(Zoo,"STRONG",{});var KFa=s(fSe);Z1t=r(KFa,"big_bird"),KFa.forEach(t),K1t=r(Zoo," \u2014 "),eie=n(Zoo,"A",{href:!0});var eTa=s(eie);e2t=r(eTa,"FlaxBigBirdForCausalLM"),eTa.forEach(t),o2t=r(Zoo," (BigBird model)"),Zoo.forEach(t),r2t=i(je),T8=n(je,"LI",{});var Koo=s(T8);gSe=n(Koo,"STRONG",{});var oTa=s(gSe);t2t=r(oTa,"electra"),oTa.forEach(t),a2t=r(Koo," \u2014 "),oie=n(Koo,"A",{href:!0});var rTa=s(oie);n2t=r(rTa,"FlaxElectraForCausalLM"),rTa.forEach(t),s2t=r(Koo," (ELECTRA model)"),Koo.forEach(t),l2t=i(je),M8=n(je,"LI",{});var ero=s(M8);hSe=n(ero,"STRONG",{});var tTa=s(hSe);i2t=r(tTa,"gpt2"),tTa.forEach(t),d2t=r(ero," \u2014 "),rie=n(ero,"A",{href:!0});var aTa=s(rie);m2t=r(aTa,"FlaxGPT2LMHeadModel"),aTa.forEach(t),c2t=r(ero," (OpenAI GPT-2 model)"),ero.forEach(t),f2t=i(je),E8=n(je,"LI",{});var oro=s(E8);uSe=n(oro,"STRONG",{});var nTa=s(uSe);g2t=r(nTa,"gpt_neo"),nTa.forEach(t),h2t=r(oro," \u2014 "),tie=n(oro,"A",{href:!0});var sTa=s(tie);u2t=r(sTa,"FlaxGPTNeoForCausalLM"),sTa.forEach(t),p2t=r(oro," (GPT Neo model)"),oro.forEach(t),_2t=i(je),C8=n(je,"LI",{});var rro=s(C8);pSe=n(rro,"STRONG",{});var lTa=s(pSe);b2t=r(lTa,"gptj"),lTa.forEach(t),v2t=r(rro," \u2014 "),aie=n(rro,"A",{href:!0});var iTa=s(aie);F2t=r(iTa,"FlaxGPTJForCausalLM"),iTa.forEach(t),T2t=r(rro," (GPT-J model)"),rro.forEach(t),M2t=i(je),w8=n(je,"LI",{});var tro=s(w8);_Se=n(tro,"STRONG",{});var dTa=s(_Se);E2t=r(dTa,"opt"),dTa.forEach(t),C2t=r(tro," \u2014 "),nie=n(tro,"A",{href:!0});var mTa=s(nie);w2t=r(mTa,"FlaxOPTForCausalLM"),mTa.forEach(t),A2t=r(tro," (OPT model)"),tro.forEach(t),L2t=i(je),A8=n(je,"LI",{});var aro=s(A8);bSe=n(aro,"STRONG",{});var cTa=s(bSe);y2t=r(cTa,"roberta"),cTa.forEach(t),x2t=r(aro," \u2014 "),sie=n(aro,"A",{href:!0});var fTa=s(sie);$2t=r(fTa,"FlaxRobertaForCausalLM"),fTa.forEach(t),k2t=r(aro," (RoBERTa model)"),aro.forEach(t),S2t=i(je),L8=n(je,"LI",{});var nro=s(L8);vSe=n(nro,"STRONG",{});var gTa=s(vSe);R2t=r(gTa,"xglm"),gTa.forEach(t),P2t=r(nro," \u2014 "),lie=n(nro,"A",{href:!0});var hTa=s(lie);B2t=r(hTa,"FlaxXGLMForCausalLM"),hTa.forEach(t),I2t=r(nro," (XGLM model)"),nro.forEach(t),je.forEach(t),N2t=i(Yi),T(y8.$$.fragment,Yi),Yi.forEach(t),Ji.forEach(t),Mno=i(c),ff=n(c,"H2",{class:!0});var Vlo=s(ff);x8=n(Vlo,"A",{id:!0,class:!0,href:!0});var uTa=s(x8);FSe=n(uTa,"SPAN",{});var pTa=s(FSe);T(ZP.$$.fragment,pTa),pTa.forEach(t),uTa.forEach(t),q2t=i(Vlo),TSe=n(Vlo,"SPAN",{});var _Ta=s(TSe);j2t=r(_Ta,"FlaxAutoModelForPreTraining"),_Ta.forEach(t),Vlo.forEach(t),Eno=i(c),yr=n(c,"DIV",{class:!0});var Zi=s(yr);T(KP.$$.fragment,Zi),D2t=i(Zi),gf=n(Zi,"P",{});var zce=s(gf);G2t=r(zce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),iie=n(zce,"A",{href:!0});var bTa=s(iie);O2t=r(bTa,"from_pretrained()"),bTa.forEach(t),V2t=r(zce," class method or the "),die=n(zce,"A",{href:!0});var vTa=s(die);X2t=r(vTa,"from_config()"),vTa.forEach(t),z2t=r(zce,` class
method.`),zce.forEach(t),Q2t=i(Zi),eB=n(Zi,"P",{});var Xlo=s(eB);W2t=r(Xlo,"This class cannot be instantiated directly using "),MSe=n(Xlo,"CODE",{});var FTa=s(MSe);U2t=r(FTa,"__init__()"),FTa.forEach(t),H2t=r(Xlo," (throws an error)."),Xlo.forEach(t),J2t=i(Zi),ua=n(Zi,"DIV",{class:!0});var jx=s(ua);T(oB.$$.fragment,jx),Y2t=i(jx),ESe=n(jx,"P",{});var TTa=s(ESe);Z2t=r(TTa,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),TTa.forEach(t),K2t=i(jx),hf=n(jx,"P",{});var Qce=s(hf);ebt=r(Qce,`Note:
Loading a model from its configuration file does `),CSe=n(Qce,"STRONG",{});var MTa=s(CSe);obt=r(MTa,"not"),MTa.forEach(t),rbt=r(Qce,` load the model weights. It only affects the
model\u2019s configuration. Use `),mie=n(Qce,"A",{href:!0});var ETa=s(mie);tbt=r(ETa,"from_pretrained()"),ETa.forEach(t),abt=r(Qce," to load the model weights."),Qce.forEach(t),nbt=i(jx),T($8.$$.fragment,jx),jx.forEach(t),sbt=i(Zi),at=n(Zi,"DIV",{class:!0});var Ki=s(at);T(rB.$$.fragment,Ki),lbt=i(Ki),wSe=n(Ki,"P",{});var CTa=s(wSe);ibt=r(CTa,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),CTa.forEach(t),dbt=i(Ki),Kn=n(Ki,"P",{});var Dx=s(Kn);mbt=r(Dx,"The model class to instantiate is selected based on the "),ASe=n(Dx,"CODE",{});var wTa=s(ASe);cbt=r(wTa,"model_type"),wTa.forEach(t),fbt=r(Dx,` property of the config object (either
passed as an argument or loaded from `),LSe=n(Dx,"CODE",{});var ATa=s(LSe);gbt=r(ATa,"pretrained_model_name_or_path"),ATa.forEach(t),hbt=r(Dx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ySe=n(Dx,"CODE",{});var LTa=s(ySe);ubt=r(LTa,"pretrained_model_name_or_path"),LTa.forEach(t),pbt=r(Dx,":"),Dx.forEach(t),_bt=i(Ki),Ee=n(Ki,"UL",{});var we=s(Ee);k8=n(we,"LI",{});var sro=s(k8);xSe=n(sro,"STRONG",{});var yTa=s(xSe);bbt=r(yTa,"albert"),yTa.forEach(t),vbt=r(sro," \u2014 "),cie=n(sro,"A",{href:!0});var xTa=s(cie);Fbt=r(xTa,"FlaxAlbertForPreTraining"),xTa.forEach(t),Tbt=r(sro," (ALBERT model)"),sro.forEach(t),Mbt=i(we),S8=n(we,"LI",{});var lro=s(S8);$Se=n(lro,"STRONG",{});var $Ta=s($Se);Ebt=r($Ta,"bart"),$Ta.forEach(t),Cbt=r(lro," \u2014 "),fie=n(lro,"A",{href:!0});var kTa=s(fie);wbt=r(kTa,"FlaxBartForConditionalGeneration"),kTa.forEach(t),Abt=r(lro," (BART model)"),lro.forEach(t),Lbt=i(we),R8=n(we,"LI",{});var iro=s(R8);kSe=n(iro,"STRONG",{});var STa=s(kSe);ybt=r(STa,"bert"),STa.forEach(t),xbt=r(iro," \u2014 "),gie=n(iro,"A",{href:!0});var RTa=s(gie);$bt=r(RTa,"FlaxBertForPreTraining"),RTa.forEach(t),kbt=r(iro," (BERT model)"),iro.forEach(t),Sbt=i(we),P8=n(we,"LI",{});var dro=s(P8);SSe=n(dro,"STRONG",{});var PTa=s(SSe);Rbt=r(PTa,"big_bird"),PTa.forEach(t),Pbt=r(dro," \u2014 "),hie=n(dro,"A",{href:!0});var BTa=s(hie);Bbt=r(BTa,"FlaxBigBirdForPreTraining"),BTa.forEach(t),Ibt=r(dro," (BigBird model)"),dro.forEach(t),Nbt=i(we),B8=n(we,"LI",{});var mro=s(B8);RSe=n(mro,"STRONG",{});var ITa=s(RSe);qbt=r(ITa,"electra"),ITa.forEach(t),jbt=r(mro," \u2014 "),uie=n(mro,"A",{href:!0});var NTa=s(uie);Dbt=r(NTa,"FlaxElectraForPreTraining"),NTa.forEach(t),Gbt=r(mro," (ELECTRA model)"),mro.forEach(t),Obt=i(we),I8=n(we,"LI",{});var cro=s(I8);PSe=n(cro,"STRONG",{});var qTa=s(PSe);Vbt=r(qTa,"longt5"),qTa.forEach(t),Xbt=r(cro," \u2014 "),pie=n(cro,"A",{href:!0});var jTa=s(pie);zbt=r(jTa,"FlaxLongT5ForConditionalGeneration"),jTa.forEach(t),Qbt=r(cro," (LongT5 model)"),cro.forEach(t),Wbt=i(we),N8=n(we,"LI",{});var fro=s(N8);BSe=n(fro,"STRONG",{});var DTa=s(BSe);Ubt=r(DTa,"mbart"),DTa.forEach(t),Hbt=r(fro," \u2014 "),_ie=n(fro,"A",{href:!0});var GTa=s(_ie);Jbt=r(GTa,"FlaxMBartForConditionalGeneration"),GTa.forEach(t),Ybt=r(fro," (mBART model)"),fro.forEach(t),Zbt=i(we),q8=n(we,"LI",{});var gro=s(q8);ISe=n(gro,"STRONG",{});var OTa=s(ISe);Kbt=r(OTa,"mt5"),OTa.forEach(t),evt=r(gro," \u2014 "),bie=n(gro,"A",{href:!0});var VTa=s(bie);ovt=r(VTa,"FlaxMT5ForConditionalGeneration"),VTa.forEach(t),rvt=r(gro," (MT5 model)"),gro.forEach(t),tvt=i(we),j8=n(we,"LI",{});var hro=s(j8);NSe=n(hro,"STRONG",{});var XTa=s(NSe);avt=r(XTa,"roberta"),XTa.forEach(t),nvt=r(hro," \u2014 "),vie=n(hro,"A",{href:!0});var zTa=s(vie);svt=r(zTa,"FlaxRobertaForMaskedLM"),zTa.forEach(t),lvt=r(hro," (RoBERTa model)"),hro.forEach(t),ivt=i(we),D8=n(we,"LI",{});var uro=s(D8);qSe=n(uro,"STRONG",{});var QTa=s(qSe);dvt=r(QTa,"roformer"),QTa.forEach(t),mvt=r(uro," \u2014 "),Fie=n(uro,"A",{href:!0});var WTa=s(Fie);cvt=r(WTa,"FlaxRoFormerForMaskedLM"),WTa.forEach(t),fvt=r(uro," (RoFormer model)"),uro.forEach(t),gvt=i(we),G8=n(we,"LI",{});var pro=s(G8);jSe=n(pro,"STRONG",{});var UTa=s(jSe);hvt=r(UTa,"t5"),UTa.forEach(t),uvt=r(pro," \u2014 "),Tie=n(pro,"A",{href:!0});var HTa=s(Tie);pvt=r(HTa,"FlaxT5ForConditionalGeneration"),HTa.forEach(t),_vt=r(pro," (T5 model)"),pro.forEach(t),bvt=i(we),O8=n(we,"LI",{});var _ro=s(O8);DSe=n(_ro,"STRONG",{});var JTa=s(DSe);vvt=r(JTa,"wav2vec2"),JTa.forEach(t),Fvt=r(_ro," \u2014 "),Mie=n(_ro,"A",{href:!0});var YTa=s(Mie);Tvt=r(YTa,"FlaxWav2Vec2ForPreTraining"),YTa.forEach(t),Mvt=r(_ro," (Wav2Vec2 model)"),_ro.forEach(t),Evt=i(we),V8=n(we,"LI",{});var bro=s(V8);GSe=n(bro,"STRONG",{});var ZTa=s(GSe);Cvt=r(ZTa,"xlm-roberta"),ZTa.forEach(t),wvt=r(bro," \u2014 "),Eie=n(bro,"A",{href:!0});var KTa=s(Eie);Avt=r(KTa,"FlaxXLMRobertaForMaskedLM"),KTa.forEach(t),Lvt=r(bro," (XLM-RoBERTa model)"),bro.forEach(t),we.forEach(t),yvt=i(Ki),T(X8.$$.fragment,Ki),Ki.forEach(t),Zi.forEach(t),Cno=i(c),uf=n(c,"H2",{class:!0});var zlo=s(uf);z8=n(zlo,"A",{id:!0,class:!0,href:!0});var eMa=s(z8);OSe=n(eMa,"SPAN",{});var oMa=s(OSe);T(tB.$$.fragment,oMa),oMa.forEach(t),eMa.forEach(t),xvt=i(zlo),VSe=n(zlo,"SPAN",{});var rMa=s(VSe);$vt=r(rMa,"FlaxAutoModelForMaskedLM"),rMa.forEach(t),zlo.forEach(t),wno=i(c),xr=n(c,"DIV",{class:!0});var ed=s(xr);T(aB.$$.fragment,ed),kvt=i(ed),pf=n(ed,"P",{});var Wce=s(pf);Svt=r(Wce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Cie=n(Wce,"A",{href:!0});var tMa=s(Cie);Rvt=r(tMa,"from_pretrained()"),tMa.forEach(t),Pvt=r(Wce," class method or the "),wie=n(Wce,"A",{href:!0});var aMa=s(wie);Bvt=r(aMa,"from_config()"),aMa.forEach(t),Ivt=r(Wce,` class
method.`),Wce.forEach(t),Nvt=i(ed),nB=n(ed,"P",{});var Qlo=s(nB);qvt=r(Qlo,"This class cannot be instantiated directly using "),XSe=n(Qlo,"CODE",{});var nMa=s(XSe);jvt=r(nMa,"__init__()"),nMa.forEach(t),Dvt=r(Qlo," (throws an error)."),Qlo.forEach(t),Gvt=i(ed),pa=n(ed,"DIV",{class:!0});var Gx=s(pa);T(sB.$$.fragment,Gx),Ovt=i(Gx),zSe=n(Gx,"P",{});var sMa=s(zSe);Vvt=r(sMa,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),sMa.forEach(t),Xvt=i(Gx),_f=n(Gx,"P",{});var Uce=s(_f);zvt=r(Uce,`Note:
Loading a model from its configuration file does `),QSe=n(Uce,"STRONG",{});var lMa=s(QSe);Qvt=r(lMa,"not"),lMa.forEach(t),Wvt=r(Uce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Aie=n(Uce,"A",{href:!0});var iMa=s(Aie);Uvt=r(iMa,"from_pretrained()"),iMa.forEach(t),Hvt=r(Uce," to load the model weights."),Uce.forEach(t),Jvt=i(Gx),T(Q8.$$.fragment,Gx),Gx.forEach(t),Yvt=i(ed),nt=n(ed,"DIV",{class:!0});var od=s(nt);T(lB.$$.fragment,od),Zvt=i(od),WSe=n(od,"P",{});var dMa=s(WSe);Kvt=r(dMa,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),dMa.forEach(t),eFt=i(od),es=n(od,"P",{});var Ox=s(es);oFt=r(Ox,"The model class to instantiate is selected based on the "),USe=n(Ox,"CODE",{});var mMa=s(USe);rFt=r(mMa,"model_type"),mMa.forEach(t),tFt=r(Ox,` property of the config object (either
passed as an argument or loaded from `),HSe=n(Ox,"CODE",{});var cMa=s(HSe);aFt=r(cMa,"pretrained_model_name_or_path"),cMa.forEach(t),nFt=r(Ox,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JSe=n(Ox,"CODE",{});var fMa=s(JSe);sFt=r(fMa,"pretrained_model_name_or_path"),fMa.forEach(t),lFt=r(Ox,":"),Ox.forEach(t),iFt=i(od),ke=n(od,"UL",{});var De=s(ke);W8=n(De,"LI",{});var vro=s(W8);YSe=n(vro,"STRONG",{});var gMa=s(YSe);dFt=r(gMa,"albert"),gMa.forEach(t),mFt=r(vro," \u2014 "),Lie=n(vro,"A",{href:!0});var hMa=s(Lie);cFt=r(hMa,"FlaxAlbertForMaskedLM"),hMa.forEach(t),fFt=r(vro," (ALBERT model)"),vro.forEach(t),gFt=i(De),U8=n(De,"LI",{});var Fro=s(U8);ZSe=n(Fro,"STRONG",{});var uMa=s(ZSe);hFt=r(uMa,"bart"),uMa.forEach(t),uFt=r(Fro," \u2014 "),yie=n(Fro,"A",{href:!0});var pMa=s(yie);pFt=r(pMa,"FlaxBartForConditionalGeneration"),pMa.forEach(t),_Ft=r(Fro," (BART model)"),Fro.forEach(t),bFt=i(De),H8=n(De,"LI",{});var Tro=s(H8);KSe=n(Tro,"STRONG",{});var _Ma=s(KSe);vFt=r(_Ma,"bert"),_Ma.forEach(t),FFt=r(Tro," \u2014 "),xie=n(Tro,"A",{href:!0});var bMa=s(xie);TFt=r(bMa,"FlaxBertForMaskedLM"),bMa.forEach(t),MFt=r(Tro," (BERT model)"),Tro.forEach(t),EFt=i(De),J8=n(De,"LI",{});var Mro=s(J8);eRe=n(Mro,"STRONG",{});var vMa=s(eRe);CFt=r(vMa,"big_bird"),vMa.forEach(t),wFt=r(Mro," \u2014 "),$ie=n(Mro,"A",{href:!0});var FMa=s($ie);AFt=r(FMa,"FlaxBigBirdForMaskedLM"),FMa.forEach(t),LFt=r(Mro," (BigBird model)"),Mro.forEach(t),yFt=i(De),Y8=n(De,"LI",{});var Ero=s(Y8);oRe=n(Ero,"STRONG",{});var TMa=s(oRe);xFt=r(TMa,"distilbert"),TMa.forEach(t),$Ft=r(Ero," \u2014 "),kie=n(Ero,"A",{href:!0});var MMa=s(kie);kFt=r(MMa,"FlaxDistilBertForMaskedLM"),MMa.forEach(t),SFt=r(Ero," (DistilBERT model)"),Ero.forEach(t),RFt=i(De),Z8=n(De,"LI",{});var Cro=s(Z8);rRe=n(Cro,"STRONG",{});var EMa=s(rRe);PFt=r(EMa,"electra"),EMa.forEach(t),BFt=r(Cro," \u2014 "),Sie=n(Cro,"A",{href:!0});var CMa=s(Sie);IFt=r(CMa,"FlaxElectraForMaskedLM"),CMa.forEach(t),NFt=r(Cro," (ELECTRA model)"),Cro.forEach(t),qFt=i(De),K8=n(De,"LI",{});var wro=s(K8);tRe=n(wro,"STRONG",{});var wMa=s(tRe);jFt=r(wMa,"mbart"),wMa.forEach(t),DFt=r(wro," \u2014 "),Rie=n(wro,"A",{href:!0});var AMa=s(Rie);GFt=r(AMa,"FlaxMBartForConditionalGeneration"),AMa.forEach(t),OFt=r(wro," (mBART model)"),wro.forEach(t),VFt=i(De),eL=n(De,"LI",{});var Aro=s(eL);aRe=n(Aro,"STRONG",{});var LMa=s(aRe);XFt=r(LMa,"roberta"),LMa.forEach(t),zFt=r(Aro," \u2014 "),Pie=n(Aro,"A",{href:!0});var yMa=s(Pie);QFt=r(yMa,"FlaxRobertaForMaskedLM"),yMa.forEach(t),WFt=r(Aro," (RoBERTa model)"),Aro.forEach(t),UFt=i(De),oL=n(De,"LI",{});var Lro=s(oL);nRe=n(Lro,"STRONG",{});var xMa=s(nRe);HFt=r(xMa,"roformer"),xMa.forEach(t),JFt=r(Lro," \u2014 "),Bie=n(Lro,"A",{href:!0});var $Ma=s(Bie);YFt=r($Ma,"FlaxRoFormerForMaskedLM"),$Ma.forEach(t),ZFt=r(Lro," (RoFormer model)"),Lro.forEach(t),KFt=i(De),rL=n(De,"LI",{});var yro=s(rL);sRe=n(yro,"STRONG",{});var kMa=s(sRe);eTt=r(kMa,"xlm-roberta"),kMa.forEach(t),oTt=r(yro," \u2014 "),Iie=n(yro,"A",{href:!0});var SMa=s(Iie);rTt=r(SMa,"FlaxXLMRobertaForMaskedLM"),SMa.forEach(t),tTt=r(yro," (XLM-RoBERTa model)"),yro.forEach(t),De.forEach(t),aTt=i(od),T(tL.$$.fragment,od),od.forEach(t),ed.forEach(t),Ano=i(c),bf=n(c,"H2",{class:!0});var Wlo=s(bf);aL=n(Wlo,"A",{id:!0,class:!0,href:!0});var RMa=s(aL);lRe=n(RMa,"SPAN",{});var PMa=s(lRe);T(iB.$$.fragment,PMa),PMa.forEach(t),RMa.forEach(t),nTt=i(Wlo),iRe=n(Wlo,"SPAN",{});var BMa=s(iRe);sTt=r(BMa,"FlaxAutoModelForSeq2SeqLM"),BMa.forEach(t),Wlo.forEach(t),Lno=i(c),$r=n(c,"DIV",{class:!0});var rd=s($r);T(dB.$$.fragment,rd),lTt=i(rd),vf=n(rd,"P",{});var Hce=s(vf);iTt=r(Hce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Nie=n(Hce,"A",{href:!0});var IMa=s(Nie);dTt=r(IMa,"from_pretrained()"),IMa.forEach(t),mTt=r(Hce," class method or the "),qie=n(Hce,"A",{href:!0});var NMa=s(qie);cTt=r(NMa,"from_config()"),NMa.forEach(t),fTt=r(Hce,` class
method.`),Hce.forEach(t),gTt=i(rd),mB=n(rd,"P",{});var Ulo=s(mB);hTt=r(Ulo,"This class cannot be instantiated directly using "),dRe=n(Ulo,"CODE",{});var qMa=s(dRe);uTt=r(qMa,"__init__()"),qMa.forEach(t),pTt=r(Ulo," (throws an error)."),Ulo.forEach(t),_Tt=i(rd),_a=n(rd,"DIV",{class:!0});var Vx=s(_a);T(cB.$$.fragment,Vx),bTt=i(Vx),mRe=n(Vx,"P",{});var jMa=s(mRe);vTt=r(jMa,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),jMa.forEach(t),FTt=i(Vx),Ff=n(Vx,"P",{});var Jce=s(Ff);TTt=r(Jce,`Note:
Loading a model from its configuration file does `),cRe=n(Jce,"STRONG",{});var DMa=s(cRe);MTt=r(DMa,"not"),DMa.forEach(t),ETt=r(Jce,` load the model weights. It only affects the
model\u2019s configuration. Use `),jie=n(Jce,"A",{href:!0});var GMa=s(jie);CTt=r(GMa,"from_pretrained()"),GMa.forEach(t),wTt=r(Jce," to load the model weights."),Jce.forEach(t),ATt=i(Vx),T(nL.$$.fragment,Vx),Vx.forEach(t),LTt=i(rd),st=n(rd,"DIV",{class:!0});var td=s(st);T(fB.$$.fragment,td),yTt=i(td),fRe=n(td,"P",{});var OMa=s(fRe);xTt=r(OMa,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),OMa.forEach(t),$Tt=i(td),os=n(td,"P",{});var Xx=s(os);kTt=r(Xx,"The model class to instantiate is selected based on the "),gRe=n(Xx,"CODE",{});var VMa=s(gRe);STt=r(VMa,"model_type"),VMa.forEach(t),RTt=r(Xx,` property of the config object (either
passed as an argument or loaded from `),hRe=n(Xx,"CODE",{});var XMa=s(hRe);PTt=r(XMa,"pretrained_model_name_or_path"),XMa.forEach(t),BTt=r(Xx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uRe=n(Xx,"CODE",{});var zMa=s(uRe);ITt=r(zMa,"pretrained_model_name_or_path"),zMa.forEach(t),NTt=r(Xx,":"),Xx.forEach(t),qTt=i(td),Se=n(td,"UL",{});var Ge=s(Se);sL=n(Ge,"LI",{});var xro=s(sL);pRe=n(xro,"STRONG",{});var QMa=s(pRe);jTt=r(QMa,"bart"),QMa.forEach(t),DTt=r(xro," \u2014 "),Die=n(xro,"A",{href:!0});var WMa=s(Die);GTt=r(WMa,"FlaxBartForConditionalGeneration"),WMa.forEach(t),OTt=r(xro," (BART model)"),xro.forEach(t),VTt=i(Ge),lL=n(Ge,"LI",{});var $ro=s(lL);_Re=n($ro,"STRONG",{});var UMa=s(_Re);XTt=r(UMa,"blenderbot"),UMa.forEach(t),zTt=r($ro," \u2014 "),Gie=n($ro,"A",{href:!0});var HMa=s(Gie);QTt=r(HMa,"FlaxBlenderbotForConditionalGeneration"),HMa.forEach(t),WTt=r($ro," (Blenderbot model)"),$ro.forEach(t),UTt=i(Ge),iL=n(Ge,"LI",{});var kro=s(iL);bRe=n(kro,"STRONG",{});var JMa=s(bRe);HTt=r(JMa,"blenderbot-small"),JMa.forEach(t),JTt=r(kro," \u2014 "),Oie=n(kro,"A",{href:!0});var YMa=s(Oie);YTt=r(YMa,"FlaxBlenderbotSmallForConditionalGeneration"),YMa.forEach(t),ZTt=r(kro," (BlenderbotSmall model)"),kro.forEach(t),KTt=i(Ge),dL=n(Ge,"LI",{});var Sro=s(dL);vRe=n(Sro,"STRONG",{});var ZMa=s(vRe);eMt=r(ZMa,"encoder-decoder"),ZMa.forEach(t),oMt=r(Sro," \u2014 "),Vie=n(Sro,"A",{href:!0});var KMa=s(Vie);rMt=r(KMa,"FlaxEncoderDecoderModel"),KMa.forEach(t),tMt=r(Sro," (Encoder decoder model)"),Sro.forEach(t),aMt=i(Ge),mL=n(Ge,"LI",{});var Rro=s(mL);FRe=n(Rro,"STRONG",{});var eEa=s(FRe);nMt=r(eEa,"longt5"),eEa.forEach(t),sMt=r(Rro," \u2014 "),Xie=n(Rro,"A",{href:!0});var oEa=s(Xie);lMt=r(oEa,"FlaxLongT5ForConditionalGeneration"),oEa.forEach(t),iMt=r(Rro," (LongT5 model)"),Rro.forEach(t),dMt=i(Ge),cL=n(Ge,"LI",{});var Pro=s(cL);TRe=n(Pro,"STRONG",{});var rEa=s(TRe);mMt=r(rEa,"marian"),rEa.forEach(t),cMt=r(Pro," \u2014 "),zie=n(Pro,"A",{href:!0});var tEa=s(zie);fMt=r(tEa,"FlaxMarianMTModel"),tEa.forEach(t),gMt=r(Pro," (Marian model)"),Pro.forEach(t),hMt=i(Ge),fL=n(Ge,"LI",{});var Bro=s(fL);MRe=n(Bro,"STRONG",{});var aEa=s(MRe);uMt=r(aEa,"mbart"),aEa.forEach(t),pMt=r(Bro," \u2014 "),Qie=n(Bro,"A",{href:!0});var nEa=s(Qie);_Mt=r(nEa,"FlaxMBartForConditionalGeneration"),nEa.forEach(t),bMt=r(Bro," (mBART model)"),Bro.forEach(t),vMt=i(Ge),gL=n(Ge,"LI",{});var Iro=s(gL);ERe=n(Iro,"STRONG",{});var sEa=s(ERe);FMt=r(sEa,"mt5"),sEa.forEach(t),TMt=r(Iro," \u2014 "),Wie=n(Iro,"A",{href:!0});var lEa=s(Wie);MMt=r(lEa,"FlaxMT5ForConditionalGeneration"),lEa.forEach(t),EMt=r(Iro," (MT5 model)"),Iro.forEach(t),CMt=i(Ge),hL=n(Ge,"LI",{});var Nro=s(hL);CRe=n(Nro,"STRONG",{});var iEa=s(CRe);wMt=r(iEa,"pegasus"),iEa.forEach(t),AMt=r(Nro," \u2014 "),Uie=n(Nro,"A",{href:!0});var dEa=s(Uie);LMt=r(dEa,"FlaxPegasusForConditionalGeneration"),dEa.forEach(t),yMt=r(Nro," (Pegasus model)"),Nro.forEach(t),xMt=i(Ge),uL=n(Ge,"LI",{});var qro=s(uL);wRe=n(qro,"STRONG",{});var mEa=s(wRe);$Mt=r(mEa,"t5"),mEa.forEach(t),kMt=r(qro," \u2014 "),Hie=n(qro,"A",{href:!0});var cEa=s(Hie);SMt=r(cEa,"FlaxT5ForConditionalGeneration"),cEa.forEach(t),RMt=r(qro," (T5 model)"),qro.forEach(t),Ge.forEach(t),PMt=i(td),T(pL.$$.fragment,td),td.forEach(t),rd.forEach(t),yno=i(c),Tf=n(c,"H2",{class:!0});var Hlo=s(Tf);_L=n(Hlo,"A",{id:!0,class:!0,href:!0});var fEa=s(_L);ARe=n(fEa,"SPAN",{});var gEa=s(ARe);T(gB.$$.fragment,gEa),gEa.forEach(t),fEa.forEach(t),BMt=i(Hlo),LRe=n(Hlo,"SPAN",{});var hEa=s(LRe);IMt=r(hEa,"FlaxAutoModelForSequenceClassification"),hEa.forEach(t),Hlo.forEach(t),xno=i(c),kr=n(c,"DIV",{class:!0});var ad=s(kr);T(hB.$$.fragment,ad),NMt=i(ad),Mf=n(ad,"P",{});var Yce=s(Mf);qMt=r(Yce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Jie=n(Yce,"A",{href:!0});var uEa=s(Jie);jMt=r(uEa,"from_pretrained()"),uEa.forEach(t),DMt=r(Yce," class method or the "),Yie=n(Yce,"A",{href:!0});var pEa=s(Yie);GMt=r(pEa,"from_config()"),pEa.forEach(t),OMt=r(Yce,` class
method.`),Yce.forEach(t),VMt=i(ad),uB=n(ad,"P",{});var Jlo=s(uB);XMt=r(Jlo,"This class cannot be instantiated directly using "),yRe=n(Jlo,"CODE",{});var _Ea=s(yRe);zMt=r(_Ea,"__init__()"),_Ea.forEach(t),QMt=r(Jlo," (throws an error)."),Jlo.forEach(t),WMt=i(ad),ba=n(ad,"DIV",{class:!0});var zx=s(ba);T(pB.$$.fragment,zx),UMt=i(zx),xRe=n(zx,"P",{});var bEa=s(xRe);HMt=r(bEa,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),bEa.forEach(t),JMt=i(zx),Ef=n(zx,"P",{});var Zce=s(Ef);YMt=r(Zce,`Note:
Loading a model from its configuration file does `),$Re=n(Zce,"STRONG",{});var vEa=s($Re);ZMt=r(vEa,"not"),vEa.forEach(t),KMt=r(Zce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Zie=n(Zce,"A",{href:!0});var FEa=s(Zie);eEt=r(FEa,"from_pretrained()"),FEa.forEach(t),oEt=r(Zce," to load the model weights."),Zce.forEach(t),rEt=i(zx),T(bL.$$.fragment,zx),zx.forEach(t),tEt=i(ad),lt=n(ad,"DIV",{class:!0});var nd=s(lt);T(_B.$$.fragment,nd),aEt=i(nd),kRe=n(nd,"P",{});var TEa=s(kRe);nEt=r(TEa,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),TEa.forEach(t),sEt=i(nd),rs=n(nd,"P",{});var Qx=s(rs);lEt=r(Qx,"The model class to instantiate is selected based on the "),SRe=n(Qx,"CODE",{});var MEa=s(SRe);iEt=r(MEa,"model_type"),MEa.forEach(t),dEt=r(Qx,` property of the config object (either
passed as an argument or loaded from `),RRe=n(Qx,"CODE",{});var EEa=s(RRe);mEt=r(EEa,"pretrained_model_name_or_path"),EEa.forEach(t),cEt=r(Qx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),PRe=n(Qx,"CODE",{});var CEa=s(PRe);fEt=r(CEa,"pretrained_model_name_or_path"),CEa.forEach(t),gEt=r(Qx,":"),Qx.forEach(t),hEt=i(nd),Re=n(nd,"UL",{});var Oe=s(Re);vL=n(Oe,"LI",{});var jro=s(vL);BRe=n(jro,"STRONG",{});var wEa=s(BRe);uEt=r(wEa,"albert"),wEa.forEach(t),pEt=r(jro," \u2014 "),Kie=n(jro,"A",{href:!0});var AEa=s(Kie);_Et=r(AEa,"FlaxAlbertForSequenceClassification"),AEa.forEach(t),bEt=r(jro," (ALBERT model)"),jro.forEach(t),vEt=i(Oe),FL=n(Oe,"LI",{});var Dro=s(FL);IRe=n(Dro,"STRONG",{});var LEa=s(IRe);FEt=r(LEa,"bart"),LEa.forEach(t),TEt=r(Dro," \u2014 "),ede=n(Dro,"A",{href:!0});var yEa=s(ede);MEt=r(yEa,"FlaxBartForSequenceClassification"),yEa.forEach(t),EEt=r(Dro," (BART model)"),Dro.forEach(t),CEt=i(Oe),TL=n(Oe,"LI",{});var Gro=s(TL);NRe=n(Gro,"STRONG",{});var xEa=s(NRe);wEt=r(xEa,"bert"),xEa.forEach(t),AEt=r(Gro," \u2014 "),ode=n(Gro,"A",{href:!0});var $Ea=s(ode);LEt=r($Ea,"FlaxBertForSequenceClassification"),$Ea.forEach(t),yEt=r(Gro," (BERT model)"),Gro.forEach(t),xEt=i(Oe),ML=n(Oe,"LI",{});var Oro=s(ML);qRe=n(Oro,"STRONG",{});var kEa=s(qRe);$Et=r(kEa,"big_bird"),kEa.forEach(t),kEt=r(Oro," \u2014 "),rde=n(Oro,"A",{href:!0});var SEa=s(rde);SEt=r(SEa,"FlaxBigBirdForSequenceClassification"),SEa.forEach(t),REt=r(Oro," (BigBird model)"),Oro.forEach(t),PEt=i(Oe),EL=n(Oe,"LI",{});var Vro=s(EL);jRe=n(Vro,"STRONG",{});var REa=s(jRe);BEt=r(REa,"distilbert"),REa.forEach(t),IEt=r(Vro," \u2014 "),tde=n(Vro,"A",{href:!0});var PEa=s(tde);NEt=r(PEa,"FlaxDistilBertForSequenceClassification"),PEa.forEach(t),qEt=r(Vro," (DistilBERT model)"),Vro.forEach(t),jEt=i(Oe),CL=n(Oe,"LI",{});var Xro=s(CL);DRe=n(Xro,"STRONG",{});var BEa=s(DRe);DEt=r(BEa,"electra"),BEa.forEach(t),GEt=r(Xro," \u2014 "),ade=n(Xro,"A",{href:!0});var IEa=s(ade);OEt=r(IEa,"FlaxElectraForSequenceClassification"),IEa.forEach(t),VEt=r(Xro," (ELECTRA model)"),Xro.forEach(t),XEt=i(Oe),wL=n(Oe,"LI",{});var zro=s(wL);GRe=n(zro,"STRONG",{});var NEa=s(GRe);zEt=r(NEa,"mbart"),NEa.forEach(t),QEt=r(zro," \u2014 "),nde=n(zro,"A",{href:!0});var qEa=s(nde);WEt=r(qEa,"FlaxMBartForSequenceClassification"),qEa.forEach(t),UEt=r(zro," (mBART model)"),zro.forEach(t),HEt=i(Oe),AL=n(Oe,"LI",{});var Qro=s(AL);ORe=n(Qro,"STRONG",{});var jEa=s(ORe);JEt=r(jEa,"roberta"),jEa.forEach(t),YEt=r(Qro," \u2014 "),sde=n(Qro,"A",{href:!0});var DEa=s(sde);ZEt=r(DEa,"FlaxRobertaForSequenceClassification"),DEa.forEach(t),KEt=r(Qro," (RoBERTa model)"),Qro.forEach(t),e4t=i(Oe),LL=n(Oe,"LI",{});var Wro=s(LL);VRe=n(Wro,"STRONG",{});var GEa=s(VRe);o4t=r(GEa,"roformer"),GEa.forEach(t),r4t=r(Wro," \u2014 "),lde=n(Wro,"A",{href:!0});var OEa=s(lde);t4t=r(OEa,"FlaxRoFormerForSequenceClassification"),OEa.forEach(t),a4t=r(Wro," (RoFormer model)"),Wro.forEach(t),n4t=i(Oe),yL=n(Oe,"LI",{});var Uro=s(yL);XRe=n(Uro,"STRONG",{});var VEa=s(XRe);s4t=r(VEa,"xlm-roberta"),VEa.forEach(t),l4t=r(Uro," \u2014 "),ide=n(Uro,"A",{href:!0});var XEa=s(ide);i4t=r(XEa,"FlaxXLMRobertaForSequenceClassification"),XEa.forEach(t),d4t=r(Uro," (XLM-RoBERTa model)"),Uro.forEach(t),Oe.forEach(t),m4t=i(nd),T(xL.$$.fragment,nd),nd.forEach(t),ad.forEach(t),$no=i(c),Cf=n(c,"H2",{class:!0});var Ylo=s(Cf);$L=n(Ylo,"A",{id:!0,class:!0,href:!0});var zEa=s($L);zRe=n(zEa,"SPAN",{});var QEa=s(zRe);T(bB.$$.fragment,QEa),QEa.forEach(t),zEa.forEach(t),c4t=i(Ylo),QRe=n(Ylo,"SPAN",{});var WEa=s(QRe);f4t=r(WEa,"FlaxAutoModelForQuestionAnswering"),WEa.forEach(t),Ylo.forEach(t),kno=i(c),Sr=n(c,"DIV",{class:!0});var sd=s(Sr);T(vB.$$.fragment,sd),g4t=i(sd),wf=n(sd,"P",{});var Kce=s(wf);h4t=r(Kce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),dde=n(Kce,"A",{href:!0});var UEa=s(dde);u4t=r(UEa,"from_pretrained()"),UEa.forEach(t),p4t=r(Kce," class method or the "),mde=n(Kce,"A",{href:!0});var HEa=s(mde);_4t=r(HEa,"from_config()"),HEa.forEach(t),b4t=r(Kce,` class
method.`),Kce.forEach(t),v4t=i(sd),FB=n(sd,"P",{});var Zlo=s(FB);F4t=r(Zlo,"This class cannot be instantiated directly using "),WRe=n(Zlo,"CODE",{});var JEa=s(WRe);T4t=r(JEa,"__init__()"),JEa.forEach(t),M4t=r(Zlo," (throws an error)."),Zlo.forEach(t),E4t=i(sd),va=n(sd,"DIV",{class:!0});var Wx=s(va);T(TB.$$.fragment,Wx),C4t=i(Wx),URe=n(Wx,"P",{});var YEa=s(URe);w4t=r(YEa,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),YEa.forEach(t),A4t=i(Wx),Af=n(Wx,"P",{});var efe=s(Af);L4t=r(efe,`Note:
Loading a model from its configuration file does `),HRe=n(efe,"STRONG",{});var ZEa=s(HRe);y4t=r(ZEa,"not"),ZEa.forEach(t),x4t=r(efe,` load the model weights. It only affects the
model\u2019s configuration. Use `),cde=n(efe,"A",{href:!0});var KEa=s(cde);$4t=r(KEa,"from_pretrained()"),KEa.forEach(t),k4t=r(efe," to load the model weights."),efe.forEach(t),S4t=i(Wx),T(kL.$$.fragment,Wx),Wx.forEach(t),R4t=i(sd),it=n(sd,"DIV",{class:!0});var ld=s(it);T(MB.$$.fragment,ld),P4t=i(ld),JRe=n(ld,"P",{});var e4a=s(JRe);B4t=r(e4a,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),e4a.forEach(t),I4t=i(ld),ts=n(ld,"P",{});var Ux=s(ts);N4t=r(Ux,"The model class to instantiate is selected based on the "),YRe=n(Ux,"CODE",{});var o4a=s(YRe);q4t=r(o4a,"model_type"),o4a.forEach(t),j4t=r(Ux,` property of the config object (either
passed as an argument or loaded from `),ZRe=n(Ux,"CODE",{});var r4a=s(ZRe);D4t=r(r4a,"pretrained_model_name_or_path"),r4a.forEach(t),G4t=r(Ux,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KRe=n(Ux,"CODE",{});var t4a=s(KRe);O4t=r(t4a,"pretrained_model_name_or_path"),t4a.forEach(t),V4t=r(Ux,":"),Ux.forEach(t),X4t=i(ld),Pe=n(ld,"UL",{});var Ve=s(Pe);SL=n(Ve,"LI",{});var Hro=s(SL);ePe=n(Hro,"STRONG",{});var a4a=s(ePe);z4t=r(a4a,"albert"),a4a.forEach(t),Q4t=r(Hro," \u2014 "),fde=n(Hro,"A",{href:!0});var n4a=s(fde);W4t=r(n4a,"FlaxAlbertForQuestionAnswering"),n4a.forEach(t),U4t=r(Hro," (ALBERT model)"),Hro.forEach(t),H4t=i(Ve),RL=n(Ve,"LI",{});var Jro=s(RL);oPe=n(Jro,"STRONG",{});var s4a=s(oPe);J4t=r(s4a,"bart"),s4a.forEach(t),Y4t=r(Jro," \u2014 "),gde=n(Jro,"A",{href:!0});var l4a=s(gde);Z4t=r(l4a,"FlaxBartForQuestionAnswering"),l4a.forEach(t),K4t=r(Jro," (BART model)"),Jro.forEach(t),eCt=i(Ve),PL=n(Ve,"LI",{});var Yro=s(PL);rPe=n(Yro,"STRONG",{});var i4a=s(rPe);oCt=r(i4a,"bert"),i4a.forEach(t),rCt=r(Yro," \u2014 "),hde=n(Yro,"A",{href:!0});var d4a=s(hde);tCt=r(d4a,"FlaxBertForQuestionAnswering"),d4a.forEach(t),aCt=r(Yro," (BERT model)"),Yro.forEach(t),nCt=i(Ve),BL=n(Ve,"LI",{});var Zro=s(BL);tPe=n(Zro,"STRONG",{});var m4a=s(tPe);sCt=r(m4a,"big_bird"),m4a.forEach(t),lCt=r(Zro," \u2014 "),ude=n(Zro,"A",{href:!0});var c4a=s(ude);iCt=r(c4a,"FlaxBigBirdForQuestionAnswering"),c4a.forEach(t),dCt=r(Zro," (BigBird model)"),Zro.forEach(t),mCt=i(Ve),IL=n(Ve,"LI",{});var Kro=s(IL);aPe=n(Kro,"STRONG",{});var f4a=s(aPe);cCt=r(f4a,"distilbert"),f4a.forEach(t),fCt=r(Kro," \u2014 "),pde=n(Kro,"A",{href:!0});var g4a=s(pde);gCt=r(g4a,"FlaxDistilBertForQuestionAnswering"),g4a.forEach(t),hCt=r(Kro," (DistilBERT model)"),Kro.forEach(t),uCt=i(Ve),NL=n(Ve,"LI",{});var eto=s(NL);nPe=n(eto,"STRONG",{});var h4a=s(nPe);pCt=r(h4a,"electra"),h4a.forEach(t),_Ct=r(eto," \u2014 "),_de=n(eto,"A",{href:!0});var u4a=s(_de);bCt=r(u4a,"FlaxElectraForQuestionAnswering"),u4a.forEach(t),vCt=r(eto," (ELECTRA model)"),eto.forEach(t),FCt=i(Ve),qL=n(Ve,"LI",{});var oto=s(qL);sPe=n(oto,"STRONG",{});var p4a=s(sPe);TCt=r(p4a,"mbart"),p4a.forEach(t),MCt=r(oto," \u2014 "),bde=n(oto,"A",{href:!0});var _4a=s(bde);ECt=r(_4a,"FlaxMBartForQuestionAnswering"),_4a.forEach(t),CCt=r(oto," (mBART model)"),oto.forEach(t),wCt=i(Ve),jL=n(Ve,"LI",{});var rto=s(jL);lPe=n(rto,"STRONG",{});var b4a=s(lPe);ACt=r(b4a,"roberta"),b4a.forEach(t),LCt=r(rto," \u2014 "),vde=n(rto,"A",{href:!0});var v4a=s(vde);yCt=r(v4a,"FlaxRobertaForQuestionAnswering"),v4a.forEach(t),xCt=r(rto," (RoBERTa model)"),rto.forEach(t),$Ct=i(Ve),DL=n(Ve,"LI",{});var tto=s(DL);iPe=n(tto,"STRONG",{});var F4a=s(iPe);kCt=r(F4a,"roformer"),F4a.forEach(t),SCt=r(tto," \u2014 "),Fde=n(tto,"A",{href:!0});var T4a=s(Fde);RCt=r(T4a,"FlaxRoFormerForQuestionAnswering"),T4a.forEach(t),PCt=r(tto," (RoFormer model)"),tto.forEach(t),BCt=i(Ve),GL=n(Ve,"LI",{});var ato=s(GL);dPe=n(ato,"STRONG",{});var M4a=s(dPe);ICt=r(M4a,"xlm-roberta"),M4a.forEach(t),NCt=r(ato," \u2014 "),Tde=n(ato,"A",{href:!0});var E4a=s(Tde);qCt=r(E4a,"FlaxXLMRobertaForQuestionAnswering"),E4a.forEach(t),jCt=r(ato," (XLM-RoBERTa model)"),ato.forEach(t),Ve.forEach(t),DCt=i(ld),T(OL.$$.fragment,ld),ld.forEach(t),sd.forEach(t),Sno=i(c),Lf=n(c,"H2",{class:!0});var Klo=s(Lf);VL=n(Klo,"A",{id:!0,class:!0,href:!0});var C4a=s(VL);mPe=n(C4a,"SPAN",{});var w4a=s(mPe);T(EB.$$.fragment,w4a),w4a.forEach(t),C4a.forEach(t),GCt=i(Klo),cPe=n(Klo,"SPAN",{});var A4a=s(cPe);OCt=r(A4a,"FlaxAutoModelForTokenClassification"),A4a.forEach(t),Klo.forEach(t),Rno=i(c),Rr=n(c,"DIV",{class:!0});var id=s(Rr);T(CB.$$.fragment,id),VCt=i(id),yf=n(id,"P",{});var ofe=s(yf);XCt=r(ofe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Mde=n(ofe,"A",{href:!0});var L4a=s(Mde);zCt=r(L4a,"from_pretrained()"),L4a.forEach(t),QCt=r(ofe," class method or the "),Ede=n(ofe,"A",{href:!0});var y4a=s(Ede);WCt=r(y4a,"from_config()"),y4a.forEach(t),UCt=r(ofe,` class
method.`),ofe.forEach(t),HCt=i(id),wB=n(id,"P",{});var eio=s(wB);JCt=r(eio,"This class cannot be instantiated directly using "),fPe=n(eio,"CODE",{});var x4a=s(fPe);YCt=r(x4a,"__init__()"),x4a.forEach(t),ZCt=r(eio," (throws an error)."),eio.forEach(t),KCt=i(id),Fa=n(id,"DIV",{class:!0});var Hx=s(Fa);T(AB.$$.fragment,Hx),e3t=i(Hx),gPe=n(Hx,"P",{});var $4a=s(gPe);o3t=r($4a,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),$4a.forEach(t),r3t=i(Hx),xf=n(Hx,"P",{});var rfe=s(xf);t3t=r(rfe,`Note:
Loading a model from its configuration file does `),hPe=n(rfe,"STRONG",{});var k4a=s(hPe);a3t=r(k4a,"not"),k4a.forEach(t),n3t=r(rfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Cde=n(rfe,"A",{href:!0});var S4a=s(Cde);s3t=r(S4a,"from_pretrained()"),S4a.forEach(t),l3t=r(rfe," to load the model weights."),rfe.forEach(t),i3t=i(Hx),T(XL.$$.fragment,Hx),Hx.forEach(t),d3t=i(id),dt=n(id,"DIV",{class:!0});var dd=s(dt);T(LB.$$.fragment,dd),m3t=i(dd),uPe=n(dd,"P",{});var R4a=s(uPe);c3t=r(R4a,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),R4a.forEach(t),f3t=i(dd),as=n(dd,"P",{});var Jx=s(as);g3t=r(Jx,"The model class to instantiate is selected based on the "),pPe=n(Jx,"CODE",{});var P4a=s(pPe);h3t=r(P4a,"model_type"),P4a.forEach(t),u3t=r(Jx,` property of the config object (either
passed as an argument or loaded from `),_Pe=n(Jx,"CODE",{});var B4a=s(_Pe);p3t=r(B4a,"pretrained_model_name_or_path"),B4a.forEach(t),_3t=r(Jx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bPe=n(Jx,"CODE",{});var I4a=s(bPe);b3t=r(I4a,"pretrained_model_name_or_path"),I4a.forEach(t),v3t=r(Jx,":"),Jx.forEach(t),F3t=i(dd),ze=n(dd,"UL",{});var yo=s(ze);zL=n(yo,"LI",{});var nto=s(zL);vPe=n(nto,"STRONG",{});var N4a=s(vPe);T3t=r(N4a,"albert"),N4a.forEach(t),M3t=r(nto," \u2014 "),wde=n(nto,"A",{href:!0});var q4a=s(wde);E3t=r(q4a,"FlaxAlbertForTokenClassification"),q4a.forEach(t),C3t=r(nto," (ALBERT model)"),nto.forEach(t),w3t=i(yo),QL=n(yo,"LI",{});var sto=s(QL);FPe=n(sto,"STRONG",{});var j4a=s(FPe);A3t=r(j4a,"bert"),j4a.forEach(t),L3t=r(sto," \u2014 "),Ade=n(sto,"A",{href:!0});var D4a=s(Ade);y3t=r(D4a,"FlaxBertForTokenClassification"),D4a.forEach(t),x3t=r(sto," (BERT model)"),sto.forEach(t),$3t=i(yo),WL=n(yo,"LI",{});var lto=s(WL);TPe=n(lto,"STRONG",{});var G4a=s(TPe);k3t=r(G4a,"big_bird"),G4a.forEach(t),S3t=r(lto," \u2014 "),Lde=n(lto,"A",{href:!0});var O4a=s(Lde);R3t=r(O4a,"FlaxBigBirdForTokenClassification"),O4a.forEach(t),P3t=r(lto," (BigBird model)"),lto.forEach(t),B3t=i(yo),UL=n(yo,"LI",{});var ito=s(UL);MPe=n(ito,"STRONG",{});var V4a=s(MPe);I3t=r(V4a,"distilbert"),V4a.forEach(t),N3t=r(ito," \u2014 "),yde=n(ito,"A",{href:!0});var X4a=s(yde);q3t=r(X4a,"FlaxDistilBertForTokenClassification"),X4a.forEach(t),j3t=r(ito," (DistilBERT model)"),ito.forEach(t),D3t=i(yo),HL=n(yo,"LI",{});var dto=s(HL);EPe=n(dto,"STRONG",{});var z4a=s(EPe);G3t=r(z4a,"electra"),z4a.forEach(t),O3t=r(dto," \u2014 "),xde=n(dto,"A",{href:!0});var Q4a=s(xde);V3t=r(Q4a,"FlaxElectraForTokenClassification"),Q4a.forEach(t),X3t=r(dto," (ELECTRA model)"),dto.forEach(t),z3t=i(yo),JL=n(yo,"LI",{});var mto=s(JL);CPe=n(mto,"STRONG",{});var W4a=s(CPe);Q3t=r(W4a,"roberta"),W4a.forEach(t),W3t=r(mto," \u2014 "),$de=n(mto,"A",{href:!0});var U4a=s($de);U3t=r(U4a,"FlaxRobertaForTokenClassification"),U4a.forEach(t),H3t=r(mto," (RoBERTa model)"),mto.forEach(t),J3t=i(yo),YL=n(yo,"LI",{});var cto=s(YL);wPe=n(cto,"STRONG",{});var H4a=s(wPe);Y3t=r(H4a,"roformer"),H4a.forEach(t),Z3t=r(cto," \u2014 "),kde=n(cto,"A",{href:!0});var J4a=s(kde);K3t=r(J4a,"FlaxRoFormerForTokenClassification"),J4a.forEach(t),e5t=r(cto," (RoFormer model)"),cto.forEach(t),o5t=i(yo),ZL=n(yo,"LI",{});var fto=s(ZL);APe=n(fto,"STRONG",{});var Y4a=s(APe);r5t=r(Y4a,"xlm-roberta"),Y4a.forEach(t),t5t=r(fto," \u2014 "),Sde=n(fto,"A",{href:!0});var Z4a=s(Sde);a5t=r(Z4a,"FlaxXLMRobertaForTokenClassification"),Z4a.forEach(t),n5t=r(fto," (XLM-RoBERTa model)"),fto.forEach(t),yo.forEach(t),s5t=i(dd),T(KL.$$.fragment,dd),dd.forEach(t),id.forEach(t),Pno=i(c),$f=n(c,"H2",{class:!0});var oio=s($f);ey=n(oio,"A",{id:!0,class:!0,href:!0});var K4a=s(ey);LPe=n(K4a,"SPAN",{});var eCa=s(LPe);T(yB.$$.fragment,eCa),eCa.forEach(t),K4a.forEach(t),l5t=i(oio),yPe=n(oio,"SPAN",{});var oCa=s(yPe);i5t=r(oCa,"FlaxAutoModelForMultipleChoice"),oCa.forEach(t),oio.forEach(t),Bno=i(c),Pr=n(c,"DIV",{class:!0});var md=s(Pr);T(xB.$$.fragment,md),d5t=i(md),kf=n(md,"P",{});var tfe=s(kf);m5t=r(tfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Rde=n(tfe,"A",{href:!0});var rCa=s(Rde);c5t=r(rCa,"from_pretrained()"),rCa.forEach(t),f5t=r(tfe," class method or the "),Pde=n(tfe,"A",{href:!0});var tCa=s(Pde);g5t=r(tCa,"from_config()"),tCa.forEach(t),h5t=r(tfe,` class
method.`),tfe.forEach(t),u5t=i(md),$B=n(md,"P",{});var rio=s($B);p5t=r(rio,"This class cannot be instantiated directly using "),xPe=n(rio,"CODE",{});var aCa=s(xPe);_5t=r(aCa,"__init__()"),aCa.forEach(t),b5t=r(rio," (throws an error)."),rio.forEach(t),v5t=i(md),Ta=n(md,"DIV",{class:!0});var Yx=s(Ta);T(kB.$$.fragment,Yx),F5t=i(Yx),$Pe=n(Yx,"P",{});var nCa=s($Pe);T5t=r(nCa,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),nCa.forEach(t),M5t=i(Yx),Sf=n(Yx,"P",{});var afe=s(Sf);E5t=r(afe,`Note:
Loading a model from its configuration file does `),kPe=n(afe,"STRONG",{});var sCa=s(kPe);C5t=r(sCa,"not"),sCa.forEach(t),w5t=r(afe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Bde=n(afe,"A",{href:!0});var lCa=s(Bde);A5t=r(lCa,"from_pretrained()"),lCa.forEach(t),L5t=r(afe," to load the model weights."),afe.forEach(t),y5t=i(Yx),T(oy.$$.fragment,Yx),Yx.forEach(t),x5t=i(md),mt=n(md,"DIV",{class:!0});var cd=s(mt);T(SB.$$.fragment,cd),$5t=i(cd),SPe=n(cd,"P",{});var iCa=s(SPe);k5t=r(iCa,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),iCa.forEach(t),S5t=i(cd),ns=n(cd,"P",{});var Zx=s(ns);R5t=r(Zx,"The model class to instantiate is selected based on the "),RPe=n(Zx,"CODE",{});var dCa=s(RPe);P5t=r(dCa,"model_type"),dCa.forEach(t),B5t=r(Zx,` property of the config object (either
passed as an argument or loaded from `),PPe=n(Zx,"CODE",{});var mCa=s(PPe);I5t=r(mCa,"pretrained_model_name_or_path"),mCa.forEach(t),N5t=r(Zx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),BPe=n(Zx,"CODE",{});var cCa=s(BPe);q5t=r(cCa,"pretrained_model_name_or_path"),cCa.forEach(t),j5t=r(Zx,":"),Zx.forEach(t),D5t=i(cd),Qe=n(cd,"UL",{});var xo=s(Qe);ry=n(xo,"LI",{});var gto=s(ry);IPe=n(gto,"STRONG",{});var fCa=s(IPe);G5t=r(fCa,"albert"),fCa.forEach(t),O5t=r(gto," \u2014 "),Ide=n(gto,"A",{href:!0});var gCa=s(Ide);V5t=r(gCa,"FlaxAlbertForMultipleChoice"),gCa.forEach(t),X5t=r(gto," (ALBERT model)"),gto.forEach(t),z5t=i(xo),ty=n(xo,"LI",{});var hto=s(ty);NPe=n(hto,"STRONG",{});var hCa=s(NPe);Q5t=r(hCa,"bert"),hCa.forEach(t),W5t=r(hto," \u2014 "),Nde=n(hto,"A",{href:!0});var uCa=s(Nde);U5t=r(uCa,"FlaxBertForMultipleChoice"),uCa.forEach(t),H5t=r(hto," (BERT model)"),hto.forEach(t),J5t=i(xo),ay=n(xo,"LI",{});var uto=s(ay);qPe=n(uto,"STRONG",{});var pCa=s(qPe);Y5t=r(pCa,"big_bird"),pCa.forEach(t),Z5t=r(uto," \u2014 "),qde=n(uto,"A",{href:!0});var _Ca=s(qde);K5t=r(_Ca,"FlaxBigBirdForMultipleChoice"),_Ca.forEach(t),e0t=r(uto," (BigBird model)"),uto.forEach(t),o0t=i(xo),ny=n(xo,"LI",{});var pto=s(ny);jPe=n(pto,"STRONG",{});var bCa=s(jPe);r0t=r(bCa,"distilbert"),bCa.forEach(t),t0t=r(pto," \u2014 "),jde=n(pto,"A",{href:!0});var vCa=s(jde);a0t=r(vCa,"FlaxDistilBertForMultipleChoice"),vCa.forEach(t),n0t=r(pto," (DistilBERT model)"),pto.forEach(t),s0t=i(xo),sy=n(xo,"LI",{});var _to=s(sy);DPe=n(_to,"STRONG",{});var FCa=s(DPe);l0t=r(FCa,"electra"),FCa.forEach(t),i0t=r(_to," \u2014 "),Dde=n(_to,"A",{href:!0});var TCa=s(Dde);d0t=r(TCa,"FlaxElectraForMultipleChoice"),TCa.forEach(t),m0t=r(_to," (ELECTRA model)"),_to.forEach(t),c0t=i(xo),ly=n(xo,"LI",{});var bto=s(ly);GPe=n(bto,"STRONG",{});var MCa=s(GPe);f0t=r(MCa,"roberta"),MCa.forEach(t),g0t=r(bto," \u2014 "),Gde=n(bto,"A",{href:!0});var ECa=s(Gde);h0t=r(ECa,"FlaxRobertaForMultipleChoice"),ECa.forEach(t),u0t=r(bto," (RoBERTa model)"),bto.forEach(t),p0t=i(xo),iy=n(xo,"LI",{});var vto=s(iy);OPe=n(vto,"STRONG",{});var CCa=s(OPe);_0t=r(CCa,"roformer"),CCa.forEach(t),b0t=r(vto," \u2014 "),Ode=n(vto,"A",{href:!0});var wCa=s(Ode);v0t=r(wCa,"FlaxRoFormerForMultipleChoice"),wCa.forEach(t),F0t=r(vto," (RoFormer model)"),vto.forEach(t),T0t=i(xo),dy=n(xo,"LI",{});var Fto=s(dy);VPe=n(Fto,"STRONG",{});var ACa=s(VPe);M0t=r(ACa,"xlm-roberta"),ACa.forEach(t),E0t=r(Fto," \u2014 "),Vde=n(Fto,"A",{href:!0});var LCa=s(Vde);C0t=r(LCa,"FlaxXLMRobertaForMultipleChoice"),LCa.forEach(t),w0t=r(Fto," (XLM-RoBERTa model)"),Fto.forEach(t),xo.forEach(t),A0t=i(cd),T(my.$$.fragment,cd),cd.forEach(t),md.forEach(t),Ino=i(c),Rf=n(c,"H2",{class:!0});var tio=s(Rf);cy=n(tio,"A",{id:!0,class:!0,href:!0});var yCa=s(cy);XPe=n(yCa,"SPAN",{});var xCa=s(XPe);T(RB.$$.fragment,xCa),xCa.forEach(t),yCa.forEach(t),L0t=i(tio),zPe=n(tio,"SPAN",{});var $Ca=s(zPe);y0t=r($Ca,"FlaxAutoModelForNextSentencePrediction"),$Ca.forEach(t),tio.forEach(t),Nno=i(c),Br=n(c,"DIV",{class:!0});var fd=s(Br);T(PB.$$.fragment,fd),x0t=i(fd),Pf=n(fd,"P",{});var nfe=s(Pf);$0t=r(nfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Xde=n(nfe,"A",{href:!0});var kCa=s(Xde);k0t=r(kCa,"from_pretrained()"),kCa.forEach(t),S0t=r(nfe," class method or the "),zde=n(nfe,"A",{href:!0});var SCa=s(zde);R0t=r(SCa,"from_config()"),SCa.forEach(t),P0t=r(nfe,` class
method.`),nfe.forEach(t),B0t=i(fd),BB=n(fd,"P",{});var aio=s(BB);I0t=r(aio,"This class cannot be instantiated directly using "),QPe=n(aio,"CODE",{});var RCa=s(QPe);N0t=r(RCa,"__init__()"),RCa.forEach(t),q0t=r(aio," (throws an error)."),aio.forEach(t),j0t=i(fd),Ma=n(fd,"DIV",{class:!0});var Kx=s(Ma);T(IB.$$.fragment,Kx),D0t=i(Kx),WPe=n(Kx,"P",{});var PCa=s(WPe);G0t=r(PCa,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),PCa.forEach(t),O0t=i(Kx),Bf=n(Kx,"P",{});var sfe=s(Bf);V0t=r(sfe,`Note:
Loading a model from its configuration file does `),UPe=n(sfe,"STRONG",{});var BCa=s(UPe);X0t=r(BCa,"not"),BCa.forEach(t),z0t=r(sfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Qde=n(sfe,"A",{href:!0});var ICa=s(Qde);Q0t=r(ICa,"from_pretrained()"),ICa.forEach(t),W0t=r(sfe," to load the model weights."),sfe.forEach(t),U0t=i(Kx),T(fy.$$.fragment,Kx),Kx.forEach(t),H0t=i(fd),ct=n(fd,"DIV",{class:!0});var gd=s(ct);T(NB.$$.fragment,gd),J0t=i(gd),HPe=n(gd,"P",{});var NCa=s(HPe);Y0t=r(NCa,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),NCa.forEach(t),Z0t=i(gd),ss=n(gd,"P",{});var e$=s(ss);K0t=r(e$,"The model class to instantiate is selected based on the "),JPe=n(e$,"CODE",{});var qCa=s(JPe);ewt=r(qCa,"model_type"),qCa.forEach(t),owt=r(e$,` property of the config object (either
passed as an argument or loaded from `),YPe=n(e$,"CODE",{});var jCa=s(YPe);rwt=r(jCa,"pretrained_model_name_or_path"),jCa.forEach(t),twt=r(e$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ZPe=n(e$,"CODE",{});var DCa=s(ZPe);awt=r(DCa,"pretrained_model_name_or_path"),DCa.forEach(t),nwt=r(e$,":"),e$.forEach(t),swt=i(gd),KPe=n(gd,"UL",{});var GCa=s(KPe);gy=n(GCa,"LI",{});var Tto=s(gy);eBe=n(Tto,"STRONG",{});var OCa=s(eBe);lwt=r(OCa,"bert"),OCa.forEach(t),iwt=r(Tto," \u2014 "),Wde=n(Tto,"A",{href:!0});var VCa=s(Wde);dwt=r(VCa,"FlaxBertForNextSentencePrediction"),VCa.forEach(t),mwt=r(Tto," (BERT model)"),Tto.forEach(t),GCa.forEach(t),cwt=i(gd),T(hy.$$.fragment,gd),gd.forEach(t),fd.forEach(t),qno=i(c),If=n(c,"H2",{class:!0});var nio=s(If);uy=n(nio,"A",{id:!0,class:!0,href:!0});var XCa=s(uy);oBe=n(XCa,"SPAN",{});var zCa=s(oBe);T(qB.$$.fragment,zCa),zCa.forEach(t),XCa.forEach(t),fwt=i(nio),rBe=n(nio,"SPAN",{});var QCa=s(rBe);gwt=r(QCa,"FlaxAutoModelForImageClassification"),QCa.forEach(t),nio.forEach(t),jno=i(c),Ir=n(c,"DIV",{class:!0});var hd=s(Ir);T(jB.$$.fragment,hd),hwt=i(hd),Nf=n(hd,"P",{});var lfe=s(Nf);uwt=r(lfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Ude=n(lfe,"A",{href:!0});var WCa=s(Ude);pwt=r(WCa,"from_pretrained()"),WCa.forEach(t),_wt=r(lfe," class method or the "),Hde=n(lfe,"A",{href:!0});var UCa=s(Hde);bwt=r(UCa,"from_config()"),UCa.forEach(t),vwt=r(lfe,` class
method.`),lfe.forEach(t),Fwt=i(hd),DB=n(hd,"P",{});var sio=s(DB);Twt=r(sio,"This class cannot be instantiated directly using "),tBe=n(sio,"CODE",{});var HCa=s(tBe);Mwt=r(HCa,"__init__()"),HCa.forEach(t),Ewt=r(sio," (throws an error)."),sio.forEach(t),Cwt=i(hd),Ea=n(hd,"DIV",{class:!0});var o$=s(Ea);T(GB.$$.fragment,o$),wwt=i(o$),aBe=n(o$,"P",{});var JCa=s(aBe);Awt=r(JCa,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),JCa.forEach(t),Lwt=i(o$),qf=n(o$,"P",{});var ife=s(qf);ywt=r(ife,`Note:
Loading a model from its configuration file does `),nBe=n(ife,"STRONG",{});var YCa=s(nBe);xwt=r(YCa,"not"),YCa.forEach(t),$wt=r(ife,` load the model weights. It only affects the
model\u2019s configuration. Use `),Jde=n(ife,"A",{href:!0});var ZCa=s(Jde);kwt=r(ZCa,"from_pretrained()"),ZCa.forEach(t),Swt=r(ife," to load the model weights."),ife.forEach(t),Rwt=i(o$),T(py.$$.fragment,o$),o$.forEach(t),Pwt=i(hd),ft=n(hd,"DIV",{class:!0});var ud=s(ft);T(OB.$$.fragment,ud),Bwt=i(ud),sBe=n(ud,"P",{});var KCa=s(sBe);Iwt=r(KCa,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),KCa.forEach(t),Nwt=i(ud),ls=n(ud,"P",{});var r$=s(ls);qwt=r(r$,"The model class to instantiate is selected based on the "),lBe=n(r$,"CODE",{});var e3a=s(lBe);jwt=r(e3a,"model_type"),e3a.forEach(t),Dwt=r(r$,` property of the config object (either
passed as an argument or loaded from `),iBe=n(r$,"CODE",{});var o3a=s(iBe);Gwt=r(o3a,"pretrained_model_name_or_path"),o3a.forEach(t),Owt=r(r$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dBe=n(r$,"CODE",{});var r3a=s(dBe);Vwt=r(r3a,"pretrained_model_name_or_path"),r3a.forEach(t),Xwt=r(r$,":"),r$.forEach(t),zwt=i(ud),VB=n(ud,"UL",{});var lio=s(VB);_y=n(lio,"LI",{});var Mto=s(_y);mBe=n(Mto,"STRONG",{});var t3a=s(mBe);Qwt=r(t3a,"beit"),t3a.forEach(t),Wwt=r(Mto," \u2014 "),Yde=n(Mto,"A",{href:!0});var a3a=s(Yde);Uwt=r(a3a,"FlaxBeitForImageClassification"),a3a.forEach(t),Hwt=r(Mto," (BEiT model)"),Mto.forEach(t),Jwt=i(lio),by=n(lio,"LI",{});var Eto=s(by);cBe=n(Eto,"STRONG",{});var n3a=s(cBe);Ywt=r(n3a,"vit"),n3a.forEach(t),Zwt=r(Eto," \u2014 "),Zde=n(Eto,"A",{href:!0});var s3a=s(Zde);Kwt=r(s3a,"FlaxViTForImageClassification"),s3a.forEach(t),eAt=r(Eto," (ViT model)"),Eto.forEach(t),lio.forEach(t),oAt=i(ud),T(vy.$$.fragment,ud),ud.forEach(t),hd.forEach(t),Dno=i(c),jf=n(c,"H2",{class:!0});var iio=s(jf);Fy=n(iio,"A",{id:!0,class:!0,href:!0});var l3a=s(Fy);fBe=n(l3a,"SPAN",{});var i3a=s(fBe);T(XB.$$.fragment,i3a),i3a.forEach(t),l3a.forEach(t),rAt=i(iio),gBe=n(iio,"SPAN",{});var d3a=s(gBe);tAt=r(d3a,"FlaxAutoModelForVision2Seq"),d3a.forEach(t),iio.forEach(t),Gno=i(c),Nr=n(c,"DIV",{class:!0});var pd=s(Nr);T(zB.$$.fragment,pd),aAt=i(pd),Df=n(pd,"P",{});var dfe=s(Df);nAt=r(dfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Kde=n(dfe,"A",{href:!0});var m3a=s(Kde);sAt=r(m3a,"from_pretrained()"),m3a.forEach(t),lAt=r(dfe," class method or the "),eme=n(dfe,"A",{href:!0});var c3a=s(eme);iAt=r(c3a,"from_config()"),c3a.forEach(t),dAt=r(dfe,` class
method.`),dfe.forEach(t),mAt=i(pd),QB=n(pd,"P",{});var dio=s(QB);cAt=r(dio,"This class cannot be instantiated directly using "),hBe=n(dio,"CODE",{});var f3a=s(hBe);fAt=r(f3a,"__init__()"),f3a.forEach(t),gAt=r(dio," (throws an error)."),dio.forEach(t),hAt=i(pd),Ca=n(pd,"DIV",{class:!0});var t$=s(Ca);T(WB.$$.fragment,t$),uAt=i(t$),uBe=n(t$,"P",{});var g3a=s(uBe);pAt=r(g3a,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),g3a.forEach(t),_At=i(t$),Gf=n(t$,"P",{});var mfe=s(Gf);bAt=r(mfe,`Note:
Loading a model from its configuration file does `),pBe=n(mfe,"STRONG",{});var h3a=s(pBe);vAt=r(h3a,"not"),h3a.forEach(t),FAt=r(mfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),ome=n(mfe,"A",{href:!0});var u3a=s(ome);TAt=r(u3a,"from_pretrained()"),u3a.forEach(t),MAt=r(mfe," to load the model weights."),mfe.forEach(t),EAt=i(t$),T(Ty.$$.fragment,t$),t$.forEach(t),CAt=i(pd),gt=n(pd,"DIV",{class:!0});var _d=s(gt);T(UB.$$.fragment,_d),wAt=i(_d),_Be=n(_d,"P",{});var p3a=s(_Be);AAt=r(p3a,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),p3a.forEach(t),LAt=i(_d),is=n(_d,"P",{});var a$=s(is);yAt=r(a$,"The model class to instantiate is selected based on the "),bBe=n(a$,"CODE",{});var _3a=s(bBe);xAt=r(_3a,"model_type"),_3a.forEach(t),$At=r(a$,` property of the config object (either
passed as an argument or loaded from `),vBe=n(a$,"CODE",{});var b3a=s(vBe);kAt=r(b3a,"pretrained_model_name_or_path"),b3a.forEach(t),SAt=r(a$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),FBe=n(a$,"CODE",{});var v3a=s(FBe);RAt=r(v3a,"pretrained_model_name_or_path"),v3a.forEach(t),PAt=r(a$,":"),a$.forEach(t),BAt=i(_d),TBe=n(_d,"UL",{});var F3a=s(TBe);My=n(F3a,"LI",{});var Cto=s(My);MBe=n(Cto,"STRONG",{});var T3a=s(MBe);IAt=r(T3a,"vision-encoder-decoder"),T3a.forEach(t),NAt=r(Cto," \u2014 "),rme=n(Cto,"A",{href:!0});var M3a=s(rme);qAt=r(M3a,"FlaxVisionEncoderDecoderModel"),M3a.forEach(t),jAt=r(Cto," (Vision Encoder decoder model)"),Cto.forEach(t),F3a.forEach(t),DAt=i(_d),T(Ey.$$.fragment,_d),_d.forEach(t),pd.forEach(t),this.h()},h(){m(g,"name","hf:doc:metadata"),m(g,"content",JSON.stringify(D0a)),m(f,"id","auto-classes"),m(f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(f,"href","#auto-classes"),m(u,"class","relative group"),m(ms,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig"),m(fs,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoModel"),m(gs,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer"),m(Cd,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),m(Hf,"id","extending-the-auto-classes"),m(Hf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Hf,"href","#extending-the-auto-classes"),m(wd,"class","relative group"),m(Yf,"id","transformers.AutoConfig"),m(Yf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Yf,"href","#transformers.AutoConfig"),m(Ad,"class","relative group"),m(yN,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),m(xN,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig"),m($N,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartConfig"),m(kN,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig"),m(SN,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertConfig"),m(RN,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig"),m(PN,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig"),m(BN,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),m(IN,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig"),m(NN,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),m(qN,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig"),m(jN,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig"),m(DN,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig"),m(GN,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig"),m(ON,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig"),m(VN,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig"),m(XN,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig"),m(zN,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig"),m(QN,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig"),m(WN,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig"),m(UN,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),m(HN,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig"),m(JN,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),m(YN,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig"),m(ZN,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config"),m(KN,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),m(eq,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig"),m(oq,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig"),m(rq,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig"),m(tq,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig"),m(aq,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig"),m(nq,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig"),m(sq,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig"),m(lq,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig"),m(iq,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),m(dq,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig"),m(mq,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig"),m(cq,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig"),m(fq,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig"),m(gq,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig"),m(hq,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig"),m(uq,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig"),m(pq,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig"),m(_q,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config"),m(bq,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),m(vq,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),m(Fq,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig"),m(Tq,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig"),m(Mq,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig"),m(Eq,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig"),m(Cq,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig"),m(wq,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig"),m(Aq,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig"),m(Lq,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),m(yq,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),m(xq,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDConfig"),m($q,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig"),m(kq,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig"),m(Sq,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig"),m(Rq,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config"),m(Pq,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig"),m(Bq,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig"),m(Iq,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config"),m(Nq,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig"),m(qq,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig"),m(jq,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig"),m(Dq,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig"),m(Gq,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig"),m(Oq,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),m(Vq,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig"),m(Xq,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig"),m(zq,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig"),m(Qq,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config"),m(Wq,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig"),m(Uq,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig"),m(Hq,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig"),m(Jq,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),m(Yq,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig"),m(Zq,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig"),m(Kq,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig"),m(ej,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig"),m(oj,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig"),m(rj,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig"),m(tj,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig"),m(aj,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig"),m(nj,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig"),m(sj,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagConfig"),m(lj,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmConfig"),m(ij,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig"),m(dj,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig"),m(mj,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig"),m(cj,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig"),m(fj,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig"),m(gj,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig"),m(hj,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig"),m(uj,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig"),m(pj,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig"),m(_j,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig"),m(bj,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),m(vj,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),m(Fj,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),m(Tj,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig"),m(Mj,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),m(Ej,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig"),m(Cj,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config"),m(wj,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Config"),m(Aj,"href","/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerConfig"),m(Lj,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig"),m(yj,"href","/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig"),m(xj,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),m($j,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),m(kj,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig"),m(Sj,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig"),m(Rj,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),m(Pj,"href","/docs/transformers/main/en/model_doc/van#transformers.VanConfig"),m(Bj,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig"),m(Ij,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig"),m(Nj,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),m(qj,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),m(jj,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig"),m(Dj,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig"),m(Gj,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig"),m(Oj,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig"),m(Vj,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),m(Xj,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),m(zj,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig"),m(Qj,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig"),m(Wj,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig"),m(Uj,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig"),m(Hj,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig"),m(Jj,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),m(Yj,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),m(Zj,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),m(Kj,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig"),m(eD,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig"),m(oD,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig"),m(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Au,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Lu,"id","transformers.AutoTokenizer"),m(Lu,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Lu,"href","#transformers.AutoTokenizer"),m(yd,"class","relative group"),m(rD,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),m(tD,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),m(aD,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),m(nD,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizer"),m(sD,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizerFast"),m(lD,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizer"),m(iD,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizerFast"),m(dD,"href","/docs/transformers/main/en/model_doc/bartpho#transformers.BartphoTokenizer"),m(mD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(cD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(fD,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),m(gD,"href","/docs/transformers/main/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),m(hD,"href","/docs/transformers/main/en/model_doc/bertweet#transformers.BertweetTokenizer"),m(uD,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizer"),m(pD,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),m(_D,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),m(bD,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),m(vD,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),m(FD,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),m(TD,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),m(MD,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomTokenizerFast"),m(ED,"href","/docs/transformers/main/en/model_doc/byt5#transformers.ByT5Tokenizer"),m(CD,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizer"),m(wD,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizerFast"),m(AD,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineTokenizer"),m(LD,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),m(yD,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),m(xD,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizer"),m($D,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizerFast"),m(kD,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizer"),m(SD,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),m(RD,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizer"),m(PD,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizerFast"),m(BD,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLTokenizer"),m(ID,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),m(ND,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),m(qD,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizer"),m(jD,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizerFast"),m(DD,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),m(GD,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),m(OD,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizer"),m(VD,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),m(XD,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),m(zD,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),m(QD,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizer"),m(WD,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizerFast"),m(UD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(HD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(JD,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmTokenizer"),m(YD,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertTokenizer"),m(ZD,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizer"),m(KD,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizerFast"),m(eG,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTTokenizer"),m(oG,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizer"),m(rG,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizerFast"),m(tG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),m(aG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),m(nG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),m(sG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),m(lG,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),m(iG,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseTokenizer"),m(dG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),m(mG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),m(cG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),m(fG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),m(gG,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizer"),m(hG,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizerFast"),m(uG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),m(pG,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),m(_G,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),m(bG,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),m(vG,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),m(FG,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),m(TG,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),m(MG,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),m(EG,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),m(CG,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),m(wG,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),m(AG,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizer"),m(LG,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizerFast"),m(yG,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),m(xG,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),m($G,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizer"),m(kG,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizerFast"),m(SG,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),m(RG,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),m(PG,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeTokenizer"),m(BG,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizer"),m(IG,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),m(NG,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),m(qG,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianTokenizer"),m(jG,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizer"),m(DG,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizerFast"),m(GG,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50Tokenizer"),m(OG,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50TokenizerFast"),m(VG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(XG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(zG,"href","/docs/transformers/main/en/model_doc/mluke#transformers.MLukeTokenizer"),m(QG,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),m(WG,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),m(UG,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizer"),m(HG,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),m(JG,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),m(YG,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),m(ZG,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizer"),m(KG,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizerFast"),m(eO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(oO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(rO,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizer"),m(tO,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizerFast"),m(aO,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),m(nO,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),m(sO,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),m(lO,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),m(iO,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),m(dO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),m(mO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),m(cO,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),m(fO,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),m(gO,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),m(hO,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),m(uO,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverTokenizer"),m(pO,"href","/docs/transformers/main/en/model_doc/phobert#transformers.PhobertTokenizer"),m(_O,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartTokenizer"),m(bO,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),m(vO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(FO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(TO,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagTokenizer"),m(MO,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizer"),m(EO,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizerFast"),m(CO,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizer"),m(wO,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizerFast"),m(AO,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizer"),m(LO,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizerFast"),m(yO,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizer"),m(xO,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),m($O,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),m(kO,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),m(SO,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizer"),m(RO,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),m(PO,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),m(BO,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),m(IO,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizer"),m(NO,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizerFast"),m(qO,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),m(jO,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),m(DO,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),m(GO,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),m(OO,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasTokenizer"),m(VO,"href","/docs/transformers/main/en/model_doc/tapex#transformers.TapexTokenizer"),m(XO,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),m(zO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(QO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(WO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(UO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(HO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),m(JO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),m(YO,"href","/docs/transformers/main/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),m(ZO,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperTokenizer"),m(KO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),m(eV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),m(oV,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizer"),m(rV,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizerFast"),m(tV,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMTokenizer"),m(aV,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),m(nV,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),m(sV,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),m(lV,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),m(iV,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),m(dV,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizer"),m(mV,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),m(cV,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),m(fV,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),m(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(cp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(fp,"id","transformers.AutoFeatureExtractor"),m(fp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(fp,"href","#transformers.AutoFeatureExtractor"),m(xd,"class","relative group"),m(gV,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),m(hV,"href","/docs/transformers/main/en/model_doc/beit#transformers.models.beit.image_processing_beit.BeitImageProcessor"),m(uV,"href","/docs/transformers/main/en/model_doc/clip#transformers.models.clip.image_processing_clip.CLIPImageProcessor"),m(pV,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrFeatureExtractor"),m(_V,"href","/docs/transformers/main/en/model_doc/convnext#transformers.models.convnext.image_processing_convnext.ConvNextImageProcessor"),m(bV,"href","/docs/transformers/main/en/model_doc/convnext#transformers.models.convnext.image_processing_convnext.ConvNextImageProcessor"),m(vV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),m(FV,"href","/docs/transformers/main/en/model_doc/beit#transformers.models.beit.image_processing_beit.BeitImageProcessor"),m(TV,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrFeatureExtractor"),m(MV,"href","/docs/transformers/main/en/model_doc/deit#transformers.models.deit.image_processing_deit.DeiTImageProcessor"),m(EV,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrFeatureExtractor"),m(CV,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutFeatureExtractor"),m(wV,"href","/docs/transformers/main/en/model_doc/dpt#transformers.models.dpt.image_processing_dpt.DPTImageProcessor"),m(AV,"href","/docs/transformers/main/en/model_doc/flava#transformers.models.flava.image_processing_flava.FlavaImageProcessor"),m(LV,"href","/docs/transformers/main/en/model_doc/glpn#transformers.models.glpn.image_processing_glpn.GLPNImageProcessor"),m(yV,"href","/docs/transformers/main/en/model_doc/clip#transformers.models.clip.image_processing_clip.CLIPImageProcessor"),m(xV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),m($V,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.models.imagegpt.image_processing_imagegpt.ImageGPTImageProcessor"),m(kV,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.models.layoutlmv2.image_processing_layoutlmv2.LayoutLMv2ImageProcessor"),m(SV,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.models.layoutlmv3.image_processing_layoutlmv3.LayoutLMv3ImageProcessor"),m(RV,"href","/docs/transformers/main/en/model_doc/levit#transformers.models.levit.image_processing_levit.LevitImageProcessor"),m(PV,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),m(BV,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),m(IV,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.models.mobilevit.image_processing_mobilevit.MobileViTImageProcessor"),m(NV,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTFeatureExtractor"),m(qV,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.models.perceiver.image_processing_perceiver.PerceiverImageProcessor"),m(jV,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.models.poolformer.image_processing_poolformer.PoolFormerImageProcessor"),m(DV,"href","/docs/transformers/main/en/model_doc/convnext#transformers.models.convnext.image_processing_convnext.ConvNextImageProcessor"),m(GV,"href","/docs/transformers/main/en/model_doc/convnext#transformers.models.convnext.image_processing_convnext.ConvNextImageProcessor"),m(OV,"href","/docs/transformers/main/en/model_doc/segformer#transformers.models.segformer.image_processing_segformer.SegformerImageProcessor"),m(VV,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),m(XV,"href","/docs/transformers/main/en/model_doc/vit#transformers.models.vit.image_processing_vit.ViTImageProcessor"),m(zV,"href","/docs/transformers/main/en/model_doc/vit#transformers.models.vit.image_processing_vit.ViTImageProcessor"),m(QV,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrFeatureExtractor"),m(WV,"href","/docs/transformers/main/en/model_doc/convnext#transformers.models.convnext.image_processing_convnext.ConvNextImageProcessor"),m(UV,"href","/docs/transformers/main/en/model_doc/videomae#transformers.models.videomae.image_processing_videomae.VideoMAEImageProcessor"),m(HV,"href","/docs/transformers/main/en/model_doc/vilt#transformers.models.vilt.image_processing_vilt.ViltImageProcessor"),m(JV,"href","/docs/transformers/main/en/model_doc/vit#transformers.models.vit.image_processing_vit.ViTImageProcessor"),m(YV,"href","/docs/transformers/main/en/model_doc/vit#transformers.models.vit.image_processing_vit.ViTImageProcessor"),m(ZV,"href","/docs/transformers/main/en/model_doc/vit#transformers.models.vit.image_processing_vit.ViTImageProcessor"),m(KV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),m(eX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),m(oX,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperFeatureExtractor"),m(rX,"href","/docs/transformers/main/en/model_doc/clip#transformers.models.clip.image_processing_clip.CLIPImageProcessor"),m(tX,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosFeatureExtractor"),m(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(n_,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(s_,"id","transformers.AutoProcessor"),m(s_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(s_,"href","#transformers.AutoProcessor"),m($d,"class","relative group"),m(aX,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),m(nX,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),m(sX,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaProcessor"),m(lX,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),m(iX,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),m(dX,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),m(mX,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),m(cX,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMProcessor"),m(fX,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTProcessor"),m(gX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(hX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(uX,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),m(pX,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),m(_X,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRProcessor"),m(bX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(vX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(FX,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltProcessor"),m(TX,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),m(MX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(EX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(CX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(wX,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperProcessor"),m(AX,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPProcessor"),m(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(k_,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(S_,"id","transformers.AutoModel"),m(S_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(S_,"href","#transformers.AutoModel"),m(Sd,"class","relative group"),m(LX,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(yX,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(xX,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m($X,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel"),m(kX,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartModel"),m(SX,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitModel"),m(RX,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),m(PX,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),m(BX,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel"),m(IX,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),m(NX,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel"),m(qX,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),m(jX,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel"),m(DX,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel"),m(GX,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineModel"),m(OX,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel"),m(VX,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel"),m(XX,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrModel"),m(zX,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel"),m(QX,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel"),m(WX,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel"),m(UX,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel"),m(HX,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel"),m(JX,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel"),m(YX,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel"),m(ZX,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel"),m(KX,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model"),m(ez,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),m(oz,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrModel"),m(rz,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel"),m(tz,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrModel"),m(az,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel"),m(nz,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel"),m(sz,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder"),m(lz,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel"),m(iz,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel"),m(dz,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel"),m(mz,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmModel"),m(cz,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel"),m(fz,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel"),m(gz,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel"),m(hz,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel"),m(uz,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel"),m(pz,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel"),m(_z,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel"),m(bz,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model"),m(vz,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel"),m(Fz,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),m(Tz,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel"),m(Mz,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel"),m(Ez,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel"),m(Cz,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel"),m(wz,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel"),m(Az,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel"),m(Lz,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel"),m(yz,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),m(xz,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),m($z,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDModel"),m(kz,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitModel"),m(Sz,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltModel"),m(Rz,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel"),m(Pz,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model"),m(Bz,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeModel"),m(Iz,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel"),m(Nz,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),m(qz,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianModel"),m(jz,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMModel"),m(Dz,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel"),m(Gz,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel"),m(Oz,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel"),m(Vz,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel"),m(Xz,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel"),m(zz,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel"),m(Qz,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel"),m(Wz,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model"),m(Uz,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel"),m(Hz,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel"),m(Jz,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),m(Yz,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel"),m(Zz,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),m(Kz,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTModel"),m(eQ,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel"),m(oQ,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel"),m(rQ,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel"),m(tQ,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel"),m(aQ,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel"),m(nQ,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel"),m(sQ,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel"),m(lQ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel"),m(iQ,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel"),m(dQ,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel"),m(mQ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel"),m(cQ,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel"),m(fQ,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),m(gQ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel"),m(hQ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel"),m(uQ,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel"),m(pQ,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWModel"),m(_Q,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel"),m(bQ,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel"),m(vQ,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel"),m(FQ,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel"),m(TQ,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinModel"),m(MQ,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model"),m(EQ,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Model"),m(CQ,"href","/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerModel"),m(wQ,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel"),m(AQ,"href","/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel"),m(LQ,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),m(yQ,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel"),m(xQ,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel"),m($Q,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),m(kQ,"href","/docs/transformers/main/en/model_doc/van#transformers.VanModel"),m(SQ,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel"),m(RQ,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel"),m(PQ,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),m(BQ,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel"),m(IQ,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTModel"),m(NQ,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel"),m(qQ,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNModel"),m(jQ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),m(DQ,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),m(GQ,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel"),m(OQ,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperModel"),m(VQ,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel"),m(XQ,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel"),m(zQ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel"),m(QQ,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),m(WQ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),m(UQ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),m(HQ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel"),m(JQ,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel"),m(YQ,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel"),m(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(rb,"id","transformers.AutoModelForPreTraining"),m(rb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(rb,"href","#transformers.AutoModelForPreTraining"),m(Bd,"class","relative group"),m(ZQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(KQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(eW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(oW,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining"),m(rW,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),m(tW,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining"),m(aW,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),m(nW,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),m(sW,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),m(lW,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),m(iW,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),m(dW,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),m(mW,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),m(cW,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),m(fW,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining"),m(gW,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining"),m(hW,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),m(uW,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining"),m(pW,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining"),m(_W,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),m(bW,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining"),m(vW,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),m(FW,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),m(TW,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),m(MW,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),m(EW,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),m(CW,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining"),m(wW,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),m(AW,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),m(LW,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),m(yW,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),m(xW,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining"),m($W,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),m(kW,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),m(SW,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),m(RW,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining"),m(PW,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),m(BW,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),m(IW,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),m(NW,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),m(qW,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),m(jW,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),m(DW,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining"),m(GW,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),m(OW,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),m(VW,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),m(XW,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),m(zW,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),m(QW,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),m(WW,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),m(UW,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),m(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ev,"id","transformers.AutoModelForCausalLM"),m(ev,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ev,"href","#transformers.AutoModelForCausalLM"),m(qd,"class","relative group"),m(HW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(JW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(YW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ZW,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM"),m(KW,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel"),m(eU,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),m(oU,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),m(rU,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),m(tU,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),m(aU,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),m(nU,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),m(sU,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM"),m(lU,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM"),m(iU,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),m(dU,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),m(mU,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM"),m(cU,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM"),m(fU,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),m(gU,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),m(hU,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),m(uU,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM"),m(pU,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM"),m(_U,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM"),m(bU,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM"),m(vU,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),m(FU,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM"),m(TU,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),m(MU,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM"),m(EU,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM"),m(CU,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM"),m(wU,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),m(AU,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),m(LU,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),m(yU,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM"),m(xU,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM"),m($U,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM"),m(kU,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),m(SU,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),m(RU,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM"),m(PU,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM"),m(BU,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),m(IU,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),m(NU,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),m(qU,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),m(jU,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),m(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Qv,"id","transformers.AutoModelForDepthEstimation"),m(Qv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Qv,"href","#transformers.AutoModelForDepthEstimation"),m(Gd,"class","relative group"),m(DU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(GU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(OU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(VU,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTForDepthEstimation"),m(XU,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNForDepthEstimation"),m(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Zv,"id","transformers.AutoModelForMaskedLM"),m(Zv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Zv,"href","#transformers.AutoModelForMaskedLM"),m(Xd,"class","relative group"),m(zU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(QU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(WU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(UU,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM"),m(HU,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),m(JU,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM"),m(YU,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),m(ZU,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),m(KU,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),m(eH,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),m(oH,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),m(rH,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),m(tH,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),m(aH,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM"),m(nH,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM"),m(sH,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),m(lH,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM"),m(iH,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM"),m(dH,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),m(mH,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),m(cH,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),m(fH,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),m(gH,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),m(hH,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),m(uH,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),m(pH,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),m(_H,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),m(bH,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM"),m(vH,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),m(FH,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),m(TH,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),m(MH,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM"),m(EH,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM"),m(CH,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),m(wH,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),m(AH,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),m(LH,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),m(yH,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),m(xH,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),m($H,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),m(kH,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM"),m(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(GF,"id","transformers.AutoModelForSeq2SeqLM"),m(GF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(GF,"href","#transformers.AutoModelForSeq2SeqLM"),m(Wd,"class","relative group"),m(SH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(RH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(PH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(BH,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),m(IH,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),m(NH,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),m(qH,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),m(jH,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),m(DH,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),m(GH,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration"),m(OH,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),m(VH,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),m(XH,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel"),m(zH,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),m(QH,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),m(WH,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),m(UH,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),m(HH,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),m(JH,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration"),m(YH,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),m(ZH,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),m(KH,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),m(eJ,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),m(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(cT,"id","transformers.AutoModelForSequenceClassification"),m(cT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(cT,"href","#transformers.AutoModelForSequenceClassification"),m(Jd,"class","relative group"),m(oJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(rJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(tJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(aJ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification"),m(nJ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification"),m(sJ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification"),m(lJ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),m(iJ,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),m(dJ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification"),m(mJ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),m(cJ,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification"),m(fJ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),m(gJ,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),m(hJ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),m(uJ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),m(pJ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),m(_J,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),m(bJ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification"),m(vJ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification"),m(FJ,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmForSequenceClassification"),m(TJ,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),m(MJ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification"),m(EJ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),m(CJ,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),m(wJ,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),m(AJ,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),m(LJ,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification"),m(yJ,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),m(xJ,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),m($J,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),m(kJ,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification"),m(SJ,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltForSequenceClassification"),m(RJ,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),m(PJ,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification"),m(BJ,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification"),m(IJ,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification"),m(NJ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),m(qJ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),m(jJ,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),m(DJ,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification"),m(GJ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification"),m(OJ,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),m(VJ,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),m(XJ,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification"),m(zJ,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),m(QJ,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),m(WJ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),m(UJ,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),m(HJ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),m(JJ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),m(YJ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),m(ZJ,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),m(KJ,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification"),m(eY,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),m(oY,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification"),m(rY,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),m(tY,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),m(aY,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),m(nY,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification"),m(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(_M,"id","transformers.AutoModelForMultipleChoice"),m(_M,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(_M,"href","#transformers.AutoModelForMultipleChoice"),m(Kd,"class","relative group"),m(sY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(lY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(iY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(dY,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice"),m(mY,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice"),m(cY,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),m(fY,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),m(gY,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice"),m(hY,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),m(uY,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),m(pY,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),m(_Y,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),m(bY,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice"),m(vY,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice"),m(FY,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),m(TY,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice"),m(MY,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),m(EY,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice"),m(CY,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),m(wY,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice"),m(AY,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),m(LY,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),m(yY,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),m(xY,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice"),m($Y,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),m(kY,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),m(SY,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),m(RY,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),m(PY,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),m(BY,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),m(IY,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice"),m(NY,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),m(qY,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),m(jY,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),m(DY,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice"),m(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(KM,"id","transformers.AutoModelForNextSentencePrediction"),m(KM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(KM,"href","#transformers.AutoModelForNextSentencePrediction"),m(rm,"class","relative group"),m(GY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(OY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(VY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(XY,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction"),m(zY,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction"),m(QY,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),m(WY,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),m(UY,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),m(HY,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction"),m(JY,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),m(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(mE,"id","transformers.AutoModelForTokenClassification"),m(mE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(mE,"href","#transformers.AutoModelForTokenClassification"),m(nm,"class","relative group"),m(YY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ZY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(KY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(eZ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification"),m(oZ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification"),m(rZ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),m(tZ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification"),m(aZ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification"),m(nZ,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification"),m(sZ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),m(lZ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),m(iZ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification"),m(dZ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),m(mZ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),m(cZ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification"),m(fZ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification"),m(gZ,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmForTokenClassification"),m(hZ,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),m(uZ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification"),m(pZ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification"),m(_Z,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),m(bZ,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification"),m(vZ,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),m(FZ,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),m(TZ,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),m(MZ,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltForTokenClassification"),m(EZ,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification"),m(CZ,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification"),m(wZ,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification"),m(AZ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),m(LZ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),m(yZ,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),m(xZ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification"),m($Z,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),m(kZ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),m(SZ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification"),m(RZ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification"),m(PZ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),m(BZ,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),m(IZ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification"),m(NZ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),m(qZ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),m(jZ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),m(DZ,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification"),m(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(o4,"id","transformers.AutoModelForQuestionAnswering"),m(o4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(o4,"href","#transformers.AutoModelForQuestionAnswering"),m(im,"class","relative group"),m(GZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(OZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(VZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(XZ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),m(zZ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering"),m(QZ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering"),m(WZ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),m(UZ,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),m(HZ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForQuestionAnswering"),m(JZ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),m(YZ,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering"),m(ZZ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),m(KZ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),m(eK,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),m(oK,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),m(rK,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),m(tK,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),m(aK,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering"),m(nK,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),m(sK,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),m(lK,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),m(iK,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),m(dK,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),m(mK,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),m(cK,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),m(fK,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering"),m(gK,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltForQuestionAnswering"),m(hK,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),m(uK,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering"),m(pK,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),m(_K,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering"),m(bK,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),m(vK,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),m(FK,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),m(TK,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),m(MK,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering"),m(EK,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering"),m(CK,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),m(wK,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForQuestionAnswering"),m(AK,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),m(LK,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),m(yK,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),m(xK,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),m($K,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),m(kK,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),m(SK,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),m(RK,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),m(PK,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),m(BK,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),m(IK,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),m(NK,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),m(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(K4,"id","transformers.AutoModelForTableQuestionAnswering"),m(K4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(K4,"href","#transformers.AutoModelForTableQuestionAnswering"),m(cm,"class","relative group"),m(qK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(jK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(DK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(GK,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),m(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(aC,"id","transformers.AutoModelForDocumentQuestionAnswering"),m(aC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(aC,"href","#transformers.AutoModelForDocumentQuestionAnswering"),m(hm,"class","relative group"),m(OK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(VK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(XK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(zK,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering"),m(QK,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),m(WK,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),m(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(cC,"id","transformers.AutoModelForImageClassification"),m(cC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(cC,"href","#transformers.AutoModelForImageClassification"),m(bm,"class","relative group"),m(UK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(HK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(JK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(YK,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification"),m(ZK,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification"),m(KK,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification"),m(eee,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),m(oee,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification"),m(ree,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),m(tee,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),m(aee,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification"),m(nee,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),m(see,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification"),m(lee,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),m(iee,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),m(dee,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),m(mee,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),m(cee,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification"),m(fee,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification"),m(gee,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification"),m(hee,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification"),m(uee,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification"),m(pee,"href","/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification"),m(_ee,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification"),m(bee,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification"),m(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m($C,"id","transformers.AutoModelForVideoClassification"),m($C,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m($C,"href","#transformers.AutoModelForVideoClassification"),m(Tm,"class","relative group"),m(vee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Fee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Tee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Mee,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification"),m(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(BC,"id","transformers.AutoModelForVision2Seq"),m(BC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(BC,"href","#transformers.AutoModelForVision2Seq"),m(Cm,"class","relative group"),m(Eee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Cee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(wee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Aee,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),m(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(DC,"id","transformers.AutoModelForVisualQuestionAnswering"),m(DC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(DC,"href","#transformers.AutoModelForVisualQuestionAnswering"),m(Lm,"class","relative group"),m(Lee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(yee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(xee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m($ee,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),m(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(zC,"id","transformers.AutoModelForAudioClassification"),m(zC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(zC,"href","#transformers.AutoModelForAudioClassification"),m($m,"class","relative group"),m(kee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(See,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Ree,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Pee,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),m(Bee,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification"),m(Iee,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification"),m(Nee,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),m(qee,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),m(jee,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),m(Dee,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),m(Gee,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),m(Oee,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),m(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(a3,"id","transformers.AutoModelForAudioFrameClassification"),m(a3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(a3,"href","#transformers.AutoModelForAudioFrameClassification"),m(Rm,"class","relative group"),m(Vee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Xee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(zee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Qee,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),m(Wee,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),m(Uee,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),m(Hee,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),m(Jee,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),m(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(g3,"id","transformers.AutoModelForCTC"),m(g3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(g3,"href","#transformers.AutoModelForCTC"),m(Im,"class","relative group"),m(Yee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Zee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Kee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(eoe,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),m(ooe,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC"),m(roe,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC"),m(toe,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC"),m(aoe,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC"),m(noe,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC"),m(soe,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),m(loe,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),m(ioe,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),m(doe,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC"),m(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(L3,"id","transformers.AutoModelForSpeechSeq2Seq"),m(L3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(L3,"href","#transformers.AutoModelForSpeechSeq2Seq"),m(jm,"class","relative group"),m(moe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(coe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(foe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(goe,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),m(hoe,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),m(uoe,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperForConditionalGeneration"),m(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(P3,"id","transformers.AutoModelForAudioXVector"),m(P3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(P3,"href","#transformers.AutoModelForAudioXVector"),m(Vm,"class","relative group"),m(poe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(_oe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(boe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(voe,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),m(Foe,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),m(Toe,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),m(Moe,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),m(Eoe,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector"),m(To,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(V3,"id","transformers.AutoModelForMaskedImageModeling"),m(V3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(V3,"href","#transformers.AutoModelForMaskedImageModeling"),m(Qm,"class","relative group"),m(Coe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(woe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Aoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Loe,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),m(yoe,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),m(xoe,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling"),m($oe,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),m(Mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Y3,"id","transformers.AutoModelForObjectDetection"),m(Y3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Y3,"href","#transformers.AutoModelForObjectDetection"),m(Hm,"class","relative group"),m(koe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Soe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Roe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Poe,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection"),m(Boe,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection"),m(Ioe,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection"),m(Noe,"href","/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerForObjectDetection"),m(qoe,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection"),m(Eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(s5,"id","transformers.AutoModelForImageSegmentation"),m(s5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(s5,"href","#transformers.AutoModelForImageSegmentation"),m(Zm,"class","relative group"),m(joe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Doe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Goe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ooe,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation"),m(Co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(c5,"id","transformers.AutoModelForSemanticSegmentation"),m(c5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(c5,"href","#transformers.AutoModelForSemanticSegmentation"),m(oc,"class","relative group"),m(Voe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Xoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(zoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Qoe,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),m(Woe,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),m(Uoe,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),m(Hoe,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation"),m(Joe,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),m(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(F5,"id","transformers.AutoModelForInstanceSegmentation"),m(F5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(F5,"href","#transformers.AutoModelForInstanceSegmentation"),m(ac,"class","relative group"),m(Yoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Zoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Koe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ere,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),m(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(w5,"id","transformers.AutoModelForZeroShotObjectDetection"),m(w5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(w5,"href","#transformers.AutoModelForZeroShotObjectDetection"),m(lc,"class","relative group"),m(ore,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(rre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(tre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(are,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTForObjectDetection"),m(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m($5,"id","transformers.TFAutoModel"),m($5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m($5,"href","#transformers.TFAutoModel"),m(mc,"class","relative group"),m(nre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(sre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(lre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ire,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel"),m(dre,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel"),m(mre,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel"),m(cre,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),m(fre,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),m(gre,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel"),m(hre,"href","/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel"),m(ure,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel"),m(pre,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel"),m(_re,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel"),m(bre,"href","/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtModel"),m(vre,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),m(Fre,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel"),m(Tre,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),m(Mre,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel"),m(Ere,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel"),m(Cre,"href","/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),m(wre,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel"),m(Are,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmModel"),m(Lre,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel"),m(yre,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel"),m(xre,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel"),m($re,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model"),m(kre,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel"),m(Sre,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.TFGroupViTModel"),m(Rre,"href","/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel"),m(Pre,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),m(Bre,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model"),m(Ire,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel"),m(Nre,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel"),m(qre,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel"),m(jre,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel"),m(Dre,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel"),m(Gre,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel"),m(Ore,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel"),m(Vre,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel"),m(Xre,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model"),m(zre,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),m(Qre,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel"),m(Wre,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel"),m(Ure,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel"),m(Hre,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel"),m(Jre,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel"),m(Yre,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel"),m(Zre,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel"),m(Kre,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel"),m(ete,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),m(ote,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel"),m(rte,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model"),m(tte,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel"),m(ate,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),m(nte,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel"),m(ste,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel"),m(lte,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),m(ite,"href","/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperModel"),m(dte,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel"),m(mte,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel"),m(cte,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),m(fte,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel"),m(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(I0,"id","transformers.TFAutoModelForPreTraining"),m(I0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(I0,"href","#transformers.TFAutoModelForPreTraining"),m(gc,"class","relative group"),m(gte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(hte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(ute,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(pte,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining"),m(_te,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),m(bte,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining"),m(vte,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),m(Fte,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),m(Tte,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),m(Mte,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining"),m(Ete,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),m(Cte,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),m(wte,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),m(Ate,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),m(Lte,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),m(yte,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),m(xte,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),m($te,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),m(kte,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),m(Ste,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),m(Rte,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),m(Pte,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),m(Bte,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),m(Ite,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),m(Nte,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),m(qte,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),m(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(iw,"id","transformers.TFAutoModelForCausalLM"),m(iw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(iw,"href","#transformers.TFAutoModelForCausalLM"),m(pc,"class","relative group"),m(jte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Dte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Gte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ote,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel"),m(Vte,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),m(Xte,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),m(zte,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),m(Qte,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),m(Wte,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),m(Ute,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM"),m(Hte,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),m(Jte,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),m(Yte,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),m(Zte,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),m(Kte,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM"),m(eae,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),m(oae,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),m(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ww,"id","transformers.TFAutoModelForImageClassification"),m(ww,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ww,"href","#transformers.TFAutoModelForImageClassification"),m(vc,"class","relative group"),m(rae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(tae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(aae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(nae,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),m(sae,"href","/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtForImageClassification"),m(lae,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),m(iae,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification"),m(dae,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher"),m(mae,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification"),m(cae,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification"),m(fae,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification"),m(gae,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification"),m(hae,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification"),m(uae,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification"),m(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Nw,"id","transformers.TFAutoModelForSemanticSegmentation"),m(Nw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Nw,"href","#transformers.TFAutoModelForSemanticSegmentation"),m(Mc,"class","relative group"),m(pae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(_ae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(bae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(vae,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation"),m(Fae,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation"),m(Tae,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation"),m(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Vw,"id","transformers.TFAutoModelForMaskedLM"),m(Vw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Vw,"href","#transformers.TFAutoModelForMaskedLM"),m(Ac,"class","relative group"),m(Mae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Eae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Cae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ra,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(wae,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),m(Aae,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM"),m(Lae,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),m(yae,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),m(xae,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),m($ae,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),m(kae,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),m(Sae,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM"),m(Rae,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForMaskedLM"),m(Pae,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),m(Bae,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),m(Iae,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),m(Nae,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),m(qae,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),m(jae,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),m(Dae,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),m(Gae,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),m(Oae,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),m(Vae,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),m(Xae,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),m(zae,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),m(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(gA,"id","transformers.TFAutoModelForSeq2SeqLM"),m(gA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(gA,"href","#transformers.TFAutoModelForSeq2SeqLM"),m(xc,"class","relative group"),m(Qae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Wae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Uae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Hae,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),m(Jae,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),m(Yae,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),m(Zae,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),m(Kae,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),m(ene,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel"),m(one,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),m(rne,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),m(tne,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),m(ane,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),m(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(AA,"id","transformers.TFAutoModelForSequenceClassification"),m(AA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(AA,"href","#transformers.TFAutoModelForSequenceClassification"),m(Sc,"class","relative group"),m(nne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(sne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(lne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(aa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ine,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),m(dne,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification"),m(mne,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),m(cne,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),m(fne,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),m(gne,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),m(hne,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),m(une,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),m(pne,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),m(_ne,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForSequenceClassification"),m(bne,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),m(vne,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),m(Fne,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),m(Tne,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),m(Mne,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),m(Ene,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification"),m(Cne,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),m(wne,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),m(Ane,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),m(Lne,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),m(yne,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),m(xne,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),m($ne,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),m(kne,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),m(Sne,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),m(Rne,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),m(Pne,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),m(Bne,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),m(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(t6,"id","transformers.TFAutoModelForMultipleChoice"),m(t6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(t6,"href","#transformers.TFAutoModelForMultipleChoice"),m(Bc,"class","relative group"),m(Ine,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Nne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(qne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(na,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(jne,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),m(Dne,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice"),m(Gne,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),m(One,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),m(Vne,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),m(Xne,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),m(zne,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),m(Qne,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),m(Wne,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),m(Une,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),m(Hne,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),m(Jne,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),m(Yne,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),m(Zne,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),m(Kne,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),m(ese,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),m(ose,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),m(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(E6,"id","transformers.TFAutoModelForNextSentencePrediction"),m(E6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(E6,"href","#transformers.TFAutoModelForNextSentencePrediction"),m(qc,"class","relative group"),m(rse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(tse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(ase,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(sa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(nse,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),m(sse,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),m(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(y6,"id","transformers.TFAutoModelForTableQuestionAnswering"),m(y6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(y6,"href","#transformers.TFAutoModelForTableQuestionAnswering"),m(Gc,"class","relative group"),m(lse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ise,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(dse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(la,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(mse,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),m(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(S6,"id","transformers.TFAutoModelForDocumentQuestionAnswering"),m(S6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(S6,"href","#transformers.TFAutoModelForDocumentQuestionAnswering"),m(Xc,"class","relative group"),m(cse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(fse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(gse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ia,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(hse,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering"),m(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(I6,"id","transformers.TFAutoModelForTokenClassification"),m(I6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(I6,"href","#transformers.TFAutoModelForTokenClassification"),m(Wc,"class","relative group"),m(use,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(pse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(_se,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(da,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(bse,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),m(vse,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification"),m(Fse,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),m(Tse,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),m(Mse,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),m(Ese,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),m(Cse,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),m(wse,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification"),m(Ase,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForTokenClassification"),m(Lse,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),m(yse,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),m(xse,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),m($se,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification"),m(kse,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),m(Sse,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),m(Rse,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),m(Pse,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),m(Bse,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),m(Ise,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),m(Nse,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),m(qse,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),m(jse,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),m(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(l7,"id","transformers.TFAutoModelForQuestionAnswering"),m(l7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(l7,"href","#transformers.TFAutoModelForQuestionAnswering"),m(Jc,"class","relative group"),m(Dse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Gse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Ose,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ma,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Vse,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),m(Xse,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),m(zse,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),m(Qse,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),m(Wse,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),m(Use,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),m(Hse,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),m(Jse,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),m(Yse,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),m(Zse,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),m(Kse,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),m(ele,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering"),m(ole,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),m(rle,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),m(tle,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),m(ale,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),m(nle,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),m(sle,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),m(lle,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),m(ile,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),m(dle,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),m(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(k7,"id","transformers.TFAutoModelForVision2Seq"),m(k7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(k7,"href","#transformers.TFAutoModelForVision2Seq"),m(Kc,"class","relative group"),m(mle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(cle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(fle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ca,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(gle,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),m(et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(B7,"id","transformers.TFAutoModelForSpeechSeq2Seq"),m(B7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(B7,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),m(rf,"class","relative group"),m(hle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ule,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(ple,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(fa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(_le,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),m(ble,"href","/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration"),m(ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(D7,"id","transformers.FlaxAutoModel"),m(D7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(D7,"href","#transformers.FlaxAutoModel"),m(nf,"class","relative group"),m(vle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Fle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Tle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ga,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Mle,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel"),m(Ele,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel"),m(Cle,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel"),m(wle,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel"),m(Ale,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),m(Lle,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),m(yle,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),m(xle,"href","/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel"),m($le,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),m(kle,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel"),m(Sle,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model"),m(Rle,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),m(Ple,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel"),m(Ble,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model"),m(Ile,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel"),m(Nle,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel"),m(qle,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model"),m(jle,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel"),m(Dle,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel"),m(Gle,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel"),m(Ole,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel"),m(Vle,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model"),m(Xle,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),m(zle,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel"),m(Qle,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),m(Wle,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel"),m(Ule,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),m(rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(p8,"id","transformers.FlaxAutoModelForCausalLM"),m(p8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(p8,"href","#transformers.FlaxAutoModelForCausalLM"),m(df,"class","relative group"),m(Hle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Jle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Yle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ha,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Zle,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM"),m(Kle,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM"),m(eie,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),m(oie,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),m(rie,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),m(tie,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),m(aie,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),m(nie,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),m(sie,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),m(lie,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),m(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(x8,"id","transformers.FlaxAutoModelForPreTraining"),m(x8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(x8,"href","#transformers.FlaxAutoModelForPreTraining"),m(ff,"class","relative group"),m(iie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(die,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(mie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ua,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(cie,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),m(fie,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),m(gie,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining"),m(hie,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),m(uie,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),m(pie,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),m(_ie,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),m(bie,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),m(vie,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),m(Fie,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),m(Tie,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),m(Mie,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),m(Eie,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),m(at,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(z8,"id","transformers.FlaxAutoModelForMaskedLM"),m(z8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(z8,"href","#transformers.FlaxAutoModelForMaskedLM"),m(uf,"class","relative group"),m(Cie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(wie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Aie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(pa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Lie,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),m(yie,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),m(xie,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),m($ie,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),m(kie,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),m(Sie,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),m(Rie,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),m(Pie,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),m(Bie,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),m(Iie,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),m(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(aL,"id","transformers.FlaxAutoModelForSeq2SeqLM"),m(aL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(aL,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),m(bf,"class","relative group"),m(Nie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(qie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(jie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(_a,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Die,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),m(Gie,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),m(Oie,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),m(Vie,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),m(Xie,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),m(zie,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel"),m(Qie,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),m(Wie,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),m(Uie,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),m(Hie,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),m(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(_L,"id","transformers.FlaxAutoModelForSequenceClassification"),m(_L,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(_L,"href","#transformers.FlaxAutoModelForSequenceClassification"),m(Tf,"class","relative group"),m(Jie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Yie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Zie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ba,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Kie,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),m(ede,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),m(ode,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),m(rde,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),m(tde,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),m(ade,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),m(nde,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),m(sde,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),m(lde,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),m(ide,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),m(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m($L,"id","transformers.FlaxAutoModelForQuestionAnswering"),m($L,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m($L,"href","#transformers.FlaxAutoModelForQuestionAnswering"),m(Cf,"class","relative group"),m(dde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(mde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(cde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(va,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(fde,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),m(gde,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),m(hde,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),m(ude,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),m(pde,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),m(_de,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),m(bde,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),m(vde,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),m(Fde,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),m(Tde,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),m(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(VL,"id","transformers.FlaxAutoModelForTokenClassification"),m(VL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(VL,"href","#transformers.FlaxAutoModelForTokenClassification"),m(Lf,"class","relative group"),m(Mde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ede,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Cde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Fa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(wde,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),m(Ade,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),m(Lde,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),m(yde,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),m(xde,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),m($de,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),m(kde,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),m(Sde,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),m(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ey,"id","transformers.FlaxAutoModelForMultipleChoice"),m(ey,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ey,"href","#transformers.FlaxAutoModelForMultipleChoice"),m($f,"class","relative group"),m(Rde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Pde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Bde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ide,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),m(Nde,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),m(qde,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),m(jde,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),m(Dde,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),m(Gde,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),m(Ode,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),m(Vde,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),m(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(cy,"id","transformers.FlaxAutoModelForNextSentencePrediction"),m(cy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(cy,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),m(Rf,"class","relative group"),m(Xde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(zde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Qde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ma,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Wde,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),m(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(uy,"id","transformers.FlaxAutoModelForImageClassification"),m(uy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(uy,"href","#transformers.FlaxAutoModelForImageClassification"),m(If,"class","relative group"),m(Ude,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Hde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Jde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Yde,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),m(Zde,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification"),m(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Fy,"id","transformers.FlaxAutoModelForVision2Seq"),m(Fy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Fy,"href","#transformers.FlaxAutoModelForVision2Seq"),m(jf,"class","relative group"),m(Kde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(eme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(ome,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ca,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(rme,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),m(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(c,_){e(document.head,g),b(c,v,_),b(c,u,_),e(u,f),e(f,p),M(d,p,null),e(u,h),e(u,$o),e($o,bd),b(c,zf,_),b(c,Tt,_),e(Tt,vd),e(Tt,Fd),e(Fd,n$),e(Tt,Qf),b(c,Xe,_),b(c,He,_),e(He,Td),e(He,ms),e(ms,s$),e(He,cs),e(He,fs),e(fs,l$),e(He,Md),e(He,gs),e(gs,i$),e(He,Ed),b(c,Wf,_),M(on,c,_),b(c,Je,_),b(c,Ae,_),e(Ae,MN),e(Ae,Cd),e(Cd,EN),e(Ae,CN),b(c,ko,_),b(c,rn,_),e(rn,wN),e(rn,Uf),e(Uf,AN),e(rn,mio),b(c,wto,_),b(c,wd,_),e(wd,Hf),e(Hf,cfe),M(d$,cfe,null),e(wd,cio),e(wd,ffe),e(ffe,fio),b(c,Ato,_),b(c,hs,_),e(hs,gio),e(hs,gfe),e(gfe,hio),e(hs,uio),e(hs,hfe),e(hfe,pio),e(hs,_io),b(c,Lto,_),M(m$,c,_),b(c,yto,_),b(c,LN,_),e(LN,bio),b(c,xto,_),M(Jf,c,_),b(c,$to,_),b(c,Ad,_),e(Ad,Yf),e(Yf,ufe),M(c$,ufe,null),e(Ad,vio),e(Ad,pfe),e(pfe,Fio),b(c,kto,_),b(c,So,_),M(f$,So,null),e(So,Tio),e(So,g$),e(g$,Mio),e(g$,yN),e(yN,Eio),e(g$,Cio),e(So,wio),e(So,h$),e(h$,Aio),e(h$,_fe),e(_fe,Lio),e(h$,yio),e(So,xio),e(So,qr),M(u$,qr,null),e(qr,$io),e(qr,bfe),e(bfe,kio),e(qr,Sio),e(qr,Ld),e(Ld,Rio),e(Ld,vfe),e(vfe,Pio),e(Ld,Bio),e(Ld,Ffe),e(Ffe,Iio),e(Ld,Nio),e(qr,qio),e(qr,A),e(A,Zf),e(Zf,Tfe),e(Tfe,jio),e(Zf,Dio),e(Zf,xN),e(xN,Gio),e(Zf,Oio),e(A,Vio),e(A,Kf),e(Kf,Mfe),e(Mfe,Xio),e(Kf,zio),e(Kf,$N),e($N,Qio),e(Kf,Wio),e(A,Uio),e(A,eg),e(eg,Efe),e(Efe,Hio),e(eg,Jio),e(eg,kN),e(kN,Yio),e(eg,Zio),e(A,Kio),e(A,og),e(og,Cfe),e(Cfe,edo),e(og,odo),e(og,SN),e(SN,rdo),e(og,tdo),e(A,ado),e(A,rg),e(rg,wfe),e(wfe,ndo),e(rg,sdo),e(rg,RN),e(RN,ldo),e(rg,ido),e(A,ddo),e(A,tg),e(tg,Afe),e(Afe,mdo),e(tg,cdo),e(tg,PN),e(PN,fdo),e(tg,gdo),e(A,hdo),e(A,ag),e(ag,Lfe),e(Lfe,udo),e(ag,pdo),e(ag,BN),e(BN,_do),e(ag,bdo),e(A,vdo),e(A,ng),e(ng,yfe),e(yfe,Fdo),e(ng,Tdo),e(ng,IN),e(IN,Mdo),e(ng,Edo),e(A,Cdo),e(A,sg),e(sg,xfe),e(xfe,wdo),e(sg,Ado),e(sg,NN),e(NN,Ldo),e(sg,ydo),e(A,xdo),e(A,lg),e(lg,$fe),e($fe,$do),e(lg,kdo),e(lg,qN),e(qN,Sdo),e(lg,Rdo),e(A,Pdo),e(A,ig),e(ig,kfe),e(kfe,Bdo),e(ig,Ido),e(ig,jN),e(jN,Ndo),e(ig,qdo),e(A,jdo),e(A,dg),e(dg,Sfe),e(Sfe,Ddo),e(dg,Gdo),e(dg,DN),e(DN,Odo),e(dg,Vdo),e(A,Xdo),e(A,mg),e(mg,Rfe),e(Rfe,zdo),e(mg,Qdo),e(mg,GN),e(GN,Wdo),e(mg,Udo),e(A,Hdo),e(A,cg),e(cg,Pfe),e(Pfe,Jdo),e(cg,Ydo),e(cg,ON),e(ON,Zdo),e(cg,Kdo),e(A,emo),e(A,fg),e(fg,Bfe),e(Bfe,omo),e(fg,rmo),e(fg,VN),e(VN,tmo),e(fg,amo),e(A,nmo),e(A,gg),e(gg,Ife),e(Ife,smo),e(gg,lmo),e(gg,XN),e(XN,imo),e(gg,dmo),e(A,mmo),e(A,hg),e(hg,Nfe),e(Nfe,cmo),e(hg,fmo),e(hg,zN),e(zN,gmo),e(hg,hmo),e(A,umo),e(A,ug),e(ug,qfe),e(qfe,pmo),e(ug,_mo),e(ug,QN),e(QN,bmo),e(ug,vmo),e(A,Fmo),e(A,pg),e(pg,jfe),e(jfe,Tmo),e(pg,Mmo),e(pg,WN),e(WN,Emo),e(pg,Cmo),e(A,wmo),e(A,_g),e(_g,Dfe),e(Dfe,Amo),e(_g,Lmo),e(_g,UN),e(UN,ymo),e(_g,xmo),e(A,$mo),e(A,bg),e(bg,Gfe),e(Gfe,kmo),e(bg,Smo),e(bg,HN),e(HN,Rmo),e(bg,Pmo),e(A,Bmo),e(A,vg),e(vg,Ofe),e(Ofe,Imo),e(vg,Nmo),e(vg,JN),e(JN,qmo),e(vg,jmo),e(A,Dmo),e(A,Fg),e(Fg,Vfe),e(Vfe,Gmo),e(Fg,Omo),e(Fg,YN),e(YN,Vmo),e(Fg,Xmo),e(A,zmo),e(A,Tg),e(Tg,Xfe),e(Xfe,Qmo),e(Tg,Wmo),e(Tg,ZN),e(ZN,Umo),e(Tg,Hmo),e(A,Jmo),e(A,Mg),e(Mg,zfe),e(zfe,Ymo),e(Mg,Zmo),e(Mg,KN),e(KN,Kmo),e(Mg,eco),e(A,oco),e(A,Eg),e(Eg,Qfe),e(Qfe,rco),e(Eg,tco),e(Eg,eq),e(eq,aco),e(Eg,nco),e(A,sco),e(A,Cg),e(Cg,Wfe),e(Wfe,lco),e(Cg,ico),e(Cg,oq),e(oq,dco),e(Cg,mco),e(A,cco),e(A,wg),e(wg,Ufe),e(Ufe,fco),e(wg,gco),e(wg,rq),e(rq,hco),e(wg,uco),e(A,pco),e(A,Ag),e(Ag,Hfe),e(Hfe,_co),e(Ag,bco),e(Ag,tq),e(tq,vco),e(Ag,Fco),e(A,Tco),e(A,Lg),e(Lg,Jfe),e(Jfe,Mco),e(Lg,Eco),e(Lg,aq),e(aq,Cco),e(Lg,wco),e(A,Aco),e(A,yg),e(yg,Yfe),e(Yfe,Lco),e(yg,yco),e(yg,nq),e(nq,xco),e(yg,$co),e(A,kco),e(A,xg),e(xg,Zfe),e(Zfe,Sco),e(xg,Rco),e(xg,sq),e(sq,Pco),e(xg,Bco),e(A,Ico),e(A,$g),e($g,Kfe),e(Kfe,Nco),e($g,qco),e($g,lq),e(lq,jco),e($g,Dco),e(A,Gco),e(A,kg),e(kg,ege),e(ege,Oco),e(kg,Vco),e(kg,iq),e(iq,Xco),e(kg,zco),e(A,Qco),e(A,Sg),e(Sg,oge),e(oge,Wco),e(Sg,Uco),e(Sg,dq),e(dq,Hco),e(Sg,Jco),e(A,Yco),e(A,Rg),e(Rg,rge),e(rge,Zco),e(Rg,Kco),e(Rg,mq),e(mq,efo),e(Rg,ofo),e(A,rfo),e(A,Pg),e(Pg,tge),e(tge,tfo),e(Pg,afo),e(Pg,cq),e(cq,nfo),e(Pg,sfo),e(A,lfo),e(A,Bg),e(Bg,age),e(age,ifo),e(Bg,dfo),e(Bg,fq),e(fq,mfo),e(Bg,cfo),e(A,ffo),e(A,Ig),e(Ig,nge),e(nge,gfo),e(Ig,hfo),e(Ig,gq),e(gq,ufo),e(Ig,pfo),e(A,_fo),e(A,Ng),e(Ng,sge),e(sge,bfo),e(Ng,vfo),e(Ng,hq),e(hq,Ffo),e(Ng,Tfo),e(A,Mfo),e(A,qg),e(qg,lge),e(lge,Efo),e(qg,Cfo),e(qg,uq),e(uq,wfo),e(qg,Afo),e(A,Lfo),e(A,jg),e(jg,ige),e(ige,yfo),e(jg,xfo),e(jg,pq),e(pq,$fo),e(jg,kfo),e(A,Sfo),e(A,Dg),e(Dg,dge),e(dge,Rfo),e(Dg,Pfo),e(Dg,_q),e(_q,Bfo),e(Dg,Ifo),e(A,Nfo),e(A,Gg),e(Gg,mge),e(mge,qfo),e(Gg,jfo),e(Gg,bq),e(bq,Dfo),e(Gg,Gfo),e(A,Ofo),e(A,Og),e(Og,cge),e(cge,Vfo),e(Og,Xfo),e(Og,vq),e(vq,zfo),e(Og,Qfo),e(A,Wfo),e(A,Vg),e(Vg,fge),e(fge,Ufo),e(Vg,Hfo),e(Vg,Fq),e(Fq,Jfo),e(Vg,Yfo),e(A,Zfo),e(A,Xg),e(Xg,gge),e(gge,Kfo),e(Xg,ego),e(Xg,Tq),e(Tq,ogo),e(Xg,rgo),e(A,tgo),e(A,zg),e(zg,hge),e(hge,ago),e(zg,ngo),e(zg,Mq),e(Mq,sgo),e(zg,lgo),e(A,igo),e(A,Qg),e(Qg,uge),e(uge,dgo),e(Qg,mgo),e(Qg,Eq),e(Eq,cgo),e(Qg,fgo),e(A,ggo),e(A,Wg),e(Wg,pge),e(pge,hgo),e(Wg,ugo),e(Wg,Cq),e(Cq,pgo),e(Wg,_go),e(A,bgo),e(A,Ug),e(Ug,_ge),e(_ge,vgo),e(Ug,Fgo),e(Ug,wq),e(wq,Tgo),e(Ug,Mgo),e(A,Ego),e(A,Hg),e(Hg,bge),e(bge,Cgo),e(Hg,wgo),e(Hg,Aq),e(Aq,Ago),e(Hg,Lgo),e(A,ygo),e(A,Jg),e(Jg,vge),e(vge,xgo),e(Jg,$go),e(Jg,Lq),e(Lq,kgo),e(Jg,Sgo),e(A,Rgo),e(A,Yg),e(Yg,Fge),e(Fge,Pgo),e(Yg,Bgo),e(Yg,yq),e(yq,Igo),e(Yg,Ngo),e(A,qgo),e(A,Zg),e(Zg,Tge),e(Tge,jgo),e(Zg,Dgo),e(Zg,xq),e(xq,Ggo),e(Zg,Ogo),e(A,Vgo),e(A,Kg),e(Kg,Mge),e(Mge,Xgo),e(Kg,zgo),e(Kg,$q),e($q,Qgo),e(Kg,Wgo),e(A,Ugo),e(A,eh),e(eh,Ege),e(Ege,Hgo),e(eh,Jgo),e(eh,kq),e(kq,Ygo),e(eh,Zgo),e(A,Kgo),e(A,oh),e(oh,Cge),e(Cge,eho),e(oh,oho),e(oh,Sq),e(Sq,rho),e(oh,tho),e(A,aho),e(A,rh),e(rh,wge),e(wge,nho),e(rh,sho),e(rh,Rq),e(Rq,lho),e(rh,iho),e(A,dho),e(A,th),e(th,Age),e(Age,mho),e(th,cho),e(th,Pq),e(Pq,fho),e(th,gho),e(A,hho),e(A,ah),e(ah,Lge),e(Lge,uho),e(ah,pho),e(ah,Bq),e(Bq,_ho),e(ah,bho),e(A,vho),e(A,nh),e(nh,yge),e(yge,Fho),e(nh,Tho),e(nh,Iq),e(Iq,Mho),e(nh,Eho),e(A,Cho),e(A,sh),e(sh,xge),e(xge,who),e(sh,Aho),e(sh,Nq),e(Nq,Lho),e(sh,yho),e(A,xho),e(A,lh),e(lh,$ge),e($ge,$ho),e(lh,kho),e(lh,qq),e(qq,Sho),e(lh,Rho),e(A,Pho),e(A,ih),e(ih,kge),e(kge,Bho),e(ih,Iho),e(ih,jq),e(jq,Nho),e(ih,qho),e(A,jho),e(A,dh),e(dh,Sge),e(Sge,Dho),e(dh,Gho),e(dh,Dq),e(Dq,Oho),e(dh,Vho),e(A,Xho),e(A,mh),e(mh,Rge),e(Rge,zho),e(mh,Qho),e(mh,Gq),e(Gq,Who),e(mh,Uho),e(A,Hho),e(A,ch),e(ch,Pge),e(Pge,Jho),e(ch,Yho),e(ch,Oq),e(Oq,Zho),e(ch,Kho),e(A,euo),e(A,fh),e(fh,Bge),e(Bge,ouo),e(fh,ruo),e(fh,Vq),e(Vq,tuo),e(fh,auo),e(A,nuo),e(A,gh),e(gh,Ige),e(Ige,suo),e(gh,luo),e(gh,Xq),e(Xq,iuo),e(gh,duo),e(A,muo),e(A,hh),e(hh,Nge),e(Nge,cuo),e(hh,fuo),e(hh,zq),e(zq,guo),e(hh,huo),e(A,uuo),e(A,uh),e(uh,qge),e(qge,puo),e(uh,_uo),e(uh,Qq),e(Qq,buo),e(uh,vuo),e(A,Fuo),e(A,ph),e(ph,jge),e(jge,Tuo),e(ph,Muo),e(ph,Wq),e(Wq,Euo),e(ph,Cuo),e(A,wuo),e(A,_h),e(_h,Dge),e(Dge,Auo),e(_h,Luo),e(_h,Uq),e(Uq,yuo),e(_h,xuo),e(A,$uo),e(A,bh),e(bh,Gge),e(Gge,kuo),e(bh,Suo),e(bh,Hq),e(Hq,Ruo),e(bh,Puo),e(A,Buo),e(A,vh),e(vh,Oge),e(Oge,Iuo),e(vh,Nuo),e(vh,Jq),e(Jq,quo),e(vh,juo),e(A,Duo),e(A,Fh),e(Fh,Vge),e(Vge,Guo),e(Fh,Ouo),e(Fh,Yq),e(Yq,Vuo),e(Fh,Xuo),e(A,zuo),e(A,Th),e(Th,Xge),e(Xge,Quo),e(Th,Wuo),e(Th,Zq),e(Zq,Uuo),e(Th,Huo),e(A,Juo),e(A,Mh),e(Mh,zge),e(zge,Yuo),e(Mh,Zuo),e(Mh,Kq),e(Kq,Kuo),e(Mh,epo),e(A,opo),e(A,Eh),e(Eh,Qge),e(Qge,rpo),e(Eh,tpo),e(Eh,ej),e(ej,apo),e(Eh,npo),e(A,spo),e(A,Ch),e(Ch,Wge),e(Wge,lpo),e(Ch,ipo),e(Ch,oj),e(oj,dpo),e(Ch,mpo),e(A,cpo),e(A,wh),e(wh,Uge),e(Uge,fpo),e(wh,gpo),e(wh,rj),e(rj,hpo),e(wh,upo),e(A,ppo),e(A,Ah),e(Ah,Hge),e(Hge,_po),e(Ah,bpo),e(Ah,tj),e(tj,vpo),e(Ah,Fpo),e(A,Tpo),e(A,Lh),e(Lh,Jge),e(Jge,Mpo),e(Lh,Epo),e(Lh,aj),e(aj,Cpo),e(Lh,wpo),e(A,Apo),e(A,yh),e(yh,Yge),e(Yge,Lpo),e(yh,ypo),e(yh,nj),e(nj,xpo),e(yh,$po),e(A,kpo),e(A,xh),e(xh,Zge),e(Zge,Spo),e(xh,Rpo),e(xh,sj),e(sj,Ppo),e(xh,Bpo),e(A,Ipo),e(A,$h),e($h,Kge),e(Kge,Npo),e($h,qpo),e($h,lj),e(lj,jpo),e($h,Dpo),e(A,Gpo),e(A,kh),e(kh,ehe),e(ehe,Opo),e(kh,Vpo),e(kh,ij),e(ij,Xpo),e(kh,zpo),e(A,Qpo),e(A,Sh),e(Sh,ohe),e(ohe,Wpo),e(Sh,Upo),e(Sh,dj),e(dj,Hpo),e(Sh,Jpo),e(A,Ypo),e(A,Rh),e(Rh,rhe),e(rhe,Zpo),e(Rh,Kpo),e(Rh,mj),e(mj,e_o),e(Rh,o_o),e(A,r_o),e(A,Ph),e(Ph,the),e(the,t_o),e(Ph,a_o),e(Ph,cj),e(cj,n_o),e(Ph,s_o),e(A,l_o),e(A,Bh),e(Bh,ahe),e(ahe,i_o),e(Bh,d_o),e(Bh,fj),e(fj,m_o),e(Bh,c_o),e(A,f_o),e(A,Ih),e(Ih,nhe),e(nhe,g_o),e(Ih,h_o),e(Ih,gj),e(gj,u_o),e(Ih,p_o),e(A,__o),e(A,Nh),e(Nh,she),e(she,b_o),e(Nh,v_o),e(Nh,hj),e(hj,F_o),e(Nh,T_o),e(A,M_o),e(A,qh),e(qh,lhe),e(lhe,E_o),e(qh,C_o),e(qh,uj),e(uj,w_o),e(qh,A_o),e(A,L_o),e(A,jh),e(jh,ihe),e(ihe,y_o),e(jh,x_o),e(jh,pj),e(pj,$_o),e(jh,k_o),e(A,S_o),e(A,Dh),e(Dh,dhe),e(dhe,R_o),e(Dh,P_o),e(Dh,_j),e(_j,B_o),e(Dh,I_o),e(A,N_o),e(A,Gh),e(Gh,mhe),e(mhe,q_o),e(Gh,j_o),e(Gh,bj),e(bj,D_o),e(Gh,G_o),e(A,O_o),e(A,Oh),e(Oh,che),e(che,V_o),e(Oh,X_o),e(Oh,vj),e(vj,z_o),e(Oh,Q_o),e(A,W_o),e(A,Vh),e(Vh,fhe),e(fhe,U_o),e(Vh,H_o),e(Vh,Fj),e(Fj,J_o),e(Vh,Y_o),e(A,Z_o),e(A,Xh),e(Xh,ghe),e(ghe,K_o),e(Xh,e1o),e(Xh,Tj),e(Tj,o1o),e(Xh,r1o),e(A,t1o),e(A,zh),e(zh,hhe),e(hhe,a1o),e(zh,n1o),e(zh,Mj),e(Mj,s1o),e(zh,l1o),e(A,i1o),e(A,Qh),e(Qh,uhe),e(uhe,d1o),e(Qh,m1o),e(Qh,Ej),e(Ej,c1o),e(Qh,f1o),e(A,g1o),e(A,Wh),e(Wh,phe),e(phe,h1o),e(Wh,u1o),e(Wh,Cj),e(Cj,p1o),e(Wh,_1o),e(A,b1o),e(A,Uh),e(Uh,_he),e(_he,v1o),e(Uh,F1o),e(Uh,wj),e(wj,T1o),e(Uh,M1o),e(A,E1o),e(A,Hh),e(Hh,bhe),e(bhe,C1o),e(Hh,w1o),e(Hh,Aj),e(Aj,A1o),e(Hh,L1o),e(A,y1o),e(A,Jh),e(Jh,vhe),e(vhe,x1o),e(Jh,$1o),e(Jh,Lj),e(Lj,k1o),e(Jh,S1o),e(A,R1o),e(A,Yh),e(Yh,Fhe),e(Fhe,P1o),e(Yh,B1o),e(Yh,yj),e(yj,I1o),e(Yh,N1o),e(A,q1o),e(A,Zh),e(Zh,The),e(The,j1o),e(Zh,D1o),e(Zh,xj),e(xj,G1o),e(Zh,O1o),e(A,V1o),e(A,Kh),e(Kh,Mhe),e(Mhe,X1o),e(Kh,z1o),e(Kh,$j),e($j,Q1o),e(Kh,W1o),e(A,U1o),e(A,eu),e(eu,Ehe),e(Ehe,H1o),e(eu,J1o),e(eu,kj),e(kj,Y1o),e(eu,Z1o),e(A,K1o),e(A,ou),e(ou,Che),e(Che,e2o),e(ou,o2o),e(ou,Sj),e(Sj,r2o),e(ou,t2o),e(A,a2o),e(A,ru),e(ru,whe),e(whe,n2o),e(ru,s2o),e(ru,Rj),e(Rj,l2o),e(ru,i2o),e(A,d2o),e(A,tu),e(tu,Ahe),e(Ahe,m2o),e(tu,c2o),e(tu,Pj),e(Pj,f2o),e(tu,g2o),e(A,h2o),e(A,au),e(au,Lhe),e(Lhe,u2o),e(au,p2o),e(au,Bj),e(Bj,_2o),e(au,b2o),e(A,v2o),e(A,nu),e(nu,yhe),e(yhe,F2o),e(nu,T2o),e(nu,Ij),e(Ij,M2o),e(nu,E2o),e(A,C2o),e(A,su),e(su,xhe),e(xhe,w2o),e(su,A2o),e(su,Nj),e(Nj,L2o),e(su,y2o),e(A,x2o),e(A,lu),e(lu,$he),e($he,$2o),e(lu,k2o),e(lu,qj),e(qj,S2o),e(lu,R2o),e(A,P2o),e(A,iu),e(iu,khe),e(khe,B2o),e(iu,I2o),e(iu,jj),e(jj,N2o),e(iu,q2o),e(A,j2o),e(A,du),e(du,She),e(She,D2o),e(du,G2o),e(du,Dj),e(Dj,O2o),e(du,V2o),e(A,X2o),e(A,mu),e(mu,Rhe),e(Rhe,z2o),e(mu,Q2o),e(mu,Gj),e(Gj,W2o),e(mu,U2o),e(A,H2o),e(A,cu),e(cu,Phe),e(Phe,J2o),e(cu,Y2o),e(cu,Oj),e(Oj,Z2o),e(cu,K2o),e(A,ebo),e(A,fu),e(fu,Bhe),e(Bhe,obo),e(fu,rbo),e(fu,Vj),e(Vj,tbo),e(fu,abo),e(A,nbo),e(A,gu),e(gu,Ihe),e(Ihe,sbo),e(gu,lbo),e(gu,Xj),e(Xj,ibo),e(gu,dbo),e(A,mbo),e(A,hu),e(hu,Nhe),e(Nhe,cbo),e(hu,fbo),e(hu,zj),e(zj,gbo),e(hu,hbo),e(A,ubo),e(A,uu),e(uu,qhe),e(qhe,pbo),e(uu,_bo),e(uu,Qj),e(Qj,bbo),e(uu,vbo),e(A,Fbo),e(A,pu),e(pu,jhe),e(jhe,Tbo),e(pu,Mbo),e(pu,Wj),e(Wj,Ebo),e(pu,Cbo),e(A,wbo),e(A,_u),e(_u,Dhe),e(Dhe,Abo),e(_u,Lbo),e(_u,Uj),e(Uj,ybo),e(_u,xbo),e(A,$bo),e(A,bu),e(bu,Ghe),e(Ghe,kbo),e(bu,Sbo),e(bu,Hj),e(Hj,Rbo),e(bu,Pbo),e(A,Bbo),e(A,vu),e(vu,Ohe),e(Ohe,Ibo),e(vu,Nbo),e(vu,Jj),e(Jj,qbo),e(vu,jbo),e(A,Dbo),e(A,Fu),e(Fu,Vhe),e(Vhe,Gbo),e(Fu,Obo),e(Fu,Yj),e(Yj,Vbo),e(Fu,Xbo),e(A,zbo),e(A,Tu),e(Tu,Xhe),e(Xhe,Qbo),e(Tu,Wbo),e(Tu,Zj),e(Zj,Ubo),e(Tu,Hbo),e(A,Jbo),e(A,Mu),e(Mu,zhe),e(zhe,Ybo),e(Mu,Zbo),e(Mu,Kj),e(Kj,Kbo),e(Mu,evo),e(A,ovo),e(A,Eu),e(Eu,Qhe),e(Qhe,rvo),e(Eu,tvo),e(Eu,eD),e(eD,avo),e(Eu,nvo),e(A,svo),e(A,Cu),e(Cu,Whe),e(Whe,lvo),e(Cu,ivo),e(Cu,oD),e(oD,dvo),e(Cu,mvo),e(qr,cvo),M(wu,qr,null),e(So,fvo),e(So,Au),M(p$,Au,null),e(Au,gvo),e(Au,Uhe),e(Uhe,hvo),b(c,Sto,_),b(c,yd,_),e(yd,Lu),e(Lu,Hhe),M(_$,Hhe,null),e(yd,uvo),e(yd,Jhe),e(Jhe,pvo),b(c,Rto,_),b(c,Ro,_),M(b$,Ro,null),e(Ro,_vo),e(Ro,v$),e(v$,bvo),e(v$,rD),e(rD,vvo),e(v$,Fvo),e(Ro,Tvo),e(Ro,F$),e(F$,Mvo),e(F$,Yhe),e(Yhe,Evo),e(F$,Cvo),e(Ro,wvo),e(Ro,jr),M(T$,jr,null),e(jr,Avo),e(jr,Zhe),e(Zhe,Lvo),e(jr,yvo),e(jr,tn),e(tn,xvo),e(tn,Khe),e(Khe,$vo),e(tn,kvo),e(tn,eue),e(eue,Svo),e(tn,Rvo),e(tn,oue),e(oue,Pvo),e(tn,Bvo),e(jr,Ivo),e(jr,k),e(k,us),e(us,rue),e(rue,Nvo),e(us,qvo),e(us,tD),e(tD,jvo),e(us,Dvo),e(us,aD),e(aD,Gvo),e(us,Ovo),e(k,Vvo),e(k,ps),e(ps,tue),e(tue,Xvo),e(ps,zvo),e(ps,nD),e(nD,Qvo),e(ps,Wvo),e(ps,sD),e(sD,Uvo),e(ps,Hvo),e(k,Jvo),e(k,_s),e(_s,aue),e(aue,Yvo),e(_s,Zvo),e(_s,lD),e(lD,Kvo),e(_s,eFo),e(_s,iD),e(iD,oFo),e(_s,rFo),e(k,tFo),e(k,yu),e(yu,nue),e(nue,aFo),e(yu,nFo),e(yu,dD),e(dD,sFo),e(yu,lFo),e(k,iFo),e(k,bs),e(bs,sue),e(sue,dFo),e(bs,mFo),e(bs,mD),e(mD,cFo),e(bs,fFo),e(bs,cD),e(cD,gFo),e(bs,hFo),e(k,uFo),e(k,xu),e(xu,lue),e(lue,pFo),e(xu,_Fo),e(xu,fD),e(fD,bFo),e(xu,vFo),e(k,FFo),e(k,$u),e($u,iue),e(iue,TFo),e($u,MFo),e($u,gD),e(gD,EFo),e($u,CFo),e(k,wFo),e(k,ku),e(ku,due),e(due,AFo),e(ku,LFo),e(ku,hD),e(hD,yFo),e(ku,xFo),e(k,$Fo),e(k,vs),e(vs,mue),e(mue,kFo),e(vs,SFo),e(vs,uD),e(uD,RFo),e(vs,PFo),e(vs,pD),e(pD,BFo),e(vs,IFo),e(k,NFo),e(k,Fs),e(Fs,cue),e(cue,qFo),e(Fs,jFo),e(Fs,_D),e(_D,DFo),e(Fs,GFo),e(Fs,bD),e(bD,OFo),e(Fs,VFo),e(k,XFo),e(k,Ts),e(Ts,fue),e(fue,zFo),e(Ts,QFo),e(Ts,vD),e(vD,WFo),e(Ts,UFo),e(Ts,FD),e(FD,HFo),e(Ts,JFo),e(k,YFo),e(k,Su),e(Su,gue),e(gue,ZFo),e(Su,KFo),e(Su,TD),e(TD,eTo),e(Su,oTo),e(k,rTo),e(k,Ru),e(Ru,hue),e(hue,tTo),e(Ru,aTo),e(Ru,MD),e(MD,nTo),e(Ru,sTo),e(k,lTo),e(k,Pu),e(Pu,uue),e(uue,iTo),e(Pu,dTo),e(Pu,ED),e(ED,mTo),e(Pu,cTo),e(k,fTo),e(k,Ms),e(Ms,pue),e(pue,gTo),e(Ms,hTo),e(Ms,CD),e(CD,uTo),e(Ms,pTo),e(Ms,wD),e(wD,_To),e(Ms,bTo),e(k,vTo),e(k,Bu),e(Bu,_ue),e(_ue,FTo),e(Bu,TTo),e(Bu,AD),e(AD,MTo),e(Bu,ETo),e(k,CTo),e(k,Es),e(Es,bue),e(bue,wTo),e(Es,ATo),e(Es,LD),e(LD,LTo),e(Es,yTo),e(Es,yD),e(yD,xTo),e(Es,$To),e(k,kTo),e(k,Cs),e(Cs,vue),e(vue,STo),e(Cs,RTo),e(Cs,xD),e(xD,PTo),e(Cs,BTo),e(Cs,$D),e($D,ITo),e(Cs,NTo),e(k,qTo),e(k,ws),e(ws,Fue),e(Fue,jTo),e(ws,DTo),e(ws,kD),e(kD,GTo),e(ws,OTo),e(ws,SD),e(SD,VTo),e(ws,XTo),e(k,zTo),e(k,As),e(As,Tue),e(Tue,QTo),e(As,WTo),e(As,RD),e(RD,UTo),e(As,HTo),e(As,PD),e(PD,JTo),e(As,YTo),e(k,ZTo),e(k,Iu),e(Iu,Mue),e(Mue,KTo),e(Iu,eMo),e(Iu,BD),e(BD,oMo),e(Iu,rMo),e(k,tMo),e(k,Ls),e(Ls,Eue),e(Eue,aMo),e(Ls,nMo),e(Ls,ID),e(ID,sMo),e(Ls,lMo),e(Ls,ND),e(ND,iMo),e(Ls,dMo),e(k,mMo),e(k,ys),e(ys,Cue),e(Cue,cMo),e(ys,fMo),e(ys,qD),e(qD,gMo),e(ys,hMo),e(ys,jD),e(jD,uMo),e(ys,pMo),e(k,_Mo),e(k,xs),e(xs,wue),e(wue,bMo),e(xs,vMo),e(xs,DD),e(DD,FMo),e(xs,TMo),e(xs,GD),e(GD,MMo),e(xs,EMo),e(k,CMo),e(k,$s),e($s,Aue),e(Aue,wMo),e($s,AMo),e($s,OD),e(OD,LMo),e($s,yMo),e($s,VD),e(VD,xMo),e($s,$Mo),e(k,kMo),e(k,ks),e(ks,Lue),e(Lue,SMo),e(ks,RMo),e(ks,XD),e(XD,PMo),e(ks,BMo),e(ks,zD),e(zD,IMo),e(ks,NMo),e(k,qMo),e(k,Ss),e(Ss,yue),e(yue,jMo),e(Ss,DMo),e(Ss,QD),e(QD,GMo),e(Ss,OMo),e(Ss,WD),e(WD,VMo),e(Ss,XMo),e(k,zMo),e(k,Rs),e(Rs,xue),e(xue,QMo),e(Rs,WMo),e(Rs,UD),e(UD,UMo),e(Rs,HMo),e(Rs,HD),e(HD,JMo),e(Rs,YMo),e(k,ZMo),e(k,Nu),e(Nu,$ue),e($ue,KMo),e(Nu,eEo),e(Nu,JD),e(JD,oEo),e(Nu,rEo),e(k,tEo),e(k,qu),e(qu,kue),e(kue,aEo),e(qu,nEo),e(qu,YD),e(YD,sEo),e(qu,lEo),e(k,iEo),e(k,Ps),e(Ps,Sue),e(Sue,dEo),e(Ps,mEo),e(Ps,ZD),e(ZD,cEo),e(Ps,fEo),e(Ps,KD),e(KD,gEo),e(Ps,hEo),e(k,uEo),e(k,ju),e(ju,Rue),e(Rue,pEo),e(ju,_Eo),e(ju,eG),e(eG,bEo),e(ju,vEo),e(k,FEo),e(k,Bs),e(Bs,Pue),e(Pue,TEo),e(Bs,MEo),e(Bs,oG),e(oG,EEo),e(Bs,CEo),e(Bs,rG),e(rG,wEo),e(Bs,AEo),e(k,LEo),e(k,Is),e(Is,Bue),e(Bue,yEo),e(Is,xEo),e(Is,tG),e(tG,$Eo),e(Is,kEo),e(Is,aG),e(aG,SEo),e(Is,REo),e(k,PEo),e(k,Ns),e(Ns,Iue),e(Iue,BEo),e(Ns,IEo),e(Ns,nG),e(nG,NEo),e(Ns,qEo),e(Ns,sG),e(sG,jEo),e(Ns,DEo),e(k,GEo),e(k,Du),e(Du,Nue),e(Nue,OEo),e(Du,VEo),e(Du,lG),e(lG,XEo),e(Du,zEo),e(k,QEo),e(k,Gu),e(Gu,que),e(que,WEo),e(Gu,UEo),e(Gu,iG),e(iG,HEo),e(Gu,JEo),e(k,YEo),e(k,qs),e(qs,jue),e(jue,ZEo),e(qs,KEo),e(qs,dG),e(dG,e4o),e(qs,o4o),e(qs,mG),e(mG,r4o),e(qs,t4o),e(k,a4o),e(k,js),e(js,Due),e(Due,n4o),e(js,s4o),e(js,cG),e(cG,l4o),e(js,i4o),e(js,fG),e(fG,d4o),e(js,m4o),e(k,c4o),e(k,Ds),e(Ds,Gue),e(Gue,f4o),e(Ds,g4o),e(Ds,gG),e(gG,h4o),e(Ds,u4o),e(Ds,hG),e(hG,p4o),e(Ds,_4o),e(k,b4o),e(k,Ou),e(Ou,Oue),e(Oue,v4o),e(Ou,F4o),e(Ou,uG),e(uG,T4o),e(Ou,M4o),e(k,E4o),e(k,Gs),e(Gs,Vue),e(Vue,C4o),e(Gs,w4o),e(Gs,pG),e(pG,A4o),e(Gs,L4o),e(Gs,_G),e(_G,y4o),e(Gs,x4o),e(k,$4o),e(k,Os),e(Os,Xue),e(Xue,k4o),e(Os,S4o),e(Os,bG),e(bG,R4o),e(Os,P4o),e(Os,vG),e(vG,B4o),e(Os,I4o),e(k,N4o),e(k,Vs),e(Vs,zue),e(zue,q4o),e(Vs,j4o),e(Vs,FG),e(FG,D4o),e(Vs,G4o),e(Vs,TG),e(TG,O4o),e(Vs,V4o),e(k,X4o),e(k,Xs),e(Xs,Que),e(Que,z4o),e(Xs,Q4o),e(Xs,MG),e(MG,W4o),e(Xs,U4o),e(Xs,EG),e(EG,H4o),e(Xs,J4o),e(k,Y4o),e(k,zs),e(zs,Wue),e(Wue,Z4o),e(zs,K4o),e(zs,CG),e(CG,eCo),e(zs,oCo),e(zs,wG),e(wG,rCo),e(zs,tCo),e(k,aCo),e(k,Qs),e(Qs,Uue),e(Uue,nCo),e(Qs,sCo),e(Qs,AG),e(AG,lCo),e(Qs,iCo),e(Qs,LG),e(LG,dCo),e(Qs,mCo),e(k,cCo),e(k,Ws),e(Ws,Hue),e(Hue,fCo),e(Ws,gCo),e(Ws,yG),e(yG,hCo),e(Ws,uCo),e(Ws,xG),e(xG,pCo),e(Ws,_Co),e(k,bCo),e(k,Us),e(Us,Jue),e(Jue,vCo),e(Us,FCo),e(Us,$G),e($G,TCo),e(Us,MCo),e(Us,kG),e(kG,ECo),e(Us,CCo),e(k,wCo),e(k,Hs),e(Hs,Yue),e(Yue,ACo),e(Hs,LCo),e(Hs,SG),e(SG,yCo),e(Hs,xCo),e(Hs,RG),e(RG,$Co),e(Hs,kCo),e(k,SCo),e(k,Vu),e(Vu,Zue),e(Zue,RCo),e(Vu,PCo),e(Vu,PG),e(PG,BCo),e(Vu,ICo),e(k,NCo),e(k,Js),e(Js,Kue),e(Kue,qCo),e(Js,jCo),e(Js,BG),e(BG,DCo),e(Js,GCo),e(Js,IG),e(IG,OCo),e(Js,VCo),e(k,XCo),e(k,Xu),e(Xu,epe),e(epe,zCo),e(Xu,QCo),e(Xu,NG),e(NG,WCo),e(Xu,UCo),e(k,HCo),e(k,zu),e(zu,ope),e(ope,JCo),e(zu,YCo),e(zu,qG),e(qG,ZCo),e(zu,KCo),e(k,e3o),e(k,Ys),e(Ys,rpe),e(rpe,o3o),e(Ys,r3o),e(Ys,jG),e(jG,t3o),e(Ys,a3o),e(Ys,DG),e(DG,n3o),e(Ys,s3o),e(k,l3o),e(k,Zs),e(Zs,tpe),e(tpe,i3o),e(Zs,d3o),e(Zs,GG),e(GG,m3o),e(Zs,c3o),e(Zs,OG),e(OG,f3o),e(Zs,g3o),e(k,h3o),e(k,Ks),e(Ks,ape),e(ape,u3o),e(Ks,p3o),e(Ks,VG),e(VG,_3o),e(Ks,b3o),e(Ks,XG),e(XG,v3o),e(Ks,F3o),e(k,T3o),e(k,Qu),e(Qu,npe),e(npe,M3o),e(Qu,E3o),e(Qu,zG),e(zG,C3o),e(Qu,w3o),e(k,A3o),e(k,el),e(el,spe),e(spe,L3o),e(el,y3o),e(el,QG),e(QG,x3o),e(el,$3o),e(el,WG),e(WG,k3o),e(el,S3o),e(k,R3o),e(k,ol),e(ol,lpe),e(lpe,P3o),e(ol,B3o),e(ol,UG),e(UG,I3o),e(ol,N3o),e(ol,HG),e(HG,q3o),e(ol,j3o),e(k,D3o),e(k,rl),e(rl,ipe),e(ipe,G3o),e(rl,O3o),e(rl,JG),e(JG,V3o),e(rl,X3o),e(rl,YG),e(YG,z3o),e(rl,Q3o),e(k,W3o),e(k,tl),e(tl,dpe),e(dpe,U3o),e(tl,H3o),e(tl,ZG),e(ZG,J3o),e(tl,Y3o),e(tl,KG),e(KG,Z3o),e(tl,K3o),e(k,e5o),e(k,al),e(al,mpe),e(mpe,o5o),e(al,r5o),e(al,eO),e(eO,t5o),e(al,a5o),e(al,oO),e(oO,n5o),e(al,s5o),e(k,l5o),e(k,nl),e(nl,cpe),e(cpe,i5o),e(nl,d5o),e(nl,rO),e(rO,m5o),e(nl,c5o),e(nl,tO),e(tO,f5o),e(nl,g5o),e(k,h5o),e(k,sl),e(sl,fpe),e(fpe,u5o),e(sl,p5o),e(sl,aO),e(aO,_5o),e(sl,b5o),e(sl,nO),e(nO,v5o),e(sl,F5o),e(k,T5o),e(k,ll),e(ll,gpe),e(gpe,M5o),e(ll,E5o),e(ll,sO),e(sO,C5o),e(ll,w5o),e(ll,lO),e(lO,A5o),e(ll,L5o),e(k,y5o),e(k,Wu),e(Wu,hpe),e(hpe,x5o),e(Wu,$5o),e(Wu,iO),e(iO,k5o),e(Wu,S5o),e(k,R5o),e(k,il),e(il,upe),e(upe,P5o),e(il,B5o),e(il,dO),e(dO,I5o),e(il,N5o),e(il,mO),e(mO,q5o),e(il,j5o),e(k,D5o),e(k,dl),e(dl,ppe),e(ppe,G5o),e(dl,O5o),e(dl,cO),e(cO,V5o),e(dl,X5o),e(dl,fO),e(fO,z5o),e(dl,Q5o),e(k,W5o),e(k,ml),e(ml,_pe),e(_pe,U5o),e(ml,H5o),e(ml,gO),e(gO,J5o),e(ml,Y5o),e(ml,hO),e(hO,Z5o),e(ml,K5o),e(k,e0o),e(k,Uu),e(Uu,bpe),e(bpe,o0o),e(Uu,r0o),e(Uu,uO),e(uO,t0o),e(Uu,a0o),e(k,n0o),e(k,Hu),e(Hu,vpe),e(vpe,s0o),e(Hu,l0o),e(Hu,pO),e(pO,i0o),e(Hu,d0o),e(k,m0o),e(k,Ju),e(Ju,Fpe),e(Fpe,c0o),e(Ju,f0o),e(Ju,_O),e(_O,g0o),e(Ju,h0o),e(k,u0o),e(k,Yu),e(Yu,Tpe),e(Tpe,p0o),e(Yu,_0o),e(Yu,bO),e(bO,b0o),e(Yu,v0o),e(k,F0o),e(k,cl),e(cl,Mpe),e(Mpe,T0o),e(cl,M0o),e(cl,vO),e(vO,E0o),e(cl,C0o),e(cl,FO),e(FO,w0o),e(cl,A0o),e(k,L0o),e(k,Zu),e(Zu,Epe),e(Epe,y0o),e(Zu,x0o),e(Zu,TO),e(TO,$0o),e(Zu,k0o),e(k,S0o),e(k,fl),e(fl,Cpe),e(Cpe,R0o),e(fl,P0o),e(fl,MO),e(MO,B0o),e(fl,I0o),e(fl,EO),e(EO,N0o),e(fl,q0o),e(k,j0o),e(k,gl),e(gl,wpe),e(wpe,D0o),e(gl,G0o),e(gl,CO),e(CO,O0o),e(gl,V0o),e(gl,wO),e(wO,X0o),e(gl,z0o),e(k,Q0o),e(k,hl),e(hl,Ape),e(Ape,W0o),e(hl,U0o),e(hl,AO),e(AO,H0o),e(hl,J0o),e(hl,LO),e(LO,Y0o),e(hl,Z0o),e(k,K0o),e(k,ul),e(ul,Lpe),e(Lpe,ewo),e(ul,owo),e(ul,yO),e(yO,rwo),e(ul,two),e(ul,xO),e(xO,awo),e(ul,nwo),e(k,swo),e(k,pl),e(pl,ype),e(ype,lwo),e(pl,iwo),e(pl,$O),e($O,dwo),e(pl,mwo),e(pl,kO),e(kO,cwo),e(pl,fwo),e(k,gwo),e(k,_l),e(_l,xpe),e(xpe,hwo),e(_l,uwo),e(_l,SO),e(SO,pwo),e(_l,_wo),e(_l,RO),e(RO,bwo),e(_l,vwo),e(k,Fwo),e(k,Ku),e(Ku,$pe),e($pe,Two),e(Ku,Mwo),e(Ku,PO),e(PO,Ewo),e(Ku,Cwo),e(k,wwo),e(k,ep),e(ep,kpe),e(kpe,Awo),e(ep,Lwo),e(ep,BO),e(BO,ywo),e(ep,xwo),e(k,$wo),e(k,bl),e(bl,Spe),e(Spe,kwo),e(bl,Swo),e(bl,IO),e(IO,Rwo),e(bl,Pwo),e(bl,NO),e(NO,Bwo),e(bl,Iwo),e(k,Nwo),e(k,vl),e(vl,Rpe),e(Rpe,qwo),e(vl,jwo),e(vl,qO),e(qO,Dwo),e(vl,Gwo),e(vl,jO),e(jO,Owo),e(vl,Vwo),e(k,Xwo),e(k,Fl),e(Fl,Ppe),e(Ppe,zwo),e(Fl,Qwo),e(Fl,DO),e(DO,Wwo),e(Fl,Uwo),e(Fl,GO),e(GO,Hwo),e(Fl,Jwo),e(k,Ywo),e(k,op),e(op,Bpe),e(Bpe,Zwo),e(op,Kwo),e(op,OO),e(OO,eAo),e(op,oAo),e(k,rAo),e(k,rp),e(rp,Ipe),e(Ipe,tAo),e(rp,aAo),e(rp,VO),e(VO,nAo),e(rp,sAo),e(k,lAo),e(k,tp),e(tp,Npe),e(Npe,iAo),e(tp,dAo),e(tp,XO),e(XO,mAo),e(tp,cAo),e(k,fAo),e(k,Tl),e(Tl,qpe),e(qpe,gAo),e(Tl,hAo),e(Tl,zO),e(zO,uAo),e(Tl,pAo),e(Tl,QO),e(QO,_Ao),e(Tl,bAo),e(k,vAo),e(k,Ml),e(Ml,jpe),e(jpe,FAo),e(Ml,TAo),e(Ml,WO),e(WO,MAo),e(Ml,EAo),e(Ml,UO),e(UO,CAo),e(Ml,wAo),e(k,AAo),e(k,ap),e(ap,Dpe),e(Dpe,LAo),e(ap,yAo),e(ap,HO),e(HO,xAo),e(ap,$Ao),e(k,kAo),e(k,np),e(np,Gpe),e(Gpe,SAo),e(np,RAo),e(np,JO),e(JO,PAo),e(np,BAo),e(k,IAo),e(k,sp),e(sp,Ope),e(Ope,NAo),e(sp,qAo),e(sp,YO),e(YO,jAo),e(sp,DAo),e(k,GAo),e(k,lp),e(lp,Vpe),e(Vpe,OAo),e(lp,VAo),e(lp,ZO),e(ZO,XAo),e(lp,zAo),e(k,QAo),e(k,El),e(El,Xpe),e(Xpe,WAo),e(El,UAo),e(El,KO),e(KO,HAo),e(El,JAo),e(El,eV),e(eV,YAo),e(El,ZAo),e(k,KAo),e(k,Cl),e(Cl,zpe),e(zpe,e6o),e(Cl,o6o),e(Cl,oV),e(oV,r6o),e(Cl,t6o),e(Cl,rV),e(rV,a6o),e(Cl,n6o),e(k,s6o),e(k,ip),e(ip,Qpe),e(Qpe,l6o),e(ip,i6o),e(ip,tV),e(tV,d6o),e(ip,m6o),e(k,c6o),e(k,dp),e(dp,Wpe),e(Wpe,f6o),e(dp,g6o),e(dp,aV),e(aV,h6o),e(dp,u6o),e(k,p6o),e(k,wl),e(wl,Upe),e(Upe,_6o),e(wl,b6o),e(wl,nV),e(nV,v6o),e(wl,F6o),e(wl,sV),e(sV,T6o),e(wl,M6o),e(k,E6o),e(k,Al),e(Al,Hpe),e(Hpe,C6o),e(Al,w6o),e(Al,lV),e(lV,A6o),e(Al,L6o),e(Al,iV),e(iV,y6o),e(Al,x6o),e(k,$6o),e(k,Ll),e(Ll,Jpe),e(Jpe,k6o),e(Ll,S6o),e(Ll,dV),e(dV,R6o),e(Ll,P6o),e(Ll,mV),e(mV,B6o),e(Ll,I6o),e(k,N6o),e(k,yl),e(yl,Ype),e(Ype,q6o),e(yl,j6o),e(yl,cV),e(cV,D6o),e(yl,G6o),e(yl,fV),e(fV,O6o),e(yl,V6o),e(jr,X6o),M(mp,jr,null),e(Ro,z6o),e(Ro,cp),M(M$,cp,null),e(cp,Q6o),e(cp,Zpe),e(Zpe,W6o),b(c,Pto,_),b(c,xd,_),e(xd,fp),e(fp,Kpe),M(E$,Kpe,null),e(xd,U6o),e(xd,e_e),e(e_e,H6o),b(c,Bto,_),b(c,Po,_),M(C$,Po,null),e(Po,J6o),e(Po,w$),e(w$,Y6o),e(w$,gV),e(gV,Z6o),e(w$,K6o),e(Po,e7o),e(Po,A$),e(A$,o7o),e(A$,o_e),e(o_e,r7o),e(A$,t7o),e(Po,a7o),e(Po,Ye),M(L$,Ye,null),e(Ye,n7o),e(Ye,r_e),e(r_e,s7o),e(Ye,l7o),e(Ye,an),e(an,i7o),e(an,t_e),e(t_e,d7o),e(an,m7o),e(an,a_e),e(a_e,c7o),e(an,f7o),e(an,n_e),e(n_e,g7o),e(an,h7o),e(Ye,u7o),e(Ye,z),e(z,gp),e(gp,s_e),e(s_e,p7o),e(gp,_7o),e(gp,hV),e(hV,b7o),e(gp,v7o),e(z,F7o),e(z,hp),e(hp,l_e),e(l_e,T7o),e(hp,M7o),e(hp,uV),e(uV,E7o),e(hp,C7o),e(z,w7o),e(z,up),e(up,i_e),e(i_e,A7o),e(up,L7o),e(up,pV),e(pV,y7o),e(up,x7o),e(z,$7o),e(z,pp),e(pp,d_e),e(d_e,k7o),e(pp,S7o),e(pp,_V),e(_V,R7o),e(pp,P7o),e(z,B7o),e(z,_p),e(_p,m_e),e(m_e,I7o),e(_p,N7o),e(_p,bV),e(bV,q7o),e(_p,j7o),e(z,D7o),e(z,bp),e(bp,c_e),e(c_e,G7o),e(bp,O7o),e(bp,vV),e(vV,V7o),e(bp,X7o),e(z,z7o),e(z,vp),e(vp,f_e),e(f_e,Q7o),e(vp,W7o),e(vp,FV),e(FV,U7o),e(vp,H7o),e(z,J7o),e(z,Fp),e(Fp,g_e),e(g_e,Y7o),e(Fp,Z7o),e(Fp,TV),e(TV,K7o),e(Fp,e8o),e(z,o8o),e(z,Tp),e(Tp,h_e),e(h_e,r8o),e(Tp,t8o),e(Tp,MV),e(MV,a8o),e(Tp,n8o),e(z,s8o),e(z,Mp),e(Mp,u_e),e(u_e,l8o),e(Mp,i8o),e(Mp,EV),e(EV,d8o),e(Mp,m8o),e(z,c8o),e(z,Ep),e(Ep,p_e),e(p_e,f8o),e(Ep,g8o),e(Ep,CV),e(CV,h8o),e(Ep,u8o),e(z,p8o),e(z,Cp),e(Cp,__e),e(__e,_8o),e(Cp,b8o),e(Cp,wV),e(wV,v8o),e(Cp,F8o),e(z,T8o),e(z,wp),e(wp,b_e),e(b_e,M8o),e(wp,E8o),e(wp,AV),e(AV,C8o),e(wp,w8o),e(z,A8o),e(z,Ap),e(Ap,v_e),e(v_e,L8o),e(Ap,y8o),e(Ap,LV),e(LV,x8o),e(Ap,$8o),e(z,k8o),e(z,Lp),e(Lp,F_e),e(F_e,S8o),e(Lp,R8o),e(Lp,yV),e(yV,P8o),e(Lp,B8o),e(z,I8o),e(z,yp),e(yp,T_e),e(T_e,N8o),e(yp,q8o),e(yp,xV),e(xV,j8o),e(yp,D8o),e(z,G8o),e(z,xp),e(xp,M_e),e(M_e,O8o),e(xp,V8o),e(xp,$V),e($V,X8o),e(xp,z8o),e(z,Q8o),e(z,$p),e($p,E_e),e(E_e,W8o),e($p,U8o),e($p,kV),e(kV,H8o),e($p,J8o),e(z,Y8o),e(z,kp),e(kp,C_e),e(C_e,Z8o),e(kp,K8o),e(kp,SV),e(SV,eLo),e(kp,oLo),e(z,rLo),e(z,Sp),e(Sp,w_e),e(w_e,tLo),e(Sp,aLo),e(Sp,RV),e(RV,nLo),e(Sp,sLo),e(z,lLo),e(z,Rp),e(Rp,A_e),e(A_e,iLo),e(Rp,dLo),e(Rp,PV),e(PV,mLo),e(Rp,cLo),e(z,fLo),e(z,Pp),e(Pp,L_e),e(L_e,gLo),e(Pp,hLo),e(Pp,BV),e(BV,uLo),e(Pp,pLo),e(z,_Lo),e(z,Bp),e(Bp,y_e),e(y_e,bLo),e(Bp,vLo),e(Bp,IV),e(IV,FLo),e(Bp,TLo),e(z,MLo),e(z,Ip),e(Ip,x_e),e(x_e,ELo),e(Ip,CLo),e(Ip,NV),e(NV,wLo),e(Ip,ALo),e(z,LLo),e(z,Np),e(Np,$_e),e($_e,yLo),e(Np,xLo),e(Np,qV),e(qV,$Lo),e(Np,kLo),e(z,SLo),e(z,qp),e(qp,k_e),e(k_e,RLo),e(qp,PLo),e(qp,jV),e(jV,BLo),e(qp,ILo),e(z,NLo),e(z,jp),e(jp,S_e),e(S_e,qLo),e(jp,jLo),e(jp,DV),e(DV,DLo),e(jp,GLo),e(z,OLo),e(z,Dp),e(Dp,R_e),e(R_e,VLo),e(Dp,XLo),e(Dp,GV),e(GV,zLo),e(Dp,QLo),e(z,WLo),e(z,Gp),e(Gp,P_e),e(P_e,ULo),e(Gp,HLo),e(Gp,OV),e(OV,JLo),e(Gp,YLo),e(z,ZLo),e(z,Op),e(Op,B_e),e(B_e,KLo),e(Op,eyo),e(Op,VV),e(VV,oyo),e(Op,ryo),e(z,tyo),e(z,Vp),e(Vp,I_e),e(I_e,ayo),e(Vp,nyo),e(Vp,XV),e(XV,syo),e(Vp,lyo),e(z,iyo),e(z,Xp),e(Xp,N_e),e(N_e,dyo),e(Xp,myo),e(Xp,zV),e(zV,cyo),e(Xp,fyo),e(z,gyo),e(z,zp),e(zp,q_e),e(q_e,hyo),e(zp,uyo),e(zp,QV),e(QV,pyo),e(zp,_yo),e(z,byo),e(z,Qp),e(Qp,j_e),e(j_e,vyo),e(Qp,Fyo),e(Qp,WV),e(WV,Tyo),e(Qp,Myo),e(z,Eyo),e(z,Wp),e(Wp,D_e),e(D_e,Cyo),e(Wp,wyo),e(Wp,UV),e(UV,Ayo),e(Wp,Lyo),e(z,yyo),e(z,Up),e(Up,G_e),e(G_e,xyo),e(Up,$yo),e(Up,HV),e(HV,kyo),e(Up,Syo),e(z,Ryo),e(z,Hp),e(Hp,O_e),e(O_e,Pyo),e(Hp,Byo),e(Hp,JV),e(JV,Iyo),e(Hp,Nyo),e(z,qyo),e(z,Jp),e(Jp,V_e),e(V_e,jyo),e(Jp,Dyo),e(Jp,YV),e(YV,Gyo),e(Jp,Oyo),e(z,Vyo),e(z,Yp),e(Yp,X_e),e(X_e,Xyo),e(Yp,zyo),e(Yp,ZV),e(ZV,Qyo),e(Yp,Wyo),e(z,Uyo),e(z,Zp),e(Zp,z_e),e(z_e,Hyo),e(Zp,Jyo),e(Zp,KV),e(KV,Yyo),e(Zp,Zyo),e(z,Kyo),e(z,Kp),e(Kp,Q_e),e(Q_e,e9o),e(Kp,o9o),e(Kp,eX),e(eX,r9o),e(Kp,t9o),e(z,a9o),e(z,e_),e(e_,W_e),e(W_e,n9o),e(e_,s9o),e(e_,oX),e(oX,l9o),e(e_,i9o),e(z,d9o),e(z,o_),e(o_,U_e),e(U_e,m9o),e(o_,c9o),e(o_,rX),e(rX,f9o),e(o_,g9o),e(z,h9o),e(z,r_),e(r_,H_e),e(H_e,u9o),e(r_,p9o),e(r_,tX),e(tX,_9o),e(r_,b9o),e(Ye,v9o),M(t_,Ye,null),e(Ye,F9o),M(a_,Ye,null),e(Po,T9o),e(Po,n_),M(y$,n_,null),e(n_,M9o),e(n_,J_e),e(J_e,E9o),b(c,Ito,_),b(c,$d,_),e($d,s_),e(s_,Y_e),M(x$,Y_e,null),e($d,C9o),e($d,Z_e),e(Z_e,w9o),b(c,Nto,_),b(c,Bo,_),M($$,Bo,null),e(Bo,A9o),e(Bo,k$),e(k$,L9o),e(k$,aX),e(aX,y9o),e(k$,x9o),e(Bo,$9o),e(Bo,S$),e(S$,k9o),e(S$,K_e),e(K_e,S9o),e(S$,R9o),e(Bo,P9o),e(Bo,Ze),M(R$,Ze,null),e(Ze,B9o),e(Ze,e1e),e(e1e,I9o),e(Ze,N9o),e(Ze,kd),e(kd,q9o),e(kd,o1e),e(o1e,j9o),e(kd,D9o),e(kd,r1e),e(r1e,G9o),e(kd,O9o),e(Ze,V9o),e(Ze,le),e(le,l_),e(l_,t1e),e(t1e,X9o),e(l_,z9o),e(l_,nX),e(nX,Q9o),e(l_,W9o),e(le,U9o),e(le,i_),e(i_,a1e),e(a1e,H9o),e(i_,J9o),e(i_,sX),e(sX,Y9o),e(i_,Z9o),e(le,K9o),e(le,d_),e(d_,n1e),e(n1e,exo),e(d_,oxo),e(d_,lX),e(lX,rxo),e(d_,txo),e(le,axo),e(le,m_),e(m_,s1e),e(s1e,nxo),e(m_,sxo),e(m_,iX),e(iX,lxo),e(m_,ixo),e(le,dxo),e(le,c_),e(c_,l1e),e(l1e,mxo),e(c_,cxo),e(c_,dX),e(dX,fxo),e(c_,gxo),e(le,hxo),e(le,f_),e(f_,i1e),e(i1e,uxo),e(f_,pxo),e(f_,mX),e(mX,_xo),e(f_,bxo),e(le,vxo),e(le,g_),e(g_,d1e),e(d1e,Fxo),e(g_,Txo),e(g_,cX),e(cX,Mxo),e(g_,Exo),e(le,Cxo),e(le,h_),e(h_,m1e),e(m1e,wxo),e(h_,Axo),e(h_,fX),e(fX,Lxo),e(h_,yxo),e(le,xxo),e(le,u_),e(u_,c1e),e(c1e,$xo),e(u_,kxo),e(u_,gX),e(gX,Sxo),e(u_,Rxo),e(le,Pxo),e(le,p_),e(p_,f1e),e(f1e,Bxo),e(p_,Ixo),e(p_,hX),e(hX,Nxo),e(p_,qxo),e(le,jxo),e(le,__),e(__,g1e),e(g1e,Dxo),e(__,Gxo),e(__,uX),e(uX,Oxo),e(__,Vxo),e(le,Xxo),e(le,b_),e(b_,h1e),e(h1e,zxo),e(b_,Qxo),e(b_,pX),e(pX,Wxo),e(b_,Uxo),e(le,Hxo),e(le,v_),e(v_,u1e),e(u1e,Jxo),e(v_,Yxo),e(v_,_X),e(_X,Zxo),e(v_,Kxo),e(le,e$o),e(le,F_),e(F_,p1e),e(p1e,o$o),e(F_,r$o),e(F_,bX),e(bX,t$o),e(F_,a$o),e(le,n$o),e(le,T_),e(T_,_1e),e(_1e,s$o),e(T_,l$o),e(T_,vX),e(vX,i$o),e(T_,d$o),e(le,m$o),e(le,M_),e(M_,b1e),e(b1e,c$o),e(M_,f$o),e(M_,FX),e(FX,g$o),e(M_,h$o),e(le,u$o),e(le,E_),e(E_,v1e),e(v1e,p$o),e(E_,_$o),e(E_,TX),e(TX,b$o),e(E_,v$o),e(le,F$o),e(le,C_),e(C_,F1e),e(F1e,T$o),e(C_,M$o),e(C_,MX),e(MX,E$o),e(C_,C$o),e(le,w$o),e(le,w_),e(w_,T1e),e(T1e,A$o),e(w_,L$o),e(w_,EX),e(EX,y$o),e(w_,x$o),e(le,$$o),e(le,A_),e(A_,M1e),e(M1e,k$o),e(A_,S$o),e(A_,CX),e(CX,R$o),e(A_,P$o),e(le,B$o),e(le,L_),e(L_,E1e),e(E1e,I$o),e(L_,N$o),e(L_,wX),e(wX,q$o),e(L_,j$o),e(le,D$o),e(le,y_),e(y_,C1e),e(C1e,G$o),e(y_,O$o),e(y_,AX),e(AX,V$o),e(y_,X$o),e(Ze,z$o),M(x_,Ze,null),e(Ze,Q$o),M($_,Ze,null),e(Bo,W$o),e(Bo,k_),M(P$,k_,null),e(k_,U$o),e(k_,w1e),e(w1e,H$o),b(c,qto,_),b(c,Sd,_),e(Sd,S_),e(S_,A1e),M(B$,A1e,null),e(Sd,J$o),e(Sd,L1e),e(L1e,Y$o),b(c,jto,_),b(c,Io,_),M(I$,Io,null),e(Io,Z$o),e(Io,Rd),e(Rd,K$o),e(Rd,LX),e(LX,eko),e(Rd,oko),e(Rd,yX),e(yX,rko),e(Rd,tko),e(Io,ako),e(Io,N$),e(N$,nko),e(N$,y1e),e(y1e,sko),e(N$,lko),e(Io,iko),e(Io,Mt),M(q$,Mt,null),e(Mt,dko),e(Mt,x1e),e(x1e,mko),e(Mt,cko),e(Mt,Pd),e(Pd,fko),e(Pd,$1e),e($1e,gko),e(Pd,hko),e(Pd,xX),e(xX,uko),e(Pd,pko),e(Mt,_ko),M(R_,Mt,null),e(Io,bko),e(Io,Ke),M(j$,Ke,null),e(Ke,vko),e(Ke,k1e),e(k1e,Fko),e(Ke,Tko),e(Ke,nn),e(nn,Mko),e(nn,S1e),e(S1e,Eko),e(nn,Cko),e(nn,R1e),e(R1e,wko),e(nn,Ako),e(nn,P1e),e(P1e,Lko),e(nn,yko),e(Ke,xko),e(Ke,y),e(y,P_),e(P_,B1e),e(B1e,$ko),e(P_,kko),e(P_,$X),e($X,Sko),e(P_,Rko),e(y,Pko),e(y,B_),e(B_,I1e),e(I1e,Bko),e(B_,Iko),e(B_,kX),e(kX,Nko),e(B_,qko),e(y,jko),e(y,I_),e(I_,N1e),e(N1e,Dko),e(I_,Gko),e(I_,SX),e(SX,Oko),e(I_,Vko),e(y,Xko),e(y,N_),e(N_,q1e),e(q1e,zko),e(N_,Qko),e(N_,RX),e(RX,Wko),e(N_,Uko),e(y,Hko),e(y,q_),e(q_,j1e),e(j1e,Jko),e(q_,Yko),e(q_,PX),e(PX,Zko),e(q_,Kko),e(y,eSo),e(y,j_),e(j_,D1e),e(D1e,oSo),e(j_,rSo),e(j_,BX),e(BX,tSo),e(j_,aSo),e(y,nSo),e(y,D_),e(D_,G1e),e(G1e,sSo),e(D_,lSo),e(D_,IX),e(IX,iSo),e(D_,dSo),e(y,mSo),e(y,G_),e(G_,O1e),e(O1e,cSo),e(G_,fSo),e(G_,NX),e(NX,gSo),e(G_,hSo),e(y,uSo),e(y,O_),e(O_,V1e),e(V1e,pSo),e(O_,_So),e(O_,qX),e(qX,bSo),e(O_,vSo),e(y,FSo),e(y,V_),e(V_,X1e),e(X1e,TSo),e(V_,MSo),e(V_,jX),e(jX,ESo),e(V_,CSo),e(y,wSo),e(y,X_),e(X_,z1e),e(z1e,ASo),e(X_,LSo),e(X_,DX),e(DX,ySo),e(X_,xSo),e(y,$So),e(y,z_),e(z_,Q1e),e(Q1e,kSo),e(z_,SSo),e(z_,GX),e(GX,RSo),e(z_,PSo),e(y,BSo),e(y,Q_),e(Q_,W1e),e(W1e,ISo),e(Q_,NSo),e(Q_,OX),e(OX,qSo),e(Q_,jSo),e(y,DSo),e(y,W_),e(W_,U1e),e(U1e,GSo),e(W_,OSo),e(W_,VX),e(VX,VSo),e(W_,XSo),e(y,zSo),e(y,U_),e(U_,H1e),e(H1e,QSo),e(U_,WSo),e(U_,XX),e(XX,USo),e(U_,HSo),e(y,JSo),e(y,H_),e(H_,J1e),e(J1e,YSo),e(H_,ZSo),e(H_,zX),e(zX,KSo),e(H_,eRo),e(y,oRo),e(y,J_),e(J_,Y1e),e(Y1e,rRo),e(J_,tRo),e(J_,QX),e(QX,aRo),e(J_,nRo),e(y,sRo),e(y,Y_),e(Y_,Z1e),e(Z1e,lRo),e(Y_,iRo),e(Y_,WX),e(WX,dRo),e(Y_,mRo),e(y,cRo),e(y,Z_),e(Z_,K1e),e(K1e,fRo),e(Z_,gRo),e(Z_,UX),e(UX,hRo),e(Z_,uRo),e(y,pRo),e(y,K_),e(K_,e2e),e(e2e,_Ro),e(K_,bRo),e(K_,HX),e(HX,vRo),e(K_,FRo),e(y,TRo),e(y,e1),e(e1,o2e),e(o2e,MRo),e(e1,ERo),e(e1,JX),e(JX,CRo),e(e1,wRo),e(y,ARo),e(y,o1),e(o1,r2e),e(r2e,LRo),e(o1,yRo),e(o1,YX),e(YX,xRo),e(o1,$Ro),e(y,kRo),e(y,r1),e(r1,t2e),e(t2e,SRo),e(r1,RRo),e(r1,ZX),e(ZX,PRo),e(r1,BRo),e(y,IRo),e(y,t1),e(t1,a2e),e(a2e,NRo),e(t1,qRo),e(t1,KX),e(KX,jRo),e(t1,DRo),e(y,GRo),e(y,a1),e(a1,n2e),e(n2e,ORo),e(a1,VRo),e(a1,ez),e(ez,XRo),e(a1,zRo),e(y,QRo),e(y,n1),e(n1,s2e),e(s2e,WRo),e(n1,URo),e(n1,oz),e(oz,HRo),e(n1,JRo),e(y,YRo),e(y,s1),e(s1,l2e),e(l2e,ZRo),e(s1,KRo),e(s1,rz),e(rz,ePo),e(s1,oPo),e(y,rPo),e(y,l1),e(l1,i2e),e(i2e,tPo),e(l1,aPo),e(l1,tz),e(tz,nPo),e(l1,sPo),e(y,lPo),e(y,i1),e(i1,d2e),e(d2e,iPo),e(i1,dPo),e(i1,az),e(az,mPo),e(i1,cPo),e(y,fPo),e(y,d1),e(d1,m2e),e(m2e,gPo),e(d1,hPo),e(d1,nz),e(nz,uPo),e(d1,pPo),e(y,_Po),e(y,m1),e(m1,c2e),e(c2e,bPo),e(m1,vPo),e(m1,sz),e(sz,FPo),e(m1,TPo),e(y,MPo),e(y,c1),e(c1,f2e),e(f2e,EPo),e(c1,CPo),e(c1,lz),e(lz,wPo),e(c1,APo),e(y,LPo),e(y,f1),e(f1,g2e),e(g2e,yPo),e(f1,xPo),e(f1,iz),e(iz,$Po),e(f1,kPo),e(y,SPo),e(y,g1),e(g1,h2e),e(h2e,RPo),e(g1,PPo),e(g1,dz),e(dz,BPo),e(g1,IPo),e(y,NPo),e(y,h1),e(h1,u2e),e(u2e,qPo),e(h1,jPo),e(h1,mz),e(mz,DPo),e(h1,GPo),e(y,OPo),e(y,u1),e(u1,p2e),e(p2e,VPo),e(u1,XPo),e(u1,cz),e(cz,zPo),e(u1,QPo),e(y,WPo),e(y,p1),e(p1,_2e),e(_2e,UPo),e(p1,HPo),e(p1,fz),e(fz,JPo),e(p1,YPo),e(y,ZPo),e(y,_1),e(_1,b2e),e(b2e,KPo),e(_1,eBo),e(_1,gz),e(gz,oBo),e(_1,rBo),e(y,tBo),e(y,b1),e(b1,v2e),e(v2e,aBo),e(b1,nBo),e(b1,hz),e(hz,sBo),e(b1,lBo),e(y,iBo),e(y,xl),e(xl,F2e),e(F2e,dBo),e(xl,mBo),e(xl,uz),e(uz,cBo),e(xl,fBo),e(xl,pz),e(pz,gBo),e(xl,hBo),e(y,uBo),e(y,v1),e(v1,T2e),e(T2e,pBo),e(v1,_Bo),e(v1,_z),e(_z,bBo),e(v1,vBo),e(y,FBo),e(y,F1),e(F1,M2e),e(M2e,TBo),e(F1,MBo),e(F1,bz),e(bz,EBo),e(F1,CBo),e(y,wBo),e(y,T1),e(T1,E2e),e(E2e,ABo),e(T1,LBo),e(T1,vz),e(vz,yBo),e(T1,xBo),e(y,$Bo),e(y,M1),e(M1,C2e),e(C2e,kBo),e(M1,SBo),e(M1,Fz),e(Fz,RBo),e(M1,PBo),e(y,BBo),e(y,E1),e(E1,w2e),e(w2e,IBo),e(E1,NBo),e(E1,Tz),e(Tz,qBo),e(E1,jBo),e(y,DBo),e(y,C1),e(C1,A2e),e(A2e,GBo),e(C1,OBo),e(C1,Mz),e(Mz,VBo),e(C1,XBo),e(y,zBo),e(y,w1),e(w1,L2e),e(L2e,QBo),e(w1,WBo),e(w1,Ez),e(Ez,UBo),e(w1,HBo),e(y,JBo),e(y,A1),e(A1,y2e),e(y2e,YBo),e(A1,ZBo),e(A1,Cz),e(Cz,KBo),e(A1,eIo),e(y,oIo),e(y,L1),e(L1,x2e),e(x2e,rIo),e(L1,tIo),e(L1,wz),e(wz,aIo),e(L1,nIo),e(y,sIo),e(y,y1),e(y1,$2e),e($2e,lIo),e(y1,iIo),e(y1,Az),e(Az,dIo),e(y1,mIo),e(y,cIo),e(y,x1),e(x1,k2e),e(k2e,fIo),e(x1,gIo),e(x1,Lz),e(Lz,hIo),e(x1,uIo),e(y,pIo),e(y,$1),e($1,S2e),e(S2e,_Io),e($1,bIo),e($1,yz),e(yz,vIo),e($1,FIo),e(y,TIo),e(y,k1),e(k1,R2e),e(R2e,MIo),e(k1,EIo),e(k1,xz),e(xz,CIo),e(k1,wIo),e(y,AIo),e(y,S1),e(S1,P2e),e(P2e,LIo),e(S1,yIo),e(S1,$z),e($z,xIo),e(S1,$Io),e(y,kIo),e(y,R1),e(R1,B2e),e(B2e,SIo),e(R1,RIo),e(R1,kz),e(kz,PIo),e(R1,BIo),e(y,IIo),e(y,P1),e(P1,I2e),e(I2e,NIo),e(P1,qIo),e(P1,Sz),e(Sz,jIo),e(P1,DIo),e(y,GIo),e(y,B1),e(B1,N2e),e(N2e,OIo),e(B1,VIo),e(B1,Rz),e(Rz,XIo),e(B1,zIo),e(y,QIo),e(y,I1),e(I1,q2e),e(q2e,WIo),e(I1,UIo),e(I1,Pz),e(Pz,HIo),e(I1,JIo),e(y,YIo),e(y,N1),e(N1,j2e),e(j2e,ZIo),e(N1,KIo),e(N1,Bz),e(Bz,eNo),e(N1,oNo),e(y,rNo),e(y,q1),e(q1,D2e),e(D2e,tNo),e(q1,aNo),e(q1,Iz),e(Iz,nNo),e(q1,sNo),e(y,lNo),e(y,j1),e(j1,G2e),e(G2e,iNo),e(j1,dNo),e(j1,Nz),e(Nz,mNo),e(j1,cNo),e(y,fNo),e(y,D1),e(D1,O2e),e(O2e,gNo),e(D1,hNo),e(D1,qz),e(qz,uNo),e(D1,pNo),e(y,_No),e(y,G1),e(G1,V2e),e(V2e,bNo),e(G1,vNo),e(G1,jz),e(jz,FNo),e(G1,TNo),e(y,MNo),e(y,O1),e(O1,X2e),e(X2e,ENo),e(O1,CNo),e(O1,Dz),e(Dz,wNo),e(O1,ANo),e(y,LNo),e(y,V1),e(V1,z2e),e(z2e,yNo),e(V1,xNo),e(V1,Gz),e(Gz,$No),e(V1,kNo),e(y,SNo),e(y,X1),e(X1,Q2e),e(Q2e,RNo),e(X1,PNo),e(X1,Oz),e(Oz,BNo),e(X1,INo),e(y,NNo),e(y,z1),e(z1,W2e),e(W2e,qNo),e(z1,jNo),e(z1,Vz),e(Vz,DNo),e(z1,GNo),e(y,ONo),e(y,Q1),e(Q1,U2e),e(U2e,VNo),e(Q1,XNo),e(Q1,Xz),e(Xz,zNo),e(Q1,QNo),e(y,WNo),e(y,W1),e(W1,H2e),e(H2e,UNo),e(W1,HNo),e(W1,zz),e(zz,JNo),e(W1,YNo),e(y,ZNo),e(y,U1),e(U1,J2e),e(J2e,KNo),e(U1,eqo),e(U1,Qz),e(Qz,oqo),e(U1,rqo),e(y,tqo),e(y,H1),e(H1,Y2e),e(Y2e,aqo),e(H1,nqo),e(H1,Wz),e(Wz,sqo),e(H1,lqo),e(y,iqo),e(y,J1),e(J1,Z2e),e(Z2e,dqo),e(J1,mqo),e(J1,Uz),e(Uz,cqo),e(J1,fqo),e(y,gqo),e(y,Y1),e(Y1,K2e),e(K2e,hqo),e(Y1,uqo),e(Y1,Hz),e(Hz,pqo),e(Y1,_qo),e(y,bqo),e(y,Z1),e(Z1,ebe),e(ebe,vqo),e(Z1,Fqo),e(Z1,Jz),e(Jz,Tqo),e(Z1,Mqo),e(y,Eqo),e(y,K1),e(K1,obe),e(obe,Cqo),e(K1,wqo),e(K1,Yz),e(Yz,Aqo),e(K1,Lqo),e(y,yqo),e(y,e2),e(e2,rbe),e(rbe,xqo),e(e2,$qo),e(e2,Zz),e(Zz,kqo),e(e2,Sqo),e(y,Rqo),e(y,o2),e(o2,tbe),e(tbe,Pqo),e(o2,Bqo),e(o2,Kz),e(Kz,Iqo),e(o2,Nqo),e(y,qqo),e(y,r2),e(r2,abe),e(abe,jqo),e(r2,Dqo),e(r2,eQ),e(eQ,Gqo),e(r2,Oqo),e(y,Vqo),e(y,t2),e(t2,nbe),e(nbe,Xqo),e(t2,zqo),e(t2,oQ),e(oQ,Qqo),e(t2,Wqo),e(y,Uqo),e(y,a2),e(a2,sbe),e(sbe,Hqo),e(a2,Jqo),e(a2,rQ),e(rQ,Yqo),e(a2,Zqo),e(y,Kqo),e(y,n2),e(n2,lbe),e(lbe,ejo),e(n2,ojo),e(n2,tQ),e(tQ,rjo),e(n2,tjo),e(y,ajo),e(y,s2),e(s2,ibe),e(ibe,njo),e(s2,sjo),e(s2,aQ),e(aQ,ljo),e(s2,ijo),e(y,djo),e(y,l2),e(l2,dbe),e(dbe,mjo),e(l2,cjo),e(l2,nQ),e(nQ,fjo),e(l2,gjo),e(y,hjo),e(y,i2),e(i2,mbe),e(mbe,ujo),e(i2,pjo),e(i2,sQ),e(sQ,_jo),e(i2,bjo),e(y,vjo),e(y,d2),e(d2,cbe),e(cbe,Fjo),e(d2,Tjo),e(d2,lQ),e(lQ,Mjo),e(d2,Ejo),e(y,Cjo),e(y,m2),e(m2,fbe),e(fbe,wjo),e(m2,Ajo),e(m2,iQ),e(iQ,Ljo),e(m2,yjo),e(y,xjo),e(y,c2),e(c2,gbe),e(gbe,$jo),e(c2,kjo),e(c2,dQ),e(dQ,Sjo),e(c2,Rjo),e(y,Pjo),e(y,f2),e(f2,hbe),e(hbe,Bjo),e(f2,Ijo),e(f2,mQ),e(mQ,Njo),e(f2,qjo),e(y,jjo),e(y,g2),e(g2,ube),e(ube,Djo),e(g2,Gjo),e(g2,cQ),e(cQ,Ojo),e(g2,Vjo),e(y,Xjo),e(y,h2),e(h2,pbe),e(pbe,zjo),e(h2,Qjo),e(h2,fQ),e(fQ,Wjo),e(h2,Ujo),e(y,Hjo),e(y,u2),e(u2,_be),e(_be,Jjo),e(u2,Yjo),e(u2,gQ),e(gQ,Zjo),e(u2,Kjo),e(y,eDo),e(y,p2),e(p2,bbe),e(bbe,oDo),e(p2,rDo),e(p2,hQ),e(hQ,tDo),e(p2,aDo),e(y,nDo),e(y,_2),e(_2,vbe),e(vbe,sDo),e(_2,lDo),e(_2,uQ),e(uQ,iDo),e(_2,dDo),e(y,mDo),e(y,b2),e(b2,Fbe),e(Fbe,cDo),e(b2,fDo),e(b2,pQ),e(pQ,gDo),e(b2,hDo),e(y,uDo),e(y,v2),e(v2,Tbe),e(Tbe,pDo),e(v2,_Do),e(v2,_Q),e(_Q,bDo),e(v2,vDo),e(y,FDo),e(y,F2),e(F2,Mbe),e(Mbe,TDo),e(F2,MDo),e(F2,bQ),e(bQ,EDo),e(F2,CDo),e(y,wDo),e(y,T2),e(T2,Ebe),e(Ebe,ADo),e(T2,LDo),e(T2,vQ),e(vQ,yDo),e(T2,xDo),e(y,$Do),e(y,M2),e(M2,Cbe),e(Cbe,kDo),e(M2,SDo),e(M2,FQ),e(FQ,RDo),e(M2,PDo),e(y,BDo),e(y,E2),e(E2,wbe),e(wbe,IDo),e(E2,NDo),e(E2,TQ),e(TQ,qDo),e(E2,jDo),e(y,DDo),e(y,C2),e(C2,Abe),e(Abe,GDo),e(C2,ODo),e(C2,MQ),e(MQ,VDo),e(C2,XDo),e(y,zDo),e(y,w2),e(w2,Lbe),e(Lbe,QDo),e(w2,WDo),e(w2,EQ),e(EQ,UDo),e(w2,HDo),e(y,JDo),e(y,A2),e(A2,ybe),e(ybe,YDo),e(A2,ZDo),e(A2,CQ),e(CQ,KDo),e(A2,eGo),e(y,oGo),e(y,L2),e(L2,xbe),e(xbe,rGo),e(L2,tGo),e(L2,wQ),e(wQ,aGo),e(L2,nGo),e(y,sGo),e(y,y2),e(y2,$be),e($be,lGo),e(y2,iGo),e(y2,AQ),e(AQ,dGo),e(y2,mGo),e(y,cGo),e(y,x2),e(x2,kbe),e(kbe,fGo),e(x2,gGo),e(x2,LQ),e(LQ,hGo),e(x2,uGo),e(y,pGo),e(y,$2),e($2,Sbe),e(Sbe,_Go),e($2,bGo),e($2,yQ),e(yQ,vGo),e($2,FGo),e(y,TGo),e(y,k2),e(k2,Rbe),e(Rbe,MGo),e(k2,EGo),e(k2,xQ),e(xQ,CGo),e(k2,wGo),e(y,AGo),e(y,S2),e(S2,Pbe),e(Pbe,LGo),e(S2,yGo),e(S2,$Q),e($Q,xGo),e(S2,$Go),e(y,kGo),e(y,R2),e(R2,Bbe),e(Bbe,SGo),e(R2,RGo),e(R2,kQ),e(kQ,PGo),e(R2,BGo),e(y,IGo),e(y,P2),e(P2,Ibe),e(Ibe,NGo),e(P2,qGo),e(P2,SQ),e(SQ,jGo),e(P2,DGo),e(y,GGo),e(y,B2),e(B2,Nbe),e(Nbe,OGo),e(B2,VGo),e(B2,RQ),e(RQ,XGo),e(B2,zGo),e(y,QGo),e(y,I2),e(I2,qbe),e(qbe,WGo),e(I2,UGo),e(I2,PQ),e(PQ,HGo),e(I2,JGo),e(y,YGo),e(y,N2),e(N2,jbe),e(jbe,ZGo),e(N2,KGo),e(N2,BQ),e(BQ,eOo),e(N2,oOo),e(y,rOo),e(y,q2),e(q2,Dbe),e(Dbe,tOo),e(q2,aOo),e(q2,IQ),e(IQ,nOo),e(q2,sOo),e(y,lOo),e(y,j2),e(j2,Gbe),e(Gbe,iOo),e(j2,dOo),e(j2,NQ),e(NQ,mOo),e(j2,cOo),e(y,fOo),e(y,D2),e(D2,Obe),e(Obe,gOo),e(D2,hOo),e(D2,qQ),e(qQ,uOo),e(D2,pOo),e(y,_Oo),e(y,G2),e(G2,Vbe),e(Vbe,bOo),e(G2,vOo),e(G2,jQ),e(jQ,FOo),e(G2,TOo),e(y,MOo),e(y,O2),e(O2,Xbe),e(Xbe,EOo),e(O2,COo),e(O2,DQ),e(DQ,wOo),e(O2,AOo),e(y,LOo),e(y,V2),e(V2,zbe),e(zbe,yOo),e(V2,xOo),e(V2,GQ),e(GQ,$Oo),e(V2,kOo),e(y,SOo),e(y,X2),e(X2,Qbe),e(Qbe,ROo),e(X2,POo),e(X2,OQ),e(OQ,BOo),e(X2,IOo),e(y,NOo),e(y,z2),e(z2,Wbe),e(Wbe,qOo),e(z2,jOo),e(z2,VQ),e(VQ,DOo),e(z2,GOo),e(y,OOo),e(y,Q2),e(Q2,Ube),e(Ube,VOo),e(Q2,XOo),e(Q2,XQ),e(XQ,zOo),e(Q2,QOo),e(y,WOo),e(y,W2),e(W2,Hbe),e(Hbe,UOo),e(W2,HOo),e(W2,zQ),e(zQ,JOo),e(W2,YOo),e(y,ZOo),e(y,U2),e(U2,Jbe),e(Jbe,KOo),e(U2,eVo),e(U2,QQ),e(QQ,oVo),e(U2,rVo),e(y,tVo),e(y,H2),e(H2,Ybe),e(Ybe,aVo),e(H2,nVo),e(H2,WQ),e(WQ,sVo),e(H2,lVo),e(y,iVo),e(y,J2),e(J2,Zbe),e(Zbe,dVo),e(J2,mVo),e(J2,UQ),e(UQ,cVo),e(J2,fVo),e(y,gVo),e(y,Y2),e(Y2,Kbe),e(Kbe,hVo),e(Y2,uVo),e(Y2,HQ),e(HQ,pVo),e(Y2,_Vo),e(y,bVo),e(y,Z2),e(Z2,eve),e(eve,vVo),e(Z2,FVo),e(Z2,JQ),e(JQ,TVo),e(Z2,MVo),e(y,EVo),e(y,K2),e(K2,ove),e(ove,CVo),e(K2,wVo),e(K2,YQ),e(YQ,AVo),e(K2,LVo),e(Ke,yVo),e(Ke,eb),e(eb,xVo),e(eb,rve),e(rve,$Vo),e(eb,kVo),e(eb,tve),e(tve,SVo),e(Ke,RVo),M(ob,Ke,null),b(c,Dto,_),b(c,Bd,_),e(Bd,rb),e(rb,ave),M(D$,ave,null),e(Bd,PVo),e(Bd,nve),e(nve,BVo),b(c,Gto,_),b(c,No,_),M(G$,No,null),e(No,IVo),e(No,Id),e(Id,NVo),e(Id,ZQ),e(ZQ,qVo),e(Id,jVo),e(Id,KQ),e(KQ,DVo),e(Id,GVo),e(No,OVo),e(No,O$),e(O$,VVo),e(O$,sve),e(sve,XVo),e(O$,zVo),e(No,QVo),e(No,Et),M(V$,Et,null),e(Et,WVo),e(Et,lve),e(lve,UVo),e(Et,HVo),e(Et,Nd),e(Nd,JVo),e(Nd,ive),e(ive,YVo),e(Nd,ZVo),e(Nd,eW),e(eW,KVo),e(Nd,eXo),e(Et,oXo),M(tb,Et,null),e(No,rXo),e(No,eo),M(X$,eo,null),e(eo,tXo),e(eo,dve),e(dve,aXo),e(eo,nXo),e(eo,sn),e(sn,sXo),e(sn,mve),e(mve,lXo),e(sn,iXo),e(sn,cve),e(cve,dXo),e(sn,mXo),e(sn,fve),e(fve,cXo),e(sn,fXo),e(eo,gXo),e(eo,G),e(G,ab),e(ab,gve),e(gve,hXo),e(ab,uXo),e(ab,oW),e(oW,pXo),e(ab,_Xo),e(G,bXo),e(G,nb),e(nb,hve),e(hve,vXo),e(nb,FXo),e(nb,rW),e(rW,TXo),e(nb,MXo),e(G,EXo),e(G,sb),e(sb,uve),e(uve,CXo),e(sb,wXo),e(sb,tW),e(tW,AXo),e(sb,LXo),e(G,yXo),e(G,lb),e(lb,pve),e(pve,xXo),e(lb,$Xo),e(lb,aW),e(aW,kXo),e(lb,SXo),e(G,RXo),e(G,ib),e(ib,_ve),e(_ve,PXo),e(ib,BXo),e(ib,nW),e(nW,IXo),e(ib,NXo),e(G,qXo),e(G,db),e(db,bve),e(bve,jXo),e(db,DXo),e(db,sW),e(sW,GXo),e(db,OXo),e(G,VXo),e(G,mb),e(mb,vve),e(vve,XXo),e(mb,zXo),e(mb,lW),e(lW,QXo),e(mb,WXo),e(G,UXo),e(G,cb),e(cb,Fve),e(Fve,HXo),e(cb,JXo),e(cb,iW),e(iW,YXo),e(cb,ZXo),e(G,KXo),e(G,fb),e(fb,Tve),e(Tve,ezo),e(fb,ozo),e(fb,dW),e(dW,rzo),e(fb,tzo),e(G,azo),e(G,gb),e(gb,Mve),e(Mve,nzo),e(gb,szo),e(gb,mW),e(mW,lzo),e(gb,izo),e(G,dzo),e(G,hb),e(hb,Eve),e(Eve,mzo),e(hb,czo),e(hb,cW),e(cW,fzo),e(hb,gzo),e(G,hzo),e(G,ub),e(ub,Cve),e(Cve,uzo),e(ub,pzo),e(ub,fW),e(fW,_zo),e(ub,bzo),e(G,vzo),e(G,pb),e(pb,wve),e(wve,Fzo),e(pb,Tzo),e(pb,gW),e(gW,Mzo),e(pb,Ezo),e(G,Czo),e(G,_b),e(_b,Ave),e(Ave,wzo),e(_b,Azo),e(_b,hW),e(hW,Lzo),e(_b,yzo),e(G,xzo),e(G,bb),e(bb,Lve),e(Lve,$zo),e(bb,kzo),e(bb,uW),e(uW,Szo),e(bb,Rzo),e(G,Pzo),e(G,vb),e(vb,yve),e(yve,Bzo),e(vb,Izo),e(vb,pW),e(pW,Nzo),e(vb,qzo),e(G,jzo),e(G,Fb),e(Fb,xve),e(xve,Dzo),e(Fb,Gzo),e(Fb,_W),e(_W,Ozo),e(Fb,Vzo),e(G,Xzo),e(G,Tb),e(Tb,$ve),e($ve,zzo),e(Tb,Qzo),e(Tb,bW),e(bW,Wzo),e(Tb,Uzo),e(G,Hzo),e(G,Mb),e(Mb,kve),e(kve,Jzo),e(Mb,Yzo),e(Mb,vW),e(vW,Zzo),e(Mb,Kzo),e(G,eQo),e(G,Eb),e(Eb,Sve),e(Sve,oQo),e(Eb,rQo),e(Eb,FW),e(FW,tQo),e(Eb,aQo),e(G,nQo),e(G,Cb),e(Cb,Rve),e(Rve,sQo),e(Cb,lQo),e(Cb,TW),e(TW,iQo),e(Cb,dQo),e(G,mQo),e(G,wb),e(wb,Pve),e(Pve,cQo),e(wb,fQo),e(wb,MW),e(MW,gQo),e(wb,hQo),e(G,uQo),e(G,Ab),e(Ab,Bve),e(Bve,pQo),e(Ab,_Qo),e(Ab,EW),e(EW,bQo),e(Ab,vQo),e(G,FQo),e(G,Lb),e(Lb,Ive),e(Ive,TQo),e(Lb,MQo),e(Lb,CW),e(CW,EQo),e(Lb,CQo),e(G,wQo),e(G,yb),e(yb,Nve),e(Nve,AQo),e(yb,LQo),e(yb,wW),e(wW,yQo),e(yb,xQo),e(G,$Qo),e(G,xb),e(xb,qve),e(qve,kQo),e(xb,SQo),e(xb,AW),e(AW,RQo),e(xb,PQo),e(G,BQo),e(G,$b),e($b,jve),e(jve,IQo),e($b,NQo),e($b,LW),e(LW,qQo),e($b,jQo),e(G,DQo),e(G,kb),e(kb,Dve),e(Dve,GQo),e(kb,OQo),e(kb,yW),e(yW,VQo),e(kb,XQo),e(G,zQo),e(G,Sb),e(Sb,Gve),e(Gve,QQo),e(Sb,WQo),e(Sb,xW),e(xW,UQo),e(Sb,HQo),e(G,JQo),e(G,Rb),e(Rb,Ove),e(Ove,YQo),e(Rb,ZQo),e(Rb,$W),e($W,KQo),e(Rb,eWo),e(G,oWo),e(G,Pb),e(Pb,Vve),e(Vve,rWo),e(Pb,tWo),e(Pb,kW),e(kW,aWo),e(Pb,nWo),e(G,sWo),e(G,Bb),e(Bb,Xve),e(Xve,lWo),e(Bb,iWo),e(Bb,SW),e(SW,dWo),e(Bb,mWo),e(G,cWo),e(G,Ib),e(Ib,zve),e(zve,fWo),e(Ib,gWo),e(Ib,RW),e(RW,hWo),e(Ib,uWo),e(G,pWo),e(G,Nb),e(Nb,Qve),e(Qve,_Wo),e(Nb,bWo),e(Nb,PW),e(PW,vWo),e(Nb,FWo),e(G,TWo),e(G,qb),e(qb,Wve),e(Wve,MWo),e(qb,EWo),e(qb,BW),e(BW,CWo),e(qb,wWo),e(G,AWo),e(G,jb),e(jb,Uve),e(Uve,LWo),e(jb,yWo),e(jb,IW),e(IW,xWo),e(jb,$Wo),e(G,kWo),e(G,Db),e(Db,Hve),e(Hve,SWo),e(Db,RWo),e(Db,NW),e(NW,PWo),e(Db,BWo),e(G,IWo),e(G,Gb),e(Gb,Jve),e(Jve,NWo),e(Gb,qWo),e(Gb,qW),e(qW,jWo),e(Gb,DWo),e(G,GWo),e(G,Ob),e(Ob,Yve),e(Yve,OWo),e(Ob,VWo),e(Ob,jW),e(jW,XWo),e(Ob,zWo),e(G,QWo),e(G,Vb),e(Vb,Zve),e(Zve,WWo),e(Vb,UWo),e(Vb,DW),e(DW,HWo),e(Vb,JWo),e(G,YWo),e(G,Xb),e(Xb,Kve),e(Kve,ZWo),e(Xb,KWo),e(Xb,GW),e(GW,eUo),e(Xb,oUo),e(G,rUo),e(G,zb),e(zb,eFe),e(eFe,tUo),e(zb,aUo),e(zb,OW),e(OW,nUo),e(zb,sUo),e(G,lUo),e(G,Qb),e(Qb,oFe),e(oFe,iUo),e(Qb,dUo),e(Qb,VW),e(VW,mUo),e(Qb,cUo),e(G,fUo),e(G,Wb),e(Wb,rFe),e(rFe,gUo),e(Wb,hUo),e(Wb,XW),e(XW,uUo),e(Wb,pUo),e(G,_Uo),e(G,Ub),e(Ub,tFe),e(tFe,bUo),e(Ub,vUo),e(Ub,zW),e(zW,FUo),e(Ub,TUo),e(G,MUo),e(G,Hb),e(Hb,aFe),e(aFe,EUo),e(Hb,CUo),e(Hb,QW),e(QW,wUo),e(Hb,AUo),e(G,LUo),e(G,Jb),e(Jb,nFe),e(nFe,yUo),e(Jb,xUo),e(Jb,WW),e(WW,$Uo),e(Jb,kUo),e(G,SUo),e(G,Yb),e(Yb,sFe),e(sFe,RUo),e(Yb,PUo),e(Yb,UW),e(UW,BUo),e(Yb,IUo),e(eo,NUo),e(eo,Zb),e(Zb,qUo),e(Zb,lFe),e(lFe,jUo),e(Zb,DUo),e(Zb,iFe),e(iFe,GUo),e(eo,OUo),M(Kb,eo,null),b(c,Oto,_),b(c,qd,_),e(qd,ev),e(ev,dFe),M(z$,dFe,null),e(qd,VUo),e(qd,mFe),e(mFe,XUo),b(c,Vto,_),b(c,qo,_),M(Q$,qo,null),e(qo,zUo),e(qo,jd),e(jd,QUo),e(jd,HW),e(HW,WUo),e(jd,UUo),e(jd,JW),e(JW,HUo),e(jd,JUo),e(qo,YUo),e(qo,W$),e(W$,ZUo),e(W$,cFe),e(cFe,KUo),e(W$,eHo),e(qo,oHo),e(qo,Ct),M(U$,Ct,null),e(Ct,rHo),e(Ct,fFe),e(fFe,tHo),e(Ct,aHo),e(Ct,Dd),e(Dd,nHo),e(Dd,gFe),e(gFe,sHo),e(Dd,lHo),e(Dd,YW),e(YW,iHo),e(Dd,dHo),e(Ct,mHo),M(ov,Ct,null),e(qo,cHo),e(qo,oo),M(H$,oo,null),e(oo,fHo),e(oo,hFe),e(hFe,gHo),e(oo,hHo),e(oo,ln),e(ln,uHo),e(ln,uFe),e(uFe,pHo),e(ln,_Ho),e(ln,pFe),e(pFe,bHo),e(ln,vHo),e(ln,_Fe),e(_Fe,FHo),e(ln,THo),e(oo,MHo),e(oo,W),e(W,rv),e(rv,bFe),e(bFe,EHo),e(rv,CHo),e(rv,ZW),e(ZW,wHo),e(rv,AHo),e(W,LHo),e(W,tv),e(tv,vFe),e(vFe,yHo),e(tv,xHo),e(tv,KW),e(KW,$Ho),e(tv,kHo),e(W,SHo),e(W,av),e(av,FFe),e(FFe,RHo),e(av,PHo),e(av,eU),e(eU,BHo),e(av,IHo),e(W,NHo),e(W,nv),e(nv,TFe),e(TFe,qHo),e(nv,jHo),e(nv,oU),e(oU,DHo),e(nv,GHo),e(W,OHo),e(W,sv),e(sv,MFe),e(MFe,VHo),e(sv,XHo),e(sv,rU),e(rU,zHo),e(sv,QHo),e(W,WHo),e(W,lv),e(lv,EFe),e(EFe,UHo),e(lv,HHo),e(lv,tU),e(tU,JHo),e(lv,YHo),e(W,ZHo),e(W,iv),e(iv,CFe),e(CFe,KHo),e(iv,eJo),e(iv,aU),e(aU,oJo),e(iv,rJo),e(W,tJo),e(W,dv),e(dv,wFe),e(wFe,aJo),e(dv,nJo),e(dv,nU),e(nU,sJo),e(dv,lJo),e(W,iJo),e(W,mv),e(mv,AFe),e(AFe,dJo),e(mv,mJo),e(mv,sU),e(sU,cJo),e(mv,fJo),e(W,gJo),e(W,cv),e(cv,LFe),e(LFe,hJo),e(cv,uJo),e(cv,lU),e(lU,pJo),e(cv,_Jo),e(W,bJo),e(W,fv),e(fv,yFe),e(yFe,vJo),e(fv,FJo),e(fv,iU),e(iU,TJo),e(fv,MJo),e(W,EJo),e(W,gv),e(gv,xFe),e(xFe,CJo),e(gv,wJo),e(gv,dU),e(dU,AJo),e(gv,LJo),e(W,yJo),e(W,hv),e(hv,$Fe),e($Fe,xJo),e(hv,$Jo),e(hv,mU),e(mU,kJo),e(hv,SJo),e(W,RJo),e(W,uv),e(uv,kFe),e(kFe,PJo),e(uv,BJo),e(uv,cU),e(cU,IJo),e(uv,NJo),e(W,qJo),e(W,pv),e(pv,SFe),e(SFe,jJo),e(pv,DJo),e(pv,fU),e(fU,GJo),e(pv,OJo),e(W,VJo),e(W,_v),e(_v,RFe),e(RFe,XJo),e(_v,zJo),e(_v,gU),e(gU,QJo),e(_v,WJo),e(W,UJo),e(W,bv),e(bv,PFe),e(PFe,HJo),e(bv,JJo),e(bv,hU),e(hU,YJo),e(bv,ZJo),e(W,KJo),e(W,vv),e(vv,BFe),e(BFe,eYo),e(vv,oYo),e(vv,uU),e(uU,rYo),e(vv,tYo),e(W,aYo),e(W,Fv),e(Fv,IFe),e(IFe,nYo),e(Fv,sYo),e(Fv,pU),e(pU,lYo),e(Fv,iYo),e(W,dYo),e(W,Tv),e(Tv,NFe),e(NFe,mYo),e(Tv,cYo),e(Tv,_U),e(_U,fYo),e(Tv,gYo),e(W,hYo),e(W,Mv),e(Mv,qFe),e(qFe,uYo),e(Mv,pYo),e(Mv,bU),e(bU,_Yo),e(Mv,bYo),e(W,vYo),e(W,Ev),e(Ev,jFe),e(jFe,FYo),e(Ev,TYo),e(Ev,vU),e(vU,MYo),e(Ev,EYo),e(W,CYo),e(W,Cv),e(Cv,DFe),e(DFe,wYo),e(Cv,AYo),e(Cv,FU),e(FU,LYo),e(Cv,yYo),e(W,xYo),e(W,wv),e(wv,GFe),e(GFe,$Yo),e(wv,kYo),e(wv,TU),e(TU,SYo),e(wv,RYo),e(W,PYo),e(W,Av),e(Av,OFe),e(OFe,BYo),e(Av,IYo),e(Av,MU),e(MU,NYo),e(Av,qYo),e(W,jYo),e(W,Lv),e(Lv,VFe),e(VFe,DYo),e(Lv,GYo),e(Lv,EU),e(EU,OYo),e(Lv,VYo),e(W,XYo),e(W,yv),e(yv,XFe),e(XFe,zYo),e(yv,QYo),e(yv,CU),e(CU,WYo),e(yv,UYo),e(W,HYo),e(W,xv),e(xv,zFe),e(zFe,JYo),e(xv,YYo),e(xv,wU),e(wU,ZYo),e(xv,KYo),e(W,eZo),e(W,$v),e($v,QFe),e(QFe,oZo),e($v,rZo),e($v,AU),e(AU,tZo),e($v,aZo),e(W,nZo),e(W,kv),e(kv,WFe),e(WFe,sZo),e(kv,lZo),e(kv,LU),e(LU,iZo),e(kv,dZo),e(W,mZo),e(W,Sv),e(Sv,UFe),e(UFe,cZo),e(Sv,fZo),e(Sv,yU),e(yU,gZo),e(Sv,hZo),e(W,uZo),e(W,Rv),e(Rv,HFe),e(HFe,pZo),e(Rv,_Zo),e(Rv,xU),e(xU,bZo),e(Rv,vZo),e(W,FZo),e(W,Pv),e(Pv,JFe),e(JFe,TZo),e(Pv,MZo),e(Pv,$U),e($U,EZo),e(Pv,CZo),e(W,wZo),e(W,Bv),e(Bv,YFe),e(YFe,AZo),e(Bv,LZo),e(Bv,kU),e(kU,yZo),e(Bv,xZo),e(W,$Zo),e(W,Iv),e(Iv,ZFe),e(ZFe,kZo),e(Iv,SZo),e(Iv,SU),e(SU,RZo),e(Iv,PZo),e(W,BZo),e(W,Nv),e(Nv,KFe),e(KFe,IZo),e(Nv,NZo),e(Nv,RU),e(RU,qZo),e(Nv,jZo),e(W,DZo),e(W,qv),e(qv,eTe),e(eTe,GZo),e(qv,OZo),e(qv,PU),e(PU,VZo),e(qv,XZo),e(W,zZo),e(W,jv),e(jv,oTe),e(oTe,QZo),e(jv,WZo),e(jv,BU),e(BU,UZo),e(jv,HZo),e(W,JZo),e(W,Dv),e(Dv,rTe),e(rTe,YZo),e(Dv,ZZo),e(Dv,IU),e(IU,KZo),e(Dv,eKo),e(W,oKo),e(W,Gv),e(Gv,tTe),e(tTe,rKo),e(Gv,tKo),e(Gv,NU),e(NU,aKo),e(Gv,nKo),e(W,sKo),e(W,Ov),e(Ov,aTe),e(aTe,lKo),e(Ov,iKo),e(Ov,qU),e(qU,dKo),e(Ov,mKo),e(W,cKo),e(W,Vv),e(Vv,nTe),e(nTe,fKo),e(Vv,gKo),e(Vv,jU),e(jU,hKo),e(Vv,uKo),e(oo,pKo),e(oo,Xv),e(Xv,_Ko),e(Xv,sTe),e(sTe,bKo),e(Xv,vKo),e(Xv,lTe),e(lTe,FKo),e(oo,TKo),M(zv,oo,null),b(c,Xto,_),b(c,Gd,_),e(Gd,Qv),e(Qv,iTe),M(J$,iTe,null),e(Gd,MKo),e(Gd,dTe),e(dTe,EKo),b(c,zto,_),b(c,jo,_),M(Y$,jo,null),e(jo,CKo),e(jo,Od),e(Od,wKo),e(Od,DU),e(DU,AKo),e(Od,LKo),e(Od,GU),e(GU,yKo),e(Od,xKo),e(jo,$Ko),e(jo,Z$),e(Z$,kKo),e(Z$,mTe),e(mTe,SKo),e(Z$,RKo),e(jo,PKo),e(jo,wt),M(K$,wt,null),e(wt,BKo),e(wt,cTe),e(cTe,IKo),e(wt,NKo),e(wt,Vd),e(Vd,qKo),e(Vd,fTe),e(fTe,jKo),e(Vd,DKo),e(Vd,OU),e(OU,GKo),e(Vd,OKo),e(wt,VKo),M(Wv,wt,null),e(jo,XKo),e(jo,ro),M(ek,ro,null),e(ro,zKo),e(ro,gTe),e(gTe,QKo),e(ro,WKo),e(ro,dn),e(dn,UKo),e(dn,hTe),e(hTe,HKo),e(dn,JKo),e(dn,uTe),e(uTe,YKo),e(dn,ZKo),e(dn,pTe),e(pTe,KKo),e(dn,eer),e(ro,oer),e(ro,ok),e(ok,Uv),e(Uv,_Te),e(_Te,rer),e(Uv,ter),e(Uv,VU),e(VU,aer),e(Uv,ner),e(ok,ser),e(ok,Hv),e(Hv,bTe),e(bTe,ler),e(Hv,ier),e(Hv,XU),e(XU,der),e(Hv,mer),e(ro,cer),e(ro,Jv),e(Jv,fer),e(Jv,vTe),e(vTe,ger),e(Jv,her),e(Jv,FTe),e(FTe,uer),e(ro,per),M(Yv,ro,null),b(c,Qto,_),b(c,Xd,_),e(Xd,Zv),e(Zv,TTe),M(rk,TTe,null),e(Xd,_er),e(Xd,MTe),e(MTe,ber),b(c,Wto,_),b(c,Do,_),M(tk,Do,null),e(Do,ver),e(Do,zd),e(zd,Fer),e(zd,zU),e(zU,Ter),e(zd,Mer),e(zd,QU),e(QU,Eer),e(zd,Cer),e(Do,wer),e(Do,ak),e(ak,Aer),e(ak,ETe),e(ETe,Ler),e(ak,yer),e(Do,xer),e(Do,At),M(nk,At,null),e(At,$er),e(At,CTe),e(CTe,ker),e(At,Ser),e(At,Qd),e(Qd,Rer),e(Qd,wTe),e(wTe,Per),e(Qd,Ber),e(Qd,WU),e(WU,Ier),e(Qd,Ner),e(At,qer),M(Kv,At,null),e(Do,jer),e(Do,to),M(sk,to,null),e(to,Der),e(to,ATe),e(ATe,Ger),e(to,Oer),e(to,mn),e(mn,Ver),e(mn,LTe),e(LTe,Xer),e(mn,zer),e(mn,yTe),e(yTe,Qer),e(mn,Wer),e(mn,xTe),e(xTe,Uer),e(mn,Her),e(to,Jer),e(to,Y),e(Y,eF),e(eF,$Te),e($Te,Yer),e(eF,Zer),e(eF,UU),e(UU,Ker),e(eF,eor),e(Y,oor),e(Y,oF),e(oF,kTe),e(kTe,ror),e(oF,tor),e(oF,HU),e(HU,aor),e(oF,nor),e(Y,sor),e(Y,rF),e(rF,STe),e(STe,lor),e(rF,ior),e(rF,JU),e(JU,dor),e(rF,mor),e(Y,cor),e(Y,tF),e(tF,RTe),e(RTe,gor),e(tF,hor),e(tF,YU),e(YU,uor),e(tF,por),e(Y,_or),e(Y,aF),e(aF,PTe),e(PTe,bor),e(aF,vor),e(aF,ZU),e(ZU,For),e(aF,Tor),e(Y,Mor),e(Y,nF),e(nF,BTe),e(BTe,Eor),e(nF,Cor),e(nF,KU),e(KU,wor),e(nF,Aor),e(Y,Lor),e(Y,sF),e(sF,ITe),e(ITe,yor),e(sF,xor),e(sF,eH),e(eH,$or),e(sF,kor),e(Y,Sor),e(Y,lF),e(lF,NTe),e(NTe,Ror),e(lF,Por),e(lF,oH),e(oH,Bor),e(lF,Ior),e(Y,Nor),e(Y,iF),e(iF,qTe),e(qTe,qor),e(iF,jor),e(iF,rH),e(rH,Dor),e(iF,Gor),e(Y,Oor),e(Y,dF),e(dF,jTe),e(jTe,Vor),e(dF,Xor),e(dF,tH),e(tH,zor),e(dF,Qor),e(Y,Wor),e(Y,mF),e(mF,DTe),e(DTe,Uor),e(mF,Hor),e(mF,aH),e(aH,Jor),e(mF,Yor),e(Y,Zor),e(Y,cF),e(cF,GTe),e(GTe,Kor),e(cF,err),e(cF,nH),e(nH,orr),e(cF,rrr),e(Y,trr),e(Y,fF),e(fF,OTe),e(OTe,arr),e(fF,nrr),e(fF,sH),e(sH,srr),e(fF,lrr),e(Y,irr),e(Y,gF),e(gF,VTe),e(VTe,drr),e(gF,mrr),e(gF,lH),e(lH,crr),e(gF,frr),e(Y,grr),e(Y,hF),e(hF,XTe),e(XTe,hrr),e(hF,urr),e(hF,iH),e(iH,prr),e(hF,_rr),e(Y,brr),e(Y,uF),e(uF,zTe),e(zTe,vrr),e(uF,Frr),e(uF,dH),e(dH,Trr),e(uF,Mrr),e(Y,Err),e(Y,pF),e(pF,QTe),e(QTe,Crr),e(pF,wrr),e(pF,mH),e(mH,Arr),e(pF,Lrr),e(Y,yrr),e(Y,_F),e(_F,WTe),e(WTe,xrr),e(_F,$rr),e(_F,cH),e(cH,krr),e(_F,Srr),e(Y,Rrr),e(Y,bF),e(bF,UTe),e(UTe,Prr),e(bF,Brr),e(bF,fH),e(fH,Irr),e(bF,Nrr),e(Y,qrr),e(Y,vF),e(vF,HTe),e(HTe,jrr),e(vF,Drr),e(vF,gH),e(gH,Grr),e(vF,Orr),e(Y,Vrr),e(Y,FF),e(FF,JTe),e(JTe,Xrr),e(FF,zrr),e(FF,hH),e(hH,Qrr),e(FF,Wrr),e(Y,Urr),e(Y,TF),e(TF,YTe),e(YTe,Hrr),e(TF,Jrr),e(TF,uH),e(uH,Yrr),e(TF,Zrr),e(Y,Krr),e(Y,MF),e(MF,ZTe),e(ZTe,etr),e(MF,otr),e(MF,pH),e(pH,rtr),e(MF,ttr),e(Y,atr),e(Y,EF),e(EF,KTe),e(KTe,ntr),e(EF,str),e(EF,_H),e(_H,ltr),e(EF,itr),e(Y,dtr),e(Y,CF),e(CF,eMe),e(eMe,mtr),e(CF,ctr),e(CF,bH),e(bH,ftr),e(CF,gtr),e(Y,htr),e(Y,wF),e(wF,oMe),e(oMe,utr),e(wF,ptr),e(wF,vH),e(vH,_tr),e(wF,btr),e(Y,vtr),e(Y,AF),e(AF,rMe),e(rMe,Ftr),e(AF,Ttr),e(AF,FH),e(FH,Mtr),e(AF,Etr),e(Y,Ctr),e(Y,LF),e(LF,tMe),e(tMe,wtr),e(LF,Atr),e(LF,TH),e(TH,Ltr),e(LF,ytr),e(Y,xtr),e(Y,yF),e(yF,aMe),e(aMe,$tr),e(yF,ktr),e(yF,MH),e(MH,Str),e(yF,Rtr),e(Y,Ptr),e(Y,xF),e(xF,nMe),e(nMe,Btr),e(xF,Itr),e(xF,EH),e(EH,Ntr),e(xF,qtr),e(Y,jtr),e(Y,$F),e($F,sMe),e(sMe,Dtr),e($F,Gtr),e($F,CH),e(CH,Otr),e($F,Vtr),e(Y,Xtr),e(Y,kF),e(kF,lMe),e(lMe,ztr),e(kF,Qtr),e(kF,wH),e(wH,Wtr),e(kF,Utr),e(Y,Htr),e(Y,SF),e(SF,iMe),e(iMe,Jtr),e(SF,Ytr),e(SF,AH),e(AH,Ztr),e(SF,Ktr),e(Y,ear),e(Y,RF),e(RF,dMe),e(dMe,oar),e(RF,rar),e(RF,LH),e(LH,tar),e(RF,aar),e(Y,nar),e(Y,PF),e(PF,mMe),e(mMe,sar),e(PF,lar),e(PF,cMe),e(cMe,iar),e(PF,dar),e(Y,mar),e(Y,BF),e(BF,fMe),e(fMe,car),e(BF,far),e(BF,yH),e(yH,gar),e(BF,har),e(Y,uar),e(Y,IF),e(IF,gMe),e(gMe,par),e(IF,_ar),e(IF,xH),e(xH,bar),e(IF,Far),e(Y,Tar),e(Y,NF),e(NF,hMe),e(hMe,Mar),e(NF,Ear),e(NF,$H),e($H,Car),e(NF,war),e(Y,Aar),e(Y,qF),e(qF,uMe),e(uMe,Lar),e(qF,yar),e(qF,kH),e(kH,xar),e(qF,$ar),e(to,kar),e(to,jF),e(jF,Sar),e(jF,pMe),e(pMe,Rar),e(jF,Par),e(jF,_Me),e(_Me,Bar),e(to,Iar),M(DF,to,null),b(c,Uto,_),b(c,Wd,_),e(Wd,GF),e(GF,bMe),M(lk,bMe,null),e(Wd,Nar),e(Wd,vMe),e(vMe,qar),b(c,Hto,_),b(c,Go,_),M(ik,Go,null),e(Go,jar),e(Go,Ud),e(Ud,Dar),e(Ud,SH),e(SH,Gar),e(Ud,Oar),e(Ud,RH),e(RH,Var),e(Ud,Xar),e(Go,zar),e(Go,dk),e(dk,Qar),e(dk,FMe),e(FMe,War),e(dk,Uar),e(Go,Har),e(Go,Lt),M(mk,Lt,null),e(Lt,Jar),e(Lt,TMe),e(TMe,Yar),e(Lt,Zar),e(Lt,Hd),e(Hd,Kar),e(Hd,MMe),e(MMe,enr),e(Hd,onr),e(Hd,PH),e(PH,rnr),e(Hd,tnr),e(Lt,anr),M(OF,Lt,null),e(Go,nnr),e(Go,ao),M(ck,ao,null),e(ao,snr),e(ao,EMe),e(EMe,lnr),e(ao,inr),e(ao,cn),e(cn,dnr),e(cn,CMe),e(CMe,mnr),e(cn,cnr),e(cn,wMe),e(wMe,fnr),e(cn,gnr),e(cn,AMe),e(AMe,hnr),e(cn,unr),e(ao,pnr),e(ao,he),e(he,VF),e(VF,LMe),e(LMe,_nr),e(VF,bnr),e(VF,BH),e(BH,vnr),e(VF,Fnr),e(he,Tnr),e(he,XF),e(XF,yMe),e(yMe,Mnr),e(XF,Enr),e(XF,IH),e(IH,Cnr),e(XF,wnr),e(he,Anr),e(he,zF),e(zF,xMe),e(xMe,Lnr),e(zF,ynr),e(zF,NH),e(NH,xnr),e(zF,$nr),e(he,knr),e(he,QF),e(QF,$Me),e($Me,Snr),e(QF,Rnr),e(QF,qH),e(qH,Pnr),e(QF,Bnr),e(he,Inr),e(he,WF),e(WF,kMe),e(kMe,Nnr),e(WF,qnr),e(WF,jH),e(jH,jnr),e(WF,Dnr),e(he,Gnr),e(he,UF),e(UF,SMe),e(SMe,Onr),e(UF,Vnr),e(UF,DH),e(DH,Xnr),e(UF,znr),e(he,Qnr),e(he,HF),e(HF,RMe),e(RMe,Wnr),e(HF,Unr),e(HF,GH),e(GH,Hnr),e(HF,Jnr),e(he,Ynr),e(he,JF),e(JF,PMe),e(PMe,Znr),e(JF,Knr),e(JF,OH),e(OH,esr),e(JF,osr),e(he,rsr),e(he,YF),e(YF,BMe),e(BMe,tsr),e(YF,asr),e(YF,VH),e(VH,nsr),e(YF,ssr),e(he,lsr),e(he,ZF),e(ZF,IMe),e(IMe,isr),e(ZF,dsr),e(ZF,XH),e(XH,msr),e(ZF,csr),e(he,fsr),e(he,KF),e(KF,NMe),e(NMe,gsr),e(KF,hsr),e(KF,zH),e(zH,usr),e(KF,psr),e(he,_sr),e(he,eT),e(eT,qMe),e(qMe,bsr),e(eT,vsr),e(eT,QH),e(QH,Fsr),e(eT,Tsr),e(he,Msr),e(he,oT),e(oT,jMe),e(jMe,Esr),e(oT,Csr),e(oT,WH),e(WH,wsr),e(oT,Asr),e(he,Lsr),e(he,rT),e(rT,DMe),e(DMe,ysr),e(rT,xsr),e(rT,UH),e(UH,$sr),e(rT,ksr),e(he,Ssr),e(he,tT),e(tT,GMe),e(GMe,Rsr),e(tT,Psr),e(tT,HH),e(HH,Bsr),e(tT,Isr),e(he,Nsr),e(he,aT),e(aT,OMe),e(OMe,qsr),e(aT,jsr),e(aT,JH),e(JH,Dsr),e(aT,Gsr),e(he,Osr),e(he,nT),e(nT,VMe),e(VMe,Vsr),e(nT,Xsr),e(nT,YH),e(YH,zsr),e(nT,Qsr),e(he,Wsr),e(he,sT),e(sT,XMe),e(XMe,Usr),e(sT,Hsr),e(sT,ZH),e(ZH,Jsr),e(sT,Ysr),e(he,Zsr),e(he,lT),e(lT,zMe),e(zMe,Ksr),e(lT,elr),e(lT,KH),e(KH,olr),e(lT,rlr),e(he,tlr),e(he,iT),e(iT,QMe),e(QMe,alr),e(iT,nlr),e(iT,eJ),e(eJ,slr),e(iT,llr),e(ao,ilr),e(ao,dT),e(dT,dlr),e(dT,WMe),e(WMe,mlr),e(dT,clr),e(dT,UMe),e(UMe,flr),e(ao,glr),M(mT,ao,null),b(c,Jto,_),b(c,Jd,_),e(Jd,cT),e(cT,HMe),M(fk,HMe,null),e(Jd,hlr),e(Jd,JMe),e(JMe,ulr),b(c,Yto,_),b(c,Oo,_),M(gk,Oo,null),e(Oo,plr),e(Oo,Yd),e(Yd,_lr),e(Yd,oJ),e(oJ,blr),e(Yd,vlr),e(Yd,rJ),e(rJ,Flr),e(Yd,Tlr),e(Oo,Mlr),e(Oo,hk),e(hk,Elr),e(hk,YMe),e(YMe,Clr),e(hk,wlr),e(Oo,Alr),e(Oo,yt),M(uk,yt,null),e(yt,Llr),e(yt,ZMe),e(ZMe,ylr),e(yt,xlr),e(yt,Zd),e(Zd,$lr),e(Zd,KMe),e(KMe,klr),e(Zd,Slr),e(Zd,tJ),e(tJ,Rlr),e(Zd,Plr),e(yt,Blr),M(fT,yt,null),e(Oo,Ilr),e(Oo,no),M(pk,no,null),e(no,Nlr),e(no,eEe),e(eEe,qlr),e(no,jlr),e(no,fn),e(fn,Dlr),e(fn,oEe),e(oEe,Glr),e(fn,Olr),e(fn,rEe),e(rEe,Vlr),e(fn,Xlr),e(fn,tEe),e(tEe,zlr),e(fn,Qlr),e(no,Wlr),e(no,j),e(j,gT),e(gT,aEe),e(aEe,Ulr),e(gT,Hlr),e(gT,aJ),e(aJ,Jlr),e(gT,Ylr),e(j,Zlr),e(j,hT),e(hT,nEe),e(nEe,Klr),e(hT,eir),e(hT,nJ),e(nJ,oir),e(hT,rir),e(j,tir),e(j,uT),e(uT,sEe),e(sEe,air),e(uT,nir),e(uT,sJ),e(sJ,sir),e(uT,lir),e(j,iir),e(j,pT),e(pT,lEe),e(lEe,dir),e(pT,mir),e(pT,lJ),e(lJ,cir),e(pT,fir),e(j,gir),e(j,_T),e(_T,iEe),e(iEe,hir),e(_T,uir),e(_T,iJ),e(iJ,pir),e(_T,_ir),e(j,bir),e(j,bT),e(bT,dEe),e(dEe,vir),e(bT,Fir),e(bT,dJ),e(dJ,Tir),e(bT,Mir),e(j,Eir),e(j,vT),e(vT,mEe),e(mEe,Cir),e(vT,wir),e(vT,mJ),e(mJ,Air),e(vT,Lir),e(j,yir),e(j,FT),e(FT,cEe),e(cEe,xir),e(FT,$ir),e(FT,cJ),e(cJ,kir),e(FT,Sir),e(j,Rir),e(j,TT),e(TT,fEe),e(fEe,Pir),e(TT,Bir),e(TT,fJ),e(fJ,Iir),e(TT,Nir),e(j,qir),e(j,MT),e(MT,gEe),e(gEe,jir),e(MT,Dir),e(MT,gJ),e(gJ,Gir),e(MT,Oir),e(j,Vir),e(j,ET),e(ET,hEe),e(hEe,Xir),e(ET,zir),e(ET,hJ),e(hJ,Qir),e(ET,Wir),e(j,Uir),e(j,CT),e(CT,uEe),e(uEe,Hir),e(CT,Jir),e(CT,uJ),e(uJ,Yir),e(CT,Zir),e(j,Kir),e(j,wT),e(wT,pEe),e(pEe,edr),e(wT,odr),e(wT,pJ),e(pJ,rdr),e(wT,tdr),e(j,adr),e(j,AT),e(AT,_Ee),e(_Ee,ndr),e(AT,sdr),e(AT,_J),e(_J,ldr),e(AT,idr),e(j,ddr),e(j,LT),e(LT,bEe),e(bEe,mdr),e(LT,cdr),e(LT,bJ),e(bJ,fdr),e(LT,gdr),e(j,hdr),e(j,yT),e(yT,vEe),e(vEe,udr),e(yT,pdr),e(yT,vJ),e(vJ,_dr),e(yT,bdr),e(j,vdr),e(j,xT),e(xT,FEe),e(FEe,Fdr),e(xT,Tdr),e(xT,FJ),e(FJ,Mdr),e(xT,Edr),e(j,Cdr),e(j,$T),e($T,TEe),e(TEe,wdr),e($T,Adr),e($T,TJ),e(TJ,Ldr),e($T,ydr),e(j,xdr),e(j,kT),e(kT,MEe),e(MEe,$dr),e(kT,kdr),e(kT,MJ),e(MJ,Sdr),e(kT,Rdr),e(j,Pdr),e(j,ST),e(ST,EEe),e(EEe,Bdr),e(ST,Idr),e(ST,EJ),e(EJ,Ndr),e(ST,qdr),e(j,jdr),e(j,RT),e(RT,CEe),e(CEe,Ddr),e(RT,Gdr),e(RT,CJ),e(CJ,Odr),e(RT,Vdr),e(j,Xdr),e(j,PT),e(PT,wEe),e(wEe,zdr),e(PT,Qdr),e(PT,wJ),e(wJ,Wdr),e(PT,Udr),e(j,Hdr),e(j,BT),e(BT,AEe),e(AEe,Jdr),e(BT,Ydr),e(BT,AJ),e(AJ,Zdr),e(BT,Kdr),e(j,emr),e(j,IT),e(IT,LEe),e(LEe,omr),e(IT,rmr),e(IT,LJ),e(LJ,tmr),e(IT,amr),e(j,nmr),e(j,NT),e(NT,yEe),e(yEe,smr),e(NT,lmr),e(NT,yJ),e(yJ,imr),e(NT,dmr),e(j,mmr),e(j,qT),e(qT,xEe),e(xEe,cmr),e(qT,fmr),e(qT,xJ),e(xJ,gmr),e(qT,hmr),e(j,umr),e(j,jT),e(jT,$Ee),e($Ee,pmr),e(jT,_mr),e(jT,$J),e($J,bmr),e(jT,vmr),e(j,Fmr),e(j,DT),e(DT,kEe),e(kEe,Tmr),e(DT,Mmr),e(DT,kJ),e(kJ,Emr),e(DT,Cmr),e(j,wmr),e(j,GT),e(GT,SEe),e(SEe,Amr),e(GT,Lmr),e(GT,SJ),e(SJ,ymr),e(GT,xmr),e(j,$mr),e(j,OT),e(OT,REe),e(REe,kmr),e(OT,Smr),e(OT,RJ),e(RJ,Rmr),e(OT,Pmr),e(j,Bmr),e(j,VT),e(VT,PEe),e(PEe,Imr),e(VT,Nmr),e(VT,PJ),e(PJ,qmr),e(VT,jmr),e(j,Dmr),e(j,XT),e(XT,BEe),e(BEe,Gmr),e(XT,Omr),e(XT,BJ),e(BJ,Vmr),e(XT,Xmr),e(j,zmr),e(j,zT),e(zT,IEe),e(IEe,Qmr),e(zT,Wmr),e(zT,IJ),e(IJ,Umr),e(zT,Hmr),e(j,Jmr),e(j,QT),e(QT,NEe),e(NEe,Ymr),e(QT,Zmr),e(QT,NJ),e(NJ,Kmr),e(QT,ecr),e(j,ocr),e(j,WT),e(WT,qEe),e(qEe,rcr),e(WT,tcr),e(WT,qJ),e(qJ,acr),e(WT,ncr),e(j,scr),e(j,UT),e(UT,jEe),e(jEe,lcr),e(UT,icr),e(UT,jJ),e(jJ,dcr),e(UT,mcr),e(j,ccr),e(j,HT),e(HT,DEe),e(DEe,fcr),e(HT,gcr),e(HT,DJ),e(DJ,hcr),e(HT,ucr),e(j,pcr),e(j,JT),e(JT,GEe),e(GEe,_cr),e(JT,bcr),e(JT,GJ),e(GJ,vcr),e(JT,Fcr),e(j,Tcr),e(j,YT),e(YT,OEe),e(OEe,Mcr),e(YT,Ecr),e(YT,OJ),e(OJ,Ccr),e(YT,wcr),e(j,Acr),e(j,ZT),e(ZT,VEe),e(VEe,Lcr),e(ZT,ycr),e(ZT,VJ),e(VJ,xcr),e(ZT,$cr),e(j,kcr),e(j,KT),e(KT,XEe),e(XEe,Scr),e(KT,Rcr),e(KT,XJ),e(XJ,Pcr),e(KT,Bcr),e(j,Icr),e(j,eM),e(eM,zEe),e(zEe,Ncr),e(eM,qcr),e(eM,zJ),e(zJ,jcr),e(eM,Dcr),e(j,Gcr),e(j,oM),e(oM,QEe),e(QEe,Ocr),e(oM,Vcr),e(oM,QJ),e(QJ,Xcr),e(oM,zcr),e(j,Qcr),e(j,rM),e(rM,WEe),e(WEe,Wcr),e(rM,Ucr),e(rM,WJ),e(WJ,Hcr),e(rM,Jcr),e(j,Ycr),e(j,tM),e(tM,UEe),e(UEe,Zcr),e(tM,Kcr),e(tM,UJ),e(UJ,efr),e(tM,ofr),e(j,rfr),e(j,aM),e(aM,HEe),e(HEe,tfr),e(aM,afr),e(aM,HJ),e(HJ,nfr),e(aM,sfr),e(j,lfr),e(j,nM),e(nM,JEe),e(JEe,ifr),e(nM,dfr),e(nM,JJ),e(JJ,mfr),e(nM,cfr),e(j,ffr),e(j,sM),e(sM,YEe),e(YEe,gfr),e(sM,hfr),e(sM,YJ),e(YJ,ufr),e(sM,pfr),e(j,_fr),e(j,lM),e(lM,ZEe),e(ZEe,bfr),e(lM,vfr),e(lM,ZJ),e(ZJ,Ffr),e(lM,Tfr),e(j,Mfr),e(j,iM),e(iM,KEe),e(KEe,Efr),e(iM,Cfr),e(iM,KJ),e(KJ,wfr),e(iM,Afr),e(j,Lfr),e(j,dM),e(dM,e4e),e(e4e,yfr),e(dM,xfr),e(dM,eY),e(eY,$fr),e(dM,kfr),e(j,Sfr),e(j,mM),e(mM,o4e),e(o4e,Rfr),e(mM,Pfr),e(mM,oY),e(oY,Bfr),e(mM,Ifr),e(j,Nfr),e(j,cM),e(cM,r4e),e(r4e,qfr),e(cM,jfr),e(cM,rY),e(rY,Dfr),e(cM,Gfr),e(j,Ofr),e(j,fM),e(fM,t4e),e(t4e,Vfr),e(fM,Xfr),e(fM,tY),e(tY,zfr),e(fM,Qfr),e(j,Wfr),e(j,gM),e(gM,a4e),e(a4e,Ufr),e(gM,Hfr),e(gM,aY),e(aY,Jfr),e(gM,Yfr),e(j,Zfr),e(j,hM),e(hM,n4e),e(n4e,Kfr),e(hM,egr),e(hM,nY),e(nY,ogr),e(hM,rgr),e(no,tgr),e(no,uM),e(uM,agr),e(uM,s4e),e(s4e,ngr),e(uM,sgr),e(uM,l4e),e(l4e,lgr),e(no,igr),M(pM,no,null),b(c,Zto,_),b(c,Kd,_),e(Kd,_M),e(_M,i4e),M(_k,i4e,null),e(Kd,dgr),e(Kd,d4e),e(d4e,mgr),b(c,Kto,_),b(c,Vo,_),M(bk,Vo,null),e(Vo,cgr),e(Vo,em),e(em,fgr),e(em,sY),e(sY,ggr),e(em,hgr),e(em,lY),e(lY,ugr),e(em,pgr),e(Vo,_gr),e(Vo,vk),e(vk,bgr),e(vk,m4e),e(m4e,vgr),e(vk,Fgr),e(Vo,Tgr),e(Vo,xt),M(Fk,xt,null),e(xt,Mgr),e(xt,c4e),e(c4e,Egr),e(xt,Cgr),e(xt,om),e(om,wgr),e(om,f4e),e(f4e,Agr),e(om,Lgr),e(om,iY),e(iY,ygr),e(om,xgr),e(xt,$gr),M(bM,xt,null),e(Vo,kgr),e(Vo,so),M(Tk,so,null),e(so,Sgr),e(so,g4e),e(g4e,Rgr),e(so,Pgr),e(so,gn),e(gn,Bgr),e(gn,h4e),e(h4e,Igr),e(gn,Ngr),e(gn,u4e),e(u4e,qgr),e(gn,jgr),e(gn,p4e),e(p4e,Dgr),e(gn,Ggr),e(so,Ogr),e(so,K),e(K,vM),e(vM,_4e),e(_4e,Vgr),e(vM,Xgr),e(vM,dY),e(dY,zgr),e(vM,Qgr),e(K,Wgr),e(K,FM),e(FM,b4e),e(b4e,Ugr),e(FM,Hgr),e(FM,mY),e(mY,Jgr),e(FM,Ygr),e(K,Zgr),e(K,TM),e(TM,v4e),e(v4e,Kgr),e(TM,ehr),e(TM,cY),e(cY,ohr),e(TM,rhr),e(K,thr),e(K,MM),e(MM,F4e),e(F4e,ahr),e(MM,nhr),e(MM,fY),e(fY,shr),e(MM,lhr),e(K,ihr),e(K,EM),e(EM,T4e),e(T4e,dhr),e(EM,mhr),e(EM,gY),e(gY,chr),e(EM,fhr),e(K,ghr),e(K,CM),e(CM,M4e),e(M4e,hhr),e(CM,uhr),e(CM,hY),e(hY,phr),e(CM,_hr),e(K,bhr),e(K,wM),e(wM,E4e),e(E4e,vhr),e(wM,Fhr),e(wM,uY),e(uY,Thr),e(wM,Mhr),e(K,Ehr),e(K,AM),e(AM,C4e),e(C4e,Chr),e(AM,whr),e(AM,pY),e(pY,Ahr),e(AM,Lhr),e(K,yhr),e(K,LM),e(LM,w4e),e(w4e,xhr),e(LM,$hr),e(LM,_Y),e(_Y,khr),e(LM,Shr),e(K,Rhr),e(K,yM),e(yM,A4e),e(A4e,Phr),e(yM,Bhr),e(yM,bY),e(bY,Ihr),e(yM,Nhr),e(K,qhr),e(K,xM),e(xM,L4e),e(L4e,jhr),e(xM,Dhr),e(xM,vY),e(vY,Ghr),e(xM,Ohr),e(K,Vhr),e(K,$M),e($M,y4e),e(y4e,Xhr),e($M,zhr),e($M,FY),e(FY,Qhr),e($M,Whr),e(K,Uhr),e(K,kM),e(kM,x4e),e(x4e,Hhr),e(kM,Jhr),e(kM,TY),e(TY,Yhr),e(kM,Zhr),e(K,Khr),e(K,SM),e(SM,$4e),e($4e,eur),e(SM,our),e(SM,MY),e(MY,rur),e(SM,tur),e(K,aur),e(K,RM),e(RM,k4e),e(k4e,nur),e(RM,sur),e(RM,EY),e(EY,lur),e(RM,iur),e(K,dur),e(K,PM),e(PM,S4e),e(S4e,mur),e(PM,cur),e(PM,CY),e(CY,fur),e(PM,gur),e(K,hur),e(K,BM),e(BM,R4e),e(R4e,uur),e(BM,pur),e(BM,wY),e(wY,_ur),e(BM,bur),e(K,vur),e(K,IM),e(IM,P4e),e(P4e,Fur),e(IM,Tur),e(IM,AY),e(AY,Mur),e(IM,Eur),e(K,Cur),e(K,NM),e(NM,B4e),e(B4e,wur),e(NM,Aur),e(NM,LY),e(LY,Lur),e(NM,yur),e(K,xur),e(K,qM),e(qM,I4e),e(I4e,$ur),e(qM,kur),e(qM,yY),e(yY,Sur),e(qM,Rur),e(K,Pur),e(K,jM),e(jM,N4e),e(N4e,Bur),e(jM,Iur),e(jM,xY),e(xY,Nur),e(jM,qur),e(K,jur),e(K,DM),e(DM,q4e),e(q4e,Dur),e(DM,Gur),e(DM,$Y),e($Y,Our),e(DM,Vur),e(K,Xur),e(K,GM),e(GM,j4e),e(j4e,zur),e(GM,Qur),e(GM,kY),e(kY,Wur),e(GM,Uur),e(K,Hur),e(K,OM),e(OM,D4e),e(D4e,Jur),e(OM,Yur),e(OM,SY),e(SY,Zur),e(OM,Kur),e(K,epr),e(K,VM),e(VM,G4e),e(G4e,opr),e(VM,rpr),e(VM,RY),e(RY,tpr),e(VM,apr),e(K,npr),e(K,XM),e(XM,O4e),e(O4e,spr),e(XM,lpr),e(XM,PY),e(PY,ipr),e(XM,dpr),e(K,mpr),e(K,zM),e(zM,V4e),e(V4e,cpr),e(zM,fpr),e(zM,BY),e(BY,gpr),e(zM,hpr),e(K,upr),e(K,QM),e(QM,X4e),e(X4e,ppr),e(QM,_pr),e(QM,IY),e(IY,bpr),e(QM,vpr),e(K,Fpr),e(K,WM),e(WM,z4e),e(z4e,Tpr),e(WM,Mpr),e(WM,NY),e(NY,Epr),e(WM,Cpr),e(K,wpr),e(K,UM),e(UM,Q4e),e(Q4e,Apr),e(UM,Lpr),e(UM,qY),e(qY,ypr),e(UM,xpr),e(K,$pr),e(K,HM),e(HM,W4e),e(W4e,kpr),e(HM,Spr),e(HM,jY),e(jY,Rpr),e(HM,Ppr),e(K,Bpr),e(K,JM),e(JM,U4e),e(U4e,Ipr),e(JM,Npr),e(JM,DY),e(DY,qpr),e(JM,jpr),e(so,Dpr),e(so,YM),e(YM,Gpr),e(YM,H4e),e(H4e,Opr),e(YM,Vpr),e(YM,J4e),e(J4e,Xpr),e(so,zpr),M(ZM,so,null),b(c,eao,_),b(c,rm,_),e(rm,KM),e(KM,Y4e),M(Mk,Y4e,null),e(rm,Qpr),e(rm,Z4e),e(Z4e,Wpr),b(c,oao,_),b(c,Xo,_),M(Ek,Xo,null),e(Xo,Upr),e(Xo,tm),e(tm,Hpr),e(tm,GY),e(GY,Jpr),e(tm,Ypr),e(tm,OY),e(OY,Zpr),e(tm,Kpr),e(Xo,e_r),e(Xo,Ck),e(Ck,o_r),e(Ck,K4e),e(K4e,r_r),e(Ck,t_r),e(Xo,a_r),e(Xo,$t),M(wk,$t,null),e($t,n_r),e($t,eCe),e(eCe,s_r),e($t,l_r),e($t,am),e(am,i_r),e(am,oCe),e(oCe,d_r),e(am,m_r),e(am,VY),e(VY,c_r),e(am,f_r),e($t,g_r),M(eE,$t,null),e(Xo,h_r),e(Xo,lo),M(Ak,lo,null),e(lo,u_r),e(lo,rCe),e(rCe,p_r),e(lo,__r),e(lo,hn),e(hn,b_r),e(hn,tCe),e(tCe,v_r),e(hn,F_r),e(hn,aCe),e(aCe,T_r),e(hn,M_r),e(hn,nCe),e(nCe,E_r),e(hn,C_r),e(lo,w_r),e(lo,Ue),e(Ue,oE),e(oE,sCe),e(sCe,A_r),e(oE,L_r),e(oE,XY),e(XY,y_r),e(oE,x_r),e(Ue,$_r),e(Ue,rE),e(rE,lCe),e(lCe,k_r),e(rE,S_r),e(rE,zY),e(zY,R_r),e(rE,P_r),e(Ue,B_r),e(Ue,tE),e(tE,iCe),e(iCe,I_r),e(tE,N_r),e(tE,QY),e(QY,q_r),e(tE,j_r),e(Ue,D_r),e(Ue,aE),e(aE,dCe),e(dCe,G_r),e(aE,O_r),e(aE,WY),e(WY,V_r),e(aE,X_r),e(Ue,z_r),e(Ue,nE),e(nE,mCe),e(mCe,Q_r),e(nE,W_r),e(nE,UY),e(UY,U_r),e(nE,H_r),e(Ue,J_r),e(Ue,sE),e(sE,cCe),e(cCe,Y_r),e(sE,Z_r),e(sE,HY),e(HY,K_r),e(sE,e1r),e(Ue,o1r),e(Ue,lE),e(lE,fCe),e(fCe,r1r),e(lE,t1r),e(lE,JY),e(JY,a1r),e(lE,n1r),e(lo,s1r),e(lo,iE),e(iE,l1r),e(iE,gCe),e(gCe,i1r),e(iE,d1r),e(iE,hCe),e(hCe,m1r),e(lo,c1r),M(dE,lo,null),b(c,rao,_),b(c,nm,_),e(nm,mE),e(mE,uCe),M(Lk,uCe,null),e(nm,f1r),e(nm,pCe),e(pCe,g1r),b(c,tao,_),b(c,zo,_),M(yk,zo,null),e(zo,h1r),e(zo,sm),e(sm,u1r),e(sm,YY),e(YY,p1r),e(sm,_1r),e(sm,ZY),e(ZY,b1r),e(sm,v1r),e(zo,F1r),e(zo,xk),e(xk,T1r),e(xk,_Ce),e(_Ce,M1r),e(xk,E1r),e(zo,C1r),e(zo,kt),M($k,kt,null),e(kt,w1r),e(kt,bCe),e(bCe,A1r),e(kt,L1r),e(kt,lm),e(lm,y1r),e(lm,vCe),e(vCe,x1r),e(lm,$1r),e(lm,KY),e(KY,k1r),e(lm,S1r),e(kt,R1r),M(cE,kt,null),e(zo,P1r),e(zo,io),M(kk,io,null),e(io,B1r),e(io,FCe),e(FCe,I1r),e(io,N1r),e(io,un),e(un,q1r),e(un,TCe),e(TCe,j1r),e(un,D1r),e(un,MCe),e(MCe,G1r),e(un,O1r),e(un,ECe),e(ECe,V1r),e(un,X1r),e(io,z1r),e(io,U),e(U,fE),e(fE,CCe),e(CCe,Q1r),e(fE,W1r),e(fE,eZ),e(eZ,U1r),e(fE,H1r),e(U,J1r),e(U,gE),e(gE,wCe),e(wCe,Y1r),e(gE,Z1r),e(gE,oZ),e(oZ,K1r),e(gE,e2r),e(U,o2r),e(U,hE),e(hE,ACe),e(ACe,r2r),e(hE,t2r),e(hE,rZ),e(rZ,a2r),e(hE,n2r),e(U,s2r),e(U,uE),e(uE,LCe),e(LCe,l2r),e(uE,i2r),e(uE,tZ),e(tZ,d2r),e(uE,m2r),e(U,c2r),e(U,pE),e(pE,yCe),e(yCe,f2r),e(pE,g2r),e(pE,aZ),e(aZ,h2r),e(pE,u2r),e(U,p2r),e(U,_E),e(_E,xCe),e(xCe,_2r),e(_E,b2r),e(_E,nZ),e(nZ,v2r),e(_E,F2r),e(U,T2r),e(U,bE),e(bE,$Ce),e($Ce,M2r),e(bE,E2r),e(bE,sZ),e(sZ,C2r),e(bE,w2r),e(U,A2r),e(U,vE),e(vE,kCe),e(kCe,L2r),e(vE,y2r),e(vE,lZ),e(lZ,x2r),e(vE,$2r),e(U,k2r),e(U,FE),e(FE,SCe),e(SCe,S2r),e(FE,R2r),e(FE,iZ),e(iZ,P2r),e(FE,B2r),e(U,I2r),e(U,TE),e(TE,RCe),e(RCe,N2r),e(TE,q2r),e(TE,dZ),e(dZ,j2r),e(TE,D2r),e(U,G2r),e(U,ME),e(ME,PCe),e(PCe,O2r),e(ME,V2r),e(ME,mZ),e(mZ,X2r),e(ME,z2r),e(U,Q2r),e(U,EE),e(EE,BCe),e(BCe,W2r),e(EE,U2r),e(EE,cZ),e(cZ,H2r),e(EE,J2r),e(U,Y2r),e(U,CE),e(CE,ICe),e(ICe,Z2r),e(CE,K2r),e(CE,fZ),e(fZ,ebr),e(CE,obr),e(U,rbr),e(U,wE),e(wE,NCe),e(NCe,tbr),e(wE,abr),e(wE,gZ),e(gZ,nbr),e(wE,sbr),e(U,lbr),e(U,AE),e(AE,qCe),e(qCe,ibr),e(AE,dbr),e(AE,hZ),e(hZ,mbr),e(AE,cbr),e(U,fbr),e(U,LE),e(LE,jCe),e(jCe,gbr),e(LE,hbr),e(LE,uZ),e(uZ,ubr),e(LE,pbr),e(U,_br),e(U,yE),e(yE,DCe),e(DCe,bbr),e(yE,vbr),e(yE,pZ),e(pZ,Fbr),e(yE,Tbr),e(U,Mbr),e(U,xE),e(xE,GCe),e(GCe,Ebr),e(xE,Cbr),e(xE,_Z),e(_Z,wbr),e(xE,Abr),e(U,Lbr),e(U,$E),e($E,OCe),e(OCe,ybr),e($E,xbr),e($E,bZ),e(bZ,$br),e($E,kbr),e(U,Sbr),e(U,kE),e(kE,VCe),e(VCe,Rbr),e(kE,Pbr),e(kE,vZ),e(vZ,Bbr),e(kE,Ibr),e(U,Nbr),e(U,SE),e(SE,XCe),e(XCe,qbr),e(SE,jbr),e(SE,FZ),e(FZ,Dbr),e(SE,Gbr),e(U,Obr),e(U,RE),e(RE,zCe),e(zCe,Vbr),e(RE,Xbr),e(RE,TZ),e(TZ,zbr),e(RE,Qbr),e(U,Wbr),e(U,PE),e(PE,QCe),e(QCe,Ubr),e(PE,Hbr),e(PE,MZ),e(MZ,Jbr),e(PE,Ybr),e(U,Zbr),e(U,BE),e(BE,WCe),e(WCe,Kbr),e(BE,evr),e(BE,EZ),e(EZ,ovr),e(BE,rvr),e(U,tvr),e(U,IE),e(IE,UCe),e(UCe,avr),e(IE,nvr),e(IE,CZ),e(CZ,svr),e(IE,lvr),e(U,ivr),e(U,NE),e(NE,HCe),e(HCe,dvr),e(NE,mvr),e(NE,wZ),e(wZ,cvr),e(NE,fvr),e(U,gvr),e(U,qE),e(qE,JCe),e(JCe,hvr),e(qE,uvr),e(qE,AZ),e(AZ,pvr),e(qE,_vr),e(U,bvr),e(U,jE),e(jE,YCe),e(YCe,vvr),e(jE,Fvr),e(jE,LZ),e(LZ,Tvr),e(jE,Mvr),e(U,Evr),e(U,DE),e(DE,ZCe),e(ZCe,Cvr),e(DE,wvr),e(DE,yZ),e(yZ,Avr),e(DE,Lvr),e(U,yvr),e(U,GE),e(GE,KCe),e(KCe,xvr),e(GE,$vr),e(GE,xZ),e(xZ,kvr),e(GE,Svr),e(U,Rvr),e(U,OE),e(OE,e3e),e(e3e,Pvr),e(OE,Bvr),e(OE,$Z),e($Z,Ivr),e(OE,Nvr),e(U,qvr),e(U,VE),e(VE,o3e),e(o3e,jvr),e(VE,Dvr),e(VE,kZ),e(kZ,Gvr),e(VE,Ovr),e(U,Vvr),e(U,XE),e(XE,r3e),e(r3e,Xvr),e(XE,zvr),e(XE,SZ),e(SZ,Qvr),e(XE,Wvr),e(U,Uvr),e(U,zE),e(zE,t3e),e(t3e,Hvr),e(zE,Jvr),e(zE,RZ),e(RZ,Yvr),e(zE,Zvr),e(U,Kvr),e(U,QE),e(QE,a3e),e(a3e,eFr),e(QE,oFr),e(QE,PZ),e(PZ,rFr),e(QE,tFr),e(U,aFr),e(U,WE),e(WE,n3e),e(n3e,nFr),e(WE,sFr),e(WE,BZ),e(BZ,lFr),e(WE,iFr),e(U,dFr),e(U,UE),e(UE,s3e),e(s3e,mFr),e(UE,cFr),e(UE,IZ),e(IZ,fFr),e(UE,gFr),e(U,hFr),e(U,HE),e(HE,l3e),e(l3e,uFr),e(HE,pFr),e(HE,NZ),e(NZ,_Fr),e(HE,bFr),e(U,vFr),e(U,JE),e(JE,i3e),e(i3e,FFr),e(JE,TFr),e(JE,qZ),e(qZ,MFr),e(JE,EFr),e(U,CFr),e(U,YE),e(YE,d3e),e(d3e,wFr),e(YE,AFr),e(YE,jZ),e(jZ,LFr),e(YE,yFr),e(U,xFr),e(U,ZE),e(ZE,m3e),e(m3e,$Fr),e(ZE,kFr),e(ZE,DZ),e(DZ,SFr),e(ZE,RFr),e(io,PFr),e(io,KE),e(KE,BFr),e(KE,c3e),e(c3e,IFr),e(KE,NFr),e(KE,f3e),e(f3e,qFr),e(io,jFr),M(e4,io,null),b(c,aao,_),b(c,im,_),e(im,o4),e(o4,g3e),M(Sk,g3e,null),e(im,DFr),e(im,h3e),e(h3e,GFr),b(c,nao,_),b(c,Qo,_),M(Rk,Qo,null),e(Qo,OFr),e(Qo,dm),e(dm,VFr),e(dm,GZ),e(GZ,XFr),e(dm,zFr),e(dm,OZ),e(OZ,QFr),e(dm,WFr),e(Qo,UFr),e(Qo,Pk),e(Pk,HFr),e(Pk,u3e),e(u3e,JFr),e(Pk,YFr),e(Qo,ZFr),e(Qo,St),M(Bk,St,null),e(St,KFr),e(St,p3e),e(p3e,eTr),e(St,oTr),e(St,mm),e(mm,rTr),e(mm,_3e),e(_3e,tTr),e(mm,aTr),e(mm,VZ),e(VZ,nTr),e(mm,sTr),e(St,lTr),M(r4,St,null),e(Qo,iTr),e(Qo,mo),M(Ik,mo,null),e(mo,dTr),e(mo,b3e),e(b3e,mTr),e(mo,cTr),e(mo,pn),e(pn,fTr),e(pn,v3e),e(v3e,gTr),e(pn,hTr),e(pn,F3e),e(F3e,uTr),e(pn,pTr),e(pn,T3e),e(T3e,_Tr),e(pn,bTr),e(mo,vTr),e(mo,O),e(O,t4),e(t4,M3e),e(M3e,FTr),e(t4,TTr),e(t4,XZ),e(XZ,MTr),e(t4,ETr),e(O,CTr),e(O,a4),e(a4,E3e),e(E3e,wTr),e(a4,ATr),e(a4,zZ),e(zZ,LTr),e(a4,yTr),e(O,xTr),e(O,n4),e(n4,C3e),e(C3e,$Tr),e(n4,kTr),e(n4,QZ),e(QZ,STr),e(n4,RTr),e(O,PTr),e(O,s4),e(s4,w3e),e(w3e,BTr),e(s4,ITr),e(s4,WZ),e(WZ,NTr),e(s4,qTr),e(O,jTr),e(O,l4),e(l4,A3e),e(A3e,DTr),e(l4,GTr),e(l4,UZ),e(UZ,OTr),e(l4,VTr),e(O,XTr),e(O,i4),e(i4,L3e),e(L3e,zTr),e(i4,QTr),e(i4,HZ),e(HZ,WTr),e(i4,UTr),e(O,HTr),e(O,d4),e(d4,y3e),e(y3e,JTr),e(d4,YTr),e(d4,JZ),e(JZ,ZTr),e(d4,KTr),e(O,eMr),e(O,m4),e(m4,x3e),e(x3e,oMr),e(m4,rMr),e(m4,YZ),e(YZ,tMr),e(m4,aMr),e(O,nMr),e(O,c4),e(c4,$3e),e($3e,sMr),e(c4,lMr),e(c4,ZZ),e(ZZ,iMr),e(c4,dMr),e(O,mMr),e(O,f4),e(f4,k3e),e(k3e,cMr),e(f4,fMr),e(f4,KZ),e(KZ,gMr),e(f4,hMr),e(O,uMr),e(O,g4),e(g4,S3e),e(S3e,pMr),e(g4,_Mr),e(g4,eK),e(eK,bMr),e(g4,vMr),e(O,FMr),e(O,h4),e(h4,R3e),e(R3e,TMr),e(h4,MMr),e(h4,oK),e(oK,EMr),e(h4,CMr),e(O,wMr),e(O,u4),e(u4,P3e),e(P3e,AMr),e(u4,LMr),e(u4,rK),e(rK,yMr),e(u4,xMr),e(O,$Mr),e(O,p4),e(p4,B3e),e(B3e,kMr),e(p4,SMr),e(p4,tK),e(tK,RMr),e(p4,PMr),e(O,BMr),e(O,_4),e(_4,I3e),e(I3e,IMr),e(_4,NMr),e(_4,aK),e(aK,qMr),e(_4,jMr),e(O,DMr),e(O,b4),e(b4,N3e),e(N3e,GMr),e(b4,OMr),e(b4,nK),e(nK,VMr),e(b4,XMr),e(O,zMr),e(O,v4),e(v4,q3e),e(q3e,QMr),e(v4,WMr),e(v4,sK),e(sK,UMr),e(v4,HMr),e(O,JMr),e(O,F4),e(F4,j3e),e(j3e,YMr),e(F4,ZMr),e(F4,lK),e(lK,KMr),e(F4,eEr),e(O,oEr),e(O,T4),e(T4,D3e),e(D3e,rEr),e(T4,tEr),e(T4,iK),e(iK,aEr),e(T4,nEr),e(O,sEr),e(O,M4),e(M4,G3e),e(G3e,lEr),e(M4,iEr),e(M4,dK),e(dK,dEr),e(M4,mEr),e(O,cEr),e(O,E4),e(E4,O3e),e(O3e,fEr),e(E4,gEr),e(E4,mK),e(mK,hEr),e(E4,uEr),e(O,pEr),e(O,C4),e(C4,V3e),e(V3e,_Er),e(C4,bEr),e(C4,cK),e(cK,vEr),e(C4,FEr),e(O,TEr),e(O,w4),e(w4,X3e),e(X3e,MEr),e(w4,EEr),e(w4,fK),e(fK,CEr),e(w4,wEr),e(O,AEr),e(O,A4),e(A4,z3e),e(z3e,LEr),e(A4,yEr),e(A4,gK),e(gK,xEr),e(A4,$Er),e(O,kEr),e(O,L4),e(L4,Q3e),e(Q3e,SEr),e(L4,REr),e(L4,hK),e(hK,PEr),e(L4,BEr),e(O,IEr),e(O,y4),e(y4,W3e),e(W3e,NEr),e(y4,qEr),e(y4,uK),e(uK,jEr),e(y4,DEr),e(O,GEr),e(O,x4),e(x4,U3e),e(U3e,OEr),e(x4,VEr),e(x4,pK),e(pK,XEr),e(x4,zEr),e(O,QEr),e(O,$4),e($4,H3e),e(H3e,WEr),e($4,UEr),e($4,_K),e(_K,HEr),e($4,JEr),e(O,YEr),e(O,k4),e(k4,J3e),e(J3e,ZEr),e(k4,KEr),e(k4,bK),e(bK,e4r),e(k4,o4r),e(O,r4r),e(O,S4),e(S4,Y3e),e(Y3e,t4r),e(S4,a4r),e(S4,vK),e(vK,n4r),e(S4,s4r),e(O,l4r),e(O,R4),e(R4,Z3e),e(Z3e,i4r),e(R4,d4r),e(R4,FK),e(FK,m4r),e(R4,c4r),e(O,f4r),e(O,P4),e(P4,K3e),e(K3e,g4r),e(P4,h4r),e(P4,TK),e(TK,u4r),e(P4,p4r),e(O,_4r),e(O,B4),e(B4,e5e),e(e5e,b4r),e(B4,v4r),e(B4,MK),e(MK,F4r),e(B4,T4r),e(O,M4r),e(O,I4),e(I4,o5e),e(o5e,E4r),e(I4,C4r),e(I4,EK),e(EK,w4r),e(I4,A4r),e(O,L4r),e(O,N4),e(N4,r5e),e(r5e,y4r),e(N4,x4r),e(N4,CK),e(CK,$4r),e(N4,k4r),e(O,S4r),e(O,q4),e(q4,t5e),e(t5e,R4r),e(q4,P4r),e(q4,wK),e(wK,B4r),e(q4,I4r),e(O,N4r),e(O,j4),e(j4,a5e),e(a5e,q4r),e(j4,j4r),e(j4,AK),e(AK,D4r),e(j4,G4r),e(O,O4r),e(O,D4),e(D4,n5e),e(n5e,V4r),e(D4,X4r),e(D4,LK),e(LK,z4r),e(D4,Q4r),e(O,W4r),e(O,G4),e(G4,s5e),e(s5e,U4r),e(G4,H4r),e(G4,yK),e(yK,J4r),e(G4,Y4r),e(O,Z4r),e(O,O4),e(O4,l5e),e(l5e,K4r),e(O4,eCr),e(O4,xK),e(xK,oCr),e(O4,rCr),e(O,tCr),e(O,V4),e(V4,i5e),e(i5e,aCr),e(V4,nCr),e(V4,$K),e($K,sCr),e(V4,lCr),e(O,iCr),e(O,X4),e(X4,d5e),e(d5e,dCr),e(X4,mCr),e(X4,kK),e(kK,cCr),e(X4,fCr),e(O,gCr),e(O,z4),e(z4,m5e),e(m5e,hCr),e(z4,uCr),e(z4,SK),e(SK,pCr),e(z4,_Cr),e(O,bCr),e(O,Q4),e(Q4,c5e),e(c5e,vCr),e(Q4,FCr),e(Q4,RK),e(RK,TCr),e(Q4,MCr),e(O,ECr),e(O,W4),e(W4,f5e),e(f5e,CCr),e(W4,wCr),e(W4,PK),e(PK,ACr),e(W4,LCr),e(O,yCr),e(O,U4),e(U4,g5e),e(g5e,xCr),e(U4,$Cr),e(U4,BK),e(BK,kCr),e(U4,SCr),e(O,RCr),e(O,H4),e(H4,h5e),e(h5e,PCr),e(H4,BCr),e(H4,IK),e(IK,ICr),e(H4,NCr),e(O,qCr),e(O,J4),e(J4,u5e),e(u5e,jCr),e(J4,DCr),e(J4,NK),e(NK,GCr),e(J4,OCr),e(mo,VCr),e(mo,Y4),e(Y4,XCr),e(Y4,p5e),e(p5e,zCr),e(Y4,QCr),e(Y4,_5e),e(_5e,WCr),e(mo,UCr),M(Z4,mo,null),b(c,sao,_),b(c,cm,_),e(cm,K4),e(K4,b5e),M(Nk,b5e,null),e(cm,HCr),e(cm,v5e),e(v5e,JCr),b(c,lao,_),b(c,Wo,_),M(qk,Wo,null),e(Wo,YCr),e(Wo,fm),e(fm,ZCr),e(fm,qK),e(qK,KCr),e(fm,e3r),e(fm,jK),e(jK,o3r),e(fm,r3r),e(Wo,t3r),e(Wo,jk),e(jk,a3r),e(jk,F5e),e(F5e,n3r),e(jk,s3r),e(Wo,l3r),e(Wo,Rt),M(Dk,Rt,null),e(Rt,i3r),e(Rt,T5e),e(T5e,d3r),e(Rt,m3r),e(Rt,gm),e(gm,c3r),e(gm,M5e),e(M5e,f3r),e(gm,g3r),e(gm,DK),e(DK,h3r),e(gm,u3r),e(Rt,p3r),M(eC,Rt,null),e(Wo,_3r),e(Wo,co),M(Gk,co,null),e(co,b3r),e(co,E5e),e(E5e,v3r),e(co,F3r),e(co,_n),e(_n,T3r),e(_n,C5e),e(C5e,M3r),e(_n,E3r),e(_n,w5e),e(w5e,C3r),e(_n,w3r),e(_n,A5e),e(A5e,A3r),e(_n,L3r),e(co,y3r),e(co,L5e),e(L5e,oC),e(oC,y5e),e(y5e,x3r),e(oC,$3r),e(oC,GK),e(GK,k3r),e(oC,S3r),e(co,R3r),e(co,rC),e(rC,P3r),e(rC,x5e),e(x5e,B3r),e(rC,I3r),e(rC,$5e),e($5e,N3r),e(co,q3r),M(tC,co,null),b(c,iao,_),b(c,hm,_),e(hm,aC),e(aC,k5e),M(Ok,k5e,null),e(hm,j3r),e(hm,S5e),e(S5e,D3r),b(c,dao,_),b(c,Uo,_),M(Vk,Uo,null),e(Uo,G3r),e(Uo,um),e(um,O3r),e(um,OK),e(OK,V3r),e(um,X3r),e(um,VK),e(VK,z3r),e(um,Q3r),e(Uo,W3r),e(Uo,Xk),e(Xk,U3r),e(Xk,R5e),e(R5e,H3r),e(Xk,J3r),e(Uo,Y3r),e(Uo,Pt),M(zk,Pt,null),e(Pt,Z3r),e(Pt,P5e),e(P5e,K3r),e(Pt,e5r),e(Pt,pm),e(pm,o5r),e(pm,B5e),e(B5e,r5r),e(pm,t5r),e(pm,XK),e(XK,a5r),e(pm,n5r),e(Pt,s5r),M(nC,Pt,null),e(Uo,l5r),e(Uo,fo),M(Qk,fo,null),e(fo,i5r),e(fo,I5e),e(I5e,d5r),e(fo,m5r),e(fo,bn),e(bn,c5r),e(bn,N5e),e(N5e,f5r),e(bn,g5r),e(bn,q5e),e(q5e,h5r),e(bn,u5r),e(bn,j5e),e(j5e,p5r),e(bn,_5r),e(fo,b5r),e(fo,_m),e(_m,sC),e(sC,D5e),e(D5e,v5r),e(sC,F5r),e(sC,zK),e(zK,T5r),e(sC,M5r),e(_m,E5r),e(_m,lC),e(lC,G5e),e(G5e,C5r),e(lC,w5r),e(lC,QK),e(QK,A5r),e(lC,L5r),e(_m,y5r),e(_m,iC),e(iC,O5e),e(O5e,x5r),e(iC,$5r),e(iC,WK),e(WK,k5r),e(iC,S5r),e(fo,R5r),e(fo,dC),e(dC,P5r),e(dC,V5e),e(V5e,B5r),e(dC,I5r),e(dC,X5e),e(X5e,N5r),e(fo,q5r),M(mC,fo,null),b(c,mao,_),b(c,bm,_),e(bm,cC),e(cC,z5e),M(Wk,z5e,null),e(bm,j5r),e(bm,Q5e),e(Q5e,D5r),b(c,cao,_),b(c,Ho,_),M(Uk,Ho,null),e(Ho,G5r),e(Ho,vm),e(vm,O5r),e(vm,UK),e(UK,V5r),e(vm,X5r),e(vm,HK),e(HK,z5r),e(vm,Q5r),e(Ho,W5r),e(Ho,Hk),e(Hk,U5r),e(Hk,W5e),e(W5e,H5r),e(Hk,J5r),e(Ho,Y5r),e(Ho,Bt),M(Jk,Bt,null),e(Bt,Z5r),e(Bt,U5e),e(U5e,K5r),e(Bt,e0r),e(Bt,Fm),e(Fm,o0r),e(Fm,H5e),e(H5e,r0r),e(Fm,t0r),e(Fm,JK),e(JK,a0r),e(Fm,n0r),e(Bt,s0r),M(fC,Bt,null),e(Ho,l0r),e(Ho,go),M(Yk,go,null),e(go,i0r),e(go,J5e),e(J5e,d0r),e(go,m0r),e(go,vn),e(vn,c0r),e(vn,Y5e),e(Y5e,f0r),e(vn,g0r),e(vn,Z5e),e(Z5e,h0r),e(vn,u0r),e(vn,K5e),e(K5e,p0r),e(vn,_0r),e(go,b0r),e(go,be),e(be,gC),e(gC,e0e),e(e0e,v0r),e(gC,F0r),e(gC,YK),e(YK,T0r),e(gC,M0r),e(be,E0r),e(be,hC),e(hC,o0e),e(o0e,C0r),e(hC,w0r),e(hC,ZK),e(ZK,A0r),e(hC,L0r),e(be,y0r),e(be,uC),e(uC,r0e),e(r0e,x0r),e(uC,$0r),e(uC,KK),e(KK,k0r),e(uC,S0r),e(be,R0r),e(be,pC),e(pC,t0e),e(t0e,P0r),e(pC,B0r),e(pC,eee),e(eee,I0r),e(pC,N0r),e(be,q0r),e(be,$l),e($l,a0e),e(a0e,j0r),e($l,D0r),e($l,oee),e(oee,G0r),e($l,O0r),e($l,ree),e(ree,V0r),e($l,X0r),e(be,z0r),e(be,_C),e(_C,n0e),e(n0e,Q0r),e(_C,W0r),e(_C,tee),e(tee,U0r),e(_C,H0r),e(be,J0r),e(be,kl),e(kl,s0e),e(s0e,Y0r),e(kl,Z0r),e(kl,aee),e(aee,K0r),e(kl,ewr),e(kl,nee),e(nee,owr),e(kl,rwr),e(be,twr),e(be,bC),e(bC,l0e),e(l0e,awr),e(bC,nwr),e(bC,see),e(see,swr),e(bC,lwr),e(be,iwr),e(be,It),e(It,i0e),e(i0e,dwr),e(It,mwr),e(It,lee),e(lee,cwr),e(It,fwr),e(It,iee),e(iee,gwr),e(It,hwr),e(It,dee),e(dee,uwr),e(It,pwr),e(be,_wr),e(be,vC),e(vC,d0e),e(d0e,bwr),e(vC,vwr),e(vC,mee),e(mee,Fwr),e(vC,Twr),e(be,Mwr),e(be,FC),e(FC,m0e),e(m0e,Ewr),e(FC,Cwr),e(FC,cee),e(cee,wwr),e(FC,Awr),e(be,Lwr),e(be,TC),e(TC,c0e),e(c0e,ywr),e(TC,xwr),e(TC,fee),e(fee,$wr),e(TC,kwr),e(be,Swr),e(be,MC),e(MC,f0e),e(f0e,Rwr),e(MC,Pwr),e(MC,gee),e(gee,Bwr),e(MC,Iwr),e(be,Nwr),e(be,EC),e(EC,g0e),e(g0e,qwr),e(EC,jwr),e(EC,hee),e(hee,Dwr),e(EC,Gwr),e(be,Owr),e(be,CC),e(CC,h0e),e(h0e,Vwr),e(CC,Xwr),e(CC,uee),e(uee,zwr),e(CC,Qwr),e(be,Wwr),e(be,wC),e(wC,u0e),e(u0e,Uwr),e(wC,Hwr),e(wC,pee),e(pee,Jwr),e(wC,Ywr),e(be,Zwr),e(be,AC),e(AC,p0e),e(p0e,Kwr),e(AC,eAr),e(AC,_ee),e(_ee,oAr),e(AC,rAr),e(be,tAr),e(be,LC),e(LC,_0e),e(_0e,aAr),e(LC,nAr),e(LC,bee),e(bee,sAr),e(LC,lAr),e(go,iAr),e(go,yC),e(yC,dAr),e(yC,b0e),e(b0e,mAr),e(yC,cAr),e(yC,v0e),e(v0e,fAr),e(go,gAr),M(xC,go,null),b(c,fao,_),b(c,Tm,_),e(Tm,$C),e($C,F0e),M(Zk,F0e,null),e(Tm,hAr),e(Tm,T0e),e(T0e,uAr),b(c,gao,_),b(c,Jo,_),M(Kk,Jo,null),e(Jo,pAr),e(Jo,Mm),e(Mm,_Ar),e(Mm,vee),e(vee,bAr),e(Mm,vAr),e(Mm,Fee),e(Fee,FAr),e(Mm,TAr),e(Jo,MAr),e(Jo,eS),e(eS,EAr),e(eS,M0e),e(M0e,CAr),e(eS,wAr),e(Jo,AAr),e(Jo,Nt),M(oS,Nt,null),e(Nt,LAr),e(Nt,E0e),e(E0e,yAr),e(Nt,xAr),e(Nt,Em),e(Em,$Ar),e(Em,C0e),e(C0e,kAr),e(Em,SAr),e(Em,Tee),e(Tee,RAr),e(Em,PAr),e(Nt,BAr),M(kC,Nt,null),e(Jo,IAr),e(Jo,ho),M(rS,ho,null),e(ho,NAr),e(ho,w0e),e(w0e,qAr),e(ho,jAr),e(ho,Fn),e(Fn,DAr),e(Fn,A0e),e(A0e,GAr),e(Fn,OAr),e(Fn,L0e),e(L0e,VAr),e(Fn,XAr),e(Fn,y0e),e(y0e,zAr),e(Fn,QAr),e(ho,WAr),e(ho,x0e),e(x0e,SC),e(SC,$0e),e($0e,UAr),e(SC,HAr),e(SC,Mee),e(Mee,JAr),e(SC,YAr),e(ho,ZAr),e(ho,RC),e(RC,KAr),e(RC,k0e),e(k0e,e6r),e(RC,o6r),e(RC,S0e),e(S0e,r6r),e(ho,t6r),M(PC,ho,null),b(c,hao,_),b(c,Cm,_),e(Cm,BC),e(BC,R0e),M(tS,R0e,null),e(Cm,a6r),e(Cm,P0e),e(P0e,n6r),b(c,uao,_),b(c,Yo,_),M(aS,Yo,null),e(Yo,s6r),e(Yo,wm),e(wm,l6r),e(wm,Eee),e(Eee,i6r),e(wm,d6r),e(wm,Cee),e(Cee,m6r),e(wm,c6r),e(Yo,f6r),e(Yo,nS),e(nS,g6r),e(nS,B0e),e(B0e,h6r),e(nS,u6r),e(Yo,p6r),e(Yo,qt),M(sS,qt,null),e(qt,_6r),e(qt,I0e),e(I0e,b6r),e(qt,v6r),e(qt,Am),e(Am,F6r),e(Am,N0e),e(N0e,T6r),e(Am,M6r),e(Am,wee),e(wee,E6r),e(Am,C6r),e(qt,w6r),M(IC,qt,null),e(Yo,A6r),e(Yo,uo),M(lS,uo,null),e(uo,L6r),e(uo,q0e),e(q0e,y6r),e(uo,x6r),e(uo,Tn),e(Tn,$6r),e(Tn,j0e),e(j0e,k6r),e(Tn,S6r),e(Tn,D0e),e(D0e,R6r),e(Tn,P6r),e(Tn,G0e),e(G0e,B6r),e(Tn,I6r),e(uo,N6r),e(uo,O0e),e(O0e,NC),e(NC,V0e),e(V0e,q6r),e(NC,j6r),e(NC,Aee),e(Aee,D6r),e(NC,G6r),e(uo,O6r),e(uo,qC),e(qC,V6r),e(qC,X0e),e(X0e,X6r),e(qC,z6r),e(qC,z0e),e(z0e,Q6r),e(uo,W6r),M(jC,uo,null),b(c,pao,_),b(c,Lm,_),e(Lm,DC),e(DC,Q0e),M(iS,Q0e,null),e(Lm,U6r),e(Lm,W0e),e(W0e,H6r),b(c,_ao,_),b(c,Zo,_),M(dS,Zo,null),e(Zo,J6r),e(Zo,ym),e(ym,Y6r),e(ym,Lee),e(Lee,Z6r),e(ym,K6r),e(ym,yee),e(yee,e7r),e(ym,o7r),e(Zo,r7r),e(Zo,mS),e(mS,t7r),e(mS,U0e),e(U0e,a7r),e(mS,n7r),e(Zo,s7r),e(Zo,jt),M(cS,jt,null),e(jt,l7r),e(jt,H0e),e(H0e,i7r),e(jt,d7r),e(jt,xm),e(xm,m7r),e(xm,J0e),e(J0e,c7r),e(xm,f7r),e(xm,xee),e(xee,g7r),e(xm,h7r),e(jt,u7r),M(GC,jt,null),e(Zo,p7r),e(Zo,po),M(fS,po,null),e(po,_7r),e(po,Y0e),e(Y0e,b7r),e(po,v7r),e(po,Mn),e(Mn,F7r),e(Mn,Z0e),e(Z0e,T7r),e(Mn,M7r),e(Mn,K0e),e(K0e,E7r),e(Mn,C7r),e(Mn,ewe),e(ewe,w7r),e(Mn,A7r),e(po,L7r),e(po,owe),e(owe,OC),e(OC,rwe),e(rwe,y7r),e(OC,x7r),e(OC,$ee),e($ee,$7r),e(OC,k7r),e(po,S7r),e(po,VC),e(VC,R7r),e(VC,twe),e(twe,P7r),e(VC,B7r),e(VC,awe),e(awe,I7r),e(po,N7r),M(XC,po,null),b(c,bao,_),b(c,$m,_),e($m,zC),e(zC,nwe),M(gS,nwe,null),e($m,q7r),e($m,swe),e(swe,j7r),b(c,vao,_),b(c,Ko,_),M(hS,Ko,null),e(Ko,D7r),e(Ko,km),e(km,G7r),e(km,kee),e(kee,O7r),e(km,V7r),e(km,See),e(See,X7r),e(km,z7r),e(Ko,Q7r),e(Ko,uS),e(uS,W7r),e(uS,lwe),e(lwe,U7r),e(uS,H7r),e(Ko,J7r),e(Ko,Dt),M(pS,Dt,null),e(Dt,Y7r),e(Dt,iwe),e(iwe,Z7r),e(Dt,K7r),e(Dt,Sm),e(Sm,e8r),e(Sm,dwe),e(dwe,o8r),e(Sm,r8r),e(Sm,Ree),e(Ree,t8r),e(Sm,a8r),e(Dt,n8r),M(QC,Dt,null),e(Ko,s8r),e(Ko,_o),M(_S,_o,null),e(_o,l8r),e(_o,mwe),e(mwe,i8r),e(_o,d8r),e(_o,En),e(En,m8r),e(En,cwe),e(cwe,c8r),e(En,f8r),e(En,fwe),e(fwe,g8r),e(En,h8r),e(En,gwe),e(gwe,u8r),e(En,p8r),e(_o,_8r),e(_o,Be),e(Be,WC),e(WC,hwe),e(hwe,b8r),e(WC,v8r),e(WC,Pee),e(Pee,F8r),e(WC,T8r),e(Be,M8r),e(Be,UC),e(UC,uwe),e(uwe,E8r),e(UC,C8r),e(UC,Bee),e(Bee,w8r),e(UC,A8r),e(Be,L8r),e(Be,HC),e(HC,pwe),e(pwe,y8r),e(HC,x8r),e(HC,Iee),e(Iee,$8r),e(HC,k8r),e(Be,S8r),e(Be,JC),e(JC,_we),e(_we,R8r),e(JC,P8r),e(JC,Nee),e(Nee,B8r),e(JC,I8r),e(Be,N8r),e(Be,YC),e(YC,bwe),e(bwe,q8r),e(YC,j8r),e(YC,qee),e(qee,D8r),e(YC,G8r),e(Be,O8r),e(Be,ZC),e(ZC,vwe),e(vwe,V8r),e(ZC,X8r),e(ZC,jee),e(jee,z8r),e(ZC,Q8r),e(Be,W8r),e(Be,KC),e(KC,Fwe),e(Fwe,U8r),e(KC,H8r),e(KC,Dee),e(Dee,J8r),e(KC,Y8r),e(Be,Z8r),e(Be,e3),e(e3,Twe),e(Twe,K8r),e(e3,eLr),e(e3,Gee),e(Gee,oLr),e(e3,rLr),e(Be,tLr),e(Be,o3),e(o3,Mwe),e(Mwe,aLr),e(o3,nLr),e(o3,Oee),e(Oee,sLr),e(o3,lLr),e(_o,iLr),e(_o,r3),e(r3,dLr),e(r3,Ewe),e(Ewe,mLr),e(r3,cLr),e(r3,Cwe),e(Cwe,fLr),e(_o,gLr),M(t3,_o,null),b(c,Fao,_),b(c,Rm,_),e(Rm,a3),e(a3,wwe),M(bS,wwe,null),e(Rm,hLr),e(Rm,Awe),e(Awe,uLr),b(c,Tao,_),b(c,er,_),M(vS,er,null),e(er,pLr),e(er,Pm),e(Pm,_Lr),e(Pm,Vee),e(Vee,bLr),e(Pm,vLr),e(Pm,Xee),e(Xee,FLr),e(Pm,TLr),e(er,MLr),e(er,FS),e(FS,ELr),e(FS,Lwe),e(Lwe,CLr),e(FS,wLr),e(er,ALr),e(er,Gt),M(TS,Gt,null),e(Gt,LLr),e(Gt,ywe),e(ywe,yLr),e(Gt,xLr),e(Gt,Bm),e(Bm,$Lr),e(Bm,xwe),e(xwe,kLr),e(Bm,SLr),e(Bm,zee),e(zee,RLr),e(Bm,PLr),e(Gt,BLr),M(n3,Gt,null),e(er,ILr),e(er,bo),M(MS,bo,null),e(bo,NLr),e(bo,$we),e($we,qLr),e(bo,jLr),e(bo,Cn),e(Cn,DLr),e(Cn,kwe),e(kwe,GLr),e(Cn,OLr),e(Cn,Swe),e(Swe,VLr),e(Cn,XLr),e(Cn,Rwe),e(Rwe,zLr),e(Cn,QLr),e(bo,WLr),e(bo,ut),e(ut,s3),e(s3,Pwe),e(Pwe,ULr),e(s3,HLr),e(s3,Qee),e(Qee,JLr),e(s3,YLr),e(ut,ZLr),e(ut,l3),e(l3,Bwe),e(Bwe,KLr),e(l3,eyr),e(l3,Wee),e(Wee,oyr),e(l3,ryr),e(ut,tyr),e(ut,i3),e(i3,Iwe),e(Iwe,ayr),e(i3,nyr),e(i3,Uee),e(Uee,syr),e(i3,lyr),e(ut,iyr),e(ut,d3),e(d3,Nwe),e(Nwe,dyr),e(d3,myr),e(d3,Hee),e(Hee,cyr),e(d3,fyr),e(ut,gyr),e(ut,m3),e(m3,qwe),e(qwe,hyr),e(m3,uyr),e(m3,Jee),e(Jee,pyr),e(m3,_yr),e(bo,byr),e(bo,c3),e(c3,vyr),e(c3,jwe),e(jwe,Fyr),e(c3,Tyr),e(c3,Dwe),e(Dwe,Myr),e(bo,Eyr),M(f3,bo,null),b(c,Mao,_),b(c,Im,_),e(Im,g3),e(g3,Gwe),M(ES,Gwe,null),e(Im,Cyr),e(Im,Owe),e(Owe,wyr),b(c,Eao,_),b(c,or,_),M(CS,or,null),e(or,Ayr),e(or,Nm),e(Nm,Lyr),e(Nm,Yee),e(Yee,yyr),e(Nm,xyr),e(Nm,Zee),e(Zee,$yr),e(Nm,kyr),e(or,Syr),e(or,wS),e(wS,Ryr),e(wS,Vwe),e(Vwe,Pyr),e(wS,Byr),e(or,Iyr),e(or,Ot),M(AS,Ot,null),e(Ot,Nyr),e(Ot,Xwe),e(Xwe,qyr),e(Ot,jyr),e(Ot,qm),e(qm,Dyr),e(qm,zwe),e(zwe,Gyr),e(qm,Oyr),e(qm,Kee),e(Kee,Vyr),e(qm,Xyr),e(Ot,zyr),M(h3,Ot,null),e(or,Qyr),e(or,vo),M(LS,vo,null),e(vo,Wyr),e(vo,Qwe),e(Qwe,Uyr),e(vo,Hyr),e(vo,wn),e(wn,Jyr),e(wn,Wwe),e(Wwe,Yyr),e(wn,Zyr),e(wn,Uwe),e(Uwe,Kyr),e(wn,e9r),e(wn,Hwe),e(Hwe,o9r),e(wn,r9r),e(vo,t9r),e(vo,Le),e(Le,u3),e(u3,Jwe),e(Jwe,a9r),e(u3,n9r),e(u3,eoe),e(eoe,s9r),e(u3,l9r),e(Le,i9r),e(Le,p3),e(p3,Ywe),e(Ywe,d9r),e(p3,m9r),e(p3,ooe),e(ooe,c9r),e(p3,f9r),e(Le,g9r),e(Le,_3),e(_3,Zwe),e(Zwe,h9r),e(_3,u9r),e(_3,roe),e(roe,p9r),e(_3,_9r),e(Le,b9r),e(Le,b3),e(b3,Kwe),e(Kwe,v9r),e(b3,F9r),e(b3,toe),e(toe,T9r),e(b3,M9r),e(Le,E9r),e(Le,v3),e(v3,eAe),e(eAe,C9r),e(v3,w9r),e(v3,aoe),e(aoe,A9r),e(v3,L9r),e(Le,y9r),e(Le,F3),e(F3,oAe),e(oAe,x9r),e(F3,$9r),e(F3,noe),e(noe,k9r),e(F3,S9r),e(Le,R9r),e(Le,T3),e(T3,rAe),e(rAe,P9r),e(T3,B9r),e(T3,soe),e(soe,I9r),e(T3,N9r),e(Le,q9r),e(Le,M3),e(M3,tAe),e(tAe,j9r),e(M3,D9r),e(M3,loe),e(loe,G9r),e(M3,O9r),e(Le,V9r),e(Le,E3),e(E3,aAe),e(aAe,X9r),e(E3,z9r),e(E3,ioe),e(ioe,Q9r),e(E3,W9r),e(Le,U9r),e(Le,C3),e(C3,nAe),e(nAe,H9r),e(C3,J9r),e(C3,doe),e(doe,Y9r),e(C3,Z9r),e(vo,K9r),e(vo,w3),e(w3,exr),e(w3,sAe),e(sAe,oxr),e(w3,rxr),e(w3,lAe),e(lAe,txr),e(vo,axr),M(A3,vo,null),b(c,Cao,_),b(c,jm,_),e(jm,L3),e(L3,iAe),M(yS,iAe,null),e(jm,nxr),e(jm,dAe),e(dAe,sxr),b(c,wao,_),b(c,rr,_),M(xS,rr,null),e(rr,lxr),e(rr,Dm),e(Dm,ixr),e(Dm,moe),e(moe,dxr),e(Dm,mxr),e(Dm,coe),e(coe,cxr),e(Dm,fxr),e(rr,gxr),e(rr,$S),e($S,hxr),e($S,mAe),e(mAe,uxr),e($S,pxr),e(rr,_xr),e(rr,Vt),M(kS,Vt,null),e(Vt,bxr),e(Vt,cAe),e(cAe,vxr),e(Vt,Fxr),e(Vt,Gm),e(Gm,Txr),e(Gm,fAe),e(fAe,Mxr),e(Gm,Exr),e(Gm,foe),e(foe,Cxr),e(Gm,wxr),e(Vt,Axr),M(y3,Vt,null),e(rr,Lxr),e(rr,Fo),M(SS,Fo,null),e(Fo,yxr),e(Fo,gAe),e(gAe,xxr),e(Fo,$xr),e(Fo,An),e(An,kxr),e(An,hAe),e(hAe,Sxr),e(An,Rxr),e(An,uAe),e(uAe,Pxr),e(An,Bxr),e(An,pAe),e(pAe,Ixr),e(An,Nxr),e(Fo,qxr),e(Fo,Om),e(Om,x3),e(x3,_Ae),e(_Ae,jxr),e(x3,Dxr),e(x3,goe),e(goe,Gxr),e(x3,Oxr),e(Om,Vxr),e(Om,$3),e($3,bAe),e(bAe,Xxr),e($3,zxr),e($3,hoe),e(hoe,Qxr),e($3,Wxr),e(Om,Uxr),e(Om,k3),e(k3,vAe),e(vAe,Hxr),e(k3,Jxr),e(k3,uoe),e(uoe,Yxr),e(k3,Zxr),e(Fo,Kxr),e(Fo,S3),e(S3,e$r),e(S3,FAe),e(FAe,o$r),e(S3,r$r),e(S3,TAe),e(TAe,t$r),e(Fo,a$r),M(R3,Fo,null),b(c,Aao,_),b(c,Vm,_),e(Vm,P3),e(P3,MAe),M(RS,MAe,null),e(Vm,n$r),e(Vm,EAe),e(EAe,s$r),b(c,Lao,_),b(c,tr,_),M(PS,tr,null),e(tr,l$r),e(tr,Xm),e(Xm,i$r),e(Xm,poe),e(poe,d$r),e(Xm,m$r),e(Xm,_oe),e(_oe,c$r),e(Xm,f$r),e(tr,g$r),e(tr,BS),e(BS,h$r),e(BS,CAe),e(CAe,u$r),e(BS,p$r),e(tr,_$r),e(tr,Xt),M(IS,Xt,null),e(Xt,b$r),e(Xt,wAe),e(wAe,v$r),e(Xt,F$r),e(Xt,zm),e(zm,T$r),e(zm,AAe),e(AAe,M$r),e(zm,E$r),e(zm,boe),e(boe,C$r),e(zm,w$r),e(Xt,A$r),M(B3,Xt,null),e(tr,L$r),e(tr,To),M(NS,To,null),e(To,y$r),e(To,LAe),e(LAe,x$r),e(To,$$r),e(To,Ln),e(Ln,k$r),e(Ln,yAe),e(yAe,S$r),e(Ln,R$r),e(Ln,xAe),e(xAe,P$r),e(Ln,B$r),e(Ln,$Ae),e($Ae,I$r),e(Ln,N$r),e(To,q$r),e(To,pt),e(pt,I3),e(I3,kAe),e(kAe,j$r),e(I3,D$r),e(I3,voe),e(voe,G$r),e(I3,O$r),e(pt,V$r),e(pt,N3),e(N3,SAe),e(SAe,X$r),e(N3,z$r),e(N3,Foe),e(Foe,Q$r),e(N3,W$r),e(pt,U$r),e(pt,q3),e(q3,RAe),e(RAe,H$r),e(q3,J$r),e(q3,Toe),e(Toe,Y$r),e(q3,Z$r),e(pt,K$r),e(pt,j3),e(j3,PAe),e(PAe,ekr),e(j3,okr),e(j3,Moe),e(Moe,rkr),e(j3,tkr),e(pt,akr),e(pt,D3),e(D3,BAe),e(BAe,nkr),e(D3,skr),e(D3,Eoe),e(Eoe,lkr),e(D3,ikr),e(To,dkr),e(To,G3),e(G3,mkr),e(G3,IAe),e(IAe,ckr),e(G3,fkr),e(G3,NAe),e(NAe,gkr),e(To,hkr),M(O3,To,null),b(c,yao,_),b(c,Qm,_),e(Qm,V3),e(V3,qAe),M(qS,qAe,null),e(Qm,ukr),e(Qm,jAe),e(jAe,pkr),b(c,xao,_),b(c,ar,_),M(jS,ar,null),e(ar,_kr),e(ar,Wm),e(Wm,bkr),e(Wm,Coe),e(Coe,vkr),e(Wm,Fkr),e(Wm,woe),e(woe,Tkr),e(Wm,Mkr),e(ar,Ekr),e(ar,DS),e(DS,Ckr),e(DS,DAe),e(DAe,wkr),e(DS,Akr),e(ar,Lkr),e(ar,zt),M(GS,zt,null),e(zt,ykr),e(zt,GAe),e(GAe,xkr),e(zt,$kr),e(zt,Um),e(Um,kkr),e(Um,OAe),e(OAe,Skr),e(Um,Rkr),e(Um,Aoe),e(Aoe,Pkr),e(Um,Bkr),e(zt,Ikr),M(X3,zt,null),e(ar,Nkr),e(ar,Mo),M(OS,Mo,null),e(Mo,qkr),e(Mo,VAe),e(VAe,jkr),e(Mo,Dkr),e(Mo,yn),e(yn,Gkr),e(yn,XAe),e(XAe,Okr),e(yn,Vkr),e(yn,zAe),e(zAe,Xkr),e(yn,zkr),e(yn,QAe),e(QAe,Qkr),e(yn,Wkr),e(Mo,Ukr),e(Mo,xn),e(xn,z3),e(z3,WAe),e(WAe,Hkr),e(z3,Jkr),e(z3,Loe),e(Loe,Ykr),e(z3,Zkr),e(xn,Kkr),e(xn,Q3),e(Q3,UAe),e(UAe,eSr),e(Q3,oSr),e(Q3,yoe),e(yoe,rSr),e(Q3,tSr),e(xn,aSr),e(xn,W3),e(W3,HAe),e(HAe,nSr),e(W3,sSr),e(W3,xoe),e(xoe,lSr),e(W3,iSr),e(xn,dSr),e(xn,U3),e(U3,JAe),e(JAe,mSr),e(U3,cSr),e(U3,$oe),e($oe,fSr),e(U3,gSr),e(Mo,hSr),e(Mo,H3),e(H3,uSr),e(H3,YAe),e(YAe,pSr),e(H3,_Sr),e(H3,ZAe),e(ZAe,bSr),e(Mo,vSr),M(J3,Mo,null),b(c,$ao,_),b(c,Hm,_),e(Hm,Y3),e(Y3,KAe),M(VS,KAe,null),e(Hm,FSr),e(Hm,e6e),e(e6e,TSr),b(c,kao,_),b(c,nr,_),M(XS,nr,null),e(nr,MSr),e(nr,Jm),e(Jm,ESr),e(Jm,koe),e(koe,CSr),e(Jm,wSr),e(Jm,Soe),e(Soe,ASr),e(Jm,LSr),e(nr,ySr),e(nr,zS),e(zS,xSr),e(zS,o6e),e(o6e,$Sr),e(zS,kSr),e(nr,SSr),e(nr,Qt),M(QS,Qt,null),e(Qt,RSr),e(Qt,r6e),e(r6e,PSr),e(Qt,BSr),e(Qt,Ym),e(Ym,ISr),e(Ym,t6e),e(t6e,NSr),e(Ym,qSr),e(Ym,Roe),e(Roe,jSr),e(Ym,DSr),e(Qt,GSr),M(Z3,Qt,null),e(nr,OSr),e(nr,Eo),M(WS,Eo,null),e(Eo,VSr),e(Eo,a6e),e(a6e,XSr),e(Eo,zSr),e(Eo,$n),e($n,QSr),e($n,n6e),e(n6e,WSr),e($n,USr),e($n,s6e),e(s6e,HSr),e($n,JSr),e($n,l6e),e(l6e,YSr),e($n,ZSr),e(Eo,KSr),e(Eo,_t),e(_t,K3),e(K3,i6e),e(i6e,eRr),e(K3,oRr),e(K3,Poe),e(Poe,rRr),e(K3,tRr),e(_t,aRr),e(_t,e5),e(e5,d6e),e(d6e,nRr),e(e5,sRr),e(e5,Boe),e(Boe,lRr),e(e5,iRr),e(_t,dRr),e(_t,o5),e(o5,m6e),e(m6e,mRr),e(o5,cRr),e(o5,Ioe),e(Ioe,fRr),e(o5,gRr),e(_t,hRr),e(_t,r5),e(r5,c6e),e(c6e,uRr),e(r5,pRr),e(r5,Noe),e(Noe,_Rr),e(r5,bRr),e(_t,vRr),e(_t,t5),e(t5,f6e),e(f6e,FRr),e(t5,TRr),e(t5,qoe),e(qoe,MRr),e(t5,ERr),e(Eo,CRr),e(Eo,a5),e(a5,wRr),e(a5,g6e),e(g6e,ARr),e(a5,LRr),e(a5,h6e),e(h6e,yRr),e(Eo,xRr),M(n5,Eo,null),b(c,Sao,_),b(c,Zm,_),e(Zm,s5),e(s5,u6e),M(US,u6e,null),e(Zm,$Rr),e(Zm,p6e),e(p6e,kRr),b(c,Rao,_),b(c,sr,_),M(HS,sr,null),e(sr,SRr),e(sr,Km),e(Km,RRr),e(Km,joe),e(joe,PRr),e(Km,BRr),e(Km,Doe),e(Doe,IRr),e(Km,NRr),e(sr,qRr),e(sr,JS),e(JS,jRr),e(JS,_6e),e(_6e,DRr),e(JS,GRr),e(sr,ORr),e(sr,Wt),M(YS,Wt,null),e(Wt,VRr),e(Wt,b6e),e(b6e,XRr),e(Wt,zRr),e(Wt,ec),e(ec,QRr),e(ec,v6e),e(v6e,WRr),e(ec,URr),e(ec,Goe),e(Goe,HRr),e(ec,JRr),e(Wt,YRr),M(l5,Wt,null),e(sr,ZRr),e(sr,Co),M(ZS,Co,null),e(Co,KRr),e(Co,F6e),e(F6e,ePr),e(Co,oPr),e(Co,kn),e(kn,rPr),e(kn,T6e),e(T6e,tPr),e(kn,aPr),e(kn,M6e),e(M6e,nPr),e(kn,sPr),e(kn,E6e),e(E6e,lPr),e(kn,iPr),e(Co,dPr),e(Co,C6e),e(C6e,i5),e(i5,w6e),e(w6e,mPr),e(i5,cPr),e(i5,Ooe),e(Ooe,fPr),e(i5,gPr),e(Co,hPr),e(Co,d5),e(d5,uPr),e(d5,A6e),e(A6e,pPr),e(d5,_Pr),e(d5,L6e),e(L6e,bPr),e(Co,vPr),M(m5,Co,null),b(c,Pao,_),b(c,oc,_),e(oc,c5),e(c5,y6e),M(KS,y6e,null),e(oc,FPr),e(oc,x6e),e(x6e,TPr),b(c,Bao,_),b(c,lr,_),M(eR,lr,null),e(lr,MPr),e(lr,rc),e(rc,EPr),e(rc,Voe),e(Voe,CPr),e(rc,wPr),e(rc,Xoe),e(Xoe,APr),e(rc,LPr),e(lr,yPr),e(lr,oR),e(oR,xPr),e(oR,$6e),e($6e,$Pr),e(oR,kPr),e(lr,SPr),e(lr,Ut),M(rR,Ut,null),e(Ut,RPr),e(Ut,k6e),e(k6e,PPr),e(Ut,BPr),e(Ut,tc),e(tc,IPr),e(tc,S6e),e(S6e,NPr),e(tc,qPr),e(tc,zoe),e(zoe,jPr),e(tc,DPr),e(Ut,GPr),M(f5,Ut,null),e(lr,OPr),e(lr,wo),M(tR,wo,null),e(wo,VPr),e(wo,R6e),e(R6e,XPr),e(wo,zPr),e(wo,Sn),e(Sn,QPr),e(Sn,P6e),e(P6e,WPr),e(Sn,UPr),e(Sn,B6e),e(B6e,HPr),e(Sn,JPr),e(Sn,I6e),e(I6e,YPr),e(Sn,ZPr),e(wo,KPr),e(wo,bt),e(bt,g5),e(g5,N6e),e(N6e,eBr),e(g5,oBr),e(g5,Qoe),e(Qoe,rBr),e(g5,tBr),e(bt,aBr),e(bt,h5),e(h5,q6e),e(q6e,nBr),e(h5,sBr),e(h5,Woe),e(Woe,lBr),e(h5,iBr),e(bt,dBr),e(bt,u5),e(u5,j6e),e(j6e,mBr),e(u5,cBr),e(u5,Uoe),e(Uoe,fBr),e(u5,gBr),e(bt,hBr),e(bt,p5),e(p5,D6e),e(D6e,uBr),e(p5,pBr),e(p5,Hoe),e(Hoe,_Br),e(p5,bBr),e(bt,vBr),e(bt,_5),e(_5,G6e),e(G6e,FBr),e(_5,TBr),e(_5,Joe),e(Joe,MBr),e(_5,EBr),e(wo,CBr),e(wo,b5),e(b5,wBr),e(b5,O6e),e(O6e,ABr),e(b5,LBr),e(b5,V6e),e(V6e,yBr),e(wo,xBr),M(v5,wo,null),b(c,Iao,_),b(c,ac,_),e(ac,F5),e(F5,X6e),M(aR,X6e,null),e(ac,$Br),e(ac,z6e),e(z6e,kBr),b(c,Nao,_),b(c,ir,_),M(nR,ir,null),e(ir,SBr),e(ir,nc),e(nc,RBr),e(nc,Yoe),e(Yoe,PBr),e(nc,BBr),e(nc,Zoe),e(Zoe,IBr),e(nc,NBr),e(ir,qBr),e(ir,sR),e(sR,jBr),e(sR,Q6e),e(Q6e,DBr),e(sR,GBr),e(ir,OBr),e(ir,Ht),M(lR,Ht,null),e(Ht,VBr),e(Ht,W6e),e(W6e,XBr),e(Ht,zBr),e(Ht,sc),e(sc,QBr),e(sc,U6e),e(U6e,WBr),e(sc,UBr),e(sc,Koe),e(Koe,HBr),e(sc,JBr),e(Ht,YBr),M(T5,Ht,null),e(ir,ZBr),e(ir,Ao),M(iR,Ao,null),e(Ao,KBr),e(Ao,H6e),e(H6e,eIr),e(Ao,oIr),e(Ao,Rn),e(Rn,rIr),e(Rn,J6e),e(J6e,tIr),e(Rn,aIr),e(Rn,Y6e),e(Y6e,nIr),e(Rn,sIr),e(Rn,Z6e),e(Z6e,lIr),e(Rn,iIr),e(Ao,dIr),e(Ao,K6e),e(K6e,M5),e(M5,e7e),e(e7e,mIr),e(M5,cIr),e(M5,ere),e(ere,fIr),e(M5,gIr),e(Ao,hIr),e(Ao,E5),e(E5,uIr),e(E5,o7e),e(o7e,pIr),e(E5,_Ir),e(E5,r7e),e(r7e,bIr),e(Ao,vIr),M(C5,Ao,null),b(c,qao,_),b(c,lc,_),e(lc,w5),e(w5,t7e),M(dR,t7e,null),e(lc,FIr),e(lc,a7e),e(a7e,TIr),b(c,jao,_),b(c,dr,_),M(mR,dr,null),e(dr,MIr),e(dr,ic),e(ic,EIr),e(ic,ore),e(ore,CIr),e(ic,wIr),e(ic,rre),e(rre,AIr),e(ic,LIr),e(dr,yIr),e(dr,cR),e(cR,xIr),e(cR,n7e),e(n7e,$Ir),e(cR,kIr),e(dr,SIr),e(dr,Jt),M(fR,Jt,null),e(Jt,RIr),e(Jt,s7e),e(s7e,PIr),e(Jt,BIr),e(Jt,dc),e(dc,IIr),e(dc,l7e),e(l7e,NIr),e(dc,qIr),e(dc,tre),e(tre,jIr),e(dc,DIr),e(Jt,GIr),M(A5,Jt,null),e(dr,OIr),e(dr,Lo),M(gR,Lo,null),e(Lo,VIr),e(Lo,i7e),e(i7e,XIr),e(Lo,zIr),e(Lo,Pn),e(Pn,QIr),e(Pn,d7e),e(d7e,WIr),e(Pn,UIr),e(Pn,m7e),e(m7e,HIr),e(Pn,JIr),e(Pn,c7e),e(c7e,YIr),e(Pn,ZIr),e(Lo,KIr),e(Lo,f7e),e(f7e,L5),e(L5,g7e),e(g7e,eNr),e(L5,oNr),e(L5,are),e(are,rNr),e(L5,tNr),e(Lo,aNr),e(Lo,y5),e(y5,nNr),e(y5,h7e),e(h7e,sNr),e(y5,lNr),e(y5,u7e),e(u7e,iNr),e(Lo,dNr),M(x5,Lo,null),b(c,Dao,_),b(c,mc,_),e(mc,$5),e($5,p7e),M(hR,p7e,null),e(mc,mNr),e(mc,_7e),e(_7e,cNr),b(c,Gao,_),b(c,mr,_),M(uR,mr,null),e(mr,fNr),e(mr,cc),e(cc,gNr),e(cc,nre),e(nre,hNr),e(cc,uNr),e(cc,sre),e(sre,pNr),e(cc,_Nr),e(mr,bNr),e(mr,pR),e(pR,vNr),e(pR,b7e),e(b7e,FNr),e(pR,TNr),e(mr,MNr),e(mr,Yt),M(_R,Yt,null),e(Yt,ENr),e(Yt,v7e),e(v7e,CNr),e(Yt,wNr),e(Yt,fc),e(fc,ANr),e(fc,F7e),e(F7e,LNr),e(fc,yNr),e(fc,lre),e(lre,xNr),e(fc,$Nr),e(Yt,kNr),M(k5,Yt,null),e(mr,SNr),e(mr,Dr),M(bR,Dr,null),e(Dr,RNr),e(Dr,T7e),e(T7e,PNr),e(Dr,BNr),e(Dr,Bn),e(Bn,INr),e(Bn,M7e),e(M7e,NNr),e(Bn,qNr),e(Bn,E7e),e(E7e,jNr),e(Bn,DNr),e(Bn,C7e),e(C7e,GNr),e(Bn,ONr),e(Dr,VNr),e(Dr,P),e(P,S5),e(S5,w7e),e(w7e,XNr),e(S5,zNr),e(S5,ire),e(ire,QNr),e(S5,WNr),e(P,UNr),e(P,R5),e(R5,A7e),e(A7e,HNr),e(R5,JNr),e(R5,dre),e(dre,YNr),e(R5,ZNr),e(P,KNr),e(P,P5),e(P5,L7e),e(L7e,eqr),e(P5,oqr),e(P5,mre),e(mre,rqr),e(P5,tqr),e(P,aqr),e(P,B5),e(B5,y7e),e(y7e,nqr),e(B5,sqr),e(B5,cre),e(cre,lqr),e(B5,iqr),e(P,dqr),e(P,I5),e(I5,x7e),e(x7e,mqr),e(I5,cqr),e(I5,fre),e(fre,fqr),e(I5,gqr),e(P,hqr),e(P,N5),e(N5,$7e),e($7e,uqr),e(N5,pqr),e(N5,gre),e(gre,_qr),e(N5,bqr),e(P,vqr),e(P,q5),e(q5,k7e),e(k7e,Fqr),e(q5,Tqr),e(q5,hre),e(hre,Mqr),e(q5,Eqr),e(P,Cqr),e(P,j5),e(j5,S7e),e(S7e,wqr),e(j5,Aqr),e(j5,ure),e(ure,Lqr),e(j5,yqr),e(P,xqr),e(P,D5),e(D5,R7e),e(R7e,$qr),e(D5,kqr),e(D5,pre),e(pre,Sqr),e(D5,Rqr),e(P,Pqr),e(P,G5),e(G5,P7e),e(P7e,Bqr),e(G5,Iqr),e(G5,_re),e(_re,Nqr),e(G5,qqr),e(P,jqr),e(P,O5),e(O5,B7e),e(B7e,Dqr),e(O5,Gqr),e(O5,bre),e(bre,Oqr),e(O5,Vqr),e(P,Xqr),e(P,V5),e(V5,I7e),e(I7e,zqr),e(V5,Qqr),e(V5,vre),e(vre,Wqr),e(V5,Uqr),e(P,Hqr),e(P,X5),e(X5,N7e),e(N7e,Jqr),e(X5,Yqr),e(X5,Fre),e(Fre,Zqr),e(X5,Kqr),e(P,ejr),e(P,z5),e(z5,q7e),e(q7e,ojr),e(z5,rjr),e(z5,Tre),e(Tre,tjr),e(z5,ajr),e(P,njr),e(P,Q5),e(Q5,j7e),e(j7e,sjr),e(Q5,ljr),e(Q5,Mre),e(Mre,ijr),e(Q5,djr),e(P,mjr),e(P,W5),e(W5,D7e),e(D7e,cjr),e(W5,fjr),e(W5,Ere),e(Ere,gjr),e(W5,hjr),e(P,ujr),e(P,U5),e(U5,G7e),e(G7e,pjr),e(U5,_jr),e(U5,Cre),e(Cre,bjr),e(U5,vjr),e(P,Fjr),e(P,H5),e(H5,O7e),e(O7e,Tjr),e(H5,Mjr),e(H5,wre),e(wre,Ejr),e(H5,Cjr),e(P,wjr),e(P,J5),e(J5,V7e),e(V7e,Ajr),e(J5,Ljr),e(J5,Are),e(Are,yjr),e(J5,xjr),e(P,$jr),e(P,Y5),e(Y5,X7e),e(X7e,kjr),e(Y5,Sjr),e(Y5,Lre),e(Lre,Rjr),e(Y5,Pjr),e(P,Bjr),e(P,Sl),e(Sl,z7e),e(z7e,Ijr),e(Sl,Njr),e(Sl,yre),e(yre,qjr),e(Sl,jjr),e(Sl,xre),e(xre,Djr),e(Sl,Gjr),e(P,Ojr),e(P,Z5),e(Z5,Q7e),e(Q7e,Vjr),e(Z5,Xjr),e(Z5,$re),e($re,zjr),e(Z5,Qjr),e(P,Wjr),e(P,K5),e(K5,W7e),e(W7e,Ujr),e(K5,Hjr),e(K5,kre),e(kre,Jjr),e(K5,Yjr),e(P,Zjr),e(P,e0),e(e0,U7e),e(U7e,Kjr),e(e0,eDr),e(e0,Sre),e(Sre,oDr),e(e0,rDr),e(P,tDr),e(P,o0),e(o0,H7e),e(H7e,aDr),e(o0,nDr),e(o0,Rre),e(Rre,sDr),e(o0,lDr),e(P,iDr),e(P,r0),e(r0,J7e),e(J7e,dDr),e(r0,mDr),e(r0,Pre),e(Pre,cDr),e(r0,fDr),e(P,gDr),e(P,t0),e(t0,Y7e),e(Y7e,hDr),e(t0,uDr),e(t0,Bre),e(Bre,pDr),e(t0,_Dr),e(P,bDr),e(P,a0),e(a0,Z7e),e(Z7e,vDr),e(a0,FDr),e(a0,Ire),e(Ire,TDr),e(a0,MDr),e(P,EDr),e(P,n0),e(n0,K7e),e(K7e,CDr),e(n0,wDr),e(n0,Nre),e(Nre,ADr),e(n0,LDr),e(P,yDr),e(P,s0),e(s0,e8e),e(e8e,xDr),e(s0,$Dr),e(s0,qre),e(qre,kDr),e(s0,SDr),e(P,RDr),e(P,l0),e(l0,o8e),e(o8e,PDr),e(l0,BDr),e(l0,jre),e(jre,IDr),e(l0,NDr),e(P,qDr),e(P,i0),e(i0,r8e),e(r8e,jDr),e(i0,DDr),e(i0,Dre),e(Dre,GDr),e(i0,ODr),e(P,VDr),e(P,d0),e(d0,t8e),e(t8e,XDr),e(d0,zDr),e(d0,Gre),e(Gre,QDr),e(d0,WDr),e(P,UDr),e(P,m0),e(m0,a8e),e(a8e,HDr),e(m0,JDr),e(m0,Ore),e(Ore,YDr),e(m0,ZDr),e(P,KDr),e(P,c0),e(c0,n8e),e(n8e,eGr),e(c0,oGr),e(c0,Vre),e(Vre,rGr),e(c0,tGr),e(P,aGr),e(P,f0),e(f0,s8e),e(s8e,nGr),e(f0,sGr),e(f0,Xre),e(Xre,lGr),e(f0,iGr),e(P,dGr),e(P,g0),e(g0,l8e),e(l8e,mGr),e(g0,cGr),e(g0,zre),e(zre,fGr),e(g0,gGr),e(P,hGr),e(P,h0),e(h0,i8e),e(i8e,uGr),e(h0,pGr),e(h0,Qre),e(Qre,_Gr),e(h0,bGr),e(P,vGr),e(P,u0),e(u0,d8e),e(d8e,FGr),e(u0,TGr),e(u0,Wre),e(Wre,MGr),e(u0,EGr),e(P,CGr),e(P,p0),e(p0,m8e),e(m8e,wGr),e(p0,AGr),e(p0,Ure),e(Ure,LGr),e(p0,yGr),e(P,xGr),e(P,_0),e(_0,c8e),e(c8e,$Gr),e(_0,kGr),e(_0,Hre),e(Hre,SGr),e(_0,RGr),e(P,PGr),e(P,b0),e(b0,f8e),e(f8e,BGr),e(b0,IGr),e(b0,Jre),e(Jre,NGr),e(b0,qGr),e(P,jGr),e(P,v0),e(v0,g8e),e(g8e,DGr),e(v0,GGr),e(v0,Yre),e(Yre,OGr),e(v0,VGr),e(P,XGr),e(P,F0),e(F0,h8e),e(h8e,zGr),e(F0,QGr),e(F0,Zre),e(Zre,WGr),e(F0,UGr),e(P,HGr),e(P,T0),e(T0,u8e),e(u8e,JGr),e(T0,YGr),e(T0,Kre),e(Kre,ZGr),e(T0,KGr),e(P,eOr),e(P,M0),e(M0,p8e),e(p8e,oOr),e(M0,rOr),e(M0,ete),e(ete,tOr),e(M0,aOr),e(P,nOr),e(P,E0),e(E0,_8e),e(_8e,sOr),e(E0,lOr),e(E0,ote),e(ote,iOr),e(E0,dOr),e(P,mOr),e(P,C0),e(C0,b8e),e(b8e,cOr),e(C0,fOr),e(C0,rte),e(rte,gOr),e(C0,hOr),e(P,uOr),e(P,w0),e(w0,v8e),e(v8e,pOr),e(w0,_Or),e(w0,tte),e(tte,bOr),e(w0,vOr),e(P,FOr),e(P,A0),e(A0,F8e),e(F8e,TOr),e(A0,MOr),e(A0,ate),e(ate,EOr),e(A0,COr),e(P,wOr),e(P,L0),e(L0,T8e),e(T8e,AOr),e(L0,LOr),e(L0,nte),e(nte,yOr),e(L0,xOr),e(P,$Or),e(P,y0),e(y0,M8e),e(M8e,kOr),e(y0,SOr),e(y0,ste),e(ste,ROr),e(y0,POr),e(P,BOr),e(P,x0),e(x0,E8e),e(E8e,IOr),e(x0,NOr),e(x0,lte),e(lte,qOr),e(x0,jOr),e(P,DOr),e(P,$0),e($0,C8e),e(C8e,GOr),e($0,OOr),e($0,ite),e(ite,VOr),e($0,XOr),e(P,zOr),e(P,k0),e(k0,w8e),e(w8e,QOr),e(k0,WOr),e(k0,dte),e(dte,UOr),e(k0,HOr),e(P,JOr),e(P,S0),e(S0,A8e),e(A8e,YOr),e(S0,ZOr),e(S0,mte),e(mte,KOr),e(S0,eVr),e(P,oVr),e(P,R0),e(R0,L8e),e(L8e,rVr),e(R0,tVr),e(R0,cte),e(cte,aVr),e(R0,nVr),e(P,sVr),e(P,P0),e(P0,y8e),e(y8e,lVr),e(P0,iVr),e(P0,fte),e(fte,dVr),e(P0,mVr),e(Dr,cVr),M(B0,Dr,null),b(c,Oao,_),b(c,gc,_),e(gc,I0),e(I0,x8e),M(vR,x8e,null),e(gc,fVr),e(gc,$8e),e($8e,gVr),b(c,Vao,_),b(c,cr,_),M(FR,cr,null),e(cr,hVr),e(cr,hc),e(hc,uVr),e(hc,gte),e(gte,pVr),e(hc,_Vr),e(hc,hte),e(hte,bVr),e(hc,vVr),e(cr,FVr),e(cr,TR),e(TR,TVr),e(TR,k8e),e(k8e,MVr),e(TR,EVr),e(cr,CVr),e(cr,Zt),M(MR,Zt,null),e(Zt,wVr),e(Zt,S8e),e(S8e,AVr),e(Zt,LVr),e(Zt,uc),e(uc,yVr),e(uc,R8e),e(R8e,xVr),e(uc,$Vr),e(uc,ute),e(ute,kVr),e(uc,SVr),e(Zt,RVr),M(N0,Zt,null),e(cr,PVr),e(cr,Gr),M(ER,Gr,null),e(Gr,BVr),e(Gr,P8e),e(P8e,IVr),e(Gr,NVr),e(Gr,In),e(In,qVr),e(In,B8e),e(B8e,jVr),e(In,DVr),e(In,I8e),e(I8e,GVr),e(In,OVr),e(In,N8e),e(N8e,VVr),e(In,XVr),e(Gr,zVr),e(Gr,se),e(se,q0),e(q0,q8e),e(q8e,QVr),e(q0,WVr),e(q0,pte),e(pte,UVr),e(q0,HVr),e(se,JVr),e(se,j0),e(j0,j8e),e(j8e,YVr),e(j0,ZVr),e(j0,_te),e(_te,KVr),e(j0,eXr),e(se,oXr),e(se,D0),e(D0,D8e),e(D8e,rXr),e(D0,tXr),e(D0,bte),e(bte,aXr),e(D0,nXr),e(se,sXr),e(se,G0),e(G0,G8e),e(G8e,lXr),e(G0,iXr),e(G0,vte),e(vte,dXr),e(G0,mXr),e(se,cXr),e(se,O0),e(O0,O8e),e(O8e,fXr),e(O0,gXr),e(O0,Fte),e(Fte,hXr),e(O0,uXr),e(se,pXr),e(se,V0),e(V0,V8e),e(V8e,_Xr),e(V0,bXr),e(V0,Tte),e(Tte,vXr),e(V0,FXr),e(se,TXr),e(se,X0),e(X0,X8e),e(X8e,MXr),e(X0,EXr),e(X0,Mte),e(Mte,CXr),e(X0,wXr),e(se,AXr),e(se,z0),e(z0,z8e),e(z8e,LXr),e(z0,yXr),e(z0,Ete),e(Ete,xXr),e(z0,$Xr),e(se,kXr),e(se,Q0),e(Q0,Q8e),e(Q8e,SXr),e(Q0,RXr),e(Q0,Cte),e(Cte,PXr),e(Q0,BXr),e(se,IXr),e(se,W0),e(W0,W8e),e(W8e,NXr),e(W0,qXr),e(W0,wte),e(wte,jXr),e(W0,DXr),e(se,GXr),e(se,U0),e(U0,U8e),e(U8e,OXr),e(U0,VXr),e(U0,Ate),e(Ate,XXr),e(U0,zXr),e(se,QXr),e(se,H0),e(H0,H8e),e(H8e,WXr),e(H0,UXr),e(H0,Lte),e(Lte,HXr),e(H0,JXr),e(se,YXr),e(se,J0),e(J0,J8e),e(J8e,ZXr),e(J0,KXr),e(J0,yte),e(yte,ezr),e(J0,ozr),e(se,rzr),e(se,Y0),e(Y0,Y8e),e(Y8e,tzr),e(Y0,azr),e(Y0,xte),e(xte,nzr),e(Y0,szr),e(se,lzr),e(se,Z0),e(Z0,Z8e),e(Z8e,izr),e(Z0,dzr),e(Z0,$te),e($te,mzr),e(Z0,czr),e(se,fzr),e(se,K0),e(K0,K8e),e(K8e,gzr),e(K0,hzr),e(K0,kte),e(kte,uzr),e(K0,pzr),e(se,_zr),e(se,ew),e(ew,eLe),e(eLe,bzr),e(ew,vzr),e(ew,Ste),e(Ste,Fzr),e(ew,Tzr),e(se,Mzr),e(se,ow),e(ow,oLe),e(oLe,Ezr),e(ow,Czr),e(ow,Rte),e(Rte,wzr),e(ow,Azr),e(se,Lzr),e(se,rw),e(rw,rLe),e(rLe,yzr),e(rw,xzr),e(rw,Pte),e(Pte,$zr),e(rw,kzr),e(se,Szr),e(se,tw),e(tw,tLe),e(tLe,Rzr),e(tw,Pzr),e(tw,Bte),e(Bte,Bzr),e(tw,Izr),e(se,Nzr),e(se,aw),e(aw,aLe),e(aLe,qzr),e(aw,jzr),e(aw,Ite),e(Ite,Dzr),e(aw,Gzr),e(se,Ozr),e(se,nw),e(nw,nLe),e(nLe,Vzr),e(nw,Xzr),e(nw,Nte),e(Nte,zzr),e(nw,Qzr),e(se,Wzr),e(se,sw),e(sw,sLe),e(sLe,Uzr),e(sw,Hzr),e(sw,qte),e(qte,Jzr),e(sw,Yzr),e(Gr,Zzr),M(lw,Gr,null),b(c,Xao,_),b(c,pc,_),e(pc,iw),e(iw,lLe),M(CR,lLe,null),e(pc,Kzr),e(pc,iLe),e(iLe,eQr),b(c,zao,_),b(c,fr,_),M(wR,fr,null),e(fr,oQr),e(fr,_c),e(_c,rQr),e(_c,jte),e(jte,tQr),e(_c,aQr),e(_c,Dte),e(Dte,nQr),e(_c,sQr),e(fr,lQr),e(fr,AR),e(AR,iQr),e(AR,dLe),e(dLe,dQr),e(AR,mQr),e(fr,cQr),e(fr,Kt),M(LR,Kt,null),e(Kt,fQr),e(Kt,mLe),e(mLe,gQr),e(Kt,hQr),e(Kt,bc),e(bc,uQr),e(bc,cLe),e(cLe,pQr),e(bc,_Qr),e(bc,Gte),e(Gte,bQr),e(bc,vQr),e(Kt,FQr),M(dw,Kt,null),e(fr,TQr),e(fr,Or),M(yR,Or,null),e(Or,MQr),e(Or,fLe),e(fLe,EQr),e(Or,CQr),e(Or,Nn),e(Nn,wQr),e(Nn,gLe),e(gLe,AQr),e(Nn,LQr),e(Nn,hLe),e(hLe,yQr),e(Nn,xQr),e(Nn,uLe),e(uLe,$Qr),e(Nn,kQr),e(Or,SQr),e(Or,Me),e(Me,mw),e(mw,pLe),e(pLe,RQr),e(mw,PQr),e(mw,Ote),e(Ote,BQr),e(mw,IQr),e(Me,NQr),e(Me,cw),e(cw,_Le),e(_Le,qQr),e(cw,jQr),e(cw,Vte),e(Vte,DQr),e(cw,GQr),e(Me,OQr),e(Me,fw),e(fw,bLe),e(bLe,VQr),e(fw,XQr),e(fw,Xte),e(Xte,zQr),e(fw,QQr),e(Me,WQr),e(Me,gw),e(gw,vLe),e(vLe,UQr),e(gw,HQr),e(gw,zte),e(zte,JQr),e(gw,YQr),e(Me,ZQr),e(Me,hw),e(hw,FLe),e(FLe,KQr),e(hw,eWr),e(hw,Qte),e(Qte,oWr),e(hw,rWr),e(Me,tWr),e(Me,uw),e(uw,TLe),e(TLe,aWr),e(uw,nWr),e(uw,Wte),e(Wte,sWr),e(uw,lWr),e(Me,iWr),e(Me,pw),e(pw,MLe),e(MLe,dWr),e(pw,mWr),e(pw,Ute),e(Ute,cWr),e(pw,fWr),e(Me,gWr),e(Me,_w),e(_w,ELe),e(ELe,hWr),e(_w,uWr),e(_w,Hte),e(Hte,pWr),e(_w,_Wr),e(Me,bWr),e(Me,bw),e(bw,CLe),e(CLe,vWr),e(bw,FWr),e(bw,Jte),e(Jte,TWr),e(bw,MWr),e(Me,EWr),e(Me,vw),e(vw,wLe),e(wLe,CWr),e(vw,wWr),e(vw,Yte),e(Yte,AWr),e(vw,LWr),e(Me,yWr),e(Me,Fw),e(Fw,ALe),e(ALe,xWr),e(Fw,$Wr),e(Fw,Zte),e(Zte,kWr),e(Fw,SWr),e(Me,RWr),e(Me,Tw),e(Tw,LLe),e(LLe,PWr),e(Tw,BWr),e(Tw,Kte),e(Kte,IWr),e(Tw,NWr),e(Me,qWr),e(Me,Mw),e(Mw,yLe),e(yLe,jWr),e(Mw,DWr),e(Mw,eae),e(eae,GWr),e(Mw,OWr),e(Me,VWr),e(Me,Ew),e(Ew,xLe),e(xLe,XWr),e(Ew,zWr),e(Ew,oae),e(oae,QWr),e(Ew,WWr),e(Or,UWr),M(Cw,Or,null),b(c,Qao,_),b(c,vc,_),e(vc,ww),e(ww,$Le),M(xR,$Le,null),e(vc,HWr),e(vc,kLe),e(kLe,JWr),b(c,Wao,_),b(c,gr,_),M($R,gr,null),e(gr,YWr),e(gr,Fc),e(Fc,ZWr),e(Fc,rae),e(rae,KWr),e(Fc,eUr),e(Fc,tae),e(tae,oUr),e(Fc,rUr),e(gr,tUr),e(gr,kR),e(kR,aUr),e(kR,SLe),e(SLe,nUr),e(kR,sUr),e(gr,lUr),e(gr,ea),M(SR,ea,null),e(ea,iUr),e(ea,RLe),e(RLe,dUr),e(ea,mUr),e(ea,Tc),e(Tc,cUr),e(Tc,PLe),e(PLe,fUr),e(Tc,gUr),e(Tc,aae),e(aae,hUr),e(Tc,uUr),e(ea,pUr),M(Aw,ea,null),e(gr,_Ur),e(gr,Vr),M(RR,Vr,null),e(Vr,bUr),e(Vr,BLe),e(BLe,vUr),e(Vr,FUr),e(Vr,qn),e(qn,TUr),e(qn,ILe),e(ILe,MUr),e(qn,EUr),e(qn,NLe),e(NLe,CUr),e(qn,wUr),e(qn,qLe),e(qLe,AUr),e(qn,LUr),e(Vr,yUr),e(Vr,ye),e(ye,Lw),e(Lw,jLe),e(jLe,xUr),e(Lw,$Ur),e(Lw,nae),e(nae,kUr),e(Lw,SUr),e(ye,RUr),e(ye,yw),e(yw,DLe),e(DLe,PUr),e(yw,BUr),e(yw,sae),e(sae,IUr),e(yw,NUr),e(ye,qUr),e(ye,xw),e(xw,GLe),e(GLe,jUr),e(xw,DUr),e(xw,lae),e(lae,GUr),e(xw,OUr),e(ye,VUr),e(ye,Rl),e(Rl,OLe),e(OLe,XUr),e(Rl,zUr),e(Rl,iae),e(iae,QUr),e(Rl,WUr),e(Rl,dae),e(dae,UUr),e(Rl,HUr),e(ye,JUr),e(ye,$w),e($w,VLe),e(VLe,YUr),e($w,ZUr),e($w,mae),e(mae,KUr),e($w,eHr),e(ye,oHr),e(ye,kw),e(kw,XLe),e(XLe,rHr),e(kw,tHr),e(kw,cae),e(cae,aHr),e(kw,nHr),e(ye,sHr),e(ye,Sw),e(Sw,zLe),e(zLe,lHr),e(Sw,iHr),e(Sw,fae),e(fae,dHr),e(Sw,mHr),e(ye,cHr),e(ye,Rw),e(Rw,QLe),e(QLe,fHr),e(Rw,gHr),e(Rw,gae),e(gae,hHr),e(Rw,uHr),e(ye,pHr),e(ye,Pw),e(Pw,WLe),e(WLe,_Hr),e(Pw,bHr),e(Pw,hae),e(hae,vHr),e(Pw,FHr),e(ye,THr),e(ye,Bw),e(Bw,ULe),e(ULe,MHr),e(Bw,EHr),e(Bw,uae),e(uae,CHr),e(Bw,wHr),e(Vr,AHr),M(Iw,Vr,null),b(c,Uao,_),b(c,Mc,_),e(Mc,Nw),e(Nw,HLe),M(PR,HLe,null),e(Mc,LHr),e(Mc,JLe),e(JLe,yHr),b(c,Hao,_),b(c,hr,_),M(BR,hr,null),e(hr,xHr),e(hr,Ec),e(Ec,$Hr),e(Ec,pae),e(pae,kHr),e(Ec,SHr),e(Ec,_ae),e(_ae,RHr),e(Ec,PHr),e(hr,BHr),e(hr,IR),e(IR,IHr),e(IR,YLe),e(YLe,NHr),e(IR,qHr),e(hr,jHr),e(hr,oa),M(NR,oa,null),e(oa,DHr),e(oa,ZLe),e(ZLe,GHr),e(oa,OHr),e(oa,Cc),e(Cc,VHr),e(Cc,KLe),e(KLe,XHr),e(Cc,zHr),e(Cc,bae),e(bae,QHr),e(Cc,WHr),e(oa,UHr),M(qw,oa,null),e(hr,HHr),e(hr,Xr),M(qR,Xr,null),e(Xr,JHr),e(Xr,eye),e(eye,YHr),e(Xr,ZHr),e(Xr,jn),e(jn,KHr),e(jn,oye),e(oye,eJr),e(jn,oJr),e(jn,rye),e(rye,rJr),e(jn,tJr),e(jn,tye),e(tye,aJr),e(jn,nJr),e(Xr,sJr),e(Xr,wc),e(wc,jw),e(jw,aye),e(aye,lJr),e(jw,iJr),e(jw,vae),e(vae,dJr),e(jw,mJr),e(wc,cJr),e(wc,Dw),e(Dw,nye),e(nye,fJr),e(Dw,gJr),e(Dw,Fae),e(Fae,hJr),e(Dw,uJr),e(wc,pJr),e(wc,Gw),e(Gw,sye),e(sye,_Jr),e(Gw,bJr),e(Gw,Tae),e(Tae,vJr),e(Gw,FJr),e(Xr,TJr),M(Ow,Xr,null),b(c,Jao,_),b(c,Ac,_),e(Ac,Vw),e(Vw,lye),M(jR,lye,null),e(Ac,MJr),e(Ac,iye),e(iye,EJr),b(c,Yao,_),b(c,ur,_),M(DR,ur,null),e(ur,CJr),e(ur,Lc),e(Lc,wJr),e(Lc,Mae),e(Mae,AJr),e(Lc,LJr),e(Lc,Eae),e(Eae,yJr),e(Lc,xJr),e(ur,$Jr),e(ur,GR),e(GR,kJr),e(GR,dye),e(dye,SJr),e(GR,RJr),e(ur,PJr),e(ur,ra),M(OR,ra,null),e(ra,BJr),e(ra,mye),e(mye,IJr),e(ra,NJr),e(ra,yc),e(yc,qJr),e(yc,cye),e(cye,jJr),e(yc,DJr),e(yc,Cae),e(Cae,GJr),e(yc,OJr),e(ra,VJr),M(Xw,ra,null),e(ur,XJr),e(ur,zr),M(VR,zr,null),e(zr,zJr),e(zr,fye),e(fye,QJr),e(zr,WJr),e(zr,Dn),e(Dn,UJr),e(Dn,gye),e(gye,HJr),e(Dn,JJr),e(Dn,hye),e(hye,YJr),e(Dn,ZJr),e(Dn,uye),e(uye,KJr),e(Dn,eYr),e(zr,oYr),e(zr,me),e(me,zw),e(zw,pye),e(pye,rYr),e(zw,tYr),e(zw,wae),e(wae,aYr),e(zw,nYr),e(me,sYr),e(me,Qw),e(Qw,_ye),e(_ye,lYr),e(Qw,iYr),e(Qw,Aae),e(Aae,dYr),e(Qw,mYr),e(me,cYr),e(me,Ww),e(Ww,bye),e(bye,fYr),e(Ww,gYr),e(Ww,Lae),e(Lae,hYr),e(Ww,uYr),e(me,pYr),e(me,Uw),e(Uw,vye),e(vye,_Yr),e(Uw,bYr),e(Uw,yae),e(yae,vYr),e(Uw,FYr),e(me,TYr),e(me,Hw),e(Hw,Fye),e(Fye,MYr),e(Hw,EYr),e(Hw,xae),e(xae,CYr),e(Hw,wYr),e(me,AYr),e(me,Jw),e(Jw,Tye),e(Tye,LYr),e(Jw,yYr),e(Jw,$ae),e($ae,xYr),e(Jw,$Yr),e(me,kYr),e(me,Yw),e(Yw,Mye),e(Mye,SYr),e(Yw,RYr),e(Yw,kae),e(kae,PYr),e(Yw,BYr),e(me,IYr),e(me,Zw),e(Zw,Eye),e(Eye,NYr),e(Zw,qYr),e(Zw,Sae),e(Sae,jYr),e(Zw,DYr),e(me,GYr),e(me,Kw),e(Kw,Cye),e(Cye,OYr),e(Kw,VYr),e(Kw,Rae),e(Rae,XYr),e(Kw,zYr),e(me,QYr),e(me,eA),e(eA,wye),e(wye,WYr),e(eA,UYr),e(eA,Pae),e(Pae,HYr),e(eA,JYr),e(me,YYr),e(me,oA),e(oA,Aye),e(Aye,ZYr),e(oA,KYr),e(oA,Bae),e(Bae,eZr),e(oA,oZr),e(me,rZr),e(me,rA),e(rA,Lye),e(Lye,tZr),e(rA,aZr),e(rA,Iae),e(Iae,nZr),e(rA,sZr),e(me,lZr),e(me,tA),e(tA,yye),e(yye,iZr),e(tA,dZr),e(tA,Nae),e(Nae,mZr),e(tA,cZr),e(me,fZr),e(me,aA),e(aA,xye),e(xye,gZr),e(aA,hZr),e(aA,qae),e(qae,uZr),e(aA,pZr),e(me,_Zr),e(me,nA),e(nA,$ye),e($ye,bZr),e(nA,vZr),e(nA,jae),e(jae,FZr),e(nA,TZr),e(me,MZr),e(me,sA),e(sA,kye),e(kye,EZr),e(sA,CZr),e(sA,Dae),e(Dae,wZr),e(sA,AZr),e(me,LZr),e(me,lA),e(lA,Sye),e(Sye,yZr),e(lA,xZr),e(lA,Gae),e(Gae,$Zr),e(lA,kZr),e(me,SZr),e(me,iA),e(iA,Rye),e(Rye,RZr),e(iA,PZr),e(iA,Oae),e(Oae,BZr),e(iA,IZr),e(me,NZr),e(me,dA),e(dA,Pye),e(Pye,qZr),e(dA,jZr),e(dA,Vae),e(Vae,DZr),e(dA,GZr),e(me,OZr),e(me,mA),e(mA,Bye),e(Bye,VZr),e(mA,XZr),e(mA,Xae),e(Xae,zZr),e(mA,QZr),e(me,WZr),e(me,cA),e(cA,Iye),e(Iye,UZr),e(cA,HZr),e(cA,zae),e(zae,JZr),e(cA,YZr),e(zr,ZZr),M(fA,zr,null),b(c,Zao,_),b(c,xc,_),e(xc,gA),e(gA,Nye),M(XR,Nye,null),e(xc,KZr),e(xc,qye),e(qye,eKr),b(c,Kao,_),b(c,pr,_),M(zR,pr,null),e(pr,oKr),e(pr,$c),e($c,rKr),e($c,Qae),e(Qae,tKr),e($c,aKr),e($c,Wae),e(Wae,nKr),e($c,sKr),e(pr,lKr),e(pr,QR),e(QR,iKr),e(QR,jye),e(jye,dKr),e(QR,mKr),e(pr,cKr),e(pr,ta),M(WR,ta,null),e(ta,fKr),e(ta,Dye),e(Dye,gKr),e(ta,hKr),e(ta,kc),e(kc,uKr),e(kc,Gye),e(Gye,pKr),e(kc,_Kr),e(kc,Uae),e(Uae,bKr),e(kc,vKr),e(ta,FKr),M(hA,ta,null),e(pr,TKr),e(pr,Qr),M(UR,Qr,null),e(Qr,MKr),e(Qr,Oye),e(Oye,EKr),e(Qr,CKr),e(Qr,Gn),e(Gn,wKr),e(Gn,Vye),e(Vye,AKr),e(Gn,LKr),e(Gn,Xye),e(Xye,yKr),e(Gn,xKr),e(Gn,zye),e(zye,$Kr),e(Gn,kKr),e(Qr,SKr),e(Qr,xe),e(xe,uA),e(uA,Qye),e(Qye,RKr),e(uA,PKr),e(uA,Hae),e(Hae,BKr),e(uA,IKr),e(xe,NKr),e(xe,pA),e(pA,Wye),e(Wye,qKr),e(pA,jKr),e(pA,Jae),e(Jae,DKr),e(pA,GKr),e(xe,OKr),e(xe,_A),e(_A,Uye),e(Uye,VKr),e(_A,XKr),e(_A,Yae),e(Yae,zKr),e(_A,QKr),e(xe,WKr),e(xe,bA),e(bA,Hye),e(Hye,UKr),e(bA,HKr),e(bA,Zae),e(Zae,JKr),e(bA,YKr),e(xe,ZKr),e(xe,vA),e(vA,Jye),e(Jye,KKr),e(vA,eet),e(vA,Kae),e(Kae,oet),e(vA,ret),e(xe,tet),e(xe,FA),e(FA,Yye),e(Yye,aet),e(FA,net),e(FA,ene),e(ene,set),e(FA,iet),e(xe,det),e(xe,TA),e(TA,Zye),e(Zye,met),e(TA,cet),e(TA,one),e(one,fet),e(TA,get),e(xe,het),e(xe,MA),e(MA,Kye),e(Kye,uet),e(MA,pet),e(MA,rne),e(rne,_et),e(MA,bet),e(xe,vet),e(xe,EA),e(EA,e9e),e(e9e,Fet),e(EA,Tet),e(EA,tne),e(tne,Met),e(EA,Eet),e(xe,Cet),e(xe,CA),e(CA,o9e),e(o9e,wet),e(CA,Aet),e(CA,ane),e(ane,Let),e(CA,yet),e(Qr,xet),M(wA,Qr,null),b(c,eno,_),b(c,Sc,_),e(Sc,AA),e(AA,r9e),M(HR,r9e,null),e(Sc,$et),e(Sc,t9e),e(t9e,ket),b(c,ono,_),b(c,_r,_),M(JR,_r,null),e(_r,Set),e(_r,Rc),e(Rc,Ret),e(Rc,nne),e(nne,Pet),e(Rc,Bet),e(Rc,sne),e(sne,Iet),e(Rc,Net),e(_r,qet),e(_r,YR),e(YR,jet),e(YR,a9e),e(a9e,Det),e(YR,Get),e(_r,Oet),e(_r,aa),M(ZR,aa,null),e(aa,Vet),e(aa,n9e),e(n9e,Xet),e(aa,zet),e(aa,Pc),e(Pc,Qet),e(Pc,s9e),e(s9e,Wet),e(Pc,Uet),e(Pc,lne),e(lne,Het),e(Pc,Jet),e(aa,Yet),M(LA,aa,null),e(_r,Zet),e(_r,Wr),M(KR,Wr,null),e(Wr,Ket),e(Wr,l9e),e(l9e,eot),e(Wr,oot),e(Wr,On),e(On,rot),e(On,i9e),e(i9e,tot),e(On,aot),e(On,d9e),e(d9e,not),e(On,sot),e(On,m9e),e(m9e,lot),e(On,iot),e(Wr,dot),e(Wr,re),e(re,yA),e(yA,c9e),e(c9e,mot),e(yA,cot),e(yA,ine),e(ine,fot),e(yA,got),e(re,hot),e(re,xA),e(xA,f9e),e(f9e,uot),e(xA,pot),e(xA,dne),e(dne,_ot),e(xA,bot),e(re,vot),e(re,$A),e($A,g9e),e(g9e,Fot),e($A,Tot),e($A,mne),e(mne,Mot),e($A,Eot),e(re,Cot),e(re,kA),e(kA,h9e),e(h9e,wot),e(kA,Aot),e(kA,cne),e(cne,Lot),e(kA,yot),e(re,xot),e(re,SA),e(SA,u9e),e(u9e,$ot),e(SA,kot),e(SA,fne),e(fne,Sot),e(SA,Rot),e(re,Pot),e(re,RA),e(RA,p9e),e(p9e,Bot),e(RA,Iot),e(RA,gne),e(gne,Not),e(RA,qot),e(re,jot),e(re,PA),e(PA,_9e),e(_9e,Dot),e(PA,Got),e(PA,hne),e(hne,Oot),e(PA,Vot),e(re,Xot),e(re,BA),e(BA,b9e),e(b9e,zot),e(BA,Qot),e(BA,une),e(une,Wot),e(BA,Uot),e(re,Hot),e(re,IA),e(IA,v9e),e(v9e,Jot),e(IA,Yot),e(IA,pne),e(pne,Zot),e(IA,Kot),e(re,ert),e(re,NA),e(NA,F9e),e(F9e,ort),e(NA,rrt),e(NA,_ne),e(_ne,trt),e(NA,art),e(re,nrt),e(re,qA),e(qA,T9e),e(T9e,srt),e(qA,lrt),e(qA,bne),e(bne,irt),e(qA,drt),e(re,mrt),e(re,jA),e(jA,M9e),e(M9e,crt),e(jA,frt),e(jA,vne),e(vne,grt),e(jA,hrt),e(re,urt),e(re,DA),e(DA,E9e),e(E9e,prt),e(DA,_rt),e(DA,Fne),e(Fne,brt),e(DA,vrt),e(re,Frt),e(re,GA),e(GA,C9e),e(C9e,Trt),e(GA,Mrt),e(GA,Tne),e(Tne,Ert),e(GA,Crt),e(re,wrt),e(re,OA),e(OA,w9e),e(w9e,Art),e(OA,Lrt),e(OA,Mne),e(Mne,yrt),e(OA,xrt),e(re,$rt),e(re,VA),e(VA,A9e),e(A9e,krt),e(VA,Srt),e(VA,Ene),e(Ene,Rrt),e(VA,Prt),e(re,Brt),e(re,XA),e(XA,L9e),e(L9e,Irt),e(XA,Nrt),e(XA,Cne),e(Cne,qrt),e(XA,jrt),e(re,Drt),e(re,zA),e(zA,y9e),e(y9e,Grt),e(zA,Ort),e(zA,wne),e(wne,Vrt),e(zA,Xrt),e(re,zrt),e(re,QA),e(QA,x9e),e(x9e,Qrt),e(QA,Wrt),e(QA,Ane),e(Ane,Urt),e(QA,Hrt),e(re,Jrt),e(re,WA),e(WA,$9e),e($9e,Yrt),e(WA,Zrt),e(WA,Lne),e(Lne,Krt),e(WA,ett),e(re,ott),e(re,UA),e(UA,k9e),e(k9e,rtt),e(UA,ttt),e(UA,yne),e(yne,att),e(UA,ntt),e(re,stt),e(re,HA),e(HA,S9e),e(S9e,ltt),e(HA,itt),e(HA,xne),e(xne,dtt),e(HA,mtt),e(re,ctt),e(re,JA),e(JA,R9e),e(R9e,ftt),e(JA,gtt),e(JA,$ne),e($ne,htt),e(JA,utt),e(re,ptt),e(re,YA),e(YA,P9e),e(P9e,_tt),e(YA,btt),e(YA,kne),e(kne,vtt),e(YA,Ftt),e(re,Ttt),e(re,ZA),e(ZA,B9e),e(B9e,Mtt),e(ZA,Ett),e(ZA,Sne),e(Sne,Ctt),e(ZA,wtt),e(re,Att),e(re,KA),e(KA,I9e),e(I9e,Ltt),e(KA,ytt),e(KA,Rne),e(Rne,xtt),e(KA,$tt),e(re,ktt),e(re,e6),e(e6,N9e),e(N9e,Stt),e(e6,Rtt),e(e6,Pne),e(Pne,Ptt),e(e6,Btt),e(re,Itt),e(re,o6),e(o6,q9e),e(q9e,Ntt),e(o6,qtt),e(o6,Bne),e(Bne,jtt),e(o6,Dtt),e(Wr,Gtt),M(r6,Wr,null),b(c,rno,_),b(c,Bc,_),e(Bc,t6),e(t6,j9e),M(eP,j9e,null),e(Bc,Ott),e(Bc,D9e),e(D9e,Vtt),b(c,tno,_),b(c,br,_),M(oP,br,null),e(br,Xtt),e(br,Ic),e(Ic,ztt),e(Ic,Ine),e(Ine,Qtt),e(Ic,Wtt),e(Ic,Nne),e(Nne,Utt),e(Ic,Htt),e(br,Jtt),e(br,rP),e(rP,Ytt),e(rP,G9e),e(G9e,Ztt),e(rP,Ktt),e(br,eat),e(br,na),M(tP,na,null),e(na,oat),e(na,O9e),e(O9e,rat),e(na,tat),e(na,Nc),e(Nc,aat),e(Nc,V9e),e(V9e,nat),e(Nc,sat),e(Nc,qne),e(qne,lat),e(Nc,iat),e(na,dat),M(a6,na,null),e(br,mat),e(br,Ur),M(aP,Ur,null),e(Ur,cat),e(Ur,X9e),e(X9e,fat),e(Ur,gat),e(Ur,Vn),e(Vn,hat),e(Vn,z9e),e(z9e,uat),e(Vn,pat),e(Vn,Q9e),e(Q9e,_at),e(Vn,bat),e(Vn,W9e),e(W9e,vat),e(Vn,Fat),e(Ur,Tat),e(Ur,ve),e(ve,n6),e(n6,U9e),e(U9e,Mat),e(n6,Eat),e(n6,jne),e(jne,Cat),e(n6,wat),e(ve,Aat),e(ve,s6),e(s6,H9e),e(H9e,Lat),e(s6,yat),e(s6,Dne),e(Dne,xat),e(s6,$at),e(ve,kat),e(ve,l6),e(l6,J9e),e(J9e,Sat),e(l6,Rat),e(l6,Gne),e(Gne,Pat),e(l6,Bat),e(ve,Iat),e(ve,i6),e(i6,Y9e),e(Y9e,Nat),e(i6,qat),e(i6,One),e(One,jat),e(i6,Dat),e(ve,Gat),e(ve,d6),e(d6,Z9e),e(Z9e,Oat),e(d6,Vat),e(d6,Vne),e(Vne,Xat),e(d6,zat),e(ve,Qat),e(ve,m6),e(m6,K9e),e(K9e,Wat),e(m6,Uat),e(m6,Xne),e(Xne,Hat),e(m6,Jat),e(ve,Yat),e(ve,c6),e(c6,exe),e(exe,Zat),e(c6,Kat),e(c6,zne),e(zne,ent),e(c6,ont),e(ve,rnt),e(ve,f6),e(f6,oxe),e(oxe,tnt),e(f6,ant),e(f6,Qne),e(Qne,nnt),e(f6,snt),e(ve,lnt),e(ve,g6),e(g6,rxe),e(rxe,int),e(g6,dnt),e(g6,Wne),e(Wne,mnt),e(g6,cnt),e(ve,fnt),e(ve,h6),e(h6,txe),e(txe,gnt),e(h6,hnt),e(h6,Une),e(Une,unt),e(h6,pnt),e(ve,_nt),e(ve,u6),e(u6,axe),e(axe,bnt),e(u6,vnt),e(u6,Hne),e(Hne,Fnt),e(u6,Tnt),e(ve,Mnt),e(ve,p6),e(p6,nxe),e(nxe,Ent),e(p6,Cnt),e(p6,Jne),e(Jne,wnt),e(p6,Ant),e(ve,Lnt),e(ve,_6),e(_6,sxe),e(sxe,ynt),e(_6,xnt),e(_6,Yne),e(Yne,$nt),e(_6,knt),e(ve,Snt),e(ve,b6),e(b6,lxe),e(lxe,Rnt),e(b6,Pnt),e(b6,Zne),e(Zne,Bnt),e(b6,Int),e(ve,Nnt),e(ve,v6),e(v6,ixe),e(ixe,qnt),e(v6,jnt),e(v6,Kne),e(Kne,Dnt),e(v6,Gnt),e(ve,Ont),e(ve,F6),e(F6,dxe),e(dxe,Vnt),e(F6,Xnt),e(F6,ese),e(ese,znt),e(F6,Qnt),e(ve,Wnt),e(ve,T6),e(T6,mxe),e(mxe,Unt),e(T6,Hnt),e(T6,ose),e(ose,Jnt),e(T6,Ynt),e(Ur,Znt),M(M6,Ur,null),b(c,ano,_),b(c,qc,_),e(qc,E6),e(E6,cxe),M(nP,cxe,null),e(qc,Knt),e(qc,fxe),e(fxe,est),b(c,nno,_),b(c,vr,_),M(sP,vr,null),e(vr,ost),e(vr,jc),e(jc,rst),e(jc,rse),e(rse,tst),e(jc,ast),e(jc,tse),e(tse,nst),e(jc,sst),e(vr,lst),e(vr,lP),e(lP,ist),e(lP,gxe),e(gxe,dst),e(lP,mst),e(vr,cst),e(vr,sa),M(iP,sa,null),e(sa,fst),e(sa,hxe),e(hxe,gst),e(sa,hst),e(sa,Dc),e(Dc,ust),e(Dc,uxe),e(uxe,pst),e(Dc,_st),e(Dc,ase),e(ase,bst),e(Dc,vst),e(sa,Fst),M(C6,sa,null),e(vr,Tst),e(vr,Hr),M(dP,Hr,null),e(Hr,Mst),e(Hr,pxe),e(pxe,Est),e(Hr,Cst),e(Hr,Xn),e(Xn,wst),e(Xn,_xe),e(_xe,Ast),e(Xn,Lst),e(Xn,bxe),e(bxe,yst),e(Xn,xst),e(Xn,vxe),e(vxe,$st),e(Xn,kst),e(Hr,Sst),e(Hr,mP),e(mP,w6),e(w6,Fxe),e(Fxe,Rst),e(w6,Pst),e(w6,nse),e(nse,Bst),e(w6,Ist),e(mP,Nst),e(mP,A6),e(A6,Txe),e(Txe,qst),e(A6,jst),e(A6,sse),e(sse,Dst),e(A6,Gst),e(Hr,Ost),M(L6,Hr,null),b(c,sno,_),b(c,Gc,_),e(Gc,y6),e(y6,Mxe),M(cP,Mxe,null),e(Gc,Vst),e(Gc,Exe),e(Exe,Xst),b(c,lno,_),b(c,Fr,_),M(fP,Fr,null),e(Fr,zst),e(Fr,Oc),e(Oc,Qst),e(Oc,lse),e(lse,Wst),e(Oc,Ust),e(Oc,ise),e(ise,Hst),e(Oc,Jst),e(Fr,Yst),e(Fr,gP),e(gP,Zst),e(gP,Cxe),e(Cxe,Kst),e(gP,elt),e(Fr,olt),e(Fr,la),M(hP,la,null),e(la,rlt),e(la,wxe),e(wxe,tlt),e(la,alt),e(la,Vc),e(Vc,nlt),e(Vc,Axe),e(Axe,slt),e(Vc,llt),e(Vc,dse),e(dse,ilt),e(Vc,dlt),e(la,mlt),M(x6,la,null),e(Fr,clt),e(Fr,Jr),M(uP,Jr,null),e(Jr,flt),e(Jr,Lxe),e(Lxe,glt),e(Jr,hlt),e(Jr,zn),e(zn,ult),e(zn,yxe),e(yxe,plt),e(zn,_lt),e(zn,xxe),e(xxe,blt),e(zn,vlt),e(zn,$xe),e($xe,Flt),e(zn,Tlt),e(Jr,Mlt),e(Jr,kxe),e(kxe,$6),e($6,Sxe),e(Sxe,Elt),e($6,Clt),e($6,mse),e(mse,wlt),e($6,Alt),e(Jr,Llt),M(k6,Jr,null),b(c,ino,_),b(c,Xc,_),e(Xc,S6),e(S6,Rxe),M(pP,Rxe,null),e(Xc,ylt),e(Xc,Pxe),e(Pxe,xlt),b(c,dno,_),b(c,Tr,_),M(_P,Tr,null),e(Tr,$lt),e(Tr,zc),e(zc,klt),e(zc,cse),e(cse,Slt),e(zc,Rlt),e(zc,fse),e(fse,Plt),e(zc,Blt),e(Tr,Ilt),e(Tr,bP),e(bP,Nlt),e(bP,Bxe),e(Bxe,qlt),e(bP,jlt),e(Tr,Dlt),e(Tr,ia),M(vP,ia,null),e(ia,Glt),e(ia,Ixe),e(Ixe,Olt),e(ia,Vlt),e(ia,Qc),e(Qc,Xlt),e(Qc,Nxe),e(Nxe,zlt),e(Qc,Qlt),e(Qc,gse),e(gse,Wlt),e(Qc,Ult),e(ia,Hlt),M(R6,ia,null),e(Tr,Jlt),e(Tr,Yr),M(FP,Yr,null),e(Yr,Ylt),e(Yr,qxe),e(qxe,Zlt),e(Yr,Klt),e(Yr,Qn),e(Qn,eit),e(Qn,jxe),e(jxe,oit),e(Qn,rit),e(Qn,Dxe),e(Dxe,tit),e(Qn,ait),e(Qn,Gxe),e(Gxe,nit),e(Qn,sit),e(Yr,lit),e(Yr,Oxe),e(Oxe,P6),e(P6,Vxe),e(Vxe,iit),e(P6,dit),e(P6,hse),e(hse,mit),e(P6,cit),e(Yr,fit),M(B6,Yr,null),b(c,mno,_),b(c,Wc,_),e(Wc,I6),e(I6,Xxe),M(TP,Xxe,null),e(Wc,git),e(Wc,zxe),e(zxe,hit),b(c,cno,_),b(c,Mr,_),M(MP,Mr,null),e(Mr,uit),e(Mr,Uc),e(Uc,pit),e(Uc,use),e(use,_it),e(Uc,bit),e(Uc,pse),e(pse,vit),e(Uc,Fit),e(Mr,Tit),e(Mr,EP),e(EP,Mit),e(EP,Qxe),e(Qxe,Eit),e(EP,Cit),e(Mr,wit),e(Mr,da),M(CP,da,null),e(da,Ait),e(da,Wxe),e(Wxe,Lit),e(da,yit),e(da,Hc),e(Hc,xit),e(Hc,Uxe),e(Uxe,$it),e(Hc,kit),e(Hc,_se),e(_se,Sit),e(Hc,Rit),e(da,Pit),M(N6,da,null),e(Mr,Bit),e(Mr,Zr),M(wP,Zr,null),e(Zr,Iit),e(Zr,Hxe),e(Hxe,Nit),e(Zr,qit),e(Zr,Wn),e(Wn,jit),e(Wn,Jxe),e(Jxe,Dit),e(Wn,Git),e(Wn,Yxe),e(Yxe,Oit),e(Wn,Vit),e(Wn,Zxe),e(Zxe,Xit),e(Wn,zit),e(Zr,Qit),e(Zr,ie),e(ie,q6),e(q6,Kxe),e(Kxe,Wit),e(q6,Uit),e(q6,bse),e(bse,Hit),e(q6,Jit),e(ie,Yit),e(ie,j6),e(j6,e$e),e(e$e,Zit),e(j6,Kit),e(j6,vse),e(vse,edt),e(j6,odt),e(ie,rdt),e(ie,D6),e(D6,o$e),e(o$e,tdt),e(D6,adt),e(D6,Fse),e(Fse,ndt),e(D6,sdt),e(ie,ldt),e(ie,G6),e(G6,r$e),e(r$e,idt),e(G6,ddt),e(G6,Tse),e(Tse,mdt),e(G6,cdt),e(ie,fdt),e(ie,O6),e(O6,t$e),e(t$e,gdt),e(O6,hdt),e(O6,Mse),e(Mse,udt),e(O6,pdt),e(ie,_dt),e(ie,V6),e(V6,a$e),e(a$e,bdt),e(V6,vdt),e(V6,Ese),e(Ese,Fdt),e(V6,Tdt),e(ie,Mdt),e(ie,X6),e(X6,n$e),e(n$e,Edt),e(X6,Cdt),e(X6,Cse),e(Cse,wdt),e(X6,Adt),e(ie,Ldt),e(ie,z6),e(z6,s$e),e(s$e,ydt),e(z6,xdt),e(z6,wse),e(wse,$dt),e(z6,kdt),e(ie,Sdt),e(ie,Q6),e(Q6,l$e),e(l$e,Rdt),e(Q6,Pdt),e(Q6,Ase),e(Ase,Bdt),e(Q6,Idt),e(ie,Ndt),e(ie,W6),e(W6,i$e),e(i$e,qdt),e(W6,jdt),e(W6,Lse),e(Lse,Ddt),e(W6,Gdt),e(ie,Odt),e(ie,U6),e(U6,d$e),e(d$e,Vdt),e(U6,Xdt),e(U6,yse),e(yse,zdt),e(U6,Qdt),e(ie,Wdt),e(ie,H6),e(H6,m$e),e(m$e,Udt),e(H6,Hdt),e(H6,xse),e(xse,Jdt),e(H6,Ydt),e(ie,Zdt),e(ie,J6),e(J6,c$e),e(c$e,Kdt),e(J6,emt),e(J6,$se),e($se,omt),e(J6,rmt),e(ie,tmt),e(ie,Y6),e(Y6,f$e),e(f$e,amt),e(Y6,nmt),e(Y6,kse),e(kse,smt),e(Y6,lmt),e(ie,imt),e(ie,Z6),e(Z6,g$e),e(g$e,dmt),e(Z6,mmt),e(Z6,Sse),e(Sse,cmt),e(Z6,fmt),e(ie,gmt),e(ie,K6),e(K6,h$e),e(h$e,hmt),e(K6,umt),e(K6,Rse),e(Rse,pmt),e(K6,_mt),e(ie,bmt),e(ie,e7),e(e7,u$e),e(u$e,vmt),e(e7,Fmt),e(e7,Pse),e(Pse,Tmt),e(e7,Mmt),e(ie,Emt),e(ie,o7),e(o7,p$e),e(p$e,Cmt),e(o7,wmt),e(o7,Bse),e(Bse,Amt),e(o7,Lmt),e(ie,ymt),e(ie,r7),e(r7,_$e),e(_$e,xmt),e(r7,$mt),e(r7,Ise),e(Ise,kmt),e(r7,Smt),e(ie,Rmt),e(ie,t7),e(t7,b$e),e(b$e,Pmt),e(t7,Bmt),e(t7,Nse),e(Nse,Imt),e(t7,Nmt),e(ie,qmt),e(ie,a7),e(a7,v$e),e(v$e,jmt),e(a7,Dmt),e(a7,qse),e(qse,Gmt),e(a7,Omt),e(ie,Vmt),e(ie,n7),e(n7,F$e),e(F$e,Xmt),e(n7,zmt),e(n7,jse),e(jse,Qmt),e(n7,Wmt),e(Zr,Umt),M(s7,Zr,null),b(c,fno,_),b(c,Jc,_),e(Jc,l7),e(l7,T$e),M(AP,T$e,null),e(Jc,Hmt),e(Jc,M$e),e(M$e,Jmt),b(c,gno,_),b(c,Er,_),M(LP,Er,null),e(Er,Ymt),e(Er,Yc),e(Yc,Zmt),e(Yc,Dse),e(Dse,Kmt),e(Yc,ect),e(Yc,Gse),e(Gse,oct),e(Yc,rct),e(Er,tct),e(Er,yP),e(yP,act),e(yP,E$e),e(E$e,nct),e(yP,sct),e(Er,lct),e(Er,ma),M(xP,ma,null),e(ma,ict),e(ma,C$e),e(C$e,dct),e(ma,mct),e(ma,Zc),e(Zc,cct),e(Zc,w$e),e(w$e,fct),e(Zc,gct),e(Zc,Ose),e(Ose,hct),e(Zc,uct),e(ma,pct),M(i7,ma,null),e(Er,_ct),e(Er,Kr),M($P,Kr,null),e(Kr,bct),e(Kr,A$e),e(A$e,vct),e(Kr,Fct),e(Kr,Un),e(Un,Tct),e(Un,L$e),e(L$e,Mct),e(Un,Ect),e(Un,y$e),e(y$e,Cct),e(Un,wct),e(Un,x$e),e(x$e,Act),e(Un,Lct),e(Kr,yct),e(Kr,ce),e(ce,d7),e(d7,$$e),e($$e,xct),e(d7,$ct),e(d7,Vse),e(Vse,kct),e(d7,Sct),e(ce,Rct),e(ce,m7),e(m7,k$e),e(k$e,Pct),e(m7,Bct),e(m7,Xse),e(Xse,Ict),e(m7,Nct),e(ce,qct),e(ce,c7),e(c7,S$e),e(S$e,jct),e(c7,Dct),e(c7,zse),e(zse,Gct),e(c7,Oct),e(ce,Vct),e(ce,f7),e(f7,R$e),e(R$e,Xct),e(f7,zct),e(f7,Qse),e(Qse,Qct),e(f7,Wct),e(ce,Uct),e(ce,g7),e(g7,P$e),e(P$e,Hct),e(g7,Jct),e(g7,Wse),e(Wse,Yct),e(g7,Zct),e(ce,Kct),e(ce,h7),e(h7,B$e),e(B$e,eft),e(h7,oft),e(h7,Use),e(Use,rft),e(h7,tft),e(ce,aft),e(ce,u7),e(u7,I$e),e(I$e,nft),e(u7,sft),e(u7,Hse),e(Hse,lft),e(u7,ift),e(ce,dft),e(ce,p7),e(p7,N$e),e(N$e,mft),e(p7,cft),e(p7,Jse),e(Jse,fft),e(p7,gft),e(ce,hft),e(ce,_7),e(_7,q$e),e(q$e,uft),e(_7,pft),e(_7,Yse),e(Yse,_ft),e(_7,bft),e(ce,vft),e(ce,b7),e(b7,j$e),e(j$e,Fft),e(b7,Tft),e(b7,Zse),e(Zse,Mft),e(b7,Eft),e(ce,Cft),e(ce,v7),e(v7,D$e),e(D$e,wft),e(v7,Aft),e(v7,Kse),e(Kse,Lft),e(v7,yft),e(ce,xft),e(ce,F7),e(F7,G$e),e(G$e,$ft),e(F7,kft),e(F7,ele),e(ele,Sft),e(F7,Rft),e(ce,Pft),e(ce,T7),e(T7,O$e),e(O$e,Bft),e(T7,Ift),e(T7,ole),e(ole,Nft),e(T7,qft),e(ce,jft),e(ce,M7),e(M7,V$e),e(V$e,Dft),e(M7,Gft),e(M7,rle),e(rle,Oft),e(M7,Vft),e(ce,Xft),e(ce,E7),e(E7,X$e),e(X$e,zft),e(E7,Qft),e(E7,tle),e(tle,Wft),e(E7,Uft),e(ce,Hft),e(ce,C7),e(C7,z$e),e(z$e,Jft),e(C7,Yft),e(C7,ale),e(ale,Zft),e(C7,Kft),e(ce,egt),e(ce,w7),e(w7,Q$e),e(Q$e,ogt),e(w7,rgt),e(w7,nle),e(nle,tgt),e(w7,agt),e(ce,ngt),e(ce,A7),e(A7,W$e),e(W$e,sgt),e(A7,lgt),e(A7,sle),e(sle,igt),e(A7,dgt),e(ce,mgt),e(ce,L7),e(L7,U$e),e(U$e,cgt),e(L7,fgt),e(L7,lle),e(lle,ggt),e(L7,hgt),e(ce,ugt),e(ce,y7),e(y7,H$e),e(H$e,pgt),e(y7,_gt),e(y7,ile),e(ile,bgt),e(y7,vgt),e(ce,Fgt),e(ce,x7),e(x7,J$e),e(J$e,Tgt),e(x7,Mgt),e(x7,dle),e(dle,Egt),e(x7,Cgt),e(Kr,wgt),M($7,Kr,null),b(c,hno,_),b(c,Kc,_),e(Kc,k7),e(k7,Y$e),M(kP,Y$e,null),e(Kc,Agt),e(Kc,Z$e),e(Z$e,Lgt),b(c,uno,_),b(c,Cr,_),M(SP,Cr,null),e(Cr,ygt),e(Cr,ef),e(ef,xgt),e(ef,mle),e(mle,$gt),e(ef,kgt),e(ef,cle),e(cle,Sgt),e(ef,Rgt),e(Cr,Pgt),e(Cr,RP),e(RP,Bgt),e(RP,K$e),e(K$e,Igt),e(RP,Ngt),e(Cr,qgt),e(Cr,ca),M(PP,ca,null),e(ca,jgt),e(ca,eke),e(eke,Dgt),e(ca,Ggt),e(ca,of),e(of,Ogt),e(of,oke),e(oke,Vgt),e(of,Xgt),e(of,fle),e(fle,zgt),e(of,Qgt),e(ca,Wgt),M(S7,ca,null),e(Cr,Ugt),e(Cr,et),M(BP,et,null),e(et,Hgt),e(et,rke),e(rke,Jgt),e(et,Ygt),e(et,Hn),e(Hn,Zgt),e(Hn,tke),e(tke,Kgt),e(Hn,eht),e(Hn,ake),e(ake,oht),e(Hn,rht),e(Hn,nke),e(nke,tht),e(Hn,aht),e(et,nht),e(et,ske),e(ske,R7),e(R7,lke),e(lke,sht),e(R7,lht),e(R7,gle),e(gle,iht),e(R7,dht),e(et,mht),M(P7,et,null),b(c,pno,_),b(c,rf,_),e(rf,B7),e(B7,ike),M(IP,ike,null),e(rf,cht),e(rf,dke),e(dke,fht),b(c,_no,_),b(c,wr,_),M(NP,wr,null),e(wr,ght),e(wr,tf),e(tf,hht),e(tf,hle),e(hle,uht),e(tf,pht),e(tf,ule),e(ule,_ht),e(tf,bht),e(wr,vht),e(wr,qP),e(qP,Fht),e(qP,mke),e(mke,Tht),e(qP,Mht),e(wr,Eht),e(wr,fa),M(jP,fa,null),e(fa,Cht),e(fa,cke),e(cke,wht),e(fa,Aht),e(fa,af),e(af,Lht),e(af,fke),e(fke,yht),e(af,xht),e(af,ple),e(ple,$ht),e(af,kht),e(fa,Sht),M(I7,fa,null),e(wr,Rht),e(wr,ot),M(DP,ot,null),e(ot,Pht),e(ot,gke),e(gke,Bht),e(ot,Iht),e(ot,Jn),e(Jn,Nht),e(Jn,hke),e(hke,qht),e(Jn,jht),e(Jn,uke),e(uke,Dht),e(Jn,Ght),e(Jn,pke),e(pke,Oht),e(Jn,Vht),e(ot,Xht),e(ot,GP),e(GP,N7),e(N7,_ke),e(_ke,zht),e(N7,Qht),e(N7,_le),e(_le,Wht),e(N7,Uht),e(GP,Hht),e(GP,q7),e(q7,bke),e(bke,Jht),e(q7,Yht),e(q7,ble),e(ble,Zht),e(q7,Kht),e(ot,eut),M(j7,ot,null),b(c,bno,_),b(c,nf,_),e(nf,D7),e(D7,vke),M(OP,vke,null),e(nf,out),e(nf,Fke),e(Fke,rut),b(c,vno,_),b(c,Ar,_),M(VP,Ar,null),e(Ar,tut),e(Ar,sf),e(sf,aut),e(sf,vle),e(vle,nut),e(sf,sut),e(sf,Fle),e(Fle,lut),e(sf,iut),e(Ar,dut),e(Ar,XP),e(XP,mut),e(XP,Tke),e(Tke,cut),e(XP,fut),e(Ar,gut),e(Ar,ga),M(zP,ga,null),e(ga,hut),e(ga,Mke),e(Mke,uut),e(ga,put),e(ga,lf),e(lf,_ut),e(lf,Eke),e(Eke,but),e(lf,vut),e(lf,Tle),e(Tle,Fut),e(lf,Tut),e(ga,Mut),M(G7,ga,null),e(Ar,Eut),e(Ar,rt),M(QP,rt,null),e(rt,Cut),e(rt,Cke),e(Cke,wut),e(rt,Aut),e(rt,Yn),e(Yn,Lut),e(Yn,wke),e(wke,yut),e(Yn,xut),e(Yn,Ake),e(Ake,$ut),e(Yn,kut),e(Yn,Lke),e(Lke,Sut),e(Yn,Rut),e(rt,Put),e(rt,te),e(te,O7),e(O7,yke),e(yke,But),e(O7,Iut),e(O7,Mle),e(Mle,Nut),e(O7,qut),e(te,jut),e(te,V7),e(V7,xke),e(xke,Dut),e(V7,Gut),e(V7,Ele),e(Ele,Out),e(V7,Vut),e(te,Xut),e(te,X7),e(X7,$ke),e($ke,zut),e(X7,Qut),e(X7,Cle),e(Cle,Wut),e(X7,Uut),e(te,Hut),e(te,z7),e(z7,kke),e(kke,Jut),e(z7,Yut),e(z7,wle),e(wle,Zut),e(z7,Kut),e(te,ept),e(te,Q7),e(Q7,Ske),e(Ske,opt),e(Q7,rpt),e(Q7,Ale),e(Ale,tpt),e(Q7,apt),e(te,npt),e(te,W7),e(W7,Rke),e(Rke,spt),e(W7,lpt),e(W7,Lle),e(Lle,ipt),e(W7,dpt),e(te,mpt),e(te,U7),e(U7,Pke),e(Pke,cpt),e(U7,fpt),e(U7,yle),e(yle,gpt),e(U7,hpt),e(te,upt),e(te,H7),e(H7,Bke),e(Bke,ppt),e(H7,_pt),e(H7,xle),e(xle,bpt),e(H7,vpt),e(te,Fpt),e(te,J7),e(J7,Ike),e(Ike,Tpt),e(J7,Mpt),e(J7,$le),e($le,Ept),e(J7,Cpt),e(te,wpt),e(te,Y7),e(Y7,Nke),e(Nke,Apt),e(Y7,Lpt),e(Y7,kle),e(kle,ypt),e(Y7,xpt),e(te,$pt),e(te,Z7),e(Z7,qke),e(qke,kpt),e(Z7,Spt),e(Z7,Sle),e(Sle,Rpt),e(Z7,Ppt),e(te,Bpt),e(te,K7),e(K7,jke),e(jke,Ipt),e(K7,Npt),e(K7,Rle),e(Rle,qpt),e(K7,jpt),e(te,Dpt),e(te,e8),e(e8,Dke),e(Dke,Gpt),e(e8,Opt),e(e8,Ple),e(Ple,Vpt),e(e8,Xpt),e(te,zpt),e(te,o8),e(o8,Gke),e(Gke,Qpt),e(o8,Wpt),e(o8,Ble),e(Ble,Upt),e(o8,Hpt),e(te,Jpt),e(te,r8),e(r8,Oke),e(Oke,Ypt),e(r8,Zpt),e(r8,Ile),e(Ile,Kpt),e(r8,e_t),e(te,o_t),e(te,t8),e(t8,Vke),e(Vke,r_t),e(t8,t_t),e(t8,Nle),e(Nle,a_t),e(t8,n_t),e(te,s_t),e(te,a8),e(a8,Xke),e(Xke,l_t),e(a8,i_t),e(a8,qle),e(qle,d_t),e(a8,m_t),e(te,c_t),e(te,n8),e(n8,zke),e(zke,f_t),e(n8,g_t),e(n8,jle),e(jle,h_t),e(n8,u_t),e(te,p_t),e(te,s8),e(s8,Qke),e(Qke,__t),e(s8,b_t),e(s8,Dle),e(Dle,v_t),e(s8,F_t),e(te,T_t),e(te,l8),e(l8,Wke),e(Wke,M_t),e(l8,E_t),e(l8,Gle),e(Gle,C_t),e(l8,w_t),e(te,A_t),e(te,i8),e(i8,Uke),e(Uke,L_t),e(i8,y_t),e(i8,Ole),e(Ole,x_t),e(i8,$_t),e(te,k_t),e(te,d8),e(d8,Hke),e(Hke,S_t),e(d8,R_t),e(d8,Vle),e(Vle,P_t),e(d8,B_t),e(te,I_t),e(te,m8),e(m8,Jke),e(Jke,N_t),e(m8,q_t),e(m8,Xle),e(Xle,j_t),e(m8,D_t),e(te,G_t),e(te,c8),e(c8,Yke),e(Yke,O_t),e(c8,V_t),e(c8,zle),e(zle,X_t),e(c8,z_t),e(te,Q_t),e(te,f8),e(f8,Zke),e(Zke,W_t),e(f8,U_t),e(f8,Qle),e(Qle,H_t),e(f8,J_t),e(te,Y_t),e(te,g8),e(g8,Kke),e(Kke,Z_t),e(g8,K_t),e(g8,Wle),e(Wle,e1t),e(g8,o1t),e(te,r1t),e(te,h8),e(h8,eSe),e(eSe,t1t),e(h8,a1t),e(h8,Ule),e(Ule,n1t),e(h8,s1t),e(rt,l1t),M(u8,rt,null),b(c,Fno,_),b(c,df,_),e(df,p8),e(p8,oSe),M(WP,oSe,null),e(df,i1t),e(df,rSe),e(rSe,d1t),b(c,Tno,_),b(c,Lr,_),M(UP,Lr,null),e(Lr,m1t),e(Lr,mf),e(mf,c1t),e(mf,Hle),e(Hle,f1t),e(mf,g1t),e(mf,Jle),e(Jle,h1t),e(mf,u1t),e(Lr,p1t),e(Lr,HP),e(HP,_1t),e(HP,tSe),e(tSe,b1t),e(HP,v1t),e(Lr,F1t),e(Lr,ha),M(JP,ha,null),e(ha,T1t),e(ha,aSe),e(aSe,M1t),e(ha,E1t),e(ha,cf),e(cf,C1t),e(cf,nSe),e(nSe,w1t),e(cf,A1t),e(cf,Yle),e(Yle,L1t),e(cf,y1t),e(ha,x1t),M(_8,ha,null),e(Lr,$1t),e(Lr,tt),M(YP,tt,null),e(tt,k1t),e(tt,sSe),e(sSe,S1t),e(tt,R1t),e(tt,Zn),e(Zn,P1t),e(Zn,lSe),e(lSe,B1t),e(Zn,I1t),e(Zn,iSe),e(iSe,N1t),e(Zn,q1t),e(Zn,dSe),e(dSe,j1t),e(Zn,D1t),e(tt,G1t),e(tt,$e),e($e,b8),e(b8,mSe),e(mSe,O1t),e(b8,V1t),e(b8,Zle),e(Zle,X1t),e(b8,z1t),e($e,Q1t),e($e,v8),e(v8,cSe),e(cSe,W1t),e(v8,U1t),e(v8,Kle),e(Kle,H1t),e(v8,J1t),e($e,Y1t),e($e,F8),e(F8,fSe),e(fSe,Z1t),e(F8,K1t),e(F8,eie),e(eie,e2t),e(F8,o2t),e($e,r2t),e($e,T8),e(T8,gSe),e(gSe,t2t),e(T8,a2t),e(T8,oie),e(oie,n2t),e(T8,s2t),e($e,l2t),e($e,M8),e(M8,hSe),e(hSe,i2t),e(M8,d2t),e(M8,rie),e(rie,m2t),e(M8,c2t),e($e,f2t),e($e,E8),e(E8,uSe),e(uSe,g2t),e(E8,h2t),e(E8,tie),e(tie,u2t),e(E8,p2t),e($e,_2t),e($e,C8),e(C8,pSe),e(pSe,b2t),e(C8,v2t),e(C8,aie),e(aie,F2t),e(C8,T2t),e($e,M2t),e($e,w8),e(w8,_Se),e(_Se,E2t),e(w8,C2t),e(w8,nie),e(nie,w2t),e(w8,A2t),e($e,L2t),e($e,A8),e(A8,bSe),e(bSe,y2t),e(A8,x2t),e(A8,sie),e(sie,$2t),e(A8,k2t),e($e,S2t),e($e,L8),e(L8,vSe),e(vSe,R2t),e(L8,P2t),e(L8,lie),e(lie,B2t),e(L8,I2t),e(tt,N2t),M(y8,tt,null),b(c,Mno,_),b(c,ff,_),e(ff,x8),e(x8,FSe),M(ZP,FSe,null),e(ff,q2t),e(ff,TSe),e(TSe,j2t),b(c,Eno,_),b(c,yr,_),M(KP,yr,null),e(yr,D2t),e(yr,gf),e(gf,G2t),e(gf,iie),e(iie,O2t),e(gf,V2t),e(gf,die),e(die,X2t),e(gf,z2t),e(yr,Q2t),e(yr,eB),e(eB,W2t),e(eB,MSe),e(MSe,U2t),e(eB,H2t),e(yr,J2t),e(yr,ua),M(oB,ua,null),e(ua,Y2t),e(ua,ESe),e(ESe,Z2t),e(ua,K2t),e(ua,hf),e(hf,ebt),e(hf,CSe),e(CSe,obt),e(hf,rbt),e(hf,mie),e(mie,tbt),e(hf,abt),e(ua,nbt),M($8,ua,null),e(yr,sbt),e(yr,at),M(rB,at,null),e(at,lbt),e(at,wSe),e(wSe,ibt),e(at,dbt),e(at,Kn),e(Kn,mbt),e(Kn,ASe),e(ASe,cbt),e(Kn,fbt),e(Kn,LSe),e(LSe,gbt),e(Kn,hbt),e(Kn,ySe),e(ySe,ubt),e(Kn,pbt),e(at,_bt),e(at,Ee),e(Ee,k8),e(k8,xSe),e(xSe,bbt),e(k8,vbt),e(k8,cie),e(cie,Fbt),e(k8,Tbt),e(Ee,Mbt),e(Ee,S8),e(S8,$Se),e($Se,Ebt),e(S8,Cbt),e(S8,fie),e(fie,wbt),e(S8,Abt),e(Ee,Lbt),e(Ee,R8),e(R8,kSe),e(kSe,ybt),e(R8,xbt),e(R8,gie),e(gie,$bt),e(R8,kbt),e(Ee,Sbt),e(Ee,P8),e(P8,SSe),e(SSe,Rbt),e(P8,Pbt),e(P8,hie),e(hie,Bbt),e(P8,Ibt),e(Ee,Nbt),e(Ee,B8),e(B8,RSe),e(RSe,qbt),e(B8,jbt),e(B8,uie),e(uie,Dbt),e(B8,Gbt),e(Ee,Obt),e(Ee,I8),e(I8,PSe),e(PSe,Vbt),e(I8,Xbt),e(I8,pie),e(pie,zbt),e(I8,Qbt),e(Ee,Wbt),e(Ee,N8),e(N8,BSe),e(BSe,Ubt),e(N8,Hbt),e(N8,_ie),e(_ie,Jbt),e(N8,Ybt),e(Ee,Zbt),e(Ee,q8),e(q8,ISe),e(ISe,Kbt),e(q8,evt),e(q8,bie),e(bie,ovt),e(q8,rvt),e(Ee,tvt),e(Ee,j8),e(j8,NSe),e(NSe,avt),e(j8,nvt),e(j8,vie),e(vie,svt),e(j8,lvt),e(Ee,ivt),e(Ee,D8),e(D8,qSe),e(qSe,dvt),e(D8,mvt),e(D8,Fie),e(Fie,cvt),e(D8,fvt),e(Ee,gvt),e(Ee,G8),e(G8,jSe),e(jSe,hvt),e(G8,uvt),e(G8,Tie),e(Tie,pvt),e(G8,_vt),e(Ee,bvt),e(Ee,O8),e(O8,DSe),e(DSe,vvt),e(O8,Fvt),e(O8,Mie),e(Mie,Tvt),e(O8,Mvt),e(Ee,Evt),e(Ee,V8),e(V8,GSe),e(GSe,Cvt),e(V8,wvt),e(V8,Eie),e(Eie,Avt),e(V8,Lvt),e(at,yvt),M(X8,at,null),b(c,Cno,_),b(c,uf,_),e(uf,z8),e(z8,OSe),M(tB,OSe,null),e(uf,xvt),e(uf,VSe),e(VSe,$vt),b(c,wno,_),b(c,xr,_),M(aB,xr,null),e(xr,kvt),e(xr,pf),e(pf,Svt),e(pf,Cie),e(Cie,Rvt),e(pf,Pvt),e(pf,wie),e(wie,Bvt),e(pf,Ivt),e(xr,Nvt),e(xr,nB),e(nB,qvt),e(nB,XSe),e(XSe,jvt),e(nB,Dvt),e(xr,Gvt),e(xr,pa),M(sB,pa,null),e(pa,Ovt),e(pa,zSe),e(zSe,Vvt),e(pa,Xvt),e(pa,_f),e(_f,zvt),e(_f,QSe),e(QSe,Qvt),e(_f,Wvt),e(_f,Aie),e(Aie,Uvt),e(_f,Hvt),e(pa,Jvt),M(Q8,pa,null),e(xr,Yvt),e(xr,nt),M(lB,nt,null),e(nt,Zvt),e(nt,WSe),e(WSe,Kvt),e(nt,eFt),e(nt,es),e(es,oFt),e(es,USe),e(USe,rFt),e(es,tFt),e(es,HSe),e(HSe,aFt),e(es,nFt),e(es,JSe),e(JSe,sFt),e(es,lFt),e(nt,iFt),e(nt,ke),e(ke,W8),e(W8,YSe),e(YSe,dFt),e(W8,mFt),e(W8,Lie),e(Lie,cFt),e(W8,fFt),e(ke,gFt),e(ke,U8),e(U8,ZSe),e(ZSe,hFt),e(U8,uFt),e(U8,yie),e(yie,pFt),e(U8,_Ft),e(ke,bFt),e(ke,H8),e(H8,KSe),e(KSe,vFt),e(H8,FFt),e(H8,xie),e(xie,TFt),e(H8,MFt),e(ke,EFt),e(ke,J8),e(J8,eRe),e(eRe,CFt),e(J8,wFt),e(J8,$ie),e($ie,AFt),e(J8,LFt),e(ke,yFt),e(ke,Y8),e(Y8,oRe),e(oRe,xFt),e(Y8,$Ft),e(Y8,kie),e(kie,kFt),e(Y8,SFt),e(ke,RFt),e(ke,Z8),e(Z8,rRe),e(rRe,PFt),e(Z8,BFt),e(Z8,Sie),e(Sie,IFt),e(Z8,NFt),e(ke,qFt),e(ke,K8),e(K8,tRe),e(tRe,jFt),e(K8,DFt),e(K8,Rie),e(Rie,GFt),e(K8,OFt),e(ke,VFt),e(ke,eL),e(eL,aRe),e(aRe,XFt),e(eL,zFt),e(eL,Pie),e(Pie,QFt),e(eL,WFt),e(ke,UFt),e(ke,oL),e(oL,nRe),e(nRe,HFt),e(oL,JFt),e(oL,Bie),e(Bie,YFt),e(oL,ZFt),e(ke,KFt),e(ke,rL),e(rL,sRe),e(sRe,eTt),e(rL,oTt),e(rL,Iie),e(Iie,rTt),e(rL,tTt),e(nt,aTt),M(tL,nt,null),b(c,Ano,_),b(c,bf,_),e(bf,aL),e(aL,lRe),M(iB,lRe,null),e(bf,nTt),e(bf,iRe),e(iRe,sTt),b(c,Lno,_),b(c,$r,_),M(dB,$r,null),e($r,lTt),e($r,vf),e(vf,iTt),e(vf,Nie),e(Nie,dTt),e(vf,mTt),e(vf,qie),e(qie,cTt),e(vf,fTt),e($r,gTt),e($r,mB),e(mB,hTt),e(mB,dRe),e(dRe,uTt),e(mB,pTt),e($r,_Tt),e($r,_a),M(cB,_a,null),e(_a,bTt),e(_a,mRe),e(mRe,vTt),e(_a,FTt),e(_a,Ff),e(Ff,TTt),e(Ff,cRe),e(cRe,MTt),e(Ff,ETt),e(Ff,jie),e(jie,CTt),e(Ff,wTt),e(_a,ATt),M(nL,_a,null),e($r,LTt),e($r,st),M(fB,st,null),e(st,yTt),e(st,fRe),e(fRe,xTt),e(st,$Tt),e(st,os),e(os,kTt),e(os,gRe),e(gRe,STt),e(os,RTt),e(os,hRe),e(hRe,PTt),e(os,BTt),e(os,uRe),e(uRe,ITt),e(os,NTt),e(st,qTt),e(st,Se),e(Se,sL),e(sL,pRe),e(pRe,jTt),e(sL,DTt),e(sL,Die),e(Die,GTt),e(sL,OTt),e(Se,VTt),e(Se,lL),e(lL,_Re),e(_Re,XTt),e(lL,zTt),e(lL,Gie),e(Gie,QTt),e(lL,WTt),e(Se,UTt),e(Se,iL),e(iL,bRe),e(bRe,HTt),e(iL,JTt),e(iL,Oie),e(Oie,YTt),e(iL,ZTt),e(Se,KTt),e(Se,dL),e(dL,vRe),e(vRe,eMt),e(dL,oMt),e(dL,Vie),e(Vie,rMt),e(dL,tMt),e(Se,aMt),e(Se,mL),e(mL,FRe),e(FRe,nMt),e(mL,sMt),e(mL,Xie),e(Xie,lMt),e(mL,iMt),e(Se,dMt),e(Se,cL),e(cL,TRe),e(TRe,mMt),e(cL,cMt),e(cL,zie),e(zie,fMt),e(cL,gMt),e(Se,hMt),e(Se,fL),e(fL,MRe),e(MRe,uMt),e(fL,pMt),e(fL,Qie),e(Qie,_Mt),e(fL,bMt),e(Se,vMt),e(Se,gL),e(gL,ERe),e(ERe,FMt),e(gL,TMt),e(gL,Wie),e(Wie,MMt),e(gL,EMt),e(Se,CMt),e(Se,hL),e(hL,CRe),e(CRe,wMt),e(hL,AMt),e(hL,Uie),e(Uie,LMt),e(hL,yMt),e(Se,xMt),e(Se,uL),e(uL,wRe),e(wRe,$Mt),e(uL,kMt),e(uL,Hie),e(Hie,SMt),e(uL,RMt),e(st,PMt),M(pL,st,null),b(c,yno,_),b(c,Tf,_),e(Tf,_L),e(_L,ARe),M(gB,ARe,null),e(Tf,BMt),e(Tf,LRe),e(LRe,IMt),b(c,xno,_),b(c,kr,_),M(hB,kr,null),e(kr,NMt),e(kr,Mf),e(Mf,qMt),e(Mf,Jie),e(Jie,jMt),e(Mf,DMt),e(Mf,Yie),e(Yie,GMt),e(Mf,OMt),e(kr,VMt),e(kr,uB),e(uB,XMt),e(uB,yRe),e(yRe,zMt),e(uB,QMt),e(kr,WMt),e(kr,ba),M(pB,ba,null),e(ba,UMt),e(ba,xRe),e(xRe,HMt),e(ba,JMt),e(ba,Ef),e(Ef,YMt),e(Ef,$Re),e($Re,ZMt),e(Ef,KMt),e(Ef,Zie),e(Zie,eEt),e(Ef,oEt),e(ba,rEt),M(bL,ba,null),e(kr,tEt),e(kr,lt),M(_B,lt,null),e(lt,aEt),e(lt,kRe),e(kRe,nEt),e(lt,sEt),e(lt,rs),e(rs,lEt),e(rs,SRe),e(SRe,iEt),e(rs,dEt),e(rs,RRe),e(RRe,mEt),e(rs,cEt),e(rs,PRe),e(PRe,fEt),e(rs,gEt),e(lt,hEt),e(lt,Re),e(Re,vL),e(vL,BRe),e(BRe,uEt),e(vL,pEt),e(vL,Kie),e(Kie,_Et),e(vL,bEt),e(Re,vEt),e(Re,FL),e(FL,IRe),e(IRe,FEt),e(FL,TEt),e(FL,ede),e(ede,MEt),e(FL,EEt),e(Re,CEt),e(Re,TL),e(TL,NRe),e(NRe,wEt),e(TL,AEt),e(TL,ode),e(ode,LEt),e(TL,yEt),e(Re,xEt),e(Re,ML),e(ML,qRe),e(qRe,$Et),e(ML,kEt),e(ML,rde),e(rde,SEt),e(ML,REt),e(Re,PEt),e(Re,EL),e(EL,jRe),e(jRe,BEt),e(EL,IEt),e(EL,tde),e(tde,NEt),e(EL,qEt),e(Re,jEt),e(Re,CL),e(CL,DRe),e(DRe,DEt),e(CL,GEt),e(CL,ade),e(ade,OEt),e(CL,VEt),e(Re,XEt),e(Re,wL),e(wL,GRe),e(GRe,zEt),e(wL,QEt),e(wL,nde),e(nde,WEt),e(wL,UEt),e(Re,HEt),e(Re,AL),e(AL,ORe),e(ORe,JEt),e(AL,YEt),e(AL,sde),e(sde,ZEt),e(AL,KEt),e(Re,e4t),e(Re,LL),e(LL,VRe),e(VRe,o4t),e(LL,r4t),e(LL,lde),e(lde,t4t),e(LL,a4t),e(Re,n4t),e(Re,yL),e(yL,XRe),e(XRe,s4t),e(yL,l4t),e(yL,ide),e(ide,i4t),e(yL,d4t),e(lt,m4t),M(xL,lt,null),b(c,$no,_),b(c,Cf,_),e(Cf,$L),e($L,zRe),M(bB,zRe,null),e(Cf,c4t),e(Cf,QRe),e(QRe,f4t),b(c,kno,_),b(c,Sr,_),M(vB,Sr,null),e(Sr,g4t),e(Sr,wf),e(wf,h4t),e(wf,dde),e(dde,u4t),e(wf,p4t),e(wf,mde),e(mde,_4t),e(wf,b4t),e(Sr,v4t),e(Sr,FB),e(FB,F4t),e(FB,WRe),e(WRe,T4t),e(FB,M4t),e(Sr,E4t),e(Sr,va),M(TB,va,null),e(va,C4t),e(va,URe),e(URe,w4t),e(va,A4t),e(va,Af),e(Af,L4t),e(Af,HRe),e(HRe,y4t),e(Af,x4t),e(Af,cde),e(cde,$4t),e(Af,k4t),e(va,S4t),M(kL,va,null),e(Sr,R4t),e(Sr,it),M(MB,it,null),e(it,P4t),e(it,JRe),e(JRe,B4t),e(it,I4t),e(it,ts),e(ts,N4t),e(ts,YRe),e(YRe,q4t),e(ts,j4t),e(ts,ZRe),e(ZRe,D4t),e(ts,G4t),e(ts,KRe),e(KRe,O4t),e(ts,V4t),e(it,X4t),e(it,Pe),e(Pe,SL),e(SL,ePe),e(ePe,z4t),e(SL,Q4t),e(SL,fde),e(fde,W4t),e(SL,U4t),e(Pe,H4t),e(Pe,RL),e(RL,oPe),e(oPe,J4t),e(RL,Y4t),e(RL,gde),e(gde,Z4t),e(RL,K4t),e(Pe,eCt),e(Pe,PL),e(PL,rPe),e(rPe,oCt),e(PL,rCt),e(PL,hde),e(hde,tCt),e(PL,aCt),e(Pe,nCt),e(Pe,BL),e(BL,tPe),e(tPe,sCt),e(BL,lCt),e(BL,ude),e(ude,iCt),e(BL,dCt),e(Pe,mCt),e(Pe,IL),e(IL,aPe),e(aPe,cCt),e(IL,fCt),e(IL,pde),e(pde,gCt),e(IL,hCt),e(Pe,uCt),e(Pe,NL),e(NL,nPe),e(nPe,pCt),e(NL,_Ct),e(NL,_de),e(_de,bCt),e(NL,vCt),e(Pe,FCt),e(Pe,qL),e(qL,sPe),e(sPe,TCt),e(qL,MCt),e(qL,bde),e(bde,ECt),e(qL,CCt),e(Pe,wCt),e(Pe,jL),e(jL,lPe),e(lPe,ACt),e(jL,LCt),e(jL,vde),e(vde,yCt),e(jL,xCt),e(Pe,$Ct),e(Pe,DL),e(DL,iPe),e(iPe,kCt),e(DL,SCt),e(DL,Fde),e(Fde,RCt),e(DL,PCt),e(Pe,BCt),e(Pe,GL),e(GL,dPe),e(dPe,ICt),e(GL,NCt),e(GL,Tde),e(Tde,qCt),e(GL,jCt),e(it,DCt),M(OL,it,null),b(c,Sno,_),b(c,Lf,_),e(Lf,VL),e(VL,mPe),M(EB,mPe,null),e(Lf,GCt),e(Lf,cPe),e(cPe,OCt),b(c,Rno,_),b(c,Rr,_),M(CB,Rr,null),e(Rr,VCt),e(Rr,yf),e(yf,XCt),e(yf,Mde),e(Mde,zCt),e(yf,QCt),e(yf,Ede),e(Ede,WCt),e(yf,UCt),e(Rr,HCt),e(Rr,wB),e(wB,JCt),e(wB,fPe),e(fPe,YCt),e(wB,ZCt),e(Rr,KCt),e(Rr,Fa),M(AB,Fa,null),e(Fa,e3t),e(Fa,gPe),e(gPe,o3t),e(Fa,r3t),e(Fa,xf),e(xf,t3t),e(xf,hPe),e(hPe,a3t),e(xf,n3t),e(xf,Cde),e(Cde,s3t),e(xf,l3t),e(Fa,i3t),M(XL,Fa,null),e(Rr,d3t),e(Rr,dt),M(LB,dt,null),e(dt,m3t),e(dt,uPe),e(uPe,c3t),e(dt,f3t),e(dt,as),e(as,g3t),e(as,pPe),e(pPe,h3t),e(as,u3t),e(as,_Pe),e(_Pe,p3t),e(as,_3t),e(as,bPe),e(bPe,b3t),e(as,v3t),e(dt,F3t),e(dt,ze),e(ze,zL),e(zL,vPe),e(vPe,T3t),e(zL,M3t),e(zL,wde),e(wde,E3t),e(zL,C3t),e(ze,w3t),e(ze,QL),e(QL,FPe),e(FPe,A3t),e(QL,L3t),e(QL,Ade),e(Ade,y3t),e(QL,x3t),e(ze,$3t),e(ze,WL),e(WL,TPe),e(TPe,k3t),e(WL,S3t),e(WL,Lde),e(Lde,R3t),e(WL,P3t),e(ze,B3t),e(ze,UL),e(UL,MPe),e(MPe,I3t),e(UL,N3t),e(UL,yde),e(yde,q3t),e(UL,j3t),e(ze,D3t),e(ze,HL),e(HL,EPe),e(EPe,G3t),e(HL,O3t),e(HL,xde),e(xde,V3t),e(HL,X3t),e(ze,z3t),e(ze,JL),e(JL,CPe),e(CPe,Q3t),e(JL,W3t),e(JL,$de),e($de,U3t),e(JL,H3t),e(ze,J3t),e(ze,YL),e(YL,wPe),e(wPe,Y3t),e(YL,Z3t),e(YL,kde),e(kde,K3t),e(YL,e5t),e(ze,o5t),e(ze,ZL),e(ZL,APe),e(APe,r5t),e(ZL,t5t),e(ZL,Sde),e(Sde,a5t),e(ZL,n5t),e(dt,s5t),M(KL,dt,null),b(c,Pno,_),b(c,$f,_),e($f,ey),e(ey,LPe),M(yB,LPe,null),e($f,l5t),e($f,yPe),e(yPe,i5t),b(c,Bno,_),b(c,Pr,_),M(xB,Pr,null),e(Pr,d5t),e(Pr,kf),e(kf,m5t),e(kf,Rde),e(Rde,c5t),e(kf,f5t),e(kf,Pde),e(Pde,g5t),e(kf,h5t),e(Pr,u5t),e(Pr,$B),e($B,p5t),e($B,xPe),e(xPe,_5t),e($B,b5t),e(Pr,v5t),e(Pr,Ta),M(kB,Ta,null),e(Ta,F5t),e(Ta,$Pe),e($Pe,T5t),e(Ta,M5t),e(Ta,Sf),e(Sf,E5t),e(Sf,kPe),e(kPe,C5t),e(Sf,w5t),e(Sf,Bde),e(Bde,A5t),e(Sf,L5t),e(Ta,y5t),M(oy,Ta,null),e(Pr,x5t),e(Pr,mt),M(SB,mt,null),e(mt,$5t),e(mt,SPe),e(SPe,k5t),e(mt,S5t),e(mt,ns),e(ns,R5t),e(ns,RPe),e(RPe,P5t),e(ns,B5t),e(ns,PPe),e(PPe,I5t),e(ns,N5t),e(ns,BPe),e(BPe,q5t),e(ns,j5t),e(mt,D5t),e(mt,Qe),e(Qe,ry),e(ry,IPe),e(IPe,G5t),e(ry,O5t),e(ry,Ide),e(Ide,V5t),e(ry,X5t),e(Qe,z5t),e(Qe,ty),e(ty,NPe),e(NPe,Q5t),e(ty,W5t),e(ty,Nde),e(Nde,U5t),e(ty,H5t),e(Qe,J5t),e(Qe,ay),e(ay,qPe),e(qPe,Y5t),e(ay,Z5t),e(ay,qde),e(qde,K5t),e(ay,e0t),e(Qe,o0t),e(Qe,ny),e(ny,jPe),e(jPe,r0t),e(ny,t0t),e(ny,jde),e(jde,a0t),e(ny,n0t),e(Qe,s0t),e(Qe,sy),e(sy,DPe),e(DPe,l0t),e(sy,i0t),e(sy,Dde),e(Dde,d0t),e(sy,m0t),e(Qe,c0t),e(Qe,ly),e(ly,GPe),e(GPe,f0t),e(ly,g0t),e(ly,Gde),e(Gde,h0t),e(ly,u0t),e(Qe,p0t),e(Qe,iy),e(iy,OPe),e(OPe,_0t),e(iy,b0t),e(iy,Ode),e(Ode,v0t),e(iy,F0t),e(Qe,T0t),e(Qe,dy),e(dy,VPe),e(VPe,M0t),e(dy,E0t),e(dy,Vde),e(Vde,C0t),e(dy,w0t),e(mt,A0t),M(my,mt,null),b(c,Ino,_),b(c,Rf,_),e(Rf,cy),e(cy,XPe),M(RB,XPe,null),e(Rf,L0t),e(Rf,zPe),e(zPe,y0t),b(c,Nno,_),b(c,Br,_),M(PB,Br,null),e(Br,x0t),e(Br,Pf),e(Pf,$0t),e(Pf,Xde),e(Xde,k0t),e(Pf,S0t),e(Pf,zde),e(zde,R0t),e(Pf,P0t),e(Br,B0t),e(Br,BB),e(BB,I0t),e(BB,QPe),e(QPe,N0t),e(BB,q0t),e(Br,j0t),e(Br,Ma),M(IB,Ma,null),e(Ma,D0t),e(Ma,WPe),e(WPe,G0t),e(Ma,O0t),e(Ma,Bf),e(Bf,V0t),e(Bf,UPe),e(UPe,X0t),e(Bf,z0t),e(Bf,Qde),e(Qde,Q0t),e(Bf,W0t),e(Ma,U0t),M(fy,Ma,null),e(Br,H0t),e(Br,ct),M(NB,ct,null),e(ct,J0t),e(ct,HPe),e(HPe,Y0t),e(ct,Z0t),e(ct,ss),e(ss,K0t),e(ss,JPe),e(JPe,ewt),e(ss,owt),e(ss,YPe),e(YPe,rwt),e(ss,twt),e(ss,ZPe),e(ZPe,awt),e(ss,nwt),e(ct,swt),e(ct,KPe),e(KPe,gy),e(gy,eBe),e(eBe,lwt),e(gy,iwt),e(gy,Wde),e(Wde,dwt),e(gy,mwt),e(ct,cwt),M(hy,ct,null),b(c,qno,_),b(c,If,_),e(If,uy),e(uy,oBe),M(qB,oBe,null),e(If,fwt),e(If,rBe),e(rBe,gwt),b(c,jno,_),b(c,Ir,_),M(jB,Ir,null),e(Ir,hwt),e(Ir,Nf),e(Nf,uwt),e(Nf,Ude),e(Ude,pwt),e(Nf,_wt),e(Nf,Hde),e(Hde,bwt),e(Nf,vwt),e(Ir,Fwt),e(Ir,DB),e(DB,Twt),e(DB,tBe),e(tBe,Mwt),e(DB,Ewt),e(Ir,Cwt),e(Ir,Ea),M(GB,Ea,null),e(Ea,wwt),e(Ea,aBe),e(aBe,Awt),e(Ea,Lwt),e(Ea,qf),e(qf,ywt),e(qf,nBe),e(nBe,xwt),e(qf,$wt),e(qf,Jde),e(Jde,kwt),e(qf,Swt),e(Ea,Rwt),M(py,Ea,null),e(Ir,Pwt),e(Ir,ft),M(OB,ft,null),e(ft,Bwt),e(ft,sBe),e(sBe,Iwt),e(ft,Nwt),e(ft,ls),e(ls,qwt),e(ls,lBe),e(lBe,jwt),e(ls,Dwt),e(ls,iBe),e(iBe,Gwt),e(ls,Owt),e(ls,dBe),e(dBe,Vwt),e(ls,Xwt),e(ft,zwt),e(ft,VB),e(VB,_y),e(_y,mBe),e(mBe,Qwt),e(_y,Wwt),e(_y,Yde),e(Yde,Uwt),e(_y,Hwt),e(VB,Jwt),e(VB,by),e(by,cBe),e(cBe,Ywt),e(by,Zwt),e(by,Zde),e(Zde,Kwt),e(by,eAt),e(ft,oAt),M(vy,ft,null),b(c,Dno,_),b(c,jf,_),e(jf,Fy),e(Fy,fBe),M(XB,fBe,null),e(jf,rAt),e(jf,gBe),e(gBe,tAt),b(c,Gno,_),b(c,Nr,_),M(zB,Nr,null),e(Nr,aAt),e(Nr,Df),e(Df,nAt),e(Df,Kde),e(Kde,sAt),e(Df,lAt),e(Df,eme),e(eme,iAt),e(Df,dAt),e(Nr,mAt),e(Nr,QB),e(QB,cAt),e(QB,hBe),e(hBe,fAt),e(QB,gAt),e(Nr,hAt),e(Nr,Ca),M(WB,Ca,null),e(Ca,uAt),e(Ca,uBe),e(uBe,pAt),e(Ca,_At),e(Ca,Gf),e(Gf,bAt),e(Gf,pBe),e(pBe,vAt),e(Gf,FAt),e(Gf,ome),e(ome,TAt),e(Gf,MAt),e(Ca,EAt),M(Ty,Ca,null),e(Nr,CAt),e(Nr,gt),M(UB,gt,null),e(gt,wAt),e(gt,_Be),e(_Be,AAt),e(gt,LAt),e(gt,is),e(is,yAt),e(is,bBe),e(bBe,xAt),e(is,$At),e(is,vBe),e(vBe,kAt),e(is,SAt),e(is,FBe),e(FBe,RAt),e(is,PAt),e(gt,BAt),e(gt,TBe),e(TBe,My),e(My,MBe),e(MBe,IAt),e(My,NAt),e(My,rme),e(rme,qAt),e(My,jAt),e(gt,DAt),M(Ey,gt,null),Ono=!0},p(c,[_]){const HB={};_&2&&(HB.$$scope={dirty:_,ctx:c}),Jf.$set(HB);const EBe={};_&2&&(EBe.$$scope={dirty:_,ctx:c}),wu.$set(EBe);const CBe={};_&2&&(CBe.$$scope={dirty:_,ctx:c}),mp.$set(CBe);const wBe={};_&2&&(wBe.$$scope={dirty:_,ctx:c}),t_.$set(wBe);const JB={};_&2&&(JB.$$scope={dirty:_,ctx:c}),a_.$set(JB);const ABe={};_&2&&(ABe.$$scope={dirty:_,ctx:c}),x_.$set(ABe);const ds={};_&2&&(ds.$$scope={dirty:_,ctx:c}),$_.$set(ds);const LBe={};_&2&&(LBe.$$scope={dirty:_,ctx:c}),R_.$set(LBe);const yBe={};_&2&&(yBe.$$scope={dirty:_,ctx:c}),ob.$set(yBe);const xBe={};_&2&&(xBe.$$scope={dirty:_,ctx:c}),tb.$set(xBe);const YB={};_&2&&(YB.$$scope={dirty:_,ctx:c}),Kb.$set(YB);const $Be={};_&2&&($Be.$$scope={dirty:_,ctx:c}),ov.$set($Be);const ZB={};_&2&&(ZB.$$scope={dirty:_,ctx:c}),zv.$set(ZB);const kBe={};_&2&&(kBe.$$scope={dirty:_,ctx:c}),Wv.$set(kBe);const KB={};_&2&&(KB.$$scope={dirty:_,ctx:c}),Yv.$set(KB);const SBe={};_&2&&(SBe.$$scope={dirty:_,ctx:c}),Kv.$set(SBe);const RBe={};_&2&&(RBe.$$scope={dirty:_,ctx:c}),DF.$set(RBe);const PBe={};_&2&&(PBe.$$scope={dirty:_,ctx:c}),OF.$set(PBe);const Of={};_&2&&(Of.$$scope={dirty:_,ctx:c}),mT.$set(Of);const BBe={};_&2&&(BBe.$$scope={dirty:_,ctx:c}),fT.$set(BBe);const IBe={};_&2&&(IBe.$$scope={dirty:_,ctx:c}),pM.$set(IBe);const NBe={};_&2&&(NBe.$$scope={dirty:_,ctx:c}),bM.$set(NBe);const eI={};_&2&&(eI.$$scope={dirty:_,ctx:c}),ZM.$set(eI);const qBe={};_&2&&(qBe.$$scope={dirty:_,ctx:c}),eE.$set(qBe);const jBe={};_&2&&(jBe.$$scope={dirty:_,ctx:c}),dE.$set(jBe);const DBe={};_&2&&(DBe.$$scope={dirty:_,ctx:c}),cE.$set(DBe);const vt={};_&2&&(vt.$$scope={dirty:_,ctx:c}),e4.$set(vt);const oI={};_&2&&(oI.$$scope={dirty:_,ctx:c}),r4.$set(oI);const GBe={};_&2&&(GBe.$$scope={dirty:_,ctx:c}),Z4.$set(GBe);const rI={};_&2&&(rI.$$scope={dirty:_,ctx:c}),eC.$set(rI);const OBe={};_&2&&(OBe.$$scope={dirty:_,ctx:c}),tC.$set(OBe);const Ft={};_&2&&(Ft.$$scope={dirty:_,ctx:c}),nC.$set(Ft);const VBe={};_&2&&(VBe.$$scope={dirty:_,ctx:c}),mC.$set(VBe);const Vf={};_&2&&(Vf.$$scope={dirty:_,ctx:c}),fC.$set(Vf);const XBe={};_&2&&(XBe.$$scope={dirty:_,ctx:c}),xC.$set(XBe);const zBe={};_&2&&(zBe.$$scope={dirty:_,ctx:c}),kC.$set(zBe);const L={};_&2&&(L.$$scope={dirty:_,ctx:c}),PC.$set(L);const Cy={};_&2&&(Cy.$$scope={dirty:_,ctx:c}),IC.$set(Cy);const QBe={};_&2&&(QBe.$$scope={dirty:_,ctx:c}),jC.$set(QBe);const WBe={};_&2&&(WBe.$$scope={dirty:_,ctx:c}),GC.$set(WBe);const wy={};_&2&&(wy.$$scope={dirty:_,ctx:c}),XC.$set(wy);const UBe={};_&2&&(UBe.$$scope={dirty:_,ctx:c}),QC.$set(UBe);const HBe={};_&2&&(HBe.$$scope={dirty:_,ctx:c}),t3.$set(HBe);const Ay={};_&2&&(Ay.$$scope={dirty:_,ctx:c}),n3.$set(Ay);const JBe={};_&2&&(JBe.$$scope={dirty:_,ctx:c}),f3.$set(JBe);const YBe={};_&2&&(YBe.$$scope={dirty:_,ctx:c}),h3.$set(YBe);const Ly={};_&2&&(Ly.$$scope={dirty:_,ctx:c}),A3.$set(Ly);const ZBe={};_&2&&(ZBe.$$scope={dirty:_,ctx:c}),y3.$set(ZBe);const KBe={};_&2&&(KBe.$$scope={dirty:_,ctx:c}),R3.$set(KBe);const yy={};_&2&&(yy.$$scope={dirty:_,ctx:c}),B3.$set(yy);const eIe={};_&2&&(eIe.$$scope={dirty:_,ctx:c}),O3.$set(eIe);const oIe={};_&2&&(oIe.$$scope={dirty:_,ctx:c}),X3.$set(oIe);const xy={};_&2&&(xy.$$scope={dirty:_,ctx:c}),J3.$set(xy);const rIe={};_&2&&(rIe.$$scope={dirty:_,ctx:c}),Z3.$set(rIe);const tIe={};_&2&&(tIe.$$scope={dirty:_,ctx:c}),n5.$set(tIe);const $y={};_&2&&($y.$$scope={dirty:_,ctx:c}),l5.$set($y);const aIe={};_&2&&(aIe.$$scope={dirty:_,ctx:c}),m5.$set(aIe);const nIe={};_&2&&(nIe.$$scope={dirty:_,ctx:c}),f5.$set(nIe);const ky={};_&2&&(ky.$$scope={dirty:_,ctx:c}),v5.$set(ky);const sIe={};_&2&&(sIe.$$scope={dirty:_,ctx:c}),T5.$set(sIe);const lIe={};_&2&&(lIe.$$scope={dirty:_,ctx:c}),C5.$set(lIe);const Sy={};_&2&&(Sy.$$scope={dirty:_,ctx:c}),A5.$set(Sy);const iIe={};_&2&&(iIe.$$scope={dirty:_,ctx:c}),x5.$set(iIe);const dIe={};_&2&&(dIe.$$scope={dirty:_,ctx:c}),k5.$set(dIe);const Ry={};_&2&&(Ry.$$scope={dirty:_,ctx:c}),B0.$set(Ry);const mIe={};_&2&&(mIe.$$scope={dirty:_,ctx:c}),N0.$set(mIe);const cIe={};_&2&&(cIe.$$scope={dirty:_,ctx:c}),lw.$set(cIe);const Py={};_&2&&(Py.$$scope={dirty:_,ctx:c}),dw.$set(Py);const fIe={};_&2&&(fIe.$$scope={dirty:_,ctx:c}),Cw.$set(fIe);const gIe={};_&2&&(gIe.$$scope={dirty:_,ctx:c}),Aw.$set(gIe);const By={};_&2&&(By.$$scope={dirty:_,ctx:c}),Iw.$set(By);const hIe={};_&2&&(hIe.$$scope={dirty:_,ctx:c}),qw.$set(hIe);const uIe={};_&2&&(uIe.$$scope={dirty:_,ctx:c}),Ow.$set(uIe);const Iy={};_&2&&(Iy.$$scope={dirty:_,ctx:c}),Xw.$set(Iy);const pIe={};_&2&&(pIe.$$scope={dirty:_,ctx:c}),fA.$set(pIe);const _Ie={};_&2&&(_Ie.$$scope={dirty:_,ctx:c}),hA.$set(_Ie);const Ny={};_&2&&(Ny.$$scope={dirty:_,ctx:c}),wA.$set(Ny);const bIe={};_&2&&(bIe.$$scope={dirty:_,ctx:c}),LA.$set(bIe);const vIe={};_&2&&(vIe.$$scope={dirty:_,ctx:c}),r6.$set(vIe);const qy={};_&2&&(qy.$$scope={dirty:_,ctx:c}),a6.$set(qy);const FIe={};_&2&&(FIe.$$scope={dirty:_,ctx:c}),M6.$set(FIe);const TIe={};_&2&&(TIe.$$scope={dirty:_,ctx:c}),C6.$set(TIe);const jy={};_&2&&(jy.$$scope={dirty:_,ctx:c}),L6.$set(jy);const MIe={};_&2&&(MIe.$$scope={dirty:_,ctx:c}),x6.$set(MIe);const EIe={};_&2&&(EIe.$$scope={dirty:_,ctx:c}),k6.$set(EIe);const Dy={};_&2&&(Dy.$$scope={dirty:_,ctx:c}),R6.$set(Dy);const CIe={};_&2&&(CIe.$$scope={dirty:_,ctx:c}),B6.$set(CIe);const wIe={};_&2&&(wIe.$$scope={dirty:_,ctx:c}),N6.$set(wIe);const Gy={};_&2&&(Gy.$$scope={dirty:_,ctx:c}),s7.$set(Gy);const AIe={};_&2&&(AIe.$$scope={dirty:_,ctx:c}),i7.$set(AIe);const LIe={};_&2&&(LIe.$$scope={dirty:_,ctx:c}),$7.$set(LIe);const Oy={};_&2&&(Oy.$$scope={dirty:_,ctx:c}),S7.$set(Oy);const yIe={};_&2&&(yIe.$$scope={dirty:_,ctx:c}),P7.$set(yIe);const xIe={};_&2&&(xIe.$$scope={dirty:_,ctx:c}),I7.$set(xIe);const Vy={};_&2&&(Vy.$$scope={dirty:_,ctx:c}),j7.$set(Vy);const $Ie={};_&2&&($Ie.$$scope={dirty:_,ctx:c}),G7.$set($Ie);const kIe={};_&2&&(kIe.$$scope={dirty:_,ctx:c}),u8.$set(kIe);const Xy={};_&2&&(Xy.$$scope={dirty:_,ctx:c}),_8.$set(Xy);const SIe={};_&2&&(SIe.$$scope={dirty:_,ctx:c}),y8.$set(SIe);const RIe={};_&2&&(RIe.$$scope={dirty:_,ctx:c}),$8.$set(RIe);const zy={};_&2&&(zy.$$scope={dirty:_,ctx:c}),X8.$set(zy);const PIe={};_&2&&(PIe.$$scope={dirty:_,ctx:c}),Q8.$set(PIe);const BIe={};_&2&&(BIe.$$scope={dirty:_,ctx:c}),tL.$set(BIe);const Qy={};_&2&&(Qy.$$scope={dirty:_,ctx:c}),nL.$set(Qy);const IIe={};_&2&&(IIe.$$scope={dirty:_,ctx:c}),pL.$set(IIe);const NIe={};_&2&&(NIe.$$scope={dirty:_,ctx:c}),bL.$set(NIe);const Wy={};_&2&&(Wy.$$scope={dirty:_,ctx:c}),xL.$set(Wy);const qIe={};_&2&&(qIe.$$scope={dirty:_,ctx:c}),kL.$set(qIe);const jIe={};_&2&&(jIe.$$scope={dirty:_,ctx:c}),OL.$set(jIe);const Uy={};_&2&&(Uy.$$scope={dirty:_,ctx:c}),XL.$set(Uy);const DIe={};_&2&&(DIe.$$scope={dirty:_,ctx:c}),KL.$set(DIe);const GIe={};_&2&&(GIe.$$scope={dirty:_,ctx:c}),oy.$set(GIe);const Hy={};_&2&&(Hy.$$scope={dirty:_,ctx:c}),my.$set(Hy);const OIe={};_&2&&(OIe.$$scope={dirty:_,ctx:c}),fy.$set(OIe);const VIe={};_&2&&(VIe.$$scope={dirty:_,ctx:c}),hy.$set(VIe);const Jy={};_&2&&(Jy.$$scope={dirty:_,ctx:c}),py.$set(Jy);const XIe={};_&2&&(XIe.$$scope={dirty:_,ctx:c}),vy.$set(XIe);const zIe={};_&2&&(zIe.$$scope={dirty:_,ctx:c}),Ty.$set(zIe);const Yy={};_&2&&(Yy.$$scope={dirty:_,ctx:c}),Ey.$set(Yy)},i(c){Ono||(E(d.$$.fragment,c),E(on.$$.fragment,c),E(d$.$$.fragment,c),E(m$.$$.fragment,c),E(Jf.$$.fragment,c),E(c$.$$.fragment,c),E(f$.$$.fragment,c),E(u$.$$.fragment,c),E(wu.$$.fragment,c),E(p$.$$.fragment,c),E(_$.$$.fragment,c),E(b$.$$.fragment,c),E(T$.$$.fragment,c),E(mp.$$.fragment,c),E(M$.$$.fragment,c),E(E$.$$.fragment,c),E(C$.$$.fragment,c),E(L$.$$.fragment,c),E(t_.$$.fragment,c),E(a_.$$.fragment,c),E(y$.$$.fragment,c),E(x$.$$.fragment,c),E($$.$$.fragment,c),E(R$.$$.fragment,c),E(x_.$$.fragment,c),E($_.$$.fragment,c),E(P$.$$.fragment,c),E(B$.$$.fragment,c),E(I$.$$.fragment,c),E(q$.$$.fragment,c),E(R_.$$.fragment,c),E(j$.$$.fragment,c),E(ob.$$.fragment,c),E(D$.$$.fragment,c),E(G$.$$.fragment,c),E(V$.$$.fragment,c),E(tb.$$.fragment,c),E(X$.$$.fragment,c),E(Kb.$$.fragment,c),E(z$.$$.fragment,c),E(Q$.$$.fragment,c),E(U$.$$.fragment,c),E(ov.$$.fragment,c),E(H$.$$.fragment,c),E(zv.$$.fragment,c),E(J$.$$.fragment,c),E(Y$.$$.fragment,c),E(K$.$$.fragment,c),E(Wv.$$.fragment,c),E(ek.$$.fragment,c),E(Yv.$$.fragment,c),E(rk.$$.fragment,c),E(tk.$$.fragment,c),E(nk.$$.fragment,c),E(Kv.$$.fragment,c),E(sk.$$.fragment,c),E(DF.$$.fragment,c),E(lk.$$.fragment,c),E(ik.$$.fragment,c),E(mk.$$.fragment,c),E(OF.$$.fragment,c),E(ck.$$.fragment,c),E(mT.$$.fragment,c),E(fk.$$.fragment,c),E(gk.$$.fragment,c),E(uk.$$.fragment,c),E(fT.$$.fragment,c),E(pk.$$.fragment,c),E(pM.$$.fragment,c),E(_k.$$.fragment,c),E(bk.$$.fragment,c),E(Fk.$$.fragment,c),E(bM.$$.fragment,c),E(Tk.$$.fragment,c),E(ZM.$$.fragment,c),E(Mk.$$.fragment,c),E(Ek.$$.fragment,c),E(wk.$$.fragment,c),E(eE.$$.fragment,c),E(Ak.$$.fragment,c),E(dE.$$.fragment,c),E(Lk.$$.fragment,c),E(yk.$$.fragment,c),E($k.$$.fragment,c),E(cE.$$.fragment,c),E(kk.$$.fragment,c),E(e4.$$.fragment,c),E(Sk.$$.fragment,c),E(Rk.$$.fragment,c),E(Bk.$$.fragment,c),E(r4.$$.fragment,c),E(Ik.$$.fragment,c),E(Z4.$$.fragment,c),E(Nk.$$.fragment,c),E(qk.$$.fragment,c),E(Dk.$$.fragment,c),E(eC.$$.fragment,c),E(Gk.$$.fragment,c),E(tC.$$.fragment,c),E(Ok.$$.fragment,c),E(Vk.$$.fragment,c),E(zk.$$.fragment,c),E(nC.$$.fragment,c),E(Qk.$$.fragment,c),E(mC.$$.fragment,c),E(Wk.$$.fragment,c),E(Uk.$$.fragment,c),E(Jk.$$.fragment,c),E(fC.$$.fragment,c),E(Yk.$$.fragment,c),E(xC.$$.fragment,c),E(Zk.$$.fragment,c),E(Kk.$$.fragment,c),E(oS.$$.fragment,c),E(kC.$$.fragment,c),E(rS.$$.fragment,c),E(PC.$$.fragment,c),E(tS.$$.fragment,c),E(aS.$$.fragment,c),E(sS.$$.fragment,c),E(IC.$$.fragment,c),E(lS.$$.fragment,c),E(jC.$$.fragment,c),E(iS.$$.fragment,c),E(dS.$$.fragment,c),E(cS.$$.fragment,c),E(GC.$$.fragment,c),E(fS.$$.fragment,c),E(XC.$$.fragment,c),E(gS.$$.fragment,c),E(hS.$$.fragment,c),E(pS.$$.fragment,c),E(QC.$$.fragment,c),E(_S.$$.fragment,c),E(t3.$$.fragment,c),E(bS.$$.fragment,c),E(vS.$$.fragment,c),E(TS.$$.fragment,c),E(n3.$$.fragment,c),E(MS.$$.fragment,c),E(f3.$$.fragment,c),E(ES.$$.fragment,c),E(CS.$$.fragment,c),E(AS.$$.fragment,c),E(h3.$$.fragment,c),E(LS.$$.fragment,c),E(A3.$$.fragment,c),E(yS.$$.fragment,c),E(xS.$$.fragment,c),E(kS.$$.fragment,c),E(y3.$$.fragment,c),E(SS.$$.fragment,c),E(R3.$$.fragment,c),E(RS.$$.fragment,c),E(PS.$$.fragment,c),E(IS.$$.fragment,c),E(B3.$$.fragment,c),E(NS.$$.fragment,c),E(O3.$$.fragment,c),E(qS.$$.fragment,c),E(jS.$$.fragment,c),E(GS.$$.fragment,c),E(X3.$$.fragment,c),E(OS.$$.fragment,c),E(J3.$$.fragment,c),E(VS.$$.fragment,c),E(XS.$$.fragment,c),E(QS.$$.fragment,c),E(Z3.$$.fragment,c),E(WS.$$.fragment,c),E(n5.$$.fragment,c),E(US.$$.fragment,c),E(HS.$$.fragment,c),E(YS.$$.fragment,c),E(l5.$$.fragment,c),E(ZS.$$.fragment,c),E(m5.$$.fragment,c),E(KS.$$.fragment,c),E(eR.$$.fragment,c),E(rR.$$.fragment,c),E(f5.$$.fragment,c),E(tR.$$.fragment,c),E(v5.$$.fragment,c),E(aR.$$.fragment,c),E(nR.$$.fragment,c),E(lR.$$.fragment,c),E(T5.$$.fragment,c),E(iR.$$.fragment,c),E(C5.$$.fragment,c),E(dR.$$.fragment,c),E(mR.$$.fragment,c),E(fR.$$.fragment,c),E(A5.$$.fragment,c),E(gR.$$.fragment,c),E(x5.$$.fragment,c),E(hR.$$.fragment,c),E(uR.$$.fragment,c),E(_R.$$.fragment,c),E(k5.$$.fragment,c),E(bR.$$.fragment,c),E(B0.$$.fragment,c),E(vR.$$.fragment,c),E(FR.$$.fragment,c),E(MR.$$.fragment,c),E(N0.$$.fragment,c),E(ER.$$.fragment,c),E(lw.$$.fragment,c),E(CR.$$.fragment,c),E(wR.$$.fragment,c),E(LR.$$.fragment,c),E(dw.$$.fragment,c),E(yR.$$.fragment,c),E(Cw.$$.fragment,c),E(xR.$$.fragment,c),E($R.$$.fragment,c),E(SR.$$.fragment,c),E(Aw.$$.fragment,c),E(RR.$$.fragment,c),E(Iw.$$.fragment,c),E(PR.$$.fragment,c),E(BR.$$.fragment,c),E(NR.$$.fragment,c),E(qw.$$.fragment,c),E(qR.$$.fragment,c),E(Ow.$$.fragment,c),E(jR.$$.fragment,c),E(DR.$$.fragment,c),E(OR.$$.fragment,c),E(Xw.$$.fragment,c),E(VR.$$.fragment,c),E(fA.$$.fragment,c),E(XR.$$.fragment,c),E(zR.$$.fragment,c),E(WR.$$.fragment,c),E(hA.$$.fragment,c),E(UR.$$.fragment,c),E(wA.$$.fragment,c),E(HR.$$.fragment,c),E(JR.$$.fragment,c),E(ZR.$$.fragment,c),E(LA.$$.fragment,c),E(KR.$$.fragment,c),E(r6.$$.fragment,c),E(eP.$$.fragment,c),E(oP.$$.fragment,c),E(tP.$$.fragment,c),E(a6.$$.fragment,c),E(aP.$$.fragment,c),E(M6.$$.fragment,c),E(nP.$$.fragment,c),E(sP.$$.fragment,c),E(iP.$$.fragment,c),E(C6.$$.fragment,c),E(dP.$$.fragment,c),E(L6.$$.fragment,c),E(cP.$$.fragment,c),E(fP.$$.fragment,c),E(hP.$$.fragment,c),E(x6.$$.fragment,c),E(uP.$$.fragment,c),E(k6.$$.fragment,c),E(pP.$$.fragment,c),E(_P.$$.fragment,c),E(vP.$$.fragment,c),E(R6.$$.fragment,c),E(FP.$$.fragment,c),E(B6.$$.fragment,c),E(TP.$$.fragment,c),E(MP.$$.fragment,c),E(CP.$$.fragment,c),E(N6.$$.fragment,c),E(wP.$$.fragment,c),E(s7.$$.fragment,c),E(AP.$$.fragment,c),E(LP.$$.fragment,c),E(xP.$$.fragment,c),E(i7.$$.fragment,c),E($P.$$.fragment,c),E($7.$$.fragment,c),E(kP.$$.fragment,c),E(SP.$$.fragment,c),E(PP.$$.fragment,c),E(S7.$$.fragment,c),E(BP.$$.fragment,c),E(P7.$$.fragment,c),E(IP.$$.fragment,c),E(NP.$$.fragment,c),E(jP.$$.fragment,c),E(I7.$$.fragment,c),E(DP.$$.fragment,c),E(j7.$$.fragment,c),E(OP.$$.fragment,c),E(VP.$$.fragment,c),E(zP.$$.fragment,c),E(G7.$$.fragment,c),E(QP.$$.fragment,c),E(u8.$$.fragment,c),E(WP.$$.fragment,c),E(UP.$$.fragment,c),E(JP.$$.fragment,c),E(_8.$$.fragment,c),E(YP.$$.fragment,c),E(y8.$$.fragment,c),E(ZP.$$.fragment,c),E(KP.$$.fragment,c),E(oB.$$.fragment,c),E($8.$$.fragment,c),E(rB.$$.fragment,c),E(X8.$$.fragment,c),E(tB.$$.fragment,c),E(aB.$$.fragment,c),E(sB.$$.fragment,c),E(Q8.$$.fragment,c),E(lB.$$.fragment,c),E(tL.$$.fragment,c),E(iB.$$.fragment,c),E(dB.$$.fragment,c),E(cB.$$.fragment,c),E(nL.$$.fragment,c),E(fB.$$.fragment,c),E(pL.$$.fragment,c),E(gB.$$.fragment,c),E(hB.$$.fragment,c),E(pB.$$.fragment,c),E(bL.$$.fragment,c),E(_B.$$.fragment,c),E(xL.$$.fragment,c),E(bB.$$.fragment,c),E(vB.$$.fragment,c),E(TB.$$.fragment,c),E(kL.$$.fragment,c),E(MB.$$.fragment,c),E(OL.$$.fragment,c),E(EB.$$.fragment,c),E(CB.$$.fragment,c),E(AB.$$.fragment,c),E(XL.$$.fragment,c),E(LB.$$.fragment,c),E(KL.$$.fragment,c),E(yB.$$.fragment,c),E(xB.$$.fragment,c),E(kB.$$.fragment,c),E(oy.$$.fragment,c),E(SB.$$.fragment,c),E(my.$$.fragment,c),E(RB.$$.fragment,c),E(PB.$$.fragment,c),E(IB.$$.fragment,c),E(fy.$$.fragment,c),E(NB.$$.fragment,c),E(hy.$$.fragment,c),E(qB.$$.fragment,c),E(jB.$$.fragment,c),E(GB.$$.fragment,c),E(py.$$.fragment,c),E(OB.$$.fragment,c),E(vy.$$.fragment,c),E(XB.$$.fragment,c),E(zB.$$.fragment,c),E(WB.$$.fragment,c),E(Ty.$$.fragment,c),E(UB.$$.fragment,c),E(Ey.$$.fragment,c),Ono=!0)},o(c){C(d.$$.fragment,c),C(on.$$.fragment,c),C(d$.$$.fragment,c),C(m$.$$.fragment,c),C(Jf.$$.fragment,c),C(c$.$$.fragment,c),C(f$.$$.fragment,c),C(u$.$$.fragment,c),C(wu.$$.fragment,c),C(p$.$$.fragment,c),C(_$.$$.fragment,c),C(b$.$$.fragment,c),C(T$.$$.fragment,c),C(mp.$$.fragment,c),C(M$.$$.fragment,c),C(E$.$$.fragment,c),C(C$.$$.fragment,c),C(L$.$$.fragment,c),C(t_.$$.fragment,c),C(a_.$$.fragment,c),C(y$.$$.fragment,c),C(x$.$$.fragment,c),C($$.$$.fragment,c),C(R$.$$.fragment,c),C(x_.$$.fragment,c),C($_.$$.fragment,c),C(P$.$$.fragment,c),C(B$.$$.fragment,c),C(I$.$$.fragment,c),C(q$.$$.fragment,c),C(R_.$$.fragment,c),C(j$.$$.fragment,c),C(ob.$$.fragment,c),C(D$.$$.fragment,c),C(G$.$$.fragment,c),C(V$.$$.fragment,c),C(tb.$$.fragment,c),C(X$.$$.fragment,c),C(Kb.$$.fragment,c),C(z$.$$.fragment,c),C(Q$.$$.fragment,c),C(U$.$$.fragment,c),C(ov.$$.fragment,c),C(H$.$$.fragment,c),C(zv.$$.fragment,c),C(J$.$$.fragment,c),C(Y$.$$.fragment,c),C(K$.$$.fragment,c),C(Wv.$$.fragment,c),C(ek.$$.fragment,c),C(Yv.$$.fragment,c),C(rk.$$.fragment,c),C(tk.$$.fragment,c),C(nk.$$.fragment,c),C(Kv.$$.fragment,c),C(sk.$$.fragment,c),C(DF.$$.fragment,c),C(lk.$$.fragment,c),C(ik.$$.fragment,c),C(mk.$$.fragment,c),C(OF.$$.fragment,c),C(ck.$$.fragment,c),C(mT.$$.fragment,c),C(fk.$$.fragment,c),C(gk.$$.fragment,c),C(uk.$$.fragment,c),C(fT.$$.fragment,c),C(pk.$$.fragment,c),C(pM.$$.fragment,c),C(_k.$$.fragment,c),C(bk.$$.fragment,c),C(Fk.$$.fragment,c),C(bM.$$.fragment,c),C(Tk.$$.fragment,c),C(ZM.$$.fragment,c),C(Mk.$$.fragment,c),C(Ek.$$.fragment,c),C(wk.$$.fragment,c),C(eE.$$.fragment,c),C(Ak.$$.fragment,c),C(dE.$$.fragment,c),C(Lk.$$.fragment,c),C(yk.$$.fragment,c),C($k.$$.fragment,c),C(cE.$$.fragment,c),C(kk.$$.fragment,c),C(e4.$$.fragment,c),C(Sk.$$.fragment,c),C(Rk.$$.fragment,c),C(Bk.$$.fragment,c),C(r4.$$.fragment,c),C(Ik.$$.fragment,c),C(Z4.$$.fragment,c),C(Nk.$$.fragment,c),C(qk.$$.fragment,c),C(Dk.$$.fragment,c),C(eC.$$.fragment,c),C(Gk.$$.fragment,c),C(tC.$$.fragment,c),C(Ok.$$.fragment,c),C(Vk.$$.fragment,c),C(zk.$$.fragment,c),C(nC.$$.fragment,c),C(Qk.$$.fragment,c),C(mC.$$.fragment,c),C(Wk.$$.fragment,c),C(Uk.$$.fragment,c),C(Jk.$$.fragment,c),C(fC.$$.fragment,c),C(Yk.$$.fragment,c),C(xC.$$.fragment,c),C(Zk.$$.fragment,c),C(Kk.$$.fragment,c),C(oS.$$.fragment,c),C(kC.$$.fragment,c),C(rS.$$.fragment,c),C(PC.$$.fragment,c),C(tS.$$.fragment,c),C(aS.$$.fragment,c),C(sS.$$.fragment,c),C(IC.$$.fragment,c),C(lS.$$.fragment,c),C(jC.$$.fragment,c),C(iS.$$.fragment,c),C(dS.$$.fragment,c),C(cS.$$.fragment,c),C(GC.$$.fragment,c),C(fS.$$.fragment,c),C(XC.$$.fragment,c),C(gS.$$.fragment,c),C(hS.$$.fragment,c),C(pS.$$.fragment,c),C(QC.$$.fragment,c),C(_S.$$.fragment,c),C(t3.$$.fragment,c),C(bS.$$.fragment,c),C(vS.$$.fragment,c),C(TS.$$.fragment,c),C(n3.$$.fragment,c),C(MS.$$.fragment,c),C(f3.$$.fragment,c),C(ES.$$.fragment,c),C(CS.$$.fragment,c),C(AS.$$.fragment,c),C(h3.$$.fragment,c),C(LS.$$.fragment,c),C(A3.$$.fragment,c),C(yS.$$.fragment,c),C(xS.$$.fragment,c),C(kS.$$.fragment,c),C(y3.$$.fragment,c),C(SS.$$.fragment,c),C(R3.$$.fragment,c),C(RS.$$.fragment,c),C(PS.$$.fragment,c),C(IS.$$.fragment,c),C(B3.$$.fragment,c),C(NS.$$.fragment,c),C(O3.$$.fragment,c),C(qS.$$.fragment,c),C(jS.$$.fragment,c),C(GS.$$.fragment,c),C(X3.$$.fragment,c),C(OS.$$.fragment,c),C(J3.$$.fragment,c),C(VS.$$.fragment,c),C(XS.$$.fragment,c),C(QS.$$.fragment,c),C(Z3.$$.fragment,c),C(WS.$$.fragment,c),C(n5.$$.fragment,c),C(US.$$.fragment,c),C(HS.$$.fragment,c),C(YS.$$.fragment,c),C(l5.$$.fragment,c),C(ZS.$$.fragment,c),C(m5.$$.fragment,c),C(KS.$$.fragment,c),C(eR.$$.fragment,c),C(rR.$$.fragment,c),C(f5.$$.fragment,c),C(tR.$$.fragment,c),C(v5.$$.fragment,c),C(aR.$$.fragment,c),C(nR.$$.fragment,c),C(lR.$$.fragment,c),C(T5.$$.fragment,c),C(iR.$$.fragment,c),C(C5.$$.fragment,c),C(dR.$$.fragment,c),C(mR.$$.fragment,c),C(fR.$$.fragment,c),C(A5.$$.fragment,c),C(gR.$$.fragment,c),C(x5.$$.fragment,c),C(hR.$$.fragment,c),C(uR.$$.fragment,c),C(_R.$$.fragment,c),C(k5.$$.fragment,c),C(bR.$$.fragment,c),C(B0.$$.fragment,c),C(vR.$$.fragment,c),C(FR.$$.fragment,c),C(MR.$$.fragment,c),C(N0.$$.fragment,c),C(ER.$$.fragment,c),C(lw.$$.fragment,c),C(CR.$$.fragment,c),C(wR.$$.fragment,c),C(LR.$$.fragment,c),C(dw.$$.fragment,c),C(yR.$$.fragment,c),C(Cw.$$.fragment,c),C(xR.$$.fragment,c),C($R.$$.fragment,c),C(SR.$$.fragment,c),C(Aw.$$.fragment,c),C(RR.$$.fragment,c),C(Iw.$$.fragment,c),C(PR.$$.fragment,c),C(BR.$$.fragment,c),C(NR.$$.fragment,c),C(qw.$$.fragment,c),C(qR.$$.fragment,c),C(Ow.$$.fragment,c),C(jR.$$.fragment,c),C(DR.$$.fragment,c),C(OR.$$.fragment,c),C(Xw.$$.fragment,c),C(VR.$$.fragment,c),C(fA.$$.fragment,c),C(XR.$$.fragment,c),C(zR.$$.fragment,c),C(WR.$$.fragment,c),C(hA.$$.fragment,c),C(UR.$$.fragment,c),C(wA.$$.fragment,c),C(HR.$$.fragment,c),C(JR.$$.fragment,c),C(ZR.$$.fragment,c),C(LA.$$.fragment,c),C(KR.$$.fragment,c),C(r6.$$.fragment,c),C(eP.$$.fragment,c),C(oP.$$.fragment,c),C(tP.$$.fragment,c),C(a6.$$.fragment,c),C(aP.$$.fragment,c),C(M6.$$.fragment,c),C(nP.$$.fragment,c),C(sP.$$.fragment,c),C(iP.$$.fragment,c),C(C6.$$.fragment,c),C(dP.$$.fragment,c),C(L6.$$.fragment,c),C(cP.$$.fragment,c),C(fP.$$.fragment,c),C(hP.$$.fragment,c),C(x6.$$.fragment,c),C(uP.$$.fragment,c),C(k6.$$.fragment,c),C(pP.$$.fragment,c),C(_P.$$.fragment,c),C(vP.$$.fragment,c),C(R6.$$.fragment,c),C(FP.$$.fragment,c),C(B6.$$.fragment,c),C(TP.$$.fragment,c),C(MP.$$.fragment,c),C(CP.$$.fragment,c),C(N6.$$.fragment,c),C(wP.$$.fragment,c),C(s7.$$.fragment,c),C(AP.$$.fragment,c),C(LP.$$.fragment,c),C(xP.$$.fragment,c),C(i7.$$.fragment,c),C($P.$$.fragment,c),C($7.$$.fragment,c),C(kP.$$.fragment,c),C(SP.$$.fragment,c),C(PP.$$.fragment,c),C(S7.$$.fragment,c),C(BP.$$.fragment,c),C(P7.$$.fragment,c),C(IP.$$.fragment,c),C(NP.$$.fragment,c),C(jP.$$.fragment,c),C(I7.$$.fragment,c),C(DP.$$.fragment,c),C(j7.$$.fragment,c),C(OP.$$.fragment,c),C(VP.$$.fragment,c),C(zP.$$.fragment,c),C(G7.$$.fragment,c),C(QP.$$.fragment,c),C(u8.$$.fragment,c),C(WP.$$.fragment,c),C(UP.$$.fragment,c),C(JP.$$.fragment,c),C(_8.$$.fragment,c),C(YP.$$.fragment,c),C(y8.$$.fragment,c),C(ZP.$$.fragment,c),C(KP.$$.fragment,c),C(oB.$$.fragment,c),C($8.$$.fragment,c),C(rB.$$.fragment,c),C(X8.$$.fragment,c),C(tB.$$.fragment,c),C(aB.$$.fragment,c),C(sB.$$.fragment,c),C(Q8.$$.fragment,c),C(lB.$$.fragment,c),C(tL.$$.fragment,c),C(iB.$$.fragment,c),C(dB.$$.fragment,c),C(cB.$$.fragment,c),C(nL.$$.fragment,c),C(fB.$$.fragment,c),C(pL.$$.fragment,c),C(gB.$$.fragment,c),C(hB.$$.fragment,c),C(pB.$$.fragment,c),C(bL.$$.fragment,c),C(_B.$$.fragment,c),C(xL.$$.fragment,c),C(bB.$$.fragment,c),C(vB.$$.fragment,c),C(TB.$$.fragment,c),C(kL.$$.fragment,c),C(MB.$$.fragment,c),C(OL.$$.fragment,c),C(EB.$$.fragment,c),C(CB.$$.fragment,c),C(AB.$$.fragment,c),C(XL.$$.fragment,c),C(LB.$$.fragment,c),C(KL.$$.fragment,c),C(yB.$$.fragment,c),C(xB.$$.fragment,c),C(kB.$$.fragment,c),C(oy.$$.fragment,c),C(SB.$$.fragment,c),C(my.$$.fragment,c),C(RB.$$.fragment,c),C(PB.$$.fragment,c),C(IB.$$.fragment,c),C(fy.$$.fragment,c),C(NB.$$.fragment,c),C(hy.$$.fragment,c),C(qB.$$.fragment,c),C(jB.$$.fragment,c),C(GB.$$.fragment,c),C(py.$$.fragment,c),C(OB.$$.fragment,c),C(vy.$$.fragment,c),C(XB.$$.fragment,c),C(zB.$$.fragment,c),C(WB.$$.fragment,c),C(Ty.$$.fragment,c),C(UB.$$.fragment,c),C(Ey.$$.fragment,c),Ono=!1},d(c){t(g),c&&t(v),c&&t(u),w(d),c&&t(zf),c&&t(Tt),c&&t(Xe),c&&t(He),c&&t(Wf),w(on,c),c&&t(Je),c&&t(Ae),c&&t(ko),c&&t(rn),c&&t(wto),c&&t(wd),w(d$),c&&t(Ato),c&&t(hs),c&&t(Lto),w(m$,c),c&&t(yto),c&&t(LN),c&&t(xto),w(Jf,c),c&&t($to),c&&t(Ad),w(c$),c&&t(kto),c&&t(So),w(f$),w(u$),w(wu),w(p$),c&&t(Sto),c&&t(yd),w(_$),c&&t(Rto),c&&t(Ro),w(b$),w(T$),w(mp),w(M$),c&&t(Pto),c&&t(xd),w(E$),c&&t(Bto),c&&t(Po),w(C$),w(L$),w(t_),w(a_),w(y$),c&&t(Ito),c&&t($d),w(x$),c&&t(Nto),c&&t(Bo),w($$),w(R$),w(x_),w($_),w(P$),c&&t(qto),c&&t(Sd),w(B$),c&&t(jto),c&&t(Io),w(I$),w(q$),w(R_),w(j$),w(ob),c&&t(Dto),c&&t(Bd),w(D$),c&&t(Gto),c&&t(No),w(G$),w(V$),w(tb),w(X$),w(Kb),c&&t(Oto),c&&t(qd),w(z$),c&&t(Vto),c&&t(qo),w(Q$),w(U$),w(ov),w(H$),w(zv),c&&t(Xto),c&&t(Gd),w(J$),c&&t(zto),c&&t(jo),w(Y$),w(K$),w(Wv),w(ek),w(Yv),c&&t(Qto),c&&t(Xd),w(rk),c&&t(Wto),c&&t(Do),w(tk),w(nk),w(Kv),w(sk),w(DF),c&&t(Uto),c&&t(Wd),w(lk),c&&t(Hto),c&&t(Go),w(ik),w(mk),w(OF),w(ck),w(mT),c&&t(Jto),c&&t(Jd),w(fk),c&&t(Yto),c&&t(Oo),w(gk),w(uk),w(fT),w(pk),w(pM),c&&t(Zto),c&&t(Kd),w(_k),c&&t(Kto),c&&t(Vo),w(bk),w(Fk),w(bM),w(Tk),w(ZM),c&&t(eao),c&&t(rm),w(Mk),c&&t(oao),c&&t(Xo),w(Ek),w(wk),w(eE),w(Ak),w(dE),c&&t(rao),c&&t(nm),w(Lk),c&&t(tao),c&&t(zo),w(yk),w($k),w(cE),w(kk),w(e4),c&&t(aao),c&&t(im),w(Sk),c&&t(nao),c&&t(Qo),w(Rk),w(Bk),w(r4),w(Ik),w(Z4),c&&t(sao),c&&t(cm),w(Nk),c&&t(lao),c&&t(Wo),w(qk),w(Dk),w(eC),w(Gk),w(tC),c&&t(iao),c&&t(hm),w(Ok),c&&t(dao),c&&t(Uo),w(Vk),w(zk),w(nC),w(Qk),w(mC),c&&t(mao),c&&t(bm),w(Wk),c&&t(cao),c&&t(Ho),w(Uk),w(Jk),w(fC),w(Yk),w(xC),c&&t(fao),c&&t(Tm),w(Zk),c&&t(gao),c&&t(Jo),w(Kk),w(oS),w(kC),w(rS),w(PC),c&&t(hao),c&&t(Cm),w(tS),c&&t(uao),c&&t(Yo),w(aS),w(sS),w(IC),w(lS),w(jC),c&&t(pao),c&&t(Lm),w(iS),c&&t(_ao),c&&t(Zo),w(dS),w(cS),w(GC),w(fS),w(XC),c&&t(bao),c&&t($m),w(gS),c&&t(vao),c&&t(Ko),w(hS),w(pS),w(QC),w(_S),w(t3),c&&t(Fao),c&&t(Rm),w(bS),c&&t(Tao),c&&t(er),w(vS),w(TS),w(n3),w(MS),w(f3),c&&t(Mao),c&&t(Im),w(ES),c&&t(Eao),c&&t(or),w(CS),w(AS),w(h3),w(LS),w(A3),c&&t(Cao),c&&t(jm),w(yS),c&&t(wao),c&&t(rr),w(xS),w(kS),w(y3),w(SS),w(R3),c&&t(Aao),c&&t(Vm),w(RS),c&&t(Lao),c&&t(tr),w(PS),w(IS),w(B3),w(NS),w(O3),c&&t(yao),c&&t(Qm),w(qS),c&&t(xao),c&&t(ar),w(jS),w(GS),w(X3),w(OS),w(J3),c&&t($ao),c&&t(Hm),w(VS),c&&t(kao),c&&t(nr),w(XS),w(QS),w(Z3),w(WS),w(n5),c&&t(Sao),c&&t(Zm),w(US),c&&t(Rao),c&&t(sr),w(HS),w(YS),w(l5),w(ZS),w(m5),c&&t(Pao),c&&t(oc),w(KS),c&&t(Bao),c&&t(lr),w(eR),w(rR),w(f5),w(tR),w(v5),c&&t(Iao),c&&t(ac),w(aR),c&&t(Nao),c&&t(ir),w(nR),w(lR),w(T5),w(iR),w(C5),c&&t(qao),c&&t(lc),w(dR),c&&t(jao),c&&t(dr),w(mR),w(fR),w(A5),w(gR),w(x5),c&&t(Dao),c&&t(mc),w(hR),c&&t(Gao),c&&t(mr),w(uR),w(_R),w(k5),w(bR),w(B0),c&&t(Oao),c&&t(gc),w(vR),c&&t(Vao),c&&t(cr),w(FR),w(MR),w(N0),w(ER),w(lw),c&&t(Xao),c&&t(pc),w(CR),c&&t(zao),c&&t(fr),w(wR),w(LR),w(dw),w(yR),w(Cw),c&&t(Qao),c&&t(vc),w(xR),c&&t(Wao),c&&t(gr),w($R),w(SR),w(Aw),w(RR),w(Iw),c&&t(Uao),c&&t(Mc),w(PR),c&&t(Hao),c&&t(hr),w(BR),w(NR),w(qw),w(qR),w(Ow),c&&t(Jao),c&&t(Ac),w(jR),c&&t(Yao),c&&t(ur),w(DR),w(OR),w(Xw),w(VR),w(fA),c&&t(Zao),c&&t(xc),w(XR),c&&t(Kao),c&&t(pr),w(zR),w(WR),w(hA),w(UR),w(wA),c&&t(eno),c&&t(Sc),w(HR),c&&t(ono),c&&t(_r),w(JR),w(ZR),w(LA),w(KR),w(r6),c&&t(rno),c&&t(Bc),w(eP),c&&t(tno),c&&t(br),w(oP),w(tP),w(a6),w(aP),w(M6),c&&t(ano),c&&t(qc),w(nP),c&&t(nno),c&&t(vr),w(sP),w(iP),w(C6),w(dP),w(L6),c&&t(sno),c&&t(Gc),w(cP),c&&t(lno),c&&t(Fr),w(fP),w(hP),w(x6),w(uP),w(k6),c&&t(ino),c&&t(Xc),w(pP),c&&t(dno),c&&t(Tr),w(_P),w(vP),w(R6),w(FP),w(B6),c&&t(mno),c&&t(Wc),w(TP),c&&t(cno),c&&t(Mr),w(MP),w(CP),w(N6),w(wP),w(s7),c&&t(fno),c&&t(Jc),w(AP),c&&t(gno),c&&t(Er),w(LP),w(xP),w(i7),w($P),w($7),c&&t(hno),c&&t(Kc),w(kP),c&&t(uno),c&&t(Cr),w(SP),w(PP),w(S7),w(BP),w(P7),c&&t(pno),c&&t(rf),w(IP),c&&t(_no),c&&t(wr),w(NP),w(jP),w(I7),w(DP),w(j7),c&&t(bno),c&&t(nf),w(OP),c&&t(vno),c&&t(Ar),w(VP),w(zP),w(G7),w(QP),w(u8),c&&t(Fno),c&&t(df),w(WP),c&&t(Tno),c&&t(Lr),w(UP),w(JP),w(_8),w(YP),w(y8),c&&t(Mno),c&&t(ff),w(ZP),c&&t(Eno),c&&t(yr),w(KP),w(oB),w($8),w(rB),w(X8),c&&t(Cno),c&&t(uf),w(tB),c&&t(wno),c&&t(xr),w(aB),w(sB),w(Q8),w(lB),w(tL),c&&t(Ano),c&&t(bf),w(iB),c&&t(Lno),c&&t($r),w(dB),w(cB),w(nL),w(fB),w(pL),c&&t(yno),c&&t(Tf),w(gB),c&&t(xno),c&&t(kr),w(hB),w(pB),w(bL),w(_B),w(xL),c&&t($no),c&&t(Cf),w(bB),c&&t(kno),c&&t(Sr),w(vB),w(TB),w(kL),w(MB),w(OL),c&&t(Sno),c&&t(Lf),w(EB),c&&t(Rno),c&&t(Rr),w(CB),w(AB),w(XL),w(LB),w(KL),c&&t(Pno),c&&t($f),w(yB),c&&t(Bno),c&&t(Pr),w(xB),w(kB),w(oy),w(SB),w(my),c&&t(Ino),c&&t(Rf),w(RB),c&&t(Nno),c&&t(Br),w(PB),w(IB),w(fy),w(NB),w(hy),c&&t(qno),c&&t(If),w(qB),c&&t(jno),c&&t(Ir),w(jB),w(GB),w(py),w(OB),w(vy),c&&t(Dno),c&&t(jf),w(XB),c&&t(Gno),c&&t(Nr),w(zB),w(WB),w(Ty),w(UB),w(Ey)}}}const D0a={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForDepthEstimation",title:"AutoModelForDepthEstimation"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForDocumentQuestionAnswering",title:"AutoModelForDocumentQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVideoClassification",title:"AutoModelForVideoClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.AutoModelForZeroShotObjectDetection",title:"AutoModelForZeroShotObjectDetection"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForSemanticSegmentation",title:"TFAutoModelForSemanticSegmentation"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForDocumentQuestionAnswering",title:"TFAutoModelForDocumentQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function G0a($){return L3a(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class U0a extends E3a{constructor(g){super();C3a(this,g,G0a,j0a,w3a,{})}}export{U0a as default,D0a as metadata};
