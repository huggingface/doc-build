import{S as v3a,i as F3a,s as T3a,e as a,k as l,w as F,t as o,M as M3a,c as n,d as t,m as i,a as s,x as T,h as r,b as m,G as e,g as b,y as M,q as E,o as C,B as w,v as E3a,L as q}from"../../chunks/vendor-hf-doc-builder.js";import{T as qAt}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as B}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as oe}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as N}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function C3a($){let g,v,u,f,p,d,h,$o,_d,Xf,Tt,bd,vd,n$,zf,Xe,He,Fd,ms,s$,cs,fs,l$,Td,gs,i$,Md,Qf,on;return{c(){g=a("p"),v=o("If your "),u=a("code"),f=o("NewModelConfig"),p=o(" is a subclass of "),d=a("code"),h=o("~transformer.PretrainedConfig"),$o=o(`, make sure its
`),_d=a("code"),Xf=o("model_type"),Tt=o(" attribute is set to the same key you use when registering the config (here "),bd=a("code"),vd=o('"new-model"'),n$=o(")."),zf=l(),Xe=a("p"),He=o("Likewise, if your "),Fd=a("code"),ms=o("NewModel"),s$=o(" is a subclass of "),cs=a("a"),fs=o("PreTrainedModel"),l$=o(`, make sure its
`),Td=a("code"),gs=o("config_class"),i$=o(` attribute is set to the same class you use when registering the model (here
`),Md=a("code"),Qf=o("NewModelConfig"),on=o(")."),this.h()},l(Je){g=n(Je,"P",{});var Ae=s(g);v=r(Ae,"If your "),u=n(Ae,"CODE",{});var TN=s(u);f=r(TN,"NewModelConfig"),TN.forEach(t),p=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var Ed=s(d);h=r(Ed,"~transformer.PretrainedConfig"),Ed.forEach(t),$o=r(Ae,`, make sure its
`),_d=n(Ae,"CODE",{});var MN=s(_d);Xf=r(MN,"model_type"),MN.forEach(t),Tt=r(Ae," attribute is set to the same key you use when registering the config (here "),bd=n(Ae,"CODE",{});var EN=s(bd);vd=r(EN,'"new-model"'),EN.forEach(t),n$=r(Ae,")."),Ae.forEach(t),zf=i(Je),Xe=n(Je,"P",{});var ko=s(Xe);He=r(ko,"Likewise, if your "),Fd=n(ko,"CODE",{});var rn=s(Fd);ms=r(rn,"NewModel"),rn.forEach(t),s$=r(ko," is a subclass of "),cs=n(ko,"A",{href:!0});var CN=s(cs);fs=r(CN,"PreTrainedModel"),CN.forEach(t),l$=r(ko,`, make sure its
`),Td=n(ko,"CODE",{});var Wf=s(Td);gs=r(Wf,"config_class"),Wf.forEach(t),i$=r(ko,` attribute is set to the same class you use when registering the model (here
`),Md=n(ko,"CODE",{});var wN=s(Md);Qf=r(wN,"NewModelConfig"),wN.forEach(t),on=r(ko,")."),ko.forEach(t),this.h()},h(){m(cs,"href","/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel")},m(Je,Ae){b(Je,g,Ae),e(g,v),e(g,u),e(u,f),e(g,p),e(g,d),e(d,h),e(g,$o),e(g,_d),e(_d,Xf),e(g,Tt),e(g,bd),e(bd,vd),e(g,n$),b(Je,zf,Ae),b(Je,Xe,Ae),e(Xe,He),e(Xe,Fd),e(Fd,ms),e(Xe,s$),e(Xe,cs),e(cs,fs),e(Xe,l$),e(Xe,Td),e(Td,gs),e(Xe,i$),e(Xe,Md),e(Md,Qf),e(Xe,on)},d(Je){Je&&t(g),Je&&t(zf),Je&&t(Xe)}}}function w3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function A3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function L3a($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var $o=s(u);f=r($o,"use_auth_token=True"),$o.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(d){d&&t(g)}}}function y3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function x3a($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var $o=s(u);f=r($o,"use_auth_token=True"),$o.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(d){d&&t(g)}}}function $3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function k3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function S3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function R3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function P3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function B3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function I3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function N3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDepthEstimation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForDepthEstimation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDepthEstimation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function q3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDepthEstimation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForDepthEstimation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForDepthEstimation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForDepthEstimation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDepthEstimation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function D3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function j3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function G3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function O3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function V3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function X3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function z3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Q3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function W3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function U3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function H3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function J3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Y3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Z3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function K3a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function e5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function o5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = AutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function r5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/layoutlm_tf_model_config.json")
model = AutoModelForDocumentQuestionAnswering.from_pretrained(
    "./tf_model/layoutlm_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/layoutlm_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/layoutlm_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function t5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function a5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function n5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVideoClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function s5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVideoClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function l5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function i5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function d5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function m5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function c5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function f5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function g5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function h5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function u5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function p5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function _5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function b5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function v5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function F5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function T5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function M5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function E5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function C5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function w5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function A5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function L5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function y5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function x5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function $5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function k5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForZeroShotObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForZeroShotObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForZeroShotObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function S5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForZeroShotObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForZeroShotObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForZeroShotObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForZeroShotObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForZeroShotObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function R5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function P5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function B5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function I5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function N5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function q5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function D5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function j5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function G5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function O5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSemanticSegmentation.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function V5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function X5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function z5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Q5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function W5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function U5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function H5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function J5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Y5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Z5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function K5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function e0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function o0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function r0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/layoutlm_pt_model_config.json")
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
    "./pt_model/layoutlm_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/layoutlm_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/layoutlm_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function t0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function a0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function n0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function s0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function l0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function i0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function d0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function m0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function c0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function f0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function g0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function h0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function u0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function p0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function _0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function b0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function v0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function F0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function T0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function M0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function E0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function C0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function w0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function A0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function L0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function y0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function x0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function $0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function k0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function S0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function R0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function P0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function B0a($){let g,v,u,f,p,d,h,$o,_d,Xf,Tt,bd,vd,n$,zf,Xe,He,Fd,ms,s$,cs,fs,l$,Td,gs,i$,Md,Qf,on,Je,Ae,TN,Ed,MN,EN,ko,rn,CN,Wf,wN,dio,Cto,Cd,Uf,dfe,d$,mio,mfe,cio,wto,hs,fio,cfe,gio,hio,ffe,uio,pio,Ato,m$,Lto,AN,_io,yto,Hf,xto,wd,Jf,gfe,c$,bio,hfe,vio,$to,So,f$,Fio,g$,Tio,LN,Mio,Eio,Cio,h$,wio,ufe,Aio,Lio,yio,qr,u$,xio,pfe,$io,kio,Ad,Sio,_fe,Rio,Pio,bfe,Bio,Iio,Nio,A,Yf,vfe,qio,Dio,yN,jio,Gio,Oio,Zf,Ffe,Vio,Xio,xN,zio,Qio,Wio,Kf,Tfe,Uio,Hio,$N,Jio,Yio,Zio,eg,Mfe,Kio,edo,kN,odo,rdo,tdo,og,Efe,ado,ndo,SN,sdo,ldo,ido,rg,Cfe,ddo,mdo,RN,cdo,fdo,gdo,tg,wfe,hdo,udo,PN,pdo,_do,bdo,ag,Afe,vdo,Fdo,BN,Tdo,Mdo,Edo,ng,Lfe,Cdo,wdo,IN,Ado,Ldo,ydo,sg,yfe,xdo,$do,NN,kdo,Sdo,Rdo,lg,xfe,Pdo,Bdo,qN,Ido,Ndo,qdo,ig,$fe,Ddo,jdo,DN,Gdo,Odo,Vdo,dg,kfe,Xdo,zdo,jN,Qdo,Wdo,Udo,mg,Sfe,Hdo,Jdo,GN,Ydo,Zdo,Kdo,cg,Rfe,emo,omo,ON,rmo,tmo,amo,fg,Pfe,nmo,smo,VN,lmo,imo,dmo,gg,Bfe,mmo,cmo,XN,fmo,gmo,hmo,hg,Ife,umo,pmo,zN,_mo,bmo,vmo,ug,Nfe,Fmo,Tmo,QN,Mmo,Emo,Cmo,pg,qfe,wmo,Amo,WN,Lmo,ymo,xmo,_g,Dfe,$mo,kmo,UN,Smo,Rmo,Pmo,bg,jfe,Bmo,Imo,HN,Nmo,qmo,Dmo,vg,Gfe,jmo,Gmo,JN,Omo,Vmo,Xmo,Fg,Ofe,zmo,Qmo,YN,Wmo,Umo,Hmo,Tg,Vfe,Jmo,Ymo,ZN,Zmo,Kmo,eco,Mg,Xfe,oco,rco,KN,tco,aco,nco,Eg,zfe,sco,lco,eq,ico,dco,mco,Cg,Qfe,cco,fco,oq,gco,hco,uco,wg,Wfe,pco,_co,rq,bco,vco,Fco,Ag,Ufe,Tco,Mco,tq,Eco,Cco,wco,Lg,Hfe,Aco,Lco,aq,yco,xco,$co,yg,Jfe,kco,Sco,nq,Rco,Pco,Bco,xg,Yfe,Ico,Nco,sq,qco,Dco,jco,$g,Zfe,Gco,Oco,lq,Vco,Xco,zco,kg,Kfe,Qco,Wco,iq,Uco,Hco,Jco,Sg,ege,Yco,Zco,dq,Kco,efo,ofo,Rg,oge,rfo,tfo,mq,afo,nfo,sfo,Pg,rge,lfo,ifo,cq,dfo,mfo,cfo,Bg,tge,ffo,gfo,fq,hfo,ufo,pfo,Ig,age,_fo,bfo,gq,vfo,Ffo,Tfo,Ng,nge,Mfo,Efo,hq,Cfo,wfo,Afo,qg,sge,Lfo,yfo,uq,xfo,$fo,kfo,Dg,lge,Sfo,Rfo,pq,Pfo,Bfo,Ifo,jg,ige,Nfo,qfo,_q,Dfo,jfo,Gfo,Gg,dge,Ofo,Vfo,bq,Xfo,zfo,Qfo,Og,mge,Wfo,Ufo,vq,Hfo,Jfo,Yfo,Vg,cge,Zfo,Kfo,Fq,ego,ogo,rgo,Xg,fge,tgo,ago,Tq,ngo,sgo,lgo,zg,gge,igo,dgo,Mq,mgo,cgo,fgo,Qg,hge,ggo,hgo,Eq,ugo,pgo,_go,Wg,uge,bgo,vgo,Cq,Fgo,Tgo,Mgo,Ug,pge,Ego,Cgo,wq,wgo,Ago,Lgo,Hg,_ge,ygo,xgo,Aq,$go,kgo,Sgo,Jg,bge,Rgo,Pgo,Lq,Bgo,Igo,Ngo,Yg,vge,qgo,Dgo,yq,jgo,Ggo,Ogo,Zg,Fge,Vgo,Xgo,xq,zgo,Qgo,Wgo,Kg,Tge,Ugo,Hgo,$q,Jgo,Ygo,Zgo,eh,Mge,Kgo,eho,kq,oho,rho,tho,oh,Ege,aho,nho,Sq,sho,lho,iho,rh,Cge,dho,mho,Rq,cho,fho,gho,th,wge,hho,uho,Pq,pho,_ho,bho,ah,Age,vho,Fho,Bq,Tho,Mho,Eho,nh,Lge,Cho,who,Iq,Aho,Lho,yho,sh,yge,xho,$ho,Nq,kho,Sho,Rho,lh,xge,Pho,Bho,qq,Iho,Nho,qho,ih,$ge,Dho,jho,Dq,Gho,Oho,Vho,dh,kge,Xho,zho,jq,Qho,Who,Uho,mh,Sge,Hho,Jho,Gq,Yho,Zho,Kho,ch,Rge,euo,ouo,Oq,ruo,tuo,auo,fh,Pge,nuo,suo,Vq,luo,iuo,duo,gh,Bge,muo,cuo,Xq,fuo,guo,huo,hh,Ige,uuo,puo,zq,_uo,buo,vuo,uh,Nge,Fuo,Tuo,Qq,Muo,Euo,Cuo,ph,qge,wuo,Auo,Wq,Luo,yuo,xuo,_h,Dge,$uo,kuo,Uq,Suo,Ruo,Puo,bh,jge,Buo,Iuo,Hq,Nuo,quo,Duo,vh,Gge,juo,Guo,Jq,Ouo,Vuo,Xuo,Fh,Oge,zuo,Quo,Yq,Wuo,Uuo,Huo,Th,Vge,Juo,Yuo,Zq,Zuo,Kuo,epo,Mh,Xge,opo,rpo,Kq,tpo,apo,npo,Eh,zge,spo,lpo,eD,ipo,dpo,mpo,Ch,Qge,cpo,fpo,oD,gpo,hpo,upo,wh,Wge,ppo,_po,rD,bpo,vpo,Fpo,Ah,Uge,Tpo,Mpo,tD,Epo,Cpo,wpo,Lh,Hge,Apo,Lpo,aD,ypo,xpo,$po,yh,Jge,kpo,Spo,nD,Rpo,Ppo,Bpo,xh,Yge,Ipo,Npo,sD,qpo,Dpo,jpo,$h,Zge,Gpo,Opo,lD,Vpo,Xpo,zpo,kh,Kge,Qpo,Wpo,iD,Upo,Hpo,Jpo,Sh,ehe,Ypo,Zpo,dD,Kpo,e_o,o_o,Rh,ohe,r_o,t_o,mD,a_o,n_o,s_o,Ph,rhe,l_o,i_o,cD,d_o,m_o,c_o,Bh,the,f_o,g_o,fD,h_o,u_o,p_o,Ih,ahe,__o,b_o,gD,v_o,F_o,T_o,Nh,nhe,M_o,E_o,hD,C_o,w_o,A_o,qh,she,L_o,y_o,uD,x_o,$_o,k_o,Dh,lhe,S_o,R_o,pD,P_o,B_o,I_o,jh,ihe,N_o,q_o,_D,D_o,j_o,G_o,Gh,dhe,O_o,V_o,bD,X_o,z_o,Q_o,Oh,mhe,W_o,U_o,vD,H_o,J_o,Y_o,Vh,che,Z_o,K_o,FD,e1o,o1o,r1o,Xh,fhe,t1o,a1o,TD,n1o,s1o,l1o,zh,ghe,i1o,d1o,MD,m1o,c1o,f1o,Qh,hhe,g1o,h1o,ED,u1o,p1o,_1o,Wh,uhe,b1o,v1o,CD,F1o,T1o,M1o,Uh,phe,E1o,C1o,wD,w1o,A1o,L1o,Hh,_he,y1o,x1o,AD,$1o,k1o,S1o,Jh,bhe,R1o,P1o,LD,B1o,I1o,N1o,Yh,vhe,q1o,D1o,yD,j1o,G1o,O1o,Zh,Fhe,V1o,X1o,xD,z1o,Q1o,W1o,Kh,The,U1o,H1o,$D,J1o,Y1o,Z1o,eu,Mhe,K1o,e2o,kD,o2o,r2o,t2o,ou,Ehe,a2o,n2o,SD,s2o,l2o,i2o,ru,Che,d2o,m2o,RD,c2o,f2o,g2o,tu,whe,h2o,u2o,PD,p2o,_2o,b2o,au,Ahe,v2o,F2o,BD,T2o,M2o,E2o,nu,Lhe,C2o,w2o,ID,A2o,L2o,y2o,su,yhe,x2o,$2o,ND,k2o,S2o,R2o,lu,xhe,P2o,B2o,qD,I2o,N2o,q2o,iu,$he,D2o,j2o,DD,G2o,O2o,V2o,du,khe,X2o,z2o,jD,Q2o,W2o,U2o,mu,She,H2o,J2o,GD,Y2o,Z2o,K2o,cu,Rhe,ebo,obo,OD,rbo,tbo,abo,fu,Phe,nbo,sbo,VD,lbo,ibo,dbo,gu,Bhe,mbo,cbo,XD,fbo,gbo,hbo,hu,Ihe,ubo,pbo,zD,_bo,bbo,vbo,uu,Nhe,Fbo,Tbo,QD,Mbo,Ebo,Cbo,pu,qhe,wbo,Abo,WD,Lbo,ybo,xbo,_u,Dhe,$bo,kbo,UD,Sbo,Rbo,Pbo,bu,jhe,Bbo,Ibo,HD,Nbo,qbo,Dbo,vu,Ghe,jbo,Gbo,JD,Obo,Vbo,Xbo,Fu,Ohe,zbo,Qbo,YD,Wbo,Ubo,Hbo,Tu,Vhe,Jbo,Ybo,ZD,Zbo,Kbo,evo,Mu,Xhe,ovo,rvo,KD,tvo,avo,nvo,Eu,zhe,svo,lvo,ej,ivo,dvo,mvo,Cu,cvo,wu,p$,fvo,Qhe,gvo,kto,Ld,Au,Whe,_$,hvo,Uhe,uvo,Sto,Ro,b$,pvo,v$,_vo,oj,bvo,vvo,Fvo,F$,Tvo,Hhe,Mvo,Evo,Cvo,Dr,T$,wvo,Jhe,Avo,Lvo,tn,yvo,Yhe,xvo,$vo,Zhe,kvo,Svo,Khe,Rvo,Pvo,Bvo,k,us,eue,Ivo,Nvo,rj,qvo,Dvo,tj,jvo,Gvo,Ovo,ps,oue,Vvo,Xvo,aj,zvo,Qvo,nj,Wvo,Uvo,Hvo,_s,rue,Jvo,Yvo,sj,Zvo,Kvo,lj,eFo,oFo,rFo,Lu,tue,tFo,aFo,ij,nFo,sFo,lFo,bs,aue,iFo,dFo,dj,mFo,cFo,mj,fFo,gFo,hFo,yu,nue,uFo,pFo,cj,_Fo,bFo,vFo,xu,sue,FFo,TFo,fj,MFo,EFo,CFo,$u,lue,wFo,AFo,gj,LFo,yFo,xFo,vs,iue,$Fo,kFo,hj,SFo,RFo,uj,PFo,BFo,IFo,Fs,due,NFo,qFo,pj,DFo,jFo,_j,GFo,OFo,VFo,Ts,mue,XFo,zFo,bj,QFo,WFo,vj,UFo,HFo,JFo,ku,cue,YFo,ZFo,Fj,KFo,eTo,oTo,Su,fue,rTo,tTo,Tj,aTo,nTo,sTo,Ru,gue,lTo,iTo,Mj,dTo,mTo,cTo,Ms,hue,fTo,gTo,Ej,hTo,uTo,Cj,pTo,_To,bTo,Pu,uue,vTo,FTo,wj,TTo,MTo,ETo,Es,pue,CTo,wTo,Aj,ATo,LTo,Lj,yTo,xTo,$To,Cs,_ue,kTo,STo,yj,RTo,PTo,xj,BTo,ITo,NTo,ws,bue,qTo,DTo,$j,jTo,GTo,kj,OTo,VTo,XTo,As,vue,zTo,QTo,Sj,WTo,UTo,Rj,HTo,JTo,YTo,Bu,Fue,ZTo,KTo,Pj,eMo,oMo,rMo,Ls,Tue,tMo,aMo,Bj,nMo,sMo,Ij,lMo,iMo,dMo,ys,Mue,mMo,cMo,Nj,fMo,gMo,qj,hMo,uMo,pMo,xs,Eue,_Mo,bMo,Dj,vMo,FMo,jj,TMo,MMo,EMo,$s,Cue,CMo,wMo,Gj,AMo,LMo,Oj,yMo,xMo,$Mo,ks,wue,kMo,SMo,Vj,RMo,PMo,Xj,BMo,IMo,NMo,Ss,Aue,qMo,DMo,zj,jMo,GMo,Qj,OMo,VMo,XMo,Rs,Lue,zMo,QMo,Wj,WMo,UMo,Uj,HMo,JMo,YMo,Iu,yue,ZMo,KMo,Hj,eEo,oEo,rEo,Nu,xue,tEo,aEo,Jj,nEo,sEo,lEo,Ps,$ue,iEo,dEo,Yj,mEo,cEo,Zj,fEo,gEo,hEo,qu,kue,uEo,pEo,Kj,_Eo,bEo,vEo,Bs,Sue,FEo,TEo,eG,MEo,EEo,oG,CEo,wEo,AEo,Is,Rue,LEo,yEo,rG,xEo,$Eo,tG,kEo,SEo,REo,Ns,Pue,PEo,BEo,aG,IEo,NEo,nG,qEo,DEo,jEo,Du,Bue,GEo,OEo,sG,VEo,XEo,zEo,ju,Iue,QEo,WEo,lG,UEo,HEo,JEo,qs,Nue,YEo,ZEo,iG,KEo,e4o,dG,o4o,r4o,t4o,Ds,que,a4o,n4o,mG,s4o,l4o,cG,i4o,d4o,m4o,js,Due,c4o,f4o,fG,g4o,h4o,gG,u4o,p4o,_4o,Gu,jue,b4o,v4o,hG,F4o,T4o,M4o,Gs,Gue,E4o,C4o,uG,w4o,A4o,pG,L4o,y4o,x4o,Os,Oue,$4o,k4o,_G,S4o,R4o,bG,P4o,B4o,I4o,Vs,Vue,N4o,q4o,vG,D4o,j4o,FG,G4o,O4o,V4o,Xs,Xue,X4o,z4o,TG,Q4o,W4o,MG,U4o,H4o,J4o,zs,zue,Y4o,Z4o,EG,K4o,eCo,CG,oCo,rCo,tCo,Qs,Que,aCo,nCo,wG,sCo,lCo,AG,iCo,dCo,mCo,Ws,Wue,cCo,fCo,LG,gCo,hCo,yG,uCo,pCo,_Co,Us,Uue,bCo,vCo,xG,FCo,TCo,$G,MCo,ECo,CCo,Hs,Hue,wCo,ACo,kG,LCo,yCo,SG,xCo,$Co,kCo,Ou,Jue,SCo,RCo,RG,PCo,BCo,ICo,Js,Yue,NCo,qCo,PG,DCo,jCo,BG,GCo,OCo,VCo,Vu,Zue,XCo,zCo,IG,QCo,WCo,UCo,Xu,Kue,HCo,JCo,NG,YCo,ZCo,KCo,Ys,epe,e3o,o3o,qG,r3o,t3o,DG,a3o,n3o,s3o,Zs,ope,l3o,i3o,jG,d3o,m3o,GG,c3o,f3o,g3o,Ks,rpe,h3o,u3o,OG,p3o,_3o,VG,b3o,v3o,F3o,zu,tpe,T3o,M3o,XG,E3o,C3o,w3o,el,ape,A3o,L3o,zG,y3o,x3o,QG,$3o,k3o,S3o,ol,npe,R3o,P3o,WG,B3o,I3o,UG,N3o,q3o,D3o,rl,spe,j3o,G3o,HG,O3o,V3o,JG,X3o,z3o,Q3o,tl,lpe,W3o,U3o,YG,H3o,J3o,ZG,Y3o,Z3o,K3o,al,ipe,e5o,o5o,KG,r5o,t5o,eO,a5o,n5o,s5o,nl,dpe,l5o,i5o,oO,d5o,m5o,rO,c5o,f5o,g5o,sl,mpe,h5o,u5o,tO,p5o,_5o,aO,b5o,v5o,F5o,ll,cpe,T5o,M5o,nO,E5o,C5o,sO,w5o,A5o,L5o,Qu,fpe,y5o,x5o,lO,$5o,k5o,S5o,il,gpe,R5o,P5o,iO,B5o,I5o,dO,N5o,q5o,D5o,dl,hpe,j5o,G5o,mO,O5o,V5o,cO,X5o,z5o,Q5o,Wu,upe,W5o,U5o,fO,H5o,J5o,Y5o,Uu,ppe,Z5o,K5o,gO,e0o,o0o,r0o,Hu,_pe,t0o,a0o,hO,n0o,s0o,l0o,Ju,bpe,i0o,d0o,uO,m0o,c0o,f0o,ml,vpe,g0o,h0o,pO,u0o,p0o,_O,_0o,b0o,v0o,Yu,Fpe,F0o,T0o,bO,M0o,E0o,C0o,cl,Tpe,w0o,A0o,vO,L0o,y0o,FO,x0o,$0o,k0o,fl,Mpe,S0o,R0o,TO,P0o,B0o,MO,I0o,N0o,q0o,gl,Epe,D0o,j0o,EO,G0o,O0o,CO,V0o,X0o,z0o,hl,Cpe,Q0o,W0o,wO,U0o,H0o,AO,J0o,Y0o,Z0o,ul,wpe,K0o,ewo,LO,owo,rwo,yO,two,awo,nwo,pl,Ape,swo,lwo,xO,iwo,dwo,$O,mwo,cwo,fwo,Zu,Lpe,gwo,hwo,kO,uwo,pwo,_wo,Ku,ype,bwo,vwo,SO,Fwo,Two,Mwo,_l,xpe,Ewo,Cwo,RO,wwo,Awo,PO,Lwo,ywo,xwo,bl,$pe,$wo,kwo,BO,Swo,Rwo,IO,Pwo,Bwo,Iwo,vl,kpe,Nwo,qwo,NO,Dwo,jwo,qO,Gwo,Owo,Vwo,ep,Spe,Xwo,zwo,DO,Qwo,Wwo,Uwo,op,Rpe,Hwo,Jwo,jO,Ywo,Zwo,Kwo,rp,Ppe,eAo,oAo,GO,rAo,tAo,aAo,Fl,Bpe,nAo,sAo,OO,lAo,iAo,VO,dAo,mAo,cAo,Tl,Ipe,fAo,gAo,XO,hAo,uAo,zO,pAo,_Ao,bAo,tp,Npe,vAo,FAo,QO,TAo,MAo,EAo,ap,qpe,CAo,wAo,WO,AAo,LAo,yAo,np,Dpe,xAo,$Ao,UO,kAo,SAo,RAo,sp,jpe,PAo,BAo,HO,IAo,NAo,qAo,Ml,Gpe,DAo,jAo,JO,GAo,OAo,YO,VAo,XAo,zAo,El,Ope,QAo,WAo,ZO,UAo,HAo,KO,JAo,YAo,ZAo,lp,Vpe,KAo,e6o,eV,o6o,r6o,t6o,ip,Xpe,a6o,n6o,oV,s6o,l6o,i6o,Cl,zpe,d6o,m6o,rV,c6o,f6o,tV,g6o,h6o,u6o,wl,Qpe,p6o,_6o,aV,b6o,v6o,nV,F6o,T6o,M6o,Al,Wpe,E6o,C6o,sV,w6o,A6o,lV,L6o,y6o,x6o,Ll,Upe,$6o,k6o,iV,S6o,R6o,dV,P6o,B6o,I6o,dp,N6o,mp,M$,q6o,Hpe,D6o,Rto,yd,cp,Jpe,E$,j6o,Ype,G6o,Pto,Po,C$,O6o,w$,V6o,mV,X6o,z6o,Q6o,A$,W6o,Zpe,U6o,H6o,J6o,Ye,L$,Y6o,Kpe,Z6o,K6o,an,e7o,e_e,o7o,r7o,o_e,t7o,a7o,r_e,n7o,s7o,l7o,z,fp,t_e,i7o,d7o,cV,m7o,c7o,f7o,gp,a_e,g7o,h7o,fV,u7o,p7o,_7o,hp,n_e,b7o,v7o,gV,F7o,T7o,M7o,up,s_e,E7o,C7o,hV,w7o,A7o,L7o,pp,l_e,y7o,x7o,uV,$7o,k7o,S7o,_p,i_e,R7o,P7o,pV,B7o,I7o,N7o,bp,d_e,q7o,D7o,_V,j7o,G7o,O7o,vp,m_e,V7o,X7o,bV,z7o,Q7o,W7o,Fp,c_e,U7o,H7o,vV,J7o,Y7o,Z7o,Tp,f_e,K7o,e8o,FV,o8o,r8o,t8o,Mp,g_e,a8o,n8o,TV,s8o,l8o,i8o,Ep,h_e,d8o,m8o,MV,c8o,f8o,g8o,Cp,u_e,h8o,u8o,EV,p8o,_8o,b8o,wp,p_e,v8o,F8o,CV,T8o,M8o,E8o,Ap,__e,C8o,w8o,wV,A8o,L8o,y8o,Lp,b_e,x8o,$8o,AV,k8o,S8o,R8o,yp,v_e,P8o,B8o,LV,I8o,N8o,q8o,xp,F_e,D8o,j8o,yV,G8o,O8o,V8o,$p,T_e,X8o,z8o,xV,Q8o,W8o,U8o,kp,M_e,H8o,J8o,$V,Y8o,Z8o,K8o,Sp,E_e,eLo,oLo,kV,rLo,tLo,aLo,Rp,C_e,nLo,sLo,SV,lLo,iLo,dLo,Pp,w_e,mLo,cLo,RV,fLo,gLo,hLo,Bp,A_e,uLo,pLo,PV,_Lo,bLo,vLo,Ip,L_e,FLo,TLo,BV,MLo,ELo,CLo,Np,y_e,wLo,ALo,IV,LLo,yLo,xLo,qp,x_e,$Lo,kLo,NV,SLo,RLo,PLo,Dp,$_e,BLo,ILo,qV,NLo,qLo,DLo,jp,k_e,jLo,GLo,DV,OLo,VLo,XLo,Gp,S_e,zLo,QLo,jV,WLo,ULo,HLo,Op,R_e,JLo,YLo,GV,ZLo,KLo,eyo,Vp,P_e,oyo,ryo,OV,tyo,ayo,nyo,Xp,B_e,syo,lyo,VV,iyo,dyo,myo,zp,I_e,cyo,fyo,XV,gyo,hyo,uyo,Qp,N_e,pyo,_yo,zV,byo,vyo,Fyo,Wp,q_e,Tyo,Myo,QV,Eyo,Cyo,wyo,Up,D_e,Ayo,Lyo,WV,yyo,xyo,$yo,Hp,j_e,kyo,Syo,UV,Ryo,Pyo,Byo,Jp,G_e,Iyo,Nyo,HV,qyo,Dyo,jyo,Yp,O_e,Gyo,Oyo,JV,Vyo,Xyo,zyo,Zp,V_e,Qyo,Wyo,YV,Uyo,Hyo,Jyo,Kp,X_e,Yyo,Zyo,ZV,Kyo,e9o,o9o,e_,z_e,r9o,t9o,KV,a9o,n9o,s9o,o_,Q_e,l9o,i9o,eX,d9o,m9o,c9o,r_,f9o,t_,g9o,a_,y$,h9o,W_e,u9o,Bto,xd,n_,U_e,x$,p9o,H_e,_9o,Ito,Bo,$$,b9o,k$,v9o,oX,F9o,T9o,M9o,S$,E9o,J_e,C9o,w9o,A9o,Ze,R$,L9o,Y_e,y9o,x9o,$d,$9o,Z_e,k9o,S9o,K_e,R9o,P9o,B9o,se,s_,e1e,I9o,N9o,rX,q9o,D9o,j9o,l_,o1e,G9o,O9o,tX,V9o,X9o,z9o,i_,r1e,Q9o,W9o,aX,U9o,H9o,J9o,d_,t1e,Y9o,Z9o,nX,K9o,exo,oxo,m_,a1e,rxo,txo,sX,axo,nxo,sxo,c_,n1e,lxo,ixo,lX,dxo,mxo,cxo,f_,s1e,fxo,gxo,iX,hxo,uxo,pxo,g_,l1e,_xo,bxo,dX,vxo,Fxo,Txo,h_,i1e,Mxo,Exo,mX,Cxo,wxo,Axo,u_,d1e,Lxo,yxo,cX,xxo,$xo,kxo,p_,m1e,Sxo,Rxo,fX,Pxo,Bxo,Ixo,__,c1e,Nxo,qxo,gX,Dxo,jxo,Gxo,b_,f1e,Oxo,Vxo,hX,Xxo,zxo,Qxo,v_,g1e,Wxo,Uxo,uX,Hxo,Jxo,Yxo,F_,h1e,Zxo,Kxo,pX,e$o,o$o,r$o,T_,u1e,t$o,a$o,_X,n$o,s$o,l$o,M_,p1e,i$o,d$o,bX,m$o,c$o,f$o,E_,_1e,g$o,h$o,vX,u$o,p$o,_$o,C_,b1e,b$o,v$o,FX,F$o,T$o,M$o,w_,v1e,E$o,C$o,TX,w$o,A$o,L$o,A_,F1e,y$o,x$o,MX,$$o,k$o,S$o,L_,T1e,R$o,P$o,EX,B$o,I$o,N$o,y_,M1e,q$o,D$o,CX,j$o,G$o,O$o,x_,V$o,$_,X$o,k_,P$,z$o,E1e,Q$o,Nto,kd,S_,C1e,B$,W$o,w1e,U$o,qto,Io,I$,H$o,Sd,J$o,wX,Y$o,Z$o,AX,K$o,eko,oko,N$,rko,A1e,tko,ako,nko,Mt,q$,sko,L1e,lko,iko,Rd,dko,y1e,mko,cko,LX,fko,gko,hko,R_,uko,Ke,D$,pko,x1e,_ko,bko,nn,vko,$1e,Fko,Tko,k1e,Mko,Eko,S1e,Cko,wko,Ako,y,P_,R1e,Lko,yko,yX,xko,$ko,kko,B_,P1e,Sko,Rko,xX,Pko,Bko,Iko,I_,B1e,Nko,qko,$X,Dko,jko,Gko,N_,I1e,Oko,Vko,kX,Xko,zko,Qko,q_,N1e,Wko,Uko,SX,Hko,Jko,Yko,D_,q1e,Zko,Kko,RX,eSo,oSo,rSo,j_,D1e,tSo,aSo,PX,nSo,sSo,lSo,G_,j1e,iSo,dSo,BX,mSo,cSo,fSo,O_,G1e,gSo,hSo,IX,uSo,pSo,_So,V_,O1e,bSo,vSo,NX,FSo,TSo,MSo,X_,V1e,ESo,CSo,qX,wSo,ASo,LSo,z_,X1e,ySo,xSo,DX,$So,kSo,SSo,Q_,z1e,RSo,PSo,jX,BSo,ISo,NSo,W_,Q1e,qSo,DSo,GX,jSo,GSo,OSo,U_,W1e,VSo,XSo,OX,zSo,QSo,WSo,H_,U1e,USo,HSo,VX,JSo,YSo,ZSo,J_,H1e,KSo,eRo,XX,oRo,rRo,tRo,Y_,J1e,aRo,nRo,zX,sRo,lRo,iRo,Z_,Y1e,dRo,mRo,QX,cRo,fRo,gRo,K_,Z1e,hRo,uRo,WX,pRo,_Ro,bRo,e1,K1e,vRo,FRo,UX,TRo,MRo,ERo,o1,e2e,CRo,wRo,HX,ARo,LRo,yRo,r1,o2e,xRo,$Ro,JX,kRo,SRo,RRo,t1,r2e,PRo,BRo,YX,IRo,NRo,qRo,a1,t2e,DRo,jRo,ZX,GRo,ORo,VRo,n1,a2e,XRo,zRo,KX,QRo,WRo,URo,s1,n2e,HRo,JRo,ez,YRo,ZRo,KRo,l1,s2e,ePo,oPo,oz,rPo,tPo,aPo,i1,l2e,nPo,sPo,rz,lPo,iPo,dPo,d1,i2e,mPo,cPo,tz,fPo,gPo,hPo,m1,d2e,uPo,pPo,az,_Po,bPo,vPo,c1,m2e,FPo,TPo,nz,MPo,EPo,CPo,f1,c2e,wPo,APo,sz,LPo,yPo,xPo,g1,f2e,$Po,kPo,lz,SPo,RPo,PPo,h1,g2e,BPo,IPo,iz,NPo,qPo,DPo,u1,h2e,jPo,GPo,dz,OPo,VPo,XPo,p1,u2e,zPo,QPo,mz,WPo,UPo,HPo,_1,p2e,JPo,YPo,cz,ZPo,KPo,eBo,b1,_2e,oBo,rBo,fz,tBo,aBo,nBo,yl,b2e,sBo,lBo,gz,iBo,dBo,hz,mBo,cBo,fBo,v1,v2e,gBo,hBo,uz,uBo,pBo,_Bo,F1,F2e,bBo,vBo,pz,FBo,TBo,MBo,T1,T2e,EBo,CBo,_z,wBo,ABo,LBo,M1,M2e,yBo,xBo,bz,$Bo,kBo,SBo,E1,E2e,RBo,PBo,vz,BBo,IBo,NBo,C1,C2e,qBo,DBo,Fz,jBo,GBo,OBo,w1,w2e,VBo,XBo,Tz,zBo,QBo,WBo,A1,A2e,UBo,HBo,Mz,JBo,YBo,ZBo,L1,L2e,KBo,eIo,Ez,oIo,rIo,tIo,y1,y2e,aIo,nIo,Cz,sIo,lIo,iIo,x1,x2e,dIo,mIo,wz,cIo,fIo,gIo,$1,$2e,hIo,uIo,Az,pIo,_Io,bIo,k1,k2e,vIo,FIo,Lz,TIo,MIo,EIo,S1,S2e,CIo,wIo,yz,AIo,LIo,yIo,R1,R2e,xIo,$Io,xz,kIo,SIo,RIo,P1,P2e,PIo,BIo,$z,IIo,NIo,qIo,B1,B2e,DIo,jIo,kz,GIo,OIo,VIo,I1,I2e,XIo,zIo,Sz,QIo,WIo,UIo,N1,N2e,HIo,JIo,Rz,YIo,ZIo,KIo,q1,q2e,eNo,oNo,Pz,rNo,tNo,aNo,D1,D2e,nNo,sNo,Bz,lNo,iNo,dNo,j1,j2e,mNo,cNo,Iz,fNo,gNo,hNo,G1,G2e,uNo,pNo,Nz,_No,bNo,vNo,O1,O2e,FNo,TNo,qz,MNo,ENo,CNo,V1,V2e,wNo,ANo,Dz,LNo,yNo,xNo,X1,X2e,$No,kNo,jz,SNo,RNo,PNo,z1,z2e,BNo,INo,Gz,NNo,qNo,DNo,Q1,Q2e,jNo,GNo,Oz,ONo,VNo,XNo,W1,W2e,zNo,QNo,Vz,WNo,UNo,HNo,U1,U2e,JNo,YNo,Xz,ZNo,KNo,eqo,H1,H2e,oqo,rqo,zz,tqo,aqo,nqo,J1,J2e,sqo,lqo,Qz,iqo,dqo,mqo,Y1,Y2e,cqo,fqo,Wz,gqo,hqo,uqo,Z1,Z2e,pqo,_qo,Uz,bqo,vqo,Fqo,K1,K2e,Tqo,Mqo,Hz,Eqo,Cqo,wqo,e2,ebe,Aqo,Lqo,Jz,yqo,xqo,$qo,o2,obe,kqo,Sqo,Yz,Rqo,Pqo,Bqo,r2,rbe,Iqo,Nqo,Zz,qqo,Dqo,jqo,t2,tbe,Gqo,Oqo,Kz,Vqo,Xqo,zqo,a2,abe,Qqo,Wqo,eQ,Uqo,Hqo,Jqo,n2,nbe,Yqo,Zqo,oQ,Kqo,eDo,oDo,s2,sbe,rDo,tDo,rQ,aDo,nDo,sDo,l2,lbe,lDo,iDo,tQ,dDo,mDo,cDo,i2,ibe,fDo,gDo,aQ,hDo,uDo,pDo,d2,dbe,_Do,bDo,nQ,vDo,FDo,TDo,m2,mbe,MDo,EDo,sQ,CDo,wDo,ADo,c2,cbe,LDo,yDo,lQ,xDo,$Do,kDo,f2,fbe,SDo,RDo,iQ,PDo,BDo,IDo,g2,gbe,NDo,qDo,dQ,DDo,jDo,GDo,h2,hbe,ODo,VDo,mQ,XDo,zDo,QDo,u2,ube,WDo,UDo,cQ,HDo,JDo,YDo,p2,pbe,ZDo,KDo,fQ,ejo,ojo,rjo,_2,_be,tjo,ajo,gQ,njo,sjo,ljo,b2,bbe,ijo,djo,hQ,mjo,cjo,fjo,v2,vbe,gjo,hjo,uQ,ujo,pjo,_jo,F2,Fbe,bjo,vjo,pQ,Fjo,Tjo,Mjo,T2,Tbe,Ejo,Cjo,_Q,wjo,Ajo,Ljo,M2,Mbe,yjo,xjo,bQ,$jo,kjo,Sjo,E2,Ebe,Rjo,Pjo,vQ,Bjo,Ijo,Njo,C2,Cbe,qjo,Djo,FQ,jjo,Gjo,Ojo,w2,wbe,Vjo,Xjo,TQ,zjo,Qjo,Wjo,A2,Abe,Ujo,Hjo,MQ,Jjo,Yjo,Zjo,L2,Lbe,Kjo,eGo,EQ,oGo,rGo,tGo,y2,ybe,aGo,nGo,CQ,sGo,lGo,iGo,x2,xbe,dGo,mGo,wQ,cGo,fGo,gGo,$2,$be,hGo,uGo,AQ,pGo,_Go,bGo,k2,kbe,vGo,FGo,LQ,TGo,MGo,EGo,S2,Sbe,CGo,wGo,yQ,AGo,LGo,yGo,R2,Rbe,xGo,$Go,xQ,kGo,SGo,RGo,P2,Pbe,PGo,BGo,$Q,IGo,NGo,qGo,B2,Bbe,DGo,jGo,kQ,GGo,OGo,VGo,I2,Ibe,XGo,zGo,SQ,QGo,WGo,UGo,N2,Nbe,HGo,JGo,RQ,YGo,ZGo,KGo,q2,qbe,eOo,oOo,PQ,rOo,tOo,aOo,D2,Dbe,nOo,sOo,BQ,lOo,iOo,dOo,j2,jbe,mOo,cOo,IQ,fOo,gOo,hOo,G2,Gbe,uOo,pOo,NQ,_Oo,bOo,vOo,O2,Obe,FOo,TOo,qQ,MOo,EOo,COo,V2,Vbe,wOo,AOo,DQ,LOo,yOo,xOo,X2,Xbe,$Oo,kOo,jQ,SOo,ROo,POo,z2,zbe,BOo,IOo,GQ,NOo,qOo,DOo,Q2,Qbe,jOo,GOo,OQ,OOo,VOo,XOo,W2,Wbe,zOo,QOo,VQ,WOo,UOo,HOo,U2,Ube,JOo,YOo,XQ,ZOo,KOo,eVo,H2,Hbe,oVo,rVo,zQ,tVo,aVo,nVo,J2,Jbe,sVo,lVo,QQ,iVo,dVo,mVo,Y2,Ybe,cVo,fVo,WQ,gVo,hVo,uVo,Z2,Zbe,pVo,_Vo,UQ,bVo,vVo,FVo,K2,Kbe,TVo,MVo,HQ,EVo,CVo,wVo,eb,AVo,eve,LVo,yVo,ove,xVo,$Vo,ob,Dto,Pd,rb,rve,j$,kVo,tve,SVo,jto,No,G$,RVo,Bd,PVo,JQ,BVo,IVo,YQ,NVo,qVo,DVo,O$,jVo,ave,GVo,OVo,VVo,Et,V$,XVo,nve,zVo,QVo,Id,WVo,sve,UVo,HVo,ZQ,JVo,YVo,ZVo,tb,KVo,eo,X$,eXo,lve,oXo,rXo,sn,tXo,ive,aXo,nXo,dve,sXo,lXo,mve,iXo,dXo,mXo,G,ab,cve,cXo,fXo,KQ,gXo,hXo,uXo,nb,fve,pXo,_Xo,eW,bXo,vXo,FXo,sb,gve,TXo,MXo,oW,EXo,CXo,wXo,lb,hve,AXo,LXo,rW,yXo,xXo,$Xo,ib,uve,kXo,SXo,tW,RXo,PXo,BXo,db,pve,IXo,NXo,aW,qXo,DXo,jXo,mb,_ve,GXo,OXo,nW,VXo,XXo,zXo,cb,bve,QXo,WXo,sW,UXo,HXo,JXo,fb,vve,YXo,ZXo,lW,KXo,ezo,ozo,gb,Fve,rzo,tzo,iW,azo,nzo,szo,hb,Tve,lzo,izo,dW,dzo,mzo,czo,ub,Mve,fzo,gzo,mW,hzo,uzo,pzo,pb,Eve,_zo,bzo,cW,vzo,Fzo,Tzo,_b,Cve,Mzo,Ezo,fW,Czo,wzo,Azo,bb,wve,Lzo,yzo,gW,xzo,$zo,kzo,vb,Ave,Szo,Rzo,hW,Pzo,Bzo,Izo,Fb,Lve,Nzo,qzo,uW,Dzo,jzo,Gzo,Tb,yve,Ozo,Vzo,pW,Xzo,zzo,Qzo,Mb,xve,Wzo,Uzo,_W,Hzo,Jzo,Yzo,Eb,$ve,Zzo,Kzo,bW,eQo,oQo,rQo,Cb,kve,tQo,aQo,vW,nQo,sQo,lQo,wb,Sve,iQo,dQo,FW,mQo,cQo,fQo,Ab,Rve,gQo,hQo,TW,uQo,pQo,_Qo,Lb,Pve,bQo,vQo,MW,FQo,TQo,MQo,yb,Bve,EQo,CQo,EW,wQo,AQo,LQo,xb,Ive,yQo,xQo,CW,$Qo,kQo,SQo,$b,Nve,RQo,PQo,wW,BQo,IQo,NQo,kb,qve,qQo,DQo,AW,jQo,GQo,OQo,Sb,Dve,VQo,XQo,LW,zQo,QQo,WQo,Rb,jve,UQo,HQo,yW,JQo,YQo,ZQo,Pb,Gve,KQo,eWo,xW,oWo,rWo,tWo,Bb,Ove,aWo,nWo,$W,sWo,lWo,iWo,Ib,Vve,dWo,mWo,kW,cWo,fWo,gWo,Nb,Xve,hWo,uWo,SW,pWo,_Wo,bWo,qb,zve,vWo,FWo,RW,TWo,MWo,EWo,Db,Qve,CWo,wWo,PW,AWo,LWo,yWo,jb,Wve,xWo,$Wo,BW,kWo,SWo,RWo,Gb,Uve,PWo,BWo,IW,IWo,NWo,qWo,Ob,Hve,DWo,jWo,NW,GWo,OWo,VWo,Vb,Jve,XWo,zWo,qW,QWo,WWo,UWo,Xb,Yve,HWo,JWo,DW,YWo,ZWo,KWo,zb,Zve,eUo,oUo,jW,rUo,tUo,aUo,Qb,Kve,nUo,sUo,GW,lUo,iUo,dUo,Wb,eFe,mUo,cUo,OW,fUo,gUo,hUo,Ub,oFe,uUo,pUo,VW,_Uo,bUo,vUo,Hb,rFe,FUo,TUo,XW,MUo,EUo,CUo,Jb,tFe,wUo,AUo,zW,LUo,yUo,xUo,Yb,aFe,$Uo,kUo,QW,SUo,RUo,PUo,Zb,BUo,nFe,IUo,NUo,sFe,qUo,DUo,Kb,Gto,Nd,ev,lFe,z$,jUo,iFe,GUo,Oto,qo,Q$,OUo,qd,VUo,WW,XUo,zUo,UW,QUo,WUo,UUo,W$,HUo,dFe,JUo,YUo,ZUo,Ct,U$,KUo,mFe,eHo,oHo,Dd,rHo,cFe,tHo,aHo,HW,nHo,sHo,lHo,ov,iHo,oo,H$,dHo,fFe,mHo,cHo,ln,fHo,gFe,gHo,hHo,hFe,uHo,pHo,uFe,_Ho,bHo,vHo,W,rv,pFe,FHo,THo,JW,MHo,EHo,CHo,tv,_Fe,wHo,AHo,YW,LHo,yHo,xHo,av,bFe,$Ho,kHo,ZW,SHo,RHo,PHo,nv,vFe,BHo,IHo,KW,NHo,qHo,DHo,sv,FFe,jHo,GHo,eU,OHo,VHo,XHo,lv,TFe,zHo,QHo,oU,WHo,UHo,HHo,iv,MFe,JHo,YHo,rU,ZHo,KHo,eJo,dv,EFe,oJo,rJo,tU,tJo,aJo,nJo,mv,CFe,sJo,lJo,aU,iJo,dJo,mJo,cv,wFe,cJo,fJo,nU,gJo,hJo,uJo,fv,AFe,pJo,_Jo,sU,bJo,vJo,FJo,gv,LFe,TJo,MJo,lU,EJo,CJo,wJo,hv,yFe,AJo,LJo,iU,yJo,xJo,$Jo,uv,xFe,kJo,SJo,dU,RJo,PJo,BJo,pv,$Fe,IJo,NJo,mU,qJo,DJo,jJo,_v,kFe,GJo,OJo,cU,VJo,XJo,zJo,bv,SFe,QJo,WJo,fU,UJo,HJo,JJo,vv,RFe,YJo,ZJo,gU,KJo,eYo,oYo,Fv,PFe,rYo,tYo,hU,aYo,nYo,sYo,Tv,BFe,lYo,iYo,uU,dYo,mYo,cYo,Mv,IFe,fYo,gYo,pU,hYo,uYo,pYo,Ev,NFe,_Yo,bYo,_U,vYo,FYo,TYo,Cv,qFe,MYo,EYo,bU,CYo,wYo,AYo,wv,DFe,LYo,yYo,vU,xYo,$Yo,kYo,Av,jFe,SYo,RYo,FU,PYo,BYo,IYo,Lv,GFe,NYo,qYo,TU,DYo,jYo,GYo,yv,OFe,OYo,VYo,MU,XYo,zYo,QYo,xv,VFe,WYo,UYo,EU,HYo,JYo,YYo,$v,XFe,ZYo,KYo,CU,eZo,oZo,rZo,kv,zFe,tZo,aZo,wU,nZo,sZo,lZo,Sv,QFe,iZo,dZo,AU,mZo,cZo,fZo,Rv,WFe,gZo,hZo,LU,uZo,pZo,_Zo,Pv,UFe,bZo,vZo,yU,FZo,TZo,MZo,Bv,HFe,EZo,CZo,xU,wZo,AZo,LZo,Iv,JFe,yZo,xZo,$U,$Zo,kZo,SZo,Nv,YFe,RZo,PZo,kU,BZo,IZo,NZo,qv,ZFe,qZo,DZo,SU,jZo,GZo,OZo,Dv,KFe,VZo,XZo,RU,zZo,QZo,WZo,jv,eTe,UZo,HZo,PU,JZo,YZo,ZZo,Gv,oTe,KZo,eKo,BU,oKo,rKo,tKo,Ov,rTe,aKo,nKo,IU,sKo,lKo,iKo,Vv,tTe,dKo,mKo,NU,cKo,fKo,gKo,Xv,hKo,aTe,uKo,pKo,nTe,_Ko,bKo,zv,Vto,jd,Qv,sTe,J$,vKo,lTe,FKo,Xto,Do,Y$,TKo,Gd,MKo,qU,EKo,CKo,DU,wKo,AKo,LKo,Z$,yKo,iTe,xKo,$Ko,kKo,wt,K$,SKo,dTe,RKo,PKo,Od,BKo,mTe,IKo,NKo,jU,qKo,DKo,jKo,Wv,GKo,ro,ek,OKo,cTe,VKo,XKo,dn,zKo,fTe,QKo,WKo,gTe,UKo,HKo,hTe,JKo,YKo,ZKo,ok,Uv,uTe,KKo,eer,GU,oer,rer,ter,Hv,pTe,aer,ner,OU,ser,ler,ier,Jv,der,_Te,mer,cer,bTe,fer,ger,Yv,zto,Vd,Zv,vTe,rk,her,FTe,uer,Qto,jo,tk,per,Xd,_er,VU,ber,ver,XU,Fer,Ter,Mer,ak,Eer,TTe,Cer,wer,Aer,At,nk,Ler,MTe,yer,xer,zd,$er,ETe,ker,Ser,zU,Rer,Per,Ber,Kv,Ier,to,sk,Ner,CTe,qer,Der,mn,jer,wTe,Ger,Oer,ATe,Ver,Xer,LTe,zer,Qer,Wer,Y,eF,yTe,Uer,Her,QU,Jer,Yer,Zer,oF,xTe,Ker,eor,WU,oor,ror,tor,rF,$Te,aor,nor,UU,sor,lor,ior,tF,kTe,dor,mor,HU,cor,gor,hor,aF,STe,uor,por,JU,_or,bor,vor,nF,RTe,For,Tor,YU,Mor,Eor,Cor,sF,PTe,wor,Aor,ZU,Lor,yor,xor,lF,BTe,$or,kor,KU,Sor,Ror,Por,iF,ITe,Bor,Ior,eH,Nor,qor,Dor,dF,NTe,jor,Gor,oH,Oor,Vor,Xor,mF,qTe,zor,Qor,rH,Wor,Uor,Hor,cF,DTe,Jor,Yor,tH,Zor,Kor,err,fF,jTe,orr,rrr,aH,trr,arr,nrr,gF,GTe,srr,lrr,nH,irr,drr,mrr,hF,OTe,crr,frr,sH,grr,hrr,urr,uF,VTe,prr,_rr,lH,brr,vrr,Frr,pF,XTe,Trr,Mrr,iH,Err,Crr,wrr,_F,zTe,Arr,Lrr,dH,yrr,xrr,$rr,bF,QTe,krr,Srr,mH,Rrr,Prr,Brr,vF,WTe,Irr,Nrr,cH,qrr,Drr,jrr,FF,UTe,Grr,Orr,fH,Vrr,Xrr,zrr,TF,HTe,Qrr,Wrr,gH,Urr,Hrr,Jrr,MF,JTe,Yrr,Zrr,hH,Krr,etr,otr,EF,YTe,rtr,ttr,uH,atr,ntr,str,CF,ZTe,ltr,itr,pH,dtr,mtr,ctr,wF,KTe,ftr,gtr,_H,htr,utr,ptr,AF,eMe,_tr,btr,bH,vtr,Ftr,Ttr,LF,oMe,Mtr,Etr,vH,Ctr,wtr,Atr,yF,rMe,Ltr,ytr,FH,xtr,$tr,ktr,xF,tMe,Str,Rtr,TH,Ptr,Btr,Itr,$F,aMe,Ntr,qtr,MH,Dtr,jtr,Gtr,kF,nMe,Otr,Vtr,EH,Xtr,ztr,Qtr,SF,sMe,Wtr,Utr,CH,Htr,Jtr,Ytr,RF,lMe,Ztr,Ktr,wH,ear,oar,rar,PF,iMe,tar,aar,dMe,nar,sar,lar,BF,mMe,iar,dar,AH,mar,car,far,IF,cMe,gar,har,LH,uar,par,_ar,NF,fMe,bar,Far,yH,Tar,Mar,Ear,qF,gMe,Car,war,xH,Aar,Lar,yar,DF,xar,hMe,$ar,kar,uMe,Sar,Rar,jF,Wto,Qd,GF,pMe,lk,Par,_Me,Bar,Uto,Go,ik,Iar,Wd,Nar,$H,qar,Dar,kH,jar,Gar,Oar,dk,Var,bMe,Xar,zar,Qar,Lt,mk,War,vMe,Uar,Har,Ud,Jar,FMe,Yar,Zar,SH,Kar,enr,onr,OF,rnr,ao,ck,tnr,TMe,anr,nnr,cn,snr,MMe,lnr,inr,EMe,dnr,mnr,CMe,cnr,fnr,gnr,he,VF,wMe,hnr,unr,RH,pnr,_nr,bnr,XF,AMe,vnr,Fnr,PH,Tnr,Mnr,Enr,zF,LMe,Cnr,wnr,BH,Anr,Lnr,ynr,QF,yMe,xnr,$nr,IH,knr,Snr,Rnr,WF,xMe,Pnr,Bnr,NH,Inr,Nnr,qnr,UF,$Me,Dnr,jnr,qH,Gnr,Onr,Vnr,HF,kMe,Xnr,znr,DH,Qnr,Wnr,Unr,JF,SMe,Hnr,Jnr,jH,Ynr,Znr,Knr,YF,RMe,esr,osr,GH,rsr,tsr,asr,ZF,PMe,nsr,ssr,OH,lsr,isr,dsr,KF,BMe,msr,csr,VH,fsr,gsr,hsr,eT,IMe,usr,psr,XH,_sr,bsr,vsr,oT,NMe,Fsr,Tsr,zH,Msr,Esr,Csr,rT,qMe,wsr,Asr,QH,Lsr,ysr,xsr,tT,DMe,$sr,ksr,WH,Ssr,Rsr,Psr,aT,jMe,Bsr,Isr,UH,Nsr,qsr,Dsr,nT,GMe,jsr,Gsr,HH,Osr,Vsr,Xsr,sT,OMe,zsr,Qsr,JH,Wsr,Usr,Hsr,lT,VMe,Jsr,Ysr,YH,Zsr,Ksr,elr,iT,XMe,olr,rlr,ZH,tlr,alr,nlr,dT,slr,zMe,llr,ilr,QMe,dlr,mlr,mT,Hto,Hd,cT,WMe,fk,clr,UMe,flr,Jto,Oo,gk,glr,Jd,hlr,KH,ulr,plr,eJ,_lr,blr,vlr,hk,Flr,HMe,Tlr,Mlr,Elr,yt,uk,Clr,JMe,wlr,Alr,Yd,Llr,YMe,ylr,xlr,oJ,$lr,klr,Slr,fT,Rlr,no,pk,Plr,ZMe,Blr,Ilr,fn,Nlr,KMe,qlr,Dlr,eEe,jlr,Glr,oEe,Olr,Vlr,Xlr,D,gT,rEe,zlr,Qlr,rJ,Wlr,Ulr,Hlr,hT,tEe,Jlr,Ylr,tJ,Zlr,Klr,eir,uT,aEe,oir,rir,aJ,tir,air,nir,pT,nEe,sir,lir,nJ,iir,dir,mir,_T,sEe,cir,fir,sJ,gir,hir,uir,bT,lEe,pir,_ir,lJ,bir,vir,Fir,vT,iEe,Tir,Mir,iJ,Eir,Cir,wir,FT,dEe,Air,Lir,dJ,yir,xir,$ir,TT,mEe,kir,Sir,mJ,Rir,Pir,Bir,MT,cEe,Iir,Nir,cJ,qir,Dir,jir,ET,fEe,Gir,Oir,fJ,Vir,Xir,zir,CT,gEe,Qir,Wir,gJ,Uir,Hir,Jir,wT,hEe,Yir,Zir,hJ,Kir,edr,odr,AT,uEe,rdr,tdr,uJ,adr,ndr,sdr,LT,pEe,ldr,idr,pJ,ddr,mdr,cdr,yT,_Ee,fdr,gdr,_J,hdr,udr,pdr,xT,bEe,_dr,bdr,bJ,vdr,Fdr,Tdr,$T,vEe,Mdr,Edr,vJ,Cdr,wdr,Adr,kT,FEe,Ldr,ydr,FJ,xdr,$dr,kdr,ST,TEe,Sdr,Rdr,TJ,Pdr,Bdr,Idr,RT,MEe,Ndr,qdr,MJ,Ddr,jdr,Gdr,PT,EEe,Odr,Vdr,EJ,Xdr,zdr,Qdr,BT,CEe,Wdr,Udr,CJ,Hdr,Jdr,Ydr,IT,wEe,Zdr,Kdr,wJ,emr,omr,rmr,NT,AEe,tmr,amr,AJ,nmr,smr,lmr,qT,LEe,imr,dmr,LJ,mmr,cmr,fmr,DT,yEe,gmr,hmr,yJ,umr,pmr,_mr,jT,xEe,bmr,vmr,xJ,Fmr,Tmr,Mmr,GT,$Ee,Emr,Cmr,$J,wmr,Amr,Lmr,OT,kEe,ymr,xmr,kJ,$mr,kmr,Smr,VT,SEe,Rmr,Pmr,SJ,Bmr,Imr,Nmr,XT,REe,qmr,Dmr,RJ,jmr,Gmr,Omr,zT,PEe,Vmr,Xmr,PJ,zmr,Qmr,Wmr,QT,BEe,Umr,Hmr,BJ,Jmr,Ymr,Zmr,WT,IEe,Kmr,ecr,IJ,ocr,rcr,tcr,UT,NEe,acr,ncr,NJ,scr,lcr,icr,HT,qEe,dcr,mcr,qJ,ccr,fcr,gcr,JT,DEe,hcr,ucr,DJ,pcr,_cr,bcr,YT,jEe,vcr,Fcr,jJ,Tcr,Mcr,Ecr,ZT,GEe,Ccr,wcr,GJ,Acr,Lcr,ycr,KT,OEe,xcr,$cr,OJ,kcr,Scr,Rcr,eM,VEe,Pcr,Bcr,VJ,Icr,Ncr,qcr,oM,XEe,Dcr,jcr,XJ,Gcr,Ocr,Vcr,rM,zEe,Xcr,zcr,zJ,Qcr,Wcr,Ucr,tM,QEe,Hcr,Jcr,QJ,Ycr,Zcr,Kcr,aM,WEe,efr,ofr,WJ,rfr,tfr,afr,nM,UEe,nfr,sfr,UJ,lfr,ifr,dfr,sM,HEe,mfr,cfr,HJ,ffr,gfr,hfr,lM,JEe,ufr,pfr,JJ,_fr,bfr,vfr,iM,YEe,Ffr,Tfr,YJ,Mfr,Efr,Cfr,dM,ZEe,wfr,Afr,ZJ,Lfr,yfr,xfr,mM,KEe,$fr,kfr,KJ,Sfr,Rfr,Pfr,cM,e4e,Bfr,Ifr,eY,Nfr,qfr,Dfr,fM,o4e,jfr,Gfr,oY,Ofr,Vfr,Xfr,gM,r4e,zfr,Qfr,rY,Wfr,Ufr,Hfr,hM,t4e,Jfr,Yfr,tY,Zfr,Kfr,egr,uM,ogr,a4e,rgr,tgr,n4e,agr,ngr,pM,Yto,Zd,_M,s4e,_k,sgr,l4e,lgr,Zto,Vo,bk,igr,Kd,dgr,aY,mgr,cgr,nY,fgr,ggr,hgr,vk,ugr,i4e,pgr,_gr,bgr,xt,Fk,vgr,d4e,Fgr,Tgr,em,Mgr,m4e,Egr,Cgr,sY,wgr,Agr,Lgr,bM,ygr,so,Tk,xgr,c4e,$gr,kgr,gn,Sgr,f4e,Rgr,Pgr,g4e,Bgr,Igr,h4e,Ngr,qgr,Dgr,K,vM,u4e,jgr,Ggr,lY,Ogr,Vgr,Xgr,FM,p4e,zgr,Qgr,iY,Wgr,Ugr,Hgr,TM,_4e,Jgr,Ygr,dY,Zgr,Kgr,ehr,MM,b4e,ohr,rhr,mY,thr,ahr,nhr,EM,v4e,shr,lhr,cY,ihr,dhr,mhr,CM,F4e,chr,fhr,fY,ghr,hhr,uhr,wM,T4e,phr,_hr,gY,bhr,vhr,Fhr,AM,M4e,Thr,Mhr,hY,Ehr,Chr,whr,LM,E4e,Ahr,Lhr,uY,yhr,xhr,$hr,yM,C4e,khr,Shr,pY,Rhr,Phr,Bhr,xM,w4e,Ihr,Nhr,_Y,qhr,Dhr,jhr,$M,A4e,Ghr,Ohr,bY,Vhr,Xhr,zhr,kM,L4e,Qhr,Whr,vY,Uhr,Hhr,Jhr,SM,y4e,Yhr,Zhr,FY,Khr,eur,our,RM,x4e,rur,tur,TY,aur,nur,sur,PM,$4e,lur,iur,MY,dur,mur,cur,BM,k4e,fur,gur,EY,hur,uur,pur,IM,S4e,_ur,bur,CY,vur,Fur,Tur,NM,R4e,Mur,Eur,wY,Cur,wur,Aur,qM,P4e,Lur,yur,AY,xur,$ur,kur,DM,B4e,Sur,Rur,LY,Pur,Bur,Iur,jM,I4e,Nur,qur,yY,Dur,jur,Gur,GM,N4e,Our,Vur,xY,Xur,zur,Qur,OM,q4e,Wur,Uur,$Y,Hur,Jur,Yur,VM,D4e,Zur,Kur,kY,epr,opr,rpr,XM,j4e,tpr,apr,SY,npr,spr,lpr,zM,G4e,ipr,dpr,RY,mpr,cpr,fpr,QM,O4e,gpr,hpr,PY,upr,ppr,_pr,WM,V4e,bpr,vpr,BY,Fpr,Tpr,Mpr,UM,X4e,Epr,Cpr,IY,wpr,Apr,Lpr,HM,z4e,ypr,xpr,NY,$pr,kpr,Spr,JM,Q4e,Rpr,Ppr,qY,Bpr,Ipr,Npr,YM,qpr,W4e,Dpr,jpr,U4e,Gpr,Opr,ZM,Kto,om,KM,H4e,Mk,Vpr,J4e,Xpr,eao,Xo,Ek,zpr,rm,Qpr,DY,Wpr,Upr,jY,Hpr,Jpr,Ypr,Ck,Zpr,Y4e,Kpr,e_r,o_r,$t,wk,r_r,Z4e,t_r,a_r,tm,n_r,K4e,s_r,l_r,GY,i_r,d_r,m_r,eE,c_r,lo,Ak,f_r,eCe,g_r,h_r,hn,u_r,oCe,p_r,__r,rCe,b_r,v_r,tCe,F_r,T_r,M_r,Ue,oE,aCe,E_r,C_r,OY,w_r,A_r,L_r,rE,nCe,y_r,x_r,VY,$_r,k_r,S_r,tE,sCe,R_r,P_r,XY,B_r,I_r,N_r,aE,lCe,q_r,D_r,zY,j_r,G_r,O_r,nE,iCe,V_r,X_r,QY,z_r,Q_r,W_r,sE,dCe,U_r,H_r,WY,J_r,Y_r,Z_r,lE,mCe,K_r,e1r,UY,o1r,r1r,t1r,iE,a1r,cCe,n1r,s1r,fCe,l1r,i1r,dE,oao,am,mE,gCe,Lk,d1r,hCe,m1r,rao,zo,yk,c1r,nm,f1r,HY,g1r,h1r,JY,u1r,p1r,_1r,xk,b1r,uCe,v1r,F1r,T1r,kt,$k,M1r,pCe,E1r,C1r,sm,w1r,_Ce,A1r,L1r,YY,y1r,x1r,$1r,cE,k1r,io,kk,S1r,bCe,R1r,P1r,un,B1r,vCe,I1r,N1r,FCe,q1r,D1r,TCe,j1r,G1r,O1r,U,fE,MCe,V1r,X1r,ZY,z1r,Q1r,W1r,gE,ECe,U1r,H1r,KY,J1r,Y1r,Z1r,hE,CCe,K1r,e2r,eZ,o2r,r2r,t2r,uE,wCe,a2r,n2r,oZ,s2r,l2r,i2r,pE,ACe,d2r,m2r,rZ,c2r,f2r,g2r,_E,LCe,h2r,u2r,tZ,p2r,_2r,b2r,bE,yCe,v2r,F2r,aZ,T2r,M2r,E2r,vE,xCe,C2r,w2r,nZ,A2r,L2r,y2r,FE,$Ce,x2r,$2r,sZ,k2r,S2r,R2r,TE,kCe,P2r,B2r,lZ,I2r,N2r,q2r,ME,SCe,D2r,j2r,iZ,G2r,O2r,V2r,EE,RCe,X2r,z2r,dZ,Q2r,W2r,U2r,CE,PCe,H2r,J2r,mZ,Y2r,Z2r,K2r,wE,BCe,ebr,obr,cZ,rbr,tbr,abr,AE,ICe,nbr,sbr,fZ,lbr,ibr,dbr,LE,NCe,mbr,cbr,gZ,fbr,gbr,hbr,yE,qCe,ubr,pbr,hZ,_br,bbr,vbr,xE,DCe,Fbr,Tbr,uZ,Mbr,Ebr,Cbr,$E,jCe,wbr,Abr,pZ,Lbr,ybr,xbr,kE,GCe,$br,kbr,_Z,Sbr,Rbr,Pbr,SE,OCe,Bbr,Ibr,bZ,Nbr,qbr,Dbr,RE,VCe,jbr,Gbr,vZ,Obr,Vbr,Xbr,PE,XCe,zbr,Qbr,FZ,Wbr,Ubr,Hbr,BE,zCe,Jbr,Ybr,TZ,Zbr,Kbr,evr,IE,QCe,ovr,rvr,MZ,tvr,avr,nvr,NE,WCe,svr,lvr,EZ,ivr,dvr,mvr,qE,UCe,cvr,fvr,CZ,gvr,hvr,uvr,DE,HCe,pvr,_vr,wZ,bvr,vvr,Fvr,jE,JCe,Tvr,Mvr,AZ,Evr,Cvr,wvr,GE,YCe,Avr,Lvr,LZ,yvr,xvr,$vr,OE,ZCe,kvr,Svr,yZ,Rvr,Pvr,Bvr,VE,KCe,Ivr,Nvr,xZ,qvr,Dvr,jvr,XE,e3e,Gvr,Ovr,$Z,Vvr,Xvr,zvr,zE,o3e,Qvr,Wvr,kZ,Uvr,Hvr,Jvr,QE,r3e,Yvr,Zvr,SZ,Kvr,eFr,oFr,WE,t3e,rFr,tFr,RZ,aFr,nFr,sFr,UE,a3e,lFr,iFr,PZ,dFr,mFr,cFr,HE,n3e,fFr,gFr,BZ,hFr,uFr,pFr,JE,s3e,_Fr,bFr,IZ,vFr,FFr,TFr,YE,l3e,MFr,EFr,NZ,CFr,wFr,AFr,ZE,i3e,LFr,yFr,qZ,xFr,$Fr,kFr,KE,SFr,d3e,RFr,PFr,m3e,BFr,IFr,e4,tao,lm,o4,c3e,Sk,NFr,f3e,qFr,aao,Qo,Rk,DFr,im,jFr,DZ,GFr,OFr,jZ,VFr,XFr,zFr,Pk,QFr,g3e,WFr,UFr,HFr,St,Bk,JFr,h3e,YFr,ZFr,dm,KFr,u3e,eTr,oTr,GZ,rTr,tTr,aTr,r4,nTr,mo,Ik,sTr,p3e,lTr,iTr,pn,dTr,_3e,mTr,cTr,b3e,fTr,gTr,v3e,hTr,uTr,pTr,O,t4,F3e,_Tr,bTr,OZ,vTr,FTr,TTr,a4,T3e,MTr,ETr,VZ,CTr,wTr,ATr,n4,M3e,LTr,yTr,XZ,xTr,$Tr,kTr,s4,E3e,STr,RTr,zZ,PTr,BTr,ITr,l4,C3e,NTr,qTr,QZ,DTr,jTr,GTr,i4,w3e,OTr,VTr,WZ,XTr,zTr,QTr,d4,A3e,WTr,UTr,UZ,HTr,JTr,YTr,m4,L3e,ZTr,KTr,HZ,eMr,oMr,rMr,c4,y3e,tMr,aMr,JZ,nMr,sMr,lMr,f4,x3e,iMr,dMr,YZ,mMr,cMr,fMr,g4,$3e,gMr,hMr,ZZ,uMr,pMr,_Mr,h4,k3e,bMr,vMr,KZ,FMr,TMr,MMr,u4,S3e,EMr,CMr,eK,wMr,AMr,LMr,p4,R3e,yMr,xMr,oK,$Mr,kMr,SMr,_4,P3e,RMr,PMr,rK,BMr,IMr,NMr,b4,B3e,qMr,DMr,tK,jMr,GMr,OMr,v4,I3e,VMr,XMr,aK,zMr,QMr,WMr,F4,N3e,UMr,HMr,nK,JMr,YMr,ZMr,T4,q3e,KMr,eEr,sK,oEr,rEr,tEr,M4,D3e,aEr,nEr,lK,sEr,lEr,iEr,E4,j3e,dEr,mEr,iK,cEr,fEr,gEr,C4,G3e,hEr,uEr,dK,pEr,_Er,bEr,w4,O3e,vEr,FEr,mK,TEr,MEr,EEr,A4,V3e,CEr,wEr,cK,AEr,LEr,yEr,L4,X3e,xEr,$Er,fK,kEr,SEr,REr,y4,z3e,PEr,BEr,gK,IEr,NEr,qEr,x4,Q3e,DEr,jEr,hK,GEr,OEr,VEr,$4,W3e,XEr,zEr,uK,QEr,WEr,UEr,k4,U3e,HEr,JEr,pK,YEr,ZEr,KEr,S4,H3e,e4r,o4r,_K,r4r,t4r,a4r,R4,J3e,n4r,s4r,bK,l4r,i4r,d4r,P4,Y3e,m4r,c4r,vK,f4r,g4r,h4r,B4,Z3e,u4r,p4r,FK,_4r,b4r,v4r,I4,K3e,F4r,T4r,TK,M4r,E4r,C4r,N4,e5e,w4r,A4r,MK,L4r,y4r,x4r,q4,o5e,$4r,k4r,EK,S4r,R4r,P4r,D4,r5e,B4r,I4r,CK,N4r,q4r,D4r,j4,t5e,j4r,G4r,wK,O4r,V4r,X4r,G4,a5e,z4r,Q4r,AK,W4r,U4r,H4r,O4,n5e,J4r,Y4r,LK,Z4r,K4r,eCr,V4,s5e,oCr,rCr,yK,tCr,aCr,nCr,X4,l5e,sCr,lCr,xK,iCr,dCr,mCr,z4,i5e,cCr,fCr,$K,gCr,hCr,uCr,Q4,d5e,pCr,_Cr,kK,bCr,vCr,FCr,W4,m5e,TCr,MCr,SK,ECr,CCr,wCr,U4,c5e,ACr,LCr,RK,yCr,xCr,$Cr,H4,f5e,kCr,SCr,PK,RCr,PCr,BCr,J4,g5e,ICr,NCr,BK,qCr,DCr,jCr,Y4,GCr,h5e,OCr,VCr,u5e,XCr,zCr,Z4,nao,mm,K4,p5e,Nk,QCr,_5e,WCr,sao,Wo,qk,UCr,cm,HCr,IK,JCr,YCr,NK,ZCr,KCr,e3r,Dk,o3r,b5e,r3r,t3r,a3r,Rt,jk,n3r,v5e,s3r,l3r,fm,i3r,F5e,d3r,m3r,qK,c3r,f3r,g3r,eC,h3r,co,Gk,u3r,T5e,p3r,_3r,_n,b3r,M5e,v3r,F3r,E5e,T3r,M3r,C5e,E3r,C3r,w3r,w5e,oC,A5e,A3r,L3r,DK,y3r,x3r,$3r,rC,k3r,L5e,S3r,R3r,y5e,P3r,B3r,tC,lao,gm,aC,x5e,Ok,I3r,$5e,N3r,iao,Uo,Vk,q3r,hm,D3r,jK,j3r,G3r,GK,O3r,V3r,X3r,Xk,z3r,k5e,Q3r,W3r,U3r,Pt,zk,H3r,S5e,J3r,Y3r,um,Z3r,R5e,K3r,e5r,OK,o5r,r5r,t5r,nC,a5r,fo,Qk,n5r,P5e,s5r,l5r,bn,i5r,B5e,d5r,m5r,I5e,c5r,f5r,N5e,g5r,h5r,u5r,pm,sC,q5e,p5r,_5r,VK,b5r,v5r,F5r,lC,D5e,T5r,M5r,XK,E5r,C5r,w5r,iC,j5e,A5r,L5r,zK,y5r,x5r,$5r,dC,k5r,G5e,S5r,R5r,O5e,P5r,B5r,mC,dao,_m,cC,V5e,Wk,I5r,X5e,N5r,mao,Ho,Uk,q5r,bm,D5r,QK,j5r,G5r,WK,O5r,V5r,X5r,Hk,z5r,z5e,Q5r,W5r,U5r,Bt,Jk,H5r,Q5e,J5r,Y5r,vm,Z5r,W5e,K5r,e0r,UK,o0r,r0r,t0r,fC,a0r,go,Yk,n0r,U5e,s0r,l0r,vn,i0r,H5e,d0r,m0r,J5e,c0r,f0r,Y5e,g0r,h0r,u0r,be,gC,Z5e,p0r,_0r,HK,b0r,v0r,F0r,hC,K5e,T0r,M0r,JK,E0r,C0r,w0r,uC,e0e,A0r,L0r,YK,y0r,x0r,$0r,pC,o0e,k0r,S0r,ZK,R0r,P0r,B0r,xl,r0e,I0r,N0r,KK,q0r,D0r,eee,j0r,G0r,O0r,_C,t0e,V0r,X0r,oee,z0r,Q0r,W0r,$l,a0e,U0r,H0r,ree,J0r,Y0r,tee,Z0r,K0r,ewr,bC,n0e,owr,rwr,aee,twr,awr,nwr,It,s0e,swr,lwr,nee,iwr,dwr,see,mwr,cwr,lee,fwr,gwr,hwr,vC,l0e,uwr,pwr,iee,_wr,bwr,vwr,FC,i0e,Fwr,Twr,dee,Mwr,Ewr,Cwr,TC,d0e,wwr,Awr,mee,Lwr,ywr,xwr,MC,m0e,$wr,kwr,cee,Swr,Rwr,Pwr,EC,c0e,Bwr,Iwr,fee,Nwr,qwr,Dwr,CC,f0e,jwr,Gwr,gee,Owr,Vwr,Xwr,wC,g0e,zwr,Qwr,hee,Wwr,Uwr,Hwr,AC,h0e,Jwr,Ywr,uee,Zwr,Kwr,eAr,LC,u0e,oAr,rAr,pee,tAr,aAr,nAr,yC,sAr,p0e,lAr,iAr,_0e,dAr,mAr,xC,cao,Fm,$C,b0e,Zk,cAr,v0e,fAr,fao,Jo,Kk,gAr,Tm,hAr,_ee,uAr,pAr,bee,_Ar,bAr,vAr,eS,FAr,F0e,TAr,MAr,EAr,Nt,oS,CAr,T0e,wAr,AAr,Mm,LAr,M0e,yAr,xAr,vee,$Ar,kAr,SAr,kC,RAr,ho,rS,PAr,E0e,BAr,IAr,Fn,NAr,C0e,qAr,DAr,w0e,jAr,GAr,A0e,OAr,VAr,XAr,L0e,SC,y0e,zAr,QAr,Fee,WAr,UAr,HAr,RC,JAr,x0e,YAr,ZAr,$0e,KAr,e6r,PC,gao,Em,BC,k0e,tS,o6r,S0e,r6r,hao,Yo,aS,t6r,Cm,a6r,Tee,n6r,s6r,Mee,l6r,i6r,d6r,nS,m6r,R0e,c6r,f6r,g6r,qt,sS,h6r,P0e,u6r,p6r,wm,_6r,B0e,b6r,v6r,Eee,F6r,T6r,M6r,IC,E6r,uo,lS,C6r,I0e,w6r,A6r,Tn,L6r,N0e,y6r,x6r,q0e,$6r,k6r,D0e,S6r,R6r,P6r,j0e,NC,G0e,B6r,I6r,Cee,N6r,q6r,D6r,qC,j6r,O0e,G6r,O6r,V0e,V6r,X6r,DC,uao,Am,jC,X0e,iS,z6r,z0e,Q6r,pao,Zo,dS,W6r,Lm,U6r,wee,H6r,J6r,Aee,Y6r,Z6r,K6r,mS,e7r,Q0e,o7r,r7r,t7r,Dt,cS,a7r,W0e,n7r,s7r,ym,l7r,U0e,i7r,d7r,Lee,m7r,c7r,f7r,GC,g7r,po,fS,h7r,H0e,u7r,p7r,Mn,_7r,J0e,b7r,v7r,Y0e,F7r,T7r,Z0e,M7r,E7r,C7r,K0e,OC,ewe,w7r,A7r,yee,L7r,y7r,x7r,VC,$7r,owe,k7r,S7r,rwe,R7r,P7r,XC,_ao,xm,zC,twe,gS,B7r,awe,I7r,bao,Ko,hS,N7r,$m,q7r,xee,D7r,j7r,$ee,G7r,O7r,V7r,uS,X7r,nwe,z7r,Q7r,W7r,jt,pS,U7r,swe,H7r,J7r,km,Y7r,lwe,Z7r,K7r,kee,e8r,o8r,r8r,QC,t8r,_o,_S,a8r,iwe,n8r,s8r,En,l8r,dwe,i8r,d8r,mwe,m8r,c8r,cwe,f8r,g8r,h8r,Be,WC,fwe,u8r,p8r,See,_8r,b8r,v8r,UC,gwe,F8r,T8r,Ree,M8r,E8r,C8r,HC,hwe,w8r,A8r,Pee,L8r,y8r,x8r,JC,uwe,$8r,k8r,Bee,S8r,R8r,P8r,YC,pwe,B8r,I8r,Iee,N8r,q8r,D8r,ZC,_we,j8r,G8r,Nee,O8r,V8r,X8r,KC,bwe,z8r,Q8r,qee,W8r,U8r,H8r,e3,vwe,J8r,Y8r,Dee,Z8r,K8r,eLr,o3,Fwe,oLr,rLr,jee,tLr,aLr,nLr,r3,sLr,Twe,lLr,iLr,Mwe,dLr,mLr,t3,vao,Sm,a3,Ewe,bS,cLr,Cwe,fLr,Fao,er,vS,gLr,Rm,hLr,Gee,uLr,pLr,Oee,_Lr,bLr,vLr,FS,FLr,wwe,TLr,MLr,ELr,Gt,TS,CLr,Awe,wLr,ALr,Pm,LLr,Lwe,yLr,xLr,Vee,$Lr,kLr,SLr,n3,RLr,bo,MS,PLr,ywe,BLr,ILr,Cn,NLr,xwe,qLr,DLr,$we,jLr,GLr,kwe,OLr,VLr,XLr,ut,s3,Swe,zLr,QLr,Xee,WLr,ULr,HLr,l3,Rwe,JLr,YLr,zee,ZLr,KLr,eyr,i3,Pwe,oyr,ryr,Qee,tyr,ayr,nyr,d3,Bwe,syr,lyr,Wee,iyr,dyr,myr,m3,Iwe,cyr,fyr,Uee,gyr,hyr,uyr,c3,pyr,Nwe,_yr,byr,qwe,vyr,Fyr,f3,Tao,Bm,g3,Dwe,ES,Tyr,jwe,Myr,Mao,or,CS,Eyr,Im,Cyr,Hee,wyr,Ayr,Jee,Lyr,yyr,xyr,wS,$yr,Gwe,kyr,Syr,Ryr,Ot,AS,Pyr,Owe,Byr,Iyr,Nm,Nyr,Vwe,qyr,Dyr,Yee,jyr,Gyr,Oyr,h3,Vyr,vo,LS,Xyr,Xwe,zyr,Qyr,wn,Wyr,zwe,Uyr,Hyr,Qwe,Jyr,Yyr,Wwe,Zyr,Kyr,e9r,Le,u3,Uwe,o9r,r9r,Zee,t9r,a9r,n9r,p3,Hwe,s9r,l9r,Kee,i9r,d9r,m9r,_3,Jwe,c9r,f9r,eoe,g9r,h9r,u9r,b3,Ywe,p9r,_9r,ooe,b9r,v9r,F9r,v3,Zwe,T9r,M9r,roe,E9r,C9r,w9r,F3,Kwe,A9r,L9r,toe,y9r,x9r,$9r,T3,eAe,k9r,S9r,aoe,R9r,P9r,B9r,M3,oAe,I9r,N9r,noe,q9r,D9r,j9r,E3,rAe,G9r,O9r,soe,V9r,X9r,z9r,C3,tAe,Q9r,W9r,loe,U9r,H9r,J9r,w3,Y9r,aAe,Z9r,K9r,nAe,exr,oxr,A3,Eao,qm,L3,sAe,yS,rxr,lAe,txr,Cao,rr,xS,axr,Dm,nxr,ioe,sxr,lxr,doe,ixr,dxr,mxr,$S,cxr,iAe,fxr,gxr,hxr,Vt,kS,uxr,dAe,pxr,_xr,jm,bxr,mAe,vxr,Fxr,moe,Txr,Mxr,Exr,y3,Cxr,Fo,SS,wxr,cAe,Axr,Lxr,An,yxr,fAe,xxr,$xr,gAe,kxr,Sxr,hAe,Rxr,Pxr,Bxr,Gm,x3,uAe,Ixr,Nxr,coe,qxr,Dxr,jxr,$3,pAe,Gxr,Oxr,foe,Vxr,Xxr,zxr,k3,_Ae,Qxr,Wxr,goe,Uxr,Hxr,Jxr,S3,Yxr,bAe,Zxr,Kxr,vAe,e$r,o$r,R3,wao,Om,P3,FAe,RS,r$r,TAe,t$r,Aao,tr,PS,a$r,Vm,n$r,hoe,s$r,l$r,uoe,i$r,d$r,m$r,BS,c$r,MAe,f$r,g$r,h$r,Xt,IS,u$r,EAe,p$r,_$r,Xm,b$r,CAe,v$r,F$r,poe,T$r,M$r,E$r,B3,C$r,To,NS,w$r,wAe,A$r,L$r,Ln,y$r,AAe,x$r,$$r,LAe,k$r,S$r,yAe,R$r,P$r,B$r,pt,I3,xAe,I$r,N$r,_oe,q$r,D$r,j$r,N3,$Ae,G$r,O$r,boe,V$r,X$r,z$r,q3,kAe,Q$r,W$r,voe,U$r,H$r,J$r,D3,SAe,Y$r,Z$r,Foe,K$r,ekr,okr,j3,RAe,rkr,tkr,Toe,akr,nkr,skr,G3,lkr,PAe,ikr,dkr,BAe,mkr,ckr,O3,Lao,zm,V3,IAe,qS,fkr,NAe,gkr,yao,ar,DS,hkr,Qm,ukr,Moe,pkr,_kr,Eoe,bkr,vkr,Fkr,jS,Tkr,qAe,Mkr,Ekr,Ckr,zt,GS,wkr,DAe,Akr,Lkr,Wm,ykr,jAe,xkr,$kr,Coe,kkr,Skr,Rkr,X3,Pkr,Mo,OS,Bkr,GAe,Ikr,Nkr,yn,qkr,OAe,Dkr,jkr,VAe,Gkr,Okr,XAe,Vkr,Xkr,zkr,xn,z3,zAe,Qkr,Wkr,woe,Ukr,Hkr,Jkr,Q3,QAe,Ykr,Zkr,Aoe,Kkr,eSr,oSr,W3,WAe,rSr,tSr,Loe,aSr,nSr,sSr,U3,UAe,lSr,iSr,yoe,dSr,mSr,cSr,H3,fSr,HAe,gSr,hSr,JAe,uSr,pSr,J3,xao,Um,Y3,YAe,VS,_Sr,ZAe,bSr,$ao,nr,XS,vSr,Hm,FSr,xoe,TSr,MSr,$oe,ESr,CSr,wSr,zS,ASr,KAe,LSr,ySr,xSr,Qt,QS,$Sr,e6e,kSr,SSr,Jm,RSr,o6e,PSr,BSr,koe,ISr,NSr,qSr,Z3,DSr,Eo,WS,jSr,r6e,GSr,OSr,$n,VSr,t6e,XSr,zSr,a6e,QSr,WSr,n6e,USr,HSr,JSr,_t,K3,s6e,YSr,ZSr,Soe,KSr,eRr,oRr,e5,l6e,rRr,tRr,Roe,aRr,nRr,sRr,o5,i6e,lRr,iRr,Poe,dRr,mRr,cRr,r5,d6e,fRr,gRr,Boe,hRr,uRr,pRr,t5,m6e,_Rr,bRr,Ioe,vRr,FRr,TRr,a5,MRr,c6e,ERr,CRr,f6e,wRr,ARr,n5,kao,Ym,s5,g6e,US,LRr,h6e,yRr,Sao,sr,HS,xRr,Zm,$Rr,Noe,kRr,SRr,qoe,RRr,PRr,BRr,JS,IRr,u6e,NRr,qRr,DRr,Wt,YS,jRr,p6e,GRr,ORr,Km,VRr,_6e,XRr,zRr,Doe,QRr,WRr,URr,l5,HRr,Co,ZS,JRr,b6e,YRr,ZRr,kn,KRr,v6e,ePr,oPr,F6e,rPr,tPr,T6e,aPr,nPr,sPr,M6e,i5,E6e,lPr,iPr,joe,dPr,mPr,cPr,d5,fPr,C6e,gPr,hPr,w6e,uPr,pPr,m5,Rao,ec,c5,A6e,KS,_Pr,L6e,bPr,Pao,lr,eR,vPr,oc,FPr,Goe,TPr,MPr,Ooe,EPr,CPr,wPr,oR,APr,y6e,LPr,yPr,xPr,Ut,rR,$Pr,x6e,kPr,SPr,rc,RPr,$6e,PPr,BPr,Voe,IPr,NPr,qPr,f5,DPr,wo,tR,jPr,k6e,GPr,OPr,Sn,VPr,S6e,XPr,zPr,R6e,QPr,WPr,P6e,UPr,HPr,JPr,bt,g5,B6e,YPr,ZPr,Xoe,KPr,eBr,oBr,h5,I6e,rBr,tBr,zoe,aBr,nBr,sBr,u5,N6e,lBr,iBr,Qoe,dBr,mBr,cBr,p5,q6e,fBr,gBr,Woe,hBr,uBr,pBr,_5,D6e,_Br,bBr,Uoe,vBr,FBr,TBr,b5,MBr,j6e,EBr,CBr,G6e,wBr,ABr,v5,Bao,tc,F5,O6e,aR,LBr,V6e,yBr,Iao,ir,nR,xBr,ac,$Br,Hoe,kBr,SBr,Joe,RBr,PBr,BBr,sR,IBr,X6e,NBr,qBr,DBr,Ht,lR,jBr,z6e,GBr,OBr,nc,VBr,Q6e,XBr,zBr,Yoe,QBr,WBr,UBr,T5,HBr,Ao,iR,JBr,W6e,YBr,ZBr,Rn,KBr,U6e,eIr,oIr,H6e,rIr,tIr,J6e,aIr,nIr,sIr,Y6e,M5,Z6e,lIr,iIr,Zoe,dIr,mIr,cIr,E5,fIr,K6e,gIr,hIr,e7e,uIr,pIr,C5,Nao,sc,w5,o7e,dR,_Ir,r7e,bIr,qao,dr,mR,vIr,lc,FIr,Koe,TIr,MIr,ere,EIr,CIr,wIr,cR,AIr,t7e,LIr,yIr,xIr,Jt,fR,$Ir,a7e,kIr,SIr,ic,RIr,n7e,PIr,BIr,ore,IIr,NIr,qIr,A5,DIr,Lo,gR,jIr,s7e,GIr,OIr,Pn,VIr,l7e,XIr,zIr,i7e,QIr,WIr,d7e,UIr,HIr,JIr,m7e,L5,c7e,YIr,ZIr,rre,KIr,eNr,oNr,y5,rNr,f7e,tNr,aNr,g7e,nNr,sNr,x5,Dao,dc,$5,h7e,hR,lNr,u7e,iNr,jao,mr,uR,dNr,mc,mNr,tre,cNr,fNr,are,gNr,hNr,uNr,pR,pNr,p7e,_Nr,bNr,vNr,Yt,_R,FNr,_7e,TNr,MNr,cc,ENr,b7e,CNr,wNr,nre,ANr,LNr,yNr,k5,xNr,jr,bR,$Nr,v7e,kNr,SNr,Bn,RNr,F7e,PNr,BNr,T7e,INr,NNr,M7e,qNr,DNr,jNr,P,S5,E7e,GNr,ONr,sre,VNr,XNr,zNr,R5,C7e,QNr,WNr,lre,UNr,HNr,JNr,P5,w7e,YNr,ZNr,ire,KNr,eqr,oqr,B5,A7e,rqr,tqr,dre,aqr,nqr,sqr,I5,L7e,lqr,iqr,mre,dqr,mqr,cqr,N5,y7e,fqr,gqr,cre,hqr,uqr,pqr,q5,x7e,_qr,bqr,fre,vqr,Fqr,Tqr,D5,$7e,Mqr,Eqr,gre,Cqr,wqr,Aqr,j5,k7e,Lqr,yqr,hre,xqr,$qr,kqr,G5,S7e,Sqr,Rqr,ure,Pqr,Bqr,Iqr,O5,R7e,Nqr,qqr,pre,Dqr,jqr,Gqr,V5,P7e,Oqr,Vqr,_re,Xqr,zqr,Qqr,X5,B7e,Wqr,Uqr,bre,Hqr,Jqr,Yqr,z5,I7e,Zqr,Kqr,vre,eDr,oDr,rDr,Q5,N7e,tDr,aDr,Fre,nDr,sDr,lDr,W5,q7e,iDr,dDr,Tre,mDr,cDr,fDr,U5,D7e,gDr,hDr,Mre,uDr,pDr,_Dr,H5,j7e,bDr,vDr,Ere,FDr,TDr,MDr,J5,G7e,EDr,CDr,Cre,wDr,ADr,LDr,Y5,O7e,yDr,xDr,wre,$Dr,kDr,SDr,kl,V7e,RDr,PDr,Are,BDr,IDr,Lre,NDr,qDr,DDr,Z5,X7e,jDr,GDr,yre,ODr,VDr,XDr,K5,z7e,zDr,QDr,xre,WDr,UDr,HDr,e0,Q7e,JDr,YDr,$re,ZDr,KDr,ejr,o0,W7e,ojr,rjr,kre,tjr,ajr,njr,r0,U7e,sjr,ljr,Sre,ijr,djr,mjr,t0,H7e,cjr,fjr,Rre,gjr,hjr,ujr,a0,J7e,pjr,_jr,Pre,bjr,vjr,Fjr,n0,Y7e,Tjr,Mjr,Bre,Ejr,Cjr,wjr,s0,Z7e,Ajr,Ljr,Ire,yjr,xjr,$jr,l0,K7e,kjr,Sjr,Nre,Rjr,Pjr,Bjr,i0,e8e,Ijr,Njr,qre,qjr,Djr,jjr,d0,o8e,Gjr,Ojr,Dre,Vjr,Xjr,zjr,m0,r8e,Qjr,Wjr,jre,Ujr,Hjr,Jjr,c0,t8e,Yjr,Zjr,Gre,Kjr,eGr,oGr,f0,a8e,rGr,tGr,Ore,aGr,nGr,sGr,g0,n8e,lGr,iGr,Vre,dGr,mGr,cGr,h0,s8e,fGr,gGr,Xre,hGr,uGr,pGr,u0,l8e,_Gr,bGr,zre,vGr,FGr,TGr,p0,i8e,MGr,EGr,Qre,CGr,wGr,AGr,_0,d8e,LGr,yGr,Wre,xGr,$Gr,kGr,b0,m8e,SGr,RGr,Ure,PGr,BGr,IGr,v0,c8e,NGr,qGr,Hre,DGr,jGr,GGr,F0,f8e,OGr,VGr,Jre,XGr,zGr,QGr,T0,g8e,WGr,UGr,Yre,HGr,JGr,YGr,M0,h8e,ZGr,KGr,Zre,eOr,oOr,rOr,E0,u8e,tOr,aOr,Kre,nOr,sOr,lOr,C0,p8e,iOr,dOr,ete,mOr,cOr,fOr,w0,_8e,gOr,hOr,ote,uOr,pOr,_Or,A0,b8e,bOr,vOr,rte,FOr,TOr,MOr,L0,v8e,EOr,COr,tte,wOr,AOr,LOr,y0,F8e,yOr,xOr,ate,$Or,kOr,SOr,x0,T8e,ROr,POr,nte,BOr,IOr,NOr,$0,M8e,qOr,DOr,ste,jOr,GOr,OOr,k0,E8e,VOr,XOr,lte,zOr,QOr,WOr,S0,C8e,UOr,HOr,ite,JOr,YOr,ZOr,R0,w8e,KOr,eVr,dte,oVr,rVr,tVr,P0,A8e,aVr,nVr,mte,sVr,lVr,iVr,B0,Gao,fc,I0,L8e,vR,dVr,y8e,mVr,Oao,cr,FR,cVr,gc,fVr,cte,gVr,hVr,fte,uVr,pVr,_Vr,TR,bVr,x8e,vVr,FVr,TVr,Zt,MR,MVr,$8e,EVr,CVr,hc,wVr,k8e,AVr,LVr,gte,yVr,xVr,$Vr,N0,kVr,Gr,ER,SVr,S8e,RVr,PVr,In,BVr,R8e,IVr,NVr,P8e,qVr,DVr,B8e,jVr,GVr,OVr,le,q0,I8e,VVr,XVr,hte,zVr,QVr,WVr,D0,N8e,UVr,HVr,ute,JVr,YVr,ZVr,j0,q8e,KVr,eXr,pte,oXr,rXr,tXr,G0,D8e,aXr,nXr,_te,sXr,lXr,iXr,O0,j8e,dXr,mXr,bte,cXr,fXr,gXr,V0,G8e,hXr,uXr,vte,pXr,_Xr,bXr,X0,O8e,vXr,FXr,Fte,TXr,MXr,EXr,z0,V8e,CXr,wXr,Tte,AXr,LXr,yXr,Q0,X8e,xXr,$Xr,Mte,kXr,SXr,RXr,W0,z8e,PXr,BXr,Ete,IXr,NXr,qXr,U0,Q8e,DXr,jXr,Cte,GXr,OXr,VXr,H0,W8e,XXr,zXr,wte,QXr,WXr,UXr,J0,U8e,HXr,JXr,Ate,YXr,ZXr,KXr,Y0,H8e,ezr,ozr,Lte,rzr,tzr,azr,Z0,J8e,nzr,szr,yte,lzr,izr,dzr,K0,Y8e,mzr,czr,xte,fzr,gzr,hzr,ew,Z8e,uzr,pzr,$te,_zr,bzr,vzr,ow,K8e,Fzr,Tzr,kte,Mzr,Ezr,Czr,rw,eLe,wzr,Azr,Ste,Lzr,yzr,xzr,tw,oLe,$zr,kzr,Rte,Szr,Rzr,Pzr,aw,rLe,Bzr,Izr,Pte,Nzr,qzr,Dzr,nw,tLe,jzr,Gzr,Bte,Ozr,Vzr,Xzr,sw,aLe,zzr,Qzr,Ite,Wzr,Uzr,Hzr,lw,Vao,uc,iw,nLe,CR,Jzr,sLe,Yzr,Xao,fr,wR,Zzr,pc,Kzr,Nte,eQr,oQr,qte,rQr,tQr,aQr,AR,nQr,lLe,sQr,lQr,iQr,Kt,LR,dQr,iLe,mQr,cQr,_c,fQr,dLe,gQr,hQr,Dte,uQr,pQr,_Qr,dw,bQr,Or,yR,vQr,mLe,FQr,TQr,Nn,MQr,cLe,EQr,CQr,fLe,wQr,AQr,gLe,LQr,yQr,xQr,Me,mw,hLe,$Qr,kQr,jte,SQr,RQr,PQr,cw,uLe,BQr,IQr,Gte,NQr,qQr,DQr,fw,pLe,jQr,GQr,Ote,OQr,VQr,XQr,gw,_Le,zQr,QQr,Vte,WQr,UQr,HQr,hw,bLe,JQr,YQr,Xte,ZQr,KQr,eWr,uw,vLe,oWr,rWr,zte,tWr,aWr,nWr,pw,FLe,sWr,lWr,Qte,iWr,dWr,mWr,_w,TLe,cWr,fWr,Wte,gWr,hWr,uWr,bw,MLe,pWr,_Wr,Ute,bWr,vWr,FWr,vw,ELe,TWr,MWr,Hte,EWr,CWr,wWr,Fw,CLe,AWr,LWr,Jte,yWr,xWr,$Wr,Tw,wLe,kWr,SWr,Yte,RWr,PWr,BWr,Mw,ALe,IWr,NWr,Zte,qWr,DWr,jWr,Ew,LLe,GWr,OWr,Kte,VWr,XWr,zWr,Cw,zao,bc,ww,yLe,xR,QWr,xLe,WWr,Qao,gr,$R,UWr,vc,HWr,eae,JWr,YWr,oae,ZWr,KWr,eUr,kR,oUr,$Le,rUr,tUr,aUr,ea,SR,nUr,kLe,sUr,lUr,Fc,iUr,SLe,dUr,mUr,rae,cUr,fUr,gUr,Aw,hUr,Vr,RR,uUr,RLe,pUr,_Ur,qn,bUr,PLe,vUr,FUr,BLe,TUr,MUr,ILe,EUr,CUr,wUr,ye,Lw,NLe,AUr,LUr,tae,yUr,xUr,$Ur,yw,qLe,kUr,SUr,aae,RUr,PUr,BUr,xw,DLe,IUr,NUr,nae,qUr,DUr,jUr,Sl,jLe,GUr,OUr,sae,VUr,XUr,lae,zUr,QUr,WUr,$w,GLe,UUr,HUr,iae,JUr,YUr,ZUr,kw,OLe,KUr,eHr,dae,oHr,rHr,tHr,Sw,VLe,aHr,nHr,mae,sHr,lHr,iHr,Rw,XLe,dHr,mHr,cae,cHr,fHr,gHr,Pw,zLe,hHr,uHr,fae,pHr,_Hr,bHr,Bw,QLe,vHr,FHr,gae,THr,MHr,EHr,Iw,Wao,Tc,Nw,WLe,PR,CHr,ULe,wHr,Uao,hr,BR,AHr,Mc,LHr,hae,yHr,xHr,uae,$Hr,kHr,SHr,IR,RHr,HLe,PHr,BHr,IHr,oa,NR,NHr,JLe,qHr,DHr,Ec,jHr,YLe,GHr,OHr,pae,VHr,XHr,zHr,qw,QHr,Xr,qR,WHr,ZLe,UHr,HHr,Dn,JHr,KLe,YHr,ZHr,eye,KHr,eJr,oye,oJr,rJr,tJr,Cc,Dw,rye,aJr,nJr,_ae,sJr,lJr,iJr,jw,tye,dJr,mJr,bae,cJr,fJr,gJr,Gw,aye,hJr,uJr,vae,pJr,_Jr,bJr,Ow,Hao,wc,Vw,nye,DR,vJr,sye,FJr,Jao,ur,jR,TJr,Ac,MJr,Fae,EJr,CJr,Tae,wJr,AJr,LJr,GR,yJr,lye,xJr,$Jr,kJr,ra,OR,SJr,iye,RJr,PJr,Lc,BJr,dye,IJr,NJr,Mae,qJr,DJr,jJr,Xw,GJr,zr,VR,OJr,mye,VJr,XJr,jn,zJr,cye,QJr,WJr,fye,UJr,HJr,gye,JJr,YJr,ZJr,ce,zw,hye,KJr,eYr,Eae,oYr,rYr,tYr,Qw,uye,aYr,nYr,Cae,sYr,lYr,iYr,Ww,pye,dYr,mYr,wae,cYr,fYr,gYr,Uw,_ye,hYr,uYr,Aae,pYr,_Yr,bYr,Hw,bye,vYr,FYr,Lae,TYr,MYr,EYr,Jw,vye,CYr,wYr,yae,AYr,LYr,yYr,Yw,Fye,xYr,$Yr,xae,kYr,SYr,RYr,Zw,Tye,PYr,BYr,$ae,IYr,NYr,qYr,Kw,Mye,DYr,jYr,kae,GYr,OYr,VYr,eA,Eye,XYr,zYr,Sae,QYr,WYr,UYr,oA,Cye,HYr,JYr,Rae,YYr,ZYr,KYr,rA,wye,eZr,oZr,Pae,rZr,tZr,aZr,tA,Aye,nZr,sZr,Bae,lZr,iZr,dZr,aA,Lye,mZr,cZr,Iae,fZr,gZr,hZr,nA,yye,uZr,pZr,Nae,_Zr,bZr,vZr,sA,xye,FZr,TZr,qae,MZr,EZr,CZr,lA,$ye,wZr,AZr,Dae,LZr,yZr,xZr,iA,kye,$Zr,kZr,jae,SZr,RZr,PZr,dA,Sye,BZr,IZr,Gae,NZr,qZr,DZr,mA,Rye,jZr,GZr,Oae,OZr,VZr,XZr,cA,Pye,zZr,QZr,Vae,WZr,UZr,HZr,fA,Yao,yc,gA,Bye,XR,JZr,Iye,YZr,Zao,pr,zR,ZZr,xc,KZr,Xae,eKr,oKr,zae,rKr,tKr,aKr,QR,nKr,Nye,sKr,lKr,iKr,ta,WR,dKr,qye,mKr,cKr,$c,fKr,Dye,gKr,hKr,Qae,uKr,pKr,_Kr,hA,bKr,Qr,UR,vKr,jye,FKr,TKr,Gn,MKr,Gye,EKr,CKr,Oye,wKr,AKr,Vye,LKr,yKr,xKr,xe,uA,Xye,$Kr,kKr,Wae,SKr,RKr,PKr,pA,zye,BKr,IKr,Uae,NKr,qKr,DKr,_A,Qye,jKr,GKr,Hae,OKr,VKr,XKr,bA,Wye,zKr,QKr,Jae,WKr,UKr,HKr,vA,Uye,JKr,YKr,Yae,ZKr,KKr,eet,FA,Hye,oet,ret,Zae,tet,aet,net,TA,Jye,set,iet,Kae,det,met,cet,MA,Yye,fet,get,ene,het,uet,pet,EA,Zye,_et,bet,one,vet,Fet,Tet,CA,Kye,Met,Eet,rne,Cet,wet,Aet,wA,Kao,kc,AA,e9e,HR,Let,o9e,yet,eno,_r,JR,xet,Sc,$et,tne,ket,Set,ane,Ret,Pet,Bet,YR,Iet,r9e,Net,qet,Det,aa,ZR,jet,t9e,Get,Oet,Rc,Vet,a9e,Xet,zet,nne,Qet,Wet,Uet,LA,Het,Wr,KR,Jet,n9e,Yet,Zet,On,Ket,s9e,eot,oot,l9e,rot,tot,i9e,aot,not,sot,re,yA,d9e,lot,iot,sne,dot,mot,cot,xA,m9e,fot,got,lne,hot,uot,pot,$A,c9e,_ot,bot,ine,vot,Fot,Tot,kA,f9e,Mot,Eot,dne,Cot,wot,Aot,SA,g9e,Lot,yot,mne,xot,$ot,kot,RA,h9e,Sot,Rot,cne,Pot,Bot,Iot,PA,u9e,Not,qot,fne,Dot,jot,Got,BA,p9e,Oot,Vot,gne,Xot,zot,Qot,IA,_9e,Wot,Uot,hne,Hot,Jot,Yot,NA,b9e,Zot,Kot,une,ert,ort,rrt,qA,v9e,trt,art,pne,nrt,srt,lrt,DA,F9e,irt,drt,_ne,mrt,crt,frt,jA,T9e,grt,hrt,bne,urt,prt,_rt,GA,M9e,brt,vrt,vne,Frt,Trt,Mrt,OA,E9e,Ert,Crt,Fne,wrt,Art,Lrt,VA,C9e,yrt,xrt,Tne,$rt,krt,Srt,XA,w9e,Rrt,Prt,Mne,Brt,Irt,Nrt,zA,A9e,qrt,Drt,Ene,jrt,Grt,Ort,QA,L9e,Vrt,Xrt,Cne,zrt,Qrt,Wrt,WA,y9e,Urt,Hrt,wne,Jrt,Yrt,Zrt,UA,x9e,Krt,ett,Ane,ott,rtt,ttt,HA,$9e,att,ntt,Lne,stt,ltt,itt,JA,k9e,dtt,mtt,yne,ctt,ftt,gtt,YA,S9e,htt,utt,xne,ptt,_tt,btt,ZA,R9e,vtt,Ftt,$ne,Ttt,Mtt,Ett,KA,P9e,Ctt,wtt,kne,Att,Ltt,ytt,e6,B9e,xtt,$tt,Sne,ktt,Stt,Rtt,o6,I9e,Ptt,Btt,Rne,Itt,Ntt,qtt,r6,ono,Pc,t6,N9e,eP,Dtt,q9e,jtt,rno,br,oP,Gtt,Bc,Ott,Pne,Vtt,Xtt,Bne,ztt,Qtt,Wtt,rP,Utt,D9e,Htt,Jtt,Ytt,na,tP,Ztt,j9e,Ktt,eat,Ic,oat,G9e,rat,tat,Ine,aat,nat,sat,a6,lat,Ur,aP,iat,O9e,dat,mat,Vn,cat,V9e,fat,gat,X9e,hat,uat,z9e,pat,_at,bat,ve,n6,Q9e,vat,Fat,Nne,Tat,Mat,Eat,s6,W9e,Cat,wat,qne,Aat,Lat,yat,l6,U9e,xat,$at,Dne,kat,Sat,Rat,i6,H9e,Pat,Bat,jne,Iat,Nat,qat,d6,J9e,Dat,jat,Gne,Gat,Oat,Vat,m6,Y9e,Xat,zat,One,Qat,Wat,Uat,c6,Z9e,Hat,Jat,Vne,Yat,Zat,Kat,f6,K9e,ent,ont,Xne,rnt,tnt,ant,g6,exe,nnt,snt,zne,lnt,int,dnt,h6,oxe,mnt,cnt,Qne,fnt,gnt,hnt,u6,rxe,unt,pnt,Wne,_nt,bnt,vnt,p6,txe,Fnt,Tnt,Une,Mnt,Ent,Cnt,_6,axe,wnt,Ant,Hne,Lnt,ynt,xnt,b6,nxe,$nt,knt,Jne,Snt,Rnt,Pnt,v6,sxe,Bnt,Int,Yne,Nnt,qnt,Dnt,F6,lxe,jnt,Gnt,Zne,Ont,Vnt,Xnt,T6,ixe,znt,Qnt,Kne,Wnt,Unt,Hnt,M6,tno,Nc,E6,dxe,nP,Jnt,mxe,Ynt,ano,vr,sP,Znt,qc,Knt,ese,est,ost,ose,rst,tst,ast,lP,nst,cxe,sst,lst,ist,sa,iP,dst,fxe,mst,cst,Dc,fst,gxe,gst,hst,rse,ust,pst,_st,C6,bst,Hr,dP,vst,hxe,Fst,Tst,Xn,Mst,uxe,Est,Cst,pxe,wst,Ast,_xe,Lst,yst,xst,mP,w6,bxe,$st,kst,tse,Sst,Rst,Pst,A6,vxe,Bst,Ist,ase,Nst,qst,Dst,L6,nno,jc,y6,Fxe,cP,jst,Txe,Gst,sno,Fr,fP,Ost,Gc,Vst,nse,Xst,zst,sse,Qst,Wst,Ust,gP,Hst,Mxe,Jst,Yst,Zst,la,hP,Kst,Exe,elt,olt,Oc,rlt,Cxe,tlt,alt,lse,nlt,slt,llt,x6,ilt,Jr,uP,dlt,wxe,mlt,clt,zn,flt,Axe,glt,hlt,Lxe,ult,plt,yxe,_lt,blt,vlt,xxe,$6,$xe,Flt,Tlt,ise,Mlt,Elt,Clt,k6,lno,Vc,S6,kxe,pP,wlt,Sxe,Alt,ino,Tr,_P,Llt,Xc,ylt,dse,xlt,$lt,mse,klt,Slt,Rlt,bP,Plt,Rxe,Blt,Ilt,Nlt,ia,vP,qlt,Pxe,Dlt,jlt,zc,Glt,Bxe,Olt,Vlt,cse,Xlt,zlt,Qlt,R6,Wlt,Yr,FP,Ult,Ixe,Hlt,Jlt,Qn,Ylt,Nxe,Zlt,Klt,qxe,eit,oit,Dxe,rit,tit,ait,jxe,P6,Gxe,nit,sit,fse,lit,iit,dit,B6,dno,Qc,I6,Oxe,TP,mit,Vxe,cit,mno,Mr,MP,fit,Wc,git,gse,hit,uit,hse,pit,_it,bit,EP,vit,Xxe,Fit,Tit,Mit,da,CP,Eit,zxe,Cit,wit,Uc,Ait,Qxe,Lit,yit,use,xit,$it,kit,N6,Sit,Zr,wP,Rit,Wxe,Pit,Bit,Wn,Iit,Uxe,Nit,qit,Hxe,Dit,jit,Jxe,Git,Oit,Vit,ie,q6,Yxe,Xit,zit,pse,Qit,Wit,Uit,D6,Zxe,Hit,Jit,_se,Yit,Zit,Kit,j6,Kxe,edt,odt,bse,rdt,tdt,adt,G6,e$e,ndt,sdt,vse,ldt,idt,ddt,O6,o$e,mdt,cdt,Fse,fdt,gdt,hdt,V6,r$e,udt,pdt,Tse,_dt,bdt,vdt,X6,t$e,Fdt,Tdt,Mse,Mdt,Edt,Cdt,z6,a$e,wdt,Adt,Ese,Ldt,ydt,xdt,Q6,n$e,$dt,kdt,Cse,Sdt,Rdt,Pdt,W6,s$e,Bdt,Idt,wse,Ndt,qdt,Ddt,U6,l$e,jdt,Gdt,Ase,Odt,Vdt,Xdt,H6,i$e,zdt,Qdt,Lse,Wdt,Udt,Hdt,J6,d$e,Jdt,Ydt,yse,Zdt,Kdt,emt,Y6,m$e,omt,rmt,xse,tmt,amt,nmt,Z6,c$e,smt,lmt,$se,imt,dmt,mmt,K6,f$e,cmt,fmt,kse,gmt,hmt,umt,e7,g$e,pmt,_mt,Sse,bmt,vmt,Fmt,o7,h$e,Tmt,Mmt,Rse,Emt,Cmt,wmt,r7,u$e,Amt,Lmt,Pse,ymt,xmt,$mt,t7,p$e,kmt,Smt,Bse,Rmt,Pmt,Bmt,a7,_$e,Imt,Nmt,Ise,qmt,Dmt,jmt,n7,b$e,Gmt,Omt,Nse,Vmt,Xmt,zmt,s7,cno,Hc,l7,v$e,AP,Qmt,F$e,Wmt,fno,Er,LP,Umt,Jc,Hmt,qse,Jmt,Ymt,Dse,Zmt,Kmt,ect,yP,oct,T$e,rct,tct,act,ma,xP,nct,M$e,sct,lct,Yc,ict,E$e,dct,mct,jse,cct,fct,gct,i7,hct,Kr,$P,uct,C$e,pct,_ct,Un,bct,w$e,vct,Fct,A$e,Tct,Mct,L$e,Ect,Cct,wct,fe,d7,y$e,Act,Lct,Gse,yct,xct,$ct,m7,x$e,kct,Sct,Ose,Rct,Pct,Bct,c7,$$e,Ict,Nct,Vse,qct,Dct,jct,f7,k$e,Gct,Oct,Xse,Vct,Xct,zct,g7,S$e,Qct,Wct,zse,Uct,Hct,Jct,h7,R$e,Yct,Zct,Qse,Kct,eft,oft,u7,P$e,rft,tft,Wse,aft,nft,sft,p7,B$e,lft,ift,Use,dft,mft,cft,_7,I$e,fft,gft,Hse,hft,uft,pft,b7,N$e,_ft,bft,Jse,vft,Fft,Tft,v7,q$e,Mft,Eft,Yse,Cft,wft,Aft,F7,D$e,Lft,yft,Zse,xft,$ft,kft,T7,j$e,Sft,Rft,Kse,Pft,Bft,Ift,M7,G$e,Nft,qft,ele,Dft,jft,Gft,E7,O$e,Oft,Vft,ole,Xft,zft,Qft,C7,V$e,Wft,Uft,rle,Hft,Jft,Yft,w7,X$e,Zft,Kft,tle,egt,ogt,rgt,A7,z$e,tgt,agt,ale,ngt,sgt,lgt,L7,Q$e,igt,dgt,nle,mgt,cgt,fgt,y7,W$e,ggt,hgt,sle,ugt,pgt,_gt,x7,U$e,bgt,vgt,lle,Fgt,Tgt,Mgt,$7,gno,Zc,k7,H$e,kP,Egt,J$e,Cgt,hno,Cr,SP,wgt,Kc,Agt,ile,Lgt,ygt,dle,xgt,$gt,kgt,RP,Sgt,Y$e,Rgt,Pgt,Bgt,ca,PP,Igt,Z$e,Ngt,qgt,ef,Dgt,K$e,jgt,Ggt,mle,Ogt,Vgt,Xgt,S7,zgt,et,BP,Qgt,eke,Wgt,Ugt,Hn,Hgt,oke,Jgt,Ygt,rke,Zgt,Kgt,tke,eht,oht,rht,ake,R7,nke,tht,aht,cle,nht,sht,lht,P7,uno,of,B7,ske,IP,iht,lke,dht,pno,wr,NP,mht,rf,cht,fle,fht,ght,gle,hht,uht,pht,qP,_ht,ike,bht,vht,Fht,fa,DP,Tht,dke,Mht,Eht,tf,Cht,mke,wht,Aht,hle,Lht,yht,xht,I7,$ht,ot,jP,kht,cke,Sht,Rht,Jn,Pht,fke,Bht,Iht,gke,Nht,qht,hke,Dht,jht,Ght,GP,N7,uke,Oht,Vht,ule,Xht,zht,Qht,q7,pke,Wht,Uht,ple,Hht,Jht,Yht,D7,_no,af,j7,_ke,OP,Zht,bke,Kht,bno,Ar,VP,eut,nf,out,_le,rut,tut,ble,aut,nut,sut,XP,lut,vke,iut,dut,mut,ga,zP,cut,Fke,fut,gut,sf,hut,Tke,uut,put,vle,_ut,but,vut,G7,Fut,rt,QP,Tut,Mke,Mut,Eut,Yn,Cut,Eke,wut,Aut,Cke,Lut,yut,wke,xut,$ut,kut,te,O7,Ake,Sut,Rut,Fle,Put,But,Iut,V7,Lke,Nut,qut,Tle,Dut,jut,Gut,X7,yke,Out,Vut,Mle,Xut,zut,Qut,z7,xke,Wut,Uut,Ele,Hut,Jut,Yut,Q7,$ke,Zut,Kut,Cle,ept,opt,rpt,W7,kke,tpt,apt,wle,npt,spt,lpt,U7,Ske,ipt,dpt,Ale,mpt,cpt,fpt,H7,Rke,gpt,hpt,Lle,upt,ppt,_pt,J7,Pke,bpt,vpt,yle,Fpt,Tpt,Mpt,Y7,Bke,Ept,Cpt,xle,wpt,Apt,Lpt,Z7,Ike,ypt,xpt,$le,$pt,kpt,Spt,K7,Nke,Rpt,Ppt,kle,Bpt,Ipt,Npt,e8,qke,qpt,Dpt,Sle,jpt,Gpt,Opt,o8,Dke,Vpt,Xpt,Rle,zpt,Qpt,Wpt,r8,jke,Upt,Hpt,Ple,Jpt,Ypt,Zpt,t8,Gke,Kpt,e_t,Ble,o_t,r_t,t_t,a8,Oke,a_t,n_t,Ile,s_t,l_t,i_t,n8,Vke,d_t,m_t,Nle,c_t,f_t,g_t,s8,Xke,h_t,u_t,qle,p_t,__t,b_t,l8,zke,v_t,F_t,Dle,T_t,M_t,E_t,i8,Qke,C_t,w_t,jle,A_t,L_t,y_t,d8,Wke,x_t,$_t,Gle,k_t,S_t,R_t,m8,Uke,P_t,B_t,Ole,I_t,N_t,q_t,c8,Hke,D_t,j_t,Vle,G_t,O_t,V_t,f8,Jke,X_t,z_t,Xle,Q_t,W_t,U_t,g8,Yke,H_t,J_t,zle,Y_t,Z_t,K_t,h8,Zke,e1t,o1t,Qle,r1t,t1t,a1t,u8,vno,lf,p8,Kke,WP,n1t,eSe,s1t,Fno,Lr,UP,l1t,df,i1t,Wle,d1t,m1t,Ule,c1t,f1t,g1t,HP,h1t,oSe,u1t,p1t,_1t,ha,JP,b1t,rSe,v1t,F1t,mf,T1t,tSe,M1t,E1t,Hle,C1t,w1t,A1t,_8,L1t,tt,YP,y1t,aSe,x1t,$1t,Zn,k1t,nSe,S1t,R1t,sSe,P1t,B1t,lSe,I1t,N1t,q1t,$e,b8,iSe,D1t,j1t,Jle,G1t,O1t,V1t,v8,dSe,X1t,z1t,Yle,Q1t,W1t,U1t,F8,mSe,H1t,J1t,Zle,Y1t,Z1t,K1t,T8,cSe,e2t,o2t,Kle,r2t,t2t,a2t,M8,fSe,n2t,s2t,eie,l2t,i2t,d2t,E8,gSe,m2t,c2t,oie,f2t,g2t,h2t,C8,hSe,u2t,p2t,rie,_2t,b2t,v2t,w8,uSe,F2t,T2t,tie,M2t,E2t,C2t,A8,pSe,w2t,A2t,aie,L2t,y2t,x2t,L8,_Se,$2t,k2t,nie,S2t,R2t,P2t,y8,Tno,cf,x8,bSe,ZP,B2t,vSe,I2t,Mno,yr,KP,N2t,ff,q2t,sie,D2t,j2t,lie,G2t,O2t,V2t,eB,X2t,FSe,z2t,Q2t,W2t,ua,oB,U2t,TSe,H2t,J2t,gf,Y2t,MSe,Z2t,K2t,iie,ebt,obt,rbt,$8,tbt,at,rB,abt,ESe,nbt,sbt,Kn,lbt,CSe,ibt,dbt,wSe,mbt,cbt,ASe,fbt,gbt,hbt,Ee,k8,LSe,ubt,pbt,die,_bt,bbt,vbt,S8,ySe,Fbt,Tbt,mie,Mbt,Ebt,Cbt,R8,xSe,wbt,Abt,cie,Lbt,ybt,xbt,P8,$Se,$bt,kbt,fie,Sbt,Rbt,Pbt,B8,kSe,Bbt,Ibt,gie,Nbt,qbt,Dbt,I8,SSe,jbt,Gbt,hie,Obt,Vbt,Xbt,N8,RSe,zbt,Qbt,uie,Wbt,Ubt,Hbt,q8,PSe,Jbt,Ybt,pie,Zbt,Kbt,evt,D8,BSe,ovt,rvt,_ie,tvt,avt,nvt,j8,ISe,svt,lvt,bie,ivt,dvt,mvt,G8,NSe,cvt,fvt,vie,gvt,hvt,uvt,O8,qSe,pvt,_vt,Fie,bvt,vvt,Fvt,V8,DSe,Tvt,Mvt,Tie,Evt,Cvt,wvt,X8,Eno,hf,z8,jSe,tB,Avt,GSe,Lvt,Cno,xr,aB,yvt,uf,xvt,Mie,$vt,kvt,Eie,Svt,Rvt,Pvt,nB,Bvt,OSe,Ivt,Nvt,qvt,pa,sB,Dvt,VSe,jvt,Gvt,pf,Ovt,XSe,Vvt,Xvt,Cie,zvt,Qvt,Wvt,Q8,Uvt,nt,lB,Hvt,zSe,Jvt,Yvt,es,Zvt,QSe,Kvt,eFt,WSe,oFt,rFt,USe,tFt,aFt,nFt,ke,W8,HSe,sFt,lFt,wie,iFt,dFt,mFt,U8,JSe,cFt,fFt,Aie,gFt,hFt,uFt,H8,YSe,pFt,_Ft,Lie,bFt,vFt,FFt,J8,ZSe,TFt,MFt,yie,EFt,CFt,wFt,Y8,KSe,AFt,LFt,xie,yFt,xFt,$Ft,Z8,eRe,kFt,SFt,$ie,RFt,PFt,BFt,K8,oRe,IFt,NFt,kie,qFt,DFt,jFt,eL,rRe,GFt,OFt,Sie,VFt,XFt,zFt,oL,tRe,QFt,WFt,Rie,UFt,HFt,JFt,rL,aRe,YFt,ZFt,Pie,KFt,eTt,oTt,tL,wno,_f,aL,nRe,iB,rTt,sRe,tTt,Ano,$r,dB,aTt,bf,nTt,Bie,sTt,lTt,Iie,iTt,dTt,mTt,mB,cTt,lRe,fTt,gTt,hTt,_a,cB,uTt,iRe,pTt,_Tt,vf,bTt,dRe,vTt,FTt,Nie,TTt,MTt,ETt,nL,CTt,st,fB,wTt,mRe,ATt,LTt,os,yTt,cRe,xTt,$Tt,fRe,kTt,STt,gRe,RTt,PTt,BTt,Se,sL,hRe,ITt,NTt,qie,qTt,DTt,jTt,lL,uRe,GTt,OTt,Die,VTt,XTt,zTt,iL,pRe,QTt,WTt,jie,UTt,HTt,JTt,dL,_Re,YTt,ZTt,Gie,KTt,eMt,oMt,mL,bRe,rMt,tMt,Oie,aMt,nMt,sMt,cL,vRe,lMt,iMt,Vie,dMt,mMt,cMt,fL,FRe,fMt,gMt,Xie,hMt,uMt,pMt,gL,TRe,_Mt,bMt,zie,vMt,FMt,TMt,hL,MRe,MMt,EMt,Qie,CMt,wMt,AMt,uL,ERe,LMt,yMt,Wie,xMt,$Mt,kMt,pL,Lno,Ff,_L,CRe,gB,SMt,wRe,RMt,yno,kr,hB,PMt,Tf,BMt,Uie,IMt,NMt,Hie,qMt,DMt,jMt,uB,GMt,ARe,OMt,VMt,XMt,ba,pB,zMt,LRe,QMt,WMt,Mf,UMt,yRe,HMt,JMt,Jie,YMt,ZMt,KMt,bL,eEt,lt,_B,oEt,xRe,rEt,tEt,rs,aEt,$Re,nEt,sEt,kRe,lEt,iEt,SRe,dEt,mEt,cEt,Re,vL,RRe,fEt,gEt,Yie,hEt,uEt,pEt,FL,PRe,_Et,bEt,Zie,vEt,FEt,TEt,TL,BRe,MEt,EEt,Kie,CEt,wEt,AEt,ML,IRe,LEt,yEt,ede,xEt,$Et,kEt,EL,NRe,SEt,REt,ode,PEt,BEt,IEt,CL,qRe,NEt,qEt,rde,DEt,jEt,GEt,wL,DRe,OEt,VEt,tde,XEt,zEt,QEt,AL,jRe,WEt,UEt,ade,HEt,JEt,YEt,LL,GRe,ZEt,KEt,nde,e4t,o4t,r4t,yL,ORe,t4t,a4t,sde,n4t,s4t,l4t,xL,xno,Ef,$L,VRe,bB,i4t,XRe,d4t,$no,Sr,vB,m4t,Cf,c4t,lde,f4t,g4t,ide,h4t,u4t,p4t,FB,_4t,zRe,b4t,v4t,F4t,va,TB,T4t,QRe,M4t,E4t,wf,C4t,WRe,w4t,A4t,dde,L4t,y4t,x4t,kL,$4t,it,MB,k4t,URe,S4t,R4t,ts,P4t,HRe,B4t,I4t,JRe,N4t,q4t,YRe,D4t,j4t,G4t,Pe,SL,ZRe,O4t,V4t,mde,X4t,z4t,Q4t,RL,KRe,W4t,U4t,cde,H4t,J4t,Y4t,PL,ePe,Z4t,K4t,fde,eCt,oCt,rCt,BL,oPe,tCt,aCt,gde,nCt,sCt,lCt,IL,rPe,iCt,dCt,hde,mCt,cCt,fCt,NL,tPe,gCt,hCt,ude,uCt,pCt,_Ct,qL,aPe,bCt,vCt,pde,FCt,TCt,MCt,DL,nPe,ECt,CCt,_de,wCt,ACt,LCt,jL,sPe,yCt,xCt,bde,$Ct,kCt,SCt,GL,lPe,RCt,PCt,vde,BCt,ICt,NCt,OL,kno,Af,VL,iPe,EB,qCt,dPe,DCt,Sno,Rr,CB,jCt,Lf,GCt,Fde,OCt,VCt,Tde,XCt,zCt,QCt,wB,WCt,mPe,UCt,HCt,JCt,Fa,AB,YCt,cPe,ZCt,KCt,yf,e3t,fPe,o3t,r3t,Mde,t3t,a3t,n3t,XL,s3t,dt,LB,l3t,gPe,i3t,d3t,as,m3t,hPe,c3t,f3t,uPe,g3t,h3t,pPe,u3t,p3t,_3t,ze,zL,_Pe,b3t,v3t,Ede,F3t,T3t,M3t,QL,bPe,E3t,C3t,Cde,w3t,A3t,L3t,WL,vPe,y3t,x3t,wde,$3t,k3t,S3t,UL,FPe,R3t,P3t,Ade,B3t,I3t,N3t,HL,TPe,q3t,D3t,Lde,j3t,G3t,O3t,JL,MPe,V3t,X3t,yde,z3t,Q3t,W3t,YL,EPe,U3t,H3t,xde,J3t,Y3t,Z3t,ZL,CPe,K3t,e5t,$de,o5t,r5t,t5t,KL,Rno,xf,ey,wPe,yB,a5t,APe,n5t,Pno,Pr,xB,s5t,$f,l5t,kde,i5t,d5t,Sde,m5t,c5t,f5t,$B,g5t,LPe,h5t,u5t,p5t,Ta,kB,_5t,yPe,b5t,v5t,kf,F5t,xPe,T5t,M5t,Rde,E5t,C5t,w5t,oy,A5t,mt,SB,L5t,$Pe,y5t,x5t,ns,$5t,kPe,k5t,S5t,SPe,R5t,P5t,RPe,B5t,I5t,N5t,Qe,ry,PPe,q5t,D5t,Pde,j5t,G5t,O5t,ty,BPe,V5t,X5t,Bde,z5t,Q5t,W5t,ay,IPe,U5t,H5t,Ide,J5t,Y5t,Z5t,ny,NPe,K5t,e0t,Nde,o0t,r0t,t0t,sy,qPe,a0t,n0t,qde,s0t,l0t,i0t,ly,DPe,d0t,m0t,Dde,c0t,f0t,g0t,iy,jPe,h0t,u0t,jde,p0t,_0t,b0t,dy,GPe,v0t,F0t,Gde,T0t,M0t,E0t,my,Bno,Sf,cy,OPe,RB,C0t,VPe,w0t,Ino,Br,PB,A0t,Rf,L0t,Ode,y0t,x0t,Vde,$0t,k0t,S0t,BB,R0t,XPe,P0t,B0t,I0t,Ma,IB,N0t,zPe,q0t,D0t,Pf,j0t,QPe,G0t,O0t,Xde,V0t,X0t,z0t,fy,Q0t,ct,NB,W0t,WPe,U0t,H0t,ss,J0t,UPe,Y0t,Z0t,HPe,K0t,ewt,JPe,owt,rwt,twt,YPe,gy,ZPe,awt,nwt,zde,swt,lwt,iwt,hy,Nno,Bf,uy,KPe,qB,dwt,eBe,mwt,qno,Ir,DB,cwt,If,fwt,Qde,gwt,hwt,Wde,uwt,pwt,_wt,jB,bwt,oBe,vwt,Fwt,Twt,Ea,GB,Mwt,rBe,Ewt,Cwt,Nf,wwt,tBe,Awt,Lwt,Ude,ywt,xwt,$wt,py,kwt,ft,OB,Swt,aBe,Rwt,Pwt,ls,Bwt,nBe,Iwt,Nwt,sBe,qwt,Dwt,lBe,jwt,Gwt,Owt,VB,_y,iBe,Vwt,Xwt,Hde,zwt,Qwt,Wwt,by,dBe,Uwt,Hwt,Jde,Jwt,Ywt,Zwt,vy,Dno,qf,Fy,mBe,XB,Kwt,cBe,eAt,jno,Nr,zB,oAt,Df,rAt,Yde,tAt,aAt,Zde,nAt,sAt,lAt,QB,iAt,fBe,dAt,mAt,cAt,Ca,WB,fAt,gBe,gAt,hAt,jf,uAt,hBe,pAt,_At,Kde,bAt,vAt,FAt,Ty,TAt,gt,UB,MAt,uBe,EAt,CAt,is,wAt,pBe,AAt,LAt,_Be,yAt,xAt,bBe,$At,kAt,SAt,vBe,My,FBe,RAt,PAt,eme,BAt,IAt,NAt,Ey,Gno;return d=new oe({}),on=new B({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),d$=new oe({}),m$=new B({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),Hf=new qAt({props:{warning:!0,$$slots:{default:[C3a]},$$scope:{ctx:$}}}),c$=new oe({}),f$=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L665"}}),u$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L688"}}),Cu=new N({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[w3a]},$$scope:{ctx:$}}}),p$=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L811"}}),_$=new oe({}),b$=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L430"}}),T$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/main/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L444"}}),dp=new N({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[A3a]},$$scope:{ctx:$}}}),M$=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L645"}}),E$=new oe({}),C$=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L204"}}),L$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/main/en/internal/image_processing_utils#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L218"}}),r_=new qAt({props:{$$slots:{default:[L3a]},$$scope:{ctx:$}}}),t_=new N({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[y3a]},$$scope:{ctx:$}}}),y$=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L345"}}),x$=new oe({}),$$=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L96"}}),R$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L110"}}),x_=new qAt({props:{$$slots:{default:[x3a]},$$scope:{ctx:$}}}),$_=new N({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[$3a]},$$scope:{ctx:$}}}),P$=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L277"}}),B$=new oe({}),I$=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L887"}}),q$=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel">CodeGenModel</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig">ConditionalDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrModel">ConditionalDetrModel</a> (Conditional DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrModel">DeformableDetrModel</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig">DonutSwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel">DonutSwinModel</a> (DonutSwin model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel">ErnieModel</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmModel">EsmModel</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig">GPTNeoXJapaneseConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel">GPTNeoXJapaneseModel</a> (GPT NeoX Japanese model)</li>
<li><a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel">GroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltModel">LiltModel</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMModel">MarkupLMModel</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel">MobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel">MvpModel</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel">NezhaModel</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel">OwlViTModel</a> (OWL-ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel">PegasusXModel</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model">Swinv2Model</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerConfig">TableTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerModel">TableTransformerModel</a> (Table Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig">TimeSeriesTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel">TimeSeriesTransformerModel</a> (Time Series Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig">ViTMSNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNModel">ViTMSNModel</a> (ViTMSN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel">VideoMAEModel</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperModel">WhisperModel</a> (Whisper model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig">XCLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel">XCLIPModel</a> (X-CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),R_=new N({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[k3a]},$$scope:{ctx:$}}}),D$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),ob=new N({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[S3a]},$$scope:{ctx:$}}}),j$=new oe({}),G$=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L894"}}),V$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining">ErnieForPreTraining</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining">NezhaForPreTraining</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining">VideoMAEForPreTraining</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),tb=new N({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[R3a]},$$scope:{ctx:$}}}),X$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Kb=new N({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[P3a]},$$scope:{ctx:$}}}),z$=new oe({}),Q$=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L909"}}),U$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM">CodeGenForCausalLM</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM">ErnieForCausalLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig">GPTNeoXJapaneseConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM">GPTNeoXJapaneseForCausalLM</a> (GPT NeoX Japanese model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM">MvpForCausalLM</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),ov=new N({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[B3a]},$$scope:{ctx:$}}}),H$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),zv=new N({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[I3a]},$$scope:{ctx:$}}}),J$=new oe({}),Y$=new R({props:{name:"class transformers.AutoModelForDepthEstimation",anchor:"transformers.AutoModelForDepthEstimation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1052"}}),K$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForDepthEstimation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDepthEstimation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTForDepthEstimation">DPTForDepthEstimation</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNForDepthEstimation">GLPNForDepthEstimation</a> (GLPN model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Wv=new N({props:{anchor:"transformers.AutoModelForDepthEstimation.from_config.example",$$slots:{default:[N3a]},$$scope:{ctx:$}}}),ek=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForDepthEstimation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Yv=new N({props:{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.example",$$slots:{default:[q3a]},$$scope:{ctx:$}}}),rk=new oe({}),tk=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L916"}}),nk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM">ErnieForMaskedLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM">NezhaForMaskedLM</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Kv=new N({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[D3a]},$$scope:{ctx:$}}}),sk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),jF=new N({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[j3a]},$$scope:{ctx:$}}}),lk=new oe({}),ik=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L923"}}),mk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration">PegasusXForConditionalGeneration</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),OF=new N({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[G3a]},$$scope:{ctx:$}}}),ck=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),mT=new N({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[O3a]},$$scope:{ctx:$}}}),fk=new oe({}),gk=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L932"}}),uk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification">ErnieForSequenceClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmForSequenceClassification">EsmForSequenceClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltForSequenceClassification">LiltForSequenceClassification</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification">LukeForSequenceClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification">MarkupLMForSequenceClassification</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification">MvpForSequenceClassification</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification">NezhaForSequenceClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification">OPTForSequenceClassification</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),fT=new N({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[V3a]},$$scope:{ctx:$}}}),pk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),pM=new N({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[X3a]},$$scope:{ctx:$}}}),_k=new oe({}),bk=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L988"}}),Fk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice">ErnieForMultipleChoice</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice">LukeForMultipleChoice</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice">NezhaForMultipleChoice</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),bM=new N({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[z3a]},$$scope:{ctx:$}}}),Tk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),ZM=new N({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[Q3a]},$$scope:{ctx:$}}}),Mk=new oe({}),Ek=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L995"}}),wk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction">ErnieForNextSentencePrediction</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction">NezhaForNextSentencePrediction</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),eE=new N({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[W3a]},$$scope:{ctx:$}}}),Ak=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),dE=new N({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[U3a]},$$scope:{ctx:$}}}),Lk=new oe({}),yk=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L981"}}),$k=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification">ErnieForTokenClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmForTokenClassification">EsmForTokenClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltForTokenClassification">LiltForTokenClassification</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification">LukeForTokenClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification">MarkupLMForTokenClassification</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification">NezhaForTokenClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),cE=new N({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[H3a]},$$scope:{ctx:$}}}),kk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),e4=new N({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[J3a]},$$scope:{ctx:$}}}),Sk=new oe({}),Rk=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L941"}}),Bk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForQuestionAnswering">BloomForQuestionAnswering</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering">ErnieForQuestionAnswering</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltForQuestionAnswering">LiltForQuestionAnswering</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering">LukeForQuestionAnswering</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering">MarkupLMForQuestionAnswering</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering">MvpForQuestionAnswering</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering">NezhaForQuestionAnswering</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForQuestionAnswering">OPTForQuestionAnswering</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),r4=new N({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[Y3a]},$$scope:{ctx:$}}}),Ik=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Z4=new N({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[Z3a]},$$scope:{ctx:$}}}),Nk=new oe({}),qk=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L948"}}),jk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),eC=new N({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[K3a]},$$scope:{ctx:$}}}),Gk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),tC=new N({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[e5a]},$$scope:{ctx:$}}}),Ok=new oe({}),Vk=new R({props:{name:"class transformers.AutoModelForDocumentQuestionAnswering",anchor:"transformers.AutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L970"}}),zk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering">LayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),nC=new N({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[o5a]},$$scope:{ctx:$}}}),Qk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),mC=new N({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[r5a]},$$scope:{ctx:$}}}),Wk=new oe({}),Uk=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1004"}}),Jk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification">MobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification">Swinv2ForImageClassification</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig">ViTMSNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification">ViTMSNForImageClassification</a> (ViTMSN model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),fC=new N({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[t5a]},$$scope:{ctx:$}}}),Yk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),xC=new N({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[a5a]},$$scope:{ctx:$}}}),Zk=new oe({}),Kk=new R({props:{name:"class transformers.AutoModelForVideoClassification",anchor:"transformers.AutoModelForVideoClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1059"}}),oS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVideoClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification">VideoMAEForVideoClassification</a> (VideoMAE model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),kC=new N({props:{anchor:"transformers.AutoModelForVideoClassification.from_config.example",$$slots:{default:[n5a]},$$scope:{ctx:$}}}),rS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVideoClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),PC=new N({props:{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.example",$$slots:{default:[s5a]},$$scope:{ctx:$}}}),tS=new oe({}),aS=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1066"}}),sS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),IC=new N({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[l5a]},$$scope:{ctx:$}}}),lS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),DC=new N({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[i5a]},$$scope:{ctx:$}}}),iS=new oe({}),dS=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L959"}}),cS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),GC=new N({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[d5a]},$$scope:{ctx:$}}}),fS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),XC=new N({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[m5a]},$$scope:{ctx:$}}}),gS=new oe({}),hS=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1073"}}),pS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),QC=new N({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[c5a]},$$scope:{ctx:$}}}),_S=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),t3=new N({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[f5a]},$$scope:{ctx:$}}}),bS=new oe({}),vS=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1096"}}),TS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),n3=new N({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[g5a]},$$scope:{ctx:$}}}),MS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),f3=new N({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[h5a]},$$scope:{ctx:$}}}),ES=new oe({}),CS=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1080"}}),AS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),h3=new N({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[u5a]},$$scope:{ctx:$}}}),LS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),A3=new N({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[p5a]},$$scope:{ctx:$}}}),yS=new oe({}),xS=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1087"}}),kS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperForConditionalGeneration">WhisperForConditionalGeneration</a> (Whisper model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),y3=new N({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[_5a]},$$scope:{ctx:$}}}),SS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),R3=new N({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[b5a]},$$scope:{ctx:$}}}),RS=new oe({}),PS=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1105"}}),IS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),B3=new N({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[v5a]},$$scope:{ctx:$}}}),NS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),O3=new N({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[F5a]},$$scope:{ctx:$}}}),qS=new oe({}),DS=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1112"}}),GS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling">Swinv2ForMaskedImageModeling</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),X3=new N({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[T5a]},$$scope:{ctx:$}}}),OS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),J3=new N({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[M5a]},$$scope:{ctx:$}}}),VS=new oe({}),XS=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1036"}}),QS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig">ConditionalDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection">ConditionalDetrForObjectDetection</a> (Conditional DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection">DeformableDetrForObjectDetection</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerConfig">TableTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerForObjectDetection">TableTransformerForObjectDetection</a> (Table Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Z3=new N({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[E5a]},$$scope:{ctx:$}}}),WS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),n5=new N({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[C5a]},$$scope:{ctx:$}}}),US=new oe({}),HS=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1011"}}),YS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),l5=new N({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[w5a]},$$scope:{ctx:$}}}),ZS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),m5=new N({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[A5a]},$$scope:{ctx:$}}}),KS=new oe({}),eR=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1018"}}),rR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation">MobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),f5=new N({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[L5a]},$$scope:{ctx:$}}}),tR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),v5=new N({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[y5a]},$$scope:{ctx:$}}}),aR=new oe({}),nR=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1027"}}),lR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),T5=new N({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[x5a]},$$scope:{ctx:$}}}),iR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),C5=new N({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[$5a]},$$scope:{ctx:$}}}),dR=new oe({}),mR=new R({props:{name:"class transformers.AutoModelForZeroShotObjectDetection",anchor:"transformers.AutoModelForZeroShotObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1043"}}),fR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTForObjectDetection">OwlViTForObjectDetection</a> (OWL-ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),A5=new N({props:{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config.example",$$slots:{default:[k5a]},$$scope:{ctx:$}}}),gR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),x5=new N({props:{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.example",$$slots:{default:[S5a]},$$scope:{ctx:$}}}),hR=new oe({}),uR=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L444"}}),_R=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtModel">TFCvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel">TFDeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmModel">TFEsmModel</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/groupvit#transformers.TFGroupViTModel">TFGroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model">TFLayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel">TFMobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel">TFRegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel">TFResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel">TFSegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperModel">TFWhisperModel</a> (Whisper model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel">TFXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),k5=new N({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[R5a]},$$scope:{ctx:$}}}),bR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),B0=new N({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[P5a]},$$scope:{ctx:$}}}),vR=new oe({}),FR=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L451"}}),MR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),N0=new N({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[B5a]},$$scope:{ctx:$}}}),ER=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),lw=new N({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[I5a]},$$scope:{ctx:$}}}),CR=new oe({}),wR=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L466"}}),LR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM">TFXGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),dw=new N({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[N5a]},$$scope:{ctx:$}}}),yR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Cw=new N({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[q5a]},$$scope:{ctx:$}}}),xR=new oe({}),$R=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L482"}}),SR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtForImageClassification">TFCvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification">TFDeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher">TFDeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification">TFMobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification">TFRegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification">TFResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification">TFSegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Aw=new N({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[D5a]},$$scope:{ctx:$}}}),RR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Iw=new N({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[j5a]},$$scope:{ctx:$}}}),PR=new oe({}),BR=new R({props:{name:"class transformers.TFAutoModelForSemanticSegmentation",anchor:"transformers.TFAutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L491"}}),NR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation">TFData2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation">TFMobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation">TFSegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),qw=new N({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[G5a]},$$scope:{ctx:$}}}),qR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Ow=new N({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[O5a]},$$scope:{ctx:$}}}),DR=new oe({}),jR=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L507"}}),OR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForMaskedLM">TFEsmForMaskedLM</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Xw=new N({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[V5a]},$$scope:{ctx:$}}}),VR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),fA=new N({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[X5a]},$$scope:{ctx:$}}}),XR=new oe({}),zR=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L514"}}),WR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),hA=new N({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[z5a]},$$scope:{ctx:$}}}),UR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),wA=new N({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[Q5a]},$$scope:{ctx:$}}}),HR=new oe({}),JR=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L523"}}),ZR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForSequenceClassification">TFEsmForSequenceClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification">TFLayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),LA=new N({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[W5a]},$$scope:{ctx:$}}}),KR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),r6=new N({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[U5a]},$$scope:{ctx:$}}}),eP=new oe({}),oP=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L570"}}),tP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),a6=new N({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[H5a]},$$scope:{ctx:$}}}),aP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),M6=new N({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[J5a]},$$scope:{ctx:$}}}),nP=new oe({}),sP=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L577"}}),iP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),C6=new N({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[Y5a]},$$scope:{ctx:$}}}),dP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),L6=new N({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[Z5a]},$$scope:{ctx:$}}}),cP=new oe({}),fP=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L550"}}),hP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),x6=new N({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[K5a]},$$scope:{ctx:$}}}),uP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),k6=new N({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[e0a]},$$scope:{ctx:$}}}),pP=new oe({}),_P=new R({props:{name:"class transformers.TFAutoModelForDocumentQuestionAnswering",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L539"}}),vP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering">TFLayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),R6=new N({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[o0a]},$$scope:{ctx:$}}}),FP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),B6=new N({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[r0a]},$$scope:{ctx:$}}}),TP=new oe({}),MP=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L561"}}),CP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForTokenClassification">TFEsmForTokenClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification">TFLayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),N6=new N({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[t0a]},$$scope:{ctx:$}}}),wP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),s7=new N({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[a0a]},$$scope:{ctx:$}}}),AP=new oe({}),LP=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L532"}}),xP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering">TFLayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),i7=new N({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[n0a]},$$scope:{ctx:$}}}),$P=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),$7=new N({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[s0a]},$$scope:{ctx:$}}}),kP=new oe({}),SP=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L500"}}),PP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),S7=new N({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[l0a]},$$scope:{ctx:$}}}),BP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),P7=new N({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[i0a]},$$scope:{ctx:$}}}),IP=new oe({}),NP=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L586"}}),DP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration">TFWhisperForConditionalGeneration</a> (Whisper model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),I7=new N({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[d0a]},$$scope:{ctx:$}}}),jP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),D7=new N({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[m0a]},$$scope:{ctx:$}}}),OP=new oe({}),VP=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),zP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),G7=new N({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[c0a]},$$scope:{ctx:$}}}),QP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),u8=new N({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[f0a]},$$scope:{ctx:$}}}),WP=new oe({}),UP=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L260"}}),JP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),_8=new N({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[g0a]},$$scope:{ctx:$}}}),YP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),y8=new N({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[h0a]},$$scope:{ctx:$}}}),ZP=new oe({}),KP=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L253"}}),oB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),$8=new N({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[u0a]},$$scope:{ctx:$}}}),rB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),X8=new N({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[p0a]},$$scope:{ctx:$}}}),tB=new oe({}),aB=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L267"}}),sB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Q8=new N({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[_0a]},$$scope:{ctx:$}}}),lB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),tL=new N({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[b0a]},$$scope:{ctx:$}}}),iB=new oe({}),dB=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),cB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),nL=new N({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[v0a]},$$scope:{ctx:$}}}),fB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),pL=new N({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[F0a]},$$scope:{ctx:$}}}),gB=new oe({}),hB=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),pB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),bL=new N({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[T0a]},$$scope:{ctx:$}}}),_B=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),xL=new N({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[M0a]},$$scope:{ctx:$}}}),bB=new oe({}),vB=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),TB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),kL=new N({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[E0a]},$$scope:{ctx:$}}}),MB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),OL=new N({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[C0a]},$$scope:{ctx:$}}}),EB=new oe({}),CB=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),AB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),XL=new N({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[w0a]},$$scope:{ctx:$}}}),LB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),KL=new N({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[A0a]},$$scope:{ctx:$}}}),yB=new oe({}),xB=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L308"}}),kB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),oy=new N({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[L0a]},$$scope:{ctx:$}}}),SB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),my=new N({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[y0a]},$$scope:{ctx:$}}}),RB=new oe({}),PB=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),IB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),fy=new N({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[x0a]},$$scope:{ctx:$}}}),NB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),hy=new N({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[$0a]},$$scope:{ctx:$}}}),qB=new oe({}),DB=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),GB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),py=new N({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[k0a]},$$scope:{ctx:$}}}),OB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),vy=new N({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[S0a]},$$scope:{ctx:$}}}),XB=new oe({}),zB=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),WB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Ty=new N({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[R0a]},$$scope:{ctx:$}}}),UB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Ey=new N({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[P0a]},$$scope:{ctx:$}}}),{c(){g=a("meta"),v=l(),u=a("h1"),f=a("a"),p=a("span"),F(d.$$.fragment),h=l(),$o=a("span"),_d=o("Auto Classes"),Xf=l(),Tt=a("p"),bd=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),vd=a("code"),n$=o("from_pretrained()"),zf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Xe=l(),He=a("p"),Fd=o("Instantiating one of "),ms=a("a"),s$=o("AutoConfig"),cs=o(", "),fs=a("a"),l$=o("AutoModel"),Td=o(`, and
`),gs=a("a"),i$=o("AutoTokenizer"),Md=o(" will directly create a class of the relevant architecture. For instance"),Qf=l(),F(on.$$.fragment),Je=l(),Ae=a("p"),TN=o("will create a model that is an instance of "),Ed=a("a"),MN=o("BertModel"),EN=o("."),ko=l(),rn=a("p"),CN=o("There is one class of "),Wf=a("code"),wN=o("AutoModel"),dio=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),Cto=l(),Cd=a("h2"),Uf=a("a"),dfe=a("span"),F(d$.$$.fragment),mio=l(),mfe=a("span"),cio=o("Extending the Auto Classes"),wto=l(),hs=a("p"),fio=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),cfe=a("code"),gio=o("NewModel"),hio=o(", make sure you have a "),ffe=a("code"),uio=o("NewModelConfig"),pio=o(` then you can add those to the auto
classes like this:`),Ato=l(),F(m$.$$.fragment),Lto=l(),AN=a("p"),_io=o("You will then be able to use the auto classes like you would usually do!"),yto=l(),F(Hf.$$.fragment),xto=l(),wd=a("h2"),Jf=a("a"),gfe=a("span"),F(c$.$$.fragment),bio=l(),hfe=a("span"),vio=o("AutoConfig"),$to=l(),So=a("div"),F(f$.$$.fragment),Fio=l(),g$=a("p"),Tio=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),LN=a("a"),Mio=o("from_pretrained()"),Eio=o(" class method."),Cio=l(),h$=a("p"),wio=o("This class cannot be instantiated directly using "),ufe=a("code"),Aio=o("__init__()"),Lio=o(" (throws an error)."),yio=l(),qr=a("div"),F(u$.$$.fragment),xio=l(),pfe=a("p"),$io=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),kio=l(),Ad=a("p"),Sio=o("The configuration class to instantiate is selected based on the "),_fe=a("code"),Rio=o("model_type"),Pio=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),bfe=a("code"),Bio=o("pretrained_model_name_or_path"),Iio=o(":"),Nio=l(),A=a("ul"),Yf=a("li"),vfe=a("strong"),qio=o("albert"),Dio=o(" \u2014 "),yN=a("a"),jio=o("AlbertConfig"),Gio=o(" (ALBERT model)"),Oio=l(),Zf=a("li"),Ffe=a("strong"),Vio=o("bart"),Xio=o(" \u2014 "),xN=a("a"),zio=o("BartConfig"),Qio=o(" (BART model)"),Wio=l(),Kf=a("li"),Tfe=a("strong"),Uio=o("beit"),Hio=o(" \u2014 "),$N=a("a"),Jio=o("BeitConfig"),Yio=o(" (BEiT model)"),Zio=l(),eg=a("li"),Mfe=a("strong"),Kio=o("bert"),edo=o(" \u2014 "),kN=a("a"),odo=o("BertConfig"),rdo=o(" (BERT model)"),tdo=l(),og=a("li"),Efe=a("strong"),ado=o("bert-generation"),ndo=o(" \u2014 "),SN=a("a"),sdo=o("BertGenerationConfig"),ldo=o(" (Bert Generation model)"),ido=l(),rg=a("li"),Cfe=a("strong"),ddo=o("big_bird"),mdo=o(" \u2014 "),RN=a("a"),cdo=o("BigBirdConfig"),fdo=o(" (BigBird model)"),gdo=l(),tg=a("li"),wfe=a("strong"),hdo=o("bigbird_pegasus"),udo=o(" \u2014 "),PN=a("a"),pdo=o("BigBirdPegasusConfig"),_do=o(" (BigBird-Pegasus model)"),bdo=l(),ag=a("li"),Afe=a("strong"),vdo=o("blenderbot"),Fdo=o(" \u2014 "),BN=a("a"),Tdo=o("BlenderbotConfig"),Mdo=o(" (Blenderbot model)"),Edo=l(),ng=a("li"),Lfe=a("strong"),Cdo=o("blenderbot-small"),wdo=o(" \u2014 "),IN=a("a"),Ado=o("BlenderbotSmallConfig"),Ldo=o(" (BlenderbotSmall model)"),ydo=l(),sg=a("li"),yfe=a("strong"),xdo=o("bloom"),$do=o(" \u2014 "),NN=a("a"),kdo=o("BloomConfig"),Sdo=o(" (BLOOM model)"),Rdo=l(),lg=a("li"),xfe=a("strong"),Pdo=o("camembert"),Bdo=o(" \u2014 "),qN=a("a"),Ido=o("CamembertConfig"),Ndo=o(" (CamemBERT model)"),qdo=l(),ig=a("li"),$fe=a("strong"),Ddo=o("canine"),jdo=o(" \u2014 "),DN=a("a"),Gdo=o("CanineConfig"),Odo=o(" (CANINE model)"),Vdo=l(),dg=a("li"),kfe=a("strong"),Xdo=o("clip"),zdo=o(" \u2014 "),jN=a("a"),Qdo=o("CLIPConfig"),Wdo=o(" (CLIP model)"),Udo=l(),mg=a("li"),Sfe=a("strong"),Hdo=o("codegen"),Jdo=o(" \u2014 "),GN=a("a"),Ydo=o("CodeGenConfig"),Zdo=o(" (CodeGen model)"),Kdo=l(),cg=a("li"),Rfe=a("strong"),emo=o("conditional_detr"),omo=o(" \u2014 "),ON=a("a"),rmo=o("ConditionalDetrConfig"),tmo=o(" (Conditional DETR model)"),amo=l(),fg=a("li"),Pfe=a("strong"),nmo=o("convbert"),smo=o(" \u2014 "),VN=a("a"),lmo=o("ConvBertConfig"),imo=o(" (ConvBERT model)"),dmo=l(),gg=a("li"),Bfe=a("strong"),mmo=o("convnext"),cmo=o(" \u2014 "),XN=a("a"),fmo=o("ConvNextConfig"),gmo=o(" (ConvNeXT model)"),hmo=l(),hg=a("li"),Ife=a("strong"),umo=o("ctrl"),pmo=o(" \u2014 "),zN=a("a"),_mo=o("CTRLConfig"),bmo=o(" (CTRL model)"),vmo=l(),ug=a("li"),Nfe=a("strong"),Fmo=o("cvt"),Tmo=o(" \u2014 "),QN=a("a"),Mmo=o("CvtConfig"),Emo=o(" (CvT model)"),Cmo=l(),pg=a("li"),qfe=a("strong"),wmo=o("data2vec-audio"),Amo=o(" \u2014 "),WN=a("a"),Lmo=o("Data2VecAudioConfig"),ymo=o(" (Data2VecAudio model)"),xmo=l(),_g=a("li"),Dfe=a("strong"),$mo=o("data2vec-text"),kmo=o(" \u2014 "),UN=a("a"),Smo=o("Data2VecTextConfig"),Rmo=o(" (Data2VecText model)"),Pmo=l(),bg=a("li"),jfe=a("strong"),Bmo=o("data2vec-vision"),Imo=o(" \u2014 "),HN=a("a"),Nmo=o("Data2VecVisionConfig"),qmo=o(" (Data2VecVision model)"),Dmo=l(),vg=a("li"),Gfe=a("strong"),jmo=o("deberta"),Gmo=o(" \u2014 "),JN=a("a"),Omo=o("DebertaConfig"),Vmo=o(" (DeBERTa model)"),Xmo=l(),Fg=a("li"),Ofe=a("strong"),zmo=o("deberta-v2"),Qmo=o(" \u2014 "),YN=a("a"),Wmo=o("DebertaV2Config"),Umo=o(" (DeBERTa-v2 model)"),Hmo=l(),Tg=a("li"),Vfe=a("strong"),Jmo=o("decision_transformer"),Ymo=o(" \u2014 "),ZN=a("a"),Zmo=o("DecisionTransformerConfig"),Kmo=o(" (Decision Transformer model)"),eco=l(),Mg=a("li"),Xfe=a("strong"),oco=o("deformable_detr"),rco=o(" \u2014 "),KN=a("a"),tco=o("DeformableDetrConfig"),aco=o(" (Deformable DETR model)"),nco=l(),Eg=a("li"),zfe=a("strong"),sco=o("deit"),lco=o(" \u2014 "),eq=a("a"),ico=o("DeiTConfig"),dco=o(" (DeiT model)"),mco=l(),Cg=a("li"),Qfe=a("strong"),cco=o("detr"),fco=o(" \u2014 "),oq=a("a"),gco=o("DetrConfig"),hco=o(" (DETR model)"),uco=l(),wg=a("li"),Wfe=a("strong"),pco=o("distilbert"),_co=o(" \u2014 "),rq=a("a"),bco=o("DistilBertConfig"),vco=o(" (DistilBERT model)"),Fco=l(),Ag=a("li"),Ufe=a("strong"),Tco=o("donut-swin"),Mco=o(" \u2014 "),tq=a("a"),Eco=o("DonutSwinConfig"),Cco=o(" (DonutSwin model)"),wco=l(),Lg=a("li"),Hfe=a("strong"),Aco=o("dpr"),Lco=o(" \u2014 "),aq=a("a"),yco=o("DPRConfig"),xco=o(" (DPR model)"),$co=l(),yg=a("li"),Jfe=a("strong"),kco=o("dpt"),Sco=o(" \u2014 "),nq=a("a"),Rco=o("DPTConfig"),Pco=o(" (DPT model)"),Bco=l(),xg=a("li"),Yfe=a("strong"),Ico=o("electra"),Nco=o(" \u2014 "),sq=a("a"),qco=o("ElectraConfig"),Dco=o(" (ELECTRA model)"),jco=l(),$g=a("li"),Zfe=a("strong"),Gco=o("encoder-decoder"),Oco=o(" \u2014 "),lq=a("a"),Vco=o("EncoderDecoderConfig"),Xco=o(" (Encoder decoder model)"),zco=l(),kg=a("li"),Kfe=a("strong"),Qco=o("ernie"),Wco=o(" \u2014 "),iq=a("a"),Uco=o("ErnieConfig"),Hco=o(" (ERNIE model)"),Jco=l(),Sg=a("li"),ege=a("strong"),Yco=o("esm"),Zco=o(" \u2014 "),dq=a("a"),Kco=o("EsmConfig"),efo=o(" (ESM model)"),ofo=l(),Rg=a("li"),oge=a("strong"),rfo=o("flaubert"),tfo=o(" \u2014 "),mq=a("a"),afo=o("FlaubertConfig"),nfo=o(" (FlauBERT model)"),sfo=l(),Pg=a("li"),rge=a("strong"),lfo=o("flava"),ifo=o(" \u2014 "),cq=a("a"),dfo=o("FlavaConfig"),mfo=o(" (FLAVA model)"),cfo=l(),Bg=a("li"),tge=a("strong"),ffo=o("fnet"),gfo=o(" \u2014 "),fq=a("a"),hfo=o("FNetConfig"),ufo=o(" (FNet model)"),pfo=l(),Ig=a("li"),age=a("strong"),_fo=o("fsmt"),bfo=o(" \u2014 "),gq=a("a"),vfo=o("FSMTConfig"),Ffo=o(" (FairSeq Machine-Translation model)"),Tfo=l(),Ng=a("li"),nge=a("strong"),Mfo=o("funnel"),Efo=o(" \u2014 "),hq=a("a"),Cfo=o("FunnelConfig"),wfo=o(" (Funnel Transformer model)"),Afo=l(),qg=a("li"),sge=a("strong"),Lfo=o("glpn"),yfo=o(" \u2014 "),uq=a("a"),xfo=o("GLPNConfig"),$fo=o(" (GLPN model)"),kfo=l(),Dg=a("li"),lge=a("strong"),Sfo=o("gpt2"),Rfo=o(" \u2014 "),pq=a("a"),Pfo=o("GPT2Config"),Bfo=o(" (OpenAI GPT-2 model)"),Ifo=l(),jg=a("li"),ige=a("strong"),Nfo=o("gpt_neo"),qfo=o(" \u2014 "),_q=a("a"),Dfo=o("GPTNeoConfig"),jfo=o(" (GPT Neo model)"),Gfo=l(),Gg=a("li"),dge=a("strong"),Ofo=o("gpt_neox"),Vfo=o(" \u2014 "),bq=a("a"),Xfo=o("GPTNeoXConfig"),zfo=o(" (GPT NeoX model)"),Qfo=l(),Og=a("li"),mge=a("strong"),Wfo=o("gpt_neox_japanese"),Ufo=o(" \u2014 "),vq=a("a"),Hfo=o("GPTNeoXJapaneseConfig"),Jfo=o(" (GPT NeoX Japanese model)"),Yfo=l(),Vg=a("li"),cge=a("strong"),Zfo=o("gptj"),Kfo=o(" \u2014 "),Fq=a("a"),ego=o("GPTJConfig"),ogo=o(" (GPT-J model)"),rgo=l(),Xg=a("li"),fge=a("strong"),tgo=o("groupvit"),ago=o(" \u2014 "),Tq=a("a"),ngo=o("GroupViTConfig"),sgo=o(" (GroupViT model)"),lgo=l(),zg=a("li"),gge=a("strong"),igo=o("hubert"),dgo=o(" \u2014 "),Mq=a("a"),mgo=o("HubertConfig"),cgo=o(" (Hubert model)"),fgo=l(),Qg=a("li"),hge=a("strong"),ggo=o("ibert"),hgo=o(" \u2014 "),Eq=a("a"),ugo=o("IBertConfig"),pgo=o(" (I-BERT model)"),_go=l(),Wg=a("li"),uge=a("strong"),bgo=o("imagegpt"),vgo=o(" \u2014 "),Cq=a("a"),Fgo=o("ImageGPTConfig"),Tgo=o(" (ImageGPT model)"),Mgo=l(),Ug=a("li"),pge=a("strong"),Ego=o("layoutlm"),Cgo=o(" \u2014 "),wq=a("a"),wgo=o("LayoutLMConfig"),Ago=o(" (LayoutLM model)"),Lgo=l(),Hg=a("li"),_ge=a("strong"),ygo=o("layoutlmv2"),xgo=o(" \u2014 "),Aq=a("a"),$go=o("LayoutLMv2Config"),kgo=o(" (LayoutLMv2 model)"),Sgo=l(),Jg=a("li"),bge=a("strong"),Rgo=o("layoutlmv3"),Pgo=o(" \u2014 "),Lq=a("a"),Bgo=o("LayoutLMv3Config"),Igo=o(" (LayoutLMv3 model)"),Ngo=l(),Yg=a("li"),vge=a("strong"),qgo=o("led"),Dgo=o(" \u2014 "),yq=a("a"),jgo=o("LEDConfig"),Ggo=o(" (LED model)"),Ogo=l(),Zg=a("li"),Fge=a("strong"),Vgo=o("levit"),Xgo=o(" \u2014 "),xq=a("a"),zgo=o("LevitConfig"),Qgo=o(" (LeViT model)"),Wgo=l(),Kg=a("li"),Tge=a("strong"),Ugo=o("lilt"),Hgo=o(" \u2014 "),$q=a("a"),Jgo=o("LiltConfig"),Ygo=o(" (LiLT model)"),Zgo=l(),eh=a("li"),Mge=a("strong"),Kgo=o("longformer"),eho=o(" \u2014 "),kq=a("a"),oho=o("LongformerConfig"),rho=o(" (Longformer model)"),tho=l(),oh=a("li"),Ege=a("strong"),aho=o("longt5"),nho=o(" \u2014 "),Sq=a("a"),sho=o("LongT5Config"),lho=o(" (LongT5 model)"),iho=l(),rh=a("li"),Cge=a("strong"),dho=o("luke"),mho=o(" \u2014 "),Rq=a("a"),cho=o("LukeConfig"),fho=o(" (LUKE model)"),gho=l(),th=a("li"),wge=a("strong"),hho=o("lxmert"),uho=o(" \u2014 "),Pq=a("a"),pho=o("LxmertConfig"),_ho=o(" (LXMERT model)"),bho=l(),ah=a("li"),Age=a("strong"),vho=o("m2m_100"),Fho=o(" \u2014 "),Bq=a("a"),Tho=o("M2M100Config"),Mho=o(" (M2M100 model)"),Eho=l(),nh=a("li"),Lge=a("strong"),Cho=o("marian"),who=o(" \u2014 "),Iq=a("a"),Aho=o("MarianConfig"),Lho=o(" (Marian model)"),yho=l(),sh=a("li"),yge=a("strong"),xho=o("markuplm"),$ho=o(" \u2014 "),Nq=a("a"),kho=o("MarkupLMConfig"),Sho=o(" (MarkupLM model)"),Rho=l(),lh=a("li"),xge=a("strong"),Pho=o("maskformer"),Bho=o(" \u2014 "),qq=a("a"),Iho=o("MaskFormerConfig"),Nho=o(" (MaskFormer model)"),qho=l(),ih=a("li"),$ge=a("strong"),Dho=o("mbart"),jho=o(" \u2014 "),Dq=a("a"),Gho=o("MBartConfig"),Oho=o(" (mBART model)"),Vho=l(),dh=a("li"),kge=a("strong"),Xho=o("mctct"),zho=o(" \u2014 "),jq=a("a"),Qho=o("MCTCTConfig"),Who=o(" (M-CTC-T model)"),Uho=l(),mh=a("li"),Sge=a("strong"),Hho=o("megatron-bert"),Jho=o(" \u2014 "),Gq=a("a"),Yho=o("MegatronBertConfig"),Zho=o(" (Megatron-BERT model)"),Kho=l(),ch=a("li"),Rge=a("strong"),euo=o("mobilebert"),ouo=o(" \u2014 "),Oq=a("a"),ruo=o("MobileBertConfig"),tuo=o(" (MobileBERT model)"),auo=l(),fh=a("li"),Pge=a("strong"),nuo=o("mobilevit"),suo=o(" \u2014 "),Vq=a("a"),luo=o("MobileViTConfig"),iuo=o(" (MobileViT model)"),duo=l(),gh=a("li"),Bge=a("strong"),muo=o("mpnet"),cuo=o(" \u2014 "),Xq=a("a"),fuo=o("MPNetConfig"),guo=o(" (MPNet model)"),huo=l(),hh=a("li"),Ige=a("strong"),uuo=o("mt5"),puo=o(" \u2014 "),zq=a("a"),_uo=o("MT5Config"),buo=o(" (MT5 model)"),vuo=l(),uh=a("li"),Nge=a("strong"),Fuo=o("mvp"),Tuo=o(" \u2014 "),Qq=a("a"),Muo=o("MvpConfig"),Euo=o(" (MVP model)"),Cuo=l(),ph=a("li"),qge=a("strong"),wuo=o("nezha"),Auo=o(" \u2014 "),Wq=a("a"),Luo=o("NezhaConfig"),yuo=o(" (Nezha model)"),xuo=l(),_h=a("li"),Dge=a("strong"),$uo=o("nystromformer"),kuo=o(" \u2014 "),Uq=a("a"),Suo=o("NystromformerConfig"),Ruo=o(" (Nystr\xF6mformer model)"),Puo=l(),bh=a("li"),jge=a("strong"),Buo=o("openai-gpt"),Iuo=o(" \u2014 "),Hq=a("a"),Nuo=o("OpenAIGPTConfig"),quo=o(" (OpenAI GPT model)"),Duo=l(),vh=a("li"),Gge=a("strong"),juo=o("opt"),Guo=o(" \u2014 "),Jq=a("a"),Ouo=o("OPTConfig"),Vuo=o(" (OPT model)"),Xuo=l(),Fh=a("li"),Oge=a("strong"),zuo=o("owlvit"),Quo=o(" \u2014 "),Yq=a("a"),Wuo=o("OwlViTConfig"),Uuo=o(" (OWL-ViT model)"),Huo=l(),Th=a("li"),Vge=a("strong"),Juo=o("pegasus"),Yuo=o(" \u2014 "),Zq=a("a"),Zuo=o("PegasusConfig"),Kuo=o(" (Pegasus model)"),epo=l(),Mh=a("li"),Xge=a("strong"),opo=o("pegasus_x"),rpo=o(" \u2014 "),Kq=a("a"),tpo=o("PegasusXConfig"),apo=o(" (PEGASUS-X model)"),npo=l(),Eh=a("li"),zge=a("strong"),spo=o("perceiver"),lpo=o(" \u2014 "),eD=a("a"),ipo=o("PerceiverConfig"),dpo=o(" (Perceiver model)"),mpo=l(),Ch=a("li"),Qge=a("strong"),cpo=o("plbart"),fpo=o(" \u2014 "),oD=a("a"),gpo=o("PLBartConfig"),hpo=o(" (PLBart model)"),upo=l(),wh=a("li"),Wge=a("strong"),ppo=o("poolformer"),_po=o(" \u2014 "),rD=a("a"),bpo=o("PoolFormerConfig"),vpo=o(" (PoolFormer model)"),Fpo=l(),Ah=a("li"),Uge=a("strong"),Tpo=o("prophetnet"),Mpo=o(" \u2014 "),tD=a("a"),Epo=o("ProphetNetConfig"),Cpo=o(" (ProphetNet model)"),wpo=l(),Lh=a("li"),Hge=a("strong"),Apo=o("qdqbert"),Lpo=o(" \u2014 "),aD=a("a"),ypo=o("QDQBertConfig"),xpo=o(" (QDQBert model)"),$po=l(),yh=a("li"),Jge=a("strong"),kpo=o("rag"),Spo=o(" \u2014 "),nD=a("a"),Rpo=o("RagConfig"),Ppo=o(" (RAG model)"),Bpo=l(),xh=a("li"),Yge=a("strong"),Ipo=o("realm"),Npo=o(" \u2014 "),sD=a("a"),qpo=o("RealmConfig"),Dpo=o(" (REALM model)"),jpo=l(),$h=a("li"),Zge=a("strong"),Gpo=o("reformer"),Opo=o(" \u2014 "),lD=a("a"),Vpo=o("ReformerConfig"),Xpo=o(" (Reformer model)"),zpo=l(),kh=a("li"),Kge=a("strong"),Qpo=o("regnet"),Wpo=o(" \u2014 "),iD=a("a"),Upo=o("RegNetConfig"),Hpo=o(" (RegNet model)"),Jpo=l(),Sh=a("li"),ehe=a("strong"),Ypo=o("rembert"),Zpo=o(" \u2014 "),dD=a("a"),Kpo=o("RemBertConfig"),e_o=o(" (RemBERT model)"),o_o=l(),Rh=a("li"),ohe=a("strong"),r_o=o("resnet"),t_o=o(" \u2014 "),mD=a("a"),a_o=o("ResNetConfig"),n_o=o(" (ResNet model)"),s_o=l(),Ph=a("li"),rhe=a("strong"),l_o=o("retribert"),i_o=o(" \u2014 "),cD=a("a"),d_o=o("RetriBertConfig"),m_o=o(" (RetriBERT model)"),c_o=l(),Bh=a("li"),the=a("strong"),f_o=o("roberta"),g_o=o(" \u2014 "),fD=a("a"),h_o=o("RobertaConfig"),u_o=o(" (RoBERTa model)"),p_o=l(),Ih=a("li"),ahe=a("strong"),__o=o("roformer"),b_o=o(" \u2014 "),gD=a("a"),v_o=o("RoFormerConfig"),F_o=o(" (RoFormer model)"),T_o=l(),Nh=a("li"),nhe=a("strong"),M_o=o("segformer"),E_o=o(" \u2014 "),hD=a("a"),C_o=o("SegformerConfig"),w_o=o(" (SegFormer model)"),A_o=l(),qh=a("li"),she=a("strong"),L_o=o("sew"),y_o=o(" \u2014 "),uD=a("a"),x_o=o("SEWConfig"),$_o=o(" (SEW model)"),k_o=l(),Dh=a("li"),lhe=a("strong"),S_o=o("sew-d"),R_o=o(" \u2014 "),pD=a("a"),P_o=o("SEWDConfig"),B_o=o(" (SEW-D model)"),I_o=l(),jh=a("li"),ihe=a("strong"),N_o=o("speech-encoder-decoder"),q_o=o(" \u2014 "),_D=a("a"),D_o=o("SpeechEncoderDecoderConfig"),j_o=o(" (Speech Encoder decoder model)"),G_o=l(),Gh=a("li"),dhe=a("strong"),O_o=o("speech_to_text"),V_o=o(" \u2014 "),bD=a("a"),X_o=o("Speech2TextConfig"),z_o=o(" (Speech2Text model)"),Q_o=l(),Oh=a("li"),mhe=a("strong"),W_o=o("speech_to_text_2"),U_o=o(" \u2014 "),vD=a("a"),H_o=o("Speech2Text2Config"),J_o=o(" (Speech2Text2 model)"),Y_o=l(),Vh=a("li"),che=a("strong"),Z_o=o("splinter"),K_o=o(" \u2014 "),FD=a("a"),e1o=o("SplinterConfig"),o1o=o(" (Splinter model)"),r1o=l(),Xh=a("li"),fhe=a("strong"),t1o=o("squeezebert"),a1o=o(" \u2014 "),TD=a("a"),n1o=o("SqueezeBertConfig"),s1o=o(" (SqueezeBERT model)"),l1o=l(),zh=a("li"),ghe=a("strong"),i1o=o("swin"),d1o=o(" \u2014 "),MD=a("a"),m1o=o("SwinConfig"),c1o=o(" (Swin Transformer model)"),f1o=l(),Qh=a("li"),hhe=a("strong"),g1o=o("swinv2"),h1o=o(" \u2014 "),ED=a("a"),u1o=o("Swinv2Config"),p1o=o(" (Swin Transformer V2 model)"),_1o=l(),Wh=a("li"),uhe=a("strong"),b1o=o("t5"),v1o=o(" \u2014 "),CD=a("a"),F1o=o("T5Config"),T1o=o(" (T5 model)"),M1o=l(),Uh=a("li"),phe=a("strong"),E1o=o("table-transformer"),C1o=o(" \u2014 "),wD=a("a"),w1o=o("TableTransformerConfig"),A1o=o(" (Table Transformer model)"),L1o=l(),Hh=a("li"),_he=a("strong"),y1o=o("tapas"),x1o=o(" \u2014 "),AD=a("a"),$1o=o("TapasConfig"),k1o=o(" (TAPAS model)"),S1o=l(),Jh=a("li"),bhe=a("strong"),R1o=o("time_series_transformer"),P1o=o(" \u2014 "),LD=a("a"),B1o=o("TimeSeriesTransformerConfig"),I1o=o(" (Time Series Transformer model)"),N1o=l(),Yh=a("li"),vhe=a("strong"),q1o=o("trajectory_transformer"),D1o=o(" \u2014 "),yD=a("a"),j1o=o("TrajectoryTransformerConfig"),G1o=o(" (Trajectory Transformer model)"),O1o=l(),Zh=a("li"),Fhe=a("strong"),V1o=o("transfo-xl"),X1o=o(" \u2014 "),xD=a("a"),z1o=o("TransfoXLConfig"),Q1o=o(" (Transformer-XL model)"),W1o=l(),Kh=a("li"),The=a("strong"),U1o=o("trocr"),H1o=o(" \u2014 "),$D=a("a"),J1o=o("TrOCRConfig"),Y1o=o(" (TrOCR model)"),Z1o=l(),eu=a("li"),Mhe=a("strong"),K1o=o("unispeech"),e2o=o(" \u2014 "),kD=a("a"),o2o=o("UniSpeechConfig"),r2o=o(" (UniSpeech model)"),t2o=l(),ou=a("li"),Ehe=a("strong"),a2o=o("unispeech-sat"),n2o=o(" \u2014 "),SD=a("a"),s2o=o("UniSpeechSatConfig"),l2o=o(" (UniSpeechSat model)"),i2o=l(),ru=a("li"),Che=a("strong"),d2o=o("van"),m2o=o(" \u2014 "),RD=a("a"),c2o=o("VanConfig"),f2o=o(" (VAN model)"),g2o=l(),tu=a("li"),whe=a("strong"),h2o=o("videomae"),u2o=o(" \u2014 "),PD=a("a"),p2o=o("VideoMAEConfig"),_2o=o(" (VideoMAE model)"),b2o=l(),au=a("li"),Ahe=a("strong"),v2o=o("vilt"),F2o=o(" \u2014 "),BD=a("a"),T2o=o("ViltConfig"),M2o=o(" (ViLT model)"),E2o=l(),nu=a("li"),Lhe=a("strong"),C2o=o("vision-encoder-decoder"),w2o=o(" \u2014 "),ID=a("a"),A2o=o("VisionEncoderDecoderConfig"),L2o=o(" (Vision Encoder decoder model)"),y2o=l(),su=a("li"),yhe=a("strong"),x2o=o("vision-text-dual-encoder"),$2o=o(" \u2014 "),ND=a("a"),k2o=o("VisionTextDualEncoderConfig"),S2o=o(" (VisionTextDualEncoder model)"),R2o=l(),lu=a("li"),xhe=a("strong"),P2o=o("visual_bert"),B2o=o(" \u2014 "),qD=a("a"),I2o=o("VisualBertConfig"),N2o=o(" (VisualBERT model)"),q2o=l(),iu=a("li"),$he=a("strong"),D2o=o("vit"),j2o=o(" \u2014 "),DD=a("a"),G2o=o("ViTConfig"),O2o=o(" (ViT model)"),V2o=l(),du=a("li"),khe=a("strong"),X2o=o("vit_mae"),z2o=o(" \u2014 "),jD=a("a"),Q2o=o("ViTMAEConfig"),W2o=o(" (ViTMAE model)"),U2o=l(),mu=a("li"),She=a("strong"),H2o=o("vit_msn"),J2o=o(" \u2014 "),GD=a("a"),Y2o=o("ViTMSNConfig"),Z2o=o(" (ViTMSN model)"),K2o=l(),cu=a("li"),Rhe=a("strong"),ebo=o("wav2vec2"),obo=o(" \u2014 "),OD=a("a"),rbo=o("Wav2Vec2Config"),tbo=o(" (Wav2Vec2 model)"),abo=l(),fu=a("li"),Phe=a("strong"),nbo=o("wav2vec2-conformer"),sbo=o(" \u2014 "),VD=a("a"),lbo=o("Wav2Vec2ConformerConfig"),ibo=o(" (Wav2Vec2-Conformer model)"),dbo=l(),gu=a("li"),Bhe=a("strong"),mbo=o("wavlm"),cbo=o(" \u2014 "),XD=a("a"),fbo=o("WavLMConfig"),gbo=o(" (WavLM model)"),hbo=l(),hu=a("li"),Ihe=a("strong"),ubo=o("whisper"),pbo=o(" \u2014 "),zD=a("a"),_bo=o("WhisperConfig"),bbo=o(" (Whisper model)"),vbo=l(),uu=a("li"),Nhe=a("strong"),Fbo=o("xclip"),Tbo=o(" \u2014 "),QD=a("a"),Mbo=o("XCLIPConfig"),Ebo=o(" (X-CLIP model)"),Cbo=l(),pu=a("li"),qhe=a("strong"),wbo=o("xglm"),Abo=o(" \u2014 "),WD=a("a"),Lbo=o("XGLMConfig"),ybo=o(" (XGLM model)"),xbo=l(),_u=a("li"),Dhe=a("strong"),$bo=o("xlm"),kbo=o(" \u2014 "),UD=a("a"),Sbo=o("XLMConfig"),Rbo=o(" (XLM model)"),Pbo=l(),bu=a("li"),jhe=a("strong"),Bbo=o("xlm-prophetnet"),Ibo=o(" \u2014 "),HD=a("a"),Nbo=o("XLMProphetNetConfig"),qbo=o(" (XLM-ProphetNet model)"),Dbo=l(),vu=a("li"),Ghe=a("strong"),jbo=o("xlm-roberta"),Gbo=o(" \u2014 "),JD=a("a"),Obo=o("XLMRobertaConfig"),Vbo=o(" (XLM-RoBERTa model)"),Xbo=l(),Fu=a("li"),Ohe=a("strong"),zbo=o("xlm-roberta-xl"),Qbo=o(" \u2014 "),YD=a("a"),Wbo=o("XLMRobertaXLConfig"),Ubo=o(" (XLM-RoBERTa-XL model)"),Hbo=l(),Tu=a("li"),Vhe=a("strong"),Jbo=o("xlnet"),Ybo=o(" \u2014 "),ZD=a("a"),Zbo=o("XLNetConfig"),Kbo=o(" (XLNet model)"),evo=l(),Mu=a("li"),Xhe=a("strong"),ovo=o("yolos"),rvo=o(" \u2014 "),KD=a("a"),tvo=o("YolosConfig"),avo=o(" (YOLOS model)"),nvo=l(),Eu=a("li"),zhe=a("strong"),svo=o("yoso"),lvo=o(" \u2014 "),ej=a("a"),ivo=o("YosoConfig"),dvo=o(" (YOSO model)"),mvo=l(),F(Cu.$$.fragment),cvo=l(),wu=a("div"),F(p$.$$.fragment),fvo=l(),Qhe=a("p"),gvo=o("Register a new configuration for this class."),kto=l(),Ld=a("h2"),Au=a("a"),Whe=a("span"),F(_$.$$.fragment),hvo=l(),Uhe=a("span"),uvo=o("AutoTokenizer"),Sto=l(),Ro=a("div"),F(b$.$$.fragment),pvo=l(),v$=a("p"),_vo=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),oj=a("a"),bvo=o("AutoTokenizer.from_pretrained()"),vvo=o(" class method."),Fvo=l(),F$=a("p"),Tvo=o("This class cannot be instantiated directly using "),Hhe=a("code"),Mvo=o("__init__()"),Evo=o(" (throws an error)."),Cvo=l(),Dr=a("div"),F(T$.$$.fragment),wvo=l(),Jhe=a("p"),Avo=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),Lvo=l(),tn=a("p"),yvo=o("The tokenizer class to instantiate is selected based on the "),Yhe=a("code"),xvo=o("model_type"),$vo=o(` property of the config object (either
passed as an argument or loaded from `),Zhe=a("code"),kvo=o("pretrained_model_name_or_path"),Svo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Khe=a("code"),Rvo=o("pretrained_model_name_or_path"),Pvo=o(":"),Bvo=l(),k=a("ul"),us=a("li"),eue=a("strong"),Ivo=o("albert"),Nvo=o(" \u2014 "),rj=a("a"),qvo=o("AlbertTokenizer"),Dvo=o(" or "),tj=a("a"),jvo=o("AlbertTokenizerFast"),Gvo=o(" (ALBERT model)"),Ovo=l(),ps=a("li"),oue=a("strong"),Vvo=o("bart"),Xvo=o(" \u2014 "),aj=a("a"),zvo=o("BartTokenizer"),Qvo=o(" or "),nj=a("a"),Wvo=o("BartTokenizerFast"),Uvo=o(" (BART model)"),Hvo=l(),_s=a("li"),rue=a("strong"),Jvo=o("barthez"),Yvo=o(" \u2014 "),sj=a("a"),Zvo=o("BarthezTokenizer"),Kvo=o(" or "),lj=a("a"),eFo=o("BarthezTokenizerFast"),oFo=o(" (BARThez model)"),rFo=l(),Lu=a("li"),tue=a("strong"),tFo=o("bartpho"),aFo=o(" \u2014 "),ij=a("a"),nFo=o("BartphoTokenizer"),sFo=o(" (BARTpho model)"),lFo=l(),bs=a("li"),aue=a("strong"),iFo=o("bert"),dFo=o(" \u2014 "),dj=a("a"),mFo=o("BertTokenizer"),cFo=o(" or "),mj=a("a"),fFo=o("BertTokenizerFast"),gFo=o(" (BERT model)"),hFo=l(),yu=a("li"),nue=a("strong"),uFo=o("bert-generation"),pFo=o(" \u2014 "),cj=a("a"),_Fo=o("BertGenerationTokenizer"),bFo=o(" (Bert Generation model)"),vFo=l(),xu=a("li"),sue=a("strong"),FFo=o("bert-japanese"),TFo=o(" \u2014 "),fj=a("a"),MFo=o("BertJapaneseTokenizer"),EFo=o(" (BertJapanese model)"),CFo=l(),$u=a("li"),lue=a("strong"),wFo=o("bertweet"),AFo=o(" \u2014 "),gj=a("a"),LFo=o("BertweetTokenizer"),yFo=o(" (BERTweet model)"),xFo=l(),vs=a("li"),iue=a("strong"),$Fo=o("big_bird"),kFo=o(" \u2014 "),hj=a("a"),SFo=o("BigBirdTokenizer"),RFo=o(" or "),uj=a("a"),PFo=o("BigBirdTokenizerFast"),BFo=o(" (BigBird model)"),IFo=l(),Fs=a("li"),due=a("strong"),NFo=o("bigbird_pegasus"),qFo=o(" \u2014 "),pj=a("a"),DFo=o("PegasusTokenizer"),jFo=o(" or "),_j=a("a"),GFo=o("PegasusTokenizerFast"),OFo=o(" (BigBird-Pegasus model)"),VFo=l(),Ts=a("li"),mue=a("strong"),XFo=o("blenderbot"),zFo=o(" \u2014 "),bj=a("a"),QFo=o("BlenderbotTokenizer"),WFo=o(" or "),vj=a("a"),UFo=o("BlenderbotTokenizerFast"),HFo=o(" (Blenderbot model)"),JFo=l(),ku=a("li"),cue=a("strong"),YFo=o("blenderbot-small"),ZFo=o(" \u2014 "),Fj=a("a"),KFo=o("BlenderbotSmallTokenizer"),eTo=o(" (BlenderbotSmall model)"),oTo=l(),Su=a("li"),fue=a("strong"),rTo=o("bloom"),tTo=o(" \u2014 "),Tj=a("a"),aTo=o("BloomTokenizerFast"),nTo=o(" (BLOOM model)"),sTo=l(),Ru=a("li"),gue=a("strong"),lTo=o("byt5"),iTo=o(" \u2014 "),Mj=a("a"),dTo=o("ByT5Tokenizer"),mTo=o(" (ByT5 model)"),cTo=l(),Ms=a("li"),hue=a("strong"),fTo=o("camembert"),gTo=o(" \u2014 "),Ej=a("a"),hTo=o("CamembertTokenizer"),uTo=o(" or "),Cj=a("a"),pTo=o("CamembertTokenizerFast"),_To=o(" (CamemBERT model)"),bTo=l(),Pu=a("li"),uue=a("strong"),vTo=o("canine"),FTo=o(" \u2014 "),wj=a("a"),TTo=o("CanineTokenizer"),MTo=o(" (CANINE model)"),ETo=l(),Es=a("li"),pue=a("strong"),CTo=o("clip"),wTo=o(" \u2014 "),Aj=a("a"),ATo=o("CLIPTokenizer"),LTo=o(" or "),Lj=a("a"),yTo=o("CLIPTokenizerFast"),xTo=o(" (CLIP model)"),$To=l(),Cs=a("li"),_ue=a("strong"),kTo=o("codegen"),STo=o(" \u2014 "),yj=a("a"),RTo=o("CodeGenTokenizer"),PTo=o(" or "),xj=a("a"),BTo=o("CodeGenTokenizerFast"),ITo=o(" (CodeGen model)"),NTo=l(),ws=a("li"),bue=a("strong"),qTo=o("convbert"),DTo=o(" \u2014 "),$j=a("a"),jTo=o("ConvBertTokenizer"),GTo=o(" or "),kj=a("a"),OTo=o("ConvBertTokenizerFast"),VTo=o(" (ConvBERT model)"),XTo=l(),As=a("li"),vue=a("strong"),zTo=o("cpm"),QTo=o(" \u2014 "),Sj=a("a"),WTo=o("CpmTokenizer"),UTo=o(" or "),Rj=a("a"),HTo=o("CpmTokenizerFast"),JTo=o(" (CPM model)"),YTo=l(),Bu=a("li"),Fue=a("strong"),ZTo=o("ctrl"),KTo=o(" \u2014 "),Pj=a("a"),eMo=o("CTRLTokenizer"),oMo=o(" (CTRL model)"),rMo=l(),Ls=a("li"),Tue=a("strong"),tMo=o("data2vec-text"),aMo=o(" \u2014 "),Bj=a("a"),nMo=o("RobertaTokenizer"),sMo=o(" or "),Ij=a("a"),lMo=o("RobertaTokenizerFast"),iMo=o(" (Data2VecText model)"),dMo=l(),ys=a("li"),Mue=a("strong"),mMo=o("deberta"),cMo=o(" \u2014 "),Nj=a("a"),fMo=o("DebertaTokenizer"),gMo=o(" or "),qj=a("a"),hMo=o("DebertaTokenizerFast"),uMo=o(" (DeBERTa model)"),pMo=l(),xs=a("li"),Eue=a("strong"),_Mo=o("deberta-v2"),bMo=o(" \u2014 "),Dj=a("a"),vMo=o("DebertaV2Tokenizer"),FMo=o(" or "),jj=a("a"),TMo=o("DebertaV2TokenizerFast"),MMo=o(" (DeBERTa-v2 model)"),EMo=l(),$s=a("li"),Cue=a("strong"),CMo=o("distilbert"),wMo=o(" \u2014 "),Gj=a("a"),AMo=o("DistilBertTokenizer"),LMo=o(" or "),Oj=a("a"),yMo=o("DistilBertTokenizerFast"),xMo=o(" (DistilBERT model)"),$Mo=l(),ks=a("li"),wue=a("strong"),kMo=o("dpr"),SMo=o(" \u2014 "),Vj=a("a"),RMo=o("DPRQuestionEncoderTokenizer"),PMo=o(" or "),Xj=a("a"),BMo=o("DPRQuestionEncoderTokenizerFast"),IMo=o(" (DPR model)"),NMo=l(),Ss=a("li"),Aue=a("strong"),qMo=o("electra"),DMo=o(" \u2014 "),zj=a("a"),jMo=o("ElectraTokenizer"),GMo=o(" or "),Qj=a("a"),OMo=o("ElectraTokenizerFast"),VMo=o(" (ELECTRA model)"),XMo=l(),Rs=a("li"),Lue=a("strong"),zMo=o("ernie"),QMo=o(" \u2014 "),Wj=a("a"),WMo=o("BertTokenizer"),UMo=o(" or "),Uj=a("a"),HMo=o("BertTokenizerFast"),JMo=o(" (ERNIE model)"),YMo=l(),Iu=a("li"),yue=a("strong"),ZMo=o("esm"),KMo=o(" \u2014 "),Hj=a("a"),eEo=o("EsmTokenizer"),oEo=o(" (ESM model)"),rEo=l(),Nu=a("li"),xue=a("strong"),tEo=o("flaubert"),aEo=o(" \u2014 "),Jj=a("a"),nEo=o("FlaubertTokenizer"),sEo=o(" (FlauBERT model)"),lEo=l(),Ps=a("li"),$ue=a("strong"),iEo=o("fnet"),dEo=o(" \u2014 "),Yj=a("a"),mEo=o("FNetTokenizer"),cEo=o(" or "),Zj=a("a"),fEo=o("FNetTokenizerFast"),gEo=o(" (FNet model)"),hEo=l(),qu=a("li"),kue=a("strong"),uEo=o("fsmt"),pEo=o(" \u2014 "),Kj=a("a"),_Eo=o("FSMTTokenizer"),bEo=o(" (FairSeq Machine-Translation model)"),vEo=l(),Bs=a("li"),Sue=a("strong"),FEo=o("funnel"),TEo=o(" \u2014 "),eG=a("a"),MEo=o("FunnelTokenizer"),EEo=o(" or "),oG=a("a"),CEo=o("FunnelTokenizerFast"),wEo=o(" (Funnel Transformer model)"),AEo=l(),Is=a("li"),Rue=a("strong"),LEo=o("gpt2"),yEo=o(" \u2014 "),rG=a("a"),xEo=o("GPT2Tokenizer"),$Eo=o(" or "),tG=a("a"),kEo=o("GPT2TokenizerFast"),SEo=o(" (OpenAI GPT-2 model)"),REo=l(),Ns=a("li"),Pue=a("strong"),PEo=o("gpt_neo"),BEo=o(" \u2014 "),aG=a("a"),IEo=o("GPT2Tokenizer"),NEo=o(" or "),nG=a("a"),qEo=o("GPT2TokenizerFast"),DEo=o(" (GPT Neo model)"),jEo=l(),Du=a("li"),Bue=a("strong"),GEo=o("gpt_neox"),OEo=o(" \u2014 "),sG=a("a"),VEo=o("GPTNeoXTokenizerFast"),XEo=o(" (GPT NeoX model)"),zEo=l(),ju=a("li"),Iue=a("strong"),QEo=o("gpt_neox_japanese"),WEo=o(" \u2014 "),lG=a("a"),UEo=o("GPTNeoXJapaneseTokenizer"),HEo=o(" (GPT NeoX Japanese model)"),JEo=l(),qs=a("li"),Nue=a("strong"),YEo=o("gptj"),ZEo=o(" \u2014 "),iG=a("a"),KEo=o("GPT2Tokenizer"),e4o=o(" or "),dG=a("a"),o4o=o("GPT2TokenizerFast"),r4o=o(" (GPT-J model)"),t4o=l(),Ds=a("li"),que=a("strong"),a4o=o("groupvit"),n4o=o(" \u2014 "),mG=a("a"),s4o=o("CLIPTokenizer"),l4o=o(" or "),cG=a("a"),i4o=o("CLIPTokenizerFast"),d4o=o(" (GroupViT model)"),m4o=l(),js=a("li"),Due=a("strong"),c4o=o("herbert"),f4o=o(" \u2014 "),fG=a("a"),g4o=o("HerbertTokenizer"),h4o=o(" or "),gG=a("a"),u4o=o("HerbertTokenizerFast"),p4o=o(" (HerBERT model)"),_4o=l(),Gu=a("li"),jue=a("strong"),b4o=o("hubert"),v4o=o(" \u2014 "),hG=a("a"),F4o=o("Wav2Vec2CTCTokenizer"),T4o=o(" (Hubert model)"),M4o=l(),Gs=a("li"),Gue=a("strong"),E4o=o("ibert"),C4o=o(" \u2014 "),uG=a("a"),w4o=o("RobertaTokenizer"),A4o=o(" or "),pG=a("a"),L4o=o("RobertaTokenizerFast"),y4o=o(" (I-BERT model)"),x4o=l(),Os=a("li"),Oue=a("strong"),$4o=o("layoutlm"),k4o=o(" \u2014 "),_G=a("a"),S4o=o("LayoutLMTokenizer"),R4o=o(" or "),bG=a("a"),P4o=o("LayoutLMTokenizerFast"),B4o=o(" (LayoutLM model)"),I4o=l(),Vs=a("li"),Vue=a("strong"),N4o=o("layoutlmv2"),q4o=o(" \u2014 "),vG=a("a"),D4o=o("LayoutLMv2Tokenizer"),j4o=o(" or "),FG=a("a"),G4o=o("LayoutLMv2TokenizerFast"),O4o=o(" (LayoutLMv2 model)"),V4o=l(),Xs=a("li"),Xue=a("strong"),X4o=o("layoutlmv3"),z4o=o(" \u2014 "),TG=a("a"),Q4o=o("LayoutLMv3Tokenizer"),W4o=o(" or "),MG=a("a"),U4o=o("LayoutLMv3TokenizerFast"),H4o=o(" (LayoutLMv3 model)"),J4o=l(),zs=a("li"),zue=a("strong"),Y4o=o("layoutxlm"),Z4o=o(" \u2014 "),EG=a("a"),K4o=o("LayoutXLMTokenizer"),eCo=o(" or "),CG=a("a"),oCo=o("LayoutXLMTokenizerFast"),rCo=o(" (LayoutXLM model)"),tCo=l(),Qs=a("li"),Que=a("strong"),aCo=o("led"),nCo=o(" \u2014 "),wG=a("a"),sCo=o("LEDTokenizer"),lCo=o(" or "),AG=a("a"),iCo=o("LEDTokenizerFast"),dCo=o(" (LED model)"),mCo=l(),Ws=a("li"),Wue=a("strong"),cCo=o("lilt"),fCo=o(" \u2014 "),LG=a("a"),gCo=o("LayoutLMv3Tokenizer"),hCo=o(" or "),yG=a("a"),uCo=o("LayoutLMv3TokenizerFast"),pCo=o(" (LiLT model)"),_Co=l(),Us=a("li"),Uue=a("strong"),bCo=o("longformer"),vCo=o(" \u2014 "),xG=a("a"),FCo=o("LongformerTokenizer"),TCo=o(" or "),$G=a("a"),MCo=o("LongformerTokenizerFast"),ECo=o(" (Longformer model)"),CCo=l(),Hs=a("li"),Hue=a("strong"),wCo=o("longt5"),ACo=o(" \u2014 "),kG=a("a"),LCo=o("T5Tokenizer"),yCo=o(" or "),SG=a("a"),xCo=o("T5TokenizerFast"),$Co=o(" (LongT5 model)"),kCo=l(),Ou=a("li"),Jue=a("strong"),SCo=o("luke"),RCo=o(" \u2014 "),RG=a("a"),PCo=o("LukeTokenizer"),BCo=o(" (LUKE model)"),ICo=l(),Js=a("li"),Yue=a("strong"),NCo=o("lxmert"),qCo=o(" \u2014 "),PG=a("a"),DCo=o("LxmertTokenizer"),jCo=o(" or "),BG=a("a"),GCo=o("LxmertTokenizerFast"),OCo=o(" (LXMERT model)"),VCo=l(),Vu=a("li"),Zue=a("strong"),XCo=o("m2m_100"),zCo=o(" \u2014 "),IG=a("a"),QCo=o("M2M100Tokenizer"),WCo=o(" (M2M100 model)"),UCo=l(),Xu=a("li"),Kue=a("strong"),HCo=o("marian"),JCo=o(" \u2014 "),NG=a("a"),YCo=o("MarianTokenizer"),ZCo=o(" (Marian model)"),KCo=l(),Ys=a("li"),epe=a("strong"),e3o=o("mbart"),o3o=o(" \u2014 "),qG=a("a"),r3o=o("MBartTokenizer"),t3o=o(" or "),DG=a("a"),a3o=o("MBartTokenizerFast"),n3o=o(" (mBART model)"),s3o=l(),Zs=a("li"),ope=a("strong"),l3o=o("mbart50"),i3o=o(" \u2014 "),jG=a("a"),d3o=o("MBart50Tokenizer"),m3o=o(" or "),GG=a("a"),c3o=o("MBart50TokenizerFast"),f3o=o(" (mBART-50 model)"),g3o=l(),Ks=a("li"),rpe=a("strong"),h3o=o("megatron-bert"),u3o=o(" \u2014 "),OG=a("a"),p3o=o("BertTokenizer"),_3o=o(" or "),VG=a("a"),b3o=o("BertTokenizerFast"),v3o=o(" (Megatron-BERT model)"),F3o=l(),zu=a("li"),tpe=a("strong"),T3o=o("mluke"),M3o=o(" \u2014 "),XG=a("a"),E3o=o("MLukeTokenizer"),C3o=o(" (mLUKE model)"),w3o=l(),el=a("li"),ape=a("strong"),A3o=o("mobilebert"),L3o=o(" \u2014 "),zG=a("a"),y3o=o("MobileBertTokenizer"),x3o=o(" or "),QG=a("a"),$3o=o("MobileBertTokenizerFast"),k3o=o(" (MobileBERT model)"),S3o=l(),ol=a("li"),npe=a("strong"),R3o=o("mpnet"),P3o=o(" \u2014 "),WG=a("a"),B3o=o("MPNetTokenizer"),I3o=o(" or "),UG=a("a"),N3o=o("MPNetTokenizerFast"),q3o=o(" (MPNet model)"),D3o=l(),rl=a("li"),spe=a("strong"),j3o=o("mt5"),G3o=o(" \u2014 "),HG=a("a"),O3o=o("MT5Tokenizer"),V3o=o(" or "),JG=a("a"),X3o=o("MT5TokenizerFast"),z3o=o(" (MT5 model)"),Q3o=l(),tl=a("li"),lpe=a("strong"),W3o=o("mvp"),U3o=o(" \u2014 "),YG=a("a"),H3o=o("MvpTokenizer"),J3o=o(" or "),ZG=a("a"),Y3o=o("MvpTokenizerFast"),Z3o=o(" (MVP model)"),K3o=l(),al=a("li"),ipe=a("strong"),e5o=o("nezha"),o5o=o(" \u2014 "),KG=a("a"),r5o=o("BertTokenizer"),t5o=o(" or "),eO=a("a"),a5o=o("BertTokenizerFast"),n5o=o(" (Nezha model)"),s5o=l(),nl=a("li"),dpe=a("strong"),l5o=o("nllb"),i5o=o(" \u2014 "),oO=a("a"),d5o=o("NllbTokenizer"),m5o=o(" or "),rO=a("a"),c5o=o("NllbTokenizerFast"),f5o=o(" (NLLB model)"),g5o=l(),sl=a("li"),mpe=a("strong"),h5o=o("nystromformer"),u5o=o(" \u2014 "),tO=a("a"),p5o=o("AlbertTokenizer"),_5o=o(" or "),aO=a("a"),b5o=o("AlbertTokenizerFast"),v5o=o(" (Nystr\xF6mformer model)"),F5o=l(),ll=a("li"),cpe=a("strong"),T5o=o("openai-gpt"),M5o=o(" \u2014 "),nO=a("a"),E5o=o("OpenAIGPTTokenizer"),C5o=o(" or "),sO=a("a"),w5o=o("OpenAIGPTTokenizerFast"),A5o=o(" (OpenAI GPT model)"),L5o=l(),Qu=a("li"),fpe=a("strong"),y5o=o("opt"),x5o=o(" \u2014 "),lO=a("a"),$5o=o("GPT2Tokenizer"),k5o=o(" (OPT model)"),S5o=l(),il=a("li"),gpe=a("strong"),R5o=o("owlvit"),P5o=o(" \u2014 "),iO=a("a"),B5o=o("CLIPTokenizer"),I5o=o(" or "),dO=a("a"),N5o=o("CLIPTokenizerFast"),q5o=o(" (OWL-ViT model)"),D5o=l(),dl=a("li"),hpe=a("strong"),j5o=o("pegasus"),G5o=o(" \u2014 "),mO=a("a"),O5o=o("PegasusTokenizer"),V5o=o(" or "),cO=a("a"),X5o=o("PegasusTokenizerFast"),z5o=o(" (Pegasus model)"),Q5o=l(),Wu=a("li"),upe=a("strong"),W5o=o("perceiver"),U5o=o(" \u2014 "),fO=a("a"),H5o=o("PerceiverTokenizer"),J5o=o(" (Perceiver model)"),Y5o=l(),Uu=a("li"),ppe=a("strong"),Z5o=o("phobert"),K5o=o(" \u2014 "),gO=a("a"),e0o=o("PhobertTokenizer"),o0o=o(" (PhoBERT model)"),r0o=l(),Hu=a("li"),_pe=a("strong"),t0o=o("plbart"),a0o=o(" \u2014 "),hO=a("a"),n0o=o("PLBartTokenizer"),s0o=o(" (PLBart model)"),l0o=l(),Ju=a("li"),bpe=a("strong"),i0o=o("prophetnet"),d0o=o(" \u2014 "),uO=a("a"),m0o=o("ProphetNetTokenizer"),c0o=o(" (ProphetNet model)"),f0o=l(),ml=a("li"),vpe=a("strong"),g0o=o("qdqbert"),h0o=o(" \u2014 "),pO=a("a"),u0o=o("BertTokenizer"),p0o=o(" or "),_O=a("a"),_0o=o("BertTokenizerFast"),b0o=o(" (QDQBert model)"),v0o=l(),Yu=a("li"),Fpe=a("strong"),F0o=o("rag"),T0o=o(" \u2014 "),bO=a("a"),M0o=o("RagTokenizer"),E0o=o(" (RAG model)"),C0o=l(),cl=a("li"),Tpe=a("strong"),w0o=o("realm"),A0o=o(" \u2014 "),vO=a("a"),L0o=o("RealmTokenizer"),y0o=o(" or "),FO=a("a"),x0o=o("RealmTokenizerFast"),$0o=o(" (REALM model)"),k0o=l(),fl=a("li"),Mpe=a("strong"),S0o=o("reformer"),R0o=o(" \u2014 "),TO=a("a"),P0o=o("ReformerTokenizer"),B0o=o(" or "),MO=a("a"),I0o=o("ReformerTokenizerFast"),N0o=o(" (Reformer model)"),q0o=l(),gl=a("li"),Epe=a("strong"),D0o=o("rembert"),j0o=o(" \u2014 "),EO=a("a"),G0o=o("RemBertTokenizer"),O0o=o(" or "),CO=a("a"),V0o=o("RemBertTokenizerFast"),X0o=o(" (RemBERT model)"),z0o=l(),hl=a("li"),Cpe=a("strong"),Q0o=o("retribert"),W0o=o(" \u2014 "),wO=a("a"),U0o=o("RetriBertTokenizer"),H0o=o(" or "),AO=a("a"),J0o=o("RetriBertTokenizerFast"),Y0o=o(" (RetriBERT model)"),Z0o=l(),ul=a("li"),wpe=a("strong"),K0o=o("roberta"),ewo=o(" \u2014 "),LO=a("a"),owo=o("RobertaTokenizer"),rwo=o(" or "),yO=a("a"),two=o("RobertaTokenizerFast"),awo=o(" (RoBERTa model)"),nwo=l(),pl=a("li"),Ape=a("strong"),swo=o("roformer"),lwo=o(" \u2014 "),xO=a("a"),iwo=o("RoFormerTokenizer"),dwo=o(" or "),$O=a("a"),mwo=o("RoFormerTokenizerFast"),cwo=o(" (RoFormer model)"),fwo=l(),Zu=a("li"),Lpe=a("strong"),gwo=o("speech_to_text"),hwo=o(" \u2014 "),kO=a("a"),uwo=o("Speech2TextTokenizer"),pwo=o(" (Speech2Text model)"),_wo=l(),Ku=a("li"),ype=a("strong"),bwo=o("speech_to_text_2"),vwo=o(" \u2014 "),SO=a("a"),Fwo=o("Speech2Text2Tokenizer"),Two=o(" (Speech2Text2 model)"),Mwo=l(),_l=a("li"),xpe=a("strong"),Ewo=o("splinter"),Cwo=o(" \u2014 "),RO=a("a"),wwo=o("SplinterTokenizer"),Awo=o(" or "),PO=a("a"),Lwo=o("SplinterTokenizerFast"),ywo=o(" (Splinter model)"),xwo=l(),bl=a("li"),$pe=a("strong"),$wo=o("squeezebert"),kwo=o(" \u2014 "),BO=a("a"),Swo=o("SqueezeBertTokenizer"),Rwo=o(" or "),IO=a("a"),Pwo=o("SqueezeBertTokenizerFast"),Bwo=o(" (SqueezeBERT model)"),Iwo=l(),vl=a("li"),kpe=a("strong"),Nwo=o("t5"),qwo=o(" \u2014 "),NO=a("a"),Dwo=o("T5Tokenizer"),jwo=o(" or "),qO=a("a"),Gwo=o("T5TokenizerFast"),Owo=o(" (T5 model)"),Vwo=l(),ep=a("li"),Spe=a("strong"),Xwo=o("tapas"),zwo=o(" \u2014 "),DO=a("a"),Qwo=o("TapasTokenizer"),Wwo=o(" (TAPAS model)"),Uwo=l(),op=a("li"),Rpe=a("strong"),Hwo=o("tapex"),Jwo=o(" \u2014 "),jO=a("a"),Ywo=o("TapexTokenizer"),Zwo=o(" (TAPEX model)"),Kwo=l(),rp=a("li"),Ppe=a("strong"),eAo=o("transfo-xl"),oAo=o(" \u2014 "),GO=a("a"),rAo=o("TransfoXLTokenizer"),tAo=o(" (Transformer-XL model)"),aAo=l(),Fl=a("li"),Bpe=a("strong"),nAo=o("vilt"),sAo=o(" \u2014 "),OO=a("a"),lAo=o("BertTokenizer"),iAo=o(" or "),VO=a("a"),dAo=o("BertTokenizerFast"),mAo=o(" (ViLT model)"),cAo=l(),Tl=a("li"),Ipe=a("strong"),fAo=o("visual_bert"),gAo=o(" \u2014 "),XO=a("a"),hAo=o("BertTokenizer"),uAo=o(" or "),zO=a("a"),pAo=o("BertTokenizerFast"),_Ao=o(" (VisualBERT model)"),bAo=l(),tp=a("li"),Npe=a("strong"),vAo=o("wav2vec2"),FAo=o(" \u2014 "),QO=a("a"),TAo=o("Wav2Vec2CTCTokenizer"),MAo=o(" (Wav2Vec2 model)"),EAo=l(),ap=a("li"),qpe=a("strong"),CAo=o("wav2vec2-conformer"),wAo=o(" \u2014 "),WO=a("a"),AAo=o("Wav2Vec2CTCTokenizer"),LAo=o(" (Wav2Vec2-Conformer model)"),yAo=l(),np=a("li"),Dpe=a("strong"),xAo=o("wav2vec2_phoneme"),$Ao=o(" \u2014 "),UO=a("a"),kAo=o("Wav2Vec2PhonemeCTCTokenizer"),SAo=o(" (Wav2Vec2Phoneme model)"),RAo=l(),sp=a("li"),jpe=a("strong"),PAo=o("whisper"),BAo=o(" \u2014 "),HO=a("a"),IAo=o("WhisperTokenizer"),NAo=o(" (Whisper model)"),qAo=l(),Ml=a("li"),Gpe=a("strong"),DAo=o("xclip"),jAo=o(" \u2014 "),JO=a("a"),GAo=o("CLIPTokenizer"),OAo=o(" or "),YO=a("a"),VAo=o("CLIPTokenizerFast"),XAo=o(" (X-CLIP model)"),zAo=l(),El=a("li"),Ope=a("strong"),QAo=o("xglm"),WAo=o(" \u2014 "),ZO=a("a"),UAo=o("XGLMTokenizer"),HAo=o(" or "),KO=a("a"),JAo=o("XGLMTokenizerFast"),YAo=o(" (XGLM model)"),ZAo=l(),lp=a("li"),Vpe=a("strong"),KAo=o("xlm"),e6o=o(" \u2014 "),eV=a("a"),o6o=o("XLMTokenizer"),r6o=o(" (XLM model)"),t6o=l(),ip=a("li"),Xpe=a("strong"),a6o=o("xlm-prophetnet"),n6o=o(" \u2014 "),oV=a("a"),s6o=o("XLMProphetNetTokenizer"),l6o=o(" (XLM-ProphetNet model)"),i6o=l(),Cl=a("li"),zpe=a("strong"),d6o=o("xlm-roberta"),m6o=o(" \u2014 "),rV=a("a"),c6o=o("XLMRobertaTokenizer"),f6o=o(" or "),tV=a("a"),g6o=o("XLMRobertaTokenizerFast"),h6o=o(" (XLM-RoBERTa model)"),u6o=l(),wl=a("li"),Qpe=a("strong"),p6o=o("xlm-roberta-xl"),_6o=o(" \u2014 "),aV=a("a"),b6o=o("XLMRobertaTokenizer"),v6o=o(" or "),nV=a("a"),F6o=o("XLMRobertaTokenizerFast"),T6o=o(" (XLM-RoBERTa-XL model)"),M6o=l(),Al=a("li"),Wpe=a("strong"),E6o=o("xlnet"),C6o=o(" \u2014 "),sV=a("a"),w6o=o("XLNetTokenizer"),A6o=o(" or "),lV=a("a"),L6o=o("XLNetTokenizerFast"),y6o=o(" (XLNet model)"),x6o=l(),Ll=a("li"),Upe=a("strong"),$6o=o("yoso"),k6o=o(" \u2014 "),iV=a("a"),S6o=o("AlbertTokenizer"),R6o=o(" or "),dV=a("a"),P6o=o("AlbertTokenizerFast"),B6o=o(" (YOSO model)"),I6o=l(),F(dp.$$.fragment),N6o=l(),mp=a("div"),F(M$.$$.fragment),q6o=l(),Hpe=a("p"),D6o=o("Register a new tokenizer in this mapping."),Rto=l(),yd=a("h2"),cp=a("a"),Jpe=a("span"),F(E$.$$.fragment),j6o=l(),Ype=a("span"),G6o=o("AutoFeatureExtractor"),Pto=l(),Po=a("div"),F(C$.$$.fragment),O6o=l(),w$=a("p"),V6o=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),mV=a("a"),X6o=o("AutoFeatureExtractor.from_pretrained()"),z6o=o(" class method."),Q6o=l(),A$=a("p"),W6o=o("This class cannot be instantiated directly using "),Zpe=a("code"),U6o=o("__init__()"),H6o=o(" (throws an error)."),J6o=l(),Ye=a("div"),F(L$.$$.fragment),Y6o=l(),Kpe=a("p"),Z6o=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),K6o=l(),an=a("p"),e7o=o("The feature extractor class to instantiate is selected based on the "),e_e=a("code"),o7o=o("model_type"),r7o=o(` property of the config object
(either passed as an argument or loaded from `),o_e=a("code"),t7o=o("pretrained_model_name_or_path"),a7o=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),r_e=a("code"),n7o=o("pretrained_model_name_or_path"),s7o=o(":"),l7o=l(),z=a("ul"),fp=a("li"),t_e=a("strong"),i7o=o("beit"),d7o=o(" \u2014 "),cV=a("a"),m7o=o("BeitFeatureExtractor"),c7o=o(" (BEiT model)"),f7o=l(),gp=a("li"),a_e=a("strong"),g7o=o("clip"),h7o=o(" \u2014 "),fV=a("a"),u7o=o("CLIPFeatureExtractor"),p7o=o(" (CLIP model)"),_7o=l(),hp=a("li"),n_e=a("strong"),b7o=o("conditional_detr"),v7o=o(" \u2014 "),gV=a("a"),F7o=o("ConditionalDetrFeatureExtractor"),T7o=o(" (Conditional DETR model)"),M7o=l(),up=a("li"),s_e=a("strong"),E7o=o("convnext"),C7o=o(" \u2014 "),hV=a("a"),w7o=o("ConvNextFeatureExtractor"),A7o=o(" (ConvNeXT model)"),L7o=l(),pp=a("li"),l_e=a("strong"),y7o=o("cvt"),x7o=o(" \u2014 "),uV=a("a"),$7o=o("ConvNextFeatureExtractor"),k7o=o(" (CvT model)"),S7o=l(),_p=a("li"),i_e=a("strong"),R7o=o("data2vec-audio"),P7o=o(" \u2014 "),pV=a("a"),B7o=o("Wav2Vec2FeatureExtractor"),I7o=o(" (Data2VecAudio model)"),N7o=l(),bp=a("li"),d_e=a("strong"),q7o=o("data2vec-vision"),D7o=o(" \u2014 "),_V=a("a"),j7o=o("BeitFeatureExtractor"),G7o=o(" (Data2VecVision model)"),O7o=l(),vp=a("li"),m_e=a("strong"),V7o=o("deformable_detr"),X7o=o(" \u2014 "),bV=a("a"),z7o=o("DeformableDetrFeatureExtractor"),Q7o=o(" (Deformable DETR model)"),W7o=l(),Fp=a("li"),c_e=a("strong"),U7o=o("deit"),H7o=o(" \u2014 "),vV=a("a"),J7o=o("DeiTFeatureExtractor"),Y7o=o(" (DeiT model)"),Z7o=l(),Tp=a("li"),f_e=a("strong"),K7o=o("detr"),e8o=o(" \u2014 "),FV=a("a"),o8o=o("DetrFeatureExtractor"),r8o=o(" (DETR model)"),t8o=l(),Mp=a("li"),g_e=a("strong"),a8o=o("donut"),n8o=o(" \u2014 "),TV=a("a"),s8o=o("DonutFeatureExtractor"),l8o=o(" (Donut model)"),i8o=l(),Ep=a("li"),h_e=a("strong"),d8o=o("dpt"),m8o=o(" \u2014 "),MV=a("a"),c8o=o("DPTFeatureExtractor"),f8o=o(" (DPT model)"),g8o=l(),Cp=a("li"),u_e=a("strong"),h8o=o("flava"),u8o=o(" \u2014 "),EV=a("a"),p8o=o("FlavaFeatureExtractor"),_8o=o(" (FLAVA model)"),b8o=l(),wp=a("li"),p_e=a("strong"),v8o=o("glpn"),F8o=o(" \u2014 "),CV=a("a"),T8o=o("GLPNFeatureExtractor"),M8o=o(" (GLPN model)"),E8o=l(),Ap=a("li"),__e=a("strong"),C8o=o("groupvit"),w8o=o(" \u2014 "),wV=a("a"),A8o=o("CLIPFeatureExtractor"),L8o=o(" (GroupViT model)"),y8o=l(),Lp=a("li"),b_e=a("strong"),x8o=o("hubert"),$8o=o(" \u2014 "),AV=a("a"),k8o=o("Wav2Vec2FeatureExtractor"),S8o=o(" (Hubert model)"),R8o=l(),yp=a("li"),v_e=a("strong"),P8o=o("imagegpt"),B8o=o(" \u2014 "),LV=a("a"),I8o=o("ImageGPTFeatureExtractor"),N8o=o(" (ImageGPT model)"),q8o=l(),xp=a("li"),F_e=a("strong"),D8o=o("layoutlmv2"),j8o=o(" \u2014 "),yV=a("a"),G8o=o("LayoutLMv2FeatureExtractor"),O8o=o(" (LayoutLMv2 model)"),V8o=l(),$p=a("li"),T_e=a("strong"),X8o=o("layoutlmv3"),z8o=o(" \u2014 "),xV=a("a"),Q8o=o("LayoutLMv3FeatureExtractor"),W8o=o(" (LayoutLMv3 model)"),U8o=l(),kp=a("li"),M_e=a("strong"),H8o=o("levit"),J8o=o(" \u2014 "),$V=a("a"),Y8o=o("LevitFeatureExtractor"),Z8o=o(" (LeViT model)"),K8o=l(),Sp=a("li"),E_e=a("strong"),eLo=o("maskformer"),oLo=o(" \u2014 "),kV=a("a"),rLo=o("MaskFormerFeatureExtractor"),tLo=o(" (MaskFormer model)"),aLo=l(),Rp=a("li"),C_e=a("strong"),nLo=o("mctct"),sLo=o(" \u2014 "),SV=a("a"),lLo=o("MCTCTFeatureExtractor"),iLo=o(" (M-CTC-T model)"),dLo=l(),Pp=a("li"),w_e=a("strong"),mLo=o("mobilevit"),cLo=o(" \u2014 "),RV=a("a"),fLo=o("MobileViTFeatureExtractor"),gLo=o(" (MobileViT model)"),hLo=l(),Bp=a("li"),A_e=a("strong"),uLo=o("owlvit"),pLo=o(" \u2014 "),PV=a("a"),_Lo=o("OwlViTFeatureExtractor"),bLo=o(" (OWL-ViT model)"),vLo=l(),Ip=a("li"),L_e=a("strong"),FLo=o("perceiver"),TLo=o(" \u2014 "),BV=a("a"),MLo=o("PerceiverFeatureExtractor"),ELo=o(" (Perceiver model)"),CLo=l(),Np=a("li"),y_e=a("strong"),wLo=o("poolformer"),ALo=o(" \u2014 "),IV=a("a"),LLo=o("PoolFormerFeatureExtractor"),yLo=o(" (PoolFormer model)"),xLo=l(),qp=a("li"),x_e=a("strong"),$Lo=o("regnet"),kLo=o(" \u2014 "),NV=a("a"),SLo=o("ConvNextFeatureExtractor"),RLo=o(" (RegNet model)"),PLo=l(),Dp=a("li"),$_e=a("strong"),BLo=o("resnet"),ILo=o(" \u2014 "),qV=a("a"),NLo=o("ConvNextFeatureExtractor"),qLo=o(" (ResNet model)"),DLo=l(),jp=a("li"),k_e=a("strong"),jLo=o("segformer"),GLo=o(" \u2014 "),DV=a("a"),OLo=o("SegformerFeatureExtractor"),VLo=o(" (SegFormer model)"),XLo=l(),Gp=a("li"),S_e=a("strong"),zLo=o("speech_to_text"),QLo=o(" \u2014 "),jV=a("a"),WLo=o("Speech2TextFeatureExtractor"),ULo=o(" (Speech2Text model)"),HLo=l(),Op=a("li"),R_e=a("strong"),JLo=o("swin"),YLo=o(" \u2014 "),GV=a("a"),ZLo=o("ViTFeatureExtractor"),KLo=o(" (Swin Transformer model)"),eyo=l(),Vp=a("li"),P_e=a("strong"),oyo=o("swinv2"),ryo=o(" \u2014 "),OV=a("a"),tyo=o("ViTFeatureExtractor"),ayo=o(" (Swin Transformer V2 model)"),nyo=l(),Xp=a("li"),B_e=a("strong"),syo=o("table-transformer"),lyo=o(" \u2014 "),VV=a("a"),iyo=o("DetrFeatureExtractor"),dyo=o(" (Table Transformer model)"),myo=l(),zp=a("li"),I_e=a("strong"),cyo=o("van"),fyo=o(" \u2014 "),XV=a("a"),gyo=o("ConvNextFeatureExtractor"),hyo=o(" (VAN model)"),uyo=l(),Qp=a("li"),N_e=a("strong"),pyo=o("videomae"),_yo=o(" \u2014 "),zV=a("a"),byo=o("VideoMAEFeatureExtractor"),vyo=o(" (VideoMAE model)"),Fyo=l(),Wp=a("li"),q_e=a("strong"),Tyo=o("vilt"),Myo=o(" \u2014 "),QV=a("a"),Eyo=o("ViltFeatureExtractor"),Cyo=o(" (ViLT model)"),wyo=l(),Up=a("li"),D_e=a("strong"),Ayo=o("vit"),Lyo=o(" \u2014 "),WV=a("a"),yyo=o("ViTFeatureExtractor"),xyo=o(" (ViT model)"),$yo=l(),Hp=a("li"),j_e=a("strong"),kyo=o("vit_mae"),Syo=o(" \u2014 "),UV=a("a"),Ryo=o("ViTFeatureExtractor"),Pyo=o(" (ViTMAE model)"),Byo=l(),Jp=a("li"),G_e=a("strong"),Iyo=o("vit_msn"),Nyo=o(" \u2014 "),HV=a("a"),qyo=o("ViTFeatureExtractor"),Dyo=o(" (ViTMSN model)"),jyo=l(),Yp=a("li"),O_e=a("strong"),Gyo=o("wav2vec2"),Oyo=o(" \u2014 "),JV=a("a"),Vyo=o("Wav2Vec2FeatureExtractor"),Xyo=o(" (Wav2Vec2 model)"),zyo=l(),Zp=a("li"),V_e=a("strong"),Qyo=o("wav2vec2-conformer"),Wyo=o(" \u2014 "),YV=a("a"),Uyo=o("Wav2Vec2FeatureExtractor"),Hyo=o(" (Wav2Vec2-Conformer model)"),Jyo=l(),Kp=a("li"),X_e=a("strong"),Yyo=o("whisper"),Zyo=o(" \u2014 "),ZV=a("a"),Kyo=o("WhisperFeatureExtractor"),e9o=o(" (Whisper model)"),o9o=l(),e_=a("li"),z_e=a("strong"),r9o=o("xclip"),t9o=o(" \u2014 "),KV=a("a"),a9o=o("CLIPFeatureExtractor"),n9o=o(" (X-CLIP model)"),s9o=l(),o_=a("li"),Q_e=a("strong"),l9o=o("yolos"),i9o=o(" \u2014 "),eX=a("a"),d9o=o("YolosFeatureExtractor"),m9o=o(" (YOLOS model)"),c9o=l(),F(r_.$$.fragment),f9o=l(),F(t_.$$.fragment),g9o=l(),a_=a("div"),F(y$.$$.fragment),h9o=l(),W_e=a("p"),u9o=o("Register a new feature extractor for this class."),Bto=l(),xd=a("h2"),n_=a("a"),U_e=a("span"),F(x$.$$.fragment),p9o=l(),H_e=a("span"),_9o=o("AutoProcessor"),Ito=l(),Bo=a("div"),F($$.$$.fragment),b9o=l(),k$=a("p"),v9o=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),oX=a("a"),F9o=o("AutoProcessor.from_pretrained()"),T9o=o(" class method."),M9o=l(),S$=a("p"),E9o=o("This class cannot be instantiated directly using "),J_e=a("code"),C9o=o("__init__()"),w9o=o(" (throws an error)."),A9o=l(),Ze=a("div"),F(R$.$$.fragment),L9o=l(),Y_e=a("p"),y9o=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),x9o=l(),$d=a("p"),$9o=o("The processor class to instantiate is selected based on the "),Z_e=a("code"),k9o=o("model_type"),S9o=o(` property of the config object (either
passed as an argument or loaded from `),K_e=a("code"),R9o=o("pretrained_model_name_or_path"),P9o=o(" if possible):"),B9o=l(),se=a("ul"),s_=a("li"),e1e=a("strong"),I9o=o("clip"),N9o=o(" \u2014 "),rX=a("a"),q9o=o("CLIPProcessor"),D9o=o(" (CLIP model)"),j9o=l(),l_=a("li"),o1e=a("strong"),G9o=o("donut"),O9o=o(" \u2014 "),tX=a("a"),V9o=o("DonutProcessor"),X9o=o(" (Donut model)"),z9o=l(),i_=a("li"),r1e=a("strong"),Q9o=o("flava"),W9o=o(" \u2014 "),aX=a("a"),U9o=o("FlavaProcessor"),H9o=o(" (FLAVA model)"),J9o=l(),d_=a("li"),t1e=a("strong"),Y9o=o("groupvit"),Z9o=o(" \u2014 "),nX=a("a"),K9o=o("CLIPProcessor"),exo=o(" (GroupViT model)"),oxo=l(),m_=a("li"),a1e=a("strong"),rxo=o("layoutlmv2"),txo=o(" \u2014 "),sX=a("a"),axo=o("LayoutLMv2Processor"),nxo=o(" (LayoutLMv2 model)"),sxo=l(),c_=a("li"),n1e=a("strong"),lxo=o("layoutlmv3"),ixo=o(" \u2014 "),lX=a("a"),dxo=o("LayoutLMv3Processor"),mxo=o(" (LayoutLMv3 model)"),cxo=l(),f_=a("li"),s1e=a("strong"),fxo=o("layoutxlm"),gxo=o(" \u2014 "),iX=a("a"),hxo=o("LayoutXLMProcessor"),uxo=o(" (LayoutXLM model)"),pxo=l(),g_=a("li"),l1e=a("strong"),_xo=o("markuplm"),bxo=o(" \u2014 "),dX=a("a"),vxo=o("MarkupLMProcessor"),Fxo=o(" (MarkupLM model)"),Txo=l(),h_=a("li"),i1e=a("strong"),Mxo=o("owlvit"),Exo=o(" \u2014 "),mX=a("a"),Cxo=o("OwlViTProcessor"),wxo=o(" (OWL-ViT model)"),Axo=l(),u_=a("li"),d1e=a("strong"),Lxo=o("sew"),yxo=o(" \u2014 "),cX=a("a"),xxo=o("Wav2Vec2Processor"),$xo=o(" (SEW model)"),kxo=l(),p_=a("li"),m1e=a("strong"),Sxo=o("sew-d"),Rxo=o(" \u2014 "),fX=a("a"),Pxo=o("Wav2Vec2Processor"),Bxo=o(" (SEW-D model)"),Ixo=l(),__=a("li"),c1e=a("strong"),Nxo=o("speech_to_text"),qxo=o(" \u2014 "),gX=a("a"),Dxo=o("Speech2TextProcessor"),jxo=o(" (Speech2Text model)"),Gxo=l(),b_=a("li"),f1e=a("strong"),Oxo=o("speech_to_text_2"),Vxo=o(" \u2014 "),hX=a("a"),Xxo=o("Speech2Text2Processor"),zxo=o(" (Speech2Text2 model)"),Qxo=l(),v_=a("li"),g1e=a("strong"),Wxo=o("trocr"),Uxo=o(" \u2014 "),uX=a("a"),Hxo=o("TrOCRProcessor"),Jxo=o(" (TrOCR model)"),Yxo=l(),F_=a("li"),h1e=a("strong"),Zxo=o("unispeech"),Kxo=o(" \u2014 "),pX=a("a"),e$o=o("Wav2Vec2Processor"),o$o=o(" (UniSpeech model)"),r$o=l(),T_=a("li"),u1e=a("strong"),t$o=o("unispeech-sat"),a$o=o(" \u2014 "),_X=a("a"),n$o=o("Wav2Vec2Processor"),s$o=o(" (UniSpeechSat model)"),l$o=l(),M_=a("li"),p1e=a("strong"),i$o=o("vilt"),d$o=o(" \u2014 "),bX=a("a"),m$o=o("ViltProcessor"),c$o=o(" (ViLT model)"),f$o=l(),E_=a("li"),_1e=a("strong"),g$o=o("vision-text-dual-encoder"),h$o=o(" \u2014 "),vX=a("a"),u$o=o("VisionTextDualEncoderProcessor"),p$o=o(" (VisionTextDualEncoder model)"),_$o=l(),C_=a("li"),b1e=a("strong"),b$o=o("wav2vec2"),v$o=o(" \u2014 "),FX=a("a"),F$o=o("Wav2Vec2Processor"),T$o=o(" (Wav2Vec2 model)"),M$o=l(),w_=a("li"),v1e=a("strong"),E$o=o("wav2vec2-conformer"),C$o=o(" \u2014 "),TX=a("a"),w$o=o("Wav2Vec2Processor"),A$o=o(" (Wav2Vec2-Conformer model)"),L$o=l(),A_=a("li"),F1e=a("strong"),y$o=o("wavlm"),x$o=o(" \u2014 "),MX=a("a"),$$o=o("Wav2Vec2Processor"),k$o=o(" (WavLM model)"),S$o=l(),L_=a("li"),T1e=a("strong"),R$o=o("whisper"),P$o=o(" \u2014 "),EX=a("a"),B$o=o("WhisperProcessor"),I$o=o(" (Whisper model)"),N$o=l(),y_=a("li"),M1e=a("strong"),q$o=o("xclip"),D$o=o(" \u2014 "),CX=a("a"),j$o=o("XCLIPProcessor"),G$o=o(" (X-CLIP model)"),O$o=l(),F(x_.$$.fragment),V$o=l(),F($_.$$.fragment),X$o=l(),k_=a("div"),F(P$.$$.fragment),z$o=l(),E1e=a("p"),Q$o=o("Register a new processor for this class."),Nto=l(),kd=a("h2"),S_=a("a"),C1e=a("span"),F(B$.$$.fragment),W$o=l(),w1e=a("span"),U$o=o("AutoModel"),qto=l(),Io=a("div"),F(I$.$$.fragment),H$o=l(),Sd=a("p"),J$o=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),wX=a("a"),Y$o=o("from_pretrained()"),Z$o=o(" class method or the "),AX=a("a"),K$o=o("from_config()"),eko=o(` class
method.`),oko=l(),N$=a("p"),rko=o("This class cannot be instantiated directly using "),A1e=a("code"),tko=o("__init__()"),ako=o(" (throws an error)."),nko=l(),Mt=a("div"),F(q$.$$.fragment),sko=l(),L1e=a("p"),lko=o("Instantiates one of the base model classes of the library from a configuration."),iko=l(),Rd=a("p"),dko=o(`Note:
Loading a model from its configuration file does `),y1e=a("strong"),mko=o("not"),cko=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),LX=a("a"),fko=o("from_pretrained()"),gko=o(" to load the model weights."),hko=l(),F(R_.$$.fragment),uko=l(),Ke=a("div"),F(D$.$$.fragment),pko=l(),x1e=a("p"),_ko=o("Instantiate one of the base model classes of the library from a pretrained model."),bko=l(),nn=a("p"),vko=o("The model class to instantiate is selected based on the "),$1e=a("code"),Fko=o("model_type"),Tko=o(` property of the config object (either
passed as an argument or loaded from `),k1e=a("code"),Mko=o("pretrained_model_name_or_path"),Eko=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),S1e=a("code"),Cko=o("pretrained_model_name_or_path"),wko=o(":"),Ako=l(),y=a("ul"),P_=a("li"),R1e=a("strong"),Lko=o("albert"),yko=o(" \u2014 "),yX=a("a"),xko=o("AlbertModel"),$ko=o(" (ALBERT model)"),kko=l(),B_=a("li"),P1e=a("strong"),Sko=o("bart"),Rko=o(" \u2014 "),xX=a("a"),Pko=o("BartModel"),Bko=o(" (BART model)"),Iko=l(),I_=a("li"),B1e=a("strong"),Nko=o("beit"),qko=o(" \u2014 "),$X=a("a"),Dko=o("BeitModel"),jko=o(" (BEiT model)"),Gko=l(),N_=a("li"),I1e=a("strong"),Oko=o("bert"),Vko=o(" \u2014 "),kX=a("a"),Xko=o("BertModel"),zko=o(" (BERT model)"),Qko=l(),q_=a("li"),N1e=a("strong"),Wko=o("bert-generation"),Uko=o(" \u2014 "),SX=a("a"),Hko=o("BertGenerationEncoder"),Jko=o(" (Bert Generation model)"),Yko=l(),D_=a("li"),q1e=a("strong"),Zko=o("big_bird"),Kko=o(" \u2014 "),RX=a("a"),eSo=o("BigBirdModel"),oSo=o(" (BigBird model)"),rSo=l(),j_=a("li"),D1e=a("strong"),tSo=o("bigbird_pegasus"),aSo=o(" \u2014 "),PX=a("a"),nSo=o("BigBirdPegasusModel"),sSo=o(" (BigBird-Pegasus model)"),lSo=l(),G_=a("li"),j1e=a("strong"),iSo=o("blenderbot"),dSo=o(" \u2014 "),BX=a("a"),mSo=o("BlenderbotModel"),cSo=o(" (Blenderbot model)"),fSo=l(),O_=a("li"),G1e=a("strong"),gSo=o("blenderbot-small"),hSo=o(" \u2014 "),IX=a("a"),uSo=o("BlenderbotSmallModel"),pSo=o(" (BlenderbotSmall model)"),_So=l(),V_=a("li"),O1e=a("strong"),bSo=o("bloom"),vSo=o(" \u2014 "),NX=a("a"),FSo=o("BloomModel"),TSo=o(" (BLOOM model)"),MSo=l(),X_=a("li"),V1e=a("strong"),ESo=o("camembert"),CSo=o(" \u2014 "),qX=a("a"),wSo=o("CamembertModel"),ASo=o(" (CamemBERT model)"),LSo=l(),z_=a("li"),X1e=a("strong"),ySo=o("canine"),xSo=o(" \u2014 "),DX=a("a"),$So=o("CanineModel"),kSo=o(" (CANINE model)"),SSo=l(),Q_=a("li"),z1e=a("strong"),RSo=o("clip"),PSo=o(" \u2014 "),jX=a("a"),BSo=o("CLIPModel"),ISo=o(" (CLIP model)"),NSo=l(),W_=a("li"),Q1e=a("strong"),qSo=o("codegen"),DSo=o(" \u2014 "),GX=a("a"),jSo=o("CodeGenModel"),GSo=o(" (CodeGen model)"),OSo=l(),U_=a("li"),W1e=a("strong"),VSo=o("conditional_detr"),XSo=o(" \u2014 "),OX=a("a"),zSo=o("ConditionalDetrModel"),QSo=o(" (Conditional DETR model)"),WSo=l(),H_=a("li"),U1e=a("strong"),USo=o("convbert"),HSo=o(" \u2014 "),VX=a("a"),JSo=o("ConvBertModel"),YSo=o(" (ConvBERT model)"),ZSo=l(),J_=a("li"),H1e=a("strong"),KSo=o("convnext"),eRo=o(" \u2014 "),XX=a("a"),oRo=o("ConvNextModel"),rRo=o(" (ConvNeXT model)"),tRo=l(),Y_=a("li"),J1e=a("strong"),aRo=o("ctrl"),nRo=o(" \u2014 "),zX=a("a"),sRo=o("CTRLModel"),lRo=o(" (CTRL model)"),iRo=l(),Z_=a("li"),Y1e=a("strong"),dRo=o("cvt"),mRo=o(" \u2014 "),QX=a("a"),cRo=o("CvtModel"),fRo=o(" (CvT model)"),gRo=l(),K_=a("li"),Z1e=a("strong"),hRo=o("data2vec-audio"),uRo=o(" \u2014 "),WX=a("a"),pRo=o("Data2VecAudioModel"),_Ro=o(" (Data2VecAudio model)"),bRo=l(),e1=a("li"),K1e=a("strong"),vRo=o("data2vec-text"),FRo=o(" \u2014 "),UX=a("a"),TRo=o("Data2VecTextModel"),MRo=o(" (Data2VecText model)"),ERo=l(),o1=a("li"),e2e=a("strong"),CRo=o("data2vec-vision"),wRo=o(" \u2014 "),HX=a("a"),ARo=o("Data2VecVisionModel"),LRo=o(" (Data2VecVision model)"),yRo=l(),r1=a("li"),o2e=a("strong"),xRo=o("deberta"),$Ro=o(" \u2014 "),JX=a("a"),kRo=o("DebertaModel"),SRo=o(" (DeBERTa model)"),RRo=l(),t1=a("li"),r2e=a("strong"),PRo=o("deberta-v2"),BRo=o(" \u2014 "),YX=a("a"),IRo=o("DebertaV2Model"),NRo=o(" (DeBERTa-v2 model)"),qRo=l(),a1=a("li"),t2e=a("strong"),DRo=o("decision_transformer"),jRo=o(" \u2014 "),ZX=a("a"),GRo=o("DecisionTransformerModel"),ORo=o(" (Decision Transformer model)"),VRo=l(),n1=a("li"),a2e=a("strong"),XRo=o("deformable_detr"),zRo=o(" \u2014 "),KX=a("a"),QRo=o("DeformableDetrModel"),WRo=o(" (Deformable DETR model)"),URo=l(),s1=a("li"),n2e=a("strong"),HRo=o("deit"),JRo=o(" \u2014 "),ez=a("a"),YRo=o("DeiTModel"),ZRo=o(" (DeiT model)"),KRo=l(),l1=a("li"),s2e=a("strong"),ePo=o("detr"),oPo=o(" \u2014 "),oz=a("a"),rPo=o("DetrModel"),tPo=o(" (DETR model)"),aPo=l(),i1=a("li"),l2e=a("strong"),nPo=o("distilbert"),sPo=o(" \u2014 "),rz=a("a"),lPo=o("DistilBertModel"),iPo=o(" (DistilBERT model)"),dPo=l(),d1=a("li"),i2e=a("strong"),mPo=o("donut-swin"),cPo=o(" \u2014 "),tz=a("a"),fPo=o("DonutSwinModel"),gPo=o(" (DonutSwin model)"),hPo=l(),m1=a("li"),d2e=a("strong"),uPo=o("dpr"),pPo=o(" \u2014 "),az=a("a"),_Po=o("DPRQuestionEncoder"),bPo=o(" (DPR model)"),vPo=l(),c1=a("li"),m2e=a("strong"),FPo=o("dpt"),TPo=o(" \u2014 "),nz=a("a"),MPo=o("DPTModel"),EPo=o(" (DPT model)"),CPo=l(),f1=a("li"),c2e=a("strong"),wPo=o("electra"),APo=o(" \u2014 "),sz=a("a"),LPo=o("ElectraModel"),yPo=o(" (ELECTRA model)"),xPo=l(),g1=a("li"),f2e=a("strong"),$Po=o("ernie"),kPo=o(" \u2014 "),lz=a("a"),SPo=o("ErnieModel"),RPo=o(" (ERNIE model)"),PPo=l(),h1=a("li"),g2e=a("strong"),BPo=o("esm"),IPo=o(" \u2014 "),iz=a("a"),NPo=o("EsmModel"),qPo=o(" (ESM model)"),DPo=l(),u1=a("li"),h2e=a("strong"),jPo=o("flaubert"),GPo=o(" \u2014 "),dz=a("a"),OPo=o("FlaubertModel"),VPo=o(" (FlauBERT model)"),XPo=l(),p1=a("li"),u2e=a("strong"),zPo=o("flava"),QPo=o(" \u2014 "),mz=a("a"),WPo=o("FlavaModel"),UPo=o(" (FLAVA model)"),HPo=l(),_1=a("li"),p2e=a("strong"),JPo=o("fnet"),YPo=o(" \u2014 "),cz=a("a"),ZPo=o("FNetModel"),KPo=o(" (FNet model)"),eBo=l(),b1=a("li"),_2e=a("strong"),oBo=o("fsmt"),rBo=o(" \u2014 "),fz=a("a"),tBo=o("FSMTModel"),aBo=o(" (FairSeq Machine-Translation model)"),nBo=l(),yl=a("li"),b2e=a("strong"),sBo=o("funnel"),lBo=o(" \u2014 "),gz=a("a"),iBo=o("FunnelModel"),dBo=o(" or "),hz=a("a"),mBo=o("FunnelBaseModel"),cBo=o(" (Funnel Transformer model)"),fBo=l(),v1=a("li"),v2e=a("strong"),gBo=o("glpn"),hBo=o(" \u2014 "),uz=a("a"),uBo=o("GLPNModel"),pBo=o(" (GLPN model)"),_Bo=l(),F1=a("li"),F2e=a("strong"),bBo=o("gpt2"),vBo=o(" \u2014 "),pz=a("a"),FBo=o("GPT2Model"),TBo=o(" (OpenAI GPT-2 model)"),MBo=l(),T1=a("li"),T2e=a("strong"),EBo=o("gpt_neo"),CBo=o(" \u2014 "),_z=a("a"),wBo=o("GPTNeoModel"),ABo=o(" (GPT Neo model)"),LBo=l(),M1=a("li"),M2e=a("strong"),yBo=o("gpt_neox"),xBo=o(" \u2014 "),bz=a("a"),$Bo=o("GPTNeoXModel"),kBo=o(" (GPT NeoX model)"),SBo=l(),E1=a("li"),E2e=a("strong"),RBo=o("gpt_neox_japanese"),PBo=o(" \u2014 "),vz=a("a"),BBo=o("GPTNeoXJapaneseModel"),IBo=o(" (GPT NeoX Japanese model)"),NBo=l(),C1=a("li"),C2e=a("strong"),qBo=o("gptj"),DBo=o(" \u2014 "),Fz=a("a"),jBo=o("GPTJModel"),GBo=o(" (GPT-J model)"),OBo=l(),w1=a("li"),w2e=a("strong"),VBo=o("groupvit"),XBo=o(" \u2014 "),Tz=a("a"),zBo=o("GroupViTModel"),QBo=o(" (GroupViT model)"),WBo=l(),A1=a("li"),A2e=a("strong"),UBo=o("hubert"),HBo=o(" \u2014 "),Mz=a("a"),JBo=o("HubertModel"),YBo=o(" (Hubert model)"),ZBo=l(),L1=a("li"),L2e=a("strong"),KBo=o("ibert"),eIo=o(" \u2014 "),Ez=a("a"),oIo=o("IBertModel"),rIo=o(" (I-BERT model)"),tIo=l(),y1=a("li"),y2e=a("strong"),aIo=o("imagegpt"),nIo=o(" \u2014 "),Cz=a("a"),sIo=o("ImageGPTModel"),lIo=o(" (ImageGPT model)"),iIo=l(),x1=a("li"),x2e=a("strong"),dIo=o("layoutlm"),mIo=o(" \u2014 "),wz=a("a"),cIo=o("LayoutLMModel"),fIo=o(" (LayoutLM model)"),gIo=l(),$1=a("li"),$2e=a("strong"),hIo=o("layoutlmv2"),uIo=o(" \u2014 "),Az=a("a"),pIo=o("LayoutLMv2Model"),_Io=o(" (LayoutLMv2 model)"),bIo=l(),k1=a("li"),k2e=a("strong"),vIo=o("layoutlmv3"),FIo=o(" \u2014 "),Lz=a("a"),TIo=o("LayoutLMv3Model"),MIo=o(" (LayoutLMv3 model)"),EIo=l(),S1=a("li"),S2e=a("strong"),CIo=o("led"),wIo=o(" \u2014 "),yz=a("a"),AIo=o("LEDModel"),LIo=o(" (LED model)"),yIo=l(),R1=a("li"),R2e=a("strong"),xIo=o("levit"),$Io=o(" \u2014 "),xz=a("a"),kIo=o("LevitModel"),SIo=o(" (LeViT model)"),RIo=l(),P1=a("li"),P2e=a("strong"),PIo=o("lilt"),BIo=o(" \u2014 "),$z=a("a"),IIo=o("LiltModel"),NIo=o(" (LiLT model)"),qIo=l(),B1=a("li"),B2e=a("strong"),DIo=o("longformer"),jIo=o(" \u2014 "),kz=a("a"),GIo=o("LongformerModel"),OIo=o(" (Longformer model)"),VIo=l(),I1=a("li"),I2e=a("strong"),XIo=o("longt5"),zIo=o(" \u2014 "),Sz=a("a"),QIo=o("LongT5Model"),WIo=o(" (LongT5 model)"),UIo=l(),N1=a("li"),N2e=a("strong"),HIo=o("luke"),JIo=o(" \u2014 "),Rz=a("a"),YIo=o("LukeModel"),ZIo=o(" (LUKE model)"),KIo=l(),q1=a("li"),q2e=a("strong"),eNo=o("lxmert"),oNo=o(" \u2014 "),Pz=a("a"),rNo=o("LxmertModel"),tNo=o(" (LXMERT model)"),aNo=l(),D1=a("li"),D2e=a("strong"),nNo=o("m2m_100"),sNo=o(" \u2014 "),Bz=a("a"),lNo=o("M2M100Model"),iNo=o(" (M2M100 model)"),dNo=l(),j1=a("li"),j2e=a("strong"),mNo=o("marian"),cNo=o(" \u2014 "),Iz=a("a"),fNo=o("MarianModel"),gNo=o(" (Marian model)"),hNo=l(),G1=a("li"),G2e=a("strong"),uNo=o("markuplm"),pNo=o(" \u2014 "),Nz=a("a"),_No=o("MarkupLMModel"),bNo=o(" (MarkupLM model)"),vNo=l(),O1=a("li"),O2e=a("strong"),FNo=o("maskformer"),TNo=o(" \u2014 "),qz=a("a"),MNo=o("MaskFormerModel"),ENo=o(" (MaskFormer model)"),CNo=l(),V1=a("li"),V2e=a("strong"),wNo=o("mbart"),ANo=o(" \u2014 "),Dz=a("a"),LNo=o("MBartModel"),yNo=o(" (mBART model)"),xNo=l(),X1=a("li"),X2e=a("strong"),$No=o("mctct"),kNo=o(" \u2014 "),jz=a("a"),SNo=o("MCTCTModel"),RNo=o(" (M-CTC-T model)"),PNo=l(),z1=a("li"),z2e=a("strong"),BNo=o("megatron-bert"),INo=o(" \u2014 "),Gz=a("a"),NNo=o("MegatronBertModel"),qNo=o(" (Megatron-BERT model)"),DNo=l(),Q1=a("li"),Q2e=a("strong"),jNo=o("mobilebert"),GNo=o(" \u2014 "),Oz=a("a"),ONo=o("MobileBertModel"),VNo=o(" (MobileBERT model)"),XNo=l(),W1=a("li"),W2e=a("strong"),zNo=o("mobilevit"),QNo=o(" \u2014 "),Vz=a("a"),WNo=o("MobileViTModel"),UNo=o(" (MobileViT model)"),HNo=l(),U1=a("li"),U2e=a("strong"),JNo=o("mpnet"),YNo=o(" \u2014 "),Xz=a("a"),ZNo=o("MPNetModel"),KNo=o(" (MPNet model)"),eqo=l(),H1=a("li"),H2e=a("strong"),oqo=o("mt5"),rqo=o(" \u2014 "),zz=a("a"),tqo=o("MT5Model"),aqo=o(" (MT5 model)"),nqo=l(),J1=a("li"),J2e=a("strong"),sqo=o("mvp"),lqo=o(" \u2014 "),Qz=a("a"),iqo=o("MvpModel"),dqo=o(" (MVP model)"),mqo=l(),Y1=a("li"),Y2e=a("strong"),cqo=o("nezha"),fqo=o(" \u2014 "),Wz=a("a"),gqo=o("NezhaModel"),hqo=o(" (Nezha model)"),uqo=l(),Z1=a("li"),Z2e=a("strong"),pqo=o("nllb"),_qo=o(" \u2014 "),Uz=a("a"),bqo=o("M2M100Model"),vqo=o(" (NLLB model)"),Fqo=l(),K1=a("li"),K2e=a("strong"),Tqo=o("nystromformer"),Mqo=o(" \u2014 "),Hz=a("a"),Eqo=o("NystromformerModel"),Cqo=o(" (Nystr\xF6mformer model)"),wqo=l(),e2=a("li"),ebe=a("strong"),Aqo=o("openai-gpt"),Lqo=o(" \u2014 "),Jz=a("a"),yqo=o("OpenAIGPTModel"),xqo=o(" (OpenAI GPT model)"),$qo=l(),o2=a("li"),obe=a("strong"),kqo=o("opt"),Sqo=o(" \u2014 "),Yz=a("a"),Rqo=o("OPTModel"),Pqo=o(" (OPT model)"),Bqo=l(),r2=a("li"),rbe=a("strong"),Iqo=o("owlvit"),Nqo=o(" \u2014 "),Zz=a("a"),qqo=o("OwlViTModel"),Dqo=o(" (OWL-ViT model)"),jqo=l(),t2=a("li"),tbe=a("strong"),Gqo=o("pegasus"),Oqo=o(" \u2014 "),Kz=a("a"),Vqo=o("PegasusModel"),Xqo=o(" (Pegasus model)"),zqo=l(),a2=a("li"),abe=a("strong"),Qqo=o("pegasus_x"),Wqo=o(" \u2014 "),eQ=a("a"),Uqo=o("PegasusXModel"),Hqo=o(" (PEGASUS-X model)"),Jqo=l(),n2=a("li"),nbe=a("strong"),Yqo=o("perceiver"),Zqo=o(" \u2014 "),oQ=a("a"),Kqo=o("PerceiverModel"),eDo=o(" (Perceiver model)"),oDo=l(),s2=a("li"),sbe=a("strong"),rDo=o("plbart"),tDo=o(" \u2014 "),rQ=a("a"),aDo=o("PLBartModel"),nDo=o(" (PLBart model)"),sDo=l(),l2=a("li"),lbe=a("strong"),lDo=o("poolformer"),iDo=o(" \u2014 "),tQ=a("a"),dDo=o("PoolFormerModel"),mDo=o(" (PoolFormer model)"),cDo=l(),i2=a("li"),ibe=a("strong"),fDo=o("prophetnet"),gDo=o(" \u2014 "),aQ=a("a"),hDo=o("ProphetNetModel"),uDo=o(" (ProphetNet model)"),pDo=l(),d2=a("li"),dbe=a("strong"),_Do=o("qdqbert"),bDo=o(" \u2014 "),nQ=a("a"),vDo=o("QDQBertModel"),FDo=o(" (QDQBert model)"),TDo=l(),m2=a("li"),mbe=a("strong"),MDo=o("reformer"),EDo=o(" \u2014 "),sQ=a("a"),CDo=o("ReformerModel"),wDo=o(" (Reformer model)"),ADo=l(),c2=a("li"),cbe=a("strong"),LDo=o("regnet"),yDo=o(" \u2014 "),lQ=a("a"),xDo=o("RegNetModel"),$Do=o(" (RegNet model)"),kDo=l(),f2=a("li"),fbe=a("strong"),SDo=o("rembert"),RDo=o(" \u2014 "),iQ=a("a"),PDo=o("RemBertModel"),BDo=o(" (RemBERT model)"),IDo=l(),g2=a("li"),gbe=a("strong"),NDo=o("resnet"),qDo=o(" \u2014 "),dQ=a("a"),DDo=o("ResNetModel"),jDo=o(" (ResNet model)"),GDo=l(),h2=a("li"),hbe=a("strong"),ODo=o("retribert"),VDo=o(" \u2014 "),mQ=a("a"),XDo=o("RetriBertModel"),zDo=o(" (RetriBERT model)"),QDo=l(),u2=a("li"),ube=a("strong"),WDo=o("roberta"),UDo=o(" \u2014 "),cQ=a("a"),HDo=o("RobertaModel"),JDo=o(" (RoBERTa model)"),YDo=l(),p2=a("li"),pbe=a("strong"),ZDo=o("roformer"),KDo=o(" \u2014 "),fQ=a("a"),ejo=o("RoFormerModel"),ojo=o(" (RoFormer model)"),rjo=l(),_2=a("li"),_be=a("strong"),tjo=o("segformer"),ajo=o(" \u2014 "),gQ=a("a"),njo=o("SegformerModel"),sjo=o(" (SegFormer model)"),ljo=l(),b2=a("li"),bbe=a("strong"),ijo=o("sew"),djo=o(" \u2014 "),hQ=a("a"),mjo=o("SEWModel"),cjo=o(" (SEW model)"),fjo=l(),v2=a("li"),vbe=a("strong"),gjo=o("sew-d"),hjo=o(" \u2014 "),uQ=a("a"),ujo=o("SEWDModel"),pjo=o(" (SEW-D model)"),_jo=l(),F2=a("li"),Fbe=a("strong"),bjo=o("speech_to_text"),vjo=o(" \u2014 "),pQ=a("a"),Fjo=o("Speech2TextModel"),Tjo=o(" (Speech2Text model)"),Mjo=l(),T2=a("li"),Tbe=a("strong"),Ejo=o("splinter"),Cjo=o(" \u2014 "),_Q=a("a"),wjo=o("SplinterModel"),Ajo=o(" (Splinter model)"),Ljo=l(),M2=a("li"),Mbe=a("strong"),yjo=o("squeezebert"),xjo=o(" \u2014 "),bQ=a("a"),$jo=o("SqueezeBertModel"),kjo=o(" (SqueezeBERT model)"),Sjo=l(),E2=a("li"),Ebe=a("strong"),Rjo=o("swin"),Pjo=o(" \u2014 "),vQ=a("a"),Bjo=o("SwinModel"),Ijo=o(" (Swin Transformer model)"),Njo=l(),C2=a("li"),Cbe=a("strong"),qjo=o("swinv2"),Djo=o(" \u2014 "),FQ=a("a"),jjo=o("Swinv2Model"),Gjo=o(" (Swin Transformer V2 model)"),Ojo=l(),w2=a("li"),wbe=a("strong"),Vjo=o("t5"),Xjo=o(" \u2014 "),TQ=a("a"),zjo=o("T5Model"),Qjo=o(" (T5 model)"),Wjo=l(),A2=a("li"),Abe=a("strong"),Ujo=o("table-transformer"),Hjo=o(" \u2014 "),MQ=a("a"),Jjo=o("TableTransformerModel"),Yjo=o(" (Table Transformer model)"),Zjo=l(),L2=a("li"),Lbe=a("strong"),Kjo=o("tapas"),eGo=o(" \u2014 "),EQ=a("a"),oGo=o("TapasModel"),rGo=o(" (TAPAS model)"),tGo=l(),y2=a("li"),ybe=a("strong"),aGo=o("time_series_transformer"),nGo=o(" \u2014 "),CQ=a("a"),sGo=o("TimeSeriesTransformerModel"),lGo=o(" (Time Series Transformer model)"),iGo=l(),x2=a("li"),xbe=a("strong"),dGo=o("trajectory_transformer"),mGo=o(" \u2014 "),wQ=a("a"),cGo=o("TrajectoryTransformerModel"),fGo=o(" (Trajectory Transformer model)"),gGo=l(),$2=a("li"),$be=a("strong"),hGo=o("transfo-xl"),uGo=o(" \u2014 "),AQ=a("a"),pGo=o("TransfoXLModel"),_Go=o(" (Transformer-XL model)"),bGo=l(),k2=a("li"),kbe=a("strong"),vGo=o("unispeech"),FGo=o(" \u2014 "),LQ=a("a"),TGo=o("UniSpeechModel"),MGo=o(" (UniSpeech model)"),EGo=l(),S2=a("li"),Sbe=a("strong"),CGo=o("unispeech-sat"),wGo=o(" \u2014 "),yQ=a("a"),AGo=o("UniSpeechSatModel"),LGo=o(" (UniSpeechSat model)"),yGo=l(),R2=a("li"),Rbe=a("strong"),xGo=o("van"),$Go=o(" \u2014 "),xQ=a("a"),kGo=o("VanModel"),SGo=o(" (VAN model)"),RGo=l(),P2=a("li"),Pbe=a("strong"),PGo=o("videomae"),BGo=o(" \u2014 "),$Q=a("a"),IGo=o("VideoMAEModel"),NGo=o(" (VideoMAE model)"),qGo=l(),B2=a("li"),Bbe=a("strong"),DGo=o("vilt"),jGo=o(" \u2014 "),kQ=a("a"),GGo=o("ViltModel"),OGo=o(" (ViLT model)"),VGo=l(),I2=a("li"),Ibe=a("strong"),XGo=o("vision-text-dual-encoder"),zGo=o(" \u2014 "),SQ=a("a"),QGo=o("VisionTextDualEncoderModel"),WGo=o(" (VisionTextDualEncoder model)"),UGo=l(),N2=a("li"),Nbe=a("strong"),HGo=o("visual_bert"),JGo=o(" \u2014 "),RQ=a("a"),YGo=o("VisualBertModel"),ZGo=o(" (VisualBERT model)"),KGo=l(),q2=a("li"),qbe=a("strong"),eOo=o("vit"),oOo=o(" \u2014 "),PQ=a("a"),rOo=o("ViTModel"),tOo=o(" (ViT model)"),aOo=l(),D2=a("li"),Dbe=a("strong"),nOo=o("vit_mae"),sOo=o(" \u2014 "),BQ=a("a"),lOo=o("ViTMAEModel"),iOo=o(" (ViTMAE model)"),dOo=l(),j2=a("li"),jbe=a("strong"),mOo=o("vit_msn"),cOo=o(" \u2014 "),IQ=a("a"),fOo=o("ViTMSNModel"),gOo=o(" (ViTMSN model)"),hOo=l(),G2=a("li"),Gbe=a("strong"),uOo=o("wav2vec2"),pOo=o(" \u2014 "),NQ=a("a"),_Oo=o("Wav2Vec2Model"),bOo=o(" (Wav2Vec2 model)"),vOo=l(),O2=a("li"),Obe=a("strong"),FOo=o("wav2vec2-conformer"),TOo=o(" \u2014 "),qQ=a("a"),MOo=o("Wav2Vec2ConformerModel"),EOo=o(" (Wav2Vec2-Conformer model)"),COo=l(),V2=a("li"),Vbe=a("strong"),wOo=o("wavlm"),AOo=o(" \u2014 "),DQ=a("a"),LOo=o("WavLMModel"),yOo=o(" (WavLM model)"),xOo=l(),X2=a("li"),Xbe=a("strong"),$Oo=o("whisper"),kOo=o(" \u2014 "),jQ=a("a"),SOo=o("WhisperModel"),ROo=o(" (Whisper model)"),POo=l(),z2=a("li"),zbe=a("strong"),BOo=o("xclip"),IOo=o(" \u2014 "),GQ=a("a"),NOo=o("XCLIPModel"),qOo=o(" (X-CLIP model)"),DOo=l(),Q2=a("li"),Qbe=a("strong"),jOo=o("xglm"),GOo=o(" \u2014 "),OQ=a("a"),OOo=o("XGLMModel"),VOo=o(" (XGLM model)"),XOo=l(),W2=a("li"),Wbe=a("strong"),zOo=o("xlm"),QOo=o(" \u2014 "),VQ=a("a"),WOo=o("XLMModel"),UOo=o(" (XLM model)"),HOo=l(),U2=a("li"),Ube=a("strong"),JOo=o("xlm-prophetnet"),YOo=o(" \u2014 "),XQ=a("a"),ZOo=o("XLMProphetNetModel"),KOo=o(" (XLM-ProphetNet model)"),eVo=l(),H2=a("li"),Hbe=a("strong"),oVo=o("xlm-roberta"),rVo=o(" \u2014 "),zQ=a("a"),tVo=o("XLMRobertaModel"),aVo=o(" (XLM-RoBERTa model)"),nVo=l(),J2=a("li"),Jbe=a("strong"),sVo=o("xlm-roberta-xl"),lVo=o(" \u2014 "),QQ=a("a"),iVo=o("XLMRobertaXLModel"),dVo=o(" (XLM-RoBERTa-XL model)"),mVo=l(),Y2=a("li"),Ybe=a("strong"),cVo=o("xlnet"),fVo=o(" \u2014 "),WQ=a("a"),gVo=o("XLNetModel"),hVo=o(" (XLNet model)"),uVo=l(),Z2=a("li"),Zbe=a("strong"),pVo=o("yolos"),_Vo=o(" \u2014 "),UQ=a("a"),bVo=o("YolosModel"),vVo=o(" (YOLOS model)"),FVo=l(),K2=a("li"),Kbe=a("strong"),TVo=o("yoso"),MVo=o(" \u2014 "),HQ=a("a"),EVo=o("YosoModel"),CVo=o(" (YOSO model)"),wVo=l(),eb=a("p"),AVo=o("The model is set in evaluation mode by default using "),eve=a("code"),LVo=o("model.eval()"),yVo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ove=a("code"),xVo=o("model.train()"),$Vo=l(),F(ob.$$.fragment),Dto=l(),Pd=a("h2"),rb=a("a"),rve=a("span"),F(j$.$$.fragment),kVo=l(),tve=a("span"),SVo=o("AutoModelForPreTraining"),jto=l(),No=a("div"),F(G$.$$.fragment),RVo=l(),Bd=a("p"),PVo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),JQ=a("a"),BVo=o("from_pretrained()"),IVo=o(" class method or the "),YQ=a("a"),NVo=o("from_config()"),qVo=o(` class
method.`),DVo=l(),O$=a("p"),jVo=o("This class cannot be instantiated directly using "),ave=a("code"),GVo=o("__init__()"),OVo=o(" (throws an error)."),VVo=l(),Et=a("div"),F(V$.$$.fragment),XVo=l(),nve=a("p"),zVo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),QVo=l(),Id=a("p"),WVo=o(`Note:
Loading a model from its configuration file does `),sve=a("strong"),UVo=o("not"),HVo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ZQ=a("a"),JVo=o("from_pretrained()"),YVo=o(" to load the model weights."),ZVo=l(),F(tb.$$.fragment),KVo=l(),eo=a("div"),F(X$.$$.fragment),eXo=l(),lve=a("p"),oXo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),rXo=l(),sn=a("p"),tXo=o("The model class to instantiate is selected based on the "),ive=a("code"),aXo=o("model_type"),nXo=o(` property of the config object (either
passed as an argument or loaded from `),dve=a("code"),sXo=o("pretrained_model_name_or_path"),lXo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mve=a("code"),iXo=o("pretrained_model_name_or_path"),dXo=o(":"),mXo=l(),G=a("ul"),ab=a("li"),cve=a("strong"),cXo=o("albert"),fXo=o(" \u2014 "),KQ=a("a"),gXo=o("AlbertForPreTraining"),hXo=o(" (ALBERT model)"),uXo=l(),nb=a("li"),fve=a("strong"),pXo=o("bart"),_Xo=o(" \u2014 "),eW=a("a"),bXo=o("BartForConditionalGeneration"),vXo=o(" (BART model)"),FXo=l(),sb=a("li"),gve=a("strong"),TXo=o("bert"),MXo=o(" \u2014 "),oW=a("a"),EXo=o("BertForPreTraining"),CXo=o(" (BERT model)"),wXo=l(),lb=a("li"),hve=a("strong"),AXo=o("big_bird"),LXo=o(" \u2014 "),rW=a("a"),yXo=o("BigBirdForPreTraining"),xXo=o(" (BigBird model)"),$Xo=l(),ib=a("li"),uve=a("strong"),kXo=o("bloom"),SXo=o(" \u2014 "),tW=a("a"),RXo=o("BloomForCausalLM"),PXo=o(" (BLOOM model)"),BXo=l(),db=a("li"),pve=a("strong"),IXo=o("camembert"),NXo=o(" \u2014 "),aW=a("a"),qXo=o("CamembertForMaskedLM"),DXo=o(" (CamemBERT model)"),jXo=l(),mb=a("li"),_ve=a("strong"),GXo=o("ctrl"),OXo=o(" \u2014 "),nW=a("a"),VXo=o("CTRLLMHeadModel"),XXo=o(" (CTRL model)"),zXo=l(),cb=a("li"),bve=a("strong"),QXo=o("data2vec-text"),WXo=o(" \u2014 "),sW=a("a"),UXo=o("Data2VecTextForMaskedLM"),HXo=o(" (Data2VecText model)"),JXo=l(),fb=a("li"),vve=a("strong"),YXo=o("deberta"),ZXo=o(" \u2014 "),lW=a("a"),KXo=o("DebertaForMaskedLM"),ezo=o(" (DeBERTa model)"),ozo=l(),gb=a("li"),Fve=a("strong"),rzo=o("deberta-v2"),tzo=o(" \u2014 "),iW=a("a"),azo=o("DebertaV2ForMaskedLM"),nzo=o(" (DeBERTa-v2 model)"),szo=l(),hb=a("li"),Tve=a("strong"),lzo=o("distilbert"),izo=o(" \u2014 "),dW=a("a"),dzo=o("DistilBertForMaskedLM"),mzo=o(" (DistilBERT model)"),czo=l(),ub=a("li"),Mve=a("strong"),fzo=o("electra"),gzo=o(" \u2014 "),mW=a("a"),hzo=o("ElectraForPreTraining"),uzo=o(" (ELECTRA model)"),pzo=l(),pb=a("li"),Eve=a("strong"),_zo=o("ernie"),bzo=o(" \u2014 "),cW=a("a"),vzo=o("ErnieForPreTraining"),Fzo=o(" (ERNIE model)"),Tzo=l(),_b=a("li"),Cve=a("strong"),Mzo=o("flaubert"),Ezo=o(" \u2014 "),fW=a("a"),Czo=o("FlaubertWithLMHeadModel"),wzo=o(" (FlauBERT model)"),Azo=l(),bb=a("li"),wve=a("strong"),Lzo=o("flava"),yzo=o(" \u2014 "),gW=a("a"),xzo=o("FlavaForPreTraining"),$zo=o(" (FLAVA model)"),kzo=l(),vb=a("li"),Ave=a("strong"),Szo=o("fnet"),Rzo=o(" \u2014 "),hW=a("a"),Pzo=o("FNetForPreTraining"),Bzo=o(" (FNet model)"),Izo=l(),Fb=a("li"),Lve=a("strong"),Nzo=o("fsmt"),qzo=o(" \u2014 "),uW=a("a"),Dzo=o("FSMTForConditionalGeneration"),jzo=o(" (FairSeq Machine-Translation model)"),Gzo=l(),Tb=a("li"),yve=a("strong"),Ozo=o("funnel"),Vzo=o(" \u2014 "),pW=a("a"),Xzo=o("FunnelForPreTraining"),zzo=o(" (Funnel Transformer model)"),Qzo=l(),Mb=a("li"),xve=a("strong"),Wzo=o("gpt2"),Uzo=o(" \u2014 "),_W=a("a"),Hzo=o("GPT2LMHeadModel"),Jzo=o(" (OpenAI GPT-2 model)"),Yzo=l(),Eb=a("li"),$ve=a("strong"),Zzo=o("ibert"),Kzo=o(" \u2014 "),bW=a("a"),eQo=o("IBertForMaskedLM"),oQo=o(" (I-BERT model)"),rQo=l(),Cb=a("li"),kve=a("strong"),tQo=o("layoutlm"),aQo=o(" \u2014 "),vW=a("a"),nQo=o("LayoutLMForMaskedLM"),sQo=o(" (LayoutLM model)"),lQo=l(),wb=a("li"),Sve=a("strong"),iQo=o("longformer"),dQo=o(" \u2014 "),FW=a("a"),mQo=o("LongformerForMaskedLM"),cQo=o(" (Longformer model)"),fQo=l(),Ab=a("li"),Rve=a("strong"),gQo=o("luke"),hQo=o(" \u2014 "),TW=a("a"),uQo=o("LukeForMaskedLM"),pQo=o(" (LUKE model)"),_Qo=l(),Lb=a("li"),Pve=a("strong"),bQo=o("lxmert"),vQo=o(" \u2014 "),MW=a("a"),FQo=o("LxmertForPreTraining"),TQo=o(" (LXMERT model)"),MQo=l(),yb=a("li"),Bve=a("strong"),EQo=o("megatron-bert"),CQo=o(" \u2014 "),EW=a("a"),wQo=o("MegatronBertForPreTraining"),AQo=o(" (Megatron-BERT model)"),LQo=l(),xb=a("li"),Ive=a("strong"),yQo=o("mobilebert"),xQo=o(" \u2014 "),CW=a("a"),$Qo=o("MobileBertForPreTraining"),kQo=o(" (MobileBERT model)"),SQo=l(),$b=a("li"),Nve=a("strong"),RQo=o("mpnet"),PQo=o(" \u2014 "),wW=a("a"),BQo=o("MPNetForMaskedLM"),IQo=o(" (MPNet model)"),NQo=l(),kb=a("li"),qve=a("strong"),qQo=o("mvp"),DQo=o(" \u2014 "),AW=a("a"),jQo=o("MvpForConditionalGeneration"),GQo=o(" (MVP model)"),OQo=l(),Sb=a("li"),Dve=a("strong"),VQo=o("nezha"),XQo=o(" \u2014 "),LW=a("a"),zQo=o("NezhaForPreTraining"),QQo=o(" (Nezha model)"),WQo=l(),Rb=a("li"),jve=a("strong"),UQo=o("openai-gpt"),HQo=o(" \u2014 "),yW=a("a"),JQo=o("OpenAIGPTLMHeadModel"),YQo=o(" (OpenAI GPT model)"),ZQo=l(),Pb=a("li"),Gve=a("strong"),KQo=o("retribert"),eWo=o(" \u2014 "),xW=a("a"),oWo=o("RetriBertModel"),rWo=o(" (RetriBERT model)"),tWo=l(),Bb=a("li"),Ove=a("strong"),aWo=o("roberta"),nWo=o(" \u2014 "),$W=a("a"),sWo=o("RobertaForMaskedLM"),lWo=o(" (RoBERTa model)"),iWo=l(),Ib=a("li"),Vve=a("strong"),dWo=o("splinter"),mWo=o(" \u2014 "),kW=a("a"),cWo=o("SplinterForPreTraining"),fWo=o(" (Splinter model)"),gWo=l(),Nb=a("li"),Xve=a("strong"),hWo=o("squeezebert"),uWo=o(" \u2014 "),SW=a("a"),pWo=o("SqueezeBertForMaskedLM"),_Wo=o(" (SqueezeBERT model)"),bWo=l(),qb=a("li"),zve=a("strong"),vWo=o("t5"),FWo=o(" \u2014 "),RW=a("a"),TWo=o("T5ForConditionalGeneration"),MWo=o(" (T5 model)"),EWo=l(),Db=a("li"),Qve=a("strong"),CWo=o("tapas"),wWo=o(" \u2014 "),PW=a("a"),AWo=o("TapasForMaskedLM"),LWo=o(" (TAPAS model)"),yWo=l(),jb=a("li"),Wve=a("strong"),xWo=o("transfo-xl"),$Wo=o(" \u2014 "),BW=a("a"),kWo=o("TransfoXLLMHeadModel"),SWo=o(" (Transformer-XL model)"),RWo=l(),Gb=a("li"),Uve=a("strong"),PWo=o("unispeech"),BWo=o(" \u2014 "),IW=a("a"),IWo=o("UniSpeechForPreTraining"),NWo=o(" (UniSpeech model)"),qWo=l(),Ob=a("li"),Hve=a("strong"),DWo=o("unispeech-sat"),jWo=o(" \u2014 "),NW=a("a"),GWo=o("UniSpeechSatForPreTraining"),OWo=o(" (UniSpeechSat model)"),VWo=l(),Vb=a("li"),Jve=a("strong"),XWo=o("videomae"),zWo=o(" \u2014 "),qW=a("a"),QWo=o("VideoMAEForPreTraining"),WWo=o(" (VideoMAE model)"),UWo=l(),Xb=a("li"),Yve=a("strong"),HWo=o("visual_bert"),JWo=o(" \u2014 "),DW=a("a"),YWo=o("VisualBertForPreTraining"),ZWo=o(" (VisualBERT model)"),KWo=l(),zb=a("li"),Zve=a("strong"),eUo=o("vit_mae"),oUo=o(" \u2014 "),jW=a("a"),rUo=o("ViTMAEForPreTraining"),tUo=o(" (ViTMAE model)"),aUo=l(),Qb=a("li"),Kve=a("strong"),nUo=o("wav2vec2"),sUo=o(" \u2014 "),GW=a("a"),lUo=o("Wav2Vec2ForPreTraining"),iUo=o(" (Wav2Vec2 model)"),dUo=l(),Wb=a("li"),eFe=a("strong"),mUo=o("wav2vec2-conformer"),cUo=o(" \u2014 "),OW=a("a"),fUo=o("Wav2Vec2ConformerForPreTraining"),gUo=o(" (Wav2Vec2-Conformer model)"),hUo=l(),Ub=a("li"),oFe=a("strong"),uUo=o("xlm"),pUo=o(" \u2014 "),VW=a("a"),_Uo=o("XLMWithLMHeadModel"),bUo=o(" (XLM model)"),vUo=l(),Hb=a("li"),rFe=a("strong"),FUo=o("xlm-roberta"),TUo=o(" \u2014 "),XW=a("a"),MUo=o("XLMRobertaForMaskedLM"),EUo=o(" (XLM-RoBERTa model)"),CUo=l(),Jb=a("li"),tFe=a("strong"),wUo=o("xlm-roberta-xl"),AUo=o(" \u2014 "),zW=a("a"),LUo=o("XLMRobertaXLForMaskedLM"),yUo=o(" (XLM-RoBERTa-XL model)"),xUo=l(),Yb=a("li"),aFe=a("strong"),$Uo=o("xlnet"),kUo=o(" \u2014 "),QW=a("a"),SUo=o("XLNetLMHeadModel"),RUo=o(" (XLNet model)"),PUo=l(),Zb=a("p"),BUo=o("The model is set in evaluation mode by default using "),nFe=a("code"),IUo=o("model.eval()"),NUo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),sFe=a("code"),qUo=o("model.train()"),DUo=l(),F(Kb.$$.fragment),Gto=l(),Nd=a("h2"),ev=a("a"),lFe=a("span"),F(z$.$$.fragment),jUo=l(),iFe=a("span"),GUo=o("AutoModelForCausalLM"),Oto=l(),qo=a("div"),F(Q$.$$.fragment),OUo=l(),qd=a("p"),VUo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),WW=a("a"),XUo=o("from_pretrained()"),zUo=o(" class method or the "),UW=a("a"),QUo=o("from_config()"),WUo=o(` class
method.`),UUo=l(),W$=a("p"),HUo=o("This class cannot be instantiated directly using "),dFe=a("code"),JUo=o("__init__()"),YUo=o(" (throws an error)."),ZUo=l(),Ct=a("div"),F(U$.$$.fragment),KUo=l(),mFe=a("p"),eHo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),oHo=l(),Dd=a("p"),rHo=o(`Note:
Loading a model from its configuration file does `),cFe=a("strong"),tHo=o("not"),aHo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),HW=a("a"),nHo=o("from_pretrained()"),sHo=o(" to load the model weights."),lHo=l(),F(ov.$$.fragment),iHo=l(),oo=a("div"),F(H$.$$.fragment),dHo=l(),fFe=a("p"),mHo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),cHo=l(),ln=a("p"),fHo=o("The model class to instantiate is selected based on the "),gFe=a("code"),gHo=o("model_type"),hHo=o(` property of the config object (either
passed as an argument or loaded from `),hFe=a("code"),uHo=o("pretrained_model_name_or_path"),pHo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uFe=a("code"),_Ho=o("pretrained_model_name_or_path"),bHo=o(":"),vHo=l(),W=a("ul"),rv=a("li"),pFe=a("strong"),FHo=o("bart"),THo=o(" \u2014 "),JW=a("a"),MHo=o("BartForCausalLM"),EHo=o(" (BART model)"),CHo=l(),tv=a("li"),_Fe=a("strong"),wHo=o("bert"),AHo=o(" \u2014 "),YW=a("a"),LHo=o("BertLMHeadModel"),yHo=o(" (BERT model)"),xHo=l(),av=a("li"),bFe=a("strong"),$Ho=o("bert-generation"),kHo=o(" \u2014 "),ZW=a("a"),SHo=o("BertGenerationDecoder"),RHo=o(" (Bert Generation model)"),PHo=l(),nv=a("li"),vFe=a("strong"),BHo=o("big_bird"),IHo=o(" \u2014 "),KW=a("a"),NHo=o("BigBirdForCausalLM"),qHo=o(" (BigBird model)"),DHo=l(),sv=a("li"),FFe=a("strong"),jHo=o("bigbird_pegasus"),GHo=o(" \u2014 "),eU=a("a"),OHo=o("BigBirdPegasusForCausalLM"),VHo=o(" (BigBird-Pegasus model)"),XHo=l(),lv=a("li"),TFe=a("strong"),zHo=o("blenderbot"),QHo=o(" \u2014 "),oU=a("a"),WHo=o("BlenderbotForCausalLM"),UHo=o(" (Blenderbot model)"),HHo=l(),iv=a("li"),MFe=a("strong"),JHo=o("blenderbot-small"),YHo=o(" \u2014 "),rU=a("a"),ZHo=o("BlenderbotSmallForCausalLM"),KHo=o(" (BlenderbotSmall model)"),eJo=l(),dv=a("li"),EFe=a("strong"),oJo=o("bloom"),rJo=o(" \u2014 "),tU=a("a"),tJo=o("BloomForCausalLM"),aJo=o(" (BLOOM model)"),nJo=l(),mv=a("li"),CFe=a("strong"),sJo=o("camembert"),lJo=o(" \u2014 "),aU=a("a"),iJo=o("CamembertForCausalLM"),dJo=o(" (CamemBERT model)"),mJo=l(),cv=a("li"),wFe=a("strong"),cJo=o("codegen"),fJo=o(" \u2014 "),nU=a("a"),gJo=o("CodeGenForCausalLM"),hJo=o(" (CodeGen model)"),uJo=l(),fv=a("li"),AFe=a("strong"),pJo=o("ctrl"),_Jo=o(" \u2014 "),sU=a("a"),bJo=o("CTRLLMHeadModel"),vJo=o(" (CTRL model)"),FJo=l(),gv=a("li"),LFe=a("strong"),TJo=o("data2vec-text"),MJo=o(" \u2014 "),lU=a("a"),EJo=o("Data2VecTextForCausalLM"),CJo=o(" (Data2VecText model)"),wJo=l(),hv=a("li"),yFe=a("strong"),AJo=o("electra"),LJo=o(" \u2014 "),iU=a("a"),yJo=o("ElectraForCausalLM"),xJo=o(" (ELECTRA model)"),$Jo=l(),uv=a("li"),xFe=a("strong"),kJo=o("ernie"),SJo=o(" \u2014 "),dU=a("a"),RJo=o("ErnieForCausalLM"),PJo=o(" (ERNIE model)"),BJo=l(),pv=a("li"),$Fe=a("strong"),IJo=o("gpt2"),NJo=o(" \u2014 "),mU=a("a"),qJo=o("GPT2LMHeadModel"),DJo=o(" (OpenAI GPT-2 model)"),jJo=l(),_v=a("li"),kFe=a("strong"),GJo=o("gpt_neo"),OJo=o(" \u2014 "),cU=a("a"),VJo=o("GPTNeoForCausalLM"),XJo=o(" (GPT Neo model)"),zJo=l(),bv=a("li"),SFe=a("strong"),QJo=o("gpt_neox"),WJo=o(" \u2014 "),fU=a("a"),UJo=o("GPTNeoXForCausalLM"),HJo=o(" (GPT NeoX model)"),JJo=l(),vv=a("li"),RFe=a("strong"),YJo=o("gpt_neox_japanese"),ZJo=o(" \u2014 "),gU=a("a"),KJo=o("GPTNeoXJapaneseForCausalLM"),eYo=o(" (GPT NeoX Japanese model)"),oYo=l(),Fv=a("li"),PFe=a("strong"),rYo=o("gptj"),tYo=o(" \u2014 "),hU=a("a"),aYo=o("GPTJForCausalLM"),nYo=o(" (GPT-J model)"),sYo=l(),Tv=a("li"),BFe=a("strong"),lYo=o("marian"),iYo=o(" \u2014 "),uU=a("a"),dYo=o("MarianForCausalLM"),mYo=o(" (Marian model)"),cYo=l(),Mv=a("li"),IFe=a("strong"),fYo=o("mbart"),gYo=o(" \u2014 "),pU=a("a"),hYo=o("MBartForCausalLM"),uYo=o(" (mBART model)"),pYo=l(),Ev=a("li"),NFe=a("strong"),_Yo=o("megatron-bert"),bYo=o(" \u2014 "),_U=a("a"),vYo=o("MegatronBertForCausalLM"),FYo=o(" (Megatron-BERT model)"),TYo=l(),Cv=a("li"),qFe=a("strong"),MYo=o("mvp"),EYo=o(" \u2014 "),bU=a("a"),CYo=o("MvpForCausalLM"),wYo=o(" (MVP model)"),AYo=l(),wv=a("li"),DFe=a("strong"),LYo=o("openai-gpt"),yYo=o(" \u2014 "),vU=a("a"),xYo=o("OpenAIGPTLMHeadModel"),$Yo=o(" (OpenAI GPT model)"),kYo=l(),Av=a("li"),jFe=a("strong"),SYo=o("opt"),RYo=o(" \u2014 "),FU=a("a"),PYo=o("OPTForCausalLM"),BYo=o(" (OPT model)"),IYo=l(),Lv=a("li"),GFe=a("strong"),NYo=o("pegasus"),qYo=o(" \u2014 "),TU=a("a"),DYo=o("PegasusForCausalLM"),jYo=o(" (Pegasus model)"),GYo=l(),yv=a("li"),OFe=a("strong"),OYo=o("plbart"),VYo=o(" \u2014 "),MU=a("a"),XYo=o("PLBartForCausalLM"),zYo=o(" (PLBart model)"),QYo=l(),xv=a("li"),VFe=a("strong"),WYo=o("prophetnet"),UYo=o(" \u2014 "),EU=a("a"),HYo=o("ProphetNetForCausalLM"),JYo=o(" (ProphetNet model)"),YYo=l(),$v=a("li"),XFe=a("strong"),ZYo=o("qdqbert"),KYo=o(" \u2014 "),CU=a("a"),eZo=o("QDQBertLMHeadModel"),oZo=o(" (QDQBert model)"),rZo=l(),kv=a("li"),zFe=a("strong"),tZo=o("reformer"),aZo=o(" \u2014 "),wU=a("a"),nZo=o("ReformerModelWithLMHead"),sZo=o(" (Reformer model)"),lZo=l(),Sv=a("li"),QFe=a("strong"),iZo=o("rembert"),dZo=o(" \u2014 "),AU=a("a"),mZo=o("RemBertForCausalLM"),cZo=o(" (RemBERT model)"),fZo=l(),Rv=a("li"),WFe=a("strong"),gZo=o("roberta"),hZo=o(" \u2014 "),LU=a("a"),uZo=o("RobertaForCausalLM"),pZo=o(" (RoBERTa model)"),_Zo=l(),Pv=a("li"),UFe=a("strong"),bZo=o("roformer"),vZo=o(" \u2014 "),yU=a("a"),FZo=o("RoFormerForCausalLM"),TZo=o(" (RoFormer model)"),MZo=l(),Bv=a("li"),HFe=a("strong"),EZo=o("speech_to_text_2"),CZo=o(" \u2014 "),xU=a("a"),wZo=o("Speech2Text2ForCausalLM"),AZo=o(" (Speech2Text2 model)"),LZo=l(),Iv=a("li"),JFe=a("strong"),yZo=o("transfo-xl"),xZo=o(" \u2014 "),$U=a("a"),$Zo=o("TransfoXLLMHeadModel"),kZo=o(" (Transformer-XL model)"),SZo=l(),Nv=a("li"),YFe=a("strong"),RZo=o("trocr"),PZo=o(" \u2014 "),kU=a("a"),BZo=o("TrOCRForCausalLM"),IZo=o(" (TrOCR model)"),NZo=l(),qv=a("li"),ZFe=a("strong"),qZo=o("xglm"),DZo=o(" \u2014 "),SU=a("a"),jZo=o("XGLMForCausalLM"),GZo=o(" (XGLM model)"),OZo=l(),Dv=a("li"),KFe=a("strong"),VZo=o("xlm"),XZo=o(" \u2014 "),RU=a("a"),zZo=o("XLMWithLMHeadModel"),QZo=o(" (XLM model)"),WZo=l(),jv=a("li"),eTe=a("strong"),UZo=o("xlm-prophetnet"),HZo=o(" \u2014 "),PU=a("a"),JZo=o("XLMProphetNetForCausalLM"),YZo=o(" (XLM-ProphetNet model)"),ZZo=l(),Gv=a("li"),oTe=a("strong"),KZo=o("xlm-roberta"),eKo=o(" \u2014 "),BU=a("a"),oKo=o("XLMRobertaForCausalLM"),rKo=o(" (XLM-RoBERTa model)"),tKo=l(),Ov=a("li"),rTe=a("strong"),aKo=o("xlm-roberta-xl"),nKo=o(" \u2014 "),IU=a("a"),sKo=o("XLMRobertaXLForCausalLM"),lKo=o(" (XLM-RoBERTa-XL model)"),iKo=l(),Vv=a("li"),tTe=a("strong"),dKo=o("xlnet"),mKo=o(" \u2014 "),NU=a("a"),cKo=o("XLNetLMHeadModel"),fKo=o(" (XLNet model)"),gKo=l(),Xv=a("p"),hKo=o("The model is set in evaluation mode by default using "),aTe=a("code"),uKo=o("model.eval()"),pKo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),nTe=a("code"),_Ko=o("model.train()"),bKo=l(),F(zv.$$.fragment),Vto=l(),jd=a("h2"),Qv=a("a"),sTe=a("span"),F(J$.$$.fragment),vKo=l(),lTe=a("span"),FKo=o("AutoModelForDepthEstimation"),Xto=l(),Do=a("div"),F(Y$.$$.fragment),TKo=l(),Gd=a("p"),MKo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a depth estimation head) when created
with the `),qU=a("a"),EKo=o("from_pretrained()"),CKo=o(" class method or the "),DU=a("a"),wKo=o("from_config()"),AKo=o(` class
method.`),LKo=l(),Z$=a("p"),yKo=o("This class cannot be instantiated directly using "),iTe=a("code"),xKo=o("__init__()"),$Ko=o(" (throws an error)."),kKo=l(),wt=a("div"),F(K$.$$.fragment),SKo=l(),dTe=a("p"),RKo=o("Instantiates one of the model classes of the library (with a depth estimation head) from a configuration."),PKo=l(),Od=a("p"),BKo=o(`Note:
Loading a model from its configuration file does `),mTe=a("strong"),IKo=o("not"),NKo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jU=a("a"),qKo=o("from_pretrained()"),DKo=o(" to load the model weights."),jKo=l(),F(Wv.$$.fragment),GKo=l(),ro=a("div"),F(ek.$$.fragment),OKo=l(),cTe=a("p"),VKo=o("Instantiate one of the model classes of the library (with a depth estimation head) from a pretrained model."),XKo=l(),dn=a("p"),zKo=o("The model class to instantiate is selected based on the "),fTe=a("code"),QKo=o("model_type"),WKo=o(` property of the config object (either
passed as an argument or loaded from `),gTe=a("code"),UKo=o("pretrained_model_name_or_path"),HKo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hTe=a("code"),JKo=o("pretrained_model_name_or_path"),YKo=o(":"),ZKo=l(),ok=a("ul"),Uv=a("li"),uTe=a("strong"),KKo=o("dpt"),eer=o(" \u2014 "),GU=a("a"),oer=o("DPTForDepthEstimation"),rer=o(" (DPT model)"),ter=l(),Hv=a("li"),pTe=a("strong"),aer=o("glpn"),ner=o(" \u2014 "),OU=a("a"),ser=o("GLPNForDepthEstimation"),ler=o(" (GLPN model)"),ier=l(),Jv=a("p"),der=o("The model is set in evaluation mode by default using "),_Te=a("code"),mer=o("model.eval()"),cer=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),bTe=a("code"),fer=o("model.train()"),ger=l(),F(Yv.$$.fragment),zto=l(),Vd=a("h2"),Zv=a("a"),vTe=a("span"),F(rk.$$.fragment),her=l(),FTe=a("span"),uer=o("AutoModelForMaskedLM"),Qto=l(),jo=a("div"),F(tk.$$.fragment),per=l(),Xd=a("p"),_er=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),VU=a("a"),ber=o("from_pretrained()"),ver=o(" class method or the "),XU=a("a"),Fer=o("from_config()"),Ter=o(` class
method.`),Mer=l(),ak=a("p"),Eer=o("This class cannot be instantiated directly using "),TTe=a("code"),Cer=o("__init__()"),wer=o(" (throws an error)."),Aer=l(),At=a("div"),F(nk.$$.fragment),Ler=l(),MTe=a("p"),yer=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),xer=l(),zd=a("p"),$er=o(`Note:
Loading a model from its configuration file does `),ETe=a("strong"),ker=o("not"),Ser=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zU=a("a"),Rer=o("from_pretrained()"),Per=o(" to load the model weights."),Ber=l(),F(Kv.$$.fragment),Ier=l(),to=a("div"),F(sk.$$.fragment),Ner=l(),CTe=a("p"),qer=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Der=l(),mn=a("p"),jer=o("The model class to instantiate is selected based on the "),wTe=a("code"),Ger=o("model_type"),Oer=o(` property of the config object (either
passed as an argument or loaded from `),ATe=a("code"),Ver=o("pretrained_model_name_or_path"),Xer=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),LTe=a("code"),zer=o("pretrained_model_name_or_path"),Qer=o(":"),Wer=l(),Y=a("ul"),eF=a("li"),yTe=a("strong"),Uer=o("albert"),Her=o(" \u2014 "),QU=a("a"),Jer=o("AlbertForMaskedLM"),Yer=o(" (ALBERT model)"),Zer=l(),oF=a("li"),xTe=a("strong"),Ker=o("bart"),eor=o(" \u2014 "),WU=a("a"),oor=o("BartForConditionalGeneration"),ror=o(" (BART model)"),tor=l(),rF=a("li"),$Te=a("strong"),aor=o("bert"),nor=o(" \u2014 "),UU=a("a"),sor=o("BertForMaskedLM"),lor=o(" (BERT model)"),ior=l(),tF=a("li"),kTe=a("strong"),dor=o("big_bird"),mor=o(" \u2014 "),HU=a("a"),cor=o("BigBirdForMaskedLM"),gor=o(" (BigBird model)"),hor=l(),aF=a("li"),STe=a("strong"),uor=o("camembert"),por=o(" \u2014 "),JU=a("a"),_or=o("CamembertForMaskedLM"),bor=o(" (CamemBERT model)"),vor=l(),nF=a("li"),RTe=a("strong"),For=o("convbert"),Tor=o(" \u2014 "),YU=a("a"),Mor=o("ConvBertForMaskedLM"),Eor=o(" (ConvBERT model)"),Cor=l(),sF=a("li"),PTe=a("strong"),wor=o("data2vec-text"),Aor=o(" \u2014 "),ZU=a("a"),Lor=o("Data2VecTextForMaskedLM"),yor=o(" (Data2VecText model)"),xor=l(),lF=a("li"),BTe=a("strong"),$or=o("deberta"),kor=o(" \u2014 "),KU=a("a"),Sor=o("DebertaForMaskedLM"),Ror=o(" (DeBERTa model)"),Por=l(),iF=a("li"),ITe=a("strong"),Bor=o("deberta-v2"),Ior=o(" \u2014 "),eH=a("a"),Nor=o("DebertaV2ForMaskedLM"),qor=o(" (DeBERTa-v2 model)"),Dor=l(),dF=a("li"),NTe=a("strong"),jor=o("distilbert"),Gor=o(" \u2014 "),oH=a("a"),Oor=o("DistilBertForMaskedLM"),Vor=o(" (DistilBERT model)"),Xor=l(),mF=a("li"),qTe=a("strong"),zor=o("electra"),Qor=o(" \u2014 "),rH=a("a"),Wor=o("ElectraForMaskedLM"),Uor=o(" (ELECTRA model)"),Hor=l(),cF=a("li"),DTe=a("strong"),Jor=o("ernie"),Yor=o(" \u2014 "),tH=a("a"),Zor=o("ErnieForMaskedLM"),Kor=o(" (ERNIE model)"),err=l(),fF=a("li"),jTe=a("strong"),orr=o("flaubert"),rrr=o(" \u2014 "),aH=a("a"),trr=o("FlaubertWithLMHeadModel"),arr=o(" (FlauBERT model)"),nrr=l(),gF=a("li"),GTe=a("strong"),srr=o("fnet"),lrr=o(" \u2014 "),nH=a("a"),irr=o("FNetForMaskedLM"),drr=o(" (FNet model)"),mrr=l(),hF=a("li"),OTe=a("strong"),crr=o("funnel"),frr=o(" \u2014 "),sH=a("a"),grr=o("FunnelForMaskedLM"),hrr=o(" (Funnel Transformer model)"),urr=l(),uF=a("li"),VTe=a("strong"),prr=o("ibert"),_rr=o(" \u2014 "),lH=a("a"),brr=o("IBertForMaskedLM"),vrr=o(" (I-BERT model)"),Frr=l(),pF=a("li"),XTe=a("strong"),Trr=o("layoutlm"),Mrr=o(" \u2014 "),iH=a("a"),Err=o("LayoutLMForMaskedLM"),Crr=o(" (LayoutLM model)"),wrr=l(),_F=a("li"),zTe=a("strong"),Arr=o("longformer"),Lrr=o(" \u2014 "),dH=a("a"),yrr=o("LongformerForMaskedLM"),xrr=o(" (Longformer model)"),$rr=l(),bF=a("li"),QTe=a("strong"),krr=o("luke"),Srr=o(" \u2014 "),mH=a("a"),Rrr=o("LukeForMaskedLM"),Prr=o(" (LUKE model)"),Brr=l(),vF=a("li"),WTe=a("strong"),Irr=o("mbart"),Nrr=o(" \u2014 "),cH=a("a"),qrr=o("MBartForConditionalGeneration"),Drr=o(" (mBART model)"),jrr=l(),FF=a("li"),UTe=a("strong"),Grr=o("megatron-bert"),Orr=o(" \u2014 "),fH=a("a"),Vrr=o("MegatronBertForMaskedLM"),Xrr=o(" (Megatron-BERT model)"),zrr=l(),TF=a("li"),HTe=a("strong"),Qrr=o("mobilebert"),Wrr=o(" \u2014 "),gH=a("a"),Urr=o("MobileBertForMaskedLM"),Hrr=o(" (MobileBERT model)"),Jrr=l(),MF=a("li"),JTe=a("strong"),Yrr=o("mpnet"),Zrr=o(" \u2014 "),hH=a("a"),Krr=o("MPNetForMaskedLM"),etr=o(" (MPNet model)"),otr=l(),EF=a("li"),YTe=a("strong"),rtr=o("mvp"),ttr=o(" \u2014 "),uH=a("a"),atr=o("MvpForConditionalGeneration"),ntr=o(" (MVP model)"),str=l(),CF=a("li"),ZTe=a("strong"),ltr=o("nezha"),itr=o(" \u2014 "),pH=a("a"),dtr=o("NezhaForMaskedLM"),mtr=o(" (Nezha model)"),ctr=l(),wF=a("li"),KTe=a("strong"),ftr=o("nystromformer"),gtr=o(" \u2014 "),_H=a("a"),htr=o("NystromformerForMaskedLM"),utr=o(" (Nystr\xF6mformer model)"),ptr=l(),AF=a("li"),eMe=a("strong"),_tr=o("perceiver"),btr=o(" \u2014 "),bH=a("a"),vtr=o("PerceiverForMaskedLM"),Ftr=o(" (Perceiver model)"),Ttr=l(),LF=a("li"),oMe=a("strong"),Mtr=o("qdqbert"),Etr=o(" \u2014 "),vH=a("a"),Ctr=o("QDQBertForMaskedLM"),wtr=o(" (QDQBert model)"),Atr=l(),yF=a("li"),rMe=a("strong"),Ltr=o("reformer"),ytr=o(" \u2014 "),FH=a("a"),xtr=o("ReformerForMaskedLM"),$tr=o(" (Reformer model)"),ktr=l(),xF=a("li"),tMe=a("strong"),Str=o("rembert"),Rtr=o(" \u2014 "),TH=a("a"),Ptr=o("RemBertForMaskedLM"),Btr=o(" (RemBERT model)"),Itr=l(),$F=a("li"),aMe=a("strong"),Ntr=o("roberta"),qtr=o(" \u2014 "),MH=a("a"),Dtr=o("RobertaForMaskedLM"),jtr=o(" (RoBERTa model)"),Gtr=l(),kF=a("li"),nMe=a("strong"),Otr=o("roformer"),Vtr=o(" \u2014 "),EH=a("a"),Xtr=o("RoFormerForMaskedLM"),ztr=o(" (RoFormer model)"),Qtr=l(),SF=a("li"),sMe=a("strong"),Wtr=o("squeezebert"),Utr=o(" \u2014 "),CH=a("a"),Htr=o("SqueezeBertForMaskedLM"),Jtr=o(" (SqueezeBERT model)"),Ytr=l(),RF=a("li"),lMe=a("strong"),Ztr=o("tapas"),Ktr=o(" \u2014 "),wH=a("a"),ear=o("TapasForMaskedLM"),oar=o(" (TAPAS model)"),rar=l(),PF=a("li"),iMe=a("strong"),tar=o("wav2vec2"),aar=o(" \u2014 "),dMe=a("code"),nar=o("Wav2Vec2ForMaskedLM"),sar=o(" (Wav2Vec2 model)"),lar=l(),BF=a("li"),mMe=a("strong"),iar=o("xlm"),dar=o(" \u2014 "),AH=a("a"),mar=o("XLMWithLMHeadModel"),car=o(" (XLM model)"),far=l(),IF=a("li"),cMe=a("strong"),gar=o("xlm-roberta"),har=o(" \u2014 "),LH=a("a"),uar=o("XLMRobertaForMaskedLM"),par=o(" (XLM-RoBERTa model)"),_ar=l(),NF=a("li"),fMe=a("strong"),bar=o("xlm-roberta-xl"),Far=o(" \u2014 "),yH=a("a"),Tar=o("XLMRobertaXLForMaskedLM"),Mar=o(" (XLM-RoBERTa-XL model)"),Ear=l(),qF=a("li"),gMe=a("strong"),Car=o("yoso"),war=o(" \u2014 "),xH=a("a"),Aar=o("YosoForMaskedLM"),Lar=o(" (YOSO model)"),yar=l(),DF=a("p"),xar=o("The model is set in evaluation mode by default using "),hMe=a("code"),$ar=o("model.eval()"),kar=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),uMe=a("code"),Sar=o("model.train()"),Rar=l(),F(jF.$$.fragment),Wto=l(),Qd=a("h2"),GF=a("a"),pMe=a("span"),F(lk.$$.fragment),Par=l(),_Me=a("span"),Bar=o("AutoModelForSeq2SeqLM"),Uto=l(),Go=a("div"),F(ik.$$.fragment),Iar=l(),Wd=a("p"),Nar=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),$H=a("a"),qar=o("from_pretrained()"),Dar=o(" class method or the "),kH=a("a"),jar=o("from_config()"),Gar=o(` class
method.`),Oar=l(),dk=a("p"),Var=o("This class cannot be instantiated directly using "),bMe=a("code"),Xar=o("__init__()"),zar=o(" (throws an error)."),Qar=l(),Lt=a("div"),F(mk.$$.fragment),War=l(),vMe=a("p"),Uar=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Har=l(),Ud=a("p"),Jar=o(`Note:
Loading a model from its configuration file does `),FMe=a("strong"),Yar=o("not"),Zar=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SH=a("a"),Kar=o("from_pretrained()"),enr=o(" to load the model weights."),onr=l(),F(OF.$$.fragment),rnr=l(),ao=a("div"),F(ck.$$.fragment),tnr=l(),TMe=a("p"),anr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),nnr=l(),cn=a("p"),snr=o("The model class to instantiate is selected based on the "),MMe=a("code"),lnr=o("model_type"),inr=o(` property of the config object (either
passed as an argument or loaded from `),EMe=a("code"),dnr=o("pretrained_model_name_or_path"),mnr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),CMe=a("code"),cnr=o("pretrained_model_name_or_path"),fnr=o(":"),gnr=l(),he=a("ul"),VF=a("li"),wMe=a("strong"),hnr=o("bart"),unr=o(" \u2014 "),RH=a("a"),pnr=o("BartForConditionalGeneration"),_nr=o(" (BART model)"),bnr=l(),XF=a("li"),AMe=a("strong"),vnr=o("bigbird_pegasus"),Fnr=o(" \u2014 "),PH=a("a"),Tnr=o("BigBirdPegasusForConditionalGeneration"),Mnr=o(" (BigBird-Pegasus model)"),Enr=l(),zF=a("li"),LMe=a("strong"),Cnr=o("blenderbot"),wnr=o(" \u2014 "),BH=a("a"),Anr=o("BlenderbotForConditionalGeneration"),Lnr=o(" (Blenderbot model)"),ynr=l(),QF=a("li"),yMe=a("strong"),xnr=o("blenderbot-small"),$nr=o(" \u2014 "),IH=a("a"),knr=o("BlenderbotSmallForConditionalGeneration"),Snr=o(" (BlenderbotSmall model)"),Rnr=l(),WF=a("li"),xMe=a("strong"),Pnr=o("encoder-decoder"),Bnr=o(" \u2014 "),NH=a("a"),Inr=o("EncoderDecoderModel"),Nnr=o(" (Encoder decoder model)"),qnr=l(),UF=a("li"),$Me=a("strong"),Dnr=o("fsmt"),jnr=o(" \u2014 "),qH=a("a"),Gnr=o("FSMTForConditionalGeneration"),Onr=o(" (FairSeq Machine-Translation model)"),Vnr=l(),HF=a("li"),kMe=a("strong"),Xnr=o("led"),znr=o(" \u2014 "),DH=a("a"),Qnr=o("LEDForConditionalGeneration"),Wnr=o(" (LED model)"),Unr=l(),JF=a("li"),SMe=a("strong"),Hnr=o("longt5"),Jnr=o(" \u2014 "),jH=a("a"),Ynr=o("LongT5ForConditionalGeneration"),Znr=o(" (LongT5 model)"),Knr=l(),YF=a("li"),RMe=a("strong"),esr=o("m2m_100"),osr=o(" \u2014 "),GH=a("a"),rsr=o("M2M100ForConditionalGeneration"),tsr=o(" (M2M100 model)"),asr=l(),ZF=a("li"),PMe=a("strong"),nsr=o("marian"),ssr=o(" \u2014 "),OH=a("a"),lsr=o("MarianMTModel"),isr=o(" (Marian model)"),dsr=l(),KF=a("li"),BMe=a("strong"),msr=o("mbart"),csr=o(" \u2014 "),VH=a("a"),fsr=o("MBartForConditionalGeneration"),gsr=o(" (mBART model)"),hsr=l(),eT=a("li"),IMe=a("strong"),usr=o("mt5"),psr=o(" \u2014 "),XH=a("a"),_sr=o("MT5ForConditionalGeneration"),bsr=o(" (MT5 model)"),vsr=l(),oT=a("li"),NMe=a("strong"),Fsr=o("mvp"),Tsr=o(" \u2014 "),zH=a("a"),Msr=o("MvpForConditionalGeneration"),Esr=o(" (MVP model)"),Csr=l(),rT=a("li"),qMe=a("strong"),wsr=o("nllb"),Asr=o(" \u2014 "),QH=a("a"),Lsr=o("M2M100ForConditionalGeneration"),ysr=o(" (NLLB model)"),xsr=l(),tT=a("li"),DMe=a("strong"),$sr=o("pegasus"),ksr=o(" \u2014 "),WH=a("a"),Ssr=o("PegasusForConditionalGeneration"),Rsr=o(" (Pegasus model)"),Psr=l(),aT=a("li"),jMe=a("strong"),Bsr=o("pegasus_x"),Isr=o(" \u2014 "),UH=a("a"),Nsr=o("PegasusXForConditionalGeneration"),qsr=o(" (PEGASUS-X model)"),Dsr=l(),nT=a("li"),GMe=a("strong"),jsr=o("plbart"),Gsr=o(" \u2014 "),HH=a("a"),Osr=o("PLBartForConditionalGeneration"),Vsr=o(" (PLBart model)"),Xsr=l(),sT=a("li"),OMe=a("strong"),zsr=o("prophetnet"),Qsr=o(" \u2014 "),JH=a("a"),Wsr=o("ProphetNetForConditionalGeneration"),Usr=o(" (ProphetNet model)"),Hsr=l(),lT=a("li"),VMe=a("strong"),Jsr=o("t5"),Ysr=o(" \u2014 "),YH=a("a"),Zsr=o("T5ForConditionalGeneration"),Ksr=o(" (T5 model)"),elr=l(),iT=a("li"),XMe=a("strong"),olr=o("xlm-prophetnet"),rlr=o(" \u2014 "),ZH=a("a"),tlr=o("XLMProphetNetForConditionalGeneration"),alr=o(" (XLM-ProphetNet model)"),nlr=l(),dT=a("p"),slr=o("The model is set in evaluation mode by default using "),zMe=a("code"),llr=o("model.eval()"),ilr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),QMe=a("code"),dlr=o("model.train()"),mlr=l(),F(mT.$$.fragment),Hto=l(),Hd=a("h2"),cT=a("a"),WMe=a("span"),F(fk.$$.fragment),clr=l(),UMe=a("span"),flr=o("AutoModelForSequenceClassification"),Jto=l(),Oo=a("div"),F(gk.$$.fragment),glr=l(),Jd=a("p"),hlr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),KH=a("a"),ulr=o("from_pretrained()"),plr=o(" class method or the "),eJ=a("a"),_lr=o("from_config()"),blr=o(` class
method.`),vlr=l(),hk=a("p"),Flr=o("This class cannot be instantiated directly using "),HMe=a("code"),Tlr=o("__init__()"),Mlr=o(" (throws an error)."),Elr=l(),yt=a("div"),F(uk.$$.fragment),Clr=l(),JMe=a("p"),wlr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Alr=l(),Yd=a("p"),Llr=o(`Note:
Loading a model from its configuration file does `),YMe=a("strong"),ylr=o("not"),xlr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oJ=a("a"),$lr=o("from_pretrained()"),klr=o(" to load the model weights."),Slr=l(),F(fT.$$.fragment),Rlr=l(),no=a("div"),F(pk.$$.fragment),Plr=l(),ZMe=a("p"),Blr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Ilr=l(),fn=a("p"),Nlr=o("The model class to instantiate is selected based on the "),KMe=a("code"),qlr=o("model_type"),Dlr=o(` property of the config object (either
passed as an argument or loaded from `),eEe=a("code"),jlr=o("pretrained_model_name_or_path"),Glr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oEe=a("code"),Olr=o("pretrained_model_name_or_path"),Vlr=o(":"),Xlr=l(),D=a("ul"),gT=a("li"),rEe=a("strong"),zlr=o("albert"),Qlr=o(" \u2014 "),rJ=a("a"),Wlr=o("AlbertForSequenceClassification"),Ulr=o(" (ALBERT model)"),Hlr=l(),hT=a("li"),tEe=a("strong"),Jlr=o("bart"),Ylr=o(" \u2014 "),tJ=a("a"),Zlr=o("BartForSequenceClassification"),Klr=o(" (BART model)"),eir=l(),uT=a("li"),aEe=a("strong"),oir=o("bert"),rir=o(" \u2014 "),aJ=a("a"),tir=o("BertForSequenceClassification"),air=o(" (BERT model)"),nir=l(),pT=a("li"),nEe=a("strong"),sir=o("big_bird"),lir=o(" \u2014 "),nJ=a("a"),iir=o("BigBirdForSequenceClassification"),dir=o(" (BigBird model)"),mir=l(),_T=a("li"),sEe=a("strong"),cir=o("bigbird_pegasus"),fir=o(" \u2014 "),sJ=a("a"),gir=o("BigBirdPegasusForSequenceClassification"),hir=o(" (BigBird-Pegasus model)"),uir=l(),bT=a("li"),lEe=a("strong"),pir=o("bloom"),_ir=o(" \u2014 "),lJ=a("a"),bir=o("BloomForSequenceClassification"),vir=o(" (BLOOM model)"),Fir=l(),vT=a("li"),iEe=a("strong"),Tir=o("camembert"),Mir=o(" \u2014 "),iJ=a("a"),Eir=o("CamembertForSequenceClassification"),Cir=o(" (CamemBERT model)"),wir=l(),FT=a("li"),dEe=a("strong"),Air=o("canine"),Lir=o(" \u2014 "),dJ=a("a"),yir=o("CanineForSequenceClassification"),xir=o(" (CANINE model)"),$ir=l(),TT=a("li"),mEe=a("strong"),kir=o("convbert"),Sir=o(" \u2014 "),mJ=a("a"),Rir=o("ConvBertForSequenceClassification"),Pir=o(" (ConvBERT model)"),Bir=l(),MT=a("li"),cEe=a("strong"),Iir=o("ctrl"),Nir=o(" \u2014 "),cJ=a("a"),qir=o("CTRLForSequenceClassification"),Dir=o(" (CTRL model)"),jir=l(),ET=a("li"),fEe=a("strong"),Gir=o("data2vec-text"),Oir=o(" \u2014 "),fJ=a("a"),Vir=o("Data2VecTextForSequenceClassification"),Xir=o(" (Data2VecText model)"),zir=l(),CT=a("li"),gEe=a("strong"),Qir=o("deberta"),Wir=o(" \u2014 "),gJ=a("a"),Uir=o("DebertaForSequenceClassification"),Hir=o(" (DeBERTa model)"),Jir=l(),wT=a("li"),hEe=a("strong"),Yir=o("deberta-v2"),Zir=o(" \u2014 "),hJ=a("a"),Kir=o("DebertaV2ForSequenceClassification"),edr=o(" (DeBERTa-v2 model)"),odr=l(),AT=a("li"),uEe=a("strong"),rdr=o("distilbert"),tdr=o(" \u2014 "),uJ=a("a"),adr=o("DistilBertForSequenceClassification"),ndr=o(" (DistilBERT model)"),sdr=l(),LT=a("li"),pEe=a("strong"),ldr=o("electra"),idr=o(" \u2014 "),pJ=a("a"),ddr=o("ElectraForSequenceClassification"),mdr=o(" (ELECTRA model)"),cdr=l(),yT=a("li"),_Ee=a("strong"),fdr=o("ernie"),gdr=o(" \u2014 "),_J=a("a"),hdr=o("ErnieForSequenceClassification"),udr=o(" (ERNIE model)"),pdr=l(),xT=a("li"),bEe=a("strong"),_dr=o("esm"),bdr=o(" \u2014 "),bJ=a("a"),vdr=o("EsmForSequenceClassification"),Fdr=o(" (ESM model)"),Tdr=l(),$T=a("li"),vEe=a("strong"),Mdr=o("flaubert"),Edr=o(" \u2014 "),vJ=a("a"),Cdr=o("FlaubertForSequenceClassification"),wdr=o(" (FlauBERT model)"),Adr=l(),kT=a("li"),FEe=a("strong"),Ldr=o("fnet"),ydr=o(" \u2014 "),FJ=a("a"),xdr=o("FNetForSequenceClassification"),$dr=o(" (FNet model)"),kdr=l(),ST=a("li"),TEe=a("strong"),Sdr=o("funnel"),Rdr=o(" \u2014 "),TJ=a("a"),Pdr=o("FunnelForSequenceClassification"),Bdr=o(" (Funnel Transformer model)"),Idr=l(),RT=a("li"),MEe=a("strong"),Ndr=o("gpt2"),qdr=o(" \u2014 "),MJ=a("a"),Ddr=o("GPT2ForSequenceClassification"),jdr=o(" (OpenAI GPT-2 model)"),Gdr=l(),PT=a("li"),EEe=a("strong"),Odr=o("gpt_neo"),Vdr=o(" \u2014 "),EJ=a("a"),Xdr=o("GPTNeoForSequenceClassification"),zdr=o(" (GPT Neo model)"),Qdr=l(),BT=a("li"),CEe=a("strong"),Wdr=o("gptj"),Udr=o(" \u2014 "),CJ=a("a"),Hdr=o("GPTJForSequenceClassification"),Jdr=o(" (GPT-J model)"),Ydr=l(),IT=a("li"),wEe=a("strong"),Zdr=o("ibert"),Kdr=o(" \u2014 "),wJ=a("a"),emr=o("IBertForSequenceClassification"),omr=o(" (I-BERT model)"),rmr=l(),NT=a("li"),AEe=a("strong"),tmr=o("layoutlm"),amr=o(" \u2014 "),AJ=a("a"),nmr=o("LayoutLMForSequenceClassification"),smr=o(" (LayoutLM model)"),lmr=l(),qT=a("li"),LEe=a("strong"),imr=o("layoutlmv2"),dmr=o(" \u2014 "),LJ=a("a"),mmr=o("LayoutLMv2ForSequenceClassification"),cmr=o(" (LayoutLMv2 model)"),fmr=l(),DT=a("li"),yEe=a("strong"),gmr=o("layoutlmv3"),hmr=o(" \u2014 "),yJ=a("a"),umr=o("LayoutLMv3ForSequenceClassification"),pmr=o(" (LayoutLMv3 model)"),_mr=l(),jT=a("li"),xEe=a("strong"),bmr=o("led"),vmr=o(" \u2014 "),xJ=a("a"),Fmr=o("LEDForSequenceClassification"),Tmr=o(" (LED model)"),Mmr=l(),GT=a("li"),$Ee=a("strong"),Emr=o("lilt"),Cmr=o(" \u2014 "),$J=a("a"),wmr=o("LiltForSequenceClassification"),Amr=o(" (LiLT model)"),Lmr=l(),OT=a("li"),kEe=a("strong"),ymr=o("longformer"),xmr=o(" \u2014 "),kJ=a("a"),$mr=o("LongformerForSequenceClassification"),kmr=o(" (Longformer model)"),Smr=l(),VT=a("li"),SEe=a("strong"),Rmr=o("luke"),Pmr=o(" \u2014 "),SJ=a("a"),Bmr=o("LukeForSequenceClassification"),Imr=o(" (LUKE model)"),Nmr=l(),XT=a("li"),REe=a("strong"),qmr=o("markuplm"),Dmr=o(" \u2014 "),RJ=a("a"),jmr=o("MarkupLMForSequenceClassification"),Gmr=o(" (MarkupLM model)"),Omr=l(),zT=a("li"),PEe=a("strong"),Vmr=o("mbart"),Xmr=o(" \u2014 "),PJ=a("a"),zmr=o("MBartForSequenceClassification"),Qmr=o(" (mBART model)"),Wmr=l(),QT=a("li"),BEe=a("strong"),Umr=o("megatron-bert"),Hmr=o(" \u2014 "),BJ=a("a"),Jmr=o("MegatronBertForSequenceClassification"),Ymr=o(" (Megatron-BERT model)"),Zmr=l(),WT=a("li"),IEe=a("strong"),Kmr=o("mobilebert"),ecr=o(" \u2014 "),IJ=a("a"),ocr=o("MobileBertForSequenceClassification"),rcr=o(" (MobileBERT model)"),tcr=l(),UT=a("li"),NEe=a("strong"),acr=o("mpnet"),ncr=o(" \u2014 "),NJ=a("a"),scr=o("MPNetForSequenceClassification"),lcr=o(" (MPNet model)"),icr=l(),HT=a("li"),qEe=a("strong"),dcr=o("mvp"),mcr=o(" \u2014 "),qJ=a("a"),ccr=o("MvpForSequenceClassification"),fcr=o(" (MVP model)"),gcr=l(),JT=a("li"),DEe=a("strong"),hcr=o("nezha"),ucr=o(" \u2014 "),DJ=a("a"),pcr=o("NezhaForSequenceClassification"),_cr=o(" (Nezha model)"),bcr=l(),YT=a("li"),jEe=a("strong"),vcr=o("nystromformer"),Fcr=o(" \u2014 "),jJ=a("a"),Tcr=o("NystromformerForSequenceClassification"),Mcr=o(" (Nystr\xF6mformer model)"),Ecr=l(),ZT=a("li"),GEe=a("strong"),Ccr=o("openai-gpt"),wcr=o(" \u2014 "),GJ=a("a"),Acr=o("OpenAIGPTForSequenceClassification"),Lcr=o(" (OpenAI GPT model)"),ycr=l(),KT=a("li"),OEe=a("strong"),xcr=o("opt"),$cr=o(" \u2014 "),OJ=a("a"),kcr=o("OPTForSequenceClassification"),Scr=o(" (OPT model)"),Rcr=l(),eM=a("li"),VEe=a("strong"),Pcr=o("perceiver"),Bcr=o(" \u2014 "),VJ=a("a"),Icr=o("PerceiverForSequenceClassification"),Ncr=o(" (Perceiver model)"),qcr=l(),oM=a("li"),XEe=a("strong"),Dcr=o("plbart"),jcr=o(" \u2014 "),XJ=a("a"),Gcr=o("PLBartForSequenceClassification"),Ocr=o(" (PLBart model)"),Vcr=l(),rM=a("li"),zEe=a("strong"),Xcr=o("qdqbert"),zcr=o(" \u2014 "),zJ=a("a"),Qcr=o("QDQBertForSequenceClassification"),Wcr=o(" (QDQBert model)"),Ucr=l(),tM=a("li"),QEe=a("strong"),Hcr=o("reformer"),Jcr=o(" \u2014 "),QJ=a("a"),Ycr=o("ReformerForSequenceClassification"),Zcr=o(" (Reformer model)"),Kcr=l(),aM=a("li"),WEe=a("strong"),efr=o("rembert"),ofr=o(" \u2014 "),WJ=a("a"),rfr=o("RemBertForSequenceClassification"),tfr=o(" (RemBERT model)"),afr=l(),nM=a("li"),UEe=a("strong"),nfr=o("roberta"),sfr=o(" \u2014 "),UJ=a("a"),lfr=o("RobertaForSequenceClassification"),ifr=o(" (RoBERTa model)"),dfr=l(),sM=a("li"),HEe=a("strong"),mfr=o("roformer"),cfr=o(" \u2014 "),HJ=a("a"),ffr=o("RoFormerForSequenceClassification"),gfr=o(" (RoFormer model)"),hfr=l(),lM=a("li"),JEe=a("strong"),ufr=o("squeezebert"),pfr=o(" \u2014 "),JJ=a("a"),_fr=o("SqueezeBertForSequenceClassification"),bfr=o(" (SqueezeBERT model)"),vfr=l(),iM=a("li"),YEe=a("strong"),Ffr=o("tapas"),Tfr=o(" \u2014 "),YJ=a("a"),Mfr=o("TapasForSequenceClassification"),Efr=o(" (TAPAS model)"),Cfr=l(),dM=a("li"),ZEe=a("strong"),wfr=o("transfo-xl"),Afr=o(" \u2014 "),ZJ=a("a"),Lfr=o("TransfoXLForSequenceClassification"),yfr=o(" (Transformer-XL model)"),xfr=l(),mM=a("li"),KEe=a("strong"),$fr=o("xlm"),kfr=o(" \u2014 "),KJ=a("a"),Sfr=o("XLMForSequenceClassification"),Rfr=o(" (XLM model)"),Pfr=l(),cM=a("li"),e4e=a("strong"),Bfr=o("xlm-roberta"),Ifr=o(" \u2014 "),eY=a("a"),Nfr=o("XLMRobertaForSequenceClassification"),qfr=o(" (XLM-RoBERTa model)"),Dfr=l(),fM=a("li"),o4e=a("strong"),jfr=o("xlm-roberta-xl"),Gfr=o(" \u2014 "),oY=a("a"),Ofr=o("XLMRobertaXLForSequenceClassification"),Vfr=o(" (XLM-RoBERTa-XL model)"),Xfr=l(),gM=a("li"),r4e=a("strong"),zfr=o("xlnet"),Qfr=o(" \u2014 "),rY=a("a"),Wfr=o("XLNetForSequenceClassification"),Ufr=o(" (XLNet model)"),Hfr=l(),hM=a("li"),t4e=a("strong"),Jfr=o("yoso"),Yfr=o(" \u2014 "),tY=a("a"),Zfr=o("YosoForSequenceClassification"),Kfr=o(" (YOSO model)"),egr=l(),uM=a("p"),ogr=o("The model is set in evaluation mode by default using "),a4e=a("code"),rgr=o("model.eval()"),tgr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),n4e=a("code"),agr=o("model.train()"),ngr=l(),F(pM.$$.fragment),Yto=l(),Zd=a("h2"),_M=a("a"),s4e=a("span"),F(_k.$$.fragment),sgr=l(),l4e=a("span"),lgr=o("AutoModelForMultipleChoice"),Zto=l(),Vo=a("div"),F(bk.$$.fragment),igr=l(),Kd=a("p"),dgr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),aY=a("a"),mgr=o("from_pretrained()"),cgr=o(" class method or the "),nY=a("a"),fgr=o("from_config()"),ggr=o(` class
method.`),hgr=l(),vk=a("p"),ugr=o("This class cannot be instantiated directly using "),i4e=a("code"),pgr=o("__init__()"),_gr=o(" (throws an error)."),bgr=l(),xt=a("div"),F(Fk.$$.fragment),vgr=l(),d4e=a("p"),Fgr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Tgr=l(),em=a("p"),Mgr=o(`Note:
Loading a model from its configuration file does `),m4e=a("strong"),Egr=o("not"),Cgr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sY=a("a"),wgr=o("from_pretrained()"),Agr=o(" to load the model weights."),Lgr=l(),F(bM.$$.fragment),ygr=l(),so=a("div"),F(Tk.$$.fragment),xgr=l(),c4e=a("p"),$gr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),kgr=l(),gn=a("p"),Sgr=o("The model class to instantiate is selected based on the "),f4e=a("code"),Rgr=o("model_type"),Pgr=o(` property of the config object (either
passed as an argument or loaded from `),g4e=a("code"),Bgr=o("pretrained_model_name_or_path"),Igr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h4e=a("code"),Ngr=o("pretrained_model_name_or_path"),qgr=o(":"),Dgr=l(),K=a("ul"),vM=a("li"),u4e=a("strong"),jgr=o("albert"),Ggr=o(" \u2014 "),lY=a("a"),Ogr=o("AlbertForMultipleChoice"),Vgr=o(" (ALBERT model)"),Xgr=l(),FM=a("li"),p4e=a("strong"),zgr=o("bert"),Qgr=o(" \u2014 "),iY=a("a"),Wgr=o("BertForMultipleChoice"),Ugr=o(" (BERT model)"),Hgr=l(),TM=a("li"),_4e=a("strong"),Jgr=o("big_bird"),Ygr=o(" \u2014 "),dY=a("a"),Zgr=o("BigBirdForMultipleChoice"),Kgr=o(" (BigBird model)"),ehr=l(),MM=a("li"),b4e=a("strong"),ohr=o("camembert"),rhr=o(" \u2014 "),mY=a("a"),thr=o("CamembertForMultipleChoice"),ahr=o(" (CamemBERT model)"),nhr=l(),EM=a("li"),v4e=a("strong"),shr=o("canine"),lhr=o(" \u2014 "),cY=a("a"),ihr=o("CanineForMultipleChoice"),dhr=o(" (CANINE model)"),mhr=l(),CM=a("li"),F4e=a("strong"),chr=o("convbert"),fhr=o(" \u2014 "),fY=a("a"),ghr=o("ConvBertForMultipleChoice"),hhr=o(" (ConvBERT model)"),uhr=l(),wM=a("li"),T4e=a("strong"),phr=o("data2vec-text"),_hr=o(" \u2014 "),gY=a("a"),bhr=o("Data2VecTextForMultipleChoice"),vhr=o(" (Data2VecText model)"),Fhr=l(),AM=a("li"),M4e=a("strong"),Thr=o("deberta-v2"),Mhr=o(" \u2014 "),hY=a("a"),Ehr=o("DebertaV2ForMultipleChoice"),Chr=o(" (DeBERTa-v2 model)"),whr=l(),LM=a("li"),E4e=a("strong"),Ahr=o("distilbert"),Lhr=o(" \u2014 "),uY=a("a"),yhr=o("DistilBertForMultipleChoice"),xhr=o(" (DistilBERT model)"),$hr=l(),yM=a("li"),C4e=a("strong"),khr=o("electra"),Shr=o(" \u2014 "),pY=a("a"),Rhr=o("ElectraForMultipleChoice"),Phr=o(" (ELECTRA model)"),Bhr=l(),xM=a("li"),w4e=a("strong"),Ihr=o("ernie"),Nhr=o(" \u2014 "),_Y=a("a"),qhr=o("ErnieForMultipleChoice"),Dhr=o(" (ERNIE model)"),jhr=l(),$M=a("li"),A4e=a("strong"),Ghr=o("flaubert"),Ohr=o(" \u2014 "),bY=a("a"),Vhr=o("FlaubertForMultipleChoice"),Xhr=o(" (FlauBERT model)"),zhr=l(),kM=a("li"),L4e=a("strong"),Qhr=o("fnet"),Whr=o(" \u2014 "),vY=a("a"),Uhr=o("FNetForMultipleChoice"),Hhr=o(" (FNet model)"),Jhr=l(),SM=a("li"),y4e=a("strong"),Yhr=o("funnel"),Zhr=o(" \u2014 "),FY=a("a"),Khr=o("FunnelForMultipleChoice"),eur=o(" (Funnel Transformer model)"),our=l(),RM=a("li"),x4e=a("strong"),rur=o("ibert"),tur=o(" \u2014 "),TY=a("a"),aur=o("IBertForMultipleChoice"),nur=o(" (I-BERT model)"),sur=l(),PM=a("li"),$4e=a("strong"),lur=o("longformer"),iur=o(" \u2014 "),MY=a("a"),dur=o("LongformerForMultipleChoice"),mur=o(" (Longformer model)"),cur=l(),BM=a("li"),k4e=a("strong"),fur=o("luke"),gur=o(" \u2014 "),EY=a("a"),hur=o("LukeForMultipleChoice"),uur=o(" (LUKE model)"),pur=l(),IM=a("li"),S4e=a("strong"),_ur=o("megatron-bert"),bur=o(" \u2014 "),CY=a("a"),vur=o("MegatronBertForMultipleChoice"),Fur=o(" (Megatron-BERT model)"),Tur=l(),NM=a("li"),R4e=a("strong"),Mur=o("mobilebert"),Eur=o(" \u2014 "),wY=a("a"),Cur=o("MobileBertForMultipleChoice"),wur=o(" (MobileBERT model)"),Aur=l(),qM=a("li"),P4e=a("strong"),Lur=o("mpnet"),yur=o(" \u2014 "),AY=a("a"),xur=o("MPNetForMultipleChoice"),$ur=o(" (MPNet model)"),kur=l(),DM=a("li"),B4e=a("strong"),Sur=o("nezha"),Rur=o(" \u2014 "),LY=a("a"),Pur=o("NezhaForMultipleChoice"),Bur=o(" (Nezha model)"),Iur=l(),jM=a("li"),I4e=a("strong"),Nur=o("nystromformer"),qur=o(" \u2014 "),yY=a("a"),Dur=o("NystromformerForMultipleChoice"),jur=o(" (Nystr\xF6mformer model)"),Gur=l(),GM=a("li"),N4e=a("strong"),Our=o("qdqbert"),Vur=o(" \u2014 "),xY=a("a"),Xur=o("QDQBertForMultipleChoice"),zur=o(" (QDQBert model)"),Qur=l(),OM=a("li"),q4e=a("strong"),Wur=o("rembert"),Uur=o(" \u2014 "),$Y=a("a"),Hur=o("RemBertForMultipleChoice"),Jur=o(" (RemBERT model)"),Yur=l(),VM=a("li"),D4e=a("strong"),Zur=o("roberta"),Kur=o(" \u2014 "),kY=a("a"),epr=o("RobertaForMultipleChoice"),opr=o(" (RoBERTa model)"),rpr=l(),XM=a("li"),j4e=a("strong"),tpr=o("roformer"),apr=o(" \u2014 "),SY=a("a"),npr=o("RoFormerForMultipleChoice"),spr=o(" (RoFormer model)"),lpr=l(),zM=a("li"),G4e=a("strong"),ipr=o("squeezebert"),dpr=o(" \u2014 "),RY=a("a"),mpr=o("SqueezeBertForMultipleChoice"),cpr=o(" (SqueezeBERT model)"),fpr=l(),QM=a("li"),O4e=a("strong"),gpr=o("xlm"),hpr=o(" \u2014 "),PY=a("a"),upr=o("XLMForMultipleChoice"),ppr=o(" (XLM model)"),_pr=l(),WM=a("li"),V4e=a("strong"),bpr=o("xlm-roberta"),vpr=o(" \u2014 "),BY=a("a"),Fpr=o("XLMRobertaForMultipleChoice"),Tpr=o(" (XLM-RoBERTa model)"),Mpr=l(),UM=a("li"),X4e=a("strong"),Epr=o("xlm-roberta-xl"),Cpr=o(" \u2014 "),IY=a("a"),wpr=o("XLMRobertaXLForMultipleChoice"),Apr=o(" (XLM-RoBERTa-XL model)"),Lpr=l(),HM=a("li"),z4e=a("strong"),ypr=o("xlnet"),xpr=o(" \u2014 "),NY=a("a"),$pr=o("XLNetForMultipleChoice"),kpr=o(" (XLNet model)"),Spr=l(),JM=a("li"),Q4e=a("strong"),Rpr=o("yoso"),Ppr=o(" \u2014 "),qY=a("a"),Bpr=o("YosoForMultipleChoice"),Ipr=o(" (YOSO model)"),Npr=l(),YM=a("p"),qpr=o("The model is set in evaluation mode by default using "),W4e=a("code"),Dpr=o("model.eval()"),jpr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),U4e=a("code"),Gpr=o("model.train()"),Opr=l(),F(ZM.$$.fragment),Kto=l(),om=a("h2"),KM=a("a"),H4e=a("span"),F(Mk.$$.fragment),Vpr=l(),J4e=a("span"),Xpr=o("AutoModelForNextSentencePrediction"),eao=l(),Xo=a("div"),F(Ek.$$.fragment),zpr=l(),rm=a("p"),Qpr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),DY=a("a"),Wpr=o("from_pretrained()"),Upr=o(" class method or the "),jY=a("a"),Hpr=o("from_config()"),Jpr=o(` class
method.`),Ypr=l(),Ck=a("p"),Zpr=o("This class cannot be instantiated directly using "),Y4e=a("code"),Kpr=o("__init__()"),e_r=o(" (throws an error)."),o_r=l(),$t=a("div"),F(wk.$$.fragment),r_r=l(),Z4e=a("p"),t_r=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),a_r=l(),tm=a("p"),n_r=o(`Note:
Loading a model from its configuration file does `),K4e=a("strong"),s_r=o("not"),l_r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),GY=a("a"),i_r=o("from_pretrained()"),d_r=o(" to load the model weights."),m_r=l(),F(eE.$$.fragment),c_r=l(),lo=a("div"),F(Ak.$$.fragment),f_r=l(),eCe=a("p"),g_r=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),h_r=l(),hn=a("p"),u_r=o("The model class to instantiate is selected based on the "),oCe=a("code"),p_r=o("model_type"),__r=o(` property of the config object (either
passed as an argument or loaded from `),rCe=a("code"),b_r=o("pretrained_model_name_or_path"),v_r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tCe=a("code"),F_r=o("pretrained_model_name_or_path"),T_r=o(":"),M_r=l(),Ue=a("ul"),oE=a("li"),aCe=a("strong"),E_r=o("bert"),C_r=o(" \u2014 "),OY=a("a"),w_r=o("BertForNextSentencePrediction"),A_r=o(" (BERT model)"),L_r=l(),rE=a("li"),nCe=a("strong"),y_r=o("ernie"),x_r=o(" \u2014 "),VY=a("a"),$_r=o("ErnieForNextSentencePrediction"),k_r=o(" (ERNIE model)"),S_r=l(),tE=a("li"),sCe=a("strong"),R_r=o("fnet"),P_r=o(" \u2014 "),XY=a("a"),B_r=o("FNetForNextSentencePrediction"),I_r=o(" (FNet model)"),N_r=l(),aE=a("li"),lCe=a("strong"),q_r=o("megatron-bert"),D_r=o(" \u2014 "),zY=a("a"),j_r=o("MegatronBertForNextSentencePrediction"),G_r=o(" (Megatron-BERT model)"),O_r=l(),nE=a("li"),iCe=a("strong"),V_r=o("mobilebert"),X_r=o(" \u2014 "),QY=a("a"),z_r=o("MobileBertForNextSentencePrediction"),Q_r=o(" (MobileBERT model)"),W_r=l(),sE=a("li"),dCe=a("strong"),U_r=o("nezha"),H_r=o(" \u2014 "),WY=a("a"),J_r=o("NezhaForNextSentencePrediction"),Y_r=o(" (Nezha model)"),Z_r=l(),lE=a("li"),mCe=a("strong"),K_r=o("qdqbert"),e1r=o(" \u2014 "),UY=a("a"),o1r=o("QDQBertForNextSentencePrediction"),r1r=o(" (QDQBert model)"),t1r=l(),iE=a("p"),a1r=o("The model is set in evaluation mode by default using "),cCe=a("code"),n1r=o("model.eval()"),s1r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),fCe=a("code"),l1r=o("model.train()"),i1r=l(),F(dE.$$.fragment),oao=l(),am=a("h2"),mE=a("a"),gCe=a("span"),F(Lk.$$.fragment),d1r=l(),hCe=a("span"),m1r=o("AutoModelForTokenClassification"),rao=l(),zo=a("div"),F(yk.$$.fragment),c1r=l(),nm=a("p"),f1r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),HY=a("a"),g1r=o("from_pretrained()"),h1r=o(" class method or the "),JY=a("a"),u1r=o("from_config()"),p1r=o(` class
method.`),_1r=l(),xk=a("p"),b1r=o("This class cannot be instantiated directly using "),uCe=a("code"),v1r=o("__init__()"),F1r=o(" (throws an error)."),T1r=l(),kt=a("div"),F($k.$$.fragment),M1r=l(),pCe=a("p"),E1r=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),C1r=l(),sm=a("p"),w1r=o(`Note:
Loading a model from its configuration file does `),_Ce=a("strong"),A1r=o("not"),L1r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YY=a("a"),y1r=o("from_pretrained()"),x1r=o(" to load the model weights."),$1r=l(),F(cE.$$.fragment),k1r=l(),io=a("div"),F(kk.$$.fragment),S1r=l(),bCe=a("p"),R1r=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),P1r=l(),un=a("p"),B1r=o("The model class to instantiate is selected based on the "),vCe=a("code"),I1r=o("model_type"),N1r=o(` property of the config object (either
passed as an argument or loaded from `),FCe=a("code"),q1r=o("pretrained_model_name_or_path"),D1r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TCe=a("code"),j1r=o("pretrained_model_name_or_path"),G1r=o(":"),O1r=l(),U=a("ul"),fE=a("li"),MCe=a("strong"),V1r=o("albert"),X1r=o(" \u2014 "),ZY=a("a"),z1r=o("AlbertForTokenClassification"),Q1r=o(" (ALBERT model)"),W1r=l(),gE=a("li"),ECe=a("strong"),U1r=o("bert"),H1r=o(" \u2014 "),KY=a("a"),J1r=o("BertForTokenClassification"),Y1r=o(" (BERT model)"),Z1r=l(),hE=a("li"),CCe=a("strong"),K1r=o("big_bird"),e2r=o(" \u2014 "),eZ=a("a"),o2r=o("BigBirdForTokenClassification"),r2r=o(" (BigBird model)"),t2r=l(),uE=a("li"),wCe=a("strong"),a2r=o("bloom"),n2r=o(" \u2014 "),oZ=a("a"),s2r=o("BloomForTokenClassification"),l2r=o(" (BLOOM model)"),i2r=l(),pE=a("li"),ACe=a("strong"),d2r=o("camembert"),m2r=o(" \u2014 "),rZ=a("a"),c2r=o("CamembertForTokenClassification"),f2r=o(" (CamemBERT model)"),g2r=l(),_E=a("li"),LCe=a("strong"),h2r=o("canine"),u2r=o(" \u2014 "),tZ=a("a"),p2r=o("CanineForTokenClassification"),_2r=o(" (CANINE model)"),b2r=l(),bE=a("li"),yCe=a("strong"),v2r=o("convbert"),F2r=o(" \u2014 "),aZ=a("a"),T2r=o("ConvBertForTokenClassification"),M2r=o(" (ConvBERT model)"),E2r=l(),vE=a("li"),xCe=a("strong"),C2r=o("data2vec-text"),w2r=o(" \u2014 "),nZ=a("a"),A2r=o("Data2VecTextForTokenClassification"),L2r=o(" (Data2VecText model)"),y2r=l(),FE=a("li"),$Ce=a("strong"),x2r=o("deberta"),$2r=o(" \u2014 "),sZ=a("a"),k2r=o("DebertaForTokenClassification"),S2r=o(" (DeBERTa model)"),R2r=l(),TE=a("li"),kCe=a("strong"),P2r=o("deberta-v2"),B2r=o(" \u2014 "),lZ=a("a"),I2r=o("DebertaV2ForTokenClassification"),N2r=o(" (DeBERTa-v2 model)"),q2r=l(),ME=a("li"),SCe=a("strong"),D2r=o("distilbert"),j2r=o(" \u2014 "),iZ=a("a"),G2r=o("DistilBertForTokenClassification"),O2r=o(" (DistilBERT model)"),V2r=l(),EE=a("li"),RCe=a("strong"),X2r=o("electra"),z2r=o(" \u2014 "),dZ=a("a"),Q2r=o("ElectraForTokenClassification"),W2r=o(" (ELECTRA model)"),U2r=l(),CE=a("li"),PCe=a("strong"),H2r=o("ernie"),J2r=o(" \u2014 "),mZ=a("a"),Y2r=o("ErnieForTokenClassification"),Z2r=o(" (ERNIE model)"),K2r=l(),wE=a("li"),BCe=a("strong"),ebr=o("esm"),obr=o(" \u2014 "),cZ=a("a"),rbr=o("EsmForTokenClassification"),tbr=o(" (ESM model)"),abr=l(),AE=a("li"),ICe=a("strong"),nbr=o("flaubert"),sbr=o(" \u2014 "),fZ=a("a"),lbr=o("FlaubertForTokenClassification"),ibr=o(" (FlauBERT model)"),dbr=l(),LE=a("li"),NCe=a("strong"),mbr=o("fnet"),cbr=o(" \u2014 "),gZ=a("a"),fbr=o("FNetForTokenClassification"),gbr=o(" (FNet model)"),hbr=l(),yE=a("li"),qCe=a("strong"),ubr=o("funnel"),pbr=o(" \u2014 "),hZ=a("a"),_br=o("FunnelForTokenClassification"),bbr=o(" (Funnel Transformer model)"),vbr=l(),xE=a("li"),DCe=a("strong"),Fbr=o("gpt2"),Tbr=o(" \u2014 "),uZ=a("a"),Mbr=o("GPT2ForTokenClassification"),Ebr=o(" (OpenAI GPT-2 model)"),Cbr=l(),$E=a("li"),jCe=a("strong"),wbr=o("ibert"),Abr=o(" \u2014 "),pZ=a("a"),Lbr=o("IBertForTokenClassification"),ybr=o(" (I-BERT model)"),xbr=l(),kE=a("li"),GCe=a("strong"),$br=o("layoutlm"),kbr=o(" \u2014 "),_Z=a("a"),Sbr=o("LayoutLMForTokenClassification"),Rbr=o(" (LayoutLM model)"),Pbr=l(),SE=a("li"),OCe=a("strong"),Bbr=o("layoutlmv2"),Ibr=o(" \u2014 "),bZ=a("a"),Nbr=o("LayoutLMv2ForTokenClassification"),qbr=o(" (LayoutLMv2 model)"),Dbr=l(),RE=a("li"),VCe=a("strong"),jbr=o("layoutlmv3"),Gbr=o(" \u2014 "),vZ=a("a"),Obr=o("LayoutLMv3ForTokenClassification"),Vbr=o(" (LayoutLMv3 model)"),Xbr=l(),PE=a("li"),XCe=a("strong"),zbr=o("lilt"),Qbr=o(" \u2014 "),FZ=a("a"),Wbr=o("LiltForTokenClassification"),Ubr=o(" (LiLT model)"),Hbr=l(),BE=a("li"),zCe=a("strong"),Jbr=o("longformer"),Ybr=o(" \u2014 "),TZ=a("a"),Zbr=o("LongformerForTokenClassification"),Kbr=o(" (Longformer model)"),evr=l(),IE=a("li"),QCe=a("strong"),ovr=o("luke"),rvr=o(" \u2014 "),MZ=a("a"),tvr=o("LukeForTokenClassification"),avr=o(" (LUKE model)"),nvr=l(),NE=a("li"),WCe=a("strong"),svr=o("markuplm"),lvr=o(" \u2014 "),EZ=a("a"),ivr=o("MarkupLMForTokenClassification"),dvr=o(" (MarkupLM model)"),mvr=l(),qE=a("li"),UCe=a("strong"),cvr=o("megatron-bert"),fvr=o(" \u2014 "),CZ=a("a"),gvr=o("MegatronBertForTokenClassification"),hvr=o(" (Megatron-BERT model)"),uvr=l(),DE=a("li"),HCe=a("strong"),pvr=o("mobilebert"),_vr=o(" \u2014 "),wZ=a("a"),bvr=o("MobileBertForTokenClassification"),vvr=o(" (MobileBERT model)"),Fvr=l(),jE=a("li"),JCe=a("strong"),Tvr=o("mpnet"),Mvr=o(" \u2014 "),AZ=a("a"),Evr=o("MPNetForTokenClassification"),Cvr=o(" (MPNet model)"),wvr=l(),GE=a("li"),YCe=a("strong"),Avr=o("nezha"),Lvr=o(" \u2014 "),LZ=a("a"),yvr=o("NezhaForTokenClassification"),xvr=o(" (Nezha model)"),$vr=l(),OE=a("li"),ZCe=a("strong"),kvr=o("nystromformer"),Svr=o(" \u2014 "),yZ=a("a"),Rvr=o("NystromformerForTokenClassification"),Pvr=o(" (Nystr\xF6mformer model)"),Bvr=l(),VE=a("li"),KCe=a("strong"),Ivr=o("qdqbert"),Nvr=o(" \u2014 "),xZ=a("a"),qvr=o("QDQBertForTokenClassification"),Dvr=o(" (QDQBert model)"),jvr=l(),XE=a("li"),e3e=a("strong"),Gvr=o("rembert"),Ovr=o(" \u2014 "),$Z=a("a"),Vvr=o("RemBertForTokenClassification"),Xvr=o(" (RemBERT model)"),zvr=l(),zE=a("li"),o3e=a("strong"),Qvr=o("roberta"),Wvr=o(" \u2014 "),kZ=a("a"),Uvr=o("RobertaForTokenClassification"),Hvr=o(" (RoBERTa model)"),Jvr=l(),QE=a("li"),r3e=a("strong"),Yvr=o("roformer"),Zvr=o(" \u2014 "),SZ=a("a"),Kvr=o("RoFormerForTokenClassification"),eFr=o(" (RoFormer model)"),oFr=l(),WE=a("li"),t3e=a("strong"),rFr=o("squeezebert"),tFr=o(" \u2014 "),RZ=a("a"),aFr=o("SqueezeBertForTokenClassification"),nFr=o(" (SqueezeBERT model)"),sFr=l(),UE=a("li"),a3e=a("strong"),lFr=o("xlm"),iFr=o(" \u2014 "),PZ=a("a"),dFr=o("XLMForTokenClassification"),mFr=o(" (XLM model)"),cFr=l(),HE=a("li"),n3e=a("strong"),fFr=o("xlm-roberta"),gFr=o(" \u2014 "),BZ=a("a"),hFr=o("XLMRobertaForTokenClassification"),uFr=o(" (XLM-RoBERTa model)"),pFr=l(),JE=a("li"),s3e=a("strong"),_Fr=o("xlm-roberta-xl"),bFr=o(" \u2014 "),IZ=a("a"),vFr=o("XLMRobertaXLForTokenClassification"),FFr=o(" (XLM-RoBERTa-XL model)"),TFr=l(),YE=a("li"),l3e=a("strong"),MFr=o("xlnet"),EFr=o(" \u2014 "),NZ=a("a"),CFr=o("XLNetForTokenClassification"),wFr=o(" (XLNet model)"),AFr=l(),ZE=a("li"),i3e=a("strong"),LFr=o("yoso"),yFr=o(" \u2014 "),qZ=a("a"),xFr=o("YosoForTokenClassification"),$Fr=o(" (YOSO model)"),kFr=l(),KE=a("p"),SFr=o("The model is set in evaluation mode by default using "),d3e=a("code"),RFr=o("model.eval()"),PFr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),m3e=a("code"),BFr=o("model.train()"),IFr=l(),F(e4.$$.fragment),tao=l(),lm=a("h2"),o4=a("a"),c3e=a("span"),F(Sk.$$.fragment),NFr=l(),f3e=a("span"),qFr=o("AutoModelForQuestionAnswering"),aao=l(),Qo=a("div"),F(Rk.$$.fragment),DFr=l(),im=a("p"),jFr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),DZ=a("a"),GFr=o("from_pretrained()"),OFr=o(" class method or the "),jZ=a("a"),VFr=o("from_config()"),XFr=o(` class
method.`),zFr=l(),Pk=a("p"),QFr=o("This class cannot be instantiated directly using "),g3e=a("code"),WFr=o("__init__()"),UFr=o(" (throws an error)."),HFr=l(),St=a("div"),F(Bk.$$.fragment),JFr=l(),h3e=a("p"),YFr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),ZFr=l(),dm=a("p"),KFr=o(`Note:
Loading a model from its configuration file does `),u3e=a("strong"),eTr=o("not"),oTr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),GZ=a("a"),rTr=o("from_pretrained()"),tTr=o(" to load the model weights."),aTr=l(),F(r4.$$.fragment),nTr=l(),mo=a("div"),F(Ik.$$.fragment),sTr=l(),p3e=a("p"),lTr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),iTr=l(),pn=a("p"),dTr=o("The model class to instantiate is selected based on the "),_3e=a("code"),mTr=o("model_type"),cTr=o(` property of the config object (either
passed as an argument or loaded from `),b3e=a("code"),fTr=o("pretrained_model_name_or_path"),gTr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v3e=a("code"),hTr=o("pretrained_model_name_or_path"),uTr=o(":"),pTr=l(),O=a("ul"),t4=a("li"),F3e=a("strong"),_Tr=o("albert"),bTr=o(" \u2014 "),OZ=a("a"),vTr=o("AlbertForQuestionAnswering"),FTr=o(" (ALBERT model)"),TTr=l(),a4=a("li"),T3e=a("strong"),MTr=o("bart"),ETr=o(" \u2014 "),VZ=a("a"),CTr=o("BartForQuestionAnswering"),wTr=o(" (BART model)"),ATr=l(),n4=a("li"),M3e=a("strong"),LTr=o("bert"),yTr=o(" \u2014 "),XZ=a("a"),xTr=o("BertForQuestionAnswering"),$Tr=o(" (BERT model)"),kTr=l(),s4=a("li"),E3e=a("strong"),STr=o("big_bird"),RTr=o(" \u2014 "),zZ=a("a"),PTr=o("BigBirdForQuestionAnswering"),BTr=o(" (BigBird model)"),ITr=l(),l4=a("li"),C3e=a("strong"),NTr=o("bigbird_pegasus"),qTr=o(" \u2014 "),QZ=a("a"),DTr=o("BigBirdPegasusForQuestionAnswering"),jTr=o(" (BigBird-Pegasus model)"),GTr=l(),i4=a("li"),w3e=a("strong"),OTr=o("bloom"),VTr=o(" \u2014 "),WZ=a("a"),XTr=o("BloomForQuestionAnswering"),zTr=o(" (BLOOM model)"),QTr=l(),d4=a("li"),A3e=a("strong"),WTr=o("camembert"),UTr=o(" \u2014 "),UZ=a("a"),HTr=o("CamembertForQuestionAnswering"),JTr=o(" (CamemBERT model)"),YTr=l(),m4=a("li"),L3e=a("strong"),ZTr=o("canine"),KTr=o(" \u2014 "),HZ=a("a"),eMr=o("CanineForQuestionAnswering"),oMr=o(" (CANINE model)"),rMr=l(),c4=a("li"),y3e=a("strong"),tMr=o("convbert"),aMr=o(" \u2014 "),JZ=a("a"),nMr=o("ConvBertForQuestionAnswering"),sMr=o(" (ConvBERT model)"),lMr=l(),f4=a("li"),x3e=a("strong"),iMr=o("data2vec-text"),dMr=o(" \u2014 "),YZ=a("a"),mMr=o("Data2VecTextForQuestionAnswering"),cMr=o(" (Data2VecText model)"),fMr=l(),g4=a("li"),$3e=a("strong"),gMr=o("deberta"),hMr=o(" \u2014 "),ZZ=a("a"),uMr=o("DebertaForQuestionAnswering"),pMr=o(" (DeBERTa model)"),_Mr=l(),h4=a("li"),k3e=a("strong"),bMr=o("deberta-v2"),vMr=o(" \u2014 "),KZ=a("a"),FMr=o("DebertaV2ForQuestionAnswering"),TMr=o(" (DeBERTa-v2 model)"),MMr=l(),u4=a("li"),S3e=a("strong"),EMr=o("distilbert"),CMr=o(" \u2014 "),eK=a("a"),wMr=o("DistilBertForQuestionAnswering"),AMr=o(" (DistilBERT model)"),LMr=l(),p4=a("li"),R3e=a("strong"),yMr=o("electra"),xMr=o(" \u2014 "),oK=a("a"),$Mr=o("ElectraForQuestionAnswering"),kMr=o(" (ELECTRA model)"),SMr=l(),_4=a("li"),P3e=a("strong"),RMr=o("ernie"),PMr=o(" \u2014 "),rK=a("a"),BMr=o("ErnieForQuestionAnswering"),IMr=o(" (ERNIE model)"),NMr=l(),b4=a("li"),B3e=a("strong"),qMr=o("flaubert"),DMr=o(" \u2014 "),tK=a("a"),jMr=o("FlaubertForQuestionAnsweringSimple"),GMr=o(" (FlauBERT model)"),OMr=l(),v4=a("li"),I3e=a("strong"),VMr=o("fnet"),XMr=o(" \u2014 "),aK=a("a"),zMr=o("FNetForQuestionAnswering"),QMr=o(" (FNet model)"),WMr=l(),F4=a("li"),N3e=a("strong"),UMr=o("funnel"),HMr=o(" \u2014 "),nK=a("a"),JMr=o("FunnelForQuestionAnswering"),YMr=o(" (Funnel Transformer model)"),ZMr=l(),T4=a("li"),q3e=a("strong"),KMr=o("gptj"),eEr=o(" \u2014 "),sK=a("a"),oEr=o("GPTJForQuestionAnswering"),rEr=o(" (GPT-J model)"),tEr=l(),M4=a("li"),D3e=a("strong"),aEr=o("ibert"),nEr=o(" \u2014 "),lK=a("a"),sEr=o("IBertForQuestionAnswering"),lEr=o(" (I-BERT model)"),iEr=l(),E4=a("li"),j3e=a("strong"),dEr=o("layoutlmv2"),mEr=o(" \u2014 "),iK=a("a"),cEr=o("LayoutLMv2ForQuestionAnswering"),fEr=o(" (LayoutLMv2 model)"),gEr=l(),C4=a("li"),G3e=a("strong"),hEr=o("layoutlmv3"),uEr=o(" \u2014 "),dK=a("a"),pEr=o("LayoutLMv3ForQuestionAnswering"),_Er=o(" (LayoutLMv3 model)"),bEr=l(),w4=a("li"),O3e=a("strong"),vEr=o("led"),FEr=o(" \u2014 "),mK=a("a"),TEr=o("LEDForQuestionAnswering"),MEr=o(" (LED model)"),EEr=l(),A4=a("li"),V3e=a("strong"),CEr=o("lilt"),wEr=o(" \u2014 "),cK=a("a"),AEr=o("LiltForQuestionAnswering"),LEr=o(" (LiLT model)"),yEr=l(),L4=a("li"),X3e=a("strong"),xEr=o("longformer"),$Er=o(" \u2014 "),fK=a("a"),kEr=o("LongformerForQuestionAnswering"),SEr=o(" (Longformer model)"),REr=l(),y4=a("li"),z3e=a("strong"),PEr=o("luke"),BEr=o(" \u2014 "),gK=a("a"),IEr=o("LukeForQuestionAnswering"),NEr=o(" (LUKE model)"),qEr=l(),x4=a("li"),Q3e=a("strong"),DEr=o("lxmert"),jEr=o(" \u2014 "),hK=a("a"),GEr=o("LxmertForQuestionAnswering"),OEr=o(" (LXMERT model)"),VEr=l(),$4=a("li"),W3e=a("strong"),XEr=o("markuplm"),zEr=o(" \u2014 "),uK=a("a"),QEr=o("MarkupLMForQuestionAnswering"),WEr=o(" (MarkupLM model)"),UEr=l(),k4=a("li"),U3e=a("strong"),HEr=o("mbart"),JEr=o(" \u2014 "),pK=a("a"),YEr=o("MBartForQuestionAnswering"),ZEr=o(" (mBART model)"),KEr=l(),S4=a("li"),H3e=a("strong"),e4r=o("megatron-bert"),o4r=o(" \u2014 "),_K=a("a"),r4r=o("MegatronBertForQuestionAnswering"),t4r=o(" (Megatron-BERT model)"),a4r=l(),R4=a("li"),J3e=a("strong"),n4r=o("mobilebert"),s4r=o(" \u2014 "),bK=a("a"),l4r=o("MobileBertForQuestionAnswering"),i4r=o(" (MobileBERT model)"),d4r=l(),P4=a("li"),Y3e=a("strong"),m4r=o("mpnet"),c4r=o(" \u2014 "),vK=a("a"),f4r=o("MPNetForQuestionAnswering"),g4r=o(" (MPNet model)"),h4r=l(),B4=a("li"),Z3e=a("strong"),u4r=o("mvp"),p4r=o(" \u2014 "),FK=a("a"),_4r=o("MvpForQuestionAnswering"),b4r=o(" (MVP model)"),v4r=l(),I4=a("li"),K3e=a("strong"),F4r=o("nezha"),T4r=o(" \u2014 "),TK=a("a"),M4r=o("NezhaForQuestionAnswering"),E4r=o(" (Nezha model)"),C4r=l(),N4=a("li"),e5e=a("strong"),w4r=o("nystromformer"),A4r=o(" \u2014 "),MK=a("a"),L4r=o("NystromformerForQuestionAnswering"),y4r=o(" (Nystr\xF6mformer model)"),x4r=l(),q4=a("li"),o5e=a("strong"),$4r=o("opt"),k4r=o(" \u2014 "),EK=a("a"),S4r=o("OPTForQuestionAnswering"),R4r=o(" (OPT model)"),P4r=l(),D4=a("li"),r5e=a("strong"),B4r=o("qdqbert"),I4r=o(" \u2014 "),CK=a("a"),N4r=o("QDQBertForQuestionAnswering"),q4r=o(" (QDQBert model)"),D4r=l(),j4=a("li"),t5e=a("strong"),j4r=o("reformer"),G4r=o(" \u2014 "),wK=a("a"),O4r=o("ReformerForQuestionAnswering"),V4r=o(" (Reformer model)"),X4r=l(),G4=a("li"),a5e=a("strong"),z4r=o("rembert"),Q4r=o(" \u2014 "),AK=a("a"),W4r=o("RemBertForQuestionAnswering"),U4r=o(" (RemBERT model)"),H4r=l(),O4=a("li"),n5e=a("strong"),J4r=o("roberta"),Y4r=o(" \u2014 "),LK=a("a"),Z4r=o("RobertaForQuestionAnswering"),K4r=o(" (RoBERTa model)"),eCr=l(),V4=a("li"),s5e=a("strong"),oCr=o("roformer"),rCr=o(" \u2014 "),yK=a("a"),tCr=o("RoFormerForQuestionAnswering"),aCr=o(" (RoFormer model)"),nCr=l(),X4=a("li"),l5e=a("strong"),sCr=o("splinter"),lCr=o(" \u2014 "),xK=a("a"),iCr=o("SplinterForQuestionAnswering"),dCr=o(" (Splinter model)"),mCr=l(),z4=a("li"),i5e=a("strong"),cCr=o("squeezebert"),fCr=o(" \u2014 "),$K=a("a"),gCr=o("SqueezeBertForQuestionAnswering"),hCr=o(" (SqueezeBERT model)"),uCr=l(),Q4=a("li"),d5e=a("strong"),pCr=o("xlm"),_Cr=o(" \u2014 "),kK=a("a"),bCr=o("XLMForQuestionAnsweringSimple"),vCr=o(" (XLM model)"),FCr=l(),W4=a("li"),m5e=a("strong"),TCr=o("xlm-roberta"),MCr=o(" \u2014 "),SK=a("a"),ECr=o("XLMRobertaForQuestionAnswering"),CCr=o(" (XLM-RoBERTa model)"),wCr=l(),U4=a("li"),c5e=a("strong"),ACr=o("xlm-roberta-xl"),LCr=o(" \u2014 "),RK=a("a"),yCr=o("XLMRobertaXLForQuestionAnswering"),xCr=o(" (XLM-RoBERTa-XL model)"),$Cr=l(),H4=a("li"),f5e=a("strong"),kCr=o("xlnet"),SCr=o(" \u2014 "),PK=a("a"),RCr=o("XLNetForQuestionAnsweringSimple"),PCr=o(" (XLNet model)"),BCr=l(),J4=a("li"),g5e=a("strong"),ICr=o("yoso"),NCr=o(" \u2014 "),BK=a("a"),qCr=o("YosoForQuestionAnswering"),DCr=o(" (YOSO model)"),jCr=l(),Y4=a("p"),GCr=o("The model is set in evaluation mode by default using "),h5e=a("code"),OCr=o("model.eval()"),VCr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),u5e=a("code"),XCr=o("model.train()"),zCr=l(),F(Z4.$$.fragment),nao=l(),mm=a("h2"),K4=a("a"),p5e=a("span"),F(Nk.$$.fragment),QCr=l(),_5e=a("span"),WCr=o("AutoModelForTableQuestionAnswering"),sao=l(),Wo=a("div"),F(qk.$$.fragment),UCr=l(),cm=a("p"),HCr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),IK=a("a"),JCr=o("from_pretrained()"),YCr=o(" class method or the "),NK=a("a"),ZCr=o("from_config()"),KCr=o(` class
method.`),e3r=l(),Dk=a("p"),o3r=o("This class cannot be instantiated directly using "),b5e=a("code"),r3r=o("__init__()"),t3r=o(" (throws an error)."),a3r=l(),Rt=a("div"),F(jk.$$.fragment),n3r=l(),v5e=a("p"),s3r=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),l3r=l(),fm=a("p"),i3r=o(`Note:
Loading a model from its configuration file does `),F5e=a("strong"),d3r=o("not"),m3r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qK=a("a"),c3r=o("from_pretrained()"),f3r=o(" to load the model weights."),g3r=l(),F(eC.$$.fragment),h3r=l(),co=a("div"),F(Gk.$$.fragment),u3r=l(),T5e=a("p"),p3r=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),_3r=l(),_n=a("p"),b3r=o("The model class to instantiate is selected based on the "),M5e=a("code"),v3r=o("model_type"),F3r=o(` property of the config object (either
passed as an argument or loaded from `),E5e=a("code"),T3r=o("pretrained_model_name_or_path"),M3r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C5e=a("code"),E3r=o("pretrained_model_name_or_path"),C3r=o(":"),w3r=l(),w5e=a("ul"),oC=a("li"),A5e=a("strong"),A3r=o("tapas"),L3r=o(" \u2014 "),DK=a("a"),y3r=o("TapasForQuestionAnswering"),x3r=o(" (TAPAS model)"),$3r=l(),rC=a("p"),k3r=o("The model is set in evaluation mode by default using "),L5e=a("code"),S3r=o("model.eval()"),R3r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),y5e=a("code"),P3r=o("model.train()"),B3r=l(),F(tC.$$.fragment),lao=l(),gm=a("h2"),aC=a("a"),x5e=a("span"),F(Ok.$$.fragment),I3r=l(),$5e=a("span"),N3r=o("AutoModelForDocumentQuestionAnswering"),iao=l(),Uo=a("div"),F(Vk.$$.fragment),q3r=l(),hm=a("p"),D3r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),jK=a("a"),j3r=o("from_pretrained()"),G3r=o(" class method or the "),GK=a("a"),O3r=o("from_config()"),V3r=o(` class
method.`),X3r=l(),Xk=a("p"),z3r=o("This class cannot be instantiated directly using "),k5e=a("code"),Q3r=o("__init__()"),W3r=o(" (throws an error)."),U3r=l(),Pt=a("div"),F(zk.$$.fragment),H3r=l(),S5e=a("p"),J3r=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),Y3r=l(),um=a("p"),Z3r=o(`Note:
Loading a model from its configuration file does `),R5e=a("strong"),K3r=o("not"),e5r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),OK=a("a"),o5r=o("from_pretrained()"),r5r=o(" to load the model weights."),t5r=l(),F(nC.$$.fragment),a5r=l(),fo=a("div"),F(Qk.$$.fragment),n5r=l(),P5e=a("p"),s5r=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),l5r=l(),bn=a("p"),i5r=o("The model class to instantiate is selected based on the "),B5e=a("code"),d5r=o("model_type"),m5r=o(` property of the config object (either
passed as an argument or loaded from `),I5e=a("code"),c5r=o("pretrained_model_name_or_path"),f5r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N5e=a("code"),g5r=o("pretrained_model_name_or_path"),h5r=o(":"),u5r=l(),pm=a("ul"),sC=a("li"),q5e=a("strong"),p5r=o("layoutlm"),_5r=o(" \u2014 "),VK=a("a"),b5r=o("LayoutLMForQuestionAnswering"),v5r=o(" (LayoutLM model)"),F5r=l(),lC=a("li"),D5e=a("strong"),T5r=o("layoutlmv2"),M5r=o(" \u2014 "),XK=a("a"),E5r=o("LayoutLMv2ForQuestionAnswering"),C5r=o(" (LayoutLMv2 model)"),w5r=l(),iC=a("li"),j5e=a("strong"),A5r=o("layoutlmv3"),L5r=o(" \u2014 "),zK=a("a"),y5r=o("LayoutLMv3ForQuestionAnswering"),x5r=o(" (LayoutLMv3 model)"),$5r=l(),dC=a("p"),k5r=o("The model is set in evaluation mode by default using "),G5e=a("code"),S5r=o("model.eval()"),R5r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),O5e=a("code"),P5r=o("model.train()"),B5r=l(),F(mC.$$.fragment),dao=l(),_m=a("h2"),cC=a("a"),V5e=a("span"),F(Wk.$$.fragment),I5r=l(),X5e=a("span"),N5r=o("AutoModelForImageClassification"),mao=l(),Ho=a("div"),F(Uk.$$.fragment),q5r=l(),bm=a("p"),D5r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),QK=a("a"),j5r=o("from_pretrained()"),G5r=o(" class method or the "),WK=a("a"),O5r=o("from_config()"),V5r=o(` class
method.`),X5r=l(),Hk=a("p"),z5r=o("This class cannot be instantiated directly using "),z5e=a("code"),Q5r=o("__init__()"),W5r=o(" (throws an error)."),U5r=l(),Bt=a("div"),F(Jk.$$.fragment),H5r=l(),Q5e=a("p"),J5r=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Y5r=l(),vm=a("p"),Z5r=o(`Note:
Loading a model from its configuration file does `),W5e=a("strong"),K5r=o("not"),e0r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),UK=a("a"),o0r=o("from_pretrained()"),r0r=o(" to load the model weights."),t0r=l(),F(fC.$$.fragment),a0r=l(),go=a("div"),F(Yk.$$.fragment),n0r=l(),U5e=a("p"),s0r=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),l0r=l(),vn=a("p"),i0r=o("The model class to instantiate is selected based on the "),H5e=a("code"),d0r=o("model_type"),m0r=o(` property of the config object (either
passed as an argument or loaded from `),J5e=a("code"),c0r=o("pretrained_model_name_or_path"),f0r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Y5e=a("code"),g0r=o("pretrained_model_name_or_path"),h0r=o(":"),u0r=l(),be=a("ul"),gC=a("li"),Z5e=a("strong"),p0r=o("beit"),_0r=o(" \u2014 "),HK=a("a"),b0r=o("BeitForImageClassification"),v0r=o(" (BEiT model)"),F0r=l(),hC=a("li"),K5e=a("strong"),T0r=o("convnext"),M0r=o(" \u2014 "),JK=a("a"),E0r=o("ConvNextForImageClassification"),C0r=o(" (ConvNeXT model)"),w0r=l(),uC=a("li"),e0e=a("strong"),A0r=o("cvt"),L0r=o(" \u2014 "),YK=a("a"),y0r=o("CvtForImageClassification"),x0r=o(" (CvT model)"),$0r=l(),pC=a("li"),o0e=a("strong"),k0r=o("data2vec-vision"),S0r=o(" \u2014 "),ZK=a("a"),R0r=o("Data2VecVisionForImageClassification"),P0r=o(" (Data2VecVision model)"),B0r=l(),xl=a("li"),r0e=a("strong"),I0r=o("deit"),N0r=o(" \u2014 "),KK=a("a"),q0r=o("DeiTForImageClassification"),D0r=o(" or "),eee=a("a"),j0r=o("DeiTForImageClassificationWithTeacher"),G0r=o(" (DeiT model)"),O0r=l(),_C=a("li"),t0e=a("strong"),V0r=o("imagegpt"),X0r=o(" \u2014 "),oee=a("a"),z0r=o("ImageGPTForImageClassification"),Q0r=o(" (ImageGPT model)"),W0r=l(),$l=a("li"),a0e=a("strong"),U0r=o("levit"),H0r=o(" \u2014 "),ree=a("a"),J0r=o("LevitForImageClassification"),Y0r=o(" or "),tee=a("a"),Z0r=o("LevitForImageClassificationWithTeacher"),K0r=o(" (LeViT model)"),ewr=l(),bC=a("li"),n0e=a("strong"),owr=o("mobilevit"),rwr=o(" \u2014 "),aee=a("a"),twr=o("MobileViTForImageClassification"),awr=o(" (MobileViT model)"),nwr=l(),It=a("li"),s0e=a("strong"),swr=o("perceiver"),lwr=o(" \u2014 "),nee=a("a"),iwr=o("PerceiverForImageClassificationLearned"),dwr=o(" or "),see=a("a"),mwr=o("PerceiverForImageClassificationFourier"),cwr=o(" or "),lee=a("a"),fwr=o("PerceiverForImageClassificationConvProcessing"),gwr=o(" (Perceiver model)"),hwr=l(),vC=a("li"),l0e=a("strong"),uwr=o("poolformer"),pwr=o(" \u2014 "),iee=a("a"),_wr=o("PoolFormerForImageClassification"),bwr=o(" (PoolFormer model)"),vwr=l(),FC=a("li"),i0e=a("strong"),Fwr=o("regnet"),Twr=o(" \u2014 "),dee=a("a"),Mwr=o("RegNetForImageClassification"),Ewr=o(" (RegNet model)"),Cwr=l(),TC=a("li"),d0e=a("strong"),wwr=o("resnet"),Awr=o(" \u2014 "),mee=a("a"),Lwr=o("ResNetForImageClassification"),ywr=o(" (ResNet model)"),xwr=l(),MC=a("li"),m0e=a("strong"),$wr=o("segformer"),kwr=o(" \u2014 "),cee=a("a"),Swr=o("SegformerForImageClassification"),Rwr=o(" (SegFormer model)"),Pwr=l(),EC=a("li"),c0e=a("strong"),Bwr=o("swin"),Iwr=o(" \u2014 "),fee=a("a"),Nwr=o("SwinForImageClassification"),qwr=o(" (Swin Transformer model)"),Dwr=l(),CC=a("li"),f0e=a("strong"),jwr=o("swinv2"),Gwr=o(" \u2014 "),gee=a("a"),Owr=o("Swinv2ForImageClassification"),Vwr=o(" (Swin Transformer V2 model)"),Xwr=l(),wC=a("li"),g0e=a("strong"),zwr=o("van"),Qwr=o(" \u2014 "),hee=a("a"),Wwr=o("VanForImageClassification"),Uwr=o(" (VAN model)"),Hwr=l(),AC=a("li"),h0e=a("strong"),Jwr=o("vit"),Ywr=o(" \u2014 "),uee=a("a"),Zwr=o("ViTForImageClassification"),Kwr=o(" (ViT model)"),eAr=l(),LC=a("li"),u0e=a("strong"),oAr=o("vit_msn"),rAr=o(" \u2014 "),pee=a("a"),tAr=o("ViTMSNForImageClassification"),aAr=o(" (ViTMSN model)"),nAr=l(),yC=a("p"),sAr=o("The model is set in evaluation mode by default using "),p0e=a("code"),lAr=o("model.eval()"),iAr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_0e=a("code"),dAr=o("model.train()"),mAr=l(),F(xC.$$.fragment),cao=l(),Fm=a("h2"),$C=a("a"),b0e=a("span"),F(Zk.$$.fragment),cAr=l(),v0e=a("span"),fAr=o("AutoModelForVideoClassification"),fao=l(),Jo=a("div"),F(Kk.$$.fragment),gAr=l(),Tm=a("p"),hAr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),_ee=a("a"),uAr=o("from_pretrained()"),pAr=o(" class method or the "),bee=a("a"),_Ar=o("from_config()"),bAr=o(` class
method.`),vAr=l(),eS=a("p"),FAr=o("This class cannot be instantiated directly using "),F0e=a("code"),TAr=o("__init__()"),MAr=o(" (throws an error)."),EAr=l(),Nt=a("div"),F(oS.$$.fragment),CAr=l(),T0e=a("p"),wAr=o("Instantiates one of the model classes of the library (with a video classification head) from a configuration."),AAr=l(),Mm=a("p"),LAr=o(`Note:
Loading a model from its configuration file does `),M0e=a("strong"),yAr=o("not"),xAr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vee=a("a"),$Ar=o("from_pretrained()"),kAr=o(" to load the model weights."),SAr=l(),F(kC.$$.fragment),RAr=l(),ho=a("div"),F(rS.$$.fragment),PAr=l(),E0e=a("p"),BAr=o("Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),IAr=l(),Fn=a("p"),NAr=o("The model class to instantiate is selected based on the "),C0e=a("code"),qAr=o("model_type"),DAr=o(` property of the config object (either
passed as an argument or loaded from `),w0e=a("code"),jAr=o("pretrained_model_name_or_path"),GAr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),A0e=a("code"),OAr=o("pretrained_model_name_or_path"),VAr=o(":"),XAr=l(),L0e=a("ul"),SC=a("li"),y0e=a("strong"),zAr=o("videomae"),QAr=o(" \u2014 "),Fee=a("a"),WAr=o("VideoMAEForVideoClassification"),UAr=o(" (VideoMAE model)"),HAr=l(),RC=a("p"),JAr=o("The model is set in evaluation mode by default using "),x0e=a("code"),YAr=o("model.eval()"),ZAr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$0e=a("code"),KAr=o("model.train()"),e6r=l(),F(PC.$$.fragment),gao=l(),Em=a("h2"),BC=a("a"),k0e=a("span"),F(tS.$$.fragment),o6r=l(),S0e=a("span"),r6r=o("AutoModelForVision2Seq"),hao=l(),Yo=a("div"),F(aS.$$.fragment),t6r=l(),Cm=a("p"),a6r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Tee=a("a"),n6r=o("from_pretrained()"),s6r=o(" class method or the "),Mee=a("a"),l6r=o("from_config()"),i6r=o(` class
method.`),d6r=l(),nS=a("p"),m6r=o("This class cannot be instantiated directly using "),R0e=a("code"),c6r=o("__init__()"),f6r=o(" (throws an error)."),g6r=l(),qt=a("div"),F(sS.$$.fragment),h6r=l(),P0e=a("p"),u6r=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),p6r=l(),wm=a("p"),_6r=o(`Note:
Loading a model from its configuration file does `),B0e=a("strong"),b6r=o("not"),v6r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Eee=a("a"),F6r=o("from_pretrained()"),T6r=o(" to load the model weights."),M6r=l(),F(IC.$$.fragment),E6r=l(),uo=a("div"),F(lS.$$.fragment),C6r=l(),I0e=a("p"),w6r=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),A6r=l(),Tn=a("p"),L6r=o("The model class to instantiate is selected based on the "),N0e=a("code"),y6r=o("model_type"),x6r=o(` property of the config object (either
passed as an argument or loaded from `),q0e=a("code"),$6r=o("pretrained_model_name_or_path"),k6r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),D0e=a("code"),S6r=o("pretrained_model_name_or_path"),R6r=o(":"),P6r=l(),j0e=a("ul"),NC=a("li"),G0e=a("strong"),B6r=o("vision-encoder-decoder"),I6r=o(" \u2014 "),Cee=a("a"),N6r=o("VisionEncoderDecoderModel"),q6r=o(" (Vision Encoder decoder model)"),D6r=l(),qC=a("p"),j6r=o("The model is set in evaluation mode by default using "),O0e=a("code"),G6r=o("model.eval()"),O6r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),V0e=a("code"),V6r=o("model.train()"),X6r=l(),F(DC.$$.fragment),uao=l(),Am=a("h2"),jC=a("a"),X0e=a("span"),F(iS.$$.fragment),z6r=l(),z0e=a("span"),Q6r=o("AutoModelForVisualQuestionAnswering"),pao=l(),Zo=a("div"),F(dS.$$.fragment),W6r=l(),Lm=a("p"),U6r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),wee=a("a"),H6r=o("from_pretrained()"),J6r=o(" class method or the "),Aee=a("a"),Y6r=o("from_config()"),Z6r=o(` class
method.`),K6r=l(),mS=a("p"),e7r=o("This class cannot be instantiated directly using "),Q0e=a("code"),o7r=o("__init__()"),r7r=o(" (throws an error)."),t7r=l(),Dt=a("div"),F(cS.$$.fragment),a7r=l(),W0e=a("p"),n7r=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),s7r=l(),ym=a("p"),l7r=o(`Note:
Loading a model from its configuration file does `),U0e=a("strong"),i7r=o("not"),d7r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Lee=a("a"),m7r=o("from_pretrained()"),c7r=o(" to load the model weights."),f7r=l(),F(GC.$$.fragment),g7r=l(),po=a("div"),F(fS.$$.fragment),h7r=l(),H0e=a("p"),u7r=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),p7r=l(),Mn=a("p"),_7r=o("The model class to instantiate is selected based on the "),J0e=a("code"),b7r=o("model_type"),v7r=o(` property of the config object (either
passed as an argument or loaded from `),Y0e=a("code"),F7r=o("pretrained_model_name_or_path"),T7r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Z0e=a("code"),M7r=o("pretrained_model_name_or_path"),E7r=o(":"),C7r=l(),K0e=a("ul"),OC=a("li"),ewe=a("strong"),w7r=o("vilt"),A7r=o(" \u2014 "),yee=a("a"),L7r=o("ViltForQuestionAnswering"),y7r=o(" (ViLT model)"),x7r=l(),VC=a("p"),$7r=o("The model is set in evaluation mode by default using "),owe=a("code"),k7r=o("model.eval()"),S7r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),rwe=a("code"),R7r=o("model.train()"),P7r=l(),F(XC.$$.fragment),_ao=l(),xm=a("h2"),zC=a("a"),twe=a("span"),F(gS.$$.fragment),B7r=l(),awe=a("span"),I7r=o("AutoModelForAudioClassification"),bao=l(),Ko=a("div"),F(hS.$$.fragment),N7r=l(),$m=a("p"),q7r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),xee=a("a"),D7r=o("from_pretrained()"),j7r=o(" class method or the "),$ee=a("a"),G7r=o("from_config()"),O7r=o(` class
method.`),V7r=l(),uS=a("p"),X7r=o("This class cannot be instantiated directly using "),nwe=a("code"),z7r=o("__init__()"),Q7r=o(" (throws an error)."),W7r=l(),jt=a("div"),F(pS.$$.fragment),U7r=l(),swe=a("p"),H7r=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),J7r=l(),km=a("p"),Y7r=o(`Note:
Loading a model from its configuration file does `),lwe=a("strong"),Z7r=o("not"),K7r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kee=a("a"),e8r=o("from_pretrained()"),o8r=o(" to load the model weights."),r8r=l(),F(QC.$$.fragment),t8r=l(),_o=a("div"),F(_S.$$.fragment),a8r=l(),iwe=a("p"),n8r=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),s8r=l(),En=a("p"),l8r=o("The model class to instantiate is selected based on the "),dwe=a("code"),i8r=o("model_type"),d8r=o(` property of the config object (either
passed as an argument or loaded from `),mwe=a("code"),m8r=o("pretrained_model_name_or_path"),c8r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cwe=a("code"),f8r=o("pretrained_model_name_or_path"),g8r=o(":"),h8r=l(),Be=a("ul"),WC=a("li"),fwe=a("strong"),u8r=o("data2vec-audio"),p8r=o(" \u2014 "),See=a("a"),_8r=o("Data2VecAudioForSequenceClassification"),b8r=o(" (Data2VecAudio model)"),v8r=l(),UC=a("li"),gwe=a("strong"),F8r=o("hubert"),T8r=o(" \u2014 "),Ree=a("a"),M8r=o("HubertForSequenceClassification"),E8r=o(" (Hubert model)"),C8r=l(),HC=a("li"),hwe=a("strong"),w8r=o("sew"),A8r=o(" \u2014 "),Pee=a("a"),L8r=o("SEWForSequenceClassification"),y8r=o(" (SEW model)"),x8r=l(),JC=a("li"),uwe=a("strong"),$8r=o("sew-d"),k8r=o(" \u2014 "),Bee=a("a"),S8r=o("SEWDForSequenceClassification"),R8r=o(" (SEW-D model)"),P8r=l(),YC=a("li"),pwe=a("strong"),B8r=o("unispeech"),I8r=o(" \u2014 "),Iee=a("a"),N8r=o("UniSpeechForSequenceClassification"),q8r=o(" (UniSpeech model)"),D8r=l(),ZC=a("li"),_we=a("strong"),j8r=o("unispeech-sat"),G8r=o(" \u2014 "),Nee=a("a"),O8r=o("UniSpeechSatForSequenceClassification"),V8r=o(" (UniSpeechSat model)"),X8r=l(),KC=a("li"),bwe=a("strong"),z8r=o("wav2vec2"),Q8r=o(" \u2014 "),qee=a("a"),W8r=o("Wav2Vec2ForSequenceClassification"),U8r=o(" (Wav2Vec2 model)"),H8r=l(),e3=a("li"),vwe=a("strong"),J8r=o("wav2vec2-conformer"),Y8r=o(" \u2014 "),Dee=a("a"),Z8r=o("Wav2Vec2ConformerForSequenceClassification"),K8r=o(" (Wav2Vec2-Conformer model)"),eLr=l(),o3=a("li"),Fwe=a("strong"),oLr=o("wavlm"),rLr=o(" \u2014 "),jee=a("a"),tLr=o("WavLMForSequenceClassification"),aLr=o(" (WavLM model)"),nLr=l(),r3=a("p"),sLr=o("The model is set in evaluation mode by default using "),Twe=a("code"),lLr=o("model.eval()"),iLr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Mwe=a("code"),dLr=o("model.train()"),mLr=l(),F(t3.$$.fragment),vao=l(),Sm=a("h2"),a3=a("a"),Ewe=a("span"),F(bS.$$.fragment),cLr=l(),Cwe=a("span"),fLr=o("AutoModelForAudioFrameClassification"),Fao=l(),er=a("div"),F(vS.$$.fragment),gLr=l(),Rm=a("p"),hLr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),Gee=a("a"),uLr=o("from_pretrained()"),pLr=o(" class method or the "),Oee=a("a"),_Lr=o("from_config()"),bLr=o(` class
method.`),vLr=l(),FS=a("p"),FLr=o("This class cannot be instantiated directly using "),wwe=a("code"),TLr=o("__init__()"),MLr=o(" (throws an error)."),ELr=l(),Gt=a("div"),F(TS.$$.fragment),CLr=l(),Awe=a("p"),wLr=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),ALr=l(),Pm=a("p"),LLr=o(`Note:
Loading a model from its configuration file does `),Lwe=a("strong"),yLr=o("not"),xLr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Vee=a("a"),$Lr=o("from_pretrained()"),kLr=o(" to load the model weights."),SLr=l(),F(n3.$$.fragment),RLr=l(),bo=a("div"),F(MS.$$.fragment),PLr=l(),ywe=a("p"),BLr=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),ILr=l(),Cn=a("p"),NLr=o("The model class to instantiate is selected based on the "),xwe=a("code"),qLr=o("model_type"),DLr=o(` property of the config object (either
passed as an argument or loaded from `),$we=a("code"),jLr=o("pretrained_model_name_or_path"),GLr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kwe=a("code"),OLr=o("pretrained_model_name_or_path"),VLr=o(":"),XLr=l(),ut=a("ul"),s3=a("li"),Swe=a("strong"),zLr=o("data2vec-audio"),QLr=o(" \u2014 "),Xee=a("a"),WLr=o("Data2VecAudioForAudioFrameClassification"),ULr=o(" (Data2VecAudio model)"),HLr=l(),l3=a("li"),Rwe=a("strong"),JLr=o("unispeech-sat"),YLr=o(" \u2014 "),zee=a("a"),ZLr=o("UniSpeechSatForAudioFrameClassification"),KLr=o(" (UniSpeechSat model)"),eyr=l(),i3=a("li"),Pwe=a("strong"),oyr=o("wav2vec2"),ryr=o(" \u2014 "),Qee=a("a"),tyr=o("Wav2Vec2ForAudioFrameClassification"),ayr=o(" (Wav2Vec2 model)"),nyr=l(),d3=a("li"),Bwe=a("strong"),syr=o("wav2vec2-conformer"),lyr=o(" \u2014 "),Wee=a("a"),iyr=o("Wav2Vec2ConformerForAudioFrameClassification"),dyr=o(" (Wav2Vec2-Conformer model)"),myr=l(),m3=a("li"),Iwe=a("strong"),cyr=o("wavlm"),fyr=o(" \u2014 "),Uee=a("a"),gyr=o("WavLMForAudioFrameClassification"),hyr=o(" (WavLM model)"),uyr=l(),c3=a("p"),pyr=o("The model is set in evaluation mode by default using "),Nwe=a("code"),_yr=o("model.eval()"),byr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qwe=a("code"),vyr=o("model.train()"),Fyr=l(),F(f3.$$.fragment),Tao=l(),Bm=a("h2"),g3=a("a"),Dwe=a("span"),F(ES.$$.fragment),Tyr=l(),jwe=a("span"),Myr=o("AutoModelForCTC"),Mao=l(),or=a("div"),F(CS.$$.fragment),Eyr=l(),Im=a("p"),Cyr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),Hee=a("a"),wyr=o("from_pretrained()"),Ayr=o(" class method or the "),Jee=a("a"),Lyr=o("from_config()"),yyr=o(` class
method.`),xyr=l(),wS=a("p"),$yr=o("This class cannot be instantiated directly using "),Gwe=a("code"),kyr=o("__init__()"),Syr=o(" (throws an error)."),Ryr=l(),Ot=a("div"),F(AS.$$.fragment),Pyr=l(),Owe=a("p"),Byr=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),Iyr=l(),Nm=a("p"),Nyr=o(`Note:
Loading a model from its configuration file does `),Vwe=a("strong"),qyr=o("not"),Dyr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Yee=a("a"),jyr=o("from_pretrained()"),Gyr=o(" to load the model weights."),Oyr=l(),F(h3.$$.fragment),Vyr=l(),vo=a("div"),F(LS.$$.fragment),Xyr=l(),Xwe=a("p"),zyr=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),Qyr=l(),wn=a("p"),Wyr=o("The model class to instantiate is selected based on the "),zwe=a("code"),Uyr=o("model_type"),Hyr=o(` property of the config object (either
passed as an argument or loaded from `),Qwe=a("code"),Jyr=o("pretrained_model_name_or_path"),Yyr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wwe=a("code"),Zyr=o("pretrained_model_name_or_path"),Kyr=o(":"),e9r=l(),Le=a("ul"),u3=a("li"),Uwe=a("strong"),o9r=o("data2vec-audio"),r9r=o(" \u2014 "),Zee=a("a"),t9r=o("Data2VecAudioForCTC"),a9r=o(" (Data2VecAudio model)"),n9r=l(),p3=a("li"),Hwe=a("strong"),s9r=o("hubert"),l9r=o(" \u2014 "),Kee=a("a"),i9r=o("HubertForCTC"),d9r=o(" (Hubert model)"),m9r=l(),_3=a("li"),Jwe=a("strong"),c9r=o("mctct"),f9r=o(" \u2014 "),eoe=a("a"),g9r=o("MCTCTForCTC"),h9r=o(" (M-CTC-T model)"),u9r=l(),b3=a("li"),Ywe=a("strong"),p9r=o("sew"),_9r=o(" \u2014 "),ooe=a("a"),b9r=o("SEWForCTC"),v9r=o(" (SEW model)"),F9r=l(),v3=a("li"),Zwe=a("strong"),T9r=o("sew-d"),M9r=o(" \u2014 "),roe=a("a"),E9r=o("SEWDForCTC"),C9r=o(" (SEW-D model)"),w9r=l(),F3=a("li"),Kwe=a("strong"),A9r=o("unispeech"),L9r=o(" \u2014 "),toe=a("a"),y9r=o("UniSpeechForCTC"),x9r=o(" (UniSpeech model)"),$9r=l(),T3=a("li"),eAe=a("strong"),k9r=o("unispeech-sat"),S9r=o(" \u2014 "),aoe=a("a"),R9r=o("UniSpeechSatForCTC"),P9r=o(" (UniSpeechSat model)"),B9r=l(),M3=a("li"),oAe=a("strong"),I9r=o("wav2vec2"),N9r=o(" \u2014 "),noe=a("a"),q9r=o("Wav2Vec2ForCTC"),D9r=o(" (Wav2Vec2 model)"),j9r=l(),E3=a("li"),rAe=a("strong"),G9r=o("wav2vec2-conformer"),O9r=o(" \u2014 "),soe=a("a"),V9r=o("Wav2Vec2ConformerForCTC"),X9r=o(" (Wav2Vec2-Conformer model)"),z9r=l(),C3=a("li"),tAe=a("strong"),Q9r=o("wavlm"),W9r=o(" \u2014 "),loe=a("a"),U9r=o("WavLMForCTC"),H9r=o(" (WavLM model)"),J9r=l(),w3=a("p"),Y9r=o("The model is set in evaluation mode by default using "),aAe=a("code"),Z9r=o("model.eval()"),K9r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),nAe=a("code"),exr=o("model.train()"),oxr=l(),F(A3.$$.fragment),Eao=l(),qm=a("h2"),L3=a("a"),sAe=a("span"),F(yS.$$.fragment),rxr=l(),lAe=a("span"),txr=o("AutoModelForSpeechSeq2Seq"),Cao=l(),rr=a("div"),F(xS.$$.fragment),axr=l(),Dm=a("p"),nxr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),ioe=a("a"),sxr=o("from_pretrained()"),lxr=o(" class method or the "),doe=a("a"),ixr=o("from_config()"),dxr=o(` class
method.`),mxr=l(),$S=a("p"),cxr=o("This class cannot be instantiated directly using "),iAe=a("code"),fxr=o("__init__()"),gxr=o(" (throws an error)."),hxr=l(),Vt=a("div"),F(kS.$$.fragment),uxr=l(),dAe=a("p"),pxr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),_xr=l(),jm=a("p"),bxr=o(`Note:
Loading a model from its configuration file does `),mAe=a("strong"),vxr=o("not"),Fxr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),moe=a("a"),Txr=o("from_pretrained()"),Mxr=o(" to load the model weights."),Exr=l(),F(y3.$$.fragment),Cxr=l(),Fo=a("div"),F(SS.$$.fragment),wxr=l(),cAe=a("p"),Axr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Lxr=l(),An=a("p"),yxr=o("The model class to instantiate is selected based on the "),fAe=a("code"),xxr=o("model_type"),$xr=o(` property of the config object (either
passed as an argument or loaded from `),gAe=a("code"),kxr=o("pretrained_model_name_or_path"),Sxr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hAe=a("code"),Rxr=o("pretrained_model_name_or_path"),Pxr=o(":"),Bxr=l(),Gm=a("ul"),x3=a("li"),uAe=a("strong"),Ixr=o("speech-encoder-decoder"),Nxr=o(" \u2014 "),coe=a("a"),qxr=o("SpeechEncoderDecoderModel"),Dxr=o(" (Speech Encoder decoder model)"),jxr=l(),$3=a("li"),pAe=a("strong"),Gxr=o("speech_to_text"),Oxr=o(" \u2014 "),foe=a("a"),Vxr=o("Speech2TextForConditionalGeneration"),Xxr=o(" (Speech2Text model)"),zxr=l(),k3=a("li"),_Ae=a("strong"),Qxr=o("whisper"),Wxr=o(" \u2014 "),goe=a("a"),Uxr=o("WhisperForConditionalGeneration"),Hxr=o(" (Whisper model)"),Jxr=l(),S3=a("p"),Yxr=o("The model is set in evaluation mode by default using "),bAe=a("code"),Zxr=o("model.eval()"),Kxr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),vAe=a("code"),e$r=o("model.train()"),o$r=l(),F(R3.$$.fragment),wao=l(),Om=a("h2"),P3=a("a"),FAe=a("span"),F(RS.$$.fragment),r$r=l(),TAe=a("span"),t$r=o("AutoModelForAudioXVector"),Aao=l(),tr=a("div"),F(PS.$$.fragment),a$r=l(),Vm=a("p"),n$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),hoe=a("a"),s$r=o("from_pretrained()"),l$r=o(" class method or the "),uoe=a("a"),i$r=o("from_config()"),d$r=o(` class
method.`),m$r=l(),BS=a("p"),c$r=o("This class cannot be instantiated directly using "),MAe=a("code"),f$r=o("__init__()"),g$r=o(" (throws an error)."),h$r=l(),Xt=a("div"),F(IS.$$.fragment),u$r=l(),EAe=a("p"),p$r=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),_$r=l(),Xm=a("p"),b$r=o(`Note:
Loading a model from its configuration file does `),CAe=a("strong"),v$r=o("not"),F$r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),poe=a("a"),T$r=o("from_pretrained()"),M$r=o(" to load the model weights."),E$r=l(),F(B3.$$.fragment),C$r=l(),To=a("div"),F(NS.$$.fragment),w$r=l(),wAe=a("p"),A$r=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),L$r=l(),Ln=a("p"),y$r=o("The model class to instantiate is selected based on the "),AAe=a("code"),x$r=o("model_type"),$$r=o(` property of the config object (either
passed as an argument or loaded from `),LAe=a("code"),k$r=o("pretrained_model_name_or_path"),S$r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yAe=a("code"),R$r=o("pretrained_model_name_or_path"),P$r=o(":"),B$r=l(),pt=a("ul"),I3=a("li"),xAe=a("strong"),I$r=o("data2vec-audio"),N$r=o(" \u2014 "),_oe=a("a"),q$r=o("Data2VecAudioForXVector"),D$r=o(" (Data2VecAudio model)"),j$r=l(),N3=a("li"),$Ae=a("strong"),G$r=o("unispeech-sat"),O$r=o(" \u2014 "),boe=a("a"),V$r=o("UniSpeechSatForXVector"),X$r=o(" (UniSpeechSat model)"),z$r=l(),q3=a("li"),kAe=a("strong"),Q$r=o("wav2vec2"),W$r=o(" \u2014 "),voe=a("a"),U$r=o("Wav2Vec2ForXVector"),H$r=o(" (Wav2Vec2 model)"),J$r=l(),D3=a("li"),SAe=a("strong"),Y$r=o("wav2vec2-conformer"),Z$r=o(" \u2014 "),Foe=a("a"),K$r=o("Wav2Vec2ConformerForXVector"),ekr=o(" (Wav2Vec2-Conformer model)"),okr=l(),j3=a("li"),RAe=a("strong"),rkr=o("wavlm"),tkr=o(" \u2014 "),Toe=a("a"),akr=o("WavLMForXVector"),nkr=o(" (WavLM model)"),skr=l(),G3=a("p"),lkr=o("The model is set in evaluation mode by default using "),PAe=a("code"),ikr=o("model.eval()"),dkr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),BAe=a("code"),mkr=o("model.train()"),ckr=l(),F(O3.$$.fragment),Lao=l(),zm=a("h2"),V3=a("a"),IAe=a("span"),F(qS.$$.fragment),fkr=l(),NAe=a("span"),gkr=o("AutoModelForMaskedImageModeling"),yao=l(),ar=a("div"),F(DS.$$.fragment),hkr=l(),Qm=a("p"),ukr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),Moe=a("a"),pkr=o("from_pretrained()"),_kr=o(" class method or the "),Eoe=a("a"),bkr=o("from_config()"),vkr=o(` class
method.`),Fkr=l(),jS=a("p"),Tkr=o("This class cannot be instantiated directly using "),qAe=a("code"),Mkr=o("__init__()"),Ekr=o(" (throws an error)."),Ckr=l(),zt=a("div"),F(GS.$$.fragment),wkr=l(),DAe=a("p"),Akr=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),Lkr=l(),Wm=a("p"),ykr=o(`Note:
Loading a model from its configuration file does `),jAe=a("strong"),xkr=o("not"),$kr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Coe=a("a"),kkr=o("from_pretrained()"),Skr=o(" to load the model weights."),Rkr=l(),F(X3.$$.fragment),Pkr=l(),Mo=a("div"),F(OS.$$.fragment),Bkr=l(),GAe=a("p"),Ikr=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),Nkr=l(),yn=a("p"),qkr=o("The model class to instantiate is selected based on the "),OAe=a("code"),Dkr=o("model_type"),jkr=o(` property of the config object (either
passed as an argument or loaded from `),VAe=a("code"),Gkr=o("pretrained_model_name_or_path"),Okr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),XAe=a("code"),Vkr=o("pretrained_model_name_or_path"),Xkr=o(":"),zkr=l(),xn=a("ul"),z3=a("li"),zAe=a("strong"),Qkr=o("deit"),Wkr=o(" \u2014 "),woe=a("a"),Ukr=o("DeiTForMaskedImageModeling"),Hkr=o(" (DeiT model)"),Jkr=l(),Q3=a("li"),QAe=a("strong"),Ykr=o("swin"),Zkr=o(" \u2014 "),Aoe=a("a"),Kkr=o("SwinForMaskedImageModeling"),eSr=o(" (Swin Transformer model)"),oSr=l(),W3=a("li"),WAe=a("strong"),rSr=o("swinv2"),tSr=o(" \u2014 "),Loe=a("a"),aSr=o("Swinv2ForMaskedImageModeling"),nSr=o(" (Swin Transformer V2 model)"),sSr=l(),U3=a("li"),UAe=a("strong"),lSr=o("vit"),iSr=o(" \u2014 "),yoe=a("a"),dSr=o("ViTForMaskedImageModeling"),mSr=o(" (ViT model)"),cSr=l(),H3=a("p"),fSr=o("The model is set in evaluation mode by default using "),HAe=a("code"),gSr=o("model.eval()"),hSr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),JAe=a("code"),uSr=o("model.train()"),pSr=l(),F(J3.$$.fragment),xao=l(),Um=a("h2"),Y3=a("a"),YAe=a("span"),F(VS.$$.fragment),_Sr=l(),ZAe=a("span"),bSr=o("AutoModelForObjectDetection"),$ao=l(),nr=a("div"),F(XS.$$.fragment),vSr=l(),Hm=a("p"),FSr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),xoe=a("a"),TSr=o("from_pretrained()"),MSr=o(" class method or the "),$oe=a("a"),ESr=o("from_config()"),CSr=o(` class
method.`),wSr=l(),zS=a("p"),ASr=o("This class cannot be instantiated directly using "),KAe=a("code"),LSr=o("__init__()"),ySr=o(" (throws an error)."),xSr=l(),Qt=a("div"),F(QS.$$.fragment),$Sr=l(),e6e=a("p"),kSr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),SSr=l(),Jm=a("p"),RSr=o(`Note:
Loading a model from its configuration file does `),o6e=a("strong"),PSr=o("not"),BSr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),koe=a("a"),ISr=o("from_pretrained()"),NSr=o(" to load the model weights."),qSr=l(),F(Z3.$$.fragment),DSr=l(),Eo=a("div"),F(WS.$$.fragment),jSr=l(),r6e=a("p"),GSr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),OSr=l(),$n=a("p"),VSr=o("The model class to instantiate is selected based on the "),t6e=a("code"),XSr=o("model_type"),zSr=o(` property of the config object (either
passed as an argument or loaded from `),a6e=a("code"),QSr=o("pretrained_model_name_or_path"),WSr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n6e=a("code"),USr=o("pretrained_model_name_or_path"),HSr=o(":"),JSr=l(),_t=a("ul"),K3=a("li"),s6e=a("strong"),YSr=o("conditional_detr"),ZSr=o(" \u2014 "),Soe=a("a"),KSr=o("ConditionalDetrForObjectDetection"),eRr=o(" (Conditional DETR model)"),oRr=l(),e5=a("li"),l6e=a("strong"),rRr=o("deformable_detr"),tRr=o(" \u2014 "),Roe=a("a"),aRr=o("DeformableDetrForObjectDetection"),nRr=o(" (Deformable DETR model)"),sRr=l(),o5=a("li"),i6e=a("strong"),lRr=o("detr"),iRr=o(" \u2014 "),Poe=a("a"),dRr=o("DetrForObjectDetection"),mRr=o(" (DETR model)"),cRr=l(),r5=a("li"),d6e=a("strong"),fRr=o("table-transformer"),gRr=o(" \u2014 "),Boe=a("a"),hRr=o("TableTransformerForObjectDetection"),uRr=o(" (Table Transformer model)"),pRr=l(),t5=a("li"),m6e=a("strong"),_Rr=o("yolos"),bRr=o(" \u2014 "),Ioe=a("a"),vRr=o("YolosForObjectDetection"),FRr=o(" (YOLOS model)"),TRr=l(),a5=a("p"),MRr=o("The model is set in evaluation mode by default using "),c6e=a("code"),ERr=o("model.eval()"),CRr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),f6e=a("code"),wRr=o("model.train()"),ARr=l(),F(n5.$$.fragment),kao=l(),Ym=a("h2"),s5=a("a"),g6e=a("span"),F(US.$$.fragment),LRr=l(),h6e=a("span"),yRr=o("AutoModelForImageSegmentation"),Sao=l(),sr=a("div"),F(HS.$$.fragment),xRr=l(),Zm=a("p"),$Rr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),Noe=a("a"),kRr=o("from_pretrained()"),SRr=o(" class method or the "),qoe=a("a"),RRr=o("from_config()"),PRr=o(` class
method.`),BRr=l(),JS=a("p"),IRr=o("This class cannot be instantiated directly using "),u6e=a("code"),NRr=o("__init__()"),qRr=o(" (throws an error)."),DRr=l(),Wt=a("div"),F(YS.$$.fragment),jRr=l(),p6e=a("p"),GRr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),ORr=l(),Km=a("p"),VRr=o(`Note:
Loading a model from its configuration file does `),_6e=a("strong"),XRr=o("not"),zRr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Doe=a("a"),QRr=o("from_pretrained()"),WRr=o(" to load the model weights."),URr=l(),F(l5.$$.fragment),HRr=l(),Co=a("div"),F(ZS.$$.fragment),JRr=l(),b6e=a("p"),YRr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),ZRr=l(),kn=a("p"),KRr=o("The model class to instantiate is selected based on the "),v6e=a("code"),ePr=o("model_type"),oPr=o(` property of the config object (either
passed as an argument or loaded from `),F6e=a("code"),rPr=o("pretrained_model_name_or_path"),tPr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T6e=a("code"),aPr=o("pretrained_model_name_or_path"),nPr=o(":"),sPr=l(),M6e=a("ul"),i5=a("li"),E6e=a("strong"),lPr=o("detr"),iPr=o(" \u2014 "),joe=a("a"),dPr=o("DetrForSegmentation"),mPr=o(" (DETR model)"),cPr=l(),d5=a("p"),fPr=o("The model is set in evaluation mode by default using "),C6e=a("code"),gPr=o("model.eval()"),hPr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),w6e=a("code"),uPr=o("model.train()"),pPr=l(),F(m5.$$.fragment),Rao=l(),ec=a("h2"),c5=a("a"),A6e=a("span"),F(KS.$$.fragment),_Pr=l(),L6e=a("span"),bPr=o("AutoModelForSemanticSegmentation"),Pao=l(),lr=a("div"),F(eR.$$.fragment),vPr=l(),oc=a("p"),FPr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),Goe=a("a"),TPr=o("from_pretrained()"),MPr=o(" class method or the "),Ooe=a("a"),EPr=o("from_config()"),CPr=o(` class
method.`),wPr=l(),oR=a("p"),APr=o("This class cannot be instantiated directly using "),y6e=a("code"),LPr=o("__init__()"),yPr=o(" (throws an error)."),xPr=l(),Ut=a("div"),F(rR.$$.fragment),$Pr=l(),x6e=a("p"),kPr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),SPr=l(),rc=a("p"),RPr=o(`Note:
Loading a model from its configuration file does `),$6e=a("strong"),PPr=o("not"),BPr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Voe=a("a"),IPr=o("from_pretrained()"),NPr=o(" to load the model weights."),qPr=l(),F(f5.$$.fragment),DPr=l(),wo=a("div"),F(tR.$$.fragment),jPr=l(),k6e=a("p"),GPr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),OPr=l(),Sn=a("p"),VPr=o("The model class to instantiate is selected based on the "),S6e=a("code"),XPr=o("model_type"),zPr=o(` property of the config object (either
passed as an argument or loaded from `),R6e=a("code"),QPr=o("pretrained_model_name_or_path"),WPr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P6e=a("code"),UPr=o("pretrained_model_name_or_path"),HPr=o(":"),JPr=l(),bt=a("ul"),g5=a("li"),B6e=a("strong"),YPr=o("beit"),ZPr=o(" \u2014 "),Xoe=a("a"),KPr=o("BeitForSemanticSegmentation"),eBr=o(" (BEiT model)"),oBr=l(),h5=a("li"),I6e=a("strong"),rBr=o("data2vec-vision"),tBr=o(" \u2014 "),zoe=a("a"),aBr=o("Data2VecVisionForSemanticSegmentation"),nBr=o(" (Data2VecVision model)"),sBr=l(),u5=a("li"),N6e=a("strong"),lBr=o("dpt"),iBr=o(" \u2014 "),Qoe=a("a"),dBr=o("DPTForSemanticSegmentation"),mBr=o(" (DPT model)"),cBr=l(),p5=a("li"),q6e=a("strong"),fBr=o("mobilevit"),gBr=o(" \u2014 "),Woe=a("a"),hBr=o("MobileViTForSemanticSegmentation"),uBr=o(" (MobileViT model)"),pBr=l(),_5=a("li"),D6e=a("strong"),_Br=o("segformer"),bBr=o(" \u2014 "),Uoe=a("a"),vBr=o("SegformerForSemanticSegmentation"),FBr=o(" (SegFormer model)"),TBr=l(),b5=a("p"),MBr=o("The model is set in evaluation mode by default using "),j6e=a("code"),EBr=o("model.eval()"),CBr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),G6e=a("code"),wBr=o("model.train()"),ABr=l(),F(v5.$$.fragment),Bao=l(),tc=a("h2"),F5=a("a"),O6e=a("span"),F(aR.$$.fragment),LBr=l(),V6e=a("span"),yBr=o("AutoModelForInstanceSegmentation"),Iao=l(),ir=a("div"),F(nR.$$.fragment),xBr=l(),ac=a("p"),$Br=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),Hoe=a("a"),kBr=o("from_pretrained()"),SBr=o(" class method or the "),Joe=a("a"),RBr=o("from_config()"),PBr=o(` class
method.`),BBr=l(),sR=a("p"),IBr=o("This class cannot be instantiated directly using "),X6e=a("code"),NBr=o("__init__()"),qBr=o(" (throws an error)."),DBr=l(),Ht=a("div"),F(lR.$$.fragment),jBr=l(),z6e=a("p"),GBr=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),OBr=l(),nc=a("p"),VBr=o(`Note:
Loading a model from its configuration file does `),Q6e=a("strong"),XBr=o("not"),zBr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Yoe=a("a"),QBr=o("from_pretrained()"),WBr=o(" to load the model weights."),UBr=l(),F(T5.$$.fragment),HBr=l(),Ao=a("div"),F(iR.$$.fragment),JBr=l(),W6e=a("p"),YBr=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),ZBr=l(),Rn=a("p"),KBr=o("The model class to instantiate is selected based on the "),U6e=a("code"),eIr=o("model_type"),oIr=o(` property of the config object (either
passed as an argument or loaded from `),H6e=a("code"),rIr=o("pretrained_model_name_or_path"),tIr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),J6e=a("code"),aIr=o("pretrained_model_name_or_path"),nIr=o(":"),sIr=l(),Y6e=a("ul"),M5=a("li"),Z6e=a("strong"),lIr=o("maskformer"),iIr=o(" \u2014 "),Zoe=a("a"),dIr=o("MaskFormerForInstanceSegmentation"),mIr=o(" (MaskFormer model)"),cIr=l(),E5=a("p"),fIr=o("The model is set in evaluation mode by default using "),K6e=a("code"),gIr=o("model.eval()"),hIr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),e7e=a("code"),uIr=o("model.train()"),pIr=l(),F(C5.$$.fragment),Nao=l(),sc=a("h2"),w5=a("a"),o7e=a("span"),F(dR.$$.fragment),_Ir=l(),r7e=a("span"),bIr=o("AutoModelForZeroShotObjectDetection"),qao=l(),dr=a("div"),F(mR.$$.fragment),vIr=l(),lc=a("p"),FIr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a zero-shot object detection head) when created
with the `),Koe=a("a"),TIr=o("from_pretrained()"),MIr=o(" class method or the "),ere=a("a"),EIr=o("from_config()"),CIr=o(` class
method.`),wIr=l(),cR=a("p"),AIr=o("This class cannot be instantiated directly using "),t7e=a("code"),LIr=o("__init__()"),yIr=o(" (throws an error)."),xIr=l(),Jt=a("div"),F(fR.$$.fragment),$Ir=l(),a7e=a("p"),kIr=o("Instantiates one of the model classes of the library (with a zero-shot object detection head) from a configuration."),SIr=l(),ic=a("p"),RIr=o(`Note:
Loading a model from its configuration file does `),n7e=a("strong"),PIr=o("not"),BIr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ore=a("a"),IIr=o("from_pretrained()"),NIr=o(" to load the model weights."),qIr=l(),F(A5.$$.fragment),DIr=l(),Lo=a("div"),F(gR.$$.fragment),jIr=l(),s7e=a("p"),GIr=o("Instantiate one of the model classes of the library (with a zero-shot object detection head) from a pretrained model."),OIr=l(),Pn=a("p"),VIr=o("The model class to instantiate is selected based on the "),l7e=a("code"),XIr=o("model_type"),zIr=o(` property of the config object (either
passed as an argument or loaded from `),i7e=a("code"),QIr=o("pretrained_model_name_or_path"),WIr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d7e=a("code"),UIr=o("pretrained_model_name_or_path"),HIr=o(":"),JIr=l(),m7e=a("ul"),L5=a("li"),c7e=a("strong"),YIr=o("owlvit"),ZIr=o(" \u2014 "),rre=a("a"),KIr=o("OwlViTForObjectDetection"),eNr=o(" (OWL-ViT model)"),oNr=l(),y5=a("p"),rNr=o("The model is set in evaluation mode by default using "),f7e=a("code"),tNr=o("model.eval()"),aNr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),g7e=a("code"),nNr=o("model.train()"),sNr=l(),F(x5.$$.fragment),Dao=l(),dc=a("h2"),$5=a("a"),h7e=a("span"),F(hR.$$.fragment),lNr=l(),u7e=a("span"),iNr=o("TFAutoModel"),jao=l(),mr=a("div"),F(uR.$$.fragment),dNr=l(),mc=a("p"),mNr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),tre=a("a"),cNr=o("from_pretrained()"),fNr=o(" class method or the "),are=a("a"),gNr=o("from_config()"),hNr=o(` class
method.`),uNr=l(),pR=a("p"),pNr=o("This class cannot be instantiated directly using "),p7e=a("code"),_Nr=o("__init__()"),bNr=o(" (throws an error)."),vNr=l(),Yt=a("div"),F(_R.$$.fragment),FNr=l(),_7e=a("p"),TNr=o("Instantiates one of the base model classes of the library from a configuration."),MNr=l(),cc=a("p"),ENr=o(`Note:
Loading a model from its configuration file does `),b7e=a("strong"),CNr=o("not"),wNr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nre=a("a"),ANr=o("from_pretrained()"),LNr=o(" to load the model weights."),yNr=l(),F(k5.$$.fragment),xNr=l(),jr=a("div"),F(bR.$$.fragment),$Nr=l(),v7e=a("p"),kNr=o("Instantiate one of the base model classes of the library from a pretrained model."),SNr=l(),Bn=a("p"),RNr=o("The model class to instantiate is selected based on the "),F7e=a("code"),PNr=o("model_type"),BNr=o(` property of the config object (either
passed as an argument or loaded from `),T7e=a("code"),INr=o("pretrained_model_name_or_path"),NNr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),M7e=a("code"),qNr=o("pretrained_model_name_or_path"),DNr=o(":"),jNr=l(),P=a("ul"),S5=a("li"),E7e=a("strong"),GNr=o("albert"),ONr=o(" \u2014 "),sre=a("a"),VNr=o("TFAlbertModel"),XNr=o(" (ALBERT model)"),zNr=l(),R5=a("li"),C7e=a("strong"),QNr=o("bart"),WNr=o(" \u2014 "),lre=a("a"),UNr=o("TFBartModel"),HNr=o(" (BART model)"),JNr=l(),P5=a("li"),w7e=a("strong"),YNr=o("bert"),ZNr=o(" \u2014 "),ire=a("a"),KNr=o("TFBertModel"),eqr=o(" (BERT model)"),oqr=l(),B5=a("li"),A7e=a("strong"),rqr=o("blenderbot"),tqr=o(" \u2014 "),dre=a("a"),aqr=o("TFBlenderbotModel"),nqr=o(" (Blenderbot model)"),sqr=l(),I5=a("li"),L7e=a("strong"),lqr=o("blenderbot-small"),iqr=o(" \u2014 "),mre=a("a"),dqr=o("TFBlenderbotSmallModel"),mqr=o(" (BlenderbotSmall model)"),cqr=l(),N5=a("li"),y7e=a("strong"),fqr=o("camembert"),gqr=o(" \u2014 "),cre=a("a"),hqr=o("TFCamembertModel"),uqr=o(" (CamemBERT model)"),pqr=l(),q5=a("li"),x7e=a("strong"),_qr=o("clip"),bqr=o(" \u2014 "),fre=a("a"),vqr=o("TFCLIPModel"),Fqr=o(" (CLIP model)"),Tqr=l(),D5=a("li"),$7e=a("strong"),Mqr=o("convbert"),Eqr=o(" \u2014 "),gre=a("a"),Cqr=o("TFConvBertModel"),wqr=o(" (ConvBERT model)"),Aqr=l(),j5=a("li"),k7e=a("strong"),Lqr=o("convnext"),yqr=o(" \u2014 "),hre=a("a"),xqr=o("TFConvNextModel"),$qr=o(" (ConvNeXT model)"),kqr=l(),G5=a("li"),S7e=a("strong"),Sqr=o("ctrl"),Rqr=o(" \u2014 "),ure=a("a"),Pqr=o("TFCTRLModel"),Bqr=o(" (CTRL model)"),Iqr=l(),O5=a("li"),R7e=a("strong"),Nqr=o("cvt"),qqr=o(" \u2014 "),pre=a("a"),Dqr=o("TFCvtModel"),jqr=o(" (CvT model)"),Gqr=l(),V5=a("li"),P7e=a("strong"),Oqr=o("data2vec-vision"),Vqr=o(" \u2014 "),_re=a("a"),Xqr=o("TFData2VecVisionModel"),zqr=o(" (Data2VecVision model)"),Qqr=l(),X5=a("li"),B7e=a("strong"),Wqr=o("deberta"),Uqr=o(" \u2014 "),bre=a("a"),Hqr=o("TFDebertaModel"),Jqr=o(" (DeBERTa model)"),Yqr=l(),z5=a("li"),I7e=a("strong"),Zqr=o("deberta-v2"),Kqr=o(" \u2014 "),vre=a("a"),eDr=o("TFDebertaV2Model"),oDr=o(" (DeBERTa-v2 model)"),rDr=l(),Q5=a("li"),N7e=a("strong"),tDr=o("deit"),aDr=o(" \u2014 "),Fre=a("a"),nDr=o("TFDeiTModel"),sDr=o(" (DeiT model)"),lDr=l(),W5=a("li"),q7e=a("strong"),iDr=o("distilbert"),dDr=o(" \u2014 "),Tre=a("a"),mDr=o("TFDistilBertModel"),cDr=o(" (DistilBERT model)"),fDr=l(),U5=a("li"),D7e=a("strong"),gDr=o("dpr"),hDr=o(" \u2014 "),Mre=a("a"),uDr=o("TFDPRQuestionEncoder"),pDr=o(" (DPR model)"),_Dr=l(),H5=a("li"),j7e=a("strong"),bDr=o("electra"),vDr=o(" \u2014 "),Ere=a("a"),FDr=o("TFElectraModel"),TDr=o(" (ELECTRA model)"),MDr=l(),J5=a("li"),G7e=a("strong"),EDr=o("esm"),CDr=o(" \u2014 "),Cre=a("a"),wDr=o("TFEsmModel"),ADr=o(" (ESM model)"),LDr=l(),Y5=a("li"),O7e=a("strong"),yDr=o("flaubert"),xDr=o(" \u2014 "),wre=a("a"),$Dr=o("TFFlaubertModel"),kDr=o(" (FlauBERT model)"),SDr=l(),kl=a("li"),V7e=a("strong"),RDr=o("funnel"),PDr=o(" \u2014 "),Are=a("a"),BDr=o("TFFunnelModel"),IDr=o(" or "),Lre=a("a"),NDr=o("TFFunnelBaseModel"),qDr=o(" (Funnel Transformer model)"),DDr=l(),Z5=a("li"),X7e=a("strong"),jDr=o("gpt2"),GDr=o(" \u2014 "),yre=a("a"),ODr=o("TFGPT2Model"),VDr=o(" (OpenAI GPT-2 model)"),XDr=l(),K5=a("li"),z7e=a("strong"),zDr=o("gptj"),QDr=o(" \u2014 "),xre=a("a"),WDr=o("TFGPTJModel"),UDr=o(" (GPT-J model)"),HDr=l(),e0=a("li"),Q7e=a("strong"),JDr=o("groupvit"),YDr=o(" \u2014 "),$re=a("a"),ZDr=o("TFGroupViTModel"),KDr=o(" (GroupViT model)"),ejr=l(),o0=a("li"),W7e=a("strong"),ojr=o("hubert"),rjr=o(" \u2014 "),kre=a("a"),tjr=o("TFHubertModel"),ajr=o(" (Hubert model)"),njr=l(),r0=a("li"),U7e=a("strong"),sjr=o("layoutlm"),ljr=o(" \u2014 "),Sre=a("a"),ijr=o("TFLayoutLMModel"),djr=o(" (LayoutLM model)"),mjr=l(),t0=a("li"),H7e=a("strong"),cjr=o("layoutlmv3"),fjr=o(" \u2014 "),Rre=a("a"),gjr=o("TFLayoutLMv3Model"),hjr=o(" (LayoutLMv3 model)"),ujr=l(),a0=a("li"),J7e=a("strong"),pjr=o("led"),_jr=o(" \u2014 "),Pre=a("a"),bjr=o("TFLEDModel"),vjr=o(" (LED model)"),Fjr=l(),n0=a("li"),Y7e=a("strong"),Tjr=o("longformer"),Mjr=o(" \u2014 "),Bre=a("a"),Ejr=o("TFLongformerModel"),Cjr=o(" (Longformer model)"),wjr=l(),s0=a("li"),Z7e=a("strong"),Ajr=o("lxmert"),Ljr=o(" \u2014 "),Ire=a("a"),yjr=o("TFLxmertModel"),xjr=o(" (LXMERT model)"),$jr=l(),l0=a("li"),K7e=a("strong"),kjr=o("marian"),Sjr=o(" \u2014 "),Nre=a("a"),Rjr=o("TFMarianModel"),Pjr=o(" (Marian model)"),Bjr=l(),i0=a("li"),e8e=a("strong"),Ijr=o("mbart"),Njr=o(" \u2014 "),qre=a("a"),qjr=o("TFMBartModel"),Djr=o(" (mBART model)"),jjr=l(),d0=a("li"),o8e=a("strong"),Gjr=o("mobilebert"),Ojr=o(" \u2014 "),Dre=a("a"),Vjr=o("TFMobileBertModel"),Xjr=o(" (MobileBERT model)"),zjr=l(),m0=a("li"),r8e=a("strong"),Qjr=o("mobilevit"),Wjr=o(" \u2014 "),jre=a("a"),Ujr=o("TFMobileViTModel"),Hjr=o(" (MobileViT model)"),Jjr=l(),c0=a("li"),t8e=a("strong"),Yjr=o("mpnet"),Zjr=o(" \u2014 "),Gre=a("a"),Kjr=o("TFMPNetModel"),eGr=o(" (MPNet model)"),oGr=l(),f0=a("li"),a8e=a("strong"),rGr=o("mt5"),tGr=o(" \u2014 "),Ore=a("a"),aGr=o("TFMT5Model"),nGr=o(" (MT5 model)"),sGr=l(),g0=a("li"),n8e=a("strong"),lGr=o("openai-gpt"),iGr=o(" \u2014 "),Vre=a("a"),dGr=o("TFOpenAIGPTModel"),mGr=o(" (OpenAI GPT model)"),cGr=l(),h0=a("li"),s8e=a("strong"),fGr=o("opt"),gGr=o(" \u2014 "),Xre=a("a"),hGr=o("TFOPTModel"),uGr=o(" (OPT model)"),pGr=l(),u0=a("li"),l8e=a("strong"),_Gr=o("pegasus"),bGr=o(" \u2014 "),zre=a("a"),vGr=o("TFPegasusModel"),FGr=o(" (Pegasus model)"),TGr=l(),p0=a("li"),i8e=a("strong"),MGr=o("regnet"),EGr=o(" \u2014 "),Qre=a("a"),CGr=o("TFRegNetModel"),wGr=o(" (RegNet model)"),AGr=l(),_0=a("li"),d8e=a("strong"),LGr=o("rembert"),yGr=o(" \u2014 "),Wre=a("a"),xGr=o("TFRemBertModel"),$Gr=o(" (RemBERT model)"),kGr=l(),b0=a("li"),m8e=a("strong"),SGr=o("resnet"),RGr=o(" \u2014 "),Ure=a("a"),PGr=o("TFResNetModel"),BGr=o(" (ResNet model)"),IGr=l(),v0=a("li"),c8e=a("strong"),NGr=o("roberta"),qGr=o(" \u2014 "),Hre=a("a"),DGr=o("TFRobertaModel"),jGr=o(" (RoBERTa model)"),GGr=l(),F0=a("li"),f8e=a("strong"),OGr=o("roformer"),VGr=o(" \u2014 "),Jre=a("a"),XGr=o("TFRoFormerModel"),zGr=o(" (RoFormer model)"),QGr=l(),T0=a("li"),g8e=a("strong"),WGr=o("segformer"),UGr=o(" \u2014 "),Yre=a("a"),HGr=o("TFSegformerModel"),JGr=o(" (SegFormer model)"),YGr=l(),M0=a("li"),h8e=a("strong"),ZGr=o("speech_to_text"),KGr=o(" \u2014 "),Zre=a("a"),eOr=o("TFSpeech2TextModel"),oOr=o(" (Speech2Text model)"),rOr=l(),E0=a("li"),u8e=a("strong"),tOr=o("swin"),aOr=o(" \u2014 "),Kre=a("a"),nOr=o("TFSwinModel"),sOr=o(" (Swin Transformer model)"),lOr=l(),C0=a("li"),p8e=a("strong"),iOr=o("t5"),dOr=o(" \u2014 "),ete=a("a"),mOr=o("TFT5Model"),cOr=o(" (T5 model)"),fOr=l(),w0=a("li"),_8e=a("strong"),gOr=o("tapas"),hOr=o(" \u2014 "),ote=a("a"),uOr=o("TFTapasModel"),pOr=o(" (TAPAS model)"),_Or=l(),A0=a("li"),b8e=a("strong"),bOr=o("transfo-xl"),vOr=o(" \u2014 "),rte=a("a"),FOr=o("TFTransfoXLModel"),TOr=o(" (Transformer-XL model)"),MOr=l(),L0=a("li"),v8e=a("strong"),EOr=o("vit"),COr=o(" \u2014 "),tte=a("a"),wOr=o("TFViTModel"),AOr=o(" (ViT model)"),LOr=l(),y0=a("li"),F8e=a("strong"),yOr=o("vit_mae"),xOr=o(" \u2014 "),ate=a("a"),$Or=o("TFViTMAEModel"),kOr=o(" (ViTMAE model)"),SOr=l(),x0=a("li"),T8e=a("strong"),ROr=o("wav2vec2"),POr=o(" \u2014 "),nte=a("a"),BOr=o("TFWav2Vec2Model"),IOr=o(" (Wav2Vec2 model)"),NOr=l(),$0=a("li"),M8e=a("strong"),qOr=o("whisper"),DOr=o(" \u2014 "),ste=a("a"),jOr=o("TFWhisperModel"),GOr=o(" (Whisper model)"),OOr=l(),k0=a("li"),E8e=a("strong"),VOr=o("xglm"),XOr=o(" \u2014 "),lte=a("a"),zOr=o("TFXGLMModel"),QOr=o(" (XGLM model)"),WOr=l(),S0=a("li"),C8e=a("strong"),UOr=o("xlm"),HOr=o(" \u2014 "),ite=a("a"),JOr=o("TFXLMModel"),YOr=o(" (XLM model)"),ZOr=l(),R0=a("li"),w8e=a("strong"),KOr=o("xlm-roberta"),eVr=o(" \u2014 "),dte=a("a"),oVr=o("TFXLMRobertaModel"),rVr=o(" (XLM-RoBERTa model)"),tVr=l(),P0=a("li"),A8e=a("strong"),aVr=o("xlnet"),nVr=o(" \u2014 "),mte=a("a"),sVr=o("TFXLNetModel"),lVr=o(" (XLNet model)"),iVr=l(),F(B0.$$.fragment),Gao=l(),fc=a("h2"),I0=a("a"),L8e=a("span"),F(vR.$$.fragment),dVr=l(),y8e=a("span"),mVr=o("TFAutoModelForPreTraining"),Oao=l(),cr=a("div"),F(FR.$$.fragment),cVr=l(),gc=a("p"),fVr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),cte=a("a"),gVr=o("from_pretrained()"),hVr=o(" class method or the "),fte=a("a"),uVr=o("from_config()"),pVr=o(` class
method.`),_Vr=l(),TR=a("p"),bVr=o("This class cannot be instantiated directly using "),x8e=a("code"),vVr=o("__init__()"),FVr=o(" (throws an error)."),TVr=l(),Zt=a("div"),F(MR.$$.fragment),MVr=l(),$8e=a("p"),EVr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),CVr=l(),hc=a("p"),wVr=o(`Note:
Loading a model from its configuration file does `),k8e=a("strong"),AVr=o("not"),LVr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gte=a("a"),yVr=o("from_pretrained()"),xVr=o(" to load the model weights."),$Vr=l(),F(N0.$$.fragment),kVr=l(),Gr=a("div"),F(ER.$$.fragment),SVr=l(),S8e=a("p"),RVr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),PVr=l(),In=a("p"),BVr=o("The model class to instantiate is selected based on the "),R8e=a("code"),IVr=o("model_type"),NVr=o(` property of the config object (either
passed as an argument or loaded from `),P8e=a("code"),qVr=o("pretrained_model_name_or_path"),DVr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),B8e=a("code"),jVr=o("pretrained_model_name_or_path"),GVr=o(":"),OVr=l(),le=a("ul"),q0=a("li"),I8e=a("strong"),VVr=o("albert"),XVr=o(" \u2014 "),hte=a("a"),zVr=o("TFAlbertForPreTraining"),QVr=o(" (ALBERT model)"),WVr=l(),D0=a("li"),N8e=a("strong"),UVr=o("bart"),HVr=o(" \u2014 "),ute=a("a"),JVr=o("TFBartForConditionalGeneration"),YVr=o(" (BART model)"),ZVr=l(),j0=a("li"),q8e=a("strong"),KVr=o("bert"),eXr=o(" \u2014 "),pte=a("a"),oXr=o("TFBertForPreTraining"),rXr=o(" (BERT model)"),tXr=l(),G0=a("li"),D8e=a("strong"),aXr=o("camembert"),nXr=o(" \u2014 "),_te=a("a"),sXr=o("TFCamembertForMaskedLM"),lXr=o(" (CamemBERT model)"),iXr=l(),O0=a("li"),j8e=a("strong"),dXr=o("ctrl"),mXr=o(" \u2014 "),bte=a("a"),cXr=o("TFCTRLLMHeadModel"),fXr=o(" (CTRL model)"),gXr=l(),V0=a("li"),G8e=a("strong"),hXr=o("distilbert"),uXr=o(" \u2014 "),vte=a("a"),pXr=o("TFDistilBertForMaskedLM"),_Xr=o(" (DistilBERT model)"),bXr=l(),X0=a("li"),O8e=a("strong"),vXr=o("electra"),FXr=o(" \u2014 "),Fte=a("a"),TXr=o("TFElectraForPreTraining"),MXr=o(" (ELECTRA model)"),EXr=l(),z0=a("li"),V8e=a("strong"),CXr=o("flaubert"),wXr=o(" \u2014 "),Tte=a("a"),AXr=o("TFFlaubertWithLMHeadModel"),LXr=o(" (FlauBERT model)"),yXr=l(),Q0=a("li"),X8e=a("strong"),xXr=o("funnel"),$Xr=o(" \u2014 "),Mte=a("a"),kXr=o("TFFunnelForPreTraining"),SXr=o(" (Funnel Transformer model)"),RXr=l(),W0=a("li"),z8e=a("strong"),PXr=o("gpt2"),BXr=o(" \u2014 "),Ete=a("a"),IXr=o("TFGPT2LMHeadModel"),NXr=o(" (OpenAI GPT-2 model)"),qXr=l(),U0=a("li"),Q8e=a("strong"),DXr=o("layoutlm"),jXr=o(" \u2014 "),Cte=a("a"),GXr=o("TFLayoutLMForMaskedLM"),OXr=o(" (LayoutLM model)"),VXr=l(),H0=a("li"),W8e=a("strong"),XXr=o("lxmert"),zXr=o(" \u2014 "),wte=a("a"),QXr=o("TFLxmertForPreTraining"),WXr=o(" (LXMERT model)"),UXr=l(),J0=a("li"),U8e=a("strong"),HXr=o("mobilebert"),JXr=o(" \u2014 "),Ate=a("a"),YXr=o("TFMobileBertForPreTraining"),ZXr=o(" (MobileBERT model)"),KXr=l(),Y0=a("li"),H8e=a("strong"),ezr=o("mpnet"),ozr=o(" \u2014 "),Lte=a("a"),rzr=o("TFMPNetForMaskedLM"),tzr=o(" (MPNet model)"),azr=l(),Z0=a("li"),J8e=a("strong"),nzr=o("openai-gpt"),szr=o(" \u2014 "),yte=a("a"),lzr=o("TFOpenAIGPTLMHeadModel"),izr=o(" (OpenAI GPT model)"),dzr=l(),K0=a("li"),Y8e=a("strong"),mzr=o("roberta"),czr=o(" \u2014 "),xte=a("a"),fzr=o("TFRobertaForMaskedLM"),gzr=o(" (RoBERTa model)"),hzr=l(),ew=a("li"),Z8e=a("strong"),uzr=o("t5"),pzr=o(" \u2014 "),$te=a("a"),_zr=o("TFT5ForConditionalGeneration"),bzr=o(" (T5 model)"),vzr=l(),ow=a("li"),K8e=a("strong"),Fzr=o("tapas"),Tzr=o(" \u2014 "),kte=a("a"),Mzr=o("TFTapasForMaskedLM"),Ezr=o(" (TAPAS model)"),Czr=l(),rw=a("li"),eLe=a("strong"),wzr=o("transfo-xl"),Azr=o(" \u2014 "),Ste=a("a"),Lzr=o("TFTransfoXLLMHeadModel"),yzr=o(" (Transformer-XL model)"),xzr=l(),tw=a("li"),oLe=a("strong"),$zr=o("vit_mae"),kzr=o(" \u2014 "),Rte=a("a"),Szr=o("TFViTMAEForPreTraining"),Rzr=o(" (ViTMAE model)"),Pzr=l(),aw=a("li"),rLe=a("strong"),Bzr=o("xlm"),Izr=o(" \u2014 "),Pte=a("a"),Nzr=o("TFXLMWithLMHeadModel"),qzr=o(" (XLM model)"),Dzr=l(),nw=a("li"),tLe=a("strong"),jzr=o("xlm-roberta"),Gzr=o(" \u2014 "),Bte=a("a"),Ozr=o("TFXLMRobertaForMaskedLM"),Vzr=o(" (XLM-RoBERTa model)"),Xzr=l(),sw=a("li"),aLe=a("strong"),zzr=o("xlnet"),Qzr=o(" \u2014 "),Ite=a("a"),Wzr=o("TFXLNetLMHeadModel"),Uzr=o(" (XLNet model)"),Hzr=l(),F(lw.$$.fragment),Vao=l(),uc=a("h2"),iw=a("a"),nLe=a("span"),F(CR.$$.fragment),Jzr=l(),sLe=a("span"),Yzr=o("TFAutoModelForCausalLM"),Xao=l(),fr=a("div"),F(wR.$$.fragment),Zzr=l(),pc=a("p"),Kzr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Nte=a("a"),eQr=o("from_pretrained()"),oQr=o(" class method or the "),qte=a("a"),rQr=o("from_config()"),tQr=o(` class
method.`),aQr=l(),AR=a("p"),nQr=o("This class cannot be instantiated directly using "),lLe=a("code"),sQr=o("__init__()"),lQr=o(" (throws an error)."),iQr=l(),Kt=a("div"),F(LR.$$.fragment),dQr=l(),iLe=a("p"),mQr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),cQr=l(),_c=a("p"),fQr=o(`Note:
Loading a model from its configuration file does `),dLe=a("strong"),gQr=o("not"),hQr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Dte=a("a"),uQr=o("from_pretrained()"),pQr=o(" to load the model weights."),_Qr=l(),F(dw.$$.fragment),bQr=l(),Or=a("div"),F(yR.$$.fragment),vQr=l(),mLe=a("p"),FQr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),TQr=l(),Nn=a("p"),MQr=o("The model class to instantiate is selected based on the "),cLe=a("code"),EQr=o("model_type"),CQr=o(` property of the config object (either
passed as an argument or loaded from `),fLe=a("code"),wQr=o("pretrained_model_name_or_path"),AQr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gLe=a("code"),LQr=o("pretrained_model_name_or_path"),yQr=o(":"),xQr=l(),Me=a("ul"),mw=a("li"),hLe=a("strong"),$Qr=o("bert"),kQr=o(" \u2014 "),jte=a("a"),SQr=o("TFBertLMHeadModel"),RQr=o(" (BERT model)"),PQr=l(),cw=a("li"),uLe=a("strong"),BQr=o("camembert"),IQr=o(" \u2014 "),Gte=a("a"),NQr=o("TFCamembertForCausalLM"),qQr=o(" (CamemBERT model)"),DQr=l(),fw=a("li"),pLe=a("strong"),jQr=o("ctrl"),GQr=o(" \u2014 "),Ote=a("a"),OQr=o("TFCTRLLMHeadModel"),VQr=o(" (CTRL model)"),XQr=l(),gw=a("li"),_Le=a("strong"),zQr=o("gpt2"),QQr=o(" \u2014 "),Vte=a("a"),WQr=o("TFGPT2LMHeadModel"),UQr=o(" (OpenAI GPT-2 model)"),HQr=l(),hw=a("li"),bLe=a("strong"),JQr=o("gptj"),YQr=o(" \u2014 "),Xte=a("a"),ZQr=o("TFGPTJForCausalLM"),KQr=o(" (GPT-J model)"),eWr=l(),uw=a("li"),vLe=a("strong"),oWr=o("openai-gpt"),rWr=o(" \u2014 "),zte=a("a"),tWr=o("TFOpenAIGPTLMHeadModel"),aWr=o(" (OpenAI GPT model)"),nWr=l(),pw=a("li"),FLe=a("strong"),sWr=o("opt"),lWr=o(" \u2014 "),Qte=a("a"),iWr=o("TFOPTForCausalLM"),dWr=o(" (OPT model)"),mWr=l(),_w=a("li"),TLe=a("strong"),cWr=o("rembert"),fWr=o(" \u2014 "),Wte=a("a"),gWr=o("TFRemBertForCausalLM"),hWr=o(" (RemBERT model)"),uWr=l(),bw=a("li"),MLe=a("strong"),pWr=o("roberta"),_Wr=o(" \u2014 "),Ute=a("a"),bWr=o("TFRobertaForCausalLM"),vWr=o(" (RoBERTa model)"),FWr=l(),vw=a("li"),ELe=a("strong"),TWr=o("roformer"),MWr=o(" \u2014 "),Hte=a("a"),EWr=o("TFRoFormerForCausalLM"),CWr=o(" (RoFormer model)"),wWr=l(),Fw=a("li"),CLe=a("strong"),AWr=o("transfo-xl"),LWr=o(" \u2014 "),Jte=a("a"),yWr=o("TFTransfoXLLMHeadModel"),xWr=o(" (Transformer-XL model)"),$Wr=l(),Tw=a("li"),wLe=a("strong"),kWr=o("xglm"),SWr=o(" \u2014 "),Yte=a("a"),RWr=o("TFXGLMForCausalLM"),PWr=o(" (XGLM model)"),BWr=l(),Mw=a("li"),ALe=a("strong"),IWr=o("xlm"),NWr=o(" \u2014 "),Zte=a("a"),qWr=o("TFXLMWithLMHeadModel"),DWr=o(" (XLM model)"),jWr=l(),Ew=a("li"),LLe=a("strong"),GWr=o("xlnet"),OWr=o(" \u2014 "),Kte=a("a"),VWr=o("TFXLNetLMHeadModel"),XWr=o(" (XLNet model)"),zWr=l(),F(Cw.$$.fragment),zao=l(),bc=a("h2"),ww=a("a"),yLe=a("span"),F(xR.$$.fragment),QWr=l(),xLe=a("span"),WWr=o("TFAutoModelForImageClassification"),Qao=l(),gr=a("div"),F($R.$$.fragment),UWr=l(),vc=a("p"),HWr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),eae=a("a"),JWr=o("from_pretrained()"),YWr=o(" class method or the "),oae=a("a"),ZWr=o("from_config()"),KWr=o(` class
method.`),eUr=l(),kR=a("p"),oUr=o("This class cannot be instantiated directly using "),$Le=a("code"),rUr=o("__init__()"),tUr=o(" (throws an error)."),aUr=l(),ea=a("div"),F(SR.$$.fragment),nUr=l(),kLe=a("p"),sUr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),lUr=l(),Fc=a("p"),iUr=o(`Note:
Loading a model from its configuration file does `),SLe=a("strong"),dUr=o("not"),mUr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rae=a("a"),cUr=o("from_pretrained()"),fUr=o(" to load the model weights."),gUr=l(),F(Aw.$$.fragment),hUr=l(),Vr=a("div"),F(RR.$$.fragment),uUr=l(),RLe=a("p"),pUr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),_Ur=l(),qn=a("p"),bUr=o("The model class to instantiate is selected based on the "),PLe=a("code"),vUr=o("model_type"),FUr=o(` property of the config object (either
passed as an argument or loaded from `),BLe=a("code"),TUr=o("pretrained_model_name_or_path"),MUr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ILe=a("code"),EUr=o("pretrained_model_name_or_path"),CUr=o(":"),wUr=l(),ye=a("ul"),Lw=a("li"),NLe=a("strong"),AUr=o("convnext"),LUr=o(" \u2014 "),tae=a("a"),yUr=o("TFConvNextForImageClassification"),xUr=o(" (ConvNeXT model)"),$Ur=l(),yw=a("li"),qLe=a("strong"),kUr=o("cvt"),SUr=o(" \u2014 "),aae=a("a"),RUr=o("TFCvtForImageClassification"),PUr=o(" (CvT model)"),BUr=l(),xw=a("li"),DLe=a("strong"),IUr=o("data2vec-vision"),NUr=o(" \u2014 "),nae=a("a"),qUr=o("TFData2VecVisionForImageClassification"),DUr=o(" (Data2VecVision model)"),jUr=l(),Sl=a("li"),jLe=a("strong"),GUr=o("deit"),OUr=o(" \u2014 "),sae=a("a"),VUr=o("TFDeiTForImageClassification"),XUr=o(" or "),lae=a("a"),zUr=o("TFDeiTForImageClassificationWithTeacher"),QUr=o(" (DeiT model)"),WUr=l(),$w=a("li"),GLe=a("strong"),UUr=o("mobilevit"),HUr=o(" \u2014 "),iae=a("a"),JUr=o("TFMobileViTForImageClassification"),YUr=o(" (MobileViT model)"),ZUr=l(),kw=a("li"),OLe=a("strong"),KUr=o("regnet"),eHr=o(" \u2014 "),dae=a("a"),oHr=o("TFRegNetForImageClassification"),rHr=o(" (RegNet model)"),tHr=l(),Sw=a("li"),VLe=a("strong"),aHr=o("resnet"),nHr=o(" \u2014 "),mae=a("a"),sHr=o("TFResNetForImageClassification"),lHr=o(" (ResNet model)"),iHr=l(),Rw=a("li"),XLe=a("strong"),dHr=o("segformer"),mHr=o(" \u2014 "),cae=a("a"),cHr=o("TFSegformerForImageClassification"),fHr=o(" (SegFormer model)"),gHr=l(),Pw=a("li"),zLe=a("strong"),hHr=o("swin"),uHr=o(" \u2014 "),fae=a("a"),pHr=o("TFSwinForImageClassification"),_Hr=o(" (Swin Transformer model)"),bHr=l(),Bw=a("li"),QLe=a("strong"),vHr=o("vit"),FHr=o(" \u2014 "),gae=a("a"),THr=o("TFViTForImageClassification"),MHr=o(" (ViT model)"),EHr=l(),F(Iw.$$.fragment),Wao=l(),Tc=a("h2"),Nw=a("a"),WLe=a("span"),F(PR.$$.fragment),CHr=l(),ULe=a("span"),wHr=o("TFAutoModelForSemanticSegmentation"),Uao=l(),hr=a("div"),F(BR.$$.fragment),AHr=l(),Mc=a("p"),LHr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),hae=a("a"),yHr=o("from_pretrained()"),xHr=o(" class method or the "),uae=a("a"),$Hr=o("from_config()"),kHr=o(` class
method.`),SHr=l(),IR=a("p"),RHr=o("This class cannot be instantiated directly using "),HLe=a("code"),PHr=o("__init__()"),BHr=o(" (throws an error)."),IHr=l(),oa=a("div"),F(NR.$$.fragment),NHr=l(),JLe=a("p"),qHr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),DHr=l(),Ec=a("p"),jHr=o(`Note:
Loading a model from its configuration file does `),YLe=a("strong"),GHr=o("not"),OHr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pae=a("a"),VHr=o("from_pretrained()"),XHr=o(" to load the model weights."),zHr=l(),F(qw.$$.fragment),QHr=l(),Xr=a("div"),F(qR.$$.fragment),WHr=l(),ZLe=a("p"),UHr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),HHr=l(),Dn=a("p"),JHr=o("The model class to instantiate is selected based on the "),KLe=a("code"),YHr=o("model_type"),ZHr=o(` property of the config object (either
passed as an argument or loaded from `),eye=a("code"),KHr=o("pretrained_model_name_or_path"),eJr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oye=a("code"),oJr=o("pretrained_model_name_or_path"),rJr=o(":"),tJr=l(),Cc=a("ul"),Dw=a("li"),rye=a("strong"),aJr=o("data2vec-vision"),nJr=o(" \u2014 "),_ae=a("a"),sJr=o("TFData2VecVisionForSemanticSegmentation"),lJr=o(" (Data2VecVision model)"),iJr=l(),jw=a("li"),tye=a("strong"),dJr=o("mobilevit"),mJr=o(" \u2014 "),bae=a("a"),cJr=o("TFMobileViTForSemanticSegmentation"),fJr=o(" (MobileViT model)"),gJr=l(),Gw=a("li"),aye=a("strong"),hJr=o("segformer"),uJr=o(" \u2014 "),vae=a("a"),pJr=o("TFSegformerForSemanticSegmentation"),_Jr=o(" (SegFormer model)"),bJr=l(),F(Ow.$$.fragment),Hao=l(),wc=a("h2"),Vw=a("a"),nye=a("span"),F(DR.$$.fragment),vJr=l(),sye=a("span"),FJr=o("TFAutoModelForMaskedLM"),Jao=l(),ur=a("div"),F(jR.$$.fragment),TJr=l(),Ac=a("p"),MJr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Fae=a("a"),EJr=o("from_pretrained()"),CJr=o(" class method or the "),Tae=a("a"),wJr=o("from_config()"),AJr=o(` class
method.`),LJr=l(),GR=a("p"),yJr=o("This class cannot be instantiated directly using "),lye=a("code"),xJr=o("__init__()"),$Jr=o(" (throws an error)."),kJr=l(),ra=a("div"),F(OR.$$.fragment),SJr=l(),iye=a("p"),RJr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),PJr=l(),Lc=a("p"),BJr=o(`Note:
Loading a model from its configuration file does `),dye=a("strong"),IJr=o("not"),NJr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Mae=a("a"),qJr=o("from_pretrained()"),DJr=o(" to load the model weights."),jJr=l(),F(Xw.$$.fragment),GJr=l(),zr=a("div"),F(VR.$$.fragment),OJr=l(),mye=a("p"),VJr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),XJr=l(),jn=a("p"),zJr=o("The model class to instantiate is selected based on the "),cye=a("code"),QJr=o("model_type"),WJr=o(` property of the config object (either
passed as an argument or loaded from `),fye=a("code"),UJr=o("pretrained_model_name_or_path"),HJr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gye=a("code"),JJr=o("pretrained_model_name_or_path"),YJr=o(":"),ZJr=l(),ce=a("ul"),zw=a("li"),hye=a("strong"),KJr=o("albert"),eYr=o(" \u2014 "),Eae=a("a"),oYr=o("TFAlbertForMaskedLM"),rYr=o(" (ALBERT model)"),tYr=l(),Qw=a("li"),uye=a("strong"),aYr=o("bert"),nYr=o(" \u2014 "),Cae=a("a"),sYr=o("TFBertForMaskedLM"),lYr=o(" (BERT model)"),iYr=l(),Ww=a("li"),pye=a("strong"),dYr=o("camembert"),mYr=o(" \u2014 "),wae=a("a"),cYr=o("TFCamembertForMaskedLM"),fYr=o(" (CamemBERT model)"),gYr=l(),Uw=a("li"),_ye=a("strong"),hYr=o("convbert"),uYr=o(" \u2014 "),Aae=a("a"),pYr=o("TFConvBertForMaskedLM"),_Yr=o(" (ConvBERT model)"),bYr=l(),Hw=a("li"),bye=a("strong"),vYr=o("deberta"),FYr=o(" \u2014 "),Lae=a("a"),TYr=o("TFDebertaForMaskedLM"),MYr=o(" (DeBERTa model)"),EYr=l(),Jw=a("li"),vye=a("strong"),CYr=o("deberta-v2"),wYr=o(" \u2014 "),yae=a("a"),AYr=o("TFDebertaV2ForMaskedLM"),LYr=o(" (DeBERTa-v2 model)"),yYr=l(),Yw=a("li"),Fye=a("strong"),xYr=o("distilbert"),$Yr=o(" \u2014 "),xae=a("a"),kYr=o("TFDistilBertForMaskedLM"),SYr=o(" (DistilBERT model)"),RYr=l(),Zw=a("li"),Tye=a("strong"),PYr=o("electra"),BYr=o(" \u2014 "),$ae=a("a"),IYr=o("TFElectraForMaskedLM"),NYr=o(" (ELECTRA model)"),qYr=l(),Kw=a("li"),Mye=a("strong"),DYr=o("esm"),jYr=o(" \u2014 "),kae=a("a"),GYr=o("TFEsmForMaskedLM"),OYr=o(" (ESM model)"),VYr=l(),eA=a("li"),Eye=a("strong"),XYr=o("flaubert"),zYr=o(" \u2014 "),Sae=a("a"),QYr=o("TFFlaubertWithLMHeadModel"),WYr=o(" (FlauBERT model)"),UYr=l(),oA=a("li"),Cye=a("strong"),HYr=o("funnel"),JYr=o(" \u2014 "),Rae=a("a"),YYr=o("TFFunnelForMaskedLM"),ZYr=o(" (Funnel Transformer model)"),KYr=l(),rA=a("li"),wye=a("strong"),eZr=o("layoutlm"),oZr=o(" \u2014 "),Pae=a("a"),rZr=o("TFLayoutLMForMaskedLM"),tZr=o(" (LayoutLM model)"),aZr=l(),tA=a("li"),Aye=a("strong"),nZr=o("longformer"),sZr=o(" \u2014 "),Bae=a("a"),lZr=o("TFLongformerForMaskedLM"),iZr=o(" (Longformer model)"),dZr=l(),aA=a("li"),Lye=a("strong"),mZr=o("mobilebert"),cZr=o(" \u2014 "),Iae=a("a"),fZr=o("TFMobileBertForMaskedLM"),gZr=o(" (MobileBERT model)"),hZr=l(),nA=a("li"),yye=a("strong"),uZr=o("mpnet"),pZr=o(" \u2014 "),Nae=a("a"),_Zr=o("TFMPNetForMaskedLM"),bZr=o(" (MPNet model)"),vZr=l(),sA=a("li"),xye=a("strong"),FZr=o("rembert"),TZr=o(" \u2014 "),qae=a("a"),MZr=o("TFRemBertForMaskedLM"),EZr=o(" (RemBERT model)"),CZr=l(),lA=a("li"),$ye=a("strong"),wZr=o("roberta"),AZr=o(" \u2014 "),Dae=a("a"),LZr=o("TFRobertaForMaskedLM"),yZr=o(" (RoBERTa model)"),xZr=l(),iA=a("li"),kye=a("strong"),$Zr=o("roformer"),kZr=o(" \u2014 "),jae=a("a"),SZr=o("TFRoFormerForMaskedLM"),RZr=o(" (RoFormer model)"),PZr=l(),dA=a("li"),Sye=a("strong"),BZr=o("tapas"),IZr=o(" \u2014 "),Gae=a("a"),NZr=o("TFTapasForMaskedLM"),qZr=o(" (TAPAS model)"),DZr=l(),mA=a("li"),Rye=a("strong"),jZr=o("xlm"),GZr=o(" \u2014 "),Oae=a("a"),OZr=o("TFXLMWithLMHeadModel"),VZr=o(" (XLM model)"),XZr=l(),cA=a("li"),Pye=a("strong"),zZr=o("xlm-roberta"),QZr=o(" \u2014 "),Vae=a("a"),WZr=o("TFXLMRobertaForMaskedLM"),UZr=o(" (XLM-RoBERTa model)"),HZr=l(),F(fA.$$.fragment),Yao=l(),yc=a("h2"),gA=a("a"),Bye=a("span"),F(XR.$$.fragment),JZr=l(),Iye=a("span"),YZr=o("TFAutoModelForSeq2SeqLM"),Zao=l(),pr=a("div"),F(zR.$$.fragment),ZZr=l(),xc=a("p"),KZr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Xae=a("a"),eKr=o("from_pretrained()"),oKr=o(" class method or the "),zae=a("a"),rKr=o("from_config()"),tKr=o(` class
method.`),aKr=l(),QR=a("p"),nKr=o("This class cannot be instantiated directly using "),Nye=a("code"),sKr=o("__init__()"),lKr=o(" (throws an error)."),iKr=l(),ta=a("div"),F(WR.$$.fragment),dKr=l(),qye=a("p"),mKr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),cKr=l(),$c=a("p"),fKr=o(`Note:
Loading a model from its configuration file does `),Dye=a("strong"),gKr=o("not"),hKr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Qae=a("a"),uKr=o("from_pretrained()"),pKr=o(" to load the model weights."),_Kr=l(),F(hA.$$.fragment),bKr=l(),Qr=a("div"),F(UR.$$.fragment),vKr=l(),jye=a("p"),FKr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),TKr=l(),Gn=a("p"),MKr=o("The model class to instantiate is selected based on the "),Gye=a("code"),EKr=o("model_type"),CKr=o(` property of the config object (either
passed as an argument or loaded from `),Oye=a("code"),wKr=o("pretrained_model_name_or_path"),AKr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Vye=a("code"),LKr=o("pretrained_model_name_or_path"),yKr=o(":"),xKr=l(),xe=a("ul"),uA=a("li"),Xye=a("strong"),$Kr=o("bart"),kKr=o(" \u2014 "),Wae=a("a"),SKr=o("TFBartForConditionalGeneration"),RKr=o(" (BART model)"),PKr=l(),pA=a("li"),zye=a("strong"),BKr=o("blenderbot"),IKr=o(" \u2014 "),Uae=a("a"),NKr=o("TFBlenderbotForConditionalGeneration"),qKr=o(" (Blenderbot model)"),DKr=l(),_A=a("li"),Qye=a("strong"),jKr=o("blenderbot-small"),GKr=o(" \u2014 "),Hae=a("a"),OKr=o("TFBlenderbotSmallForConditionalGeneration"),VKr=o(" (BlenderbotSmall model)"),XKr=l(),bA=a("li"),Wye=a("strong"),zKr=o("encoder-decoder"),QKr=o(" \u2014 "),Jae=a("a"),WKr=o("TFEncoderDecoderModel"),UKr=o(" (Encoder decoder model)"),HKr=l(),vA=a("li"),Uye=a("strong"),JKr=o("led"),YKr=o(" \u2014 "),Yae=a("a"),ZKr=o("TFLEDForConditionalGeneration"),KKr=o(" (LED model)"),eet=l(),FA=a("li"),Hye=a("strong"),oet=o("marian"),ret=o(" \u2014 "),Zae=a("a"),tet=o("TFMarianMTModel"),aet=o(" (Marian model)"),net=l(),TA=a("li"),Jye=a("strong"),set=o("mbart"),iet=o(" \u2014 "),Kae=a("a"),det=o("TFMBartForConditionalGeneration"),met=o(" (mBART model)"),cet=l(),MA=a("li"),Yye=a("strong"),fet=o("mt5"),get=o(" \u2014 "),ene=a("a"),het=o("TFMT5ForConditionalGeneration"),uet=o(" (MT5 model)"),pet=l(),EA=a("li"),Zye=a("strong"),_et=o("pegasus"),bet=o(" \u2014 "),one=a("a"),vet=o("TFPegasusForConditionalGeneration"),Fet=o(" (Pegasus model)"),Tet=l(),CA=a("li"),Kye=a("strong"),Met=o("t5"),Eet=o(" \u2014 "),rne=a("a"),Cet=o("TFT5ForConditionalGeneration"),wet=o(" (T5 model)"),Aet=l(),F(wA.$$.fragment),Kao=l(),kc=a("h2"),AA=a("a"),e9e=a("span"),F(HR.$$.fragment),Let=l(),o9e=a("span"),yet=o("TFAutoModelForSequenceClassification"),eno=l(),_r=a("div"),F(JR.$$.fragment),xet=l(),Sc=a("p"),$et=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),tne=a("a"),ket=o("from_pretrained()"),Set=o(" class method or the "),ane=a("a"),Ret=o("from_config()"),Pet=o(` class
method.`),Bet=l(),YR=a("p"),Iet=o("This class cannot be instantiated directly using "),r9e=a("code"),Net=o("__init__()"),qet=o(" (throws an error)."),Det=l(),aa=a("div"),F(ZR.$$.fragment),jet=l(),t9e=a("p"),Get=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Oet=l(),Rc=a("p"),Vet=o(`Note:
Loading a model from its configuration file does `),a9e=a("strong"),Xet=o("not"),zet=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nne=a("a"),Qet=o("from_pretrained()"),Wet=o(" to load the model weights."),Uet=l(),F(LA.$$.fragment),Het=l(),Wr=a("div"),F(KR.$$.fragment),Jet=l(),n9e=a("p"),Yet=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Zet=l(),On=a("p"),Ket=o("The model class to instantiate is selected based on the "),s9e=a("code"),eot=o("model_type"),oot=o(` property of the config object (either
passed as an argument or loaded from `),l9e=a("code"),rot=o("pretrained_model_name_or_path"),tot=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i9e=a("code"),aot=o("pretrained_model_name_or_path"),not=o(":"),sot=l(),re=a("ul"),yA=a("li"),d9e=a("strong"),lot=o("albert"),iot=o(" \u2014 "),sne=a("a"),dot=o("TFAlbertForSequenceClassification"),mot=o(" (ALBERT model)"),cot=l(),xA=a("li"),m9e=a("strong"),fot=o("bert"),got=o(" \u2014 "),lne=a("a"),hot=o("TFBertForSequenceClassification"),uot=o(" (BERT model)"),pot=l(),$A=a("li"),c9e=a("strong"),_ot=o("camembert"),bot=o(" \u2014 "),ine=a("a"),vot=o("TFCamembertForSequenceClassification"),Fot=o(" (CamemBERT model)"),Tot=l(),kA=a("li"),f9e=a("strong"),Mot=o("convbert"),Eot=o(" \u2014 "),dne=a("a"),Cot=o("TFConvBertForSequenceClassification"),wot=o(" (ConvBERT model)"),Aot=l(),SA=a("li"),g9e=a("strong"),Lot=o("ctrl"),yot=o(" \u2014 "),mne=a("a"),xot=o("TFCTRLForSequenceClassification"),$ot=o(" (CTRL model)"),kot=l(),RA=a("li"),h9e=a("strong"),Sot=o("deberta"),Rot=o(" \u2014 "),cne=a("a"),Pot=o("TFDebertaForSequenceClassification"),Bot=o(" (DeBERTa model)"),Iot=l(),PA=a("li"),u9e=a("strong"),Not=o("deberta-v2"),qot=o(" \u2014 "),fne=a("a"),Dot=o("TFDebertaV2ForSequenceClassification"),jot=o(" (DeBERTa-v2 model)"),Got=l(),BA=a("li"),p9e=a("strong"),Oot=o("distilbert"),Vot=o(" \u2014 "),gne=a("a"),Xot=o("TFDistilBertForSequenceClassification"),zot=o(" (DistilBERT model)"),Qot=l(),IA=a("li"),_9e=a("strong"),Wot=o("electra"),Uot=o(" \u2014 "),hne=a("a"),Hot=o("TFElectraForSequenceClassification"),Jot=o(" (ELECTRA model)"),Yot=l(),NA=a("li"),b9e=a("strong"),Zot=o("esm"),Kot=o(" \u2014 "),une=a("a"),ert=o("TFEsmForSequenceClassification"),ort=o(" (ESM model)"),rrt=l(),qA=a("li"),v9e=a("strong"),trt=o("flaubert"),art=o(" \u2014 "),pne=a("a"),nrt=o("TFFlaubertForSequenceClassification"),srt=o(" (FlauBERT model)"),lrt=l(),DA=a("li"),F9e=a("strong"),irt=o("funnel"),drt=o(" \u2014 "),_ne=a("a"),mrt=o("TFFunnelForSequenceClassification"),crt=o(" (Funnel Transformer model)"),frt=l(),jA=a("li"),T9e=a("strong"),grt=o("gpt2"),hrt=o(" \u2014 "),bne=a("a"),urt=o("TFGPT2ForSequenceClassification"),prt=o(" (OpenAI GPT-2 model)"),_rt=l(),GA=a("li"),M9e=a("strong"),brt=o("gptj"),vrt=o(" \u2014 "),vne=a("a"),Frt=o("TFGPTJForSequenceClassification"),Trt=o(" (GPT-J model)"),Mrt=l(),OA=a("li"),E9e=a("strong"),Ert=o("layoutlm"),Crt=o(" \u2014 "),Fne=a("a"),wrt=o("TFLayoutLMForSequenceClassification"),Art=o(" (LayoutLM model)"),Lrt=l(),VA=a("li"),C9e=a("strong"),yrt=o("layoutlmv3"),xrt=o(" \u2014 "),Tne=a("a"),$rt=o("TFLayoutLMv3ForSequenceClassification"),krt=o(" (LayoutLMv3 model)"),Srt=l(),XA=a("li"),w9e=a("strong"),Rrt=o("longformer"),Prt=o(" \u2014 "),Mne=a("a"),Brt=o("TFLongformerForSequenceClassification"),Irt=o(" (Longformer model)"),Nrt=l(),zA=a("li"),A9e=a("strong"),qrt=o("mobilebert"),Drt=o(" \u2014 "),Ene=a("a"),jrt=o("TFMobileBertForSequenceClassification"),Grt=o(" (MobileBERT model)"),Ort=l(),QA=a("li"),L9e=a("strong"),Vrt=o("mpnet"),Xrt=o(" \u2014 "),Cne=a("a"),zrt=o("TFMPNetForSequenceClassification"),Qrt=o(" (MPNet model)"),Wrt=l(),WA=a("li"),y9e=a("strong"),Urt=o("openai-gpt"),Hrt=o(" \u2014 "),wne=a("a"),Jrt=o("TFOpenAIGPTForSequenceClassification"),Yrt=o(" (OpenAI GPT model)"),Zrt=l(),UA=a("li"),x9e=a("strong"),Krt=o("rembert"),ett=o(" \u2014 "),Ane=a("a"),ott=o("TFRemBertForSequenceClassification"),rtt=o(" (RemBERT model)"),ttt=l(),HA=a("li"),$9e=a("strong"),att=o("roberta"),ntt=o(" \u2014 "),Lne=a("a"),stt=o("TFRobertaForSequenceClassification"),ltt=o(" (RoBERTa model)"),itt=l(),JA=a("li"),k9e=a("strong"),dtt=o("roformer"),mtt=o(" \u2014 "),yne=a("a"),ctt=o("TFRoFormerForSequenceClassification"),ftt=o(" (RoFormer model)"),gtt=l(),YA=a("li"),S9e=a("strong"),htt=o("tapas"),utt=o(" \u2014 "),xne=a("a"),ptt=o("TFTapasForSequenceClassification"),_tt=o(" (TAPAS model)"),btt=l(),ZA=a("li"),R9e=a("strong"),vtt=o("transfo-xl"),Ftt=o(" \u2014 "),$ne=a("a"),Ttt=o("TFTransfoXLForSequenceClassification"),Mtt=o(" (Transformer-XL model)"),Ett=l(),KA=a("li"),P9e=a("strong"),Ctt=o("xlm"),wtt=o(" \u2014 "),kne=a("a"),Att=o("TFXLMForSequenceClassification"),Ltt=o(" (XLM model)"),ytt=l(),e6=a("li"),B9e=a("strong"),xtt=o("xlm-roberta"),$tt=o(" \u2014 "),Sne=a("a"),ktt=o("TFXLMRobertaForSequenceClassification"),Stt=o(" (XLM-RoBERTa model)"),Rtt=l(),o6=a("li"),I9e=a("strong"),Ptt=o("xlnet"),Btt=o(" \u2014 "),Rne=a("a"),Itt=o("TFXLNetForSequenceClassification"),Ntt=o(" (XLNet model)"),qtt=l(),F(r6.$$.fragment),ono=l(),Pc=a("h2"),t6=a("a"),N9e=a("span"),F(eP.$$.fragment),Dtt=l(),q9e=a("span"),jtt=o("TFAutoModelForMultipleChoice"),rno=l(),br=a("div"),F(oP.$$.fragment),Gtt=l(),Bc=a("p"),Ott=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Pne=a("a"),Vtt=o("from_pretrained()"),Xtt=o(" class method or the "),Bne=a("a"),ztt=o("from_config()"),Qtt=o(` class
method.`),Wtt=l(),rP=a("p"),Utt=o("This class cannot be instantiated directly using "),D9e=a("code"),Htt=o("__init__()"),Jtt=o(" (throws an error)."),Ytt=l(),na=a("div"),F(tP.$$.fragment),Ztt=l(),j9e=a("p"),Ktt=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),eat=l(),Ic=a("p"),oat=o(`Note:
Loading a model from its configuration file does `),G9e=a("strong"),rat=o("not"),tat=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ine=a("a"),aat=o("from_pretrained()"),nat=o(" to load the model weights."),sat=l(),F(a6.$$.fragment),lat=l(),Ur=a("div"),F(aP.$$.fragment),iat=l(),O9e=a("p"),dat=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),mat=l(),Vn=a("p"),cat=o("The model class to instantiate is selected based on the "),V9e=a("code"),fat=o("model_type"),gat=o(` property of the config object (either
passed as an argument or loaded from `),X9e=a("code"),hat=o("pretrained_model_name_or_path"),uat=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z9e=a("code"),pat=o("pretrained_model_name_or_path"),_at=o(":"),bat=l(),ve=a("ul"),n6=a("li"),Q9e=a("strong"),vat=o("albert"),Fat=o(" \u2014 "),Nne=a("a"),Tat=o("TFAlbertForMultipleChoice"),Mat=o(" (ALBERT model)"),Eat=l(),s6=a("li"),W9e=a("strong"),Cat=o("bert"),wat=o(" \u2014 "),qne=a("a"),Aat=o("TFBertForMultipleChoice"),Lat=o(" (BERT model)"),yat=l(),l6=a("li"),U9e=a("strong"),xat=o("camembert"),$at=o(" \u2014 "),Dne=a("a"),kat=o("TFCamembertForMultipleChoice"),Sat=o(" (CamemBERT model)"),Rat=l(),i6=a("li"),H9e=a("strong"),Pat=o("convbert"),Bat=o(" \u2014 "),jne=a("a"),Iat=o("TFConvBertForMultipleChoice"),Nat=o(" (ConvBERT model)"),qat=l(),d6=a("li"),J9e=a("strong"),Dat=o("distilbert"),jat=o(" \u2014 "),Gne=a("a"),Gat=o("TFDistilBertForMultipleChoice"),Oat=o(" (DistilBERT model)"),Vat=l(),m6=a("li"),Y9e=a("strong"),Xat=o("electra"),zat=o(" \u2014 "),One=a("a"),Qat=o("TFElectraForMultipleChoice"),Wat=o(" (ELECTRA model)"),Uat=l(),c6=a("li"),Z9e=a("strong"),Hat=o("flaubert"),Jat=o(" \u2014 "),Vne=a("a"),Yat=o("TFFlaubertForMultipleChoice"),Zat=o(" (FlauBERT model)"),Kat=l(),f6=a("li"),K9e=a("strong"),ent=o("funnel"),ont=o(" \u2014 "),Xne=a("a"),rnt=o("TFFunnelForMultipleChoice"),tnt=o(" (Funnel Transformer model)"),ant=l(),g6=a("li"),exe=a("strong"),nnt=o("longformer"),snt=o(" \u2014 "),zne=a("a"),lnt=o("TFLongformerForMultipleChoice"),int=o(" (Longformer model)"),dnt=l(),h6=a("li"),oxe=a("strong"),mnt=o("mobilebert"),cnt=o(" \u2014 "),Qne=a("a"),fnt=o("TFMobileBertForMultipleChoice"),gnt=o(" (MobileBERT model)"),hnt=l(),u6=a("li"),rxe=a("strong"),unt=o("mpnet"),pnt=o(" \u2014 "),Wne=a("a"),_nt=o("TFMPNetForMultipleChoice"),bnt=o(" (MPNet model)"),vnt=l(),p6=a("li"),txe=a("strong"),Fnt=o("rembert"),Tnt=o(" \u2014 "),Une=a("a"),Mnt=o("TFRemBertForMultipleChoice"),Ent=o(" (RemBERT model)"),Cnt=l(),_6=a("li"),axe=a("strong"),wnt=o("roberta"),Ant=o(" \u2014 "),Hne=a("a"),Lnt=o("TFRobertaForMultipleChoice"),ynt=o(" (RoBERTa model)"),xnt=l(),b6=a("li"),nxe=a("strong"),$nt=o("roformer"),knt=o(" \u2014 "),Jne=a("a"),Snt=o("TFRoFormerForMultipleChoice"),Rnt=o(" (RoFormer model)"),Pnt=l(),v6=a("li"),sxe=a("strong"),Bnt=o("xlm"),Int=o(" \u2014 "),Yne=a("a"),Nnt=o("TFXLMForMultipleChoice"),qnt=o(" (XLM model)"),Dnt=l(),F6=a("li"),lxe=a("strong"),jnt=o("xlm-roberta"),Gnt=o(" \u2014 "),Zne=a("a"),Ont=o("TFXLMRobertaForMultipleChoice"),Vnt=o(" (XLM-RoBERTa model)"),Xnt=l(),T6=a("li"),ixe=a("strong"),znt=o("xlnet"),Qnt=o(" \u2014 "),Kne=a("a"),Wnt=o("TFXLNetForMultipleChoice"),Unt=o(" (XLNet model)"),Hnt=l(),F(M6.$$.fragment),tno=l(),Nc=a("h2"),E6=a("a"),dxe=a("span"),F(nP.$$.fragment),Jnt=l(),mxe=a("span"),Ynt=o("TFAutoModelForNextSentencePrediction"),ano=l(),vr=a("div"),F(sP.$$.fragment),Znt=l(),qc=a("p"),Knt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),ese=a("a"),est=o("from_pretrained()"),ost=o(" class method or the "),ose=a("a"),rst=o("from_config()"),tst=o(` class
method.`),ast=l(),lP=a("p"),nst=o("This class cannot be instantiated directly using "),cxe=a("code"),sst=o("__init__()"),lst=o(" (throws an error)."),ist=l(),sa=a("div"),F(iP.$$.fragment),dst=l(),fxe=a("p"),mst=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),cst=l(),Dc=a("p"),fst=o(`Note:
Loading a model from its configuration file does `),gxe=a("strong"),gst=o("not"),hst=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rse=a("a"),ust=o("from_pretrained()"),pst=o(" to load the model weights."),_st=l(),F(C6.$$.fragment),bst=l(),Hr=a("div"),F(dP.$$.fragment),vst=l(),hxe=a("p"),Fst=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Tst=l(),Xn=a("p"),Mst=o("The model class to instantiate is selected based on the "),uxe=a("code"),Est=o("model_type"),Cst=o(` property of the config object (either
passed as an argument or loaded from `),pxe=a("code"),wst=o("pretrained_model_name_or_path"),Ast=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_xe=a("code"),Lst=o("pretrained_model_name_or_path"),yst=o(":"),xst=l(),mP=a("ul"),w6=a("li"),bxe=a("strong"),$st=o("bert"),kst=o(" \u2014 "),tse=a("a"),Sst=o("TFBertForNextSentencePrediction"),Rst=o(" (BERT model)"),Pst=l(),A6=a("li"),vxe=a("strong"),Bst=o("mobilebert"),Ist=o(" \u2014 "),ase=a("a"),Nst=o("TFMobileBertForNextSentencePrediction"),qst=o(" (MobileBERT model)"),Dst=l(),F(L6.$$.fragment),nno=l(),jc=a("h2"),y6=a("a"),Fxe=a("span"),F(cP.$$.fragment),jst=l(),Txe=a("span"),Gst=o("TFAutoModelForTableQuestionAnswering"),sno=l(),Fr=a("div"),F(fP.$$.fragment),Ost=l(),Gc=a("p"),Vst=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),nse=a("a"),Xst=o("from_pretrained()"),zst=o(" class method or the "),sse=a("a"),Qst=o("from_config()"),Wst=o(` class
method.`),Ust=l(),gP=a("p"),Hst=o("This class cannot be instantiated directly using "),Mxe=a("code"),Jst=o("__init__()"),Yst=o(" (throws an error)."),Zst=l(),la=a("div"),F(hP.$$.fragment),Kst=l(),Exe=a("p"),elt=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),olt=l(),Oc=a("p"),rlt=o(`Note:
Loading a model from its configuration file does `),Cxe=a("strong"),tlt=o("not"),alt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lse=a("a"),nlt=o("from_pretrained()"),slt=o(" to load the model weights."),llt=l(),F(x6.$$.fragment),ilt=l(),Jr=a("div"),F(uP.$$.fragment),dlt=l(),wxe=a("p"),mlt=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),clt=l(),zn=a("p"),flt=o("The model class to instantiate is selected based on the "),Axe=a("code"),glt=o("model_type"),hlt=o(` property of the config object (either
passed as an argument or loaded from `),Lxe=a("code"),ult=o("pretrained_model_name_or_path"),plt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yxe=a("code"),_lt=o("pretrained_model_name_or_path"),blt=o(":"),vlt=l(),xxe=a("ul"),$6=a("li"),$xe=a("strong"),Flt=o("tapas"),Tlt=o(" \u2014 "),ise=a("a"),Mlt=o("TFTapasForQuestionAnswering"),Elt=o(" (TAPAS model)"),Clt=l(),F(k6.$$.fragment),lno=l(),Vc=a("h2"),S6=a("a"),kxe=a("span"),F(pP.$$.fragment),wlt=l(),Sxe=a("span"),Alt=o("TFAutoModelForDocumentQuestionAnswering"),ino=l(),Tr=a("div"),F(_P.$$.fragment),Llt=l(),Xc=a("p"),ylt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),dse=a("a"),xlt=o("from_pretrained()"),$lt=o(" class method or the "),mse=a("a"),klt=o("from_config()"),Slt=o(` class
method.`),Rlt=l(),bP=a("p"),Plt=o("This class cannot be instantiated directly using "),Rxe=a("code"),Blt=o("__init__()"),Ilt=o(" (throws an error)."),Nlt=l(),ia=a("div"),F(vP.$$.fragment),qlt=l(),Pxe=a("p"),Dlt=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),jlt=l(),zc=a("p"),Glt=o(`Note:
Loading a model from its configuration file does `),Bxe=a("strong"),Olt=o("not"),Vlt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cse=a("a"),Xlt=o("from_pretrained()"),zlt=o(" to load the model weights."),Qlt=l(),F(R6.$$.fragment),Wlt=l(),Yr=a("div"),F(FP.$$.fragment),Ult=l(),Ixe=a("p"),Hlt=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),Jlt=l(),Qn=a("p"),Ylt=o("The model class to instantiate is selected based on the "),Nxe=a("code"),Zlt=o("model_type"),Klt=o(` property of the config object (either
passed as an argument or loaded from `),qxe=a("code"),eit=o("pretrained_model_name_or_path"),oit=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Dxe=a("code"),rit=o("pretrained_model_name_or_path"),tit=o(":"),ait=l(),jxe=a("ul"),P6=a("li"),Gxe=a("strong"),nit=o("layoutlm"),sit=o(" \u2014 "),fse=a("a"),lit=o("TFLayoutLMForQuestionAnswering"),iit=o(" (LayoutLM model)"),dit=l(),F(B6.$$.fragment),dno=l(),Qc=a("h2"),I6=a("a"),Oxe=a("span"),F(TP.$$.fragment),mit=l(),Vxe=a("span"),cit=o("TFAutoModelForTokenClassification"),mno=l(),Mr=a("div"),F(MP.$$.fragment),fit=l(),Wc=a("p"),git=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),gse=a("a"),hit=o("from_pretrained()"),uit=o(" class method or the "),hse=a("a"),pit=o("from_config()"),_it=o(` class
method.`),bit=l(),EP=a("p"),vit=o("This class cannot be instantiated directly using "),Xxe=a("code"),Fit=o("__init__()"),Tit=o(" (throws an error)."),Mit=l(),da=a("div"),F(CP.$$.fragment),Eit=l(),zxe=a("p"),Cit=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),wit=l(),Uc=a("p"),Ait=o(`Note:
Loading a model from its configuration file does `),Qxe=a("strong"),Lit=o("not"),yit=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),use=a("a"),xit=o("from_pretrained()"),$it=o(" to load the model weights."),kit=l(),F(N6.$$.fragment),Sit=l(),Zr=a("div"),F(wP.$$.fragment),Rit=l(),Wxe=a("p"),Pit=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Bit=l(),Wn=a("p"),Iit=o("The model class to instantiate is selected based on the "),Uxe=a("code"),Nit=o("model_type"),qit=o(` property of the config object (either
passed as an argument or loaded from `),Hxe=a("code"),Dit=o("pretrained_model_name_or_path"),jit=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jxe=a("code"),Git=o("pretrained_model_name_or_path"),Oit=o(":"),Vit=l(),ie=a("ul"),q6=a("li"),Yxe=a("strong"),Xit=o("albert"),zit=o(" \u2014 "),pse=a("a"),Qit=o("TFAlbertForTokenClassification"),Wit=o(" (ALBERT model)"),Uit=l(),D6=a("li"),Zxe=a("strong"),Hit=o("bert"),Jit=o(" \u2014 "),_se=a("a"),Yit=o("TFBertForTokenClassification"),Zit=o(" (BERT model)"),Kit=l(),j6=a("li"),Kxe=a("strong"),edt=o("camembert"),odt=o(" \u2014 "),bse=a("a"),rdt=o("TFCamembertForTokenClassification"),tdt=o(" (CamemBERT model)"),adt=l(),G6=a("li"),e$e=a("strong"),ndt=o("convbert"),sdt=o(" \u2014 "),vse=a("a"),ldt=o("TFConvBertForTokenClassification"),idt=o(" (ConvBERT model)"),ddt=l(),O6=a("li"),o$e=a("strong"),mdt=o("deberta"),cdt=o(" \u2014 "),Fse=a("a"),fdt=o("TFDebertaForTokenClassification"),gdt=o(" (DeBERTa model)"),hdt=l(),V6=a("li"),r$e=a("strong"),udt=o("deberta-v2"),pdt=o(" \u2014 "),Tse=a("a"),_dt=o("TFDebertaV2ForTokenClassification"),bdt=o(" (DeBERTa-v2 model)"),vdt=l(),X6=a("li"),t$e=a("strong"),Fdt=o("distilbert"),Tdt=o(" \u2014 "),Mse=a("a"),Mdt=o("TFDistilBertForTokenClassification"),Edt=o(" (DistilBERT model)"),Cdt=l(),z6=a("li"),a$e=a("strong"),wdt=o("electra"),Adt=o(" \u2014 "),Ese=a("a"),Ldt=o("TFElectraForTokenClassification"),ydt=o(" (ELECTRA model)"),xdt=l(),Q6=a("li"),n$e=a("strong"),$dt=o("esm"),kdt=o(" \u2014 "),Cse=a("a"),Sdt=o("TFEsmForTokenClassification"),Rdt=o(" (ESM model)"),Pdt=l(),W6=a("li"),s$e=a("strong"),Bdt=o("flaubert"),Idt=o(" \u2014 "),wse=a("a"),Ndt=o("TFFlaubertForTokenClassification"),qdt=o(" (FlauBERT model)"),Ddt=l(),U6=a("li"),l$e=a("strong"),jdt=o("funnel"),Gdt=o(" \u2014 "),Ase=a("a"),Odt=o("TFFunnelForTokenClassification"),Vdt=o(" (Funnel Transformer model)"),Xdt=l(),H6=a("li"),i$e=a("strong"),zdt=o("layoutlm"),Qdt=o(" \u2014 "),Lse=a("a"),Wdt=o("TFLayoutLMForTokenClassification"),Udt=o(" (LayoutLM model)"),Hdt=l(),J6=a("li"),d$e=a("strong"),Jdt=o("layoutlmv3"),Ydt=o(" \u2014 "),yse=a("a"),Zdt=o("TFLayoutLMv3ForTokenClassification"),Kdt=o(" (LayoutLMv3 model)"),emt=l(),Y6=a("li"),m$e=a("strong"),omt=o("longformer"),rmt=o(" \u2014 "),xse=a("a"),tmt=o("TFLongformerForTokenClassification"),amt=o(" (Longformer model)"),nmt=l(),Z6=a("li"),c$e=a("strong"),smt=o("mobilebert"),lmt=o(" \u2014 "),$se=a("a"),imt=o("TFMobileBertForTokenClassification"),dmt=o(" (MobileBERT model)"),mmt=l(),K6=a("li"),f$e=a("strong"),cmt=o("mpnet"),fmt=o(" \u2014 "),kse=a("a"),gmt=o("TFMPNetForTokenClassification"),hmt=o(" (MPNet model)"),umt=l(),e7=a("li"),g$e=a("strong"),pmt=o("rembert"),_mt=o(" \u2014 "),Sse=a("a"),bmt=o("TFRemBertForTokenClassification"),vmt=o(" (RemBERT model)"),Fmt=l(),o7=a("li"),h$e=a("strong"),Tmt=o("roberta"),Mmt=o(" \u2014 "),Rse=a("a"),Emt=o("TFRobertaForTokenClassification"),Cmt=o(" (RoBERTa model)"),wmt=l(),r7=a("li"),u$e=a("strong"),Amt=o("roformer"),Lmt=o(" \u2014 "),Pse=a("a"),ymt=o("TFRoFormerForTokenClassification"),xmt=o(" (RoFormer model)"),$mt=l(),t7=a("li"),p$e=a("strong"),kmt=o("xlm"),Smt=o(" \u2014 "),Bse=a("a"),Rmt=o("TFXLMForTokenClassification"),Pmt=o(" (XLM model)"),Bmt=l(),a7=a("li"),_$e=a("strong"),Imt=o("xlm-roberta"),Nmt=o(" \u2014 "),Ise=a("a"),qmt=o("TFXLMRobertaForTokenClassification"),Dmt=o(" (XLM-RoBERTa model)"),jmt=l(),n7=a("li"),b$e=a("strong"),Gmt=o("xlnet"),Omt=o(" \u2014 "),Nse=a("a"),Vmt=o("TFXLNetForTokenClassification"),Xmt=o(" (XLNet model)"),zmt=l(),F(s7.$$.fragment),cno=l(),Hc=a("h2"),l7=a("a"),v$e=a("span"),F(AP.$$.fragment),Qmt=l(),F$e=a("span"),Wmt=o("TFAutoModelForQuestionAnswering"),fno=l(),Er=a("div"),F(LP.$$.fragment),Umt=l(),Jc=a("p"),Hmt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),qse=a("a"),Jmt=o("from_pretrained()"),Ymt=o(" class method or the "),Dse=a("a"),Zmt=o("from_config()"),Kmt=o(` class
method.`),ect=l(),yP=a("p"),oct=o("This class cannot be instantiated directly using "),T$e=a("code"),rct=o("__init__()"),tct=o(" (throws an error)."),act=l(),ma=a("div"),F(xP.$$.fragment),nct=l(),M$e=a("p"),sct=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),lct=l(),Yc=a("p"),ict=o(`Note:
Loading a model from its configuration file does `),E$e=a("strong"),dct=o("not"),mct=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jse=a("a"),cct=o("from_pretrained()"),fct=o(" to load the model weights."),gct=l(),F(i7.$$.fragment),hct=l(),Kr=a("div"),F($P.$$.fragment),uct=l(),C$e=a("p"),pct=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),_ct=l(),Un=a("p"),bct=o("The model class to instantiate is selected based on the "),w$e=a("code"),vct=o("model_type"),Fct=o(` property of the config object (either
passed as an argument or loaded from `),A$e=a("code"),Tct=o("pretrained_model_name_or_path"),Mct=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L$e=a("code"),Ect=o("pretrained_model_name_or_path"),Cct=o(":"),wct=l(),fe=a("ul"),d7=a("li"),y$e=a("strong"),Act=o("albert"),Lct=o(" \u2014 "),Gse=a("a"),yct=o("TFAlbertForQuestionAnswering"),xct=o(" (ALBERT model)"),$ct=l(),m7=a("li"),x$e=a("strong"),kct=o("bert"),Sct=o(" \u2014 "),Ose=a("a"),Rct=o("TFBertForQuestionAnswering"),Pct=o(" (BERT model)"),Bct=l(),c7=a("li"),$$e=a("strong"),Ict=o("camembert"),Nct=o(" \u2014 "),Vse=a("a"),qct=o("TFCamembertForQuestionAnswering"),Dct=o(" (CamemBERT model)"),jct=l(),f7=a("li"),k$e=a("strong"),Gct=o("convbert"),Oct=o(" \u2014 "),Xse=a("a"),Vct=o("TFConvBertForQuestionAnswering"),Xct=o(" (ConvBERT model)"),zct=l(),g7=a("li"),S$e=a("strong"),Qct=o("deberta"),Wct=o(" \u2014 "),zse=a("a"),Uct=o("TFDebertaForQuestionAnswering"),Hct=o(" (DeBERTa model)"),Jct=l(),h7=a("li"),R$e=a("strong"),Yct=o("deberta-v2"),Zct=o(" \u2014 "),Qse=a("a"),Kct=o("TFDebertaV2ForQuestionAnswering"),eft=o(" (DeBERTa-v2 model)"),oft=l(),u7=a("li"),P$e=a("strong"),rft=o("distilbert"),tft=o(" \u2014 "),Wse=a("a"),aft=o("TFDistilBertForQuestionAnswering"),nft=o(" (DistilBERT model)"),sft=l(),p7=a("li"),B$e=a("strong"),lft=o("electra"),ift=o(" \u2014 "),Use=a("a"),dft=o("TFElectraForQuestionAnswering"),mft=o(" (ELECTRA model)"),cft=l(),_7=a("li"),I$e=a("strong"),fft=o("flaubert"),gft=o(" \u2014 "),Hse=a("a"),hft=o("TFFlaubertForQuestionAnsweringSimple"),uft=o(" (FlauBERT model)"),pft=l(),b7=a("li"),N$e=a("strong"),_ft=o("funnel"),bft=o(" \u2014 "),Jse=a("a"),vft=o("TFFunnelForQuestionAnswering"),Fft=o(" (Funnel Transformer model)"),Tft=l(),v7=a("li"),q$e=a("strong"),Mft=o("gptj"),Eft=o(" \u2014 "),Yse=a("a"),Cft=o("TFGPTJForQuestionAnswering"),wft=o(" (GPT-J model)"),Aft=l(),F7=a("li"),D$e=a("strong"),Lft=o("layoutlmv3"),yft=o(" \u2014 "),Zse=a("a"),xft=o("TFLayoutLMv3ForQuestionAnswering"),$ft=o(" (LayoutLMv3 model)"),kft=l(),T7=a("li"),j$e=a("strong"),Sft=o("longformer"),Rft=o(" \u2014 "),Kse=a("a"),Pft=o("TFLongformerForQuestionAnswering"),Bft=o(" (Longformer model)"),Ift=l(),M7=a("li"),G$e=a("strong"),Nft=o("mobilebert"),qft=o(" \u2014 "),ele=a("a"),Dft=o("TFMobileBertForQuestionAnswering"),jft=o(" (MobileBERT model)"),Gft=l(),E7=a("li"),O$e=a("strong"),Oft=o("mpnet"),Vft=o(" \u2014 "),ole=a("a"),Xft=o("TFMPNetForQuestionAnswering"),zft=o(" (MPNet model)"),Qft=l(),C7=a("li"),V$e=a("strong"),Wft=o("rembert"),Uft=o(" \u2014 "),rle=a("a"),Hft=o("TFRemBertForQuestionAnswering"),Jft=o(" (RemBERT model)"),Yft=l(),w7=a("li"),X$e=a("strong"),Zft=o("roberta"),Kft=o(" \u2014 "),tle=a("a"),egt=o("TFRobertaForQuestionAnswering"),ogt=o(" (RoBERTa model)"),rgt=l(),A7=a("li"),z$e=a("strong"),tgt=o("roformer"),agt=o(" \u2014 "),ale=a("a"),ngt=o("TFRoFormerForQuestionAnswering"),sgt=o(" (RoFormer model)"),lgt=l(),L7=a("li"),Q$e=a("strong"),igt=o("xlm"),dgt=o(" \u2014 "),nle=a("a"),mgt=o("TFXLMForQuestionAnsweringSimple"),cgt=o(" (XLM model)"),fgt=l(),y7=a("li"),W$e=a("strong"),ggt=o("xlm-roberta"),hgt=o(" \u2014 "),sle=a("a"),ugt=o("TFXLMRobertaForQuestionAnswering"),pgt=o(" (XLM-RoBERTa model)"),_gt=l(),x7=a("li"),U$e=a("strong"),bgt=o("xlnet"),vgt=o(" \u2014 "),lle=a("a"),Fgt=o("TFXLNetForQuestionAnsweringSimple"),Tgt=o(" (XLNet model)"),Mgt=l(),F($7.$$.fragment),gno=l(),Zc=a("h2"),k7=a("a"),H$e=a("span"),F(kP.$$.fragment),Egt=l(),J$e=a("span"),Cgt=o("TFAutoModelForVision2Seq"),hno=l(),Cr=a("div"),F(SP.$$.fragment),wgt=l(),Kc=a("p"),Agt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),ile=a("a"),Lgt=o("from_pretrained()"),ygt=o(" class method or the "),dle=a("a"),xgt=o("from_config()"),$gt=o(` class
method.`),kgt=l(),RP=a("p"),Sgt=o("This class cannot be instantiated directly using "),Y$e=a("code"),Rgt=o("__init__()"),Pgt=o(" (throws an error)."),Bgt=l(),ca=a("div"),F(PP.$$.fragment),Igt=l(),Z$e=a("p"),Ngt=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),qgt=l(),ef=a("p"),Dgt=o(`Note:
Loading a model from its configuration file does `),K$e=a("strong"),jgt=o("not"),Ggt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mle=a("a"),Ogt=o("from_pretrained()"),Vgt=o(" to load the model weights."),Xgt=l(),F(S7.$$.fragment),zgt=l(),et=a("div"),F(BP.$$.fragment),Qgt=l(),eke=a("p"),Wgt=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Ugt=l(),Hn=a("p"),Hgt=o("The model class to instantiate is selected based on the "),oke=a("code"),Jgt=o("model_type"),Ygt=o(` property of the config object (either
passed as an argument or loaded from `),rke=a("code"),Zgt=o("pretrained_model_name_or_path"),Kgt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tke=a("code"),eht=o("pretrained_model_name_or_path"),oht=o(":"),rht=l(),ake=a("ul"),R7=a("li"),nke=a("strong"),tht=o("vision-encoder-decoder"),aht=o(" \u2014 "),cle=a("a"),nht=o("TFVisionEncoderDecoderModel"),sht=o(" (Vision Encoder decoder model)"),lht=l(),F(P7.$$.fragment),uno=l(),of=a("h2"),B7=a("a"),ske=a("span"),F(IP.$$.fragment),iht=l(),lke=a("span"),dht=o("TFAutoModelForSpeechSeq2Seq"),pno=l(),wr=a("div"),F(NP.$$.fragment),mht=l(),rf=a("p"),cht=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),fle=a("a"),fht=o("from_pretrained()"),ght=o(" class method or the "),gle=a("a"),hht=o("from_config()"),uht=o(` class
method.`),pht=l(),qP=a("p"),_ht=o("This class cannot be instantiated directly using "),ike=a("code"),bht=o("__init__()"),vht=o(" (throws an error)."),Fht=l(),fa=a("div"),F(DP.$$.fragment),Tht=l(),dke=a("p"),Mht=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Eht=l(),tf=a("p"),Cht=o(`Note:
Loading a model from its configuration file does `),mke=a("strong"),wht=o("not"),Aht=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hle=a("a"),Lht=o("from_pretrained()"),yht=o(" to load the model weights."),xht=l(),F(I7.$$.fragment),$ht=l(),ot=a("div"),F(jP.$$.fragment),kht=l(),cke=a("p"),Sht=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Rht=l(),Jn=a("p"),Pht=o("The model class to instantiate is selected based on the "),fke=a("code"),Bht=o("model_type"),Iht=o(` property of the config object (either
passed as an argument or loaded from `),gke=a("code"),Nht=o("pretrained_model_name_or_path"),qht=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hke=a("code"),Dht=o("pretrained_model_name_or_path"),jht=o(":"),Ght=l(),GP=a("ul"),N7=a("li"),uke=a("strong"),Oht=o("speech_to_text"),Vht=o(" \u2014 "),ule=a("a"),Xht=o("TFSpeech2TextForConditionalGeneration"),zht=o(" (Speech2Text model)"),Qht=l(),q7=a("li"),pke=a("strong"),Wht=o("whisper"),Uht=o(" \u2014 "),ple=a("a"),Hht=o("TFWhisperForConditionalGeneration"),Jht=o(" (Whisper model)"),Yht=l(),F(D7.$$.fragment),_no=l(),af=a("h2"),j7=a("a"),_ke=a("span"),F(OP.$$.fragment),Zht=l(),bke=a("span"),Kht=o("FlaxAutoModel"),bno=l(),Ar=a("div"),F(VP.$$.fragment),eut=l(),nf=a("p"),out=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),_le=a("a"),rut=o("from_pretrained()"),tut=o(" class method or the "),ble=a("a"),aut=o("from_config()"),nut=o(` class
method.`),sut=l(),XP=a("p"),lut=o("This class cannot be instantiated directly using "),vke=a("code"),iut=o("__init__()"),dut=o(" (throws an error)."),mut=l(),ga=a("div"),F(zP.$$.fragment),cut=l(),Fke=a("p"),fut=o("Instantiates one of the base model classes of the library from a configuration."),gut=l(),sf=a("p"),hut=o(`Note:
Loading a model from its configuration file does `),Tke=a("strong"),uut=o("not"),put=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vle=a("a"),_ut=o("from_pretrained()"),but=o(" to load the model weights."),vut=l(),F(G7.$$.fragment),Fut=l(),rt=a("div"),F(QP.$$.fragment),Tut=l(),Mke=a("p"),Mut=o("Instantiate one of the base model classes of the library from a pretrained model."),Eut=l(),Yn=a("p"),Cut=o("The model class to instantiate is selected based on the "),Eke=a("code"),wut=o("model_type"),Aut=o(` property of the config object (either
passed as an argument or loaded from `),Cke=a("code"),Lut=o("pretrained_model_name_or_path"),yut=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wke=a("code"),xut=o("pretrained_model_name_or_path"),$ut=o(":"),kut=l(),te=a("ul"),O7=a("li"),Ake=a("strong"),Sut=o("albert"),Rut=o(" \u2014 "),Fle=a("a"),Put=o("FlaxAlbertModel"),But=o(" (ALBERT model)"),Iut=l(),V7=a("li"),Lke=a("strong"),Nut=o("bart"),qut=o(" \u2014 "),Tle=a("a"),Dut=o("FlaxBartModel"),jut=o(" (BART model)"),Gut=l(),X7=a("li"),yke=a("strong"),Out=o("beit"),Vut=o(" \u2014 "),Mle=a("a"),Xut=o("FlaxBeitModel"),zut=o(" (BEiT model)"),Qut=l(),z7=a("li"),xke=a("strong"),Wut=o("bert"),Uut=o(" \u2014 "),Ele=a("a"),Hut=o("FlaxBertModel"),Jut=o(" (BERT model)"),Yut=l(),Q7=a("li"),$ke=a("strong"),Zut=o("big_bird"),Kut=o(" \u2014 "),Cle=a("a"),ept=o("FlaxBigBirdModel"),opt=o(" (BigBird model)"),rpt=l(),W7=a("li"),kke=a("strong"),tpt=o("blenderbot"),apt=o(" \u2014 "),wle=a("a"),npt=o("FlaxBlenderbotModel"),spt=o(" (Blenderbot model)"),lpt=l(),U7=a("li"),Ske=a("strong"),ipt=o("blenderbot-small"),dpt=o(" \u2014 "),Ale=a("a"),mpt=o("FlaxBlenderbotSmallModel"),cpt=o(" (BlenderbotSmall model)"),fpt=l(),H7=a("li"),Rke=a("strong"),gpt=o("clip"),hpt=o(" \u2014 "),Lle=a("a"),upt=o("FlaxCLIPModel"),ppt=o(" (CLIP model)"),_pt=l(),J7=a("li"),Pke=a("strong"),bpt=o("distilbert"),vpt=o(" \u2014 "),yle=a("a"),Fpt=o("FlaxDistilBertModel"),Tpt=o(" (DistilBERT model)"),Mpt=l(),Y7=a("li"),Bke=a("strong"),Ept=o("electra"),Cpt=o(" \u2014 "),xle=a("a"),wpt=o("FlaxElectraModel"),Apt=o(" (ELECTRA model)"),Lpt=l(),Z7=a("li"),Ike=a("strong"),ypt=o("gpt2"),xpt=o(" \u2014 "),$le=a("a"),$pt=o("FlaxGPT2Model"),kpt=o(" (OpenAI GPT-2 model)"),Spt=l(),K7=a("li"),Nke=a("strong"),Rpt=o("gpt_neo"),Ppt=o(" \u2014 "),kle=a("a"),Bpt=o("FlaxGPTNeoModel"),Ipt=o(" (GPT Neo model)"),Npt=l(),e8=a("li"),qke=a("strong"),qpt=o("gptj"),Dpt=o(" \u2014 "),Sle=a("a"),jpt=o("FlaxGPTJModel"),Gpt=o(" (GPT-J model)"),Opt=l(),o8=a("li"),Dke=a("strong"),Vpt=o("longt5"),Xpt=o(" \u2014 "),Rle=a("a"),zpt=o("FlaxLongT5Model"),Qpt=o(" (LongT5 model)"),Wpt=l(),r8=a("li"),jke=a("strong"),Upt=o("marian"),Hpt=o(" \u2014 "),Ple=a("a"),Jpt=o("FlaxMarianModel"),Ypt=o(" (Marian model)"),Zpt=l(),t8=a("li"),Gke=a("strong"),Kpt=o("mbart"),e_t=o(" \u2014 "),Ble=a("a"),o_t=o("FlaxMBartModel"),r_t=o(" (mBART model)"),t_t=l(),a8=a("li"),Oke=a("strong"),a_t=o("mt5"),n_t=o(" \u2014 "),Ile=a("a"),s_t=o("FlaxMT5Model"),l_t=o(" (MT5 model)"),i_t=l(),n8=a("li"),Vke=a("strong"),d_t=o("opt"),m_t=o(" \u2014 "),Nle=a("a"),c_t=o("FlaxOPTModel"),f_t=o(" (OPT model)"),g_t=l(),s8=a("li"),Xke=a("strong"),h_t=o("pegasus"),u_t=o(" \u2014 "),qle=a("a"),p_t=o("FlaxPegasusModel"),__t=o(" (Pegasus model)"),b_t=l(),l8=a("li"),zke=a("strong"),v_t=o("roberta"),F_t=o(" \u2014 "),Dle=a("a"),T_t=o("FlaxRobertaModel"),M_t=o(" (RoBERTa model)"),E_t=l(),i8=a("li"),Qke=a("strong"),C_t=o("roformer"),w_t=o(" \u2014 "),jle=a("a"),A_t=o("FlaxRoFormerModel"),L_t=o(" (RoFormer model)"),y_t=l(),d8=a("li"),Wke=a("strong"),x_t=o("t5"),$_t=o(" \u2014 "),Gle=a("a"),k_t=o("FlaxT5Model"),S_t=o(" (T5 model)"),R_t=l(),m8=a("li"),Uke=a("strong"),P_t=o("vision-text-dual-encoder"),B_t=o(" \u2014 "),Ole=a("a"),I_t=o("FlaxVisionTextDualEncoderModel"),N_t=o(" (VisionTextDualEncoder model)"),q_t=l(),c8=a("li"),Hke=a("strong"),D_t=o("vit"),j_t=o(" \u2014 "),Vle=a("a"),G_t=o("FlaxViTModel"),O_t=o(" (ViT model)"),V_t=l(),f8=a("li"),Jke=a("strong"),X_t=o("wav2vec2"),z_t=o(" \u2014 "),Xle=a("a"),Q_t=o("FlaxWav2Vec2Model"),W_t=o(" (Wav2Vec2 model)"),U_t=l(),g8=a("li"),Yke=a("strong"),H_t=o("xglm"),J_t=o(" \u2014 "),zle=a("a"),Y_t=o("FlaxXGLMModel"),Z_t=o(" (XGLM model)"),K_t=l(),h8=a("li"),Zke=a("strong"),e1t=o("xlm-roberta"),o1t=o(" \u2014 "),Qle=a("a"),r1t=o("FlaxXLMRobertaModel"),t1t=o(" (XLM-RoBERTa model)"),a1t=l(),F(u8.$$.fragment),vno=l(),lf=a("h2"),p8=a("a"),Kke=a("span"),F(WP.$$.fragment),n1t=l(),eSe=a("span"),s1t=o("FlaxAutoModelForCausalLM"),Fno=l(),Lr=a("div"),F(UP.$$.fragment),l1t=l(),df=a("p"),i1t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Wle=a("a"),d1t=o("from_pretrained()"),m1t=o(" class method or the "),Ule=a("a"),c1t=o("from_config()"),f1t=o(` class
method.`),g1t=l(),HP=a("p"),h1t=o("This class cannot be instantiated directly using "),oSe=a("code"),u1t=o("__init__()"),p1t=o(" (throws an error)."),_1t=l(),ha=a("div"),F(JP.$$.fragment),b1t=l(),rSe=a("p"),v1t=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),F1t=l(),mf=a("p"),T1t=o(`Note:
Loading a model from its configuration file does `),tSe=a("strong"),M1t=o("not"),E1t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Hle=a("a"),C1t=o("from_pretrained()"),w1t=o(" to load the model weights."),A1t=l(),F(_8.$$.fragment),L1t=l(),tt=a("div"),F(YP.$$.fragment),y1t=l(),aSe=a("p"),x1t=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),$1t=l(),Zn=a("p"),k1t=o("The model class to instantiate is selected based on the "),nSe=a("code"),S1t=o("model_type"),R1t=o(` property of the config object (either
passed as an argument or loaded from `),sSe=a("code"),P1t=o("pretrained_model_name_or_path"),B1t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lSe=a("code"),I1t=o("pretrained_model_name_or_path"),N1t=o(":"),q1t=l(),$e=a("ul"),b8=a("li"),iSe=a("strong"),D1t=o("bart"),j1t=o(" \u2014 "),Jle=a("a"),G1t=o("FlaxBartForCausalLM"),O1t=o(" (BART model)"),V1t=l(),v8=a("li"),dSe=a("strong"),X1t=o("bert"),z1t=o(" \u2014 "),Yle=a("a"),Q1t=o("FlaxBertForCausalLM"),W1t=o(" (BERT model)"),U1t=l(),F8=a("li"),mSe=a("strong"),H1t=o("big_bird"),J1t=o(" \u2014 "),Zle=a("a"),Y1t=o("FlaxBigBirdForCausalLM"),Z1t=o(" (BigBird model)"),K1t=l(),T8=a("li"),cSe=a("strong"),e2t=o("electra"),o2t=o(" \u2014 "),Kle=a("a"),r2t=o("FlaxElectraForCausalLM"),t2t=o(" (ELECTRA model)"),a2t=l(),M8=a("li"),fSe=a("strong"),n2t=o("gpt2"),s2t=o(" \u2014 "),eie=a("a"),l2t=o("FlaxGPT2LMHeadModel"),i2t=o(" (OpenAI GPT-2 model)"),d2t=l(),E8=a("li"),gSe=a("strong"),m2t=o("gpt_neo"),c2t=o(" \u2014 "),oie=a("a"),f2t=o("FlaxGPTNeoForCausalLM"),g2t=o(" (GPT Neo model)"),h2t=l(),C8=a("li"),hSe=a("strong"),u2t=o("gptj"),p2t=o(" \u2014 "),rie=a("a"),_2t=o("FlaxGPTJForCausalLM"),b2t=o(" (GPT-J model)"),v2t=l(),w8=a("li"),uSe=a("strong"),F2t=o("opt"),T2t=o(" \u2014 "),tie=a("a"),M2t=o("FlaxOPTForCausalLM"),E2t=o(" (OPT model)"),C2t=l(),A8=a("li"),pSe=a("strong"),w2t=o("roberta"),A2t=o(" \u2014 "),aie=a("a"),L2t=o("FlaxRobertaForCausalLM"),y2t=o(" (RoBERTa model)"),x2t=l(),L8=a("li"),_Se=a("strong"),$2t=o("xglm"),k2t=o(" \u2014 "),nie=a("a"),S2t=o("FlaxXGLMForCausalLM"),R2t=o(" (XGLM model)"),P2t=l(),F(y8.$$.fragment),Tno=l(),cf=a("h2"),x8=a("a"),bSe=a("span"),F(ZP.$$.fragment),B2t=l(),vSe=a("span"),I2t=o("FlaxAutoModelForPreTraining"),Mno=l(),yr=a("div"),F(KP.$$.fragment),N2t=l(),ff=a("p"),q2t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),sie=a("a"),D2t=o("from_pretrained()"),j2t=o(" class method or the "),lie=a("a"),G2t=o("from_config()"),O2t=o(` class
method.`),V2t=l(),eB=a("p"),X2t=o("This class cannot be instantiated directly using "),FSe=a("code"),z2t=o("__init__()"),Q2t=o(" (throws an error)."),W2t=l(),ua=a("div"),F(oB.$$.fragment),U2t=l(),TSe=a("p"),H2t=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),J2t=l(),gf=a("p"),Y2t=o(`Note:
Loading a model from its configuration file does `),MSe=a("strong"),Z2t=o("not"),K2t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iie=a("a"),ebt=o("from_pretrained()"),obt=o(" to load the model weights."),rbt=l(),F($8.$$.fragment),tbt=l(),at=a("div"),F(rB.$$.fragment),abt=l(),ESe=a("p"),nbt=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),sbt=l(),Kn=a("p"),lbt=o("The model class to instantiate is selected based on the "),CSe=a("code"),ibt=o("model_type"),dbt=o(` property of the config object (either
passed as an argument or loaded from `),wSe=a("code"),mbt=o("pretrained_model_name_or_path"),cbt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ASe=a("code"),fbt=o("pretrained_model_name_or_path"),gbt=o(":"),hbt=l(),Ee=a("ul"),k8=a("li"),LSe=a("strong"),ubt=o("albert"),pbt=o(" \u2014 "),die=a("a"),_bt=o("FlaxAlbertForPreTraining"),bbt=o(" (ALBERT model)"),vbt=l(),S8=a("li"),ySe=a("strong"),Fbt=o("bart"),Tbt=o(" \u2014 "),mie=a("a"),Mbt=o("FlaxBartForConditionalGeneration"),Ebt=o(" (BART model)"),Cbt=l(),R8=a("li"),xSe=a("strong"),wbt=o("bert"),Abt=o(" \u2014 "),cie=a("a"),Lbt=o("FlaxBertForPreTraining"),ybt=o(" (BERT model)"),xbt=l(),P8=a("li"),$Se=a("strong"),$bt=o("big_bird"),kbt=o(" \u2014 "),fie=a("a"),Sbt=o("FlaxBigBirdForPreTraining"),Rbt=o(" (BigBird model)"),Pbt=l(),B8=a("li"),kSe=a("strong"),Bbt=o("electra"),Ibt=o(" \u2014 "),gie=a("a"),Nbt=o("FlaxElectraForPreTraining"),qbt=o(" (ELECTRA model)"),Dbt=l(),I8=a("li"),SSe=a("strong"),jbt=o("longt5"),Gbt=o(" \u2014 "),hie=a("a"),Obt=o("FlaxLongT5ForConditionalGeneration"),Vbt=o(" (LongT5 model)"),Xbt=l(),N8=a("li"),RSe=a("strong"),zbt=o("mbart"),Qbt=o(" \u2014 "),uie=a("a"),Wbt=o("FlaxMBartForConditionalGeneration"),Ubt=o(" (mBART model)"),Hbt=l(),q8=a("li"),PSe=a("strong"),Jbt=o("mt5"),Ybt=o(" \u2014 "),pie=a("a"),Zbt=o("FlaxMT5ForConditionalGeneration"),Kbt=o(" (MT5 model)"),evt=l(),D8=a("li"),BSe=a("strong"),ovt=o("roberta"),rvt=o(" \u2014 "),_ie=a("a"),tvt=o("FlaxRobertaForMaskedLM"),avt=o(" (RoBERTa model)"),nvt=l(),j8=a("li"),ISe=a("strong"),svt=o("roformer"),lvt=o(" \u2014 "),bie=a("a"),ivt=o("FlaxRoFormerForMaskedLM"),dvt=o(" (RoFormer model)"),mvt=l(),G8=a("li"),NSe=a("strong"),cvt=o("t5"),fvt=o(" \u2014 "),vie=a("a"),gvt=o("FlaxT5ForConditionalGeneration"),hvt=o(" (T5 model)"),uvt=l(),O8=a("li"),qSe=a("strong"),pvt=o("wav2vec2"),_vt=o(" \u2014 "),Fie=a("a"),bvt=o("FlaxWav2Vec2ForPreTraining"),vvt=o(" (Wav2Vec2 model)"),Fvt=l(),V8=a("li"),DSe=a("strong"),Tvt=o("xlm-roberta"),Mvt=o(" \u2014 "),Tie=a("a"),Evt=o("FlaxXLMRobertaForMaskedLM"),Cvt=o(" (XLM-RoBERTa model)"),wvt=l(),F(X8.$$.fragment),Eno=l(),hf=a("h2"),z8=a("a"),jSe=a("span"),F(tB.$$.fragment),Avt=l(),GSe=a("span"),Lvt=o("FlaxAutoModelForMaskedLM"),Cno=l(),xr=a("div"),F(aB.$$.fragment),yvt=l(),uf=a("p"),xvt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Mie=a("a"),$vt=o("from_pretrained()"),kvt=o(" class method or the "),Eie=a("a"),Svt=o("from_config()"),Rvt=o(` class
method.`),Pvt=l(),nB=a("p"),Bvt=o("This class cannot be instantiated directly using "),OSe=a("code"),Ivt=o("__init__()"),Nvt=o(" (throws an error)."),qvt=l(),pa=a("div"),F(sB.$$.fragment),Dvt=l(),VSe=a("p"),jvt=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Gvt=l(),pf=a("p"),Ovt=o(`Note:
Loading a model from its configuration file does `),XSe=a("strong"),Vvt=o("not"),Xvt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Cie=a("a"),zvt=o("from_pretrained()"),Qvt=o(" to load the model weights."),Wvt=l(),F(Q8.$$.fragment),Uvt=l(),nt=a("div"),F(lB.$$.fragment),Hvt=l(),zSe=a("p"),Jvt=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Yvt=l(),es=a("p"),Zvt=o("The model class to instantiate is selected based on the "),QSe=a("code"),Kvt=o("model_type"),eFt=o(` property of the config object (either
passed as an argument or loaded from `),WSe=a("code"),oFt=o("pretrained_model_name_or_path"),rFt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),USe=a("code"),tFt=o("pretrained_model_name_or_path"),aFt=o(":"),nFt=l(),ke=a("ul"),W8=a("li"),HSe=a("strong"),sFt=o("albert"),lFt=o(" \u2014 "),wie=a("a"),iFt=o("FlaxAlbertForMaskedLM"),dFt=o(" (ALBERT model)"),mFt=l(),U8=a("li"),JSe=a("strong"),cFt=o("bart"),fFt=o(" \u2014 "),Aie=a("a"),gFt=o("FlaxBartForConditionalGeneration"),hFt=o(" (BART model)"),uFt=l(),H8=a("li"),YSe=a("strong"),pFt=o("bert"),_Ft=o(" \u2014 "),Lie=a("a"),bFt=o("FlaxBertForMaskedLM"),vFt=o(" (BERT model)"),FFt=l(),J8=a("li"),ZSe=a("strong"),TFt=o("big_bird"),MFt=o(" \u2014 "),yie=a("a"),EFt=o("FlaxBigBirdForMaskedLM"),CFt=o(" (BigBird model)"),wFt=l(),Y8=a("li"),KSe=a("strong"),AFt=o("distilbert"),LFt=o(" \u2014 "),xie=a("a"),yFt=o("FlaxDistilBertForMaskedLM"),xFt=o(" (DistilBERT model)"),$Ft=l(),Z8=a("li"),eRe=a("strong"),kFt=o("electra"),SFt=o(" \u2014 "),$ie=a("a"),RFt=o("FlaxElectraForMaskedLM"),PFt=o(" (ELECTRA model)"),BFt=l(),K8=a("li"),oRe=a("strong"),IFt=o("mbart"),NFt=o(" \u2014 "),kie=a("a"),qFt=o("FlaxMBartForConditionalGeneration"),DFt=o(" (mBART model)"),jFt=l(),eL=a("li"),rRe=a("strong"),GFt=o("roberta"),OFt=o(" \u2014 "),Sie=a("a"),VFt=o("FlaxRobertaForMaskedLM"),XFt=o(" (RoBERTa model)"),zFt=l(),oL=a("li"),tRe=a("strong"),QFt=o("roformer"),WFt=o(" \u2014 "),Rie=a("a"),UFt=o("FlaxRoFormerForMaskedLM"),HFt=o(" (RoFormer model)"),JFt=l(),rL=a("li"),aRe=a("strong"),YFt=o("xlm-roberta"),ZFt=o(" \u2014 "),Pie=a("a"),KFt=o("FlaxXLMRobertaForMaskedLM"),eTt=o(" (XLM-RoBERTa model)"),oTt=l(),F(tL.$$.fragment),wno=l(),_f=a("h2"),aL=a("a"),nRe=a("span"),F(iB.$$.fragment),rTt=l(),sRe=a("span"),tTt=o("FlaxAutoModelForSeq2SeqLM"),Ano=l(),$r=a("div"),F(dB.$$.fragment),aTt=l(),bf=a("p"),nTt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Bie=a("a"),sTt=o("from_pretrained()"),lTt=o(" class method or the "),Iie=a("a"),iTt=o("from_config()"),dTt=o(` class
method.`),mTt=l(),mB=a("p"),cTt=o("This class cannot be instantiated directly using "),lRe=a("code"),fTt=o("__init__()"),gTt=o(" (throws an error)."),hTt=l(),_a=a("div"),F(cB.$$.fragment),uTt=l(),iRe=a("p"),pTt=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),_Tt=l(),vf=a("p"),bTt=o(`Note:
Loading a model from its configuration file does `),dRe=a("strong"),vTt=o("not"),FTt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Nie=a("a"),TTt=o("from_pretrained()"),MTt=o(" to load the model weights."),ETt=l(),F(nL.$$.fragment),CTt=l(),st=a("div"),F(fB.$$.fragment),wTt=l(),mRe=a("p"),ATt=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),LTt=l(),os=a("p"),yTt=o("The model class to instantiate is selected based on the "),cRe=a("code"),xTt=o("model_type"),$Tt=o(` property of the config object (either
passed as an argument or loaded from `),fRe=a("code"),kTt=o("pretrained_model_name_or_path"),STt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gRe=a("code"),RTt=o("pretrained_model_name_or_path"),PTt=o(":"),BTt=l(),Se=a("ul"),sL=a("li"),hRe=a("strong"),ITt=o("bart"),NTt=o(" \u2014 "),qie=a("a"),qTt=o("FlaxBartForConditionalGeneration"),DTt=o(" (BART model)"),jTt=l(),lL=a("li"),uRe=a("strong"),GTt=o("blenderbot"),OTt=o(" \u2014 "),Die=a("a"),VTt=o("FlaxBlenderbotForConditionalGeneration"),XTt=o(" (Blenderbot model)"),zTt=l(),iL=a("li"),pRe=a("strong"),QTt=o("blenderbot-small"),WTt=o(" \u2014 "),jie=a("a"),UTt=o("FlaxBlenderbotSmallForConditionalGeneration"),HTt=o(" (BlenderbotSmall model)"),JTt=l(),dL=a("li"),_Re=a("strong"),YTt=o("encoder-decoder"),ZTt=o(" \u2014 "),Gie=a("a"),KTt=o("FlaxEncoderDecoderModel"),eMt=o(" (Encoder decoder model)"),oMt=l(),mL=a("li"),bRe=a("strong"),rMt=o("longt5"),tMt=o(" \u2014 "),Oie=a("a"),aMt=o("FlaxLongT5ForConditionalGeneration"),nMt=o(" (LongT5 model)"),sMt=l(),cL=a("li"),vRe=a("strong"),lMt=o("marian"),iMt=o(" \u2014 "),Vie=a("a"),dMt=o("FlaxMarianMTModel"),mMt=o(" (Marian model)"),cMt=l(),fL=a("li"),FRe=a("strong"),fMt=o("mbart"),gMt=o(" \u2014 "),Xie=a("a"),hMt=o("FlaxMBartForConditionalGeneration"),uMt=o(" (mBART model)"),pMt=l(),gL=a("li"),TRe=a("strong"),_Mt=o("mt5"),bMt=o(" \u2014 "),zie=a("a"),vMt=o("FlaxMT5ForConditionalGeneration"),FMt=o(" (MT5 model)"),TMt=l(),hL=a("li"),MRe=a("strong"),MMt=o("pegasus"),EMt=o(" \u2014 "),Qie=a("a"),CMt=o("FlaxPegasusForConditionalGeneration"),wMt=o(" (Pegasus model)"),AMt=l(),uL=a("li"),ERe=a("strong"),LMt=o("t5"),yMt=o(" \u2014 "),Wie=a("a"),xMt=o("FlaxT5ForConditionalGeneration"),$Mt=o(" (T5 model)"),kMt=l(),F(pL.$$.fragment),Lno=l(),Ff=a("h2"),_L=a("a"),CRe=a("span"),F(gB.$$.fragment),SMt=l(),wRe=a("span"),RMt=o("FlaxAutoModelForSequenceClassification"),yno=l(),kr=a("div"),F(hB.$$.fragment),PMt=l(),Tf=a("p"),BMt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Uie=a("a"),IMt=o("from_pretrained()"),NMt=o(" class method or the "),Hie=a("a"),qMt=o("from_config()"),DMt=o(` class
method.`),jMt=l(),uB=a("p"),GMt=o("This class cannot be instantiated directly using "),ARe=a("code"),OMt=o("__init__()"),VMt=o(" (throws an error)."),XMt=l(),ba=a("div"),F(pB.$$.fragment),zMt=l(),LRe=a("p"),QMt=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),WMt=l(),Mf=a("p"),UMt=o(`Note:
Loading a model from its configuration file does `),yRe=a("strong"),HMt=o("not"),JMt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Jie=a("a"),YMt=o("from_pretrained()"),ZMt=o(" to load the model weights."),KMt=l(),F(bL.$$.fragment),eEt=l(),lt=a("div"),F(_B.$$.fragment),oEt=l(),xRe=a("p"),rEt=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),tEt=l(),rs=a("p"),aEt=o("The model class to instantiate is selected based on the "),$Re=a("code"),nEt=o("model_type"),sEt=o(` property of the config object (either
passed as an argument or loaded from `),kRe=a("code"),lEt=o("pretrained_model_name_or_path"),iEt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),SRe=a("code"),dEt=o("pretrained_model_name_or_path"),mEt=o(":"),cEt=l(),Re=a("ul"),vL=a("li"),RRe=a("strong"),fEt=o("albert"),gEt=o(" \u2014 "),Yie=a("a"),hEt=o("FlaxAlbertForSequenceClassification"),uEt=o(" (ALBERT model)"),pEt=l(),FL=a("li"),PRe=a("strong"),_Et=o("bart"),bEt=o(" \u2014 "),Zie=a("a"),vEt=o("FlaxBartForSequenceClassification"),FEt=o(" (BART model)"),TEt=l(),TL=a("li"),BRe=a("strong"),MEt=o("bert"),EEt=o(" \u2014 "),Kie=a("a"),CEt=o("FlaxBertForSequenceClassification"),wEt=o(" (BERT model)"),AEt=l(),ML=a("li"),IRe=a("strong"),LEt=o("big_bird"),yEt=o(" \u2014 "),ede=a("a"),xEt=o("FlaxBigBirdForSequenceClassification"),$Et=o(" (BigBird model)"),kEt=l(),EL=a("li"),NRe=a("strong"),SEt=o("distilbert"),REt=o(" \u2014 "),ode=a("a"),PEt=o("FlaxDistilBertForSequenceClassification"),BEt=o(" (DistilBERT model)"),IEt=l(),CL=a("li"),qRe=a("strong"),NEt=o("electra"),qEt=o(" \u2014 "),rde=a("a"),DEt=o("FlaxElectraForSequenceClassification"),jEt=o(" (ELECTRA model)"),GEt=l(),wL=a("li"),DRe=a("strong"),OEt=o("mbart"),VEt=o(" \u2014 "),tde=a("a"),XEt=o("FlaxMBartForSequenceClassification"),zEt=o(" (mBART model)"),QEt=l(),AL=a("li"),jRe=a("strong"),WEt=o("roberta"),UEt=o(" \u2014 "),ade=a("a"),HEt=o("FlaxRobertaForSequenceClassification"),JEt=o(" (RoBERTa model)"),YEt=l(),LL=a("li"),GRe=a("strong"),ZEt=o("roformer"),KEt=o(" \u2014 "),nde=a("a"),e4t=o("FlaxRoFormerForSequenceClassification"),o4t=o(" (RoFormer model)"),r4t=l(),yL=a("li"),ORe=a("strong"),t4t=o("xlm-roberta"),a4t=o(" \u2014 "),sde=a("a"),n4t=o("FlaxXLMRobertaForSequenceClassification"),s4t=o(" (XLM-RoBERTa model)"),l4t=l(),F(xL.$$.fragment),xno=l(),Ef=a("h2"),$L=a("a"),VRe=a("span"),F(bB.$$.fragment),i4t=l(),XRe=a("span"),d4t=o("FlaxAutoModelForQuestionAnswering"),$no=l(),Sr=a("div"),F(vB.$$.fragment),m4t=l(),Cf=a("p"),c4t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),lde=a("a"),f4t=o("from_pretrained()"),g4t=o(" class method or the "),ide=a("a"),h4t=o("from_config()"),u4t=o(` class
method.`),p4t=l(),FB=a("p"),_4t=o("This class cannot be instantiated directly using "),zRe=a("code"),b4t=o("__init__()"),v4t=o(" (throws an error)."),F4t=l(),va=a("div"),F(TB.$$.fragment),T4t=l(),QRe=a("p"),M4t=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),E4t=l(),wf=a("p"),C4t=o(`Note:
Loading a model from its configuration file does `),WRe=a("strong"),w4t=o("not"),A4t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dde=a("a"),L4t=o("from_pretrained()"),y4t=o(" to load the model weights."),x4t=l(),F(kL.$$.fragment),$4t=l(),it=a("div"),F(MB.$$.fragment),k4t=l(),URe=a("p"),S4t=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),R4t=l(),ts=a("p"),P4t=o("The model class to instantiate is selected based on the "),HRe=a("code"),B4t=o("model_type"),I4t=o(` property of the config object (either
passed as an argument or loaded from `),JRe=a("code"),N4t=o("pretrained_model_name_or_path"),q4t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),YRe=a("code"),D4t=o("pretrained_model_name_or_path"),j4t=o(":"),G4t=l(),Pe=a("ul"),SL=a("li"),ZRe=a("strong"),O4t=o("albert"),V4t=o(" \u2014 "),mde=a("a"),X4t=o("FlaxAlbertForQuestionAnswering"),z4t=o(" (ALBERT model)"),Q4t=l(),RL=a("li"),KRe=a("strong"),W4t=o("bart"),U4t=o(" \u2014 "),cde=a("a"),H4t=o("FlaxBartForQuestionAnswering"),J4t=o(" (BART model)"),Y4t=l(),PL=a("li"),ePe=a("strong"),Z4t=o("bert"),K4t=o(" \u2014 "),fde=a("a"),eCt=o("FlaxBertForQuestionAnswering"),oCt=o(" (BERT model)"),rCt=l(),BL=a("li"),oPe=a("strong"),tCt=o("big_bird"),aCt=o(" \u2014 "),gde=a("a"),nCt=o("FlaxBigBirdForQuestionAnswering"),sCt=o(" (BigBird model)"),lCt=l(),IL=a("li"),rPe=a("strong"),iCt=o("distilbert"),dCt=o(" \u2014 "),hde=a("a"),mCt=o("FlaxDistilBertForQuestionAnswering"),cCt=o(" (DistilBERT model)"),fCt=l(),NL=a("li"),tPe=a("strong"),gCt=o("electra"),hCt=o(" \u2014 "),ude=a("a"),uCt=o("FlaxElectraForQuestionAnswering"),pCt=o(" (ELECTRA model)"),_Ct=l(),qL=a("li"),aPe=a("strong"),bCt=o("mbart"),vCt=o(" \u2014 "),pde=a("a"),FCt=o("FlaxMBartForQuestionAnswering"),TCt=o(" (mBART model)"),MCt=l(),DL=a("li"),nPe=a("strong"),ECt=o("roberta"),CCt=o(" \u2014 "),_de=a("a"),wCt=o("FlaxRobertaForQuestionAnswering"),ACt=o(" (RoBERTa model)"),LCt=l(),jL=a("li"),sPe=a("strong"),yCt=o("roformer"),xCt=o(" \u2014 "),bde=a("a"),$Ct=o("FlaxRoFormerForQuestionAnswering"),kCt=o(" (RoFormer model)"),SCt=l(),GL=a("li"),lPe=a("strong"),RCt=o("xlm-roberta"),PCt=o(" \u2014 "),vde=a("a"),BCt=o("FlaxXLMRobertaForQuestionAnswering"),ICt=o(" (XLM-RoBERTa model)"),NCt=l(),F(OL.$$.fragment),kno=l(),Af=a("h2"),VL=a("a"),iPe=a("span"),F(EB.$$.fragment),qCt=l(),dPe=a("span"),DCt=o("FlaxAutoModelForTokenClassification"),Sno=l(),Rr=a("div"),F(CB.$$.fragment),jCt=l(),Lf=a("p"),GCt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Fde=a("a"),OCt=o("from_pretrained()"),VCt=o(" class method or the "),Tde=a("a"),XCt=o("from_config()"),zCt=o(` class
method.`),QCt=l(),wB=a("p"),WCt=o("This class cannot be instantiated directly using "),mPe=a("code"),UCt=o("__init__()"),HCt=o(" (throws an error)."),JCt=l(),Fa=a("div"),F(AB.$$.fragment),YCt=l(),cPe=a("p"),ZCt=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),KCt=l(),yf=a("p"),e3t=o(`Note:
Loading a model from its configuration file does `),fPe=a("strong"),o3t=o("not"),r3t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Mde=a("a"),t3t=o("from_pretrained()"),a3t=o(" to load the model weights."),n3t=l(),F(XL.$$.fragment),s3t=l(),dt=a("div"),F(LB.$$.fragment),l3t=l(),gPe=a("p"),i3t=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),d3t=l(),as=a("p"),m3t=o("The model class to instantiate is selected based on the "),hPe=a("code"),c3t=o("model_type"),f3t=o(` property of the config object (either
passed as an argument or loaded from `),uPe=a("code"),g3t=o("pretrained_model_name_or_path"),h3t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pPe=a("code"),u3t=o("pretrained_model_name_or_path"),p3t=o(":"),_3t=l(),ze=a("ul"),zL=a("li"),_Pe=a("strong"),b3t=o("albert"),v3t=o(" \u2014 "),Ede=a("a"),F3t=o("FlaxAlbertForTokenClassification"),T3t=o(" (ALBERT model)"),M3t=l(),QL=a("li"),bPe=a("strong"),E3t=o("bert"),C3t=o(" \u2014 "),Cde=a("a"),w3t=o("FlaxBertForTokenClassification"),A3t=o(" (BERT model)"),L3t=l(),WL=a("li"),vPe=a("strong"),y3t=o("big_bird"),x3t=o(" \u2014 "),wde=a("a"),$3t=o("FlaxBigBirdForTokenClassification"),k3t=o(" (BigBird model)"),S3t=l(),UL=a("li"),FPe=a("strong"),R3t=o("distilbert"),P3t=o(" \u2014 "),Ade=a("a"),B3t=o("FlaxDistilBertForTokenClassification"),I3t=o(" (DistilBERT model)"),N3t=l(),HL=a("li"),TPe=a("strong"),q3t=o("electra"),D3t=o(" \u2014 "),Lde=a("a"),j3t=o("FlaxElectraForTokenClassification"),G3t=o(" (ELECTRA model)"),O3t=l(),JL=a("li"),MPe=a("strong"),V3t=o("roberta"),X3t=o(" \u2014 "),yde=a("a"),z3t=o("FlaxRobertaForTokenClassification"),Q3t=o(" (RoBERTa model)"),W3t=l(),YL=a("li"),EPe=a("strong"),U3t=o("roformer"),H3t=o(" \u2014 "),xde=a("a"),J3t=o("FlaxRoFormerForTokenClassification"),Y3t=o(" (RoFormer model)"),Z3t=l(),ZL=a("li"),CPe=a("strong"),K3t=o("xlm-roberta"),e5t=o(" \u2014 "),$de=a("a"),o5t=o("FlaxXLMRobertaForTokenClassification"),r5t=o(" (XLM-RoBERTa model)"),t5t=l(),F(KL.$$.fragment),Rno=l(),xf=a("h2"),ey=a("a"),wPe=a("span"),F(yB.$$.fragment),a5t=l(),APe=a("span"),n5t=o("FlaxAutoModelForMultipleChoice"),Pno=l(),Pr=a("div"),F(xB.$$.fragment),s5t=l(),$f=a("p"),l5t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),kde=a("a"),i5t=o("from_pretrained()"),d5t=o(" class method or the "),Sde=a("a"),m5t=o("from_config()"),c5t=o(` class
method.`),f5t=l(),$B=a("p"),g5t=o("This class cannot be instantiated directly using "),LPe=a("code"),h5t=o("__init__()"),u5t=o(" (throws an error)."),p5t=l(),Ta=a("div"),F(kB.$$.fragment),_5t=l(),yPe=a("p"),b5t=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),v5t=l(),kf=a("p"),F5t=o(`Note:
Loading a model from its configuration file does `),xPe=a("strong"),T5t=o("not"),M5t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Rde=a("a"),E5t=o("from_pretrained()"),C5t=o(" to load the model weights."),w5t=l(),F(oy.$$.fragment),A5t=l(),mt=a("div"),F(SB.$$.fragment),L5t=l(),$Pe=a("p"),y5t=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),x5t=l(),ns=a("p"),$5t=o("The model class to instantiate is selected based on the "),kPe=a("code"),k5t=o("model_type"),S5t=o(` property of the config object (either
passed as an argument or loaded from `),SPe=a("code"),R5t=o("pretrained_model_name_or_path"),P5t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RPe=a("code"),B5t=o("pretrained_model_name_or_path"),I5t=o(":"),N5t=l(),Qe=a("ul"),ry=a("li"),PPe=a("strong"),q5t=o("albert"),D5t=o(" \u2014 "),Pde=a("a"),j5t=o("FlaxAlbertForMultipleChoice"),G5t=o(" (ALBERT model)"),O5t=l(),ty=a("li"),BPe=a("strong"),V5t=o("bert"),X5t=o(" \u2014 "),Bde=a("a"),z5t=o("FlaxBertForMultipleChoice"),Q5t=o(" (BERT model)"),W5t=l(),ay=a("li"),IPe=a("strong"),U5t=o("big_bird"),H5t=o(" \u2014 "),Ide=a("a"),J5t=o("FlaxBigBirdForMultipleChoice"),Y5t=o(" (BigBird model)"),Z5t=l(),ny=a("li"),NPe=a("strong"),K5t=o("distilbert"),e0t=o(" \u2014 "),Nde=a("a"),o0t=o("FlaxDistilBertForMultipleChoice"),r0t=o(" (DistilBERT model)"),t0t=l(),sy=a("li"),qPe=a("strong"),a0t=o("electra"),n0t=o(" \u2014 "),qde=a("a"),s0t=o("FlaxElectraForMultipleChoice"),l0t=o(" (ELECTRA model)"),i0t=l(),ly=a("li"),DPe=a("strong"),d0t=o("roberta"),m0t=o(" \u2014 "),Dde=a("a"),c0t=o("FlaxRobertaForMultipleChoice"),f0t=o(" (RoBERTa model)"),g0t=l(),iy=a("li"),jPe=a("strong"),h0t=o("roformer"),u0t=o(" \u2014 "),jde=a("a"),p0t=o("FlaxRoFormerForMultipleChoice"),_0t=o(" (RoFormer model)"),b0t=l(),dy=a("li"),GPe=a("strong"),v0t=o("xlm-roberta"),F0t=o(" \u2014 "),Gde=a("a"),T0t=o("FlaxXLMRobertaForMultipleChoice"),M0t=o(" (XLM-RoBERTa model)"),E0t=l(),F(my.$$.fragment),Bno=l(),Sf=a("h2"),cy=a("a"),OPe=a("span"),F(RB.$$.fragment),C0t=l(),VPe=a("span"),w0t=o("FlaxAutoModelForNextSentencePrediction"),Ino=l(),Br=a("div"),F(PB.$$.fragment),A0t=l(),Rf=a("p"),L0t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Ode=a("a"),y0t=o("from_pretrained()"),x0t=o(" class method or the "),Vde=a("a"),$0t=o("from_config()"),k0t=o(` class
method.`),S0t=l(),BB=a("p"),R0t=o("This class cannot be instantiated directly using "),XPe=a("code"),P0t=o("__init__()"),B0t=o(" (throws an error)."),I0t=l(),Ma=a("div"),F(IB.$$.fragment),N0t=l(),zPe=a("p"),q0t=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),D0t=l(),Pf=a("p"),j0t=o(`Note:
Loading a model from its configuration file does `),QPe=a("strong"),G0t=o("not"),O0t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Xde=a("a"),V0t=o("from_pretrained()"),X0t=o(" to load the model weights."),z0t=l(),F(fy.$$.fragment),Q0t=l(),ct=a("div"),F(NB.$$.fragment),W0t=l(),WPe=a("p"),U0t=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),H0t=l(),ss=a("p"),J0t=o("The model class to instantiate is selected based on the "),UPe=a("code"),Y0t=o("model_type"),Z0t=o(` property of the config object (either
passed as an argument or loaded from `),HPe=a("code"),K0t=o("pretrained_model_name_or_path"),ewt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JPe=a("code"),owt=o("pretrained_model_name_or_path"),rwt=o(":"),twt=l(),YPe=a("ul"),gy=a("li"),ZPe=a("strong"),awt=o("bert"),nwt=o(" \u2014 "),zde=a("a"),swt=o("FlaxBertForNextSentencePrediction"),lwt=o(" (BERT model)"),iwt=l(),F(hy.$$.fragment),Nno=l(),Bf=a("h2"),uy=a("a"),KPe=a("span"),F(qB.$$.fragment),dwt=l(),eBe=a("span"),mwt=o("FlaxAutoModelForImageClassification"),qno=l(),Ir=a("div"),F(DB.$$.fragment),cwt=l(),If=a("p"),fwt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Qde=a("a"),gwt=o("from_pretrained()"),hwt=o(" class method or the "),Wde=a("a"),uwt=o("from_config()"),pwt=o(` class
method.`),_wt=l(),jB=a("p"),bwt=o("This class cannot be instantiated directly using "),oBe=a("code"),vwt=o("__init__()"),Fwt=o(" (throws an error)."),Twt=l(),Ea=a("div"),F(GB.$$.fragment),Mwt=l(),rBe=a("p"),Ewt=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Cwt=l(),Nf=a("p"),wwt=o(`Note:
Loading a model from its configuration file does `),tBe=a("strong"),Awt=o("not"),Lwt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ude=a("a"),ywt=o("from_pretrained()"),xwt=o(" to load the model weights."),$wt=l(),F(py.$$.fragment),kwt=l(),ft=a("div"),F(OB.$$.fragment),Swt=l(),aBe=a("p"),Rwt=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Pwt=l(),ls=a("p"),Bwt=o("The model class to instantiate is selected based on the "),nBe=a("code"),Iwt=o("model_type"),Nwt=o(` property of the config object (either
passed as an argument or loaded from `),sBe=a("code"),qwt=o("pretrained_model_name_or_path"),Dwt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lBe=a("code"),jwt=o("pretrained_model_name_or_path"),Gwt=o(":"),Owt=l(),VB=a("ul"),_y=a("li"),iBe=a("strong"),Vwt=o("beit"),Xwt=o(" \u2014 "),Hde=a("a"),zwt=o("FlaxBeitForImageClassification"),Qwt=o(" (BEiT model)"),Wwt=l(),by=a("li"),dBe=a("strong"),Uwt=o("vit"),Hwt=o(" \u2014 "),Jde=a("a"),Jwt=o("FlaxViTForImageClassification"),Ywt=o(" (ViT model)"),Zwt=l(),F(vy.$$.fragment),Dno=l(),qf=a("h2"),Fy=a("a"),mBe=a("span"),F(XB.$$.fragment),Kwt=l(),cBe=a("span"),eAt=o("FlaxAutoModelForVision2Seq"),jno=l(),Nr=a("div"),F(zB.$$.fragment),oAt=l(),Df=a("p"),rAt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Yde=a("a"),tAt=o("from_pretrained()"),aAt=o(" class method or the "),Zde=a("a"),nAt=o("from_config()"),sAt=o(` class
method.`),lAt=l(),QB=a("p"),iAt=o("This class cannot be instantiated directly using "),fBe=a("code"),dAt=o("__init__()"),mAt=o(" (throws an error)."),cAt=l(),Ca=a("div"),F(WB.$$.fragment),fAt=l(),gBe=a("p"),gAt=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),hAt=l(),jf=a("p"),uAt=o(`Note:
Loading a model from its configuration file does `),hBe=a("strong"),pAt=o("not"),_At=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Kde=a("a"),bAt=o("from_pretrained()"),vAt=o(" to load the model weights."),FAt=l(),F(Ty.$$.fragment),TAt=l(),gt=a("div"),F(UB.$$.fragment),MAt=l(),uBe=a("p"),EAt=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),CAt=l(),is=a("p"),wAt=o("The model class to instantiate is selected based on the "),pBe=a("code"),AAt=o("model_type"),LAt=o(` property of the config object (either
passed as an argument or loaded from `),_Be=a("code"),yAt=o("pretrained_model_name_or_path"),xAt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bBe=a("code"),$At=o("pretrained_model_name_or_path"),kAt=o(":"),SAt=l(),vBe=a("ul"),My=a("li"),FBe=a("strong"),RAt=o("vision-encoder-decoder"),PAt=o(" \u2014 "),eme=a("a"),BAt=o("FlaxVisionEncoderDecoderModel"),IAt=o(" (Vision Encoder decoder model)"),NAt=l(),F(Ey.$$.fragment),this.h()},l(c){const _=M3a('[data-svelte="svelte-1phssyn"]',document.head);g=n(_,"META",{name:!0,content:!0}),_.forEach(t),v=i(c),u=n(c,"H1",{class:!0});var HB=s(u);f=n(HB,"A",{id:!0,class:!0,href:!0});var TBe=s(f);p=n(TBe,"SPAN",{});var MBe=s(p);T(d.$$.fragment,MBe),MBe.forEach(t),TBe.forEach(t),h=i(HB),$o=n(HB,"SPAN",{});var EBe=s($o);_d=r(EBe,"Auto Classes"),EBe.forEach(t),HB.forEach(t),Xf=i(c),Tt=n(c,"P",{});var JB=s(Tt);bd=r(JB,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),vd=n(JB,"CODE",{});var CBe=s(vd);n$=r(CBe,"from_pretrained()"),CBe.forEach(t),zf=r(JB,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),JB.forEach(t),Xe=i(c),He=n(c,"P",{});var ds=s(He);Fd=r(ds,"Instantiating one of "),ms=n(ds,"A",{href:!0});var wBe=s(ms);s$=r(wBe,"AutoConfig"),wBe.forEach(t),cs=r(ds,", "),fs=n(ds,"A",{href:!0});var ABe=s(fs);l$=r(ABe,"AutoModel"),ABe.forEach(t),Td=r(ds,`, and
`),gs=n(ds,"A",{href:!0});var LBe=s(gs);i$=r(LBe,"AutoTokenizer"),LBe.forEach(t),Md=r(ds," will directly create a class of the relevant architecture. For instance"),ds.forEach(t),Qf=i(c),T(on.$$.fragment,c),Je=i(c),Ae=n(c,"P",{});var YB=s(Ae);TN=r(YB,"will create a model that is an instance of "),Ed=n(YB,"A",{href:!0});var yBe=s(Ed);MN=r(yBe,"BertModel"),yBe.forEach(t),EN=r(YB,"."),YB.forEach(t),ko=i(c),rn=n(c,"P",{});var ZB=s(rn);CN=r(ZB,"There is one class of "),Wf=n(ZB,"CODE",{});var xBe=s(Wf);wN=r(xBe,"AutoModel"),xBe.forEach(t),dio=r(ZB," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),ZB.forEach(t),Cto=i(c),Cd=n(c,"H2",{class:!0});var KB=s(Cd);Uf=n(KB,"A",{id:!0,class:!0,href:!0});var $Be=s(Uf);dfe=n($Be,"SPAN",{});var kBe=s(dfe);T(d$.$$.fragment,kBe),kBe.forEach(t),$Be.forEach(t),mio=i(KB),mfe=n(KB,"SPAN",{});var SBe=s(mfe);cio=r(SBe,"Extending the Auto Classes"),SBe.forEach(t),KB.forEach(t),wto=i(c),hs=n(c,"P",{});var Gf=s(hs);fio=r(Gf,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),cfe=n(Gf,"CODE",{});var RBe=s(cfe);gio=r(RBe,"NewModel"),RBe.forEach(t),hio=r(Gf,", make sure you have a "),ffe=n(Gf,"CODE",{});var PBe=s(ffe);uio=r(PBe,"NewModelConfig"),PBe.forEach(t),pio=r(Gf,` then you can add those to the auto
classes like this:`),Gf.forEach(t),Ato=i(c),T(m$.$$.fragment,c),Lto=i(c),AN=n(c,"P",{});var BBe=s(AN);_io=r(BBe,"You will then be able to use the auto classes like you would usually do!"),BBe.forEach(t),yto=i(c),T(Hf.$$.fragment,c),xto=i(c),wd=n(c,"H2",{class:!0});var eI=s(wd);Jf=n(eI,"A",{id:!0,class:!0,href:!0});var IBe=s(Jf);gfe=n(IBe,"SPAN",{});var NBe=s(gfe);T(c$.$$.fragment,NBe),NBe.forEach(t),IBe.forEach(t),bio=i(eI),hfe=n(eI,"SPAN",{});var qBe=s(hfe);vio=r(qBe,"AutoConfig"),qBe.forEach(t),eI.forEach(t),$to=i(c),So=n(c,"DIV",{class:!0});var vt=s(So);T(f$.$$.fragment,vt),Fio=i(vt),g$=n(vt,"P",{});var oI=s(g$);Tio=r(oI,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),LN=n(oI,"A",{href:!0});var DBe=s(LN);Mio=r(DBe,"from_pretrained()"),DBe.forEach(t),Eio=r(oI," class method."),oI.forEach(t),Cio=i(vt),h$=n(vt,"P",{});var rI=s(h$);wio=r(rI,"This class cannot be instantiated directly using "),ufe=n(rI,"CODE",{});var jBe=s(ufe);Aio=r(jBe,"__init__()"),jBe.forEach(t),Lio=r(rI," (throws an error)."),rI.forEach(t),yio=i(vt),qr=n(vt,"DIV",{class:!0});var Ft=s(qr);T(u$.$$.fragment,Ft),xio=i(Ft),pfe=n(Ft,"P",{});var GBe=s(pfe);$io=r(GBe,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),GBe.forEach(t),kio=i(Ft),Ad=n(Ft,"P",{});var Of=s(Ad);Sio=r(Of,"The configuration class to instantiate is selected based on the "),_fe=n(Of,"CODE",{});var OBe=s(_fe);Rio=r(OBe,"model_type"),OBe.forEach(t),Pio=r(Of,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),bfe=n(Of,"CODE",{});var VBe=s(bfe);Bio=r(VBe,"pretrained_model_name_or_path"),VBe.forEach(t),Iio=r(Of,":"),Of.forEach(t),Nio=i(Ft),A=n(Ft,"UL",{});var L=s(A);Yf=n(L,"LI",{});var Cy=s(Yf);vfe=n(Cy,"STRONG",{});var XBe=s(vfe);qio=r(XBe,"albert"),XBe.forEach(t),Dio=r(Cy," \u2014 "),yN=n(Cy,"A",{href:!0});var zBe=s(yN);jio=r(zBe,"AlbertConfig"),zBe.forEach(t),Gio=r(Cy," (ALBERT model)"),Cy.forEach(t),Oio=i(L),Zf=n(L,"LI",{});var wy=s(Zf);Ffe=n(wy,"STRONG",{});var QBe=s(Ffe);Vio=r(QBe,"bart"),QBe.forEach(t),Xio=r(wy," \u2014 "),xN=n(wy,"A",{href:!0});var WBe=s(xN);zio=r(WBe,"BartConfig"),WBe.forEach(t),Qio=r(wy," (BART model)"),wy.forEach(t),Wio=i(L),Kf=n(L,"LI",{});var Ay=s(Kf);Tfe=n(Ay,"STRONG",{});var UBe=s(Tfe);Uio=r(UBe,"beit"),UBe.forEach(t),Hio=r(Ay," \u2014 "),$N=n(Ay,"A",{href:!0});var HBe=s($N);Jio=r(HBe,"BeitConfig"),HBe.forEach(t),Yio=r(Ay," (BEiT model)"),Ay.forEach(t),Zio=i(L),eg=n(L,"LI",{});var Ly=s(eg);Mfe=n(Ly,"STRONG",{});var JBe=s(Mfe);Kio=r(JBe,"bert"),JBe.forEach(t),edo=r(Ly," \u2014 "),kN=n(Ly,"A",{href:!0});var YBe=s(kN);odo=r(YBe,"BertConfig"),YBe.forEach(t),rdo=r(Ly," (BERT model)"),Ly.forEach(t),tdo=i(L),og=n(L,"LI",{});var yy=s(og);Efe=n(yy,"STRONG",{});var ZBe=s(Efe);ado=r(ZBe,"bert-generation"),ZBe.forEach(t),ndo=r(yy," \u2014 "),SN=n(yy,"A",{href:!0});var KBe=s(SN);sdo=r(KBe,"BertGenerationConfig"),KBe.forEach(t),ldo=r(yy," (Bert Generation model)"),yy.forEach(t),ido=i(L),rg=n(L,"LI",{});var xy=s(rg);Cfe=n(xy,"STRONG",{});var eIe=s(Cfe);ddo=r(eIe,"big_bird"),eIe.forEach(t),mdo=r(xy," \u2014 "),RN=n(xy,"A",{href:!0});var oIe=s(RN);cdo=r(oIe,"BigBirdConfig"),oIe.forEach(t),fdo=r(xy," (BigBird model)"),xy.forEach(t),gdo=i(L),tg=n(L,"LI",{});var $y=s(tg);wfe=n($y,"STRONG",{});var rIe=s(wfe);hdo=r(rIe,"bigbird_pegasus"),rIe.forEach(t),udo=r($y," \u2014 "),PN=n($y,"A",{href:!0});var tIe=s(PN);pdo=r(tIe,"BigBirdPegasusConfig"),tIe.forEach(t),_do=r($y," (BigBird-Pegasus model)"),$y.forEach(t),bdo=i(L),ag=n(L,"LI",{});var ky=s(ag);Afe=n(ky,"STRONG",{});var aIe=s(Afe);vdo=r(aIe,"blenderbot"),aIe.forEach(t),Fdo=r(ky," \u2014 "),BN=n(ky,"A",{href:!0});var nIe=s(BN);Tdo=r(nIe,"BlenderbotConfig"),nIe.forEach(t),Mdo=r(ky," (Blenderbot model)"),ky.forEach(t),Edo=i(L),ng=n(L,"LI",{});var Sy=s(ng);Lfe=n(Sy,"STRONG",{});var sIe=s(Lfe);Cdo=r(sIe,"blenderbot-small"),sIe.forEach(t),wdo=r(Sy," \u2014 "),IN=n(Sy,"A",{href:!0});var lIe=s(IN);Ado=r(lIe,"BlenderbotSmallConfig"),lIe.forEach(t),Ldo=r(Sy," (BlenderbotSmall model)"),Sy.forEach(t),ydo=i(L),sg=n(L,"LI",{});var Ry=s(sg);yfe=n(Ry,"STRONG",{});var iIe=s(yfe);xdo=r(iIe,"bloom"),iIe.forEach(t),$do=r(Ry," \u2014 "),NN=n(Ry,"A",{href:!0});var dIe=s(NN);kdo=r(dIe,"BloomConfig"),dIe.forEach(t),Sdo=r(Ry," (BLOOM model)"),Ry.forEach(t),Rdo=i(L),lg=n(L,"LI",{});var Py=s(lg);xfe=n(Py,"STRONG",{});var mIe=s(xfe);Pdo=r(mIe,"camembert"),mIe.forEach(t),Bdo=r(Py," \u2014 "),qN=n(Py,"A",{href:!0});var cIe=s(qN);Ido=r(cIe,"CamembertConfig"),cIe.forEach(t),Ndo=r(Py," (CamemBERT model)"),Py.forEach(t),qdo=i(L),ig=n(L,"LI",{});var By=s(ig);$fe=n(By,"STRONG",{});var fIe=s($fe);Ddo=r(fIe,"canine"),fIe.forEach(t),jdo=r(By," \u2014 "),DN=n(By,"A",{href:!0});var gIe=s(DN);Gdo=r(gIe,"CanineConfig"),gIe.forEach(t),Odo=r(By," (CANINE model)"),By.forEach(t),Vdo=i(L),dg=n(L,"LI",{});var Iy=s(dg);kfe=n(Iy,"STRONG",{});var hIe=s(kfe);Xdo=r(hIe,"clip"),hIe.forEach(t),zdo=r(Iy," \u2014 "),jN=n(Iy,"A",{href:!0});var uIe=s(jN);Qdo=r(uIe,"CLIPConfig"),uIe.forEach(t),Wdo=r(Iy," (CLIP model)"),Iy.forEach(t),Udo=i(L),mg=n(L,"LI",{});var Ny=s(mg);Sfe=n(Ny,"STRONG",{});var pIe=s(Sfe);Hdo=r(pIe,"codegen"),pIe.forEach(t),Jdo=r(Ny," \u2014 "),GN=n(Ny,"A",{href:!0});var _Ie=s(GN);Ydo=r(_Ie,"CodeGenConfig"),_Ie.forEach(t),Zdo=r(Ny," (CodeGen model)"),Ny.forEach(t),Kdo=i(L),cg=n(L,"LI",{});var qy=s(cg);Rfe=n(qy,"STRONG",{});var bIe=s(Rfe);emo=r(bIe,"conditional_detr"),bIe.forEach(t),omo=r(qy," \u2014 "),ON=n(qy,"A",{href:!0});var vIe=s(ON);rmo=r(vIe,"ConditionalDetrConfig"),vIe.forEach(t),tmo=r(qy," (Conditional DETR model)"),qy.forEach(t),amo=i(L),fg=n(L,"LI",{});var Dy=s(fg);Pfe=n(Dy,"STRONG",{});var FIe=s(Pfe);nmo=r(FIe,"convbert"),FIe.forEach(t),smo=r(Dy," \u2014 "),VN=n(Dy,"A",{href:!0});var TIe=s(VN);lmo=r(TIe,"ConvBertConfig"),TIe.forEach(t),imo=r(Dy," (ConvBERT model)"),Dy.forEach(t),dmo=i(L),gg=n(L,"LI",{});var jy=s(gg);Bfe=n(jy,"STRONG",{});var MIe=s(Bfe);mmo=r(MIe,"convnext"),MIe.forEach(t),cmo=r(jy," \u2014 "),XN=n(jy,"A",{href:!0});var EIe=s(XN);fmo=r(EIe,"ConvNextConfig"),EIe.forEach(t),gmo=r(jy," (ConvNeXT model)"),jy.forEach(t),hmo=i(L),hg=n(L,"LI",{});var Gy=s(hg);Ife=n(Gy,"STRONG",{});var CIe=s(Ife);umo=r(CIe,"ctrl"),CIe.forEach(t),pmo=r(Gy," \u2014 "),zN=n(Gy,"A",{href:!0});var wIe=s(zN);_mo=r(wIe,"CTRLConfig"),wIe.forEach(t),bmo=r(Gy," (CTRL model)"),Gy.forEach(t),vmo=i(L),ug=n(L,"LI",{});var Oy=s(ug);Nfe=n(Oy,"STRONG",{});var AIe=s(Nfe);Fmo=r(AIe,"cvt"),AIe.forEach(t),Tmo=r(Oy," \u2014 "),QN=n(Oy,"A",{href:!0});var LIe=s(QN);Mmo=r(LIe,"CvtConfig"),LIe.forEach(t),Emo=r(Oy," (CvT model)"),Oy.forEach(t),Cmo=i(L),pg=n(L,"LI",{});var Vy=s(pg);qfe=n(Vy,"STRONG",{});var yIe=s(qfe);wmo=r(yIe,"data2vec-audio"),yIe.forEach(t),Amo=r(Vy," \u2014 "),WN=n(Vy,"A",{href:!0});var xIe=s(WN);Lmo=r(xIe,"Data2VecAudioConfig"),xIe.forEach(t),ymo=r(Vy," (Data2VecAudio model)"),Vy.forEach(t),xmo=i(L),_g=n(L,"LI",{});var Xy=s(_g);Dfe=n(Xy,"STRONG",{});var $Ie=s(Dfe);$mo=r($Ie,"data2vec-text"),$Ie.forEach(t),kmo=r(Xy," \u2014 "),UN=n(Xy,"A",{href:!0});var kIe=s(UN);Smo=r(kIe,"Data2VecTextConfig"),kIe.forEach(t),Rmo=r(Xy," (Data2VecText model)"),Xy.forEach(t),Pmo=i(L),bg=n(L,"LI",{});var zy=s(bg);jfe=n(zy,"STRONG",{});var SIe=s(jfe);Bmo=r(SIe,"data2vec-vision"),SIe.forEach(t),Imo=r(zy," \u2014 "),HN=n(zy,"A",{href:!0});var RIe=s(HN);Nmo=r(RIe,"Data2VecVisionConfig"),RIe.forEach(t),qmo=r(zy," (Data2VecVision model)"),zy.forEach(t),Dmo=i(L),vg=n(L,"LI",{});var Qy=s(vg);Gfe=n(Qy,"STRONG",{});var PIe=s(Gfe);jmo=r(PIe,"deberta"),PIe.forEach(t),Gmo=r(Qy," \u2014 "),JN=n(Qy,"A",{href:!0});var BIe=s(JN);Omo=r(BIe,"DebertaConfig"),BIe.forEach(t),Vmo=r(Qy," (DeBERTa model)"),Qy.forEach(t),Xmo=i(L),Fg=n(L,"LI",{});var Wy=s(Fg);Ofe=n(Wy,"STRONG",{});var IIe=s(Ofe);zmo=r(IIe,"deberta-v2"),IIe.forEach(t),Qmo=r(Wy," \u2014 "),YN=n(Wy,"A",{href:!0});var NIe=s(YN);Wmo=r(NIe,"DebertaV2Config"),NIe.forEach(t),Umo=r(Wy," (DeBERTa-v2 model)"),Wy.forEach(t),Hmo=i(L),Tg=n(L,"LI",{});var Uy=s(Tg);Vfe=n(Uy,"STRONG",{});var qIe=s(Vfe);Jmo=r(qIe,"decision_transformer"),qIe.forEach(t),Ymo=r(Uy," \u2014 "),ZN=n(Uy,"A",{href:!0});var DIe=s(ZN);Zmo=r(DIe,"DecisionTransformerConfig"),DIe.forEach(t),Kmo=r(Uy," (Decision Transformer model)"),Uy.forEach(t),eco=i(L),Mg=n(L,"LI",{});var Hy=s(Mg);Xfe=n(Hy,"STRONG",{});var jIe=s(Xfe);oco=r(jIe,"deformable_detr"),jIe.forEach(t),rco=r(Hy," \u2014 "),KN=n(Hy,"A",{href:!0});var GIe=s(KN);tco=r(GIe,"DeformableDetrConfig"),GIe.forEach(t),aco=r(Hy," (Deformable DETR model)"),Hy.forEach(t),nco=i(L),Eg=n(L,"LI",{});var Jy=s(Eg);zfe=n(Jy,"STRONG",{});var OIe=s(zfe);sco=r(OIe,"deit"),OIe.forEach(t),lco=r(Jy," \u2014 "),eq=n(Jy,"A",{href:!0});var VIe=s(eq);ico=r(VIe,"DeiTConfig"),VIe.forEach(t),dco=r(Jy," (DeiT model)"),Jy.forEach(t),mco=i(L),Cg=n(L,"LI",{});var Yy=s(Cg);Qfe=n(Yy,"STRONG",{});var DAt=s(Qfe);cco=r(DAt,"detr"),DAt.forEach(t),fco=r(Yy," \u2014 "),oq=n(Yy,"A",{href:!0});var jAt=s(oq);gco=r(jAt,"DetrConfig"),jAt.forEach(t),hco=r(Yy," (DETR model)"),Yy.forEach(t),uco=i(L),wg=n(L,"LI",{});var XIe=s(wg);Wfe=n(XIe,"STRONG",{});var GAt=s(Wfe);pco=r(GAt,"distilbert"),GAt.forEach(t),_co=r(XIe," \u2014 "),rq=n(XIe,"A",{href:!0});var OAt=s(rq);bco=r(OAt,"DistilBertConfig"),OAt.forEach(t),vco=r(XIe," (DistilBERT model)"),XIe.forEach(t),Fco=i(L),Ag=n(L,"LI",{});var zIe=s(Ag);Ufe=n(zIe,"STRONG",{});var VAt=s(Ufe);Tco=r(VAt,"donut-swin"),VAt.forEach(t),Mco=r(zIe," \u2014 "),tq=n(zIe,"A",{href:!0});var XAt=s(tq);Eco=r(XAt,"DonutSwinConfig"),XAt.forEach(t),Cco=r(zIe," (DonutSwin model)"),zIe.forEach(t),wco=i(L),Lg=n(L,"LI",{});var QIe=s(Lg);Hfe=n(QIe,"STRONG",{});var zAt=s(Hfe);Aco=r(zAt,"dpr"),zAt.forEach(t),Lco=r(QIe," \u2014 "),aq=n(QIe,"A",{href:!0});var QAt=s(aq);yco=r(QAt,"DPRConfig"),QAt.forEach(t),xco=r(QIe," (DPR model)"),QIe.forEach(t),$co=i(L),yg=n(L,"LI",{});var WIe=s(yg);Jfe=n(WIe,"STRONG",{});var WAt=s(Jfe);kco=r(WAt,"dpt"),WAt.forEach(t),Sco=r(WIe," \u2014 "),nq=n(WIe,"A",{href:!0});var UAt=s(nq);Rco=r(UAt,"DPTConfig"),UAt.forEach(t),Pco=r(WIe," (DPT model)"),WIe.forEach(t),Bco=i(L),xg=n(L,"LI",{});var UIe=s(xg);Yfe=n(UIe,"STRONG",{});var HAt=s(Yfe);Ico=r(HAt,"electra"),HAt.forEach(t),Nco=r(UIe," \u2014 "),sq=n(UIe,"A",{href:!0});var JAt=s(sq);qco=r(JAt,"ElectraConfig"),JAt.forEach(t),Dco=r(UIe," (ELECTRA model)"),UIe.forEach(t),jco=i(L),$g=n(L,"LI",{});var HIe=s($g);Zfe=n(HIe,"STRONG",{});var YAt=s(Zfe);Gco=r(YAt,"encoder-decoder"),YAt.forEach(t),Oco=r(HIe," \u2014 "),lq=n(HIe,"A",{href:!0});var ZAt=s(lq);Vco=r(ZAt,"EncoderDecoderConfig"),ZAt.forEach(t),Xco=r(HIe," (Encoder decoder model)"),HIe.forEach(t),zco=i(L),kg=n(L,"LI",{});var JIe=s(kg);Kfe=n(JIe,"STRONG",{});var KAt=s(Kfe);Qco=r(KAt,"ernie"),KAt.forEach(t),Wco=r(JIe," \u2014 "),iq=n(JIe,"A",{href:!0});var e6t=s(iq);Uco=r(e6t,"ErnieConfig"),e6t.forEach(t),Hco=r(JIe," (ERNIE model)"),JIe.forEach(t),Jco=i(L),Sg=n(L,"LI",{});var YIe=s(Sg);ege=n(YIe,"STRONG",{});var o6t=s(ege);Yco=r(o6t,"esm"),o6t.forEach(t),Zco=r(YIe," \u2014 "),dq=n(YIe,"A",{href:!0});var r6t=s(dq);Kco=r(r6t,"EsmConfig"),r6t.forEach(t),efo=r(YIe," (ESM model)"),YIe.forEach(t),ofo=i(L),Rg=n(L,"LI",{});var ZIe=s(Rg);oge=n(ZIe,"STRONG",{});var t6t=s(oge);rfo=r(t6t,"flaubert"),t6t.forEach(t),tfo=r(ZIe," \u2014 "),mq=n(ZIe,"A",{href:!0});var a6t=s(mq);afo=r(a6t,"FlaubertConfig"),a6t.forEach(t),nfo=r(ZIe," (FlauBERT model)"),ZIe.forEach(t),sfo=i(L),Pg=n(L,"LI",{});var KIe=s(Pg);rge=n(KIe,"STRONG",{});var n6t=s(rge);lfo=r(n6t,"flava"),n6t.forEach(t),ifo=r(KIe," \u2014 "),cq=n(KIe,"A",{href:!0});var s6t=s(cq);dfo=r(s6t,"FlavaConfig"),s6t.forEach(t),mfo=r(KIe," (FLAVA model)"),KIe.forEach(t),cfo=i(L),Bg=n(L,"LI",{});var eNe=s(Bg);tge=n(eNe,"STRONG",{});var l6t=s(tge);ffo=r(l6t,"fnet"),l6t.forEach(t),gfo=r(eNe," \u2014 "),fq=n(eNe,"A",{href:!0});var i6t=s(fq);hfo=r(i6t,"FNetConfig"),i6t.forEach(t),ufo=r(eNe," (FNet model)"),eNe.forEach(t),pfo=i(L),Ig=n(L,"LI",{});var oNe=s(Ig);age=n(oNe,"STRONG",{});var d6t=s(age);_fo=r(d6t,"fsmt"),d6t.forEach(t),bfo=r(oNe," \u2014 "),gq=n(oNe,"A",{href:!0});var m6t=s(gq);vfo=r(m6t,"FSMTConfig"),m6t.forEach(t),Ffo=r(oNe," (FairSeq Machine-Translation model)"),oNe.forEach(t),Tfo=i(L),Ng=n(L,"LI",{});var rNe=s(Ng);nge=n(rNe,"STRONG",{});var c6t=s(nge);Mfo=r(c6t,"funnel"),c6t.forEach(t),Efo=r(rNe," \u2014 "),hq=n(rNe,"A",{href:!0});var f6t=s(hq);Cfo=r(f6t,"FunnelConfig"),f6t.forEach(t),wfo=r(rNe," (Funnel Transformer model)"),rNe.forEach(t),Afo=i(L),qg=n(L,"LI",{});var tNe=s(qg);sge=n(tNe,"STRONG",{});var g6t=s(sge);Lfo=r(g6t,"glpn"),g6t.forEach(t),yfo=r(tNe," \u2014 "),uq=n(tNe,"A",{href:!0});var h6t=s(uq);xfo=r(h6t,"GLPNConfig"),h6t.forEach(t),$fo=r(tNe," (GLPN model)"),tNe.forEach(t),kfo=i(L),Dg=n(L,"LI",{});var aNe=s(Dg);lge=n(aNe,"STRONG",{});var u6t=s(lge);Sfo=r(u6t,"gpt2"),u6t.forEach(t),Rfo=r(aNe," \u2014 "),pq=n(aNe,"A",{href:!0});var p6t=s(pq);Pfo=r(p6t,"GPT2Config"),p6t.forEach(t),Bfo=r(aNe," (OpenAI GPT-2 model)"),aNe.forEach(t),Ifo=i(L),jg=n(L,"LI",{});var nNe=s(jg);ige=n(nNe,"STRONG",{});var _6t=s(ige);Nfo=r(_6t,"gpt_neo"),_6t.forEach(t),qfo=r(nNe," \u2014 "),_q=n(nNe,"A",{href:!0});var b6t=s(_q);Dfo=r(b6t,"GPTNeoConfig"),b6t.forEach(t),jfo=r(nNe," (GPT Neo model)"),nNe.forEach(t),Gfo=i(L),Gg=n(L,"LI",{});var sNe=s(Gg);dge=n(sNe,"STRONG",{});var v6t=s(dge);Ofo=r(v6t,"gpt_neox"),v6t.forEach(t),Vfo=r(sNe," \u2014 "),bq=n(sNe,"A",{href:!0});var F6t=s(bq);Xfo=r(F6t,"GPTNeoXConfig"),F6t.forEach(t),zfo=r(sNe," (GPT NeoX model)"),sNe.forEach(t),Qfo=i(L),Og=n(L,"LI",{});var lNe=s(Og);mge=n(lNe,"STRONG",{});var T6t=s(mge);Wfo=r(T6t,"gpt_neox_japanese"),T6t.forEach(t),Ufo=r(lNe," \u2014 "),vq=n(lNe,"A",{href:!0});var M6t=s(vq);Hfo=r(M6t,"GPTNeoXJapaneseConfig"),M6t.forEach(t),Jfo=r(lNe," (GPT NeoX Japanese model)"),lNe.forEach(t),Yfo=i(L),Vg=n(L,"LI",{});var iNe=s(Vg);cge=n(iNe,"STRONG",{});var E6t=s(cge);Zfo=r(E6t,"gptj"),E6t.forEach(t),Kfo=r(iNe," \u2014 "),Fq=n(iNe,"A",{href:!0});var C6t=s(Fq);ego=r(C6t,"GPTJConfig"),C6t.forEach(t),ogo=r(iNe," (GPT-J model)"),iNe.forEach(t),rgo=i(L),Xg=n(L,"LI",{});var dNe=s(Xg);fge=n(dNe,"STRONG",{});var w6t=s(fge);tgo=r(w6t,"groupvit"),w6t.forEach(t),ago=r(dNe," \u2014 "),Tq=n(dNe,"A",{href:!0});var A6t=s(Tq);ngo=r(A6t,"GroupViTConfig"),A6t.forEach(t),sgo=r(dNe," (GroupViT model)"),dNe.forEach(t),lgo=i(L),zg=n(L,"LI",{});var mNe=s(zg);gge=n(mNe,"STRONG",{});var L6t=s(gge);igo=r(L6t,"hubert"),L6t.forEach(t),dgo=r(mNe," \u2014 "),Mq=n(mNe,"A",{href:!0});var y6t=s(Mq);mgo=r(y6t,"HubertConfig"),y6t.forEach(t),cgo=r(mNe," (Hubert model)"),mNe.forEach(t),fgo=i(L),Qg=n(L,"LI",{});var cNe=s(Qg);hge=n(cNe,"STRONG",{});var x6t=s(hge);ggo=r(x6t,"ibert"),x6t.forEach(t),hgo=r(cNe," \u2014 "),Eq=n(cNe,"A",{href:!0});var $6t=s(Eq);ugo=r($6t,"IBertConfig"),$6t.forEach(t),pgo=r(cNe," (I-BERT model)"),cNe.forEach(t),_go=i(L),Wg=n(L,"LI",{});var fNe=s(Wg);uge=n(fNe,"STRONG",{});var k6t=s(uge);bgo=r(k6t,"imagegpt"),k6t.forEach(t),vgo=r(fNe," \u2014 "),Cq=n(fNe,"A",{href:!0});var S6t=s(Cq);Fgo=r(S6t,"ImageGPTConfig"),S6t.forEach(t),Tgo=r(fNe," (ImageGPT model)"),fNe.forEach(t),Mgo=i(L),Ug=n(L,"LI",{});var gNe=s(Ug);pge=n(gNe,"STRONG",{});var R6t=s(pge);Ego=r(R6t,"layoutlm"),R6t.forEach(t),Cgo=r(gNe," \u2014 "),wq=n(gNe,"A",{href:!0});var P6t=s(wq);wgo=r(P6t,"LayoutLMConfig"),P6t.forEach(t),Ago=r(gNe," (LayoutLM model)"),gNe.forEach(t),Lgo=i(L),Hg=n(L,"LI",{});var hNe=s(Hg);_ge=n(hNe,"STRONG",{});var B6t=s(_ge);ygo=r(B6t,"layoutlmv2"),B6t.forEach(t),xgo=r(hNe," \u2014 "),Aq=n(hNe,"A",{href:!0});var I6t=s(Aq);$go=r(I6t,"LayoutLMv2Config"),I6t.forEach(t),kgo=r(hNe," (LayoutLMv2 model)"),hNe.forEach(t),Sgo=i(L),Jg=n(L,"LI",{});var uNe=s(Jg);bge=n(uNe,"STRONG",{});var N6t=s(bge);Rgo=r(N6t,"layoutlmv3"),N6t.forEach(t),Pgo=r(uNe," \u2014 "),Lq=n(uNe,"A",{href:!0});var q6t=s(Lq);Bgo=r(q6t,"LayoutLMv3Config"),q6t.forEach(t),Igo=r(uNe," (LayoutLMv3 model)"),uNe.forEach(t),Ngo=i(L),Yg=n(L,"LI",{});var pNe=s(Yg);vge=n(pNe,"STRONG",{});var D6t=s(vge);qgo=r(D6t,"led"),D6t.forEach(t),Dgo=r(pNe," \u2014 "),yq=n(pNe,"A",{href:!0});var j6t=s(yq);jgo=r(j6t,"LEDConfig"),j6t.forEach(t),Ggo=r(pNe," (LED model)"),pNe.forEach(t),Ogo=i(L),Zg=n(L,"LI",{});var _Ne=s(Zg);Fge=n(_Ne,"STRONG",{});var G6t=s(Fge);Vgo=r(G6t,"levit"),G6t.forEach(t),Xgo=r(_Ne," \u2014 "),xq=n(_Ne,"A",{href:!0});var O6t=s(xq);zgo=r(O6t,"LevitConfig"),O6t.forEach(t),Qgo=r(_Ne," (LeViT model)"),_Ne.forEach(t),Wgo=i(L),Kg=n(L,"LI",{});var bNe=s(Kg);Tge=n(bNe,"STRONG",{});var V6t=s(Tge);Ugo=r(V6t,"lilt"),V6t.forEach(t),Hgo=r(bNe," \u2014 "),$q=n(bNe,"A",{href:!0});var X6t=s($q);Jgo=r(X6t,"LiltConfig"),X6t.forEach(t),Ygo=r(bNe," (LiLT model)"),bNe.forEach(t),Zgo=i(L),eh=n(L,"LI",{});var vNe=s(eh);Mge=n(vNe,"STRONG",{});var z6t=s(Mge);Kgo=r(z6t,"longformer"),z6t.forEach(t),eho=r(vNe," \u2014 "),kq=n(vNe,"A",{href:!0});var Q6t=s(kq);oho=r(Q6t,"LongformerConfig"),Q6t.forEach(t),rho=r(vNe," (Longformer model)"),vNe.forEach(t),tho=i(L),oh=n(L,"LI",{});var FNe=s(oh);Ege=n(FNe,"STRONG",{});var W6t=s(Ege);aho=r(W6t,"longt5"),W6t.forEach(t),nho=r(FNe," \u2014 "),Sq=n(FNe,"A",{href:!0});var U6t=s(Sq);sho=r(U6t,"LongT5Config"),U6t.forEach(t),lho=r(FNe," (LongT5 model)"),FNe.forEach(t),iho=i(L),rh=n(L,"LI",{});var TNe=s(rh);Cge=n(TNe,"STRONG",{});var H6t=s(Cge);dho=r(H6t,"luke"),H6t.forEach(t),mho=r(TNe," \u2014 "),Rq=n(TNe,"A",{href:!0});var J6t=s(Rq);cho=r(J6t,"LukeConfig"),J6t.forEach(t),fho=r(TNe," (LUKE model)"),TNe.forEach(t),gho=i(L),th=n(L,"LI",{});var MNe=s(th);wge=n(MNe,"STRONG",{});var Y6t=s(wge);hho=r(Y6t,"lxmert"),Y6t.forEach(t),uho=r(MNe," \u2014 "),Pq=n(MNe,"A",{href:!0});var Z6t=s(Pq);pho=r(Z6t,"LxmertConfig"),Z6t.forEach(t),_ho=r(MNe," (LXMERT model)"),MNe.forEach(t),bho=i(L),ah=n(L,"LI",{});var ENe=s(ah);Age=n(ENe,"STRONG",{});var K6t=s(Age);vho=r(K6t,"m2m_100"),K6t.forEach(t),Fho=r(ENe," \u2014 "),Bq=n(ENe,"A",{href:!0});var e7t=s(Bq);Tho=r(e7t,"M2M100Config"),e7t.forEach(t),Mho=r(ENe," (M2M100 model)"),ENe.forEach(t),Eho=i(L),nh=n(L,"LI",{});var CNe=s(nh);Lge=n(CNe,"STRONG",{});var o7t=s(Lge);Cho=r(o7t,"marian"),o7t.forEach(t),who=r(CNe," \u2014 "),Iq=n(CNe,"A",{href:!0});var r7t=s(Iq);Aho=r(r7t,"MarianConfig"),r7t.forEach(t),Lho=r(CNe," (Marian model)"),CNe.forEach(t),yho=i(L),sh=n(L,"LI",{});var wNe=s(sh);yge=n(wNe,"STRONG",{});var t7t=s(yge);xho=r(t7t,"markuplm"),t7t.forEach(t),$ho=r(wNe," \u2014 "),Nq=n(wNe,"A",{href:!0});var a7t=s(Nq);kho=r(a7t,"MarkupLMConfig"),a7t.forEach(t),Sho=r(wNe," (MarkupLM model)"),wNe.forEach(t),Rho=i(L),lh=n(L,"LI",{});var ANe=s(lh);xge=n(ANe,"STRONG",{});var n7t=s(xge);Pho=r(n7t,"maskformer"),n7t.forEach(t),Bho=r(ANe," \u2014 "),qq=n(ANe,"A",{href:!0});var s7t=s(qq);Iho=r(s7t,"MaskFormerConfig"),s7t.forEach(t),Nho=r(ANe," (MaskFormer model)"),ANe.forEach(t),qho=i(L),ih=n(L,"LI",{});var LNe=s(ih);$ge=n(LNe,"STRONG",{});var l7t=s($ge);Dho=r(l7t,"mbart"),l7t.forEach(t),jho=r(LNe," \u2014 "),Dq=n(LNe,"A",{href:!0});var i7t=s(Dq);Gho=r(i7t,"MBartConfig"),i7t.forEach(t),Oho=r(LNe," (mBART model)"),LNe.forEach(t),Vho=i(L),dh=n(L,"LI",{});var yNe=s(dh);kge=n(yNe,"STRONG",{});var d7t=s(kge);Xho=r(d7t,"mctct"),d7t.forEach(t),zho=r(yNe," \u2014 "),jq=n(yNe,"A",{href:!0});var m7t=s(jq);Qho=r(m7t,"MCTCTConfig"),m7t.forEach(t),Who=r(yNe," (M-CTC-T model)"),yNe.forEach(t),Uho=i(L),mh=n(L,"LI",{});var xNe=s(mh);Sge=n(xNe,"STRONG",{});var c7t=s(Sge);Hho=r(c7t,"megatron-bert"),c7t.forEach(t),Jho=r(xNe," \u2014 "),Gq=n(xNe,"A",{href:!0});var f7t=s(Gq);Yho=r(f7t,"MegatronBertConfig"),f7t.forEach(t),Zho=r(xNe," (Megatron-BERT model)"),xNe.forEach(t),Kho=i(L),ch=n(L,"LI",{});var $Ne=s(ch);Rge=n($Ne,"STRONG",{});var g7t=s(Rge);euo=r(g7t,"mobilebert"),g7t.forEach(t),ouo=r($Ne," \u2014 "),Oq=n($Ne,"A",{href:!0});var h7t=s(Oq);ruo=r(h7t,"MobileBertConfig"),h7t.forEach(t),tuo=r($Ne," (MobileBERT model)"),$Ne.forEach(t),auo=i(L),fh=n(L,"LI",{});var kNe=s(fh);Pge=n(kNe,"STRONG",{});var u7t=s(Pge);nuo=r(u7t,"mobilevit"),u7t.forEach(t),suo=r(kNe," \u2014 "),Vq=n(kNe,"A",{href:!0});var p7t=s(Vq);luo=r(p7t,"MobileViTConfig"),p7t.forEach(t),iuo=r(kNe," (MobileViT model)"),kNe.forEach(t),duo=i(L),gh=n(L,"LI",{});var SNe=s(gh);Bge=n(SNe,"STRONG",{});var _7t=s(Bge);muo=r(_7t,"mpnet"),_7t.forEach(t),cuo=r(SNe," \u2014 "),Xq=n(SNe,"A",{href:!0});var b7t=s(Xq);fuo=r(b7t,"MPNetConfig"),b7t.forEach(t),guo=r(SNe," (MPNet model)"),SNe.forEach(t),huo=i(L),hh=n(L,"LI",{});var RNe=s(hh);Ige=n(RNe,"STRONG",{});var v7t=s(Ige);uuo=r(v7t,"mt5"),v7t.forEach(t),puo=r(RNe," \u2014 "),zq=n(RNe,"A",{href:!0});var F7t=s(zq);_uo=r(F7t,"MT5Config"),F7t.forEach(t),buo=r(RNe," (MT5 model)"),RNe.forEach(t),vuo=i(L),uh=n(L,"LI",{});var PNe=s(uh);Nge=n(PNe,"STRONG",{});var T7t=s(Nge);Fuo=r(T7t,"mvp"),T7t.forEach(t),Tuo=r(PNe," \u2014 "),Qq=n(PNe,"A",{href:!0});var M7t=s(Qq);Muo=r(M7t,"MvpConfig"),M7t.forEach(t),Euo=r(PNe," (MVP model)"),PNe.forEach(t),Cuo=i(L),ph=n(L,"LI",{});var BNe=s(ph);qge=n(BNe,"STRONG",{});var E7t=s(qge);wuo=r(E7t,"nezha"),E7t.forEach(t),Auo=r(BNe," \u2014 "),Wq=n(BNe,"A",{href:!0});var C7t=s(Wq);Luo=r(C7t,"NezhaConfig"),C7t.forEach(t),yuo=r(BNe," (Nezha model)"),BNe.forEach(t),xuo=i(L),_h=n(L,"LI",{});var INe=s(_h);Dge=n(INe,"STRONG",{});var w7t=s(Dge);$uo=r(w7t,"nystromformer"),w7t.forEach(t),kuo=r(INe," \u2014 "),Uq=n(INe,"A",{href:!0});var A7t=s(Uq);Suo=r(A7t,"NystromformerConfig"),A7t.forEach(t),Ruo=r(INe," (Nystr\xF6mformer model)"),INe.forEach(t),Puo=i(L),bh=n(L,"LI",{});var NNe=s(bh);jge=n(NNe,"STRONG",{});var L7t=s(jge);Buo=r(L7t,"openai-gpt"),L7t.forEach(t),Iuo=r(NNe," \u2014 "),Hq=n(NNe,"A",{href:!0});var y7t=s(Hq);Nuo=r(y7t,"OpenAIGPTConfig"),y7t.forEach(t),quo=r(NNe," (OpenAI GPT model)"),NNe.forEach(t),Duo=i(L),vh=n(L,"LI",{});var qNe=s(vh);Gge=n(qNe,"STRONG",{});var x7t=s(Gge);juo=r(x7t,"opt"),x7t.forEach(t),Guo=r(qNe," \u2014 "),Jq=n(qNe,"A",{href:!0});var $7t=s(Jq);Ouo=r($7t,"OPTConfig"),$7t.forEach(t),Vuo=r(qNe," (OPT model)"),qNe.forEach(t),Xuo=i(L),Fh=n(L,"LI",{});var DNe=s(Fh);Oge=n(DNe,"STRONG",{});var k7t=s(Oge);zuo=r(k7t,"owlvit"),k7t.forEach(t),Quo=r(DNe," \u2014 "),Yq=n(DNe,"A",{href:!0});var S7t=s(Yq);Wuo=r(S7t,"OwlViTConfig"),S7t.forEach(t),Uuo=r(DNe," (OWL-ViT model)"),DNe.forEach(t),Huo=i(L),Th=n(L,"LI",{});var jNe=s(Th);Vge=n(jNe,"STRONG",{});var R7t=s(Vge);Juo=r(R7t,"pegasus"),R7t.forEach(t),Yuo=r(jNe," \u2014 "),Zq=n(jNe,"A",{href:!0});var P7t=s(Zq);Zuo=r(P7t,"PegasusConfig"),P7t.forEach(t),Kuo=r(jNe," (Pegasus model)"),jNe.forEach(t),epo=i(L),Mh=n(L,"LI",{});var GNe=s(Mh);Xge=n(GNe,"STRONG",{});var B7t=s(Xge);opo=r(B7t,"pegasus_x"),B7t.forEach(t),rpo=r(GNe," \u2014 "),Kq=n(GNe,"A",{href:!0});var I7t=s(Kq);tpo=r(I7t,"PegasusXConfig"),I7t.forEach(t),apo=r(GNe," (PEGASUS-X model)"),GNe.forEach(t),npo=i(L),Eh=n(L,"LI",{});var ONe=s(Eh);zge=n(ONe,"STRONG",{});var N7t=s(zge);spo=r(N7t,"perceiver"),N7t.forEach(t),lpo=r(ONe," \u2014 "),eD=n(ONe,"A",{href:!0});var q7t=s(eD);ipo=r(q7t,"PerceiverConfig"),q7t.forEach(t),dpo=r(ONe," (Perceiver model)"),ONe.forEach(t),mpo=i(L),Ch=n(L,"LI",{});var VNe=s(Ch);Qge=n(VNe,"STRONG",{});var D7t=s(Qge);cpo=r(D7t,"plbart"),D7t.forEach(t),fpo=r(VNe," \u2014 "),oD=n(VNe,"A",{href:!0});var j7t=s(oD);gpo=r(j7t,"PLBartConfig"),j7t.forEach(t),hpo=r(VNe," (PLBart model)"),VNe.forEach(t),upo=i(L),wh=n(L,"LI",{});var XNe=s(wh);Wge=n(XNe,"STRONG",{});var G7t=s(Wge);ppo=r(G7t,"poolformer"),G7t.forEach(t),_po=r(XNe," \u2014 "),rD=n(XNe,"A",{href:!0});var O7t=s(rD);bpo=r(O7t,"PoolFormerConfig"),O7t.forEach(t),vpo=r(XNe," (PoolFormer model)"),XNe.forEach(t),Fpo=i(L),Ah=n(L,"LI",{});var zNe=s(Ah);Uge=n(zNe,"STRONG",{});var V7t=s(Uge);Tpo=r(V7t,"prophetnet"),V7t.forEach(t),Mpo=r(zNe," \u2014 "),tD=n(zNe,"A",{href:!0});var X7t=s(tD);Epo=r(X7t,"ProphetNetConfig"),X7t.forEach(t),Cpo=r(zNe," (ProphetNet model)"),zNe.forEach(t),wpo=i(L),Lh=n(L,"LI",{});var QNe=s(Lh);Hge=n(QNe,"STRONG",{});var z7t=s(Hge);Apo=r(z7t,"qdqbert"),z7t.forEach(t),Lpo=r(QNe," \u2014 "),aD=n(QNe,"A",{href:!0});var Q7t=s(aD);ypo=r(Q7t,"QDQBertConfig"),Q7t.forEach(t),xpo=r(QNe," (QDQBert model)"),QNe.forEach(t),$po=i(L),yh=n(L,"LI",{});var WNe=s(yh);Jge=n(WNe,"STRONG",{});var W7t=s(Jge);kpo=r(W7t,"rag"),W7t.forEach(t),Spo=r(WNe," \u2014 "),nD=n(WNe,"A",{href:!0});var U7t=s(nD);Rpo=r(U7t,"RagConfig"),U7t.forEach(t),Ppo=r(WNe," (RAG model)"),WNe.forEach(t),Bpo=i(L),xh=n(L,"LI",{});var UNe=s(xh);Yge=n(UNe,"STRONG",{});var H7t=s(Yge);Ipo=r(H7t,"realm"),H7t.forEach(t),Npo=r(UNe," \u2014 "),sD=n(UNe,"A",{href:!0});var J7t=s(sD);qpo=r(J7t,"RealmConfig"),J7t.forEach(t),Dpo=r(UNe," (REALM model)"),UNe.forEach(t),jpo=i(L),$h=n(L,"LI",{});var HNe=s($h);Zge=n(HNe,"STRONG",{});var Y7t=s(Zge);Gpo=r(Y7t,"reformer"),Y7t.forEach(t),Opo=r(HNe," \u2014 "),lD=n(HNe,"A",{href:!0});var Z7t=s(lD);Vpo=r(Z7t,"ReformerConfig"),Z7t.forEach(t),Xpo=r(HNe," (Reformer model)"),HNe.forEach(t),zpo=i(L),kh=n(L,"LI",{});var JNe=s(kh);Kge=n(JNe,"STRONG",{});var K7t=s(Kge);Qpo=r(K7t,"regnet"),K7t.forEach(t),Wpo=r(JNe," \u2014 "),iD=n(JNe,"A",{href:!0});var e8t=s(iD);Upo=r(e8t,"RegNetConfig"),e8t.forEach(t),Hpo=r(JNe," (RegNet model)"),JNe.forEach(t),Jpo=i(L),Sh=n(L,"LI",{});var YNe=s(Sh);ehe=n(YNe,"STRONG",{});var o8t=s(ehe);Ypo=r(o8t,"rembert"),o8t.forEach(t),Zpo=r(YNe," \u2014 "),dD=n(YNe,"A",{href:!0});var r8t=s(dD);Kpo=r(r8t,"RemBertConfig"),r8t.forEach(t),e_o=r(YNe," (RemBERT model)"),YNe.forEach(t),o_o=i(L),Rh=n(L,"LI",{});var ZNe=s(Rh);ohe=n(ZNe,"STRONG",{});var t8t=s(ohe);r_o=r(t8t,"resnet"),t8t.forEach(t),t_o=r(ZNe," \u2014 "),mD=n(ZNe,"A",{href:!0});var a8t=s(mD);a_o=r(a8t,"ResNetConfig"),a8t.forEach(t),n_o=r(ZNe," (ResNet model)"),ZNe.forEach(t),s_o=i(L),Ph=n(L,"LI",{});var KNe=s(Ph);rhe=n(KNe,"STRONG",{});var n8t=s(rhe);l_o=r(n8t,"retribert"),n8t.forEach(t),i_o=r(KNe," \u2014 "),cD=n(KNe,"A",{href:!0});var s8t=s(cD);d_o=r(s8t,"RetriBertConfig"),s8t.forEach(t),m_o=r(KNe," (RetriBERT model)"),KNe.forEach(t),c_o=i(L),Bh=n(L,"LI",{});var eqe=s(Bh);the=n(eqe,"STRONG",{});var l8t=s(the);f_o=r(l8t,"roberta"),l8t.forEach(t),g_o=r(eqe," \u2014 "),fD=n(eqe,"A",{href:!0});var i8t=s(fD);h_o=r(i8t,"RobertaConfig"),i8t.forEach(t),u_o=r(eqe," (RoBERTa model)"),eqe.forEach(t),p_o=i(L),Ih=n(L,"LI",{});var oqe=s(Ih);ahe=n(oqe,"STRONG",{});var d8t=s(ahe);__o=r(d8t,"roformer"),d8t.forEach(t),b_o=r(oqe," \u2014 "),gD=n(oqe,"A",{href:!0});var m8t=s(gD);v_o=r(m8t,"RoFormerConfig"),m8t.forEach(t),F_o=r(oqe," (RoFormer model)"),oqe.forEach(t),T_o=i(L),Nh=n(L,"LI",{});var rqe=s(Nh);nhe=n(rqe,"STRONG",{});var c8t=s(nhe);M_o=r(c8t,"segformer"),c8t.forEach(t),E_o=r(rqe," \u2014 "),hD=n(rqe,"A",{href:!0});var f8t=s(hD);C_o=r(f8t,"SegformerConfig"),f8t.forEach(t),w_o=r(rqe," (SegFormer model)"),rqe.forEach(t),A_o=i(L),qh=n(L,"LI",{});var tqe=s(qh);she=n(tqe,"STRONG",{});var g8t=s(she);L_o=r(g8t,"sew"),g8t.forEach(t),y_o=r(tqe," \u2014 "),uD=n(tqe,"A",{href:!0});var h8t=s(uD);x_o=r(h8t,"SEWConfig"),h8t.forEach(t),$_o=r(tqe," (SEW model)"),tqe.forEach(t),k_o=i(L),Dh=n(L,"LI",{});var aqe=s(Dh);lhe=n(aqe,"STRONG",{});var u8t=s(lhe);S_o=r(u8t,"sew-d"),u8t.forEach(t),R_o=r(aqe," \u2014 "),pD=n(aqe,"A",{href:!0});var p8t=s(pD);P_o=r(p8t,"SEWDConfig"),p8t.forEach(t),B_o=r(aqe," (SEW-D model)"),aqe.forEach(t),I_o=i(L),jh=n(L,"LI",{});var nqe=s(jh);ihe=n(nqe,"STRONG",{});var _8t=s(ihe);N_o=r(_8t,"speech-encoder-decoder"),_8t.forEach(t),q_o=r(nqe," \u2014 "),_D=n(nqe,"A",{href:!0});var b8t=s(_D);D_o=r(b8t,"SpeechEncoderDecoderConfig"),b8t.forEach(t),j_o=r(nqe," (Speech Encoder decoder model)"),nqe.forEach(t),G_o=i(L),Gh=n(L,"LI",{});var sqe=s(Gh);dhe=n(sqe,"STRONG",{});var v8t=s(dhe);O_o=r(v8t,"speech_to_text"),v8t.forEach(t),V_o=r(sqe," \u2014 "),bD=n(sqe,"A",{href:!0});var F8t=s(bD);X_o=r(F8t,"Speech2TextConfig"),F8t.forEach(t),z_o=r(sqe," (Speech2Text model)"),sqe.forEach(t),Q_o=i(L),Oh=n(L,"LI",{});var lqe=s(Oh);mhe=n(lqe,"STRONG",{});var T8t=s(mhe);W_o=r(T8t,"speech_to_text_2"),T8t.forEach(t),U_o=r(lqe," \u2014 "),vD=n(lqe,"A",{href:!0});var M8t=s(vD);H_o=r(M8t,"Speech2Text2Config"),M8t.forEach(t),J_o=r(lqe," (Speech2Text2 model)"),lqe.forEach(t),Y_o=i(L),Vh=n(L,"LI",{});var iqe=s(Vh);che=n(iqe,"STRONG",{});var E8t=s(che);Z_o=r(E8t,"splinter"),E8t.forEach(t),K_o=r(iqe," \u2014 "),FD=n(iqe,"A",{href:!0});var C8t=s(FD);e1o=r(C8t,"SplinterConfig"),C8t.forEach(t),o1o=r(iqe," (Splinter model)"),iqe.forEach(t),r1o=i(L),Xh=n(L,"LI",{});var dqe=s(Xh);fhe=n(dqe,"STRONG",{});var w8t=s(fhe);t1o=r(w8t,"squeezebert"),w8t.forEach(t),a1o=r(dqe," \u2014 "),TD=n(dqe,"A",{href:!0});var A8t=s(TD);n1o=r(A8t,"SqueezeBertConfig"),A8t.forEach(t),s1o=r(dqe," (SqueezeBERT model)"),dqe.forEach(t),l1o=i(L),zh=n(L,"LI",{});var mqe=s(zh);ghe=n(mqe,"STRONG",{});var L8t=s(ghe);i1o=r(L8t,"swin"),L8t.forEach(t),d1o=r(mqe," \u2014 "),MD=n(mqe,"A",{href:!0});var y8t=s(MD);m1o=r(y8t,"SwinConfig"),y8t.forEach(t),c1o=r(mqe," (Swin Transformer model)"),mqe.forEach(t),f1o=i(L),Qh=n(L,"LI",{});var cqe=s(Qh);hhe=n(cqe,"STRONG",{});var x8t=s(hhe);g1o=r(x8t,"swinv2"),x8t.forEach(t),h1o=r(cqe," \u2014 "),ED=n(cqe,"A",{href:!0});var $8t=s(ED);u1o=r($8t,"Swinv2Config"),$8t.forEach(t),p1o=r(cqe," (Swin Transformer V2 model)"),cqe.forEach(t),_1o=i(L),Wh=n(L,"LI",{});var fqe=s(Wh);uhe=n(fqe,"STRONG",{});var k8t=s(uhe);b1o=r(k8t,"t5"),k8t.forEach(t),v1o=r(fqe," \u2014 "),CD=n(fqe,"A",{href:!0});var S8t=s(CD);F1o=r(S8t,"T5Config"),S8t.forEach(t),T1o=r(fqe," (T5 model)"),fqe.forEach(t),M1o=i(L),Uh=n(L,"LI",{});var gqe=s(Uh);phe=n(gqe,"STRONG",{});var R8t=s(phe);E1o=r(R8t,"table-transformer"),R8t.forEach(t),C1o=r(gqe," \u2014 "),wD=n(gqe,"A",{href:!0});var P8t=s(wD);w1o=r(P8t,"TableTransformerConfig"),P8t.forEach(t),A1o=r(gqe," (Table Transformer model)"),gqe.forEach(t),L1o=i(L),Hh=n(L,"LI",{});var hqe=s(Hh);_he=n(hqe,"STRONG",{});var B8t=s(_he);y1o=r(B8t,"tapas"),B8t.forEach(t),x1o=r(hqe," \u2014 "),AD=n(hqe,"A",{href:!0});var I8t=s(AD);$1o=r(I8t,"TapasConfig"),I8t.forEach(t),k1o=r(hqe," (TAPAS model)"),hqe.forEach(t),S1o=i(L),Jh=n(L,"LI",{});var uqe=s(Jh);bhe=n(uqe,"STRONG",{});var N8t=s(bhe);R1o=r(N8t,"time_series_transformer"),N8t.forEach(t),P1o=r(uqe," \u2014 "),LD=n(uqe,"A",{href:!0});var q8t=s(LD);B1o=r(q8t,"TimeSeriesTransformerConfig"),q8t.forEach(t),I1o=r(uqe," (Time Series Transformer model)"),uqe.forEach(t),N1o=i(L),Yh=n(L,"LI",{});var pqe=s(Yh);vhe=n(pqe,"STRONG",{});var D8t=s(vhe);q1o=r(D8t,"trajectory_transformer"),D8t.forEach(t),D1o=r(pqe," \u2014 "),yD=n(pqe,"A",{href:!0});var j8t=s(yD);j1o=r(j8t,"TrajectoryTransformerConfig"),j8t.forEach(t),G1o=r(pqe," (Trajectory Transformer model)"),pqe.forEach(t),O1o=i(L),Zh=n(L,"LI",{});var _qe=s(Zh);Fhe=n(_qe,"STRONG",{});var G8t=s(Fhe);V1o=r(G8t,"transfo-xl"),G8t.forEach(t),X1o=r(_qe," \u2014 "),xD=n(_qe,"A",{href:!0});var O8t=s(xD);z1o=r(O8t,"TransfoXLConfig"),O8t.forEach(t),Q1o=r(_qe," (Transformer-XL model)"),_qe.forEach(t),W1o=i(L),Kh=n(L,"LI",{});var bqe=s(Kh);The=n(bqe,"STRONG",{});var V8t=s(The);U1o=r(V8t,"trocr"),V8t.forEach(t),H1o=r(bqe," \u2014 "),$D=n(bqe,"A",{href:!0});var X8t=s($D);J1o=r(X8t,"TrOCRConfig"),X8t.forEach(t),Y1o=r(bqe," (TrOCR model)"),bqe.forEach(t),Z1o=i(L),eu=n(L,"LI",{});var vqe=s(eu);Mhe=n(vqe,"STRONG",{});var z8t=s(Mhe);K1o=r(z8t,"unispeech"),z8t.forEach(t),e2o=r(vqe," \u2014 "),kD=n(vqe,"A",{href:!0});var Q8t=s(kD);o2o=r(Q8t,"UniSpeechConfig"),Q8t.forEach(t),r2o=r(vqe," (UniSpeech model)"),vqe.forEach(t),t2o=i(L),ou=n(L,"LI",{});var Fqe=s(ou);Ehe=n(Fqe,"STRONG",{});var W8t=s(Ehe);a2o=r(W8t,"unispeech-sat"),W8t.forEach(t),n2o=r(Fqe," \u2014 "),SD=n(Fqe,"A",{href:!0});var U8t=s(SD);s2o=r(U8t,"UniSpeechSatConfig"),U8t.forEach(t),l2o=r(Fqe," (UniSpeechSat model)"),Fqe.forEach(t),i2o=i(L),ru=n(L,"LI",{});var Tqe=s(ru);Che=n(Tqe,"STRONG",{});var H8t=s(Che);d2o=r(H8t,"van"),H8t.forEach(t),m2o=r(Tqe," \u2014 "),RD=n(Tqe,"A",{href:!0});var J8t=s(RD);c2o=r(J8t,"VanConfig"),J8t.forEach(t),f2o=r(Tqe," (VAN model)"),Tqe.forEach(t),g2o=i(L),tu=n(L,"LI",{});var Mqe=s(tu);whe=n(Mqe,"STRONG",{});var Y8t=s(whe);h2o=r(Y8t,"videomae"),Y8t.forEach(t),u2o=r(Mqe," \u2014 "),PD=n(Mqe,"A",{href:!0});var Z8t=s(PD);p2o=r(Z8t,"VideoMAEConfig"),Z8t.forEach(t),_2o=r(Mqe," (VideoMAE model)"),Mqe.forEach(t),b2o=i(L),au=n(L,"LI",{});var Eqe=s(au);Ahe=n(Eqe,"STRONG",{});var K8t=s(Ahe);v2o=r(K8t,"vilt"),K8t.forEach(t),F2o=r(Eqe," \u2014 "),BD=n(Eqe,"A",{href:!0});var eLt=s(BD);T2o=r(eLt,"ViltConfig"),eLt.forEach(t),M2o=r(Eqe," (ViLT model)"),Eqe.forEach(t),E2o=i(L),nu=n(L,"LI",{});var Cqe=s(nu);Lhe=n(Cqe,"STRONG",{});var oLt=s(Lhe);C2o=r(oLt,"vision-encoder-decoder"),oLt.forEach(t),w2o=r(Cqe," \u2014 "),ID=n(Cqe,"A",{href:!0});var rLt=s(ID);A2o=r(rLt,"VisionEncoderDecoderConfig"),rLt.forEach(t),L2o=r(Cqe," (Vision Encoder decoder model)"),Cqe.forEach(t),y2o=i(L),su=n(L,"LI",{});var wqe=s(su);yhe=n(wqe,"STRONG",{});var tLt=s(yhe);x2o=r(tLt,"vision-text-dual-encoder"),tLt.forEach(t),$2o=r(wqe," \u2014 "),ND=n(wqe,"A",{href:!0});var aLt=s(ND);k2o=r(aLt,"VisionTextDualEncoderConfig"),aLt.forEach(t),S2o=r(wqe," (VisionTextDualEncoder model)"),wqe.forEach(t),R2o=i(L),lu=n(L,"LI",{});var Aqe=s(lu);xhe=n(Aqe,"STRONG",{});var nLt=s(xhe);P2o=r(nLt,"visual_bert"),nLt.forEach(t),B2o=r(Aqe," \u2014 "),qD=n(Aqe,"A",{href:!0});var sLt=s(qD);I2o=r(sLt,"VisualBertConfig"),sLt.forEach(t),N2o=r(Aqe," (VisualBERT model)"),Aqe.forEach(t),q2o=i(L),iu=n(L,"LI",{});var Lqe=s(iu);$he=n(Lqe,"STRONG",{});var lLt=s($he);D2o=r(lLt,"vit"),lLt.forEach(t),j2o=r(Lqe," \u2014 "),DD=n(Lqe,"A",{href:!0});var iLt=s(DD);G2o=r(iLt,"ViTConfig"),iLt.forEach(t),O2o=r(Lqe," (ViT model)"),Lqe.forEach(t),V2o=i(L),du=n(L,"LI",{});var yqe=s(du);khe=n(yqe,"STRONG",{});var dLt=s(khe);X2o=r(dLt,"vit_mae"),dLt.forEach(t),z2o=r(yqe," \u2014 "),jD=n(yqe,"A",{href:!0});var mLt=s(jD);Q2o=r(mLt,"ViTMAEConfig"),mLt.forEach(t),W2o=r(yqe," (ViTMAE model)"),yqe.forEach(t),U2o=i(L),mu=n(L,"LI",{});var xqe=s(mu);She=n(xqe,"STRONG",{});var cLt=s(She);H2o=r(cLt,"vit_msn"),cLt.forEach(t),J2o=r(xqe," \u2014 "),GD=n(xqe,"A",{href:!0});var fLt=s(GD);Y2o=r(fLt,"ViTMSNConfig"),fLt.forEach(t),Z2o=r(xqe," (ViTMSN model)"),xqe.forEach(t),K2o=i(L),cu=n(L,"LI",{});var $qe=s(cu);Rhe=n($qe,"STRONG",{});var gLt=s(Rhe);ebo=r(gLt,"wav2vec2"),gLt.forEach(t),obo=r($qe," \u2014 "),OD=n($qe,"A",{href:!0});var hLt=s(OD);rbo=r(hLt,"Wav2Vec2Config"),hLt.forEach(t),tbo=r($qe," (Wav2Vec2 model)"),$qe.forEach(t),abo=i(L),fu=n(L,"LI",{});var kqe=s(fu);Phe=n(kqe,"STRONG",{});var uLt=s(Phe);nbo=r(uLt,"wav2vec2-conformer"),uLt.forEach(t),sbo=r(kqe," \u2014 "),VD=n(kqe,"A",{href:!0});var pLt=s(VD);lbo=r(pLt,"Wav2Vec2ConformerConfig"),pLt.forEach(t),ibo=r(kqe," (Wav2Vec2-Conformer model)"),kqe.forEach(t),dbo=i(L),gu=n(L,"LI",{});var Sqe=s(gu);Bhe=n(Sqe,"STRONG",{});var _Lt=s(Bhe);mbo=r(_Lt,"wavlm"),_Lt.forEach(t),cbo=r(Sqe," \u2014 "),XD=n(Sqe,"A",{href:!0});var bLt=s(XD);fbo=r(bLt,"WavLMConfig"),bLt.forEach(t),gbo=r(Sqe," (WavLM model)"),Sqe.forEach(t),hbo=i(L),hu=n(L,"LI",{});var Rqe=s(hu);Ihe=n(Rqe,"STRONG",{});var vLt=s(Ihe);ubo=r(vLt,"whisper"),vLt.forEach(t),pbo=r(Rqe," \u2014 "),zD=n(Rqe,"A",{href:!0});var FLt=s(zD);_bo=r(FLt,"WhisperConfig"),FLt.forEach(t),bbo=r(Rqe," (Whisper model)"),Rqe.forEach(t),vbo=i(L),uu=n(L,"LI",{});var Pqe=s(uu);Nhe=n(Pqe,"STRONG",{});var TLt=s(Nhe);Fbo=r(TLt,"xclip"),TLt.forEach(t),Tbo=r(Pqe," \u2014 "),QD=n(Pqe,"A",{href:!0});var MLt=s(QD);Mbo=r(MLt,"XCLIPConfig"),MLt.forEach(t),Ebo=r(Pqe," (X-CLIP model)"),Pqe.forEach(t),Cbo=i(L),pu=n(L,"LI",{});var Bqe=s(pu);qhe=n(Bqe,"STRONG",{});var ELt=s(qhe);wbo=r(ELt,"xglm"),ELt.forEach(t),Abo=r(Bqe," \u2014 "),WD=n(Bqe,"A",{href:!0});var CLt=s(WD);Lbo=r(CLt,"XGLMConfig"),CLt.forEach(t),ybo=r(Bqe," (XGLM model)"),Bqe.forEach(t),xbo=i(L),_u=n(L,"LI",{});var Iqe=s(_u);Dhe=n(Iqe,"STRONG",{});var wLt=s(Dhe);$bo=r(wLt,"xlm"),wLt.forEach(t),kbo=r(Iqe," \u2014 "),UD=n(Iqe,"A",{href:!0});var ALt=s(UD);Sbo=r(ALt,"XLMConfig"),ALt.forEach(t),Rbo=r(Iqe," (XLM model)"),Iqe.forEach(t),Pbo=i(L),bu=n(L,"LI",{});var Nqe=s(bu);jhe=n(Nqe,"STRONG",{});var LLt=s(jhe);Bbo=r(LLt,"xlm-prophetnet"),LLt.forEach(t),Ibo=r(Nqe," \u2014 "),HD=n(Nqe,"A",{href:!0});var yLt=s(HD);Nbo=r(yLt,"XLMProphetNetConfig"),yLt.forEach(t),qbo=r(Nqe," (XLM-ProphetNet model)"),Nqe.forEach(t),Dbo=i(L),vu=n(L,"LI",{});var qqe=s(vu);Ghe=n(qqe,"STRONG",{});var xLt=s(Ghe);jbo=r(xLt,"xlm-roberta"),xLt.forEach(t),Gbo=r(qqe," \u2014 "),JD=n(qqe,"A",{href:!0});var $Lt=s(JD);Obo=r($Lt,"XLMRobertaConfig"),$Lt.forEach(t),Vbo=r(qqe," (XLM-RoBERTa model)"),qqe.forEach(t),Xbo=i(L),Fu=n(L,"LI",{});var Dqe=s(Fu);Ohe=n(Dqe,"STRONG",{});var kLt=s(Ohe);zbo=r(kLt,"xlm-roberta-xl"),kLt.forEach(t),Qbo=r(Dqe," \u2014 "),YD=n(Dqe,"A",{href:!0});var SLt=s(YD);Wbo=r(SLt,"XLMRobertaXLConfig"),SLt.forEach(t),Ubo=r(Dqe," (XLM-RoBERTa-XL model)"),Dqe.forEach(t),Hbo=i(L),Tu=n(L,"LI",{});var jqe=s(Tu);Vhe=n(jqe,"STRONG",{});var RLt=s(Vhe);Jbo=r(RLt,"xlnet"),RLt.forEach(t),Ybo=r(jqe," \u2014 "),ZD=n(jqe,"A",{href:!0});var PLt=s(ZD);Zbo=r(PLt,"XLNetConfig"),PLt.forEach(t),Kbo=r(jqe," (XLNet model)"),jqe.forEach(t),evo=i(L),Mu=n(L,"LI",{});var Gqe=s(Mu);Xhe=n(Gqe,"STRONG",{});var BLt=s(Xhe);ovo=r(BLt,"yolos"),BLt.forEach(t),rvo=r(Gqe," \u2014 "),KD=n(Gqe,"A",{href:!0});var ILt=s(KD);tvo=r(ILt,"YolosConfig"),ILt.forEach(t),avo=r(Gqe," (YOLOS model)"),Gqe.forEach(t),nvo=i(L),Eu=n(L,"LI",{});var Oqe=s(Eu);zhe=n(Oqe,"STRONG",{});var NLt=s(zhe);svo=r(NLt,"yoso"),NLt.forEach(t),lvo=r(Oqe," \u2014 "),ej=n(Oqe,"A",{href:!0});var qLt=s(ej);ivo=r(qLt,"YosoConfig"),qLt.forEach(t),dvo=r(Oqe," (YOSO model)"),Oqe.forEach(t),L.forEach(t),mvo=i(Ft),T(Cu.$$.fragment,Ft),Ft.forEach(t),cvo=i(vt),wu=n(vt,"DIV",{class:!0});var Ono=s(wu);T(p$.$$.fragment,Ono),fvo=i(Ono),Qhe=n(Ono,"P",{});var DLt=s(Qhe);gvo=r(DLt,"Register a new configuration for this class."),DLt.forEach(t),Ono.forEach(t),vt.forEach(t),kto=i(c),Ld=n(c,"H2",{class:!0});var Vno=s(Ld);Au=n(Vno,"A",{id:!0,class:!0,href:!0});var jLt=s(Au);Whe=n(jLt,"SPAN",{});var GLt=s(Whe);T(_$.$$.fragment,GLt),GLt.forEach(t),jLt.forEach(t),hvo=i(Vno),Uhe=n(Vno,"SPAN",{});var OLt=s(Uhe);uvo=r(OLt,"AutoTokenizer"),OLt.forEach(t),Vno.forEach(t),Sto=i(c),Ro=n(c,"DIV",{class:!0});var Rl=s(Ro);T(b$.$$.fragment,Rl),pvo=i(Rl),v$=n(Rl,"P",{});var Xno=s(v$);_vo=r(Xno,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),oj=n(Xno,"A",{href:!0});var VLt=s(oj);bvo=r(VLt,"AutoTokenizer.from_pretrained()"),VLt.forEach(t),vvo=r(Xno," class method."),Xno.forEach(t),Fvo=i(Rl),F$=n(Rl,"P",{});var zno=s(F$);Tvo=r(zno,"This class cannot be instantiated directly using "),Hhe=n(zno,"CODE",{});var XLt=s(Hhe);Mvo=r(XLt,"__init__()"),XLt.forEach(t),Evo=r(zno," (throws an error)."),zno.forEach(t),Cvo=i(Rl),Dr=n(Rl,"DIV",{class:!0});var Pl=s(Dr);T(T$.$$.fragment,Pl),wvo=i(Pl),Jhe=n(Pl,"P",{});var zLt=s(Jhe);Avo=r(zLt,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),zLt.forEach(t),Lvo=i(Pl),tn=n(Pl,"P",{});var Zy=s(tn);yvo=r(Zy,"The tokenizer class to instantiate is selected based on the "),Yhe=n(Zy,"CODE",{});var QLt=s(Yhe);xvo=r(QLt,"model_type"),QLt.forEach(t),$vo=r(Zy,` property of the config object (either
passed as an argument or loaded from `),Zhe=n(Zy,"CODE",{});var WLt=s(Zhe);kvo=r(WLt,"pretrained_model_name_or_path"),WLt.forEach(t),Svo=r(Zy,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Khe=n(Zy,"CODE",{});var ULt=s(Khe);Rvo=r(ULt,"pretrained_model_name_or_path"),ULt.forEach(t),Pvo=r(Zy,":"),Zy.forEach(t),Bvo=i(Pl),k=n(Pl,"UL",{});var S=s(k);us=n(S,"LI",{});var tI=s(us);eue=n(tI,"STRONG",{});var HLt=s(eue);Ivo=r(HLt,"albert"),HLt.forEach(t),Nvo=r(tI," \u2014 "),rj=n(tI,"A",{href:!0});var JLt=s(rj);qvo=r(JLt,"AlbertTokenizer"),JLt.forEach(t),Dvo=r(tI," or "),tj=n(tI,"A",{href:!0});var YLt=s(tj);jvo=r(YLt,"AlbertTokenizerFast"),YLt.forEach(t),Gvo=r(tI," (ALBERT model)"),tI.forEach(t),Ovo=i(S),ps=n(S,"LI",{});var aI=s(ps);oue=n(aI,"STRONG",{});var ZLt=s(oue);Vvo=r(ZLt,"bart"),ZLt.forEach(t),Xvo=r(aI," \u2014 "),aj=n(aI,"A",{href:!0});var KLt=s(aj);zvo=r(KLt,"BartTokenizer"),KLt.forEach(t),Qvo=r(aI," or "),nj=n(aI,"A",{href:!0});var eyt=s(nj);Wvo=r(eyt,"BartTokenizerFast"),eyt.forEach(t),Uvo=r(aI," (BART model)"),aI.forEach(t),Hvo=i(S),_s=n(S,"LI",{});var nI=s(_s);rue=n(nI,"STRONG",{});var oyt=s(rue);Jvo=r(oyt,"barthez"),oyt.forEach(t),Yvo=r(nI," \u2014 "),sj=n(nI,"A",{href:!0});var ryt=s(sj);Zvo=r(ryt,"BarthezTokenizer"),ryt.forEach(t),Kvo=r(nI," or "),lj=n(nI,"A",{href:!0});var tyt=s(lj);eFo=r(tyt,"BarthezTokenizerFast"),tyt.forEach(t),oFo=r(nI," (BARThez model)"),nI.forEach(t),rFo=i(S),Lu=n(S,"LI",{});var Vqe=s(Lu);tue=n(Vqe,"STRONG",{});var ayt=s(tue);tFo=r(ayt,"bartpho"),ayt.forEach(t),aFo=r(Vqe," \u2014 "),ij=n(Vqe,"A",{href:!0});var nyt=s(ij);nFo=r(nyt,"BartphoTokenizer"),nyt.forEach(t),sFo=r(Vqe," (BARTpho model)"),Vqe.forEach(t),lFo=i(S),bs=n(S,"LI",{});var sI=s(bs);aue=n(sI,"STRONG",{});var syt=s(aue);iFo=r(syt,"bert"),syt.forEach(t),dFo=r(sI," \u2014 "),dj=n(sI,"A",{href:!0});var lyt=s(dj);mFo=r(lyt,"BertTokenizer"),lyt.forEach(t),cFo=r(sI," or "),mj=n(sI,"A",{href:!0});var iyt=s(mj);fFo=r(iyt,"BertTokenizerFast"),iyt.forEach(t),gFo=r(sI," (BERT model)"),sI.forEach(t),hFo=i(S),yu=n(S,"LI",{});var Xqe=s(yu);nue=n(Xqe,"STRONG",{});var dyt=s(nue);uFo=r(dyt,"bert-generation"),dyt.forEach(t),pFo=r(Xqe," \u2014 "),cj=n(Xqe,"A",{href:!0});var myt=s(cj);_Fo=r(myt,"BertGenerationTokenizer"),myt.forEach(t),bFo=r(Xqe," (Bert Generation model)"),Xqe.forEach(t),vFo=i(S),xu=n(S,"LI",{});var zqe=s(xu);sue=n(zqe,"STRONG",{});var cyt=s(sue);FFo=r(cyt,"bert-japanese"),cyt.forEach(t),TFo=r(zqe," \u2014 "),fj=n(zqe,"A",{href:!0});var fyt=s(fj);MFo=r(fyt,"BertJapaneseTokenizer"),fyt.forEach(t),EFo=r(zqe," (BertJapanese model)"),zqe.forEach(t),CFo=i(S),$u=n(S,"LI",{});var Qqe=s($u);lue=n(Qqe,"STRONG",{});var gyt=s(lue);wFo=r(gyt,"bertweet"),gyt.forEach(t),AFo=r(Qqe," \u2014 "),gj=n(Qqe,"A",{href:!0});var hyt=s(gj);LFo=r(hyt,"BertweetTokenizer"),hyt.forEach(t),yFo=r(Qqe," (BERTweet model)"),Qqe.forEach(t),xFo=i(S),vs=n(S,"LI",{});var lI=s(vs);iue=n(lI,"STRONG",{});var uyt=s(iue);$Fo=r(uyt,"big_bird"),uyt.forEach(t),kFo=r(lI," \u2014 "),hj=n(lI,"A",{href:!0});var pyt=s(hj);SFo=r(pyt,"BigBirdTokenizer"),pyt.forEach(t),RFo=r(lI," or "),uj=n(lI,"A",{href:!0});var _yt=s(uj);PFo=r(_yt,"BigBirdTokenizerFast"),_yt.forEach(t),BFo=r(lI," (BigBird model)"),lI.forEach(t),IFo=i(S),Fs=n(S,"LI",{});var iI=s(Fs);due=n(iI,"STRONG",{});var byt=s(due);NFo=r(byt,"bigbird_pegasus"),byt.forEach(t),qFo=r(iI," \u2014 "),pj=n(iI,"A",{href:!0});var vyt=s(pj);DFo=r(vyt,"PegasusTokenizer"),vyt.forEach(t),jFo=r(iI," or "),_j=n(iI,"A",{href:!0});var Fyt=s(_j);GFo=r(Fyt,"PegasusTokenizerFast"),Fyt.forEach(t),OFo=r(iI," (BigBird-Pegasus model)"),iI.forEach(t),VFo=i(S),Ts=n(S,"LI",{});var dI=s(Ts);mue=n(dI,"STRONG",{});var Tyt=s(mue);XFo=r(Tyt,"blenderbot"),Tyt.forEach(t),zFo=r(dI," \u2014 "),bj=n(dI,"A",{href:!0});var Myt=s(bj);QFo=r(Myt,"BlenderbotTokenizer"),Myt.forEach(t),WFo=r(dI," or "),vj=n(dI,"A",{href:!0});var Eyt=s(vj);UFo=r(Eyt,"BlenderbotTokenizerFast"),Eyt.forEach(t),HFo=r(dI," (Blenderbot model)"),dI.forEach(t),JFo=i(S),ku=n(S,"LI",{});var Wqe=s(ku);cue=n(Wqe,"STRONG",{});var Cyt=s(cue);YFo=r(Cyt,"blenderbot-small"),Cyt.forEach(t),ZFo=r(Wqe," \u2014 "),Fj=n(Wqe,"A",{href:!0});var wyt=s(Fj);KFo=r(wyt,"BlenderbotSmallTokenizer"),wyt.forEach(t),eTo=r(Wqe," (BlenderbotSmall model)"),Wqe.forEach(t),oTo=i(S),Su=n(S,"LI",{});var Uqe=s(Su);fue=n(Uqe,"STRONG",{});var Ayt=s(fue);rTo=r(Ayt,"bloom"),Ayt.forEach(t),tTo=r(Uqe," \u2014 "),Tj=n(Uqe,"A",{href:!0});var Lyt=s(Tj);aTo=r(Lyt,"BloomTokenizerFast"),Lyt.forEach(t),nTo=r(Uqe," (BLOOM model)"),Uqe.forEach(t),sTo=i(S),Ru=n(S,"LI",{});var Hqe=s(Ru);gue=n(Hqe,"STRONG",{});var yyt=s(gue);lTo=r(yyt,"byt5"),yyt.forEach(t),iTo=r(Hqe," \u2014 "),Mj=n(Hqe,"A",{href:!0});var xyt=s(Mj);dTo=r(xyt,"ByT5Tokenizer"),xyt.forEach(t),mTo=r(Hqe," (ByT5 model)"),Hqe.forEach(t),cTo=i(S),Ms=n(S,"LI",{});var mI=s(Ms);hue=n(mI,"STRONG",{});var $yt=s(hue);fTo=r($yt,"camembert"),$yt.forEach(t),gTo=r(mI," \u2014 "),Ej=n(mI,"A",{href:!0});var kyt=s(Ej);hTo=r(kyt,"CamembertTokenizer"),kyt.forEach(t),uTo=r(mI," or "),Cj=n(mI,"A",{href:!0});var Syt=s(Cj);pTo=r(Syt,"CamembertTokenizerFast"),Syt.forEach(t),_To=r(mI," (CamemBERT model)"),mI.forEach(t),bTo=i(S),Pu=n(S,"LI",{});var Jqe=s(Pu);uue=n(Jqe,"STRONG",{});var Ryt=s(uue);vTo=r(Ryt,"canine"),Ryt.forEach(t),FTo=r(Jqe," \u2014 "),wj=n(Jqe,"A",{href:!0});var Pyt=s(wj);TTo=r(Pyt,"CanineTokenizer"),Pyt.forEach(t),MTo=r(Jqe," (CANINE model)"),Jqe.forEach(t),ETo=i(S),Es=n(S,"LI",{});var cI=s(Es);pue=n(cI,"STRONG",{});var Byt=s(pue);CTo=r(Byt,"clip"),Byt.forEach(t),wTo=r(cI," \u2014 "),Aj=n(cI,"A",{href:!0});var Iyt=s(Aj);ATo=r(Iyt,"CLIPTokenizer"),Iyt.forEach(t),LTo=r(cI," or "),Lj=n(cI,"A",{href:!0});var Nyt=s(Lj);yTo=r(Nyt,"CLIPTokenizerFast"),Nyt.forEach(t),xTo=r(cI," (CLIP model)"),cI.forEach(t),$To=i(S),Cs=n(S,"LI",{});var fI=s(Cs);_ue=n(fI,"STRONG",{});var qyt=s(_ue);kTo=r(qyt,"codegen"),qyt.forEach(t),STo=r(fI," \u2014 "),yj=n(fI,"A",{href:!0});var Dyt=s(yj);RTo=r(Dyt,"CodeGenTokenizer"),Dyt.forEach(t),PTo=r(fI," or "),xj=n(fI,"A",{href:!0});var jyt=s(xj);BTo=r(jyt,"CodeGenTokenizerFast"),jyt.forEach(t),ITo=r(fI," (CodeGen model)"),fI.forEach(t),NTo=i(S),ws=n(S,"LI",{});var gI=s(ws);bue=n(gI,"STRONG",{});var Gyt=s(bue);qTo=r(Gyt,"convbert"),Gyt.forEach(t),DTo=r(gI," \u2014 "),$j=n(gI,"A",{href:!0});var Oyt=s($j);jTo=r(Oyt,"ConvBertTokenizer"),Oyt.forEach(t),GTo=r(gI," or "),kj=n(gI,"A",{href:!0});var Vyt=s(kj);OTo=r(Vyt,"ConvBertTokenizerFast"),Vyt.forEach(t),VTo=r(gI," (ConvBERT model)"),gI.forEach(t),XTo=i(S),As=n(S,"LI",{});var hI=s(As);vue=n(hI,"STRONG",{});var Xyt=s(vue);zTo=r(Xyt,"cpm"),Xyt.forEach(t),QTo=r(hI," \u2014 "),Sj=n(hI,"A",{href:!0});var zyt=s(Sj);WTo=r(zyt,"CpmTokenizer"),zyt.forEach(t),UTo=r(hI," or "),Rj=n(hI,"A",{href:!0});var Qyt=s(Rj);HTo=r(Qyt,"CpmTokenizerFast"),Qyt.forEach(t),JTo=r(hI," (CPM model)"),hI.forEach(t),YTo=i(S),Bu=n(S,"LI",{});var Yqe=s(Bu);Fue=n(Yqe,"STRONG",{});var Wyt=s(Fue);ZTo=r(Wyt,"ctrl"),Wyt.forEach(t),KTo=r(Yqe," \u2014 "),Pj=n(Yqe,"A",{href:!0});var Uyt=s(Pj);eMo=r(Uyt,"CTRLTokenizer"),Uyt.forEach(t),oMo=r(Yqe," (CTRL model)"),Yqe.forEach(t),rMo=i(S),Ls=n(S,"LI",{});var uI=s(Ls);Tue=n(uI,"STRONG",{});var Hyt=s(Tue);tMo=r(Hyt,"data2vec-text"),Hyt.forEach(t),aMo=r(uI," \u2014 "),Bj=n(uI,"A",{href:!0});var Jyt=s(Bj);nMo=r(Jyt,"RobertaTokenizer"),Jyt.forEach(t),sMo=r(uI," or "),Ij=n(uI,"A",{href:!0});var Yyt=s(Ij);lMo=r(Yyt,"RobertaTokenizerFast"),Yyt.forEach(t),iMo=r(uI," (Data2VecText model)"),uI.forEach(t),dMo=i(S),ys=n(S,"LI",{});var pI=s(ys);Mue=n(pI,"STRONG",{});var Zyt=s(Mue);mMo=r(Zyt,"deberta"),Zyt.forEach(t),cMo=r(pI," \u2014 "),Nj=n(pI,"A",{href:!0});var Kyt=s(Nj);fMo=r(Kyt,"DebertaTokenizer"),Kyt.forEach(t),gMo=r(pI," or "),qj=n(pI,"A",{href:!0});var e9t=s(qj);hMo=r(e9t,"DebertaTokenizerFast"),e9t.forEach(t),uMo=r(pI," (DeBERTa model)"),pI.forEach(t),pMo=i(S),xs=n(S,"LI",{});var _I=s(xs);Eue=n(_I,"STRONG",{});var o9t=s(Eue);_Mo=r(o9t,"deberta-v2"),o9t.forEach(t),bMo=r(_I," \u2014 "),Dj=n(_I,"A",{href:!0});var r9t=s(Dj);vMo=r(r9t,"DebertaV2Tokenizer"),r9t.forEach(t),FMo=r(_I," or "),jj=n(_I,"A",{href:!0});var t9t=s(jj);TMo=r(t9t,"DebertaV2TokenizerFast"),t9t.forEach(t),MMo=r(_I," (DeBERTa-v2 model)"),_I.forEach(t),EMo=i(S),$s=n(S,"LI",{});var bI=s($s);Cue=n(bI,"STRONG",{});var a9t=s(Cue);CMo=r(a9t,"distilbert"),a9t.forEach(t),wMo=r(bI," \u2014 "),Gj=n(bI,"A",{href:!0});var n9t=s(Gj);AMo=r(n9t,"DistilBertTokenizer"),n9t.forEach(t),LMo=r(bI," or "),Oj=n(bI,"A",{href:!0});var s9t=s(Oj);yMo=r(s9t,"DistilBertTokenizerFast"),s9t.forEach(t),xMo=r(bI," (DistilBERT model)"),bI.forEach(t),$Mo=i(S),ks=n(S,"LI",{});var vI=s(ks);wue=n(vI,"STRONG",{});var l9t=s(wue);kMo=r(l9t,"dpr"),l9t.forEach(t),SMo=r(vI," \u2014 "),Vj=n(vI,"A",{href:!0});var i9t=s(Vj);RMo=r(i9t,"DPRQuestionEncoderTokenizer"),i9t.forEach(t),PMo=r(vI," or "),Xj=n(vI,"A",{href:!0});var d9t=s(Xj);BMo=r(d9t,"DPRQuestionEncoderTokenizerFast"),d9t.forEach(t),IMo=r(vI," (DPR model)"),vI.forEach(t),NMo=i(S),Ss=n(S,"LI",{});var FI=s(Ss);Aue=n(FI,"STRONG",{});var m9t=s(Aue);qMo=r(m9t,"electra"),m9t.forEach(t),DMo=r(FI," \u2014 "),zj=n(FI,"A",{href:!0});var c9t=s(zj);jMo=r(c9t,"ElectraTokenizer"),c9t.forEach(t),GMo=r(FI," or "),Qj=n(FI,"A",{href:!0});var f9t=s(Qj);OMo=r(f9t,"ElectraTokenizerFast"),f9t.forEach(t),VMo=r(FI," (ELECTRA model)"),FI.forEach(t),XMo=i(S),Rs=n(S,"LI",{});var TI=s(Rs);Lue=n(TI,"STRONG",{});var g9t=s(Lue);zMo=r(g9t,"ernie"),g9t.forEach(t),QMo=r(TI," \u2014 "),Wj=n(TI,"A",{href:!0});var h9t=s(Wj);WMo=r(h9t,"BertTokenizer"),h9t.forEach(t),UMo=r(TI," or "),Uj=n(TI,"A",{href:!0});var u9t=s(Uj);HMo=r(u9t,"BertTokenizerFast"),u9t.forEach(t),JMo=r(TI," (ERNIE model)"),TI.forEach(t),YMo=i(S),Iu=n(S,"LI",{});var Zqe=s(Iu);yue=n(Zqe,"STRONG",{});var p9t=s(yue);ZMo=r(p9t,"esm"),p9t.forEach(t),KMo=r(Zqe," \u2014 "),Hj=n(Zqe,"A",{href:!0});var _9t=s(Hj);eEo=r(_9t,"EsmTokenizer"),_9t.forEach(t),oEo=r(Zqe," (ESM model)"),Zqe.forEach(t),rEo=i(S),Nu=n(S,"LI",{});var Kqe=s(Nu);xue=n(Kqe,"STRONG",{});var b9t=s(xue);tEo=r(b9t,"flaubert"),b9t.forEach(t),aEo=r(Kqe," \u2014 "),Jj=n(Kqe,"A",{href:!0});var v9t=s(Jj);nEo=r(v9t,"FlaubertTokenizer"),v9t.forEach(t),sEo=r(Kqe," (FlauBERT model)"),Kqe.forEach(t),lEo=i(S),Ps=n(S,"LI",{});var MI=s(Ps);$ue=n(MI,"STRONG",{});var F9t=s($ue);iEo=r(F9t,"fnet"),F9t.forEach(t),dEo=r(MI," \u2014 "),Yj=n(MI,"A",{href:!0});var T9t=s(Yj);mEo=r(T9t,"FNetTokenizer"),T9t.forEach(t),cEo=r(MI," or "),Zj=n(MI,"A",{href:!0});var M9t=s(Zj);fEo=r(M9t,"FNetTokenizerFast"),M9t.forEach(t),gEo=r(MI," (FNet model)"),MI.forEach(t),hEo=i(S),qu=n(S,"LI",{});var eDe=s(qu);kue=n(eDe,"STRONG",{});var E9t=s(kue);uEo=r(E9t,"fsmt"),E9t.forEach(t),pEo=r(eDe," \u2014 "),Kj=n(eDe,"A",{href:!0});var C9t=s(Kj);_Eo=r(C9t,"FSMTTokenizer"),C9t.forEach(t),bEo=r(eDe," (FairSeq Machine-Translation model)"),eDe.forEach(t),vEo=i(S),Bs=n(S,"LI",{});var EI=s(Bs);Sue=n(EI,"STRONG",{});var w9t=s(Sue);FEo=r(w9t,"funnel"),w9t.forEach(t),TEo=r(EI," \u2014 "),eG=n(EI,"A",{href:!0});var A9t=s(eG);MEo=r(A9t,"FunnelTokenizer"),A9t.forEach(t),EEo=r(EI," or "),oG=n(EI,"A",{href:!0});var L9t=s(oG);CEo=r(L9t,"FunnelTokenizerFast"),L9t.forEach(t),wEo=r(EI," (Funnel Transformer model)"),EI.forEach(t),AEo=i(S),Is=n(S,"LI",{});var CI=s(Is);Rue=n(CI,"STRONG",{});var y9t=s(Rue);LEo=r(y9t,"gpt2"),y9t.forEach(t),yEo=r(CI," \u2014 "),rG=n(CI,"A",{href:!0});var x9t=s(rG);xEo=r(x9t,"GPT2Tokenizer"),x9t.forEach(t),$Eo=r(CI," or "),tG=n(CI,"A",{href:!0});var $9t=s(tG);kEo=r($9t,"GPT2TokenizerFast"),$9t.forEach(t),SEo=r(CI," (OpenAI GPT-2 model)"),CI.forEach(t),REo=i(S),Ns=n(S,"LI",{});var wI=s(Ns);Pue=n(wI,"STRONG",{});var k9t=s(Pue);PEo=r(k9t,"gpt_neo"),k9t.forEach(t),BEo=r(wI," \u2014 "),aG=n(wI,"A",{href:!0});var S9t=s(aG);IEo=r(S9t,"GPT2Tokenizer"),S9t.forEach(t),NEo=r(wI," or "),nG=n(wI,"A",{href:!0});var R9t=s(nG);qEo=r(R9t,"GPT2TokenizerFast"),R9t.forEach(t),DEo=r(wI," (GPT Neo model)"),wI.forEach(t),jEo=i(S),Du=n(S,"LI",{});var oDe=s(Du);Bue=n(oDe,"STRONG",{});var P9t=s(Bue);GEo=r(P9t,"gpt_neox"),P9t.forEach(t),OEo=r(oDe," \u2014 "),sG=n(oDe,"A",{href:!0});var B9t=s(sG);VEo=r(B9t,"GPTNeoXTokenizerFast"),B9t.forEach(t),XEo=r(oDe," (GPT NeoX model)"),oDe.forEach(t),zEo=i(S),ju=n(S,"LI",{});var rDe=s(ju);Iue=n(rDe,"STRONG",{});var I9t=s(Iue);QEo=r(I9t,"gpt_neox_japanese"),I9t.forEach(t),WEo=r(rDe," \u2014 "),lG=n(rDe,"A",{href:!0});var N9t=s(lG);UEo=r(N9t,"GPTNeoXJapaneseTokenizer"),N9t.forEach(t),HEo=r(rDe," (GPT NeoX Japanese model)"),rDe.forEach(t),JEo=i(S),qs=n(S,"LI",{});var AI=s(qs);Nue=n(AI,"STRONG",{});var q9t=s(Nue);YEo=r(q9t,"gptj"),q9t.forEach(t),ZEo=r(AI," \u2014 "),iG=n(AI,"A",{href:!0});var D9t=s(iG);KEo=r(D9t,"GPT2Tokenizer"),D9t.forEach(t),e4o=r(AI," or "),dG=n(AI,"A",{href:!0});var j9t=s(dG);o4o=r(j9t,"GPT2TokenizerFast"),j9t.forEach(t),r4o=r(AI," (GPT-J model)"),AI.forEach(t),t4o=i(S),Ds=n(S,"LI",{});var LI=s(Ds);que=n(LI,"STRONG",{});var G9t=s(que);a4o=r(G9t,"groupvit"),G9t.forEach(t),n4o=r(LI," \u2014 "),mG=n(LI,"A",{href:!0});var O9t=s(mG);s4o=r(O9t,"CLIPTokenizer"),O9t.forEach(t),l4o=r(LI," or "),cG=n(LI,"A",{href:!0});var V9t=s(cG);i4o=r(V9t,"CLIPTokenizerFast"),V9t.forEach(t),d4o=r(LI," (GroupViT model)"),LI.forEach(t),m4o=i(S),js=n(S,"LI",{});var yI=s(js);Due=n(yI,"STRONG",{});var X9t=s(Due);c4o=r(X9t,"herbert"),X9t.forEach(t),f4o=r(yI," \u2014 "),fG=n(yI,"A",{href:!0});var z9t=s(fG);g4o=r(z9t,"HerbertTokenizer"),z9t.forEach(t),h4o=r(yI," or "),gG=n(yI,"A",{href:!0});var Q9t=s(gG);u4o=r(Q9t,"HerbertTokenizerFast"),Q9t.forEach(t),p4o=r(yI," (HerBERT model)"),yI.forEach(t),_4o=i(S),Gu=n(S,"LI",{});var tDe=s(Gu);jue=n(tDe,"STRONG",{});var W9t=s(jue);b4o=r(W9t,"hubert"),W9t.forEach(t),v4o=r(tDe," \u2014 "),hG=n(tDe,"A",{href:!0});var U9t=s(hG);F4o=r(U9t,"Wav2Vec2CTCTokenizer"),U9t.forEach(t),T4o=r(tDe," (Hubert model)"),tDe.forEach(t),M4o=i(S),Gs=n(S,"LI",{});var xI=s(Gs);Gue=n(xI,"STRONG",{});var H9t=s(Gue);E4o=r(H9t,"ibert"),H9t.forEach(t),C4o=r(xI," \u2014 "),uG=n(xI,"A",{href:!0});var J9t=s(uG);w4o=r(J9t,"RobertaTokenizer"),J9t.forEach(t),A4o=r(xI," or "),pG=n(xI,"A",{href:!0});var Y9t=s(pG);L4o=r(Y9t,"RobertaTokenizerFast"),Y9t.forEach(t),y4o=r(xI," (I-BERT model)"),xI.forEach(t),x4o=i(S),Os=n(S,"LI",{});var $I=s(Os);Oue=n($I,"STRONG",{});var Z9t=s(Oue);$4o=r(Z9t,"layoutlm"),Z9t.forEach(t),k4o=r($I," \u2014 "),_G=n($I,"A",{href:!0});var K9t=s(_G);S4o=r(K9t,"LayoutLMTokenizer"),K9t.forEach(t),R4o=r($I," or "),bG=n($I,"A",{href:!0});var ext=s(bG);P4o=r(ext,"LayoutLMTokenizerFast"),ext.forEach(t),B4o=r($I," (LayoutLM model)"),$I.forEach(t),I4o=i(S),Vs=n(S,"LI",{});var kI=s(Vs);Vue=n(kI,"STRONG",{});var oxt=s(Vue);N4o=r(oxt,"layoutlmv2"),oxt.forEach(t),q4o=r(kI," \u2014 "),vG=n(kI,"A",{href:!0});var rxt=s(vG);D4o=r(rxt,"LayoutLMv2Tokenizer"),rxt.forEach(t),j4o=r(kI," or "),FG=n(kI,"A",{href:!0});var txt=s(FG);G4o=r(txt,"LayoutLMv2TokenizerFast"),txt.forEach(t),O4o=r(kI," (LayoutLMv2 model)"),kI.forEach(t),V4o=i(S),Xs=n(S,"LI",{});var SI=s(Xs);Xue=n(SI,"STRONG",{});var axt=s(Xue);X4o=r(axt,"layoutlmv3"),axt.forEach(t),z4o=r(SI," \u2014 "),TG=n(SI,"A",{href:!0});var nxt=s(TG);Q4o=r(nxt,"LayoutLMv3Tokenizer"),nxt.forEach(t),W4o=r(SI," or "),MG=n(SI,"A",{href:!0});var sxt=s(MG);U4o=r(sxt,"LayoutLMv3TokenizerFast"),sxt.forEach(t),H4o=r(SI," (LayoutLMv3 model)"),SI.forEach(t),J4o=i(S),zs=n(S,"LI",{});var RI=s(zs);zue=n(RI,"STRONG",{});var lxt=s(zue);Y4o=r(lxt,"layoutxlm"),lxt.forEach(t),Z4o=r(RI," \u2014 "),EG=n(RI,"A",{href:!0});var ixt=s(EG);K4o=r(ixt,"LayoutXLMTokenizer"),ixt.forEach(t),eCo=r(RI," or "),CG=n(RI,"A",{href:!0});var dxt=s(CG);oCo=r(dxt,"LayoutXLMTokenizerFast"),dxt.forEach(t),rCo=r(RI," (LayoutXLM model)"),RI.forEach(t),tCo=i(S),Qs=n(S,"LI",{});var PI=s(Qs);Que=n(PI,"STRONG",{});var mxt=s(Que);aCo=r(mxt,"led"),mxt.forEach(t),nCo=r(PI," \u2014 "),wG=n(PI,"A",{href:!0});var cxt=s(wG);sCo=r(cxt,"LEDTokenizer"),cxt.forEach(t),lCo=r(PI," or "),AG=n(PI,"A",{href:!0});var fxt=s(AG);iCo=r(fxt,"LEDTokenizerFast"),fxt.forEach(t),dCo=r(PI," (LED model)"),PI.forEach(t),mCo=i(S),Ws=n(S,"LI",{});var BI=s(Ws);Wue=n(BI,"STRONG",{});var gxt=s(Wue);cCo=r(gxt,"lilt"),gxt.forEach(t),fCo=r(BI," \u2014 "),LG=n(BI,"A",{href:!0});var hxt=s(LG);gCo=r(hxt,"LayoutLMv3Tokenizer"),hxt.forEach(t),hCo=r(BI," or "),yG=n(BI,"A",{href:!0});var uxt=s(yG);uCo=r(uxt,"LayoutLMv3TokenizerFast"),uxt.forEach(t),pCo=r(BI," (LiLT model)"),BI.forEach(t),_Co=i(S),Us=n(S,"LI",{});var II=s(Us);Uue=n(II,"STRONG",{});var pxt=s(Uue);bCo=r(pxt,"longformer"),pxt.forEach(t),vCo=r(II," \u2014 "),xG=n(II,"A",{href:!0});var _xt=s(xG);FCo=r(_xt,"LongformerTokenizer"),_xt.forEach(t),TCo=r(II," or "),$G=n(II,"A",{href:!0});var bxt=s($G);MCo=r(bxt,"LongformerTokenizerFast"),bxt.forEach(t),ECo=r(II," (Longformer model)"),II.forEach(t),CCo=i(S),Hs=n(S,"LI",{});var NI=s(Hs);Hue=n(NI,"STRONG",{});var vxt=s(Hue);wCo=r(vxt,"longt5"),vxt.forEach(t),ACo=r(NI," \u2014 "),kG=n(NI,"A",{href:!0});var Fxt=s(kG);LCo=r(Fxt,"T5Tokenizer"),Fxt.forEach(t),yCo=r(NI," or "),SG=n(NI,"A",{href:!0});var Txt=s(SG);xCo=r(Txt,"T5TokenizerFast"),Txt.forEach(t),$Co=r(NI," (LongT5 model)"),NI.forEach(t),kCo=i(S),Ou=n(S,"LI",{});var aDe=s(Ou);Jue=n(aDe,"STRONG",{});var Mxt=s(Jue);SCo=r(Mxt,"luke"),Mxt.forEach(t),RCo=r(aDe," \u2014 "),RG=n(aDe,"A",{href:!0});var Ext=s(RG);PCo=r(Ext,"LukeTokenizer"),Ext.forEach(t),BCo=r(aDe," (LUKE model)"),aDe.forEach(t),ICo=i(S),Js=n(S,"LI",{});var qI=s(Js);Yue=n(qI,"STRONG",{});var Cxt=s(Yue);NCo=r(Cxt,"lxmert"),Cxt.forEach(t),qCo=r(qI," \u2014 "),PG=n(qI,"A",{href:!0});var wxt=s(PG);DCo=r(wxt,"LxmertTokenizer"),wxt.forEach(t),jCo=r(qI," or "),BG=n(qI,"A",{href:!0});var Axt=s(BG);GCo=r(Axt,"LxmertTokenizerFast"),Axt.forEach(t),OCo=r(qI," (LXMERT model)"),qI.forEach(t),VCo=i(S),Vu=n(S,"LI",{});var nDe=s(Vu);Zue=n(nDe,"STRONG",{});var Lxt=s(Zue);XCo=r(Lxt,"m2m_100"),Lxt.forEach(t),zCo=r(nDe," \u2014 "),IG=n(nDe,"A",{href:!0});var yxt=s(IG);QCo=r(yxt,"M2M100Tokenizer"),yxt.forEach(t),WCo=r(nDe," (M2M100 model)"),nDe.forEach(t),UCo=i(S),Xu=n(S,"LI",{});var sDe=s(Xu);Kue=n(sDe,"STRONG",{});var xxt=s(Kue);HCo=r(xxt,"marian"),xxt.forEach(t),JCo=r(sDe," \u2014 "),NG=n(sDe,"A",{href:!0});var $xt=s(NG);YCo=r($xt,"MarianTokenizer"),$xt.forEach(t),ZCo=r(sDe," (Marian model)"),sDe.forEach(t),KCo=i(S),Ys=n(S,"LI",{});var DI=s(Ys);epe=n(DI,"STRONG",{});var kxt=s(epe);e3o=r(kxt,"mbart"),kxt.forEach(t),o3o=r(DI," \u2014 "),qG=n(DI,"A",{href:!0});var Sxt=s(qG);r3o=r(Sxt,"MBartTokenizer"),Sxt.forEach(t),t3o=r(DI," or "),DG=n(DI,"A",{href:!0});var Rxt=s(DG);a3o=r(Rxt,"MBartTokenizerFast"),Rxt.forEach(t),n3o=r(DI," (mBART model)"),DI.forEach(t),s3o=i(S),Zs=n(S,"LI",{});var jI=s(Zs);ope=n(jI,"STRONG",{});var Pxt=s(ope);l3o=r(Pxt,"mbart50"),Pxt.forEach(t),i3o=r(jI," \u2014 "),jG=n(jI,"A",{href:!0});var Bxt=s(jG);d3o=r(Bxt,"MBart50Tokenizer"),Bxt.forEach(t),m3o=r(jI," or "),GG=n(jI,"A",{href:!0});var Ixt=s(GG);c3o=r(Ixt,"MBart50TokenizerFast"),Ixt.forEach(t),f3o=r(jI," (mBART-50 model)"),jI.forEach(t),g3o=i(S),Ks=n(S,"LI",{});var GI=s(Ks);rpe=n(GI,"STRONG",{});var Nxt=s(rpe);h3o=r(Nxt,"megatron-bert"),Nxt.forEach(t),u3o=r(GI," \u2014 "),OG=n(GI,"A",{href:!0});var qxt=s(OG);p3o=r(qxt,"BertTokenizer"),qxt.forEach(t),_3o=r(GI," or "),VG=n(GI,"A",{href:!0});var Dxt=s(VG);b3o=r(Dxt,"BertTokenizerFast"),Dxt.forEach(t),v3o=r(GI," (Megatron-BERT model)"),GI.forEach(t),F3o=i(S),zu=n(S,"LI",{});var lDe=s(zu);tpe=n(lDe,"STRONG",{});var jxt=s(tpe);T3o=r(jxt,"mluke"),jxt.forEach(t),M3o=r(lDe," \u2014 "),XG=n(lDe,"A",{href:!0});var Gxt=s(XG);E3o=r(Gxt,"MLukeTokenizer"),Gxt.forEach(t),C3o=r(lDe," (mLUKE model)"),lDe.forEach(t),w3o=i(S),el=n(S,"LI",{});var OI=s(el);ape=n(OI,"STRONG",{});var Oxt=s(ape);A3o=r(Oxt,"mobilebert"),Oxt.forEach(t),L3o=r(OI," \u2014 "),zG=n(OI,"A",{href:!0});var Vxt=s(zG);y3o=r(Vxt,"MobileBertTokenizer"),Vxt.forEach(t),x3o=r(OI," or "),QG=n(OI,"A",{href:!0});var Xxt=s(QG);$3o=r(Xxt,"MobileBertTokenizerFast"),Xxt.forEach(t),k3o=r(OI," (MobileBERT model)"),OI.forEach(t),S3o=i(S),ol=n(S,"LI",{});var VI=s(ol);npe=n(VI,"STRONG",{});var zxt=s(npe);R3o=r(zxt,"mpnet"),zxt.forEach(t),P3o=r(VI," \u2014 "),WG=n(VI,"A",{href:!0});var Qxt=s(WG);B3o=r(Qxt,"MPNetTokenizer"),Qxt.forEach(t),I3o=r(VI," or "),UG=n(VI,"A",{href:!0});var Wxt=s(UG);N3o=r(Wxt,"MPNetTokenizerFast"),Wxt.forEach(t),q3o=r(VI," (MPNet model)"),VI.forEach(t),D3o=i(S),rl=n(S,"LI",{});var XI=s(rl);spe=n(XI,"STRONG",{});var Uxt=s(spe);j3o=r(Uxt,"mt5"),Uxt.forEach(t),G3o=r(XI," \u2014 "),HG=n(XI,"A",{href:!0});var Hxt=s(HG);O3o=r(Hxt,"MT5Tokenizer"),Hxt.forEach(t),V3o=r(XI," or "),JG=n(XI,"A",{href:!0});var Jxt=s(JG);X3o=r(Jxt,"MT5TokenizerFast"),Jxt.forEach(t),z3o=r(XI," (MT5 model)"),XI.forEach(t),Q3o=i(S),tl=n(S,"LI",{});var zI=s(tl);lpe=n(zI,"STRONG",{});var Yxt=s(lpe);W3o=r(Yxt,"mvp"),Yxt.forEach(t),U3o=r(zI," \u2014 "),YG=n(zI,"A",{href:!0});var Zxt=s(YG);H3o=r(Zxt,"MvpTokenizer"),Zxt.forEach(t),J3o=r(zI," or "),ZG=n(zI,"A",{href:!0});var Kxt=s(ZG);Y3o=r(Kxt,"MvpTokenizerFast"),Kxt.forEach(t),Z3o=r(zI," (MVP model)"),zI.forEach(t),K3o=i(S),al=n(S,"LI",{});var QI=s(al);ipe=n(QI,"STRONG",{});var e$t=s(ipe);e5o=r(e$t,"nezha"),e$t.forEach(t),o5o=r(QI," \u2014 "),KG=n(QI,"A",{href:!0});var o$t=s(KG);r5o=r(o$t,"BertTokenizer"),o$t.forEach(t),t5o=r(QI," or "),eO=n(QI,"A",{href:!0});var r$t=s(eO);a5o=r(r$t,"BertTokenizerFast"),r$t.forEach(t),n5o=r(QI," (Nezha model)"),QI.forEach(t),s5o=i(S),nl=n(S,"LI",{});var WI=s(nl);dpe=n(WI,"STRONG",{});var t$t=s(dpe);l5o=r(t$t,"nllb"),t$t.forEach(t),i5o=r(WI," \u2014 "),oO=n(WI,"A",{href:!0});var a$t=s(oO);d5o=r(a$t,"NllbTokenizer"),a$t.forEach(t),m5o=r(WI," or "),rO=n(WI,"A",{href:!0});var n$t=s(rO);c5o=r(n$t,"NllbTokenizerFast"),n$t.forEach(t),f5o=r(WI," (NLLB model)"),WI.forEach(t),g5o=i(S),sl=n(S,"LI",{});var UI=s(sl);mpe=n(UI,"STRONG",{});var s$t=s(mpe);h5o=r(s$t,"nystromformer"),s$t.forEach(t),u5o=r(UI," \u2014 "),tO=n(UI,"A",{href:!0});var l$t=s(tO);p5o=r(l$t,"AlbertTokenizer"),l$t.forEach(t),_5o=r(UI," or "),aO=n(UI,"A",{href:!0});var i$t=s(aO);b5o=r(i$t,"AlbertTokenizerFast"),i$t.forEach(t),v5o=r(UI," (Nystr\xF6mformer model)"),UI.forEach(t),F5o=i(S),ll=n(S,"LI",{});var HI=s(ll);cpe=n(HI,"STRONG",{});var d$t=s(cpe);T5o=r(d$t,"openai-gpt"),d$t.forEach(t),M5o=r(HI," \u2014 "),nO=n(HI,"A",{href:!0});var m$t=s(nO);E5o=r(m$t,"OpenAIGPTTokenizer"),m$t.forEach(t),C5o=r(HI," or "),sO=n(HI,"A",{href:!0});var c$t=s(sO);w5o=r(c$t,"OpenAIGPTTokenizerFast"),c$t.forEach(t),A5o=r(HI," (OpenAI GPT model)"),HI.forEach(t),L5o=i(S),Qu=n(S,"LI",{});var iDe=s(Qu);fpe=n(iDe,"STRONG",{});var f$t=s(fpe);y5o=r(f$t,"opt"),f$t.forEach(t),x5o=r(iDe," \u2014 "),lO=n(iDe,"A",{href:!0});var g$t=s(lO);$5o=r(g$t,"GPT2Tokenizer"),g$t.forEach(t),k5o=r(iDe," (OPT model)"),iDe.forEach(t),S5o=i(S),il=n(S,"LI",{});var JI=s(il);gpe=n(JI,"STRONG",{});var h$t=s(gpe);R5o=r(h$t,"owlvit"),h$t.forEach(t),P5o=r(JI," \u2014 "),iO=n(JI,"A",{href:!0});var u$t=s(iO);B5o=r(u$t,"CLIPTokenizer"),u$t.forEach(t),I5o=r(JI," or "),dO=n(JI,"A",{href:!0});var p$t=s(dO);N5o=r(p$t,"CLIPTokenizerFast"),p$t.forEach(t),q5o=r(JI," (OWL-ViT model)"),JI.forEach(t),D5o=i(S),dl=n(S,"LI",{});var YI=s(dl);hpe=n(YI,"STRONG",{});var _$t=s(hpe);j5o=r(_$t,"pegasus"),_$t.forEach(t),G5o=r(YI," \u2014 "),mO=n(YI,"A",{href:!0});var b$t=s(mO);O5o=r(b$t,"PegasusTokenizer"),b$t.forEach(t),V5o=r(YI," or "),cO=n(YI,"A",{href:!0});var v$t=s(cO);X5o=r(v$t,"PegasusTokenizerFast"),v$t.forEach(t),z5o=r(YI," (Pegasus model)"),YI.forEach(t),Q5o=i(S),Wu=n(S,"LI",{});var dDe=s(Wu);upe=n(dDe,"STRONG",{});var F$t=s(upe);W5o=r(F$t,"perceiver"),F$t.forEach(t),U5o=r(dDe," \u2014 "),fO=n(dDe,"A",{href:!0});var T$t=s(fO);H5o=r(T$t,"PerceiverTokenizer"),T$t.forEach(t),J5o=r(dDe," (Perceiver model)"),dDe.forEach(t),Y5o=i(S),Uu=n(S,"LI",{});var mDe=s(Uu);ppe=n(mDe,"STRONG",{});var M$t=s(ppe);Z5o=r(M$t,"phobert"),M$t.forEach(t),K5o=r(mDe," \u2014 "),gO=n(mDe,"A",{href:!0});var E$t=s(gO);e0o=r(E$t,"PhobertTokenizer"),E$t.forEach(t),o0o=r(mDe," (PhoBERT model)"),mDe.forEach(t),r0o=i(S),Hu=n(S,"LI",{});var cDe=s(Hu);_pe=n(cDe,"STRONG",{});var C$t=s(_pe);t0o=r(C$t,"plbart"),C$t.forEach(t),a0o=r(cDe," \u2014 "),hO=n(cDe,"A",{href:!0});var w$t=s(hO);n0o=r(w$t,"PLBartTokenizer"),w$t.forEach(t),s0o=r(cDe," (PLBart model)"),cDe.forEach(t),l0o=i(S),Ju=n(S,"LI",{});var fDe=s(Ju);bpe=n(fDe,"STRONG",{});var A$t=s(bpe);i0o=r(A$t,"prophetnet"),A$t.forEach(t),d0o=r(fDe," \u2014 "),uO=n(fDe,"A",{href:!0});var L$t=s(uO);m0o=r(L$t,"ProphetNetTokenizer"),L$t.forEach(t),c0o=r(fDe," (ProphetNet model)"),fDe.forEach(t),f0o=i(S),ml=n(S,"LI",{});var ZI=s(ml);vpe=n(ZI,"STRONG",{});var y$t=s(vpe);g0o=r(y$t,"qdqbert"),y$t.forEach(t),h0o=r(ZI," \u2014 "),pO=n(ZI,"A",{href:!0});var x$t=s(pO);u0o=r(x$t,"BertTokenizer"),x$t.forEach(t),p0o=r(ZI," or "),_O=n(ZI,"A",{href:!0});var $$t=s(_O);_0o=r($$t,"BertTokenizerFast"),$$t.forEach(t),b0o=r(ZI," (QDQBert model)"),ZI.forEach(t),v0o=i(S),Yu=n(S,"LI",{});var gDe=s(Yu);Fpe=n(gDe,"STRONG",{});var k$t=s(Fpe);F0o=r(k$t,"rag"),k$t.forEach(t),T0o=r(gDe," \u2014 "),bO=n(gDe,"A",{href:!0});var S$t=s(bO);M0o=r(S$t,"RagTokenizer"),S$t.forEach(t),E0o=r(gDe," (RAG model)"),gDe.forEach(t),C0o=i(S),cl=n(S,"LI",{});var KI=s(cl);Tpe=n(KI,"STRONG",{});var R$t=s(Tpe);w0o=r(R$t,"realm"),R$t.forEach(t),A0o=r(KI," \u2014 "),vO=n(KI,"A",{href:!0});var P$t=s(vO);L0o=r(P$t,"RealmTokenizer"),P$t.forEach(t),y0o=r(KI," or "),FO=n(KI,"A",{href:!0});var B$t=s(FO);x0o=r(B$t,"RealmTokenizerFast"),B$t.forEach(t),$0o=r(KI," (REALM model)"),KI.forEach(t),k0o=i(S),fl=n(S,"LI",{});var eN=s(fl);Mpe=n(eN,"STRONG",{});var I$t=s(Mpe);S0o=r(I$t,"reformer"),I$t.forEach(t),R0o=r(eN," \u2014 "),TO=n(eN,"A",{href:!0});var N$t=s(TO);P0o=r(N$t,"ReformerTokenizer"),N$t.forEach(t),B0o=r(eN," or "),MO=n(eN,"A",{href:!0});var q$t=s(MO);I0o=r(q$t,"ReformerTokenizerFast"),q$t.forEach(t),N0o=r(eN," (Reformer model)"),eN.forEach(t),q0o=i(S),gl=n(S,"LI",{});var oN=s(gl);Epe=n(oN,"STRONG",{});var D$t=s(Epe);D0o=r(D$t,"rembert"),D$t.forEach(t),j0o=r(oN," \u2014 "),EO=n(oN,"A",{href:!0});var j$t=s(EO);G0o=r(j$t,"RemBertTokenizer"),j$t.forEach(t),O0o=r(oN," or "),CO=n(oN,"A",{href:!0});var G$t=s(CO);V0o=r(G$t,"RemBertTokenizerFast"),G$t.forEach(t),X0o=r(oN," (RemBERT model)"),oN.forEach(t),z0o=i(S),hl=n(S,"LI",{});var rN=s(hl);Cpe=n(rN,"STRONG",{});var O$t=s(Cpe);Q0o=r(O$t,"retribert"),O$t.forEach(t),W0o=r(rN," \u2014 "),wO=n(rN,"A",{href:!0});var V$t=s(wO);U0o=r(V$t,"RetriBertTokenizer"),V$t.forEach(t),H0o=r(rN," or "),AO=n(rN,"A",{href:!0});var X$t=s(AO);J0o=r(X$t,"RetriBertTokenizerFast"),X$t.forEach(t),Y0o=r(rN," (RetriBERT model)"),rN.forEach(t),Z0o=i(S),ul=n(S,"LI",{});var tN=s(ul);wpe=n(tN,"STRONG",{});var z$t=s(wpe);K0o=r(z$t,"roberta"),z$t.forEach(t),ewo=r(tN," \u2014 "),LO=n(tN,"A",{href:!0});var Q$t=s(LO);owo=r(Q$t,"RobertaTokenizer"),Q$t.forEach(t),rwo=r(tN," or "),yO=n(tN,"A",{href:!0});var W$t=s(yO);two=r(W$t,"RobertaTokenizerFast"),W$t.forEach(t),awo=r(tN," (RoBERTa model)"),tN.forEach(t),nwo=i(S),pl=n(S,"LI",{});var aN=s(pl);Ape=n(aN,"STRONG",{});var U$t=s(Ape);swo=r(U$t,"roformer"),U$t.forEach(t),lwo=r(aN," \u2014 "),xO=n(aN,"A",{href:!0});var H$t=s(xO);iwo=r(H$t,"RoFormerTokenizer"),H$t.forEach(t),dwo=r(aN," or "),$O=n(aN,"A",{href:!0});var J$t=s($O);mwo=r(J$t,"RoFormerTokenizerFast"),J$t.forEach(t),cwo=r(aN," (RoFormer model)"),aN.forEach(t),fwo=i(S),Zu=n(S,"LI",{});var hDe=s(Zu);Lpe=n(hDe,"STRONG",{});var Y$t=s(Lpe);gwo=r(Y$t,"speech_to_text"),Y$t.forEach(t),hwo=r(hDe," \u2014 "),kO=n(hDe,"A",{href:!0});var Z$t=s(kO);uwo=r(Z$t,"Speech2TextTokenizer"),Z$t.forEach(t),pwo=r(hDe," (Speech2Text model)"),hDe.forEach(t),_wo=i(S),Ku=n(S,"LI",{});var uDe=s(Ku);ype=n(uDe,"STRONG",{});var K$t=s(ype);bwo=r(K$t,"speech_to_text_2"),K$t.forEach(t),vwo=r(uDe," \u2014 "),SO=n(uDe,"A",{href:!0});var ekt=s(SO);Fwo=r(ekt,"Speech2Text2Tokenizer"),ekt.forEach(t),Two=r(uDe," (Speech2Text2 model)"),uDe.forEach(t),Mwo=i(S),_l=n(S,"LI",{});var nN=s(_l);xpe=n(nN,"STRONG",{});var okt=s(xpe);Ewo=r(okt,"splinter"),okt.forEach(t),Cwo=r(nN," \u2014 "),RO=n(nN,"A",{href:!0});var rkt=s(RO);wwo=r(rkt,"SplinterTokenizer"),rkt.forEach(t),Awo=r(nN," or "),PO=n(nN,"A",{href:!0});var tkt=s(PO);Lwo=r(tkt,"SplinterTokenizerFast"),tkt.forEach(t),ywo=r(nN," (Splinter model)"),nN.forEach(t),xwo=i(S),bl=n(S,"LI",{});var sN=s(bl);$pe=n(sN,"STRONG",{});var akt=s($pe);$wo=r(akt,"squeezebert"),akt.forEach(t),kwo=r(sN," \u2014 "),BO=n(sN,"A",{href:!0});var nkt=s(BO);Swo=r(nkt,"SqueezeBertTokenizer"),nkt.forEach(t),Rwo=r(sN," or "),IO=n(sN,"A",{href:!0});var skt=s(IO);Pwo=r(skt,"SqueezeBertTokenizerFast"),skt.forEach(t),Bwo=r(sN," (SqueezeBERT model)"),sN.forEach(t),Iwo=i(S),vl=n(S,"LI",{});var lN=s(vl);kpe=n(lN,"STRONG",{});var lkt=s(kpe);Nwo=r(lkt,"t5"),lkt.forEach(t),qwo=r(lN," \u2014 "),NO=n(lN,"A",{href:!0});var ikt=s(NO);Dwo=r(ikt,"T5Tokenizer"),ikt.forEach(t),jwo=r(lN," or "),qO=n(lN,"A",{href:!0});var dkt=s(qO);Gwo=r(dkt,"T5TokenizerFast"),dkt.forEach(t),Owo=r(lN," (T5 model)"),lN.forEach(t),Vwo=i(S),ep=n(S,"LI",{});var pDe=s(ep);Spe=n(pDe,"STRONG",{});var mkt=s(Spe);Xwo=r(mkt,"tapas"),mkt.forEach(t),zwo=r(pDe," \u2014 "),DO=n(pDe,"A",{href:!0});var ckt=s(DO);Qwo=r(ckt,"TapasTokenizer"),ckt.forEach(t),Wwo=r(pDe," (TAPAS model)"),pDe.forEach(t),Uwo=i(S),op=n(S,"LI",{});var _De=s(op);Rpe=n(_De,"STRONG",{});var fkt=s(Rpe);Hwo=r(fkt,"tapex"),fkt.forEach(t),Jwo=r(_De," \u2014 "),jO=n(_De,"A",{href:!0});var gkt=s(jO);Ywo=r(gkt,"TapexTokenizer"),gkt.forEach(t),Zwo=r(_De," (TAPEX model)"),_De.forEach(t),Kwo=i(S),rp=n(S,"LI",{});var bDe=s(rp);Ppe=n(bDe,"STRONG",{});var hkt=s(Ppe);eAo=r(hkt,"transfo-xl"),hkt.forEach(t),oAo=r(bDe," \u2014 "),GO=n(bDe,"A",{href:!0});var ukt=s(GO);rAo=r(ukt,"TransfoXLTokenizer"),ukt.forEach(t),tAo=r(bDe," (Transformer-XL model)"),bDe.forEach(t),aAo=i(S),Fl=n(S,"LI",{});var iN=s(Fl);Bpe=n(iN,"STRONG",{});var pkt=s(Bpe);nAo=r(pkt,"vilt"),pkt.forEach(t),sAo=r(iN," \u2014 "),OO=n(iN,"A",{href:!0});var _kt=s(OO);lAo=r(_kt,"BertTokenizer"),_kt.forEach(t),iAo=r(iN," or "),VO=n(iN,"A",{href:!0});var bkt=s(VO);dAo=r(bkt,"BertTokenizerFast"),bkt.forEach(t),mAo=r(iN," (ViLT model)"),iN.forEach(t),cAo=i(S),Tl=n(S,"LI",{});var dN=s(Tl);Ipe=n(dN,"STRONG",{});var vkt=s(Ipe);fAo=r(vkt,"visual_bert"),vkt.forEach(t),gAo=r(dN," \u2014 "),XO=n(dN,"A",{href:!0});var Fkt=s(XO);hAo=r(Fkt,"BertTokenizer"),Fkt.forEach(t),uAo=r(dN," or "),zO=n(dN,"A",{href:!0});var Tkt=s(zO);pAo=r(Tkt,"BertTokenizerFast"),Tkt.forEach(t),_Ao=r(dN," (VisualBERT model)"),dN.forEach(t),bAo=i(S),tp=n(S,"LI",{});var vDe=s(tp);Npe=n(vDe,"STRONG",{});var Mkt=s(Npe);vAo=r(Mkt,"wav2vec2"),Mkt.forEach(t),FAo=r(vDe," \u2014 "),QO=n(vDe,"A",{href:!0});var Ekt=s(QO);TAo=r(Ekt,"Wav2Vec2CTCTokenizer"),Ekt.forEach(t),MAo=r(vDe," (Wav2Vec2 model)"),vDe.forEach(t),EAo=i(S),ap=n(S,"LI",{});var FDe=s(ap);qpe=n(FDe,"STRONG",{});var Ckt=s(qpe);CAo=r(Ckt,"wav2vec2-conformer"),Ckt.forEach(t),wAo=r(FDe," \u2014 "),WO=n(FDe,"A",{href:!0});var wkt=s(WO);AAo=r(wkt,"Wav2Vec2CTCTokenizer"),wkt.forEach(t),LAo=r(FDe," (Wav2Vec2-Conformer model)"),FDe.forEach(t),yAo=i(S),np=n(S,"LI",{});var TDe=s(np);Dpe=n(TDe,"STRONG",{});var Akt=s(Dpe);xAo=r(Akt,"wav2vec2_phoneme"),Akt.forEach(t),$Ao=r(TDe," \u2014 "),UO=n(TDe,"A",{href:!0});var Lkt=s(UO);kAo=r(Lkt,"Wav2Vec2PhonemeCTCTokenizer"),Lkt.forEach(t),SAo=r(TDe," (Wav2Vec2Phoneme model)"),TDe.forEach(t),RAo=i(S),sp=n(S,"LI",{});var MDe=s(sp);jpe=n(MDe,"STRONG",{});var ykt=s(jpe);PAo=r(ykt,"whisper"),ykt.forEach(t),BAo=r(MDe," \u2014 "),HO=n(MDe,"A",{href:!0});var xkt=s(HO);IAo=r(xkt,"WhisperTokenizer"),xkt.forEach(t),NAo=r(MDe," (Whisper model)"),MDe.forEach(t),qAo=i(S),Ml=n(S,"LI",{});var mN=s(Ml);Gpe=n(mN,"STRONG",{});var $kt=s(Gpe);DAo=r($kt,"xclip"),$kt.forEach(t),jAo=r(mN," \u2014 "),JO=n(mN,"A",{href:!0});var kkt=s(JO);GAo=r(kkt,"CLIPTokenizer"),kkt.forEach(t),OAo=r(mN," or "),YO=n(mN,"A",{href:!0});var Skt=s(YO);VAo=r(Skt,"CLIPTokenizerFast"),Skt.forEach(t),XAo=r(mN," (X-CLIP model)"),mN.forEach(t),zAo=i(S),El=n(S,"LI",{});var cN=s(El);Ope=n(cN,"STRONG",{});var Rkt=s(Ope);QAo=r(Rkt,"xglm"),Rkt.forEach(t),WAo=r(cN," \u2014 "),ZO=n(cN,"A",{href:!0});var Pkt=s(ZO);UAo=r(Pkt,"XGLMTokenizer"),Pkt.forEach(t),HAo=r(cN," or "),KO=n(cN,"A",{href:!0});var Bkt=s(KO);JAo=r(Bkt,"XGLMTokenizerFast"),Bkt.forEach(t),YAo=r(cN," (XGLM model)"),cN.forEach(t),ZAo=i(S),lp=n(S,"LI",{});var EDe=s(lp);Vpe=n(EDe,"STRONG",{});var Ikt=s(Vpe);KAo=r(Ikt,"xlm"),Ikt.forEach(t),e6o=r(EDe," \u2014 "),eV=n(EDe,"A",{href:!0});var Nkt=s(eV);o6o=r(Nkt,"XLMTokenizer"),Nkt.forEach(t),r6o=r(EDe," (XLM model)"),EDe.forEach(t),t6o=i(S),ip=n(S,"LI",{});var CDe=s(ip);Xpe=n(CDe,"STRONG",{});var qkt=s(Xpe);a6o=r(qkt,"xlm-prophetnet"),qkt.forEach(t),n6o=r(CDe," \u2014 "),oV=n(CDe,"A",{href:!0});var Dkt=s(oV);s6o=r(Dkt,"XLMProphetNetTokenizer"),Dkt.forEach(t),l6o=r(CDe," (XLM-ProphetNet model)"),CDe.forEach(t),i6o=i(S),Cl=n(S,"LI",{});var fN=s(Cl);zpe=n(fN,"STRONG",{});var jkt=s(zpe);d6o=r(jkt,"xlm-roberta"),jkt.forEach(t),m6o=r(fN," \u2014 "),rV=n(fN,"A",{href:!0});var Gkt=s(rV);c6o=r(Gkt,"XLMRobertaTokenizer"),Gkt.forEach(t),f6o=r(fN," or "),tV=n(fN,"A",{href:!0});var Okt=s(tV);g6o=r(Okt,"XLMRobertaTokenizerFast"),Okt.forEach(t),h6o=r(fN," (XLM-RoBERTa model)"),fN.forEach(t),u6o=i(S),wl=n(S,"LI",{});var gN=s(wl);Qpe=n(gN,"STRONG",{});var Vkt=s(Qpe);p6o=r(Vkt,"xlm-roberta-xl"),Vkt.forEach(t),_6o=r(gN," \u2014 "),aV=n(gN,"A",{href:!0});var Xkt=s(aV);b6o=r(Xkt,"XLMRobertaTokenizer"),Xkt.forEach(t),v6o=r(gN," or "),nV=n(gN,"A",{href:!0});var zkt=s(nV);F6o=r(zkt,"XLMRobertaTokenizerFast"),zkt.forEach(t),T6o=r(gN," (XLM-RoBERTa-XL model)"),gN.forEach(t),M6o=i(S),Al=n(S,"LI",{});var hN=s(Al);Wpe=n(hN,"STRONG",{});var Qkt=s(Wpe);E6o=r(Qkt,"xlnet"),Qkt.forEach(t),C6o=r(hN," \u2014 "),sV=n(hN,"A",{href:!0});var Wkt=s(sV);w6o=r(Wkt,"XLNetTokenizer"),Wkt.forEach(t),A6o=r(hN," or "),lV=n(hN,"A",{href:!0});var Ukt=s(lV);L6o=r(Ukt,"XLNetTokenizerFast"),Ukt.forEach(t),y6o=r(hN," (XLNet model)"),hN.forEach(t),x6o=i(S),Ll=n(S,"LI",{});var uN=s(Ll);Upe=n(uN,"STRONG",{});var Hkt=s(Upe);$6o=r(Hkt,"yoso"),Hkt.forEach(t),k6o=r(uN," \u2014 "),iV=n(uN,"A",{href:!0});var Jkt=s(iV);S6o=r(Jkt,"AlbertTokenizer"),Jkt.forEach(t),R6o=r(uN," or "),dV=n(uN,"A",{href:!0});var Ykt=s(dV);P6o=r(Ykt,"AlbertTokenizerFast"),Ykt.forEach(t),B6o=r(uN," (YOSO model)"),uN.forEach(t),S.forEach(t),I6o=i(Pl),T(dp.$$.fragment,Pl),Pl.forEach(t),N6o=i(Rl),mp=n(Rl,"DIV",{class:!0});var Qno=s(mp);T(M$.$$.fragment,Qno),q6o=i(Qno),Hpe=n(Qno,"P",{});var Zkt=s(Hpe);D6o=r(Zkt,"Register a new tokenizer in this mapping."),Zkt.forEach(t),Qno.forEach(t),Rl.forEach(t),Rto=i(c),yd=n(c,"H2",{class:!0});var Wno=s(yd);cp=n(Wno,"A",{id:!0,class:!0,href:!0});var Kkt=s(cp);Jpe=n(Kkt,"SPAN",{});var eSt=s(Jpe);T(E$.$$.fragment,eSt),eSt.forEach(t),Kkt.forEach(t),j6o=i(Wno),Ype=n(Wno,"SPAN",{});var oSt=s(Ype);G6o=r(oSt,"AutoFeatureExtractor"),oSt.forEach(t),Wno.forEach(t),Pto=i(c),Po=n(c,"DIV",{class:!0});var Bl=s(Po);T(C$.$$.fragment,Bl),O6o=i(Bl),w$=n(Bl,"P",{});var Uno=s(w$);V6o=r(Uno,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),mV=n(Uno,"A",{href:!0});var rSt=s(mV);X6o=r(rSt,"AutoFeatureExtractor.from_pretrained()"),rSt.forEach(t),z6o=r(Uno," class method."),Uno.forEach(t),Q6o=i(Bl),A$=n(Bl,"P",{});var Hno=s(A$);W6o=r(Hno,"This class cannot be instantiated directly using "),Zpe=n(Hno,"CODE",{});var tSt=s(Zpe);U6o=r(tSt,"__init__()"),tSt.forEach(t),H6o=r(Hno," (throws an error)."),Hno.forEach(t),J6o=i(Bl),Ye=n(Bl,"DIV",{class:!0});var wa=s(Ye);T(L$.$$.fragment,wa),Y6o=i(wa),Kpe=n(wa,"P",{});var aSt=s(Kpe);Z6o=r(aSt,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),aSt.forEach(t),K6o=i(wa),an=n(wa,"P",{});var Ky=s(an);e7o=r(Ky,"The feature extractor class to instantiate is selected based on the "),e_e=n(Ky,"CODE",{});var nSt=s(e_e);o7o=r(nSt,"model_type"),nSt.forEach(t),r7o=r(Ky,` property of the config object
(either passed as an argument or loaded from `),o_e=n(Ky,"CODE",{});var sSt=s(o_e);t7o=r(sSt,"pretrained_model_name_or_path"),sSt.forEach(t),a7o=r(Ky,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),r_e=n(Ky,"CODE",{});var lSt=s(r_e);n7o=r(lSt,"pretrained_model_name_or_path"),lSt.forEach(t),s7o=r(Ky,":"),Ky.forEach(t),l7o=i(wa),z=n(wa,"UL",{});var Q=s(z);fp=n(Q,"LI",{});var wDe=s(fp);t_e=n(wDe,"STRONG",{});var iSt=s(t_e);i7o=r(iSt,"beit"),iSt.forEach(t),d7o=r(wDe," \u2014 "),cV=n(wDe,"A",{href:!0});var dSt=s(cV);m7o=r(dSt,"BeitFeatureExtractor"),dSt.forEach(t),c7o=r(wDe," (BEiT model)"),wDe.forEach(t),f7o=i(Q),gp=n(Q,"LI",{});var ADe=s(gp);a_e=n(ADe,"STRONG",{});var mSt=s(a_e);g7o=r(mSt,"clip"),mSt.forEach(t),h7o=r(ADe," \u2014 "),fV=n(ADe,"A",{href:!0});var cSt=s(fV);u7o=r(cSt,"CLIPFeatureExtractor"),cSt.forEach(t),p7o=r(ADe," (CLIP model)"),ADe.forEach(t),_7o=i(Q),hp=n(Q,"LI",{});var LDe=s(hp);n_e=n(LDe,"STRONG",{});var fSt=s(n_e);b7o=r(fSt,"conditional_detr"),fSt.forEach(t),v7o=r(LDe," \u2014 "),gV=n(LDe,"A",{href:!0});var gSt=s(gV);F7o=r(gSt,"ConditionalDetrFeatureExtractor"),gSt.forEach(t),T7o=r(LDe," (Conditional DETR model)"),LDe.forEach(t),M7o=i(Q),up=n(Q,"LI",{});var yDe=s(up);s_e=n(yDe,"STRONG",{});var hSt=s(s_e);E7o=r(hSt,"convnext"),hSt.forEach(t),C7o=r(yDe," \u2014 "),hV=n(yDe,"A",{href:!0});var uSt=s(hV);w7o=r(uSt,"ConvNextFeatureExtractor"),uSt.forEach(t),A7o=r(yDe," (ConvNeXT model)"),yDe.forEach(t),L7o=i(Q),pp=n(Q,"LI",{});var xDe=s(pp);l_e=n(xDe,"STRONG",{});var pSt=s(l_e);y7o=r(pSt,"cvt"),pSt.forEach(t),x7o=r(xDe," \u2014 "),uV=n(xDe,"A",{href:!0});var _St=s(uV);$7o=r(_St,"ConvNextFeatureExtractor"),_St.forEach(t),k7o=r(xDe," (CvT model)"),xDe.forEach(t),S7o=i(Q),_p=n(Q,"LI",{});var $De=s(_p);i_e=n($De,"STRONG",{});var bSt=s(i_e);R7o=r(bSt,"data2vec-audio"),bSt.forEach(t),P7o=r($De," \u2014 "),pV=n($De,"A",{href:!0});var vSt=s(pV);B7o=r(vSt,"Wav2Vec2FeatureExtractor"),vSt.forEach(t),I7o=r($De," (Data2VecAudio model)"),$De.forEach(t),N7o=i(Q),bp=n(Q,"LI",{});var kDe=s(bp);d_e=n(kDe,"STRONG",{});var FSt=s(d_e);q7o=r(FSt,"data2vec-vision"),FSt.forEach(t),D7o=r(kDe," \u2014 "),_V=n(kDe,"A",{href:!0});var TSt=s(_V);j7o=r(TSt,"BeitFeatureExtractor"),TSt.forEach(t),G7o=r(kDe," (Data2VecVision model)"),kDe.forEach(t),O7o=i(Q),vp=n(Q,"LI",{});var SDe=s(vp);m_e=n(SDe,"STRONG",{});var MSt=s(m_e);V7o=r(MSt,"deformable_detr"),MSt.forEach(t),X7o=r(SDe," \u2014 "),bV=n(SDe,"A",{href:!0});var ESt=s(bV);z7o=r(ESt,"DeformableDetrFeatureExtractor"),ESt.forEach(t),Q7o=r(SDe," (Deformable DETR model)"),SDe.forEach(t),W7o=i(Q),Fp=n(Q,"LI",{});var RDe=s(Fp);c_e=n(RDe,"STRONG",{});var CSt=s(c_e);U7o=r(CSt,"deit"),CSt.forEach(t),H7o=r(RDe," \u2014 "),vV=n(RDe,"A",{href:!0});var wSt=s(vV);J7o=r(wSt,"DeiTFeatureExtractor"),wSt.forEach(t),Y7o=r(RDe," (DeiT model)"),RDe.forEach(t),Z7o=i(Q),Tp=n(Q,"LI",{});var PDe=s(Tp);f_e=n(PDe,"STRONG",{});var ASt=s(f_e);K7o=r(ASt,"detr"),ASt.forEach(t),e8o=r(PDe," \u2014 "),FV=n(PDe,"A",{href:!0});var LSt=s(FV);o8o=r(LSt,"DetrFeatureExtractor"),LSt.forEach(t),r8o=r(PDe," (DETR model)"),PDe.forEach(t),t8o=i(Q),Mp=n(Q,"LI",{});var BDe=s(Mp);g_e=n(BDe,"STRONG",{});var ySt=s(g_e);a8o=r(ySt,"donut"),ySt.forEach(t),n8o=r(BDe," \u2014 "),TV=n(BDe,"A",{href:!0});var xSt=s(TV);s8o=r(xSt,"DonutFeatureExtractor"),xSt.forEach(t),l8o=r(BDe," (Donut model)"),BDe.forEach(t),i8o=i(Q),Ep=n(Q,"LI",{});var IDe=s(Ep);h_e=n(IDe,"STRONG",{});var $St=s(h_e);d8o=r($St,"dpt"),$St.forEach(t),m8o=r(IDe," \u2014 "),MV=n(IDe,"A",{href:!0});var kSt=s(MV);c8o=r(kSt,"DPTFeatureExtractor"),kSt.forEach(t),f8o=r(IDe," (DPT model)"),IDe.forEach(t),g8o=i(Q),Cp=n(Q,"LI",{});var NDe=s(Cp);u_e=n(NDe,"STRONG",{});var SSt=s(u_e);h8o=r(SSt,"flava"),SSt.forEach(t),u8o=r(NDe," \u2014 "),EV=n(NDe,"A",{href:!0});var RSt=s(EV);p8o=r(RSt,"FlavaFeatureExtractor"),RSt.forEach(t),_8o=r(NDe," (FLAVA model)"),NDe.forEach(t),b8o=i(Q),wp=n(Q,"LI",{});var qDe=s(wp);p_e=n(qDe,"STRONG",{});var PSt=s(p_e);v8o=r(PSt,"glpn"),PSt.forEach(t),F8o=r(qDe," \u2014 "),CV=n(qDe,"A",{href:!0});var BSt=s(CV);T8o=r(BSt,"GLPNFeatureExtractor"),BSt.forEach(t),M8o=r(qDe," (GLPN model)"),qDe.forEach(t),E8o=i(Q),Ap=n(Q,"LI",{});var DDe=s(Ap);__e=n(DDe,"STRONG",{});var ISt=s(__e);C8o=r(ISt,"groupvit"),ISt.forEach(t),w8o=r(DDe," \u2014 "),wV=n(DDe,"A",{href:!0});var NSt=s(wV);A8o=r(NSt,"CLIPFeatureExtractor"),NSt.forEach(t),L8o=r(DDe," (GroupViT model)"),DDe.forEach(t),y8o=i(Q),Lp=n(Q,"LI",{});var jDe=s(Lp);b_e=n(jDe,"STRONG",{});var qSt=s(b_e);x8o=r(qSt,"hubert"),qSt.forEach(t),$8o=r(jDe," \u2014 "),AV=n(jDe,"A",{href:!0});var DSt=s(AV);k8o=r(DSt,"Wav2Vec2FeatureExtractor"),DSt.forEach(t),S8o=r(jDe," (Hubert model)"),jDe.forEach(t),R8o=i(Q),yp=n(Q,"LI",{});var GDe=s(yp);v_e=n(GDe,"STRONG",{});var jSt=s(v_e);P8o=r(jSt,"imagegpt"),jSt.forEach(t),B8o=r(GDe," \u2014 "),LV=n(GDe,"A",{href:!0});var GSt=s(LV);I8o=r(GSt,"ImageGPTFeatureExtractor"),GSt.forEach(t),N8o=r(GDe," (ImageGPT model)"),GDe.forEach(t),q8o=i(Q),xp=n(Q,"LI",{});var ODe=s(xp);F_e=n(ODe,"STRONG",{});var OSt=s(F_e);D8o=r(OSt,"layoutlmv2"),OSt.forEach(t),j8o=r(ODe," \u2014 "),yV=n(ODe,"A",{href:!0});var VSt=s(yV);G8o=r(VSt,"LayoutLMv2FeatureExtractor"),VSt.forEach(t),O8o=r(ODe," (LayoutLMv2 model)"),ODe.forEach(t),V8o=i(Q),$p=n(Q,"LI",{});var VDe=s($p);T_e=n(VDe,"STRONG",{});var XSt=s(T_e);X8o=r(XSt,"layoutlmv3"),XSt.forEach(t),z8o=r(VDe," \u2014 "),xV=n(VDe,"A",{href:!0});var zSt=s(xV);Q8o=r(zSt,"LayoutLMv3FeatureExtractor"),zSt.forEach(t),W8o=r(VDe," (LayoutLMv3 model)"),VDe.forEach(t),U8o=i(Q),kp=n(Q,"LI",{});var XDe=s(kp);M_e=n(XDe,"STRONG",{});var QSt=s(M_e);H8o=r(QSt,"levit"),QSt.forEach(t),J8o=r(XDe," \u2014 "),$V=n(XDe,"A",{href:!0});var WSt=s($V);Y8o=r(WSt,"LevitFeatureExtractor"),WSt.forEach(t),Z8o=r(XDe," (LeViT model)"),XDe.forEach(t),K8o=i(Q),Sp=n(Q,"LI",{});var zDe=s(Sp);E_e=n(zDe,"STRONG",{});var USt=s(E_e);eLo=r(USt,"maskformer"),USt.forEach(t),oLo=r(zDe," \u2014 "),kV=n(zDe,"A",{href:!0});var HSt=s(kV);rLo=r(HSt,"MaskFormerFeatureExtractor"),HSt.forEach(t),tLo=r(zDe," (MaskFormer model)"),zDe.forEach(t),aLo=i(Q),Rp=n(Q,"LI",{});var QDe=s(Rp);C_e=n(QDe,"STRONG",{});var JSt=s(C_e);nLo=r(JSt,"mctct"),JSt.forEach(t),sLo=r(QDe," \u2014 "),SV=n(QDe,"A",{href:!0});var YSt=s(SV);lLo=r(YSt,"MCTCTFeatureExtractor"),YSt.forEach(t),iLo=r(QDe," (M-CTC-T model)"),QDe.forEach(t),dLo=i(Q),Pp=n(Q,"LI",{});var WDe=s(Pp);w_e=n(WDe,"STRONG",{});var ZSt=s(w_e);mLo=r(ZSt,"mobilevit"),ZSt.forEach(t),cLo=r(WDe," \u2014 "),RV=n(WDe,"A",{href:!0});var KSt=s(RV);fLo=r(KSt,"MobileViTFeatureExtractor"),KSt.forEach(t),gLo=r(WDe," (MobileViT model)"),WDe.forEach(t),hLo=i(Q),Bp=n(Q,"LI",{});var UDe=s(Bp);A_e=n(UDe,"STRONG",{});var eRt=s(A_e);uLo=r(eRt,"owlvit"),eRt.forEach(t),pLo=r(UDe," \u2014 "),PV=n(UDe,"A",{href:!0});var oRt=s(PV);_Lo=r(oRt,"OwlViTFeatureExtractor"),oRt.forEach(t),bLo=r(UDe," (OWL-ViT model)"),UDe.forEach(t),vLo=i(Q),Ip=n(Q,"LI",{});var HDe=s(Ip);L_e=n(HDe,"STRONG",{});var rRt=s(L_e);FLo=r(rRt,"perceiver"),rRt.forEach(t),TLo=r(HDe," \u2014 "),BV=n(HDe,"A",{href:!0});var tRt=s(BV);MLo=r(tRt,"PerceiverFeatureExtractor"),tRt.forEach(t),ELo=r(HDe," (Perceiver model)"),HDe.forEach(t),CLo=i(Q),Np=n(Q,"LI",{});var JDe=s(Np);y_e=n(JDe,"STRONG",{});var aRt=s(y_e);wLo=r(aRt,"poolformer"),aRt.forEach(t),ALo=r(JDe," \u2014 "),IV=n(JDe,"A",{href:!0});var nRt=s(IV);LLo=r(nRt,"PoolFormerFeatureExtractor"),nRt.forEach(t),yLo=r(JDe," (PoolFormer model)"),JDe.forEach(t),xLo=i(Q),qp=n(Q,"LI",{});var YDe=s(qp);x_e=n(YDe,"STRONG",{});var sRt=s(x_e);$Lo=r(sRt,"regnet"),sRt.forEach(t),kLo=r(YDe," \u2014 "),NV=n(YDe,"A",{href:!0});var lRt=s(NV);SLo=r(lRt,"ConvNextFeatureExtractor"),lRt.forEach(t),RLo=r(YDe," (RegNet model)"),YDe.forEach(t),PLo=i(Q),Dp=n(Q,"LI",{});var ZDe=s(Dp);$_e=n(ZDe,"STRONG",{});var iRt=s($_e);BLo=r(iRt,"resnet"),iRt.forEach(t),ILo=r(ZDe," \u2014 "),qV=n(ZDe,"A",{href:!0});var dRt=s(qV);NLo=r(dRt,"ConvNextFeatureExtractor"),dRt.forEach(t),qLo=r(ZDe," (ResNet model)"),ZDe.forEach(t),DLo=i(Q),jp=n(Q,"LI",{});var KDe=s(jp);k_e=n(KDe,"STRONG",{});var mRt=s(k_e);jLo=r(mRt,"segformer"),mRt.forEach(t),GLo=r(KDe," \u2014 "),DV=n(KDe,"A",{href:!0});var cRt=s(DV);OLo=r(cRt,"SegformerFeatureExtractor"),cRt.forEach(t),VLo=r(KDe," (SegFormer model)"),KDe.forEach(t),XLo=i(Q),Gp=n(Q,"LI",{});var eje=s(Gp);S_e=n(eje,"STRONG",{});var fRt=s(S_e);zLo=r(fRt,"speech_to_text"),fRt.forEach(t),QLo=r(eje," \u2014 "),jV=n(eje,"A",{href:!0});var gRt=s(jV);WLo=r(gRt,"Speech2TextFeatureExtractor"),gRt.forEach(t),ULo=r(eje," (Speech2Text model)"),eje.forEach(t),HLo=i(Q),Op=n(Q,"LI",{});var oje=s(Op);R_e=n(oje,"STRONG",{});var hRt=s(R_e);JLo=r(hRt,"swin"),hRt.forEach(t),YLo=r(oje," \u2014 "),GV=n(oje,"A",{href:!0});var uRt=s(GV);ZLo=r(uRt,"ViTFeatureExtractor"),uRt.forEach(t),KLo=r(oje," (Swin Transformer model)"),oje.forEach(t),eyo=i(Q),Vp=n(Q,"LI",{});var rje=s(Vp);P_e=n(rje,"STRONG",{});var pRt=s(P_e);oyo=r(pRt,"swinv2"),pRt.forEach(t),ryo=r(rje," \u2014 "),OV=n(rje,"A",{href:!0});var _Rt=s(OV);tyo=r(_Rt,"ViTFeatureExtractor"),_Rt.forEach(t),ayo=r(rje," (Swin Transformer V2 model)"),rje.forEach(t),nyo=i(Q),Xp=n(Q,"LI",{});var tje=s(Xp);B_e=n(tje,"STRONG",{});var bRt=s(B_e);syo=r(bRt,"table-transformer"),bRt.forEach(t),lyo=r(tje," \u2014 "),VV=n(tje,"A",{href:!0});var vRt=s(VV);iyo=r(vRt,"DetrFeatureExtractor"),vRt.forEach(t),dyo=r(tje," (Table Transformer model)"),tje.forEach(t),myo=i(Q),zp=n(Q,"LI",{});var aje=s(zp);I_e=n(aje,"STRONG",{});var FRt=s(I_e);cyo=r(FRt,"van"),FRt.forEach(t),fyo=r(aje," \u2014 "),XV=n(aje,"A",{href:!0});var TRt=s(XV);gyo=r(TRt,"ConvNextFeatureExtractor"),TRt.forEach(t),hyo=r(aje," (VAN model)"),aje.forEach(t),uyo=i(Q),Qp=n(Q,"LI",{});var nje=s(Qp);N_e=n(nje,"STRONG",{});var MRt=s(N_e);pyo=r(MRt,"videomae"),MRt.forEach(t),_yo=r(nje," \u2014 "),zV=n(nje,"A",{href:!0});var ERt=s(zV);byo=r(ERt,"VideoMAEFeatureExtractor"),ERt.forEach(t),vyo=r(nje," (VideoMAE model)"),nje.forEach(t),Fyo=i(Q),Wp=n(Q,"LI",{});var sje=s(Wp);q_e=n(sje,"STRONG",{});var CRt=s(q_e);Tyo=r(CRt,"vilt"),CRt.forEach(t),Myo=r(sje," \u2014 "),QV=n(sje,"A",{href:!0});var wRt=s(QV);Eyo=r(wRt,"ViltFeatureExtractor"),wRt.forEach(t),Cyo=r(sje," (ViLT model)"),sje.forEach(t),wyo=i(Q),Up=n(Q,"LI",{});var lje=s(Up);D_e=n(lje,"STRONG",{});var ARt=s(D_e);Ayo=r(ARt,"vit"),ARt.forEach(t),Lyo=r(lje," \u2014 "),WV=n(lje,"A",{href:!0});var LRt=s(WV);yyo=r(LRt,"ViTFeatureExtractor"),LRt.forEach(t),xyo=r(lje," (ViT model)"),lje.forEach(t),$yo=i(Q),Hp=n(Q,"LI",{});var ije=s(Hp);j_e=n(ije,"STRONG",{});var yRt=s(j_e);kyo=r(yRt,"vit_mae"),yRt.forEach(t),Syo=r(ije," \u2014 "),UV=n(ije,"A",{href:!0});var xRt=s(UV);Ryo=r(xRt,"ViTFeatureExtractor"),xRt.forEach(t),Pyo=r(ije," (ViTMAE model)"),ije.forEach(t),Byo=i(Q),Jp=n(Q,"LI",{});var dje=s(Jp);G_e=n(dje,"STRONG",{});var $Rt=s(G_e);Iyo=r($Rt,"vit_msn"),$Rt.forEach(t),Nyo=r(dje," \u2014 "),HV=n(dje,"A",{href:!0});var kRt=s(HV);qyo=r(kRt,"ViTFeatureExtractor"),kRt.forEach(t),Dyo=r(dje," (ViTMSN model)"),dje.forEach(t),jyo=i(Q),Yp=n(Q,"LI",{});var mje=s(Yp);O_e=n(mje,"STRONG",{});var SRt=s(O_e);Gyo=r(SRt,"wav2vec2"),SRt.forEach(t),Oyo=r(mje," \u2014 "),JV=n(mje,"A",{href:!0});var RRt=s(JV);Vyo=r(RRt,"Wav2Vec2FeatureExtractor"),RRt.forEach(t),Xyo=r(mje," (Wav2Vec2 model)"),mje.forEach(t),zyo=i(Q),Zp=n(Q,"LI",{});var cje=s(Zp);V_e=n(cje,"STRONG",{});var PRt=s(V_e);Qyo=r(PRt,"wav2vec2-conformer"),PRt.forEach(t),Wyo=r(cje," \u2014 "),YV=n(cje,"A",{href:!0});var BRt=s(YV);Uyo=r(BRt,"Wav2Vec2FeatureExtractor"),BRt.forEach(t),Hyo=r(cje," (Wav2Vec2-Conformer model)"),cje.forEach(t),Jyo=i(Q),Kp=n(Q,"LI",{});var fje=s(Kp);X_e=n(fje,"STRONG",{});var IRt=s(X_e);Yyo=r(IRt,"whisper"),IRt.forEach(t),Zyo=r(fje," \u2014 "),ZV=n(fje,"A",{href:!0});var NRt=s(ZV);Kyo=r(NRt,"WhisperFeatureExtractor"),NRt.forEach(t),e9o=r(fje," (Whisper model)"),fje.forEach(t),o9o=i(Q),e_=n(Q,"LI",{});var gje=s(e_);z_e=n(gje,"STRONG",{});var qRt=s(z_e);r9o=r(qRt,"xclip"),qRt.forEach(t),t9o=r(gje," \u2014 "),KV=n(gje,"A",{href:!0});var DRt=s(KV);a9o=r(DRt,"CLIPFeatureExtractor"),DRt.forEach(t),n9o=r(gje," (X-CLIP model)"),gje.forEach(t),s9o=i(Q),o_=n(Q,"LI",{});var hje=s(o_);Q_e=n(hje,"STRONG",{});var jRt=s(Q_e);l9o=r(jRt,"yolos"),jRt.forEach(t),i9o=r(hje," \u2014 "),eX=n(hje,"A",{href:!0});var GRt=s(eX);d9o=r(GRt,"YolosFeatureExtractor"),GRt.forEach(t),m9o=r(hje," (YOLOS model)"),hje.forEach(t),Q.forEach(t),c9o=i(wa),T(r_.$$.fragment,wa),f9o=i(wa),T(t_.$$.fragment,wa),wa.forEach(t),g9o=i(Bl),a_=n(Bl,"DIV",{class:!0});var Jno=s(a_);T(y$.$$.fragment,Jno),h9o=i(Jno),W_e=n(Jno,"P",{});var ORt=s(W_e);u9o=r(ORt,"Register a new feature extractor for this class."),ORt.forEach(t),Jno.forEach(t),Bl.forEach(t),Bto=i(c),xd=n(c,"H2",{class:!0});var Yno=s(xd);n_=n(Yno,"A",{id:!0,class:!0,href:!0});var VRt=s(n_);U_e=n(VRt,"SPAN",{});var XRt=s(U_e);T(x$.$$.fragment,XRt),XRt.forEach(t),VRt.forEach(t),p9o=i(Yno),H_e=n(Yno,"SPAN",{});var zRt=s(H_e);_9o=r(zRt,"AutoProcessor"),zRt.forEach(t),Yno.forEach(t),Ito=i(c),Bo=n(c,"DIV",{class:!0});var Il=s(Bo);T($$.$$.fragment,Il),b9o=i(Il),k$=n(Il,"P",{});var Zno=s(k$);v9o=r(Zno,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),oX=n(Zno,"A",{href:!0});var QRt=s(oX);F9o=r(QRt,"AutoProcessor.from_pretrained()"),QRt.forEach(t),T9o=r(Zno," class method."),Zno.forEach(t),M9o=i(Il),S$=n(Il,"P",{});var Kno=s(S$);E9o=r(Kno,"This class cannot be instantiated directly using "),J_e=n(Kno,"CODE",{});var WRt=s(J_e);C9o=r(WRt,"__init__()"),WRt.forEach(t),w9o=r(Kno," (throws an error)."),Kno.forEach(t),A9o=i(Il),Ze=n(Il,"DIV",{class:!0});var Aa=s(Ze);T(R$.$$.fragment,Aa),L9o=i(Aa),Y_e=n(Aa,"P",{});var URt=s(Y_e);y9o=r(URt,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),URt.forEach(t),x9o=i(Aa),$d=n(Aa,"P",{});var ome=s($d);$9o=r(ome,"The processor class to instantiate is selected based on the "),Z_e=n(ome,"CODE",{});var HRt=s(Z_e);k9o=r(HRt,"model_type"),HRt.forEach(t),S9o=r(ome,` property of the config object (either
passed as an argument or loaded from `),K_e=n(ome,"CODE",{});var JRt=s(K_e);R9o=r(JRt,"pretrained_model_name_or_path"),JRt.forEach(t),P9o=r(ome," if possible):"),ome.forEach(t),B9o=i(Aa),se=n(Aa,"UL",{});var de=s(se);s_=n(de,"LI",{});var uje=s(s_);e1e=n(uje,"STRONG",{});var YRt=s(e1e);I9o=r(YRt,"clip"),YRt.forEach(t),N9o=r(uje," \u2014 "),rX=n(uje,"A",{href:!0});var ZRt=s(rX);q9o=r(ZRt,"CLIPProcessor"),ZRt.forEach(t),D9o=r(uje," (CLIP model)"),uje.forEach(t),j9o=i(de),l_=n(de,"LI",{});var pje=s(l_);o1e=n(pje,"STRONG",{});var KRt=s(o1e);G9o=r(KRt,"donut"),KRt.forEach(t),O9o=r(pje," \u2014 "),tX=n(pje,"A",{href:!0});var ePt=s(tX);V9o=r(ePt,"DonutProcessor"),ePt.forEach(t),X9o=r(pje," (Donut model)"),pje.forEach(t),z9o=i(de),i_=n(de,"LI",{});var _je=s(i_);r1e=n(_je,"STRONG",{});var oPt=s(r1e);Q9o=r(oPt,"flava"),oPt.forEach(t),W9o=r(_je," \u2014 "),aX=n(_je,"A",{href:!0});var rPt=s(aX);U9o=r(rPt,"FlavaProcessor"),rPt.forEach(t),H9o=r(_je," (FLAVA model)"),_je.forEach(t),J9o=i(de),d_=n(de,"LI",{});var bje=s(d_);t1e=n(bje,"STRONG",{});var tPt=s(t1e);Y9o=r(tPt,"groupvit"),tPt.forEach(t),Z9o=r(bje," \u2014 "),nX=n(bje,"A",{href:!0});var aPt=s(nX);K9o=r(aPt,"CLIPProcessor"),aPt.forEach(t),exo=r(bje," (GroupViT model)"),bje.forEach(t),oxo=i(de),m_=n(de,"LI",{});var vje=s(m_);a1e=n(vje,"STRONG",{});var nPt=s(a1e);rxo=r(nPt,"layoutlmv2"),nPt.forEach(t),txo=r(vje," \u2014 "),sX=n(vje,"A",{href:!0});var sPt=s(sX);axo=r(sPt,"LayoutLMv2Processor"),sPt.forEach(t),nxo=r(vje," (LayoutLMv2 model)"),vje.forEach(t),sxo=i(de),c_=n(de,"LI",{});var Fje=s(c_);n1e=n(Fje,"STRONG",{});var lPt=s(n1e);lxo=r(lPt,"layoutlmv3"),lPt.forEach(t),ixo=r(Fje," \u2014 "),lX=n(Fje,"A",{href:!0});var iPt=s(lX);dxo=r(iPt,"LayoutLMv3Processor"),iPt.forEach(t),mxo=r(Fje," (LayoutLMv3 model)"),Fje.forEach(t),cxo=i(de),f_=n(de,"LI",{});var Tje=s(f_);s1e=n(Tje,"STRONG",{});var dPt=s(s1e);fxo=r(dPt,"layoutxlm"),dPt.forEach(t),gxo=r(Tje," \u2014 "),iX=n(Tje,"A",{href:!0});var mPt=s(iX);hxo=r(mPt,"LayoutXLMProcessor"),mPt.forEach(t),uxo=r(Tje," (LayoutXLM model)"),Tje.forEach(t),pxo=i(de),g_=n(de,"LI",{});var Mje=s(g_);l1e=n(Mje,"STRONG",{});var cPt=s(l1e);_xo=r(cPt,"markuplm"),cPt.forEach(t),bxo=r(Mje," \u2014 "),dX=n(Mje,"A",{href:!0});var fPt=s(dX);vxo=r(fPt,"MarkupLMProcessor"),fPt.forEach(t),Fxo=r(Mje," (MarkupLM model)"),Mje.forEach(t),Txo=i(de),h_=n(de,"LI",{});var Eje=s(h_);i1e=n(Eje,"STRONG",{});var gPt=s(i1e);Mxo=r(gPt,"owlvit"),gPt.forEach(t),Exo=r(Eje," \u2014 "),mX=n(Eje,"A",{href:!0});var hPt=s(mX);Cxo=r(hPt,"OwlViTProcessor"),hPt.forEach(t),wxo=r(Eje," (OWL-ViT model)"),Eje.forEach(t),Axo=i(de),u_=n(de,"LI",{});var Cje=s(u_);d1e=n(Cje,"STRONG",{});var uPt=s(d1e);Lxo=r(uPt,"sew"),uPt.forEach(t),yxo=r(Cje," \u2014 "),cX=n(Cje,"A",{href:!0});var pPt=s(cX);xxo=r(pPt,"Wav2Vec2Processor"),pPt.forEach(t),$xo=r(Cje," (SEW model)"),Cje.forEach(t),kxo=i(de),p_=n(de,"LI",{});var wje=s(p_);m1e=n(wje,"STRONG",{});var _Pt=s(m1e);Sxo=r(_Pt,"sew-d"),_Pt.forEach(t),Rxo=r(wje," \u2014 "),fX=n(wje,"A",{href:!0});var bPt=s(fX);Pxo=r(bPt,"Wav2Vec2Processor"),bPt.forEach(t),Bxo=r(wje," (SEW-D model)"),wje.forEach(t),Ixo=i(de),__=n(de,"LI",{});var Aje=s(__);c1e=n(Aje,"STRONG",{});var vPt=s(c1e);Nxo=r(vPt,"speech_to_text"),vPt.forEach(t),qxo=r(Aje," \u2014 "),gX=n(Aje,"A",{href:!0});var FPt=s(gX);Dxo=r(FPt,"Speech2TextProcessor"),FPt.forEach(t),jxo=r(Aje," (Speech2Text model)"),Aje.forEach(t),Gxo=i(de),b_=n(de,"LI",{});var Lje=s(b_);f1e=n(Lje,"STRONG",{});var TPt=s(f1e);Oxo=r(TPt,"speech_to_text_2"),TPt.forEach(t),Vxo=r(Lje," \u2014 "),hX=n(Lje,"A",{href:!0});var MPt=s(hX);Xxo=r(MPt,"Speech2Text2Processor"),MPt.forEach(t),zxo=r(Lje," (Speech2Text2 model)"),Lje.forEach(t),Qxo=i(de),v_=n(de,"LI",{});var yje=s(v_);g1e=n(yje,"STRONG",{});var EPt=s(g1e);Wxo=r(EPt,"trocr"),EPt.forEach(t),Uxo=r(yje," \u2014 "),uX=n(yje,"A",{href:!0});var CPt=s(uX);Hxo=r(CPt,"TrOCRProcessor"),CPt.forEach(t),Jxo=r(yje," (TrOCR model)"),yje.forEach(t),Yxo=i(de),F_=n(de,"LI",{});var xje=s(F_);h1e=n(xje,"STRONG",{});var wPt=s(h1e);Zxo=r(wPt,"unispeech"),wPt.forEach(t),Kxo=r(xje," \u2014 "),pX=n(xje,"A",{href:!0});var APt=s(pX);e$o=r(APt,"Wav2Vec2Processor"),APt.forEach(t),o$o=r(xje," (UniSpeech model)"),xje.forEach(t),r$o=i(de),T_=n(de,"LI",{});var $je=s(T_);u1e=n($je,"STRONG",{});var LPt=s(u1e);t$o=r(LPt,"unispeech-sat"),LPt.forEach(t),a$o=r($je," \u2014 "),_X=n($je,"A",{href:!0});var yPt=s(_X);n$o=r(yPt,"Wav2Vec2Processor"),yPt.forEach(t),s$o=r($je," (UniSpeechSat model)"),$je.forEach(t),l$o=i(de),M_=n(de,"LI",{});var kje=s(M_);p1e=n(kje,"STRONG",{});var xPt=s(p1e);i$o=r(xPt,"vilt"),xPt.forEach(t),d$o=r(kje," \u2014 "),bX=n(kje,"A",{href:!0});var $Pt=s(bX);m$o=r($Pt,"ViltProcessor"),$Pt.forEach(t),c$o=r(kje," (ViLT model)"),kje.forEach(t),f$o=i(de),E_=n(de,"LI",{});var Sje=s(E_);_1e=n(Sje,"STRONG",{});var kPt=s(_1e);g$o=r(kPt,"vision-text-dual-encoder"),kPt.forEach(t),h$o=r(Sje," \u2014 "),vX=n(Sje,"A",{href:!0});var SPt=s(vX);u$o=r(SPt,"VisionTextDualEncoderProcessor"),SPt.forEach(t),p$o=r(Sje," (VisionTextDualEncoder model)"),Sje.forEach(t),_$o=i(de),C_=n(de,"LI",{});var Rje=s(C_);b1e=n(Rje,"STRONG",{});var RPt=s(b1e);b$o=r(RPt,"wav2vec2"),RPt.forEach(t),v$o=r(Rje," \u2014 "),FX=n(Rje,"A",{href:!0});var PPt=s(FX);F$o=r(PPt,"Wav2Vec2Processor"),PPt.forEach(t),T$o=r(Rje," (Wav2Vec2 model)"),Rje.forEach(t),M$o=i(de),w_=n(de,"LI",{});var Pje=s(w_);v1e=n(Pje,"STRONG",{});var BPt=s(v1e);E$o=r(BPt,"wav2vec2-conformer"),BPt.forEach(t),C$o=r(Pje," \u2014 "),TX=n(Pje,"A",{href:!0});var IPt=s(TX);w$o=r(IPt,"Wav2Vec2Processor"),IPt.forEach(t),A$o=r(Pje," (Wav2Vec2-Conformer model)"),Pje.forEach(t),L$o=i(de),A_=n(de,"LI",{});var Bje=s(A_);F1e=n(Bje,"STRONG",{});var NPt=s(F1e);y$o=r(NPt,"wavlm"),NPt.forEach(t),x$o=r(Bje," \u2014 "),MX=n(Bje,"A",{href:!0});var qPt=s(MX);$$o=r(qPt,"Wav2Vec2Processor"),qPt.forEach(t),k$o=r(Bje," (WavLM model)"),Bje.forEach(t),S$o=i(de),L_=n(de,"LI",{});var Ije=s(L_);T1e=n(Ije,"STRONG",{});var DPt=s(T1e);R$o=r(DPt,"whisper"),DPt.forEach(t),P$o=r(Ije," \u2014 "),EX=n(Ije,"A",{href:!0});var jPt=s(EX);B$o=r(jPt,"WhisperProcessor"),jPt.forEach(t),I$o=r(Ije," (Whisper model)"),Ije.forEach(t),N$o=i(de),y_=n(de,"LI",{});var Nje=s(y_);M1e=n(Nje,"STRONG",{});var GPt=s(M1e);q$o=r(GPt,"xclip"),GPt.forEach(t),D$o=r(Nje," \u2014 "),CX=n(Nje,"A",{href:!0});var OPt=s(CX);j$o=r(OPt,"XCLIPProcessor"),OPt.forEach(t),G$o=r(Nje," (X-CLIP model)"),Nje.forEach(t),de.forEach(t),O$o=i(Aa),T(x_.$$.fragment,Aa),V$o=i(Aa),T($_.$$.fragment,Aa),Aa.forEach(t),X$o=i(Il),k_=n(Il,"DIV",{class:!0});var eso=s(k_);T(P$.$$.fragment,eso),z$o=i(eso),E1e=n(eso,"P",{});var VPt=s(E1e);Q$o=r(VPt,"Register a new processor for this class."),VPt.forEach(t),eso.forEach(t),Il.forEach(t),Nto=i(c),kd=n(c,"H2",{class:!0});var oso=s(kd);S_=n(oso,"A",{id:!0,class:!0,href:!0});var XPt=s(S_);C1e=n(XPt,"SPAN",{});var zPt=s(C1e);T(B$.$$.fragment,zPt),zPt.forEach(t),XPt.forEach(t),W$o=i(oso),w1e=n(oso,"SPAN",{});var QPt=s(w1e);U$o=r(QPt,"AutoModel"),QPt.forEach(t),oso.forEach(t),qto=i(c),Io=n(c,"DIV",{class:!0});var Nl=s(Io);T(I$.$$.fragment,Nl),H$o=i(Nl),Sd=n(Nl,"P",{});var rme=s(Sd);J$o=r(rme,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),wX=n(rme,"A",{href:!0});var WPt=s(wX);Y$o=r(WPt,"from_pretrained()"),WPt.forEach(t),Z$o=r(rme," class method or the "),AX=n(rme,"A",{href:!0});var UPt=s(AX);K$o=r(UPt,"from_config()"),UPt.forEach(t),eko=r(rme,` class
method.`),rme.forEach(t),oko=i(Nl),N$=n(Nl,"P",{});var rso=s(N$);rko=r(rso,"This class cannot be instantiated directly using "),A1e=n(rso,"CODE",{});var HPt=s(A1e);tko=r(HPt,"__init__()"),HPt.forEach(t),ako=r(rso," (throws an error)."),rso.forEach(t),nko=i(Nl),Mt=n(Nl,"DIV",{class:!0});var e9=s(Mt);T(q$.$$.fragment,e9),sko=i(e9),L1e=n(e9,"P",{});var JPt=s(L1e);lko=r(JPt,"Instantiates one of the base model classes of the library from a configuration."),JPt.forEach(t),iko=i(e9),Rd=n(e9,"P",{});var tme=s(Rd);dko=r(tme,`Note:
Loading a model from its configuration file does `),y1e=n(tme,"STRONG",{});var YPt=s(y1e);mko=r(YPt,"not"),YPt.forEach(t),cko=r(tme,` load the model weights. It only affects the
model\u2019s configuration. Use `),LX=n(tme,"A",{href:!0});var ZPt=s(LX);fko=r(ZPt,"from_pretrained()"),ZPt.forEach(t),gko=r(tme," to load the model weights."),tme.forEach(t),hko=i(e9),T(R_.$$.fragment,e9),e9.forEach(t),uko=i(Nl),Ke=n(Nl,"DIV",{class:!0});var La=s(Ke);T(D$.$$.fragment,La),pko=i(La),x1e=n(La,"P",{});var KPt=s(x1e);_ko=r(KPt,"Instantiate one of the base model classes of the library from a pretrained model."),KPt.forEach(t),bko=i(La),nn=n(La,"P",{});var o9=s(nn);vko=r(o9,"The model class to instantiate is selected based on the "),$1e=n(o9,"CODE",{});var eBt=s($1e);Fko=r(eBt,"model_type"),eBt.forEach(t),Tko=r(o9,` property of the config object (either
passed as an argument or loaded from `),k1e=n(o9,"CODE",{});var oBt=s(k1e);Mko=r(oBt,"pretrained_model_name_or_path"),oBt.forEach(t),Eko=r(o9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),S1e=n(o9,"CODE",{});var rBt=s(S1e);Cko=r(rBt,"pretrained_model_name_or_path"),rBt.forEach(t),wko=r(o9,":"),o9.forEach(t),Ako=i(La),y=n(La,"UL",{});var x=s(y);P_=n(x,"LI",{});var qje=s(P_);R1e=n(qje,"STRONG",{});var tBt=s(R1e);Lko=r(tBt,"albert"),tBt.forEach(t),yko=r(qje," \u2014 "),yX=n(qje,"A",{href:!0});var aBt=s(yX);xko=r(aBt,"AlbertModel"),aBt.forEach(t),$ko=r(qje," (ALBERT model)"),qje.forEach(t),kko=i(x),B_=n(x,"LI",{});var Dje=s(B_);P1e=n(Dje,"STRONG",{});var nBt=s(P1e);Sko=r(nBt,"bart"),nBt.forEach(t),Rko=r(Dje," \u2014 "),xX=n(Dje,"A",{href:!0});var sBt=s(xX);Pko=r(sBt,"BartModel"),sBt.forEach(t),Bko=r(Dje," (BART model)"),Dje.forEach(t),Iko=i(x),I_=n(x,"LI",{});var jje=s(I_);B1e=n(jje,"STRONG",{});var lBt=s(B1e);Nko=r(lBt,"beit"),lBt.forEach(t),qko=r(jje," \u2014 "),$X=n(jje,"A",{href:!0});var iBt=s($X);Dko=r(iBt,"BeitModel"),iBt.forEach(t),jko=r(jje," (BEiT model)"),jje.forEach(t),Gko=i(x),N_=n(x,"LI",{});var Gje=s(N_);I1e=n(Gje,"STRONG",{});var dBt=s(I1e);Oko=r(dBt,"bert"),dBt.forEach(t),Vko=r(Gje," \u2014 "),kX=n(Gje,"A",{href:!0});var mBt=s(kX);Xko=r(mBt,"BertModel"),mBt.forEach(t),zko=r(Gje," (BERT model)"),Gje.forEach(t),Qko=i(x),q_=n(x,"LI",{});var Oje=s(q_);N1e=n(Oje,"STRONG",{});var cBt=s(N1e);Wko=r(cBt,"bert-generation"),cBt.forEach(t),Uko=r(Oje," \u2014 "),SX=n(Oje,"A",{href:!0});var fBt=s(SX);Hko=r(fBt,"BertGenerationEncoder"),fBt.forEach(t),Jko=r(Oje," (Bert Generation model)"),Oje.forEach(t),Yko=i(x),D_=n(x,"LI",{});var Vje=s(D_);q1e=n(Vje,"STRONG",{});var gBt=s(q1e);Zko=r(gBt,"big_bird"),gBt.forEach(t),Kko=r(Vje," \u2014 "),RX=n(Vje,"A",{href:!0});var hBt=s(RX);eSo=r(hBt,"BigBirdModel"),hBt.forEach(t),oSo=r(Vje," (BigBird model)"),Vje.forEach(t),rSo=i(x),j_=n(x,"LI",{});var Xje=s(j_);D1e=n(Xje,"STRONG",{});var uBt=s(D1e);tSo=r(uBt,"bigbird_pegasus"),uBt.forEach(t),aSo=r(Xje," \u2014 "),PX=n(Xje,"A",{href:!0});var pBt=s(PX);nSo=r(pBt,"BigBirdPegasusModel"),pBt.forEach(t),sSo=r(Xje," (BigBird-Pegasus model)"),Xje.forEach(t),lSo=i(x),G_=n(x,"LI",{});var zje=s(G_);j1e=n(zje,"STRONG",{});var _Bt=s(j1e);iSo=r(_Bt,"blenderbot"),_Bt.forEach(t),dSo=r(zje," \u2014 "),BX=n(zje,"A",{href:!0});var bBt=s(BX);mSo=r(bBt,"BlenderbotModel"),bBt.forEach(t),cSo=r(zje," (Blenderbot model)"),zje.forEach(t),fSo=i(x),O_=n(x,"LI",{});var Qje=s(O_);G1e=n(Qje,"STRONG",{});var vBt=s(G1e);gSo=r(vBt,"blenderbot-small"),vBt.forEach(t),hSo=r(Qje," \u2014 "),IX=n(Qje,"A",{href:!0});var FBt=s(IX);uSo=r(FBt,"BlenderbotSmallModel"),FBt.forEach(t),pSo=r(Qje," (BlenderbotSmall model)"),Qje.forEach(t),_So=i(x),V_=n(x,"LI",{});var Wje=s(V_);O1e=n(Wje,"STRONG",{});var TBt=s(O1e);bSo=r(TBt,"bloom"),TBt.forEach(t),vSo=r(Wje," \u2014 "),NX=n(Wje,"A",{href:!0});var MBt=s(NX);FSo=r(MBt,"BloomModel"),MBt.forEach(t),TSo=r(Wje," (BLOOM model)"),Wje.forEach(t),MSo=i(x),X_=n(x,"LI",{});var Uje=s(X_);V1e=n(Uje,"STRONG",{});var EBt=s(V1e);ESo=r(EBt,"camembert"),EBt.forEach(t),CSo=r(Uje," \u2014 "),qX=n(Uje,"A",{href:!0});var CBt=s(qX);wSo=r(CBt,"CamembertModel"),CBt.forEach(t),ASo=r(Uje," (CamemBERT model)"),Uje.forEach(t),LSo=i(x),z_=n(x,"LI",{});var Hje=s(z_);X1e=n(Hje,"STRONG",{});var wBt=s(X1e);ySo=r(wBt,"canine"),wBt.forEach(t),xSo=r(Hje," \u2014 "),DX=n(Hje,"A",{href:!0});var ABt=s(DX);$So=r(ABt,"CanineModel"),ABt.forEach(t),kSo=r(Hje," (CANINE model)"),Hje.forEach(t),SSo=i(x),Q_=n(x,"LI",{});var Jje=s(Q_);z1e=n(Jje,"STRONG",{});var LBt=s(z1e);RSo=r(LBt,"clip"),LBt.forEach(t),PSo=r(Jje," \u2014 "),jX=n(Jje,"A",{href:!0});var yBt=s(jX);BSo=r(yBt,"CLIPModel"),yBt.forEach(t),ISo=r(Jje," (CLIP model)"),Jje.forEach(t),NSo=i(x),W_=n(x,"LI",{});var Yje=s(W_);Q1e=n(Yje,"STRONG",{});var xBt=s(Q1e);qSo=r(xBt,"codegen"),xBt.forEach(t),DSo=r(Yje," \u2014 "),GX=n(Yje,"A",{href:!0});var $Bt=s(GX);jSo=r($Bt,"CodeGenModel"),$Bt.forEach(t),GSo=r(Yje," (CodeGen model)"),Yje.forEach(t),OSo=i(x),U_=n(x,"LI",{});var Zje=s(U_);W1e=n(Zje,"STRONG",{});var kBt=s(W1e);VSo=r(kBt,"conditional_detr"),kBt.forEach(t),XSo=r(Zje," \u2014 "),OX=n(Zje,"A",{href:!0});var SBt=s(OX);zSo=r(SBt,"ConditionalDetrModel"),SBt.forEach(t),QSo=r(Zje," (Conditional DETR model)"),Zje.forEach(t),WSo=i(x),H_=n(x,"LI",{});var Kje=s(H_);U1e=n(Kje,"STRONG",{});var RBt=s(U1e);USo=r(RBt,"convbert"),RBt.forEach(t),HSo=r(Kje," \u2014 "),VX=n(Kje,"A",{href:!0});var PBt=s(VX);JSo=r(PBt,"ConvBertModel"),PBt.forEach(t),YSo=r(Kje," (ConvBERT model)"),Kje.forEach(t),ZSo=i(x),J_=n(x,"LI",{});var eGe=s(J_);H1e=n(eGe,"STRONG",{});var BBt=s(H1e);KSo=r(BBt,"convnext"),BBt.forEach(t),eRo=r(eGe," \u2014 "),XX=n(eGe,"A",{href:!0});var IBt=s(XX);oRo=r(IBt,"ConvNextModel"),IBt.forEach(t),rRo=r(eGe," (ConvNeXT model)"),eGe.forEach(t),tRo=i(x),Y_=n(x,"LI",{});var oGe=s(Y_);J1e=n(oGe,"STRONG",{});var NBt=s(J1e);aRo=r(NBt,"ctrl"),NBt.forEach(t),nRo=r(oGe," \u2014 "),zX=n(oGe,"A",{href:!0});var qBt=s(zX);sRo=r(qBt,"CTRLModel"),qBt.forEach(t),lRo=r(oGe," (CTRL model)"),oGe.forEach(t),iRo=i(x),Z_=n(x,"LI",{});var rGe=s(Z_);Y1e=n(rGe,"STRONG",{});var DBt=s(Y1e);dRo=r(DBt,"cvt"),DBt.forEach(t),mRo=r(rGe," \u2014 "),QX=n(rGe,"A",{href:!0});var jBt=s(QX);cRo=r(jBt,"CvtModel"),jBt.forEach(t),fRo=r(rGe," (CvT model)"),rGe.forEach(t),gRo=i(x),K_=n(x,"LI",{});var tGe=s(K_);Z1e=n(tGe,"STRONG",{});var GBt=s(Z1e);hRo=r(GBt,"data2vec-audio"),GBt.forEach(t),uRo=r(tGe," \u2014 "),WX=n(tGe,"A",{href:!0});var OBt=s(WX);pRo=r(OBt,"Data2VecAudioModel"),OBt.forEach(t),_Ro=r(tGe," (Data2VecAudio model)"),tGe.forEach(t),bRo=i(x),e1=n(x,"LI",{});var aGe=s(e1);K1e=n(aGe,"STRONG",{});var VBt=s(K1e);vRo=r(VBt,"data2vec-text"),VBt.forEach(t),FRo=r(aGe," \u2014 "),UX=n(aGe,"A",{href:!0});var XBt=s(UX);TRo=r(XBt,"Data2VecTextModel"),XBt.forEach(t),MRo=r(aGe," (Data2VecText model)"),aGe.forEach(t),ERo=i(x),o1=n(x,"LI",{});var nGe=s(o1);e2e=n(nGe,"STRONG",{});var zBt=s(e2e);CRo=r(zBt,"data2vec-vision"),zBt.forEach(t),wRo=r(nGe," \u2014 "),HX=n(nGe,"A",{href:!0});var QBt=s(HX);ARo=r(QBt,"Data2VecVisionModel"),QBt.forEach(t),LRo=r(nGe," (Data2VecVision model)"),nGe.forEach(t),yRo=i(x),r1=n(x,"LI",{});var sGe=s(r1);o2e=n(sGe,"STRONG",{});var WBt=s(o2e);xRo=r(WBt,"deberta"),WBt.forEach(t),$Ro=r(sGe," \u2014 "),JX=n(sGe,"A",{href:!0});var UBt=s(JX);kRo=r(UBt,"DebertaModel"),UBt.forEach(t),SRo=r(sGe," (DeBERTa model)"),sGe.forEach(t),RRo=i(x),t1=n(x,"LI",{});var lGe=s(t1);r2e=n(lGe,"STRONG",{});var HBt=s(r2e);PRo=r(HBt,"deberta-v2"),HBt.forEach(t),BRo=r(lGe," \u2014 "),YX=n(lGe,"A",{href:!0});var JBt=s(YX);IRo=r(JBt,"DebertaV2Model"),JBt.forEach(t),NRo=r(lGe," (DeBERTa-v2 model)"),lGe.forEach(t),qRo=i(x),a1=n(x,"LI",{});var iGe=s(a1);t2e=n(iGe,"STRONG",{});var YBt=s(t2e);DRo=r(YBt,"decision_transformer"),YBt.forEach(t),jRo=r(iGe," \u2014 "),ZX=n(iGe,"A",{href:!0});var ZBt=s(ZX);GRo=r(ZBt,"DecisionTransformerModel"),ZBt.forEach(t),ORo=r(iGe," (Decision Transformer model)"),iGe.forEach(t),VRo=i(x),n1=n(x,"LI",{});var dGe=s(n1);a2e=n(dGe,"STRONG",{});var KBt=s(a2e);XRo=r(KBt,"deformable_detr"),KBt.forEach(t),zRo=r(dGe," \u2014 "),KX=n(dGe,"A",{href:!0});var eIt=s(KX);QRo=r(eIt,"DeformableDetrModel"),eIt.forEach(t),WRo=r(dGe," (Deformable DETR model)"),dGe.forEach(t),URo=i(x),s1=n(x,"LI",{});var mGe=s(s1);n2e=n(mGe,"STRONG",{});var oIt=s(n2e);HRo=r(oIt,"deit"),oIt.forEach(t),JRo=r(mGe," \u2014 "),ez=n(mGe,"A",{href:!0});var rIt=s(ez);YRo=r(rIt,"DeiTModel"),rIt.forEach(t),ZRo=r(mGe," (DeiT model)"),mGe.forEach(t),KRo=i(x),l1=n(x,"LI",{});var cGe=s(l1);s2e=n(cGe,"STRONG",{});var tIt=s(s2e);ePo=r(tIt,"detr"),tIt.forEach(t),oPo=r(cGe," \u2014 "),oz=n(cGe,"A",{href:!0});var aIt=s(oz);rPo=r(aIt,"DetrModel"),aIt.forEach(t),tPo=r(cGe," (DETR model)"),cGe.forEach(t),aPo=i(x),i1=n(x,"LI",{});var fGe=s(i1);l2e=n(fGe,"STRONG",{});var nIt=s(l2e);nPo=r(nIt,"distilbert"),nIt.forEach(t),sPo=r(fGe," \u2014 "),rz=n(fGe,"A",{href:!0});var sIt=s(rz);lPo=r(sIt,"DistilBertModel"),sIt.forEach(t),iPo=r(fGe," (DistilBERT model)"),fGe.forEach(t),dPo=i(x),d1=n(x,"LI",{});var gGe=s(d1);i2e=n(gGe,"STRONG",{});var lIt=s(i2e);mPo=r(lIt,"donut-swin"),lIt.forEach(t),cPo=r(gGe," \u2014 "),tz=n(gGe,"A",{href:!0});var iIt=s(tz);fPo=r(iIt,"DonutSwinModel"),iIt.forEach(t),gPo=r(gGe," (DonutSwin model)"),gGe.forEach(t),hPo=i(x),m1=n(x,"LI",{});var hGe=s(m1);d2e=n(hGe,"STRONG",{});var dIt=s(d2e);uPo=r(dIt,"dpr"),dIt.forEach(t),pPo=r(hGe," \u2014 "),az=n(hGe,"A",{href:!0});var mIt=s(az);_Po=r(mIt,"DPRQuestionEncoder"),mIt.forEach(t),bPo=r(hGe," (DPR model)"),hGe.forEach(t),vPo=i(x),c1=n(x,"LI",{});var uGe=s(c1);m2e=n(uGe,"STRONG",{});var cIt=s(m2e);FPo=r(cIt,"dpt"),cIt.forEach(t),TPo=r(uGe," \u2014 "),nz=n(uGe,"A",{href:!0});var fIt=s(nz);MPo=r(fIt,"DPTModel"),fIt.forEach(t),EPo=r(uGe," (DPT model)"),uGe.forEach(t),CPo=i(x),f1=n(x,"LI",{});var pGe=s(f1);c2e=n(pGe,"STRONG",{});var gIt=s(c2e);wPo=r(gIt,"electra"),gIt.forEach(t),APo=r(pGe," \u2014 "),sz=n(pGe,"A",{href:!0});var hIt=s(sz);LPo=r(hIt,"ElectraModel"),hIt.forEach(t),yPo=r(pGe," (ELECTRA model)"),pGe.forEach(t),xPo=i(x),g1=n(x,"LI",{});var _Ge=s(g1);f2e=n(_Ge,"STRONG",{});var uIt=s(f2e);$Po=r(uIt,"ernie"),uIt.forEach(t),kPo=r(_Ge," \u2014 "),lz=n(_Ge,"A",{href:!0});var pIt=s(lz);SPo=r(pIt,"ErnieModel"),pIt.forEach(t),RPo=r(_Ge," (ERNIE model)"),_Ge.forEach(t),PPo=i(x),h1=n(x,"LI",{});var bGe=s(h1);g2e=n(bGe,"STRONG",{});var _It=s(g2e);BPo=r(_It,"esm"),_It.forEach(t),IPo=r(bGe," \u2014 "),iz=n(bGe,"A",{href:!0});var bIt=s(iz);NPo=r(bIt,"EsmModel"),bIt.forEach(t),qPo=r(bGe," (ESM model)"),bGe.forEach(t),DPo=i(x),u1=n(x,"LI",{});var vGe=s(u1);h2e=n(vGe,"STRONG",{});var vIt=s(h2e);jPo=r(vIt,"flaubert"),vIt.forEach(t),GPo=r(vGe," \u2014 "),dz=n(vGe,"A",{href:!0});var FIt=s(dz);OPo=r(FIt,"FlaubertModel"),FIt.forEach(t),VPo=r(vGe," (FlauBERT model)"),vGe.forEach(t),XPo=i(x),p1=n(x,"LI",{});var FGe=s(p1);u2e=n(FGe,"STRONG",{});var TIt=s(u2e);zPo=r(TIt,"flava"),TIt.forEach(t),QPo=r(FGe," \u2014 "),mz=n(FGe,"A",{href:!0});var MIt=s(mz);WPo=r(MIt,"FlavaModel"),MIt.forEach(t),UPo=r(FGe," (FLAVA model)"),FGe.forEach(t),HPo=i(x),_1=n(x,"LI",{});var TGe=s(_1);p2e=n(TGe,"STRONG",{});var EIt=s(p2e);JPo=r(EIt,"fnet"),EIt.forEach(t),YPo=r(TGe," \u2014 "),cz=n(TGe,"A",{href:!0});var CIt=s(cz);ZPo=r(CIt,"FNetModel"),CIt.forEach(t),KPo=r(TGe," (FNet model)"),TGe.forEach(t),eBo=i(x),b1=n(x,"LI",{});var MGe=s(b1);_2e=n(MGe,"STRONG",{});var wIt=s(_2e);oBo=r(wIt,"fsmt"),wIt.forEach(t),rBo=r(MGe," \u2014 "),fz=n(MGe,"A",{href:!0});var AIt=s(fz);tBo=r(AIt,"FSMTModel"),AIt.forEach(t),aBo=r(MGe," (FairSeq Machine-Translation model)"),MGe.forEach(t),nBo=i(x),yl=n(x,"LI",{});var pN=s(yl);b2e=n(pN,"STRONG",{});var LIt=s(b2e);sBo=r(LIt,"funnel"),LIt.forEach(t),lBo=r(pN," \u2014 "),gz=n(pN,"A",{href:!0});var yIt=s(gz);iBo=r(yIt,"FunnelModel"),yIt.forEach(t),dBo=r(pN," or "),hz=n(pN,"A",{href:!0});var xIt=s(hz);mBo=r(xIt,"FunnelBaseModel"),xIt.forEach(t),cBo=r(pN," (Funnel Transformer model)"),pN.forEach(t),fBo=i(x),v1=n(x,"LI",{});var EGe=s(v1);v2e=n(EGe,"STRONG",{});var $It=s(v2e);gBo=r($It,"glpn"),$It.forEach(t),hBo=r(EGe," \u2014 "),uz=n(EGe,"A",{href:!0});var kIt=s(uz);uBo=r(kIt,"GLPNModel"),kIt.forEach(t),pBo=r(EGe," (GLPN model)"),EGe.forEach(t),_Bo=i(x),F1=n(x,"LI",{});var CGe=s(F1);F2e=n(CGe,"STRONG",{});var SIt=s(F2e);bBo=r(SIt,"gpt2"),SIt.forEach(t),vBo=r(CGe," \u2014 "),pz=n(CGe,"A",{href:!0});var RIt=s(pz);FBo=r(RIt,"GPT2Model"),RIt.forEach(t),TBo=r(CGe," (OpenAI GPT-2 model)"),CGe.forEach(t),MBo=i(x),T1=n(x,"LI",{});var wGe=s(T1);T2e=n(wGe,"STRONG",{});var PIt=s(T2e);EBo=r(PIt,"gpt_neo"),PIt.forEach(t),CBo=r(wGe," \u2014 "),_z=n(wGe,"A",{href:!0});var BIt=s(_z);wBo=r(BIt,"GPTNeoModel"),BIt.forEach(t),ABo=r(wGe," (GPT Neo model)"),wGe.forEach(t),LBo=i(x),M1=n(x,"LI",{});var AGe=s(M1);M2e=n(AGe,"STRONG",{});var IIt=s(M2e);yBo=r(IIt,"gpt_neox"),IIt.forEach(t),xBo=r(AGe," \u2014 "),bz=n(AGe,"A",{href:!0});var NIt=s(bz);$Bo=r(NIt,"GPTNeoXModel"),NIt.forEach(t),kBo=r(AGe," (GPT NeoX model)"),AGe.forEach(t),SBo=i(x),E1=n(x,"LI",{});var LGe=s(E1);E2e=n(LGe,"STRONG",{});var qIt=s(E2e);RBo=r(qIt,"gpt_neox_japanese"),qIt.forEach(t),PBo=r(LGe," \u2014 "),vz=n(LGe,"A",{href:!0});var DIt=s(vz);BBo=r(DIt,"GPTNeoXJapaneseModel"),DIt.forEach(t),IBo=r(LGe," (GPT NeoX Japanese model)"),LGe.forEach(t),NBo=i(x),C1=n(x,"LI",{});var yGe=s(C1);C2e=n(yGe,"STRONG",{});var jIt=s(C2e);qBo=r(jIt,"gptj"),jIt.forEach(t),DBo=r(yGe," \u2014 "),Fz=n(yGe,"A",{href:!0});var GIt=s(Fz);jBo=r(GIt,"GPTJModel"),GIt.forEach(t),GBo=r(yGe," (GPT-J model)"),yGe.forEach(t),OBo=i(x),w1=n(x,"LI",{});var xGe=s(w1);w2e=n(xGe,"STRONG",{});var OIt=s(w2e);VBo=r(OIt,"groupvit"),OIt.forEach(t),XBo=r(xGe," \u2014 "),Tz=n(xGe,"A",{href:!0});var VIt=s(Tz);zBo=r(VIt,"GroupViTModel"),VIt.forEach(t),QBo=r(xGe," (GroupViT model)"),xGe.forEach(t),WBo=i(x),A1=n(x,"LI",{});var $Ge=s(A1);A2e=n($Ge,"STRONG",{});var XIt=s(A2e);UBo=r(XIt,"hubert"),XIt.forEach(t),HBo=r($Ge," \u2014 "),Mz=n($Ge,"A",{href:!0});var zIt=s(Mz);JBo=r(zIt,"HubertModel"),zIt.forEach(t),YBo=r($Ge," (Hubert model)"),$Ge.forEach(t),ZBo=i(x),L1=n(x,"LI",{});var kGe=s(L1);L2e=n(kGe,"STRONG",{});var QIt=s(L2e);KBo=r(QIt,"ibert"),QIt.forEach(t),eIo=r(kGe," \u2014 "),Ez=n(kGe,"A",{href:!0});var WIt=s(Ez);oIo=r(WIt,"IBertModel"),WIt.forEach(t),rIo=r(kGe," (I-BERT model)"),kGe.forEach(t),tIo=i(x),y1=n(x,"LI",{});var SGe=s(y1);y2e=n(SGe,"STRONG",{});var UIt=s(y2e);aIo=r(UIt,"imagegpt"),UIt.forEach(t),nIo=r(SGe," \u2014 "),Cz=n(SGe,"A",{href:!0});var HIt=s(Cz);sIo=r(HIt,"ImageGPTModel"),HIt.forEach(t),lIo=r(SGe," (ImageGPT model)"),SGe.forEach(t),iIo=i(x),x1=n(x,"LI",{});var RGe=s(x1);x2e=n(RGe,"STRONG",{});var JIt=s(x2e);dIo=r(JIt,"layoutlm"),JIt.forEach(t),mIo=r(RGe," \u2014 "),wz=n(RGe,"A",{href:!0});var YIt=s(wz);cIo=r(YIt,"LayoutLMModel"),YIt.forEach(t),fIo=r(RGe," (LayoutLM model)"),RGe.forEach(t),gIo=i(x),$1=n(x,"LI",{});var PGe=s($1);$2e=n(PGe,"STRONG",{});var ZIt=s($2e);hIo=r(ZIt,"layoutlmv2"),ZIt.forEach(t),uIo=r(PGe," \u2014 "),Az=n(PGe,"A",{href:!0});var KIt=s(Az);pIo=r(KIt,"LayoutLMv2Model"),KIt.forEach(t),_Io=r(PGe," (LayoutLMv2 model)"),PGe.forEach(t),bIo=i(x),k1=n(x,"LI",{});var BGe=s(k1);k2e=n(BGe,"STRONG",{});var eNt=s(k2e);vIo=r(eNt,"layoutlmv3"),eNt.forEach(t),FIo=r(BGe," \u2014 "),Lz=n(BGe,"A",{href:!0});var oNt=s(Lz);TIo=r(oNt,"LayoutLMv3Model"),oNt.forEach(t),MIo=r(BGe," (LayoutLMv3 model)"),BGe.forEach(t),EIo=i(x),S1=n(x,"LI",{});var IGe=s(S1);S2e=n(IGe,"STRONG",{});var rNt=s(S2e);CIo=r(rNt,"led"),rNt.forEach(t),wIo=r(IGe," \u2014 "),yz=n(IGe,"A",{href:!0});var tNt=s(yz);AIo=r(tNt,"LEDModel"),tNt.forEach(t),LIo=r(IGe," (LED model)"),IGe.forEach(t),yIo=i(x),R1=n(x,"LI",{});var NGe=s(R1);R2e=n(NGe,"STRONG",{});var aNt=s(R2e);xIo=r(aNt,"levit"),aNt.forEach(t),$Io=r(NGe," \u2014 "),xz=n(NGe,"A",{href:!0});var nNt=s(xz);kIo=r(nNt,"LevitModel"),nNt.forEach(t),SIo=r(NGe," (LeViT model)"),NGe.forEach(t),RIo=i(x),P1=n(x,"LI",{});var qGe=s(P1);P2e=n(qGe,"STRONG",{});var sNt=s(P2e);PIo=r(sNt,"lilt"),sNt.forEach(t),BIo=r(qGe," \u2014 "),$z=n(qGe,"A",{href:!0});var lNt=s($z);IIo=r(lNt,"LiltModel"),lNt.forEach(t),NIo=r(qGe," (LiLT model)"),qGe.forEach(t),qIo=i(x),B1=n(x,"LI",{});var DGe=s(B1);B2e=n(DGe,"STRONG",{});var iNt=s(B2e);DIo=r(iNt,"longformer"),iNt.forEach(t),jIo=r(DGe," \u2014 "),kz=n(DGe,"A",{href:!0});var dNt=s(kz);GIo=r(dNt,"LongformerModel"),dNt.forEach(t),OIo=r(DGe," (Longformer model)"),DGe.forEach(t),VIo=i(x),I1=n(x,"LI",{});var jGe=s(I1);I2e=n(jGe,"STRONG",{});var mNt=s(I2e);XIo=r(mNt,"longt5"),mNt.forEach(t),zIo=r(jGe," \u2014 "),Sz=n(jGe,"A",{href:!0});var cNt=s(Sz);QIo=r(cNt,"LongT5Model"),cNt.forEach(t),WIo=r(jGe," (LongT5 model)"),jGe.forEach(t),UIo=i(x),N1=n(x,"LI",{});var GGe=s(N1);N2e=n(GGe,"STRONG",{});var fNt=s(N2e);HIo=r(fNt,"luke"),fNt.forEach(t),JIo=r(GGe," \u2014 "),Rz=n(GGe,"A",{href:!0});var gNt=s(Rz);YIo=r(gNt,"LukeModel"),gNt.forEach(t),ZIo=r(GGe," (LUKE model)"),GGe.forEach(t),KIo=i(x),q1=n(x,"LI",{});var OGe=s(q1);q2e=n(OGe,"STRONG",{});var hNt=s(q2e);eNo=r(hNt,"lxmert"),hNt.forEach(t),oNo=r(OGe," \u2014 "),Pz=n(OGe,"A",{href:!0});var uNt=s(Pz);rNo=r(uNt,"LxmertModel"),uNt.forEach(t),tNo=r(OGe," (LXMERT model)"),OGe.forEach(t),aNo=i(x),D1=n(x,"LI",{});var VGe=s(D1);D2e=n(VGe,"STRONG",{});var pNt=s(D2e);nNo=r(pNt,"m2m_100"),pNt.forEach(t),sNo=r(VGe," \u2014 "),Bz=n(VGe,"A",{href:!0});var _Nt=s(Bz);lNo=r(_Nt,"M2M100Model"),_Nt.forEach(t),iNo=r(VGe," (M2M100 model)"),VGe.forEach(t),dNo=i(x),j1=n(x,"LI",{});var XGe=s(j1);j2e=n(XGe,"STRONG",{});var bNt=s(j2e);mNo=r(bNt,"marian"),bNt.forEach(t),cNo=r(XGe," \u2014 "),Iz=n(XGe,"A",{href:!0});var vNt=s(Iz);fNo=r(vNt,"MarianModel"),vNt.forEach(t),gNo=r(XGe," (Marian model)"),XGe.forEach(t),hNo=i(x),G1=n(x,"LI",{});var zGe=s(G1);G2e=n(zGe,"STRONG",{});var FNt=s(G2e);uNo=r(FNt,"markuplm"),FNt.forEach(t),pNo=r(zGe," \u2014 "),Nz=n(zGe,"A",{href:!0});var TNt=s(Nz);_No=r(TNt,"MarkupLMModel"),TNt.forEach(t),bNo=r(zGe," (MarkupLM model)"),zGe.forEach(t),vNo=i(x),O1=n(x,"LI",{});var QGe=s(O1);O2e=n(QGe,"STRONG",{});var MNt=s(O2e);FNo=r(MNt,"maskformer"),MNt.forEach(t),TNo=r(QGe," \u2014 "),qz=n(QGe,"A",{href:!0});var ENt=s(qz);MNo=r(ENt,"MaskFormerModel"),ENt.forEach(t),ENo=r(QGe," (MaskFormer model)"),QGe.forEach(t),CNo=i(x),V1=n(x,"LI",{});var WGe=s(V1);V2e=n(WGe,"STRONG",{});var CNt=s(V2e);wNo=r(CNt,"mbart"),CNt.forEach(t),ANo=r(WGe," \u2014 "),Dz=n(WGe,"A",{href:!0});var wNt=s(Dz);LNo=r(wNt,"MBartModel"),wNt.forEach(t),yNo=r(WGe," (mBART model)"),WGe.forEach(t),xNo=i(x),X1=n(x,"LI",{});var UGe=s(X1);X2e=n(UGe,"STRONG",{});var ANt=s(X2e);$No=r(ANt,"mctct"),ANt.forEach(t),kNo=r(UGe," \u2014 "),jz=n(UGe,"A",{href:!0});var LNt=s(jz);SNo=r(LNt,"MCTCTModel"),LNt.forEach(t),RNo=r(UGe," (M-CTC-T model)"),UGe.forEach(t),PNo=i(x),z1=n(x,"LI",{});var HGe=s(z1);z2e=n(HGe,"STRONG",{});var yNt=s(z2e);BNo=r(yNt,"megatron-bert"),yNt.forEach(t),INo=r(HGe," \u2014 "),Gz=n(HGe,"A",{href:!0});var xNt=s(Gz);NNo=r(xNt,"MegatronBertModel"),xNt.forEach(t),qNo=r(HGe," (Megatron-BERT model)"),HGe.forEach(t),DNo=i(x),Q1=n(x,"LI",{});var JGe=s(Q1);Q2e=n(JGe,"STRONG",{});var $Nt=s(Q2e);jNo=r($Nt,"mobilebert"),$Nt.forEach(t),GNo=r(JGe," \u2014 "),Oz=n(JGe,"A",{href:!0});var kNt=s(Oz);ONo=r(kNt,"MobileBertModel"),kNt.forEach(t),VNo=r(JGe," (MobileBERT model)"),JGe.forEach(t),XNo=i(x),W1=n(x,"LI",{});var YGe=s(W1);W2e=n(YGe,"STRONG",{});var SNt=s(W2e);zNo=r(SNt,"mobilevit"),SNt.forEach(t),QNo=r(YGe," \u2014 "),Vz=n(YGe,"A",{href:!0});var RNt=s(Vz);WNo=r(RNt,"MobileViTModel"),RNt.forEach(t),UNo=r(YGe," (MobileViT model)"),YGe.forEach(t),HNo=i(x),U1=n(x,"LI",{});var ZGe=s(U1);U2e=n(ZGe,"STRONG",{});var PNt=s(U2e);JNo=r(PNt,"mpnet"),PNt.forEach(t),YNo=r(ZGe," \u2014 "),Xz=n(ZGe,"A",{href:!0});var BNt=s(Xz);ZNo=r(BNt,"MPNetModel"),BNt.forEach(t),KNo=r(ZGe," (MPNet model)"),ZGe.forEach(t),eqo=i(x),H1=n(x,"LI",{});var KGe=s(H1);H2e=n(KGe,"STRONG",{});var INt=s(H2e);oqo=r(INt,"mt5"),INt.forEach(t),rqo=r(KGe," \u2014 "),zz=n(KGe,"A",{href:!0});var NNt=s(zz);tqo=r(NNt,"MT5Model"),NNt.forEach(t),aqo=r(KGe," (MT5 model)"),KGe.forEach(t),nqo=i(x),J1=n(x,"LI",{});var eOe=s(J1);J2e=n(eOe,"STRONG",{});var qNt=s(J2e);sqo=r(qNt,"mvp"),qNt.forEach(t),lqo=r(eOe," \u2014 "),Qz=n(eOe,"A",{href:!0});var DNt=s(Qz);iqo=r(DNt,"MvpModel"),DNt.forEach(t),dqo=r(eOe," (MVP model)"),eOe.forEach(t),mqo=i(x),Y1=n(x,"LI",{});var oOe=s(Y1);Y2e=n(oOe,"STRONG",{});var jNt=s(Y2e);cqo=r(jNt,"nezha"),jNt.forEach(t),fqo=r(oOe," \u2014 "),Wz=n(oOe,"A",{href:!0});var GNt=s(Wz);gqo=r(GNt,"NezhaModel"),GNt.forEach(t),hqo=r(oOe," (Nezha model)"),oOe.forEach(t),uqo=i(x),Z1=n(x,"LI",{});var rOe=s(Z1);Z2e=n(rOe,"STRONG",{});var ONt=s(Z2e);pqo=r(ONt,"nllb"),ONt.forEach(t),_qo=r(rOe," \u2014 "),Uz=n(rOe,"A",{href:!0});var VNt=s(Uz);bqo=r(VNt,"M2M100Model"),VNt.forEach(t),vqo=r(rOe," (NLLB model)"),rOe.forEach(t),Fqo=i(x),K1=n(x,"LI",{});var tOe=s(K1);K2e=n(tOe,"STRONG",{});var XNt=s(K2e);Tqo=r(XNt,"nystromformer"),XNt.forEach(t),Mqo=r(tOe," \u2014 "),Hz=n(tOe,"A",{href:!0});var zNt=s(Hz);Eqo=r(zNt,"NystromformerModel"),zNt.forEach(t),Cqo=r(tOe," (Nystr\xF6mformer model)"),tOe.forEach(t),wqo=i(x),e2=n(x,"LI",{});var aOe=s(e2);ebe=n(aOe,"STRONG",{});var QNt=s(ebe);Aqo=r(QNt,"openai-gpt"),QNt.forEach(t),Lqo=r(aOe," \u2014 "),Jz=n(aOe,"A",{href:!0});var WNt=s(Jz);yqo=r(WNt,"OpenAIGPTModel"),WNt.forEach(t),xqo=r(aOe," (OpenAI GPT model)"),aOe.forEach(t),$qo=i(x),o2=n(x,"LI",{});var nOe=s(o2);obe=n(nOe,"STRONG",{});var UNt=s(obe);kqo=r(UNt,"opt"),UNt.forEach(t),Sqo=r(nOe," \u2014 "),Yz=n(nOe,"A",{href:!0});var HNt=s(Yz);Rqo=r(HNt,"OPTModel"),HNt.forEach(t),Pqo=r(nOe," (OPT model)"),nOe.forEach(t),Bqo=i(x),r2=n(x,"LI",{});var sOe=s(r2);rbe=n(sOe,"STRONG",{});var JNt=s(rbe);Iqo=r(JNt,"owlvit"),JNt.forEach(t),Nqo=r(sOe," \u2014 "),Zz=n(sOe,"A",{href:!0});var YNt=s(Zz);qqo=r(YNt,"OwlViTModel"),YNt.forEach(t),Dqo=r(sOe," (OWL-ViT model)"),sOe.forEach(t),jqo=i(x),t2=n(x,"LI",{});var lOe=s(t2);tbe=n(lOe,"STRONG",{});var ZNt=s(tbe);Gqo=r(ZNt,"pegasus"),ZNt.forEach(t),Oqo=r(lOe," \u2014 "),Kz=n(lOe,"A",{href:!0});var KNt=s(Kz);Vqo=r(KNt,"PegasusModel"),KNt.forEach(t),Xqo=r(lOe," (Pegasus model)"),lOe.forEach(t),zqo=i(x),a2=n(x,"LI",{});var iOe=s(a2);abe=n(iOe,"STRONG",{});var eqt=s(abe);Qqo=r(eqt,"pegasus_x"),eqt.forEach(t),Wqo=r(iOe," \u2014 "),eQ=n(iOe,"A",{href:!0});var oqt=s(eQ);Uqo=r(oqt,"PegasusXModel"),oqt.forEach(t),Hqo=r(iOe," (PEGASUS-X model)"),iOe.forEach(t),Jqo=i(x),n2=n(x,"LI",{});var dOe=s(n2);nbe=n(dOe,"STRONG",{});var rqt=s(nbe);Yqo=r(rqt,"perceiver"),rqt.forEach(t),Zqo=r(dOe," \u2014 "),oQ=n(dOe,"A",{href:!0});var tqt=s(oQ);Kqo=r(tqt,"PerceiverModel"),tqt.forEach(t),eDo=r(dOe," (Perceiver model)"),dOe.forEach(t),oDo=i(x),s2=n(x,"LI",{});var mOe=s(s2);sbe=n(mOe,"STRONG",{});var aqt=s(sbe);rDo=r(aqt,"plbart"),aqt.forEach(t),tDo=r(mOe," \u2014 "),rQ=n(mOe,"A",{href:!0});var nqt=s(rQ);aDo=r(nqt,"PLBartModel"),nqt.forEach(t),nDo=r(mOe," (PLBart model)"),mOe.forEach(t),sDo=i(x),l2=n(x,"LI",{});var cOe=s(l2);lbe=n(cOe,"STRONG",{});var sqt=s(lbe);lDo=r(sqt,"poolformer"),sqt.forEach(t),iDo=r(cOe," \u2014 "),tQ=n(cOe,"A",{href:!0});var lqt=s(tQ);dDo=r(lqt,"PoolFormerModel"),lqt.forEach(t),mDo=r(cOe," (PoolFormer model)"),cOe.forEach(t),cDo=i(x),i2=n(x,"LI",{});var fOe=s(i2);ibe=n(fOe,"STRONG",{});var iqt=s(ibe);fDo=r(iqt,"prophetnet"),iqt.forEach(t),gDo=r(fOe," \u2014 "),aQ=n(fOe,"A",{href:!0});var dqt=s(aQ);hDo=r(dqt,"ProphetNetModel"),dqt.forEach(t),uDo=r(fOe," (ProphetNet model)"),fOe.forEach(t),pDo=i(x),d2=n(x,"LI",{});var gOe=s(d2);dbe=n(gOe,"STRONG",{});var mqt=s(dbe);_Do=r(mqt,"qdqbert"),mqt.forEach(t),bDo=r(gOe," \u2014 "),nQ=n(gOe,"A",{href:!0});var cqt=s(nQ);vDo=r(cqt,"QDQBertModel"),cqt.forEach(t),FDo=r(gOe," (QDQBert model)"),gOe.forEach(t),TDo=i(x),m2=n(x,"LI",{});var hOe=s(m2);mbe=n(hOe,"STRONG",{});var fqt=s(mbe);MDo=r(fqt,"reformer"),fqt.forEach(t),EDo=r(hOe," \u2014 "),sQ=n(hOe,"A",{href:!0});var gqt=s(sQ);CDo=r(gqt,"ReformerModel"),gqt.forEach(t),wDo=r(hOe," (Reformer model)"),hOe.forEach(t),ADo=i(x),c2=n(x,"LI",{});var uOe=s(c2);cbe=n(uOe,"STRONG",{});var hqt=s(cbe);LDo=r(hqt,"regnet"),hqt.forEach(t),yDo=r(uOe," \u2014 "),lQ=n(uOe,"A",{href:!0});var uqt=s(lQ);xDo=r(uqt,"RegNetModel"),uqt.forEach(t),$Do=r(uOe," (RegNet model)"),uOe.forEach(t),kDo=i(x),f2=n(x,"LI",{});var pOe=s(f2);fbe=n(pOe,"STRONG",{});var pqt=s(fbe);SDo=r(pqt,"rembert"),pqt.forEach(t),RDo=r(pOe," \u2014 "),iQ=n(pOe,"A",{href:!0});var _qt=s(iQ);PDo=r(_qt,"RemBertModel"),_qt.forEach(t),BDo=r(pOe," (RemBERT model)"),pOe.forEach(t),IDo=i(x),g2=n(x,"LI",{});var _Oe=s(g2);gbe=n(_Oe,"STRONG",{});var bqt=s(gbe);NDo=r(bqt,"resnet"),bqt.forEach(t),qDo=r(_Oe," \u2014 "),dQ=n(_Oe,"A",{href:!0});var vqt=s(dQ);DDo=r(vqt,"ResNetModel"),vqt.forEach(t),jDo=r(_Oe," (ResNet model)"),_Oe.forEach(t),GDo=i(x),h2=n(x,"LI",{});var bOe=s(h2);hbe=n(bOe,"STRONG",{});var Fqt=s(hbe);ODo=r(Fqt,"retribert"),Fqt.forEach(t),VDo=r(bOe," \u2014 "),mQ=n(bOe,"A",{href:!0});var Tqt=s(mQ);XDo=r(Tqt,"RetriBertModel"),Tqt.forEach(t),zDo=r(bOe," (RetriBERT model)"),bOe.forEach(t),QDo=i(x),u2=n(x,"LI",{});var vOe=s(u2);ube=n(vOe,"STRONG",{});var Mqt=s(ube);WDo=r(Mqt,"roberta"),Mqt.forEach(t),UDo=r(vOe," \u2014 "),cQ=n(vOe,"A",{href:!0});var Eqt=s(cQ);HDo=r(Eqt,"RobertaModel"),Eqt.forEach(t),JDo=r(vOe," (RoBERTa model)"),vOe.forEach(t),YDo=i(x),p2=n(x,"LI",{});var FOe=s(p2);pbe=n(FOe,"STRONG",{});var Cqt=s(pbe);ZDo=r(Cqt,"roformer"),Cqt.forEach(t),KDo=r(FOe," \u2014 "),fQ=n(FOe,"A",{href:!0});var wqt=s(fQ);ejo=r(wqt,"RoFormerModel"),wqt.forEach(t),ojo=r(FOe," (RoFormer model)"),FOe.forEach(t),rjo=i(x),_2=n(x,"LI",{});var TOe=s(_2);_be=n(TOe,"STRONG",{});var Aqt=s(_be);tjo=r(Aqt,"segformer"),Aqt.forEach(t),ajo=r(TOe," \u2014 "),gQ=n(TOe,"A",{href:!0});var Lqt=s(gQ);njo=r(Lqt,"SegformerModel"),Lqt.forEach(t),sjo=r(TOe," (SegFormer model)"),TOe.forEach(t),ljo=i(x),b2=n(x,"LI",{});var MOe=s(b2);bbe=n(MOe,"STRONG",{});var yqt=s(bbe);ijo=r(yqt,"sew"),yqt.forEach(t),djo=r(MOe," \u2014 "),hQ=n(MOe,"A",{href:!0});var xqt=s(hQ);mjo=r(xqt,"SEWModel"),xqt.forEach(t),cjo=r(MOe," (SEW model)"),MOe.forEach(t),fjo=i(x),v2=n(x,"LI",{});var EOe=s(v2);vbe=n(EOe,"STRONG",{});var $qt=s(vbe);gjo=r($qt,"sew-d"),$qt.forEach(t),hjo=r(EOe," \u2014 "),uQ=n(EOe,"A",{href:!0});var kqt=s(uQ);ujo=r(kqt,"SEWDModel"),kqt.forEach(t),pjo=r(EOe," (SEW-D model)"),EOe.forEach(t),_jo=i(x),F2=n(x,"LI",{});var COe=s(F2);Fbe=n(COe,"STRONG",{});var Sqt=s(Fbe);bjo=r(Sqt,"speech_to_text"),Sqt.forEach(t),vjo=r(COe," \u2014 "),pQ=n(COe,"A",{href:!0});var Rqt=s(pQ);Fjo=r(Rqt,"Speech2TextModel"),Rqt.forEach(t),Tjo=r(COe," (Speech2Text model)"),COe.forEach(t),Mjo=i(x),T2=n(x,"LI",{});var wOe=s(T2);Tbe=n(wOe,"STRONG",{});var Pqt=s(Tbe);Ejo=r(Pqt,"splinter"),Pqt.forEach(t),Cjo=r(wOe," \u2014 "),_Q=n(wOe,"A",{href:!0});var Bqt=s(_Q);wjo=r(Bqt,"SplinterModel"),Bqt.forEach(t),Ajo=r(wOe," (Splinter model)"),wOe.forEach(t),Ljo=i(x),M2=n(x,"LI",{});var AOe=s(M2);Mbe=n(AOe,"STRONG",{});var Iqt=s(Mbe);yjo=r(Iqt,"squeezebert"),Iqt.forEach(t),xjo=r(AOe," \u2014 "),bQ=n(AOe,"A",{href:!0});var Nqt=s(bQ);$jo=r(Nqt,"SqueezeBertModel"),Nqt.forEach(t),kjo=r(AOe," (SqueezeBERT model)"),AOe.forEach(t),Sjo=i(x),E2=n(x,"LI",{});var LOe=s(E2);Ebe=n(LOe,"STRONG",{});var qqt=s(Ebe);Rjo=r(qqt,"swin"),qqt.forEach(t),Pjo=r(LOe," \u2014 "),vQ=n(LOe,"A",{href:!0});var Dqt=s(vQ);Bjo=r(Dqt,"SwinModel"),Dqt.forEach(t),Ijo=r(LOe," (Swin Transformer model)"),LOe.forEach(t),Njo=i(x),C2=n(x,"LI",{});var yOe=s(C2);Cbe=n(yOe,"STRONG",{});var jqt=s(Cbe);qjo=r(jqt,"swinv2"),jqt.forEach(t),Djo=r(yOe," \u2014 "),FQ=n(yOe,"A",{href:!0});var Gqt=s(FQ);jjo=r(Gqt,"Swinv2Model"),Gqt.forEach(t),Gjo=r(yOe," (Swin Transformer V2 model)"),yOe.forEach(t),Ojo=i(x),w2=n(x,"LI",{});var xOe=s(w2);wbe=n(xOe,"STRONG",{});var Oqt=s(wbe);Vjo=r(Oqt,"t5"),Oqt.forEach(t),Xjo=r(xOe," \u2014 "),TQ=n(xOe,"A",{href:!0});var Vqt=s(TQ);zjo=r(Vqt,"T5Model"),Vqt.forEach(t),Qjo=r(xOe," (T5 model)"),xOe.forEach(t),Wjo=i(x),A2=n(x,"LI",{});var $Oe=s(A2);Abe=n($Oe,"STRONG",{});var Xqt=s(Abe);Ujo=r(Xqt,"table-transformer"),Xqt.forEach(t),Hjo=r($Oe," \u2014 "),MQ=n($Oe,"A",{href:!0});var zqt=s(MQ);Jjo=r(zqt,"TableTransformerModel"),zqt.forEach(t),Yjo=r($Oe," (Table Transformer model)"),$Oe.forEach(t),Zjo=i(x),L2=n(x,"LI",{});var kOe=s(L2);Lbe=n(kOe,"STRONG",{});var Qqt=s(Lbe);Kjo=r(Qqt,"tapas"),Qqt.forEach(t),eGo=r(kOe," \u2014 "),EQ=n(kOe,"A",{href:!0});var Wqt=s(EQ);oGo=r(Wqt,"TapasModel"),Wqt.forEach(t),rGo=r(kOe," (TAPAS model)"),kOe.forEach(t),tGo=i(x),y2=n(x,"LI",{});var SOe=s(y2);ybe=n(SOe,"STRONG",{});var Uqt=s(ybe);aGo=r(Uqt,"time_series_transformer"),Uqt.forEach(t),nGo=r(SOe," \u2014 "),CQ=n(SOe,"A",{href:!0});var Hqt=s(CQ);sGo=r(Hqt,"TimeSeriesTransformerModel"),Hqt.forEach(t),lGo=r(SOe," (Time Series Transformer model)"),SOe.forEach(t),iGo=i(x),x2=n(x,"LI",{});var ROe=s(x2);xbe=n(ROe,"STRONG",{});var Jqt=s(xbe);dGo=r(Jqt,"trajectory_transformer"),Jqt.forEach(t),mGo=r(ROe," \u2014 "),wQ=n(ROe,"A",{href:!0});var Yqt=s(wQ);cGo=r(Yqt,"TrajectoryTransformerModel"),Yqt.forEach(t),fGo=r(ROe," (Trajectory Transformer model)"),ROe.forEach(t),gGo=i(x),$2=n(x,"LI",{});var POe=s($2);$be=n(POe,"STRONG",{});var Zqt=s($be);hGo=r(Zqt,"transfo-xl"),Zqt.forEach(t),uGo=r(POe," \u2014 "),AQ=n(POe,"A",{href:!0});var Kqt=s(AQ);pGo=r(Kqt,"TransfoXLModel"),Kqt.forEach(t),_Go=r(POe," (Transformer-XL model)"),POe.forEach(t),bGo=i(x),k2=n(x,"LI",{});var BOe=s(k2);kbe=n(BOe,"STRONG",{});var eDt=s(kbe);vGo=r(eDt,"unispeech"),eDt.forEach(t),FGo=r(BOe," \u2014 "),LQ=n(BOe,"A",{href:!0});var oDt=s(LQ);TGo=r(oDt,"UniSpeechModel"),oDt.forEach(t),MGo=r(BOe," (UniSpeech model)"),BOe.forEach(t),EGo=i(x),S2=n(x,"LI",{});var IOe=s(S2);Sbe=n(IOe,"STRONG",{});var rDt=s(Sbe);CGo=r(rDt,"unispeech-sat"),rDt.forEach(t),wGo=r(IOe," \u2014 "),yQ=n(IOe,"A",{href:!0});var tDt=s(yQ);AGo=r(tDt,"UniSpeechSatModel"),tDt.forEach(t),LGo=r(IOe," (UniSpeechSat model)"),IOe.forEach(t),yGo=i(x),R2=n(x,"LI",{});var NOe=s(R2);Rbe=n(NOe,"STRONG",{});var aDt=s(Rbe);xGo=r(aDt,"van"),aDt.forEach(t),$Go=r(NOe," \u2014 "),xQ=n(NOe,"A",{href:!0});var nDt=s(xQ);kGo=r(nDt,"VanModel"),nDt.forEach(t),SGo=r(NOe," (VAN model)"),NOe.forEach(t),RGo=i(x),P2=n(x,"LI",{});var qOe=s(P2);Pbe=n(qOe,"STRONG",{});var sDt=s(Pbe);PGo=r(sDt,"videomae"),sDt.forEach(t),BGo=r(qOe," \u2014 "),$Q=n(qOe,"A",{href:!0});var lDt=s($Q);IGo=r(lDt,"VideoMAEModel"),lDt.forEach(t),NGo=r(qOe," (VideoMAE model)"),qOe.forEach(t),qGo=i(x),B2=n(x,"LI",{});var DOe=s(B2);Bbe=n(DOe,"STRONG",{});var iDt=s(Bbe);DGo=r(iDt,"vilt"),iDt.forEach(t),jGo=r(DOe," \u2014 "),kQ=n(DOe,"A",{href:!0});var dDt=s(kQ);GGo=r(dDt,"ViltModel"),dDt.forEach(t),OGo=r(DOe," (ViLT model)"),DOe.forEach(t),VGo=i(x),I2=n(x,"LI",{});var jOe=s(I2);Ibe=n(jOe,"STRONG",{});var mDt=s(Ibe);XGo=r(mDt,"vision-text-dual-encoder"),mDt.forEach(t),zGo=r(jOe," \u2014 "),SQ=n(jOe,"A",{href:!0});var cDt=s(SQ);QGo=r(cDt,"VisionTextDualEncoderModel"),cDt.forEach(t),WGo=r(jOe," (VisionTextDualEncoder model)"),jOe.forEach(t),UGo=i(x),N2=n(x,"LI",{});var GOe=s(N2);Nbe=n(GOe,"STRONG",{});var fDt=s(Nbe);HGo=r(fDt,"visual_bert"),fDt.forEach(t),JGo=r(GOe," \u2014 "),RQ=n(GOe,"A",{href:!0});var gDt=s(RQ);YGo=r(gDt,"VisualBertModel"),gDt.forEach(t),ZGo=r(GOe," (VisualBERT model)"),GOe.forEach(t),KGo=i(x),q2=n(x,"LI",{});var OOe=s(q2);qbe=n(OOe,"STRONG",{});var hDt=s(qbe);eOo=r(hDt,"vit"),hDt.forEach(t),oOo=r(OOe," \u2014 "),PQ=n(OOe,"A",{href:!0});var uDt=s(PQ);rOo=r(uDt,"ViTModel"),uDt.forEach(t),tOo=r(OOe," (ViT model)"),OOe.forEach(t),aOo=i(x),D2=n(x,"LI",{});var VOe=s(D2);Dbe=n(VOe,"STRONG",{});var pDt=s(Dbe);nOo=r(pDt,"vit_mae"),pDt.forEach(t),sOo=r(VOe," \u2014 "),BQ=n(VOe,"A",{href:!0});var _Dt=s(BQ);lOo=r(_Dt,"ViTMAEModel"),_Dt.forEach(t),iOo=r(VOe," (ViTMAE model)"),VOe.forEach(t),dOo=i(x),j2=n(x,"LI",{});var XOe=s(j2);jbe=n(XOe,"STRONG",{});var bDt=s(jbe);mOo=r(bDt,"vit_msn"),bDt.forEach(t),cOo=r(XOe," \u2014 "),IQ=n(XOe,"A",{href:!0});var vDt=s(IQ);fOo=r(vDt,"ViTMSNModel"),vDt.forEach(t),gOo=r(XOe," (ViTMSN model)"),XOe.forEach(t),hOo=i(x),G2=n(x,"LI",{});var zOe=s(G2);Gbe=n(zOe,"STRONG",{});var FDt=s(Gbe);uOo=r(FDt,"wav2vec2"),FDt.forEach(t),pOo=r(zOe," \u2014 "),NQ=n(zOe,"A",{href:!0});var TDt=s(NQ);_Oo=r(TDt,"Wav2Vec2Model"),TDt.forEach(t),bOo=r(zOe," (Wav2Vec2 model)"),zOe.forEach(t),vOo=i(x),O2=n(x,"LI",{});var QOe=s(O2);Obe=n(QOe,"STRONG",{});var MDt=s(Obe);FOo=r(MDt,"wav2vec2-conformer"),MDt.forEach(t),TOo=r(QOe," \u2014 "),qQ=n(QOe,"A",{href:!0});var EDt=s(qQ);MOo=r(EDt,"Wav2Vec2ConformerModel"),EDt.forEach(t),EOo=r(QOe," (Wav2Vec2-Conformer model)"),QOe.forEach(t),COo=i(x),V2=n(x,"LI",{});var WOe=s(V2);Vbe=n(WOe,"STRONG",{});var CDt=s(Vbe);wOo=r(CDt,"wavlm"),CDt.forEach(t),AOo=r(WOe," \u2014 "),DQ=n(WOe,"A",{href:!0});var wDt=s(DQ);LOo=r(wDt,"WavLMModel"),wDt.forEach(t),yOo=r(WOe," (WavLM model)"),WOe.forEach(t),xOo=i(x),X2=n(x,"LI",{});var UOe=s(X2);Xbe=n(UOe,"STRONG",{});var ADt=s(Xbe);$Oo=r(ADt,"whisper"),ADt.forEach(t),kOo=r(UOe," \u2014 "),jQ=n(UOe,"A",{href:!0});var LDt=s(jQ);SOo=r(LDt,"WhisperModel"),LDt.forEach(t),ROo=r(UOe," (Whisper model)"),UOe.forEach(t),POo=i(x),z2=n(x,"LI",{});var HOe=s(z2);zbe=n(HOe,"STRONG",{});var yDt=s(zbe);BOo=r(yDt,"xclip"),yDt.forEach(t),IOo=r(HOe," \u2014 "),GQ=n(HOe,"A",{href:!0});var xDt=s(GQ);NOo=r(xDt,"XCLIPModel"),xDt.forEach(t),qOo=r(HOe," (X-CLIP model)"),HOe.forEach(t),DOo=i(x),Q2=n(x,"LI",{});var JOe=s(Q2);Qbe=n(JOe,"STRONG",{});var $Dt=s(Qbe);jOo=r($Dt,"xglm"),$Dt.forEach(t),GOo=r(JOe," \u2014 "),OQ=n(JOe,"A",{href:!0});var kDt=s(OQ);OOo=r(kDt,"XGLMModel"),kDt.forEach(t),VOo=r(JOe," (XGLM model)"),JOe.forEach(t),XOo=i(x),W2=n(x,"LI",{});var YOe=s(W2);Wbe=n(YOe,"STRONG",{});var SDt=s(Wbe);zOo=r(SDt,"xlm"),SDt.forEach(t),QOo=r(YOe," \u2014 "),VQ=n(YOe,"A",{href:!0});var RDt=s(VQ);WOo=r(RDt,"XLMModel"),RDt.forEach(t),UOo=r(YOe," (XLM model)"),YOe.forEach(t),HOo=i(x),U2=n(x,"LI",{});var ZOe=s(U2);Ube=n(ZOe,"STRONG",{});var PDt=s(Ube);JOo=r(PDt,"xlm-prophetnet"),PDt.forEach(t),YOo=r(ZOe," \u2014 "),XQ=n(ZOe,"A",{href:!0});var BDt=s(XQ);ZOo=r(BDt,"XLMProphetNetModel"),BDt.forEach(t),KOo=r(ZOe," (XLM-ProphetNet model)"),ZOe.forEach(t),eVo=i(x),H2=n(x,"LI",{});var KOe=s(H2);Hbe=n(KOe,"STRONG",{});var IDt=s(Hbe);oVo=r(IDt,"xlm-roberta"),IDt.forEach(t),rVo=r(KOe," \u2014 "),zQ=n(KOe,"A",{href:!0});var NDt=s(zQ);tVo=r(NDt,"XLMRobertaModel"),NDt.forEach(t),aVo=r(KOe," (XLM-RoBERTa model)"),KOe.forEach(t),nVo=i(x),J2=n(x,"LI",{});var eVe=s(J2);Jbe=n(eVe,"STRONG",{});var qDt=s(Jbe);sVo=r(qDt,"xlm-roberta-xl"),qDt.forEach(t),lVo=r(eVe," \u2014 "),QQ=n(eVe,"A",{href:!0});var DDt=s(QQ);iVo=r(DDt,"XLMRobertaXLModel"),DDt.forEach(t),dVo=r(eVe," (XLM-RoBERTa-XL model)"),eVe.forEach(t),mVo=i(x),Y2=n(x,"LI",{});var oVe=s(Y2);Ybe=n(oVe,"STRONG",{});var jDt=s(Ybe);cVo=r(jDt,"xlnet"),jDt.forEach(t),fVo=r(oVe," \u2014 "),WQ=n(oVe,"A",{href:!0});var GDt=s(WQ);gVo=r(GDt,"XLNetModel"),GDt.forEach(t),hVo=r(oVe," (XLNet model)"),oVe.forEach(t),uVo=i(x),Z2=n(x,"LI",{});var rVe=s(Z2);Zbe=n(rVe,"STRONG",{});var ODt=s(Zbe);pVo=r(ODt,"yolos"),ODt.forEach(t),_Vo=r(rVe," \u2014 "),UQ=n(rVe,"A",{href:!0});var VDt=s(UQ);bVo=r(VDt,"YolosModel"),VDt.forEach(t),vVo=r(rVe," (YOLOS model)"),rVe.forEach(t),FVo=i(x),K2=n(x,"LI",{});var tVe=s(K2);Kbe=n(tVe,"STRONG",{});var XDt=s(Kbe);TVo=r(XDt,"yoso"),XDt.forEach(t),MVo=r(tVe," \u2014 "),HQ=n(tVe,"A",{href:!0});var zDt=s(HQ);EVo=r(zDt,"YosoModel"),zDt.forEach(t),CVo=r(tVe," (YOSO model)"),tVe.forEach(t),x.forEach(t),wVo=i(La),eb=n(La,"P",{});var aVe=s(eb);AVo=r(aVe,"The model is set in evaluation mode by default using "),eve=n(aVe,"CODE",{});var QDt=s(eve);LVo=r(QDt,"model.eval()"),QDt.forEach(t),yVo=r(aVe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ove=n(aVe,"CODE",{});var WDt=s(ove);xVo=r(WDt,"model.train()"),WDt.forEach(t),aVe.forEach(t),$Vo=i(La),T(ob.$$.fragment,La),La.forEach(t),Nl.forEach(t),Dto=i(c),Pd=n(c,"H2",{class:!0});var tso=s(Pd);rb=n(tso,"A",{id:!0,class:!0,href:!0});var UDt=s(rb);rve=n(UDt,"SPAN",{});var HDt=s(rve);T(j$.$$.fragment,HDt),HDt.forEach(t),UDt.forEach(t),kVo=i(tso),tve=n(tso,"SPAN",{});var JDt=s(tve);SVo=r(JDt,"AutoModelForPreTraining"),JDt.forEach(t),tso.forEach(t),jto=i(c),No=n(c,"DIV",{class:!0});var ql=s(No);T(G$.$$.fragment,ql),RVo=i(ql),Bd=n(ql,"P",{});var ame=s(Bd);PVo=r(ame,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),JQ=n(ame,"A",{href:!0});var YDt=s(JQ);BVo=r(YDt,"from_pretrained()"),YDt.forEach(t),IVo=r(ame," class method or the "),YQ=n(ame,"A",{href:!0});var ZDt=s(YQ);NVo=r(ZDt,"from_config()"),ZDt.forEach(t),qVo=r(ame,` class
method.`),ame.forEach(t),DVo=i(ql),O$=n(ql,"P",{});var aso=s(O$);jVo=r(aso,"This class cannot be instantiated directly using "),ave=n(aso,"CODE",{});var KDt=s(ave);GVo=r(KDt,"__init__()"),KDt.forEach(t),OVo=r(aso," (throws an error)."),aso.forEach(t),VVo=i(ql),Et=n(ql,"DIV",{class:!0});var r9=s(Et);T(V$.$$.fragment,r9),XVo=i(r9),nve=n(r9,"P",{});var ejt=s(nve);zVo=r(ejt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),ejt.forEach(t),QVo=i(r9),Id=n(r9,"P",{});var nme=s(Id);WVo=r(nme,`Note:
Loading a model from its configuration file does `),sve=n(nme,"STRONG",{});var ojt=s(sve);UVo=r(ojt,"not"),ojt.forEach(t),HVo=r(nme,` load the model weights. It only affects the
model\u2019s configuration. Use `),ZQ=n(nme,"A",{href:!0});var rjt=s(ZQ);JVo=r(rjt,"from_pretrained()"),rjt.forEach(t),YVo=r(nme," to load the model weights."),nme.forEach(t),ZVo=i(r9),T(tb.$$.fragment,r9),r9.forEach(t),KVo=i(ql),eo=n(ql,"DIV",{class:!0});var ya=s(eo);T(X$.$$.fragment,ya),eXo=i(ya),lve=n(ya,"P",{});var tjt=s(lve);oXo=r(tjt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),tjt.forEach(t),rXo=i(ya),sn=n(ya,"P",{});var t9=s(sn);tXo=r(t9,"The model class to instantiate is selected based on the "),ive=n(t9,"CODE",{});var ajt=s(ive);aXo=r(ajt,"model_type"),ajt.forEach(t),nXo=r(t9,` property of the config object (either
passed as an argument or loaded from `),dve=n(t9,"CODE",{});var njt=s(dve);sXo=r(njt,"pretrained_model_name_or_path"),njt.forEach(t),lXo=r(t9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mve=n(t9,"CODE",{});var sjt=s(mve);iXo=r(sjt,"pretrained_model_name_or_path"),sjt.forEach(t),dXo=r(t9,":"),t9.forEach(t),mXo=i(ya),G=n(ya,"UL",{});var V=s(G);ab=n(V,"LI",{});var nVe=s(ab);cve=n(nVe,"STRONG",{});var ljt=s(cve);cXo=r(ljt,"albert"),ljt.forEach(t),fXo=r(nVe," \u2014 "),KQ=n(nVe,"A",{href:!0});var ijt=s(KQ);gXo=r(ijt,"AlbertForPreTraining"),ijt.forEach(t),hXo=r(nVe," (ALBERT model)"),nVe.forEach(t),uXo=i(V),nb=n(V,"LI",{});var sVe=s(nb);fve=n(sVe,"STRONG",{});var djt=s(fve);pXo=r(djt,"bart"),djt.forEach(t),_Xo=r(sVe," \u2014 "),eW=n(sVe,"A",{href:!0});var mjt=s(eW);bXo=r(mjt,"BartForConditionalGeneration"),mjt.forEach(t),vXo=r(sVe," (BART model)"),sVe.forEach(t),FXo=i(V),sb=n(V,"LI",{});var lVe=s(sb);gve=n(lVe,"STRONG",{});var cjt=s(gve);TXo=r(cjt,"bert"),cjt.forEach(t),MXo=r(lVe," \u2014 "),oW=n(lVe,"A",{href:!0});var fjt=s(oW);EXo=r(fjt,"BertForPreTraining"),fjt.forEach(t),CXo=r(lVe," (BERT model)"),lVe.forEach(t),wXo=i(V),lb=n(V,"LI",{});var iVe=s(lb);hve=n(iVe,"STRONG",{});var gjt=s(hve);AXo=r(gjt,"big_bird"),gjt.forEach(t),LXo=r(iVe," \u2014 "),rW=n(iVe,"A",{href:!0});var hjt=s(rW);yXo=r(hjt,"BigBirdForPreTraining"),hjt.forEach(t),xXo=r(iVe," (BigBird model)"),iVe.forEach(t),$Xo=i(V),ib=n(V,"LI",{});var dVe=s(ib);uve=n(dVe,"STRONG",{});var ujt=s(uve);kXo=r(ujt,"bloom"),ujt.forEach(t),SXo=r(dVe," \u2014 "),tW=n(dVe,"A",{href:!0});var pjt=s(tW);RXo=r(pjt,"BloomForCausalLM"),pjt.forEach(t),PXo=r(dVe," (BLOOM model)"),dVe.forEach(t),BXo=i(V),db=n(V,"LI",{});var mVe=s(db);pve=n(mVe,"STRONG",{});var _jt=s(pve);IXo=r(_jt,"camembert"),_jt.forEach(t),NXo=r(mVe," \u2014 "),aW=n(mVe,"A",{href:!0});var bjt=s(aW);qXo=r(bjt,"CamembertForMaskedLM"),bjt.forEach(t),DXo=r(mVe," (CamemBERT model)"),mVe.forEach(t),jXo=i(V),mb=n(V,"LI",{});var cVe=s(mb);_ve=n(cVe,"STRONG",{});var vjt=s(_ve);GXo=r(vjt,"ctrl"),vjt.forEach(t),OXo=r(cVe," \u2014 "),nW=n(cVe,"A",{href:!0});var Fjt=s(nW);VXo=r(Fjt,"CTRLLMHeadModel"),Fjt.forEach(t),XXo=r(cVe," (CTRL model)"),cVe.forEach(t),zXo=i(V),cb=n(V,"LI",{});var fVe=s(cb);bve=n(fVe,"STRONG",{});var Tjt=s(bve);QXo=r(Tjt,"data2vec-text"),Tjt.forEach(t),WXo=r(fVe," \u2014 "),sW=n(fVe,"A",{href:!0});var Mjt=s(sW);UXo=r(Mjt,"Data2VecTextForMaskedLM"),Mjt.forEach(t),HXo=r(fVe," (Data2VecText model)"),fVe.forEach(t),JXo=i(V),fb=n(V,"LI",{});var gVe=s(fb);vve=n(gVe,"STRONG",{});var Ejt=s(vve);YXo=r(Ejt,"deberta"),Ejt.forEach(t),ZXo=r(gVe," \u2014 "),lW=n(gVe,"A",{href:!0});var Cjt=s(lW);KXo=r(Cjt,"DebertaForMaskedLM"),Cjt.forEach(t),ezo=r(gVe," (DeBERTa model)"),gVe.forEach(t),ozo=i(V),gb=n(V,"LI",{});var hVe=s(gb);Fve=n(hVe,"STRONG",{});var wjt=s(Fve);rzo=r(wjt,"deberta-v2"),wjt.forEach(t),tzo=r(hVe," \u2014 "),iW=n(hVe,"A",{href:!0});var Ajt=s(iW);azo=r(Ajt,"DebertaV2ForMaskedLM"),Ajt.forEach(t),nzo=r(hVe," (DeBERTa-v2 model)"),hVe.forEach(t),szo=i(V),hb=n(V,"LI",{});var uVe=s(hb);Tve=n(uVe,"STRONG",{});var Ljt=s(Tve);lzo=r(Ljt,"distilbert"),Ljt.forEach(t),izo=r(uVe," \u2014 "),dW=n(uVe,"A",{href:!0});var yjt=s(dW);dzo=r(yjt,"DistilBertForMaskedLM"),yjt.forEach(t),mzo=r(uVe," (DistilBERT model)"),uVe.forEach(t),czo=i(V),ub=n(V,"LI",{});var pVe=s(ub);Mve=n(pVe,"STRONG",{});var xjt=s(Mve);fzo=r(xjt,"electra"),xjt.forEach(t),gzo=r(pVe," \u2014 "),mW=n(pVe,"A",{href:!0});var $jt=s(mW);hzo=r($jt,"ElectraForPreTraining"),$jt.forEach(t),uzo=r(pVe," (ELECTRA model)"),pVe.forEach(t),pzo=i(V),pb=n(V,"LI",{});var _Ve=s(pb);Eve=n(_Ve,"STRONG",{});var kjt=s(Eve);_zo=r(kjt,"ernie"),kjt.forEach(t),bzo=r(_Ve," \u2014 "),cW=n(_Ve,"A",{href:!0});var Sjt=s(cW);vzo=r(Sjt,"ErnieForPreTraining"),Sjt.forEach(t),Fzo=r(_Ve," (ERNIE model)"),_Ve.forEach(t),Tzo=i(V),_b=n(V,"LI",{});var bVe=s(_b);Cve=n(bVe,"STRONG",{});var Rjt=s(Cve);Mzo=r(Rjt,"flaubert"),Rjt.forEach(t),Ezo=r(bVe," \u2014 "),fW=n(bVe,"A",{href:!0});var Pjt=s(fW);Czo=r(Pjt,"FlaubertWithLMHeadModel"),Pjt.forEach(t),wzo=r(bVe," (FlauBERT model)"),bVe.forEach(t),Azo=i(V),bb=n(V,"LI",{});var vVe=s(bb);wve=n(vVe,"STRONG",{});var Bjt=s(wve);Lzo=r(Bjt,"flava"),Bjt.forEach(t),yzo=r(vVe," \u2014 "),gW=n(vVe,"A",{href:!0});var Ijt=s(gW);xzo=r(Ijt,"FlavaForPreTraining"),Ijt.forEach(t),$zo=r(vVe," (FLAVA model)"),vVe.forEach(t),kzo=i(V),vb=n(V,"LI",{});var FVe=s(vb);Ave=n(FVe,"STRONG",{});var Njt=s(Ave);Szo=r(Njt,"fnet"),Njt.forEach(t),Rzo=r(FVe," \u2014 "),hW=n(FVe,"A",{href:!0});var qjt=s(hW);Pzo=r(qjt,"FNetForPreTraining"),qjt.forEach(t),Bzo=r(FVe," (FNet model)"),FVe.forEach(t),Izo=i(V),Fb=n(V,"LI",{});var TVe=s(Fb);Lve=n(TVe,"STRONG",{});var Djt=s(Lve);Nzo=r(Djt,"fsmt"),Djt.forEach(t),qzo=r(TVe," \u2014 "),uW=n(TVe,"A",{href:!0});var jjt=s(uW);Dzo=r(jjt,"FSMTForConditionalGeneration"),jjt.forEach(t),jzo=r(TVe," (FairSeq Machine-Translation model)"),TVe.forEach(t),Gzo=i(V),Tb=n(V,"LI",{});var MVe=s(Tb);yve=n(MVe,"STRONG",{});var Gjt=s(yve);Ozo=r(Gjt,"funnel"),Gjt.forEach(t),Vzo=r(MVe," \u2014 "),pW=n(MVe,"A",{href:!0});var Ojt=s(pW);Xzo=r(Ojt,"FunnelForPreTraining"),Ojt.forEach(t),zzo=r(MVe," (Funnel Transformer model)"),MVe.forEach(t),Qzo=i(V),Mb=n(V,"LI",{});var EVe=s(Mb);xve=n(EVe,"STRONG",{});var Vjt=s(xve);Wzo=r(Vjt,"gpt2"),Vjt.forEach(t),Uzo=r(EVe," \u2014 "),_W=n(EVe,"A",{href:!0});var Xjt=s(_W);Hzo=r(Xjt,"GPT2LMHeadModel"),Xjt.forEach(t),Jzo=r(EVe," (OpenAI GPT-2 model)"),EVe.forEach(t),Yzo=i(V),Eb=n(V,"LI",{});var CVe=s(Eb);$ve=n(CVe,"STRONG",{});var zjt=s($ve);Zzo=r(zjt,"ibert"),zjt.forEach(t),Kzo=r(CVe," \u2014 "),bW=n(CVe,"A",{href:!0});var Qjt=s(bW);eQo=r(Qjt,"IBertForMaskedLM"),Qjt.forEach(t),oQo=r(CVe," (I-BERT model)"),CVe.forEach(t),rQo=i(V),Cb=n(V,"LI",{});var wVe=s(Cb);kve=n(wVe,"STRONG",{});var Wjt=s(kve);tQo=r(Wjt,"layoutlm"),Wjt.forEach(t),aQo=r(wVe," \u2014 "),vW=n(wVe,"A",{href:!0});var Ujt=s(vW);nQo=r(Ujt,"LayoutLMForMaskedLM"),Ujt.forEach(t),sQo=r(wVe," (LayoutLM model)"),wVe.forEach(t),lQo=i(V),wb=n(V,"LI",{});var AVe=s(wb);Sve=n(AVe,"STRONG",{});var Hjt=s(Sve);iQo=r(Hjt,"longformer"),Hjt.forEach(t),dQo=r(AVe," \u2014 "),FW=n(AVe,"A",{href:!0});var Jjt=s(FW);mQo=r(Jjt,"LongformerForMaskedLM"),Jjt.forEach(t),cQo=r(AVe," (Longformer model)"),AVe.forEach(t),fQo=i(V),Ab=n(V,"LI",{});var LVe=s(Ab);Rve=n(LVe,"STRONG",{});var Yjt=s(Rve);gQo=r(Yjt,"luke"),Yjt.forEach(t),hQo=r(LVe," \u2014 "),TW=n(LVe,"A",{href:!0});var Zjt=s(TW);uQo=r(Zjt,"LukeForMaskedLM"),Zjt.forEach(t),pQo=r(LVe," (LUKE model)"),LVe.forEach(t),_Qo=i(V),Lb=n(V,"LI",{});var yVe=s(Lb);Pve=n(yVe,"STRONG",{});var Kjt=s(Pve);bQo=r(Kjt,"lxmert"),Kjt.forEach(t),vQo=r(yVe," \u2014 "),MW=n(yVe,"A",{href:!0});var eGt=s(MW);FQo=r(eGt,"LxmertForPreTraining"),eGt.forEach(t),TQo=r(yVe," (LXMERT model)"),yVe.forEach(t),MQo=i(V),yb=n(V,"LI",{});var xVe=s(yb);Bve=n(xVe,"STRONG",{});var oGt=s(Bve);EQo=r(oGt,"megatron-bert"),oGt.forEach(t),CQo=r(xVe," \u2014 "),EW=n(xVe,"A",{href:!0});var rGt=s(EW);wQo=r(rGt,"MegatronBertForPreTraining"),rGt.forEach(t),AQo=r(xVe," (Megatron-BERT model)"),xVe.forEach(t),LQo=i(V),xb=n(V,"LI",{});var $Ve=s(xb);Ive=n($Ve,"STRONG",{});var tGt=s(Ive);yQo=r(tGt,"mobilebert"),tGt.forEach(t),xQo=r($Ve," \u2014 "),CW=n($Ve,"A",{href:!0});var aGt=s(CW);$Qo=r(aGt,"MobileBertForPreTraining"),aGt.forEach(t),kQo=r($Ve," (MobileBERT model)"),$Ve.forEach(t),SQo=i(V),$b=n(V,"LI",{});var kVe=s($b);Nve=n(kVe,"STRONG",{});var nGt=s(Nve);RQo=r(nGt,"mpnet"),nGt.forEach(t),PQo=r(kVe," \u2014 "),wW=n(kVe,"A",{href:!0});var sGt=s(wW);BQo=r(sGt,"MPNetForMaskedLM"),sGt.forEach(t),IQo=r(kVe," (MPNet model)"),kVe.forEach(t),NQo=i(V),kb=n(V,"LI",{});var SVe=s(kb);qve=n(SVe,"STRONG",{});var lGt=s(qve);qQo=r(lGt,"mvp"),lGt.forEach(t),DQo=r(SVe," \u2014 "),AW=n(SVe,"A",{href:!0});var iGt=s(AW);jQo=r(iGt,"MvpForConditionalGeneration"),iGt.forEach(t),GQo=r(SVe," (MVP model)"),SVe.forEach(t),OQo=i(V),Sb=n(V,"LI",{});var RVe=s(Sb);Dve=n(RVe,"STRONG",{});var dGt=s(Dve);VQo=r(dGt,"nezha"),dGt.forEach(t),XQo=r(RVe," \u2014 "),LW=n(RVe,"A",{href:!0});var mGt=s(LW);zQo=r(mGt,"NezhaForPreTraining"),mGt.forEach(t),QQo=r(RVe," (Nezha model)"),RVe.forEach(t),WQo=i(V),Rb=n(V,"LI",{});var PVe=s(Rb);jve=n(PVe,"STRONG",{});var cGt=s(jve);UQo=r(cGt,"openai-gpt"),cGt.forEach(t),HQo=r(PVe," \u2014 "),yW=n(PVe,"A",{href:!0});var fGt=s(yW);JQo=r(fGt,"OpenAIGPTLMHeadModel"),fGt.forEach(t),YQo=r(PVe," (OpenAI GPT model)"),PVe.forEach(t),ZQo=i(V),Pb=n(V,"LI",{});var BVe=s(Pb);Gve=n(BVe,"STRONG",{});var gGt=s(Gve);KQo=r(gGt,"retribert"),gGt.forEach(t),eWo=r(BVe," \u2014 "),xW=n(BVe,"A",{href:!0});var hGt=s(xW);oWo=r(hGt,"RetriBertModel"),hGt.forEach(t),rWo=r(BVe," (RetriBERT model)"),BVe.forEach(t),tWo=i(V),Bb=n(V,"LI",{});var IVe=s(Bb);Ove=n(IVe,"STRONG",{});var uGt=s(Ove);aWo=r(uGt,"roberta"),uGt.forEach(t),nWo=r(IVe," \u2014 "),$W=n(IVe,"A",{href:!0});var pGt=s($W);sWo=r(pGt,"RobertaForMaskedLM"),pGt.forEach(t),lWo=r(IVe," (RoBERTa model)"),IVe.forEach(t),iWo=i(V),Ib=n(V,"LI",{});var NVe=s(Ib);Vve=n(NVe,"STRONG",{});var _Gt=s(Vve);dWo=r(_Gt,"splinter"),_Gt.forEach(t),mWo=r(NVe," \u2014 "),kW=n(NVe,"A",{href:!0});var bGt=s(kW);cWo=r(bGt,"SplinterForPreTraining"),bGt.forEach(t),fWo=r(NVe," (Splinter model)"),NVe.forEach(t),gWo=i(V),Nb=n(V,"LI",{});var qVe=s(Nb);Xve=n(qVe,"STRONG",{});var vGt=s(Xve);hWo=r(vGt,"squeezebert"),vGt.forEach(t),uWo=r(qVe," \u2014 "),SW=n(qVe,"A",{href:!0});var FGt=s(SW);pWo=r(FGt,"SqueezeBertForMaskedLM"),FGt.forEach(t),_Wo=r(qVe," (SqueezeBERT model)"),qVe.forEach(t),bWo=i(V),qb=n(V,"LI",{});var DVe=s(qb);zve=n(DVe,"STRONG",{});var TGt=s(zve);vWo=r(TGt,"t5"),TGt.forEach(t),FWo=r(DVe," \u2014 "),RW=n(DVe,"A",{href:!0});var MGt=s(RW);TWo=r(MGt,"T5ForConditionalGeneration"),MGt.forEach(t),MWo=r(DVe," (T5 model)"),DVe.forEach(t),EWo=i(V),Db=n(V,"LI",{});var jVe=s(Db);Qve=n(jVe,"STRONG",{});var EGt=s(Qve);CWo=r(EGt,"tapas"),EGt.forEach(t),wWo=r(jVe," \u2014 "),PW=n(jVe,"A",{href:!0});var CGt=s(PW);AWo=r(CGt,"TapasForMaskedLM"),CGt.forEach(t),LWo=r(jVe," (TAPAS model)"),jVe.forEach(t),yWo=i(V),jb=n(V,"LI",{});var GVe=s(jb);Wve=n(GVe,"STRONG",{});var wGt=s(Wve);xWo=r(wGt,"transfo-xl"),wGt.forEach(t),$Wo=r(GVe," \u2014 "),BW=n(GVe,"A",{href:!0});var AGt=s(BW);kWo=r(AGt,"TransfoXLLMHeadModel"),AGt.forEach(t),SWo=r(GVe," (Transformer-XL model)"),GVe.forEach(t),RWo=i(V),Gb=n(V,"LI",{});var OVe=s(Gb);Uve=n(OVe,"STRONG",{});var LGt=s(Uve);PWo=r(LGt,"unispeech"),LGt.forEach(t),BWo=r(OVe," \u2014 "),IW=n(OVe,"A",{href:!0});var yGt=s(IW);IWo=r(yGt,"UniSpeechForPreTraining"),yGt.forEach(t),NWo=r(OVe," (UniSpeech model)"),OVe.forEach(t),qWo=i(V),Ob=n(V,"LI",{});var VVe=s(Ob);Hve=n(VVe,"STRONG",{});var xGt=s(Hve);DWo=r(xGt,"unispeech-sat"),xGt.forEach(t),jWo=r(VVe," \u2014 "),NW=n(VVe,"A",{href:!0});var $Gt=s(NW);GWo=r($Gt,"UniSpeechSatForPreTraining"),$Gt.forEach(t),OWo=r(VVe," (UniSpeechSat model)"),VVe.forEach(t),VWo=i(V),Vb=n(V,"LI",{});var XVe=s(Vb);Jve=n(XVe,"STRONG",{});var kGt=s(Jve);XWo=r(kGt,"videomae"),kGt.forEach(t),zWo=r(XVe," \u2014 "),qW=n(XVe,"A",{href:!0});var SGt=s(qW);QWo=r(SGt,"VideoMAEForPreTraining"),SGt.forEach(t),WWo=r(XVe," (VideoMAE model)"),XVe.forEach(t),UWo=i(V),Xb=n(V,"LI",{});var zVe=s(Xb);Yve=n(zVe,"STRONG",{});var RGt=s(Yve);HWo=r(RGt,"visual_bert"),RGt.forEach(t),JWo=r(zVe," \u2014 "),DW=n(zVe,"A",{href:!0});var PGt=s(DW);YWo=r(PGt,"VisualBertForPreTraining"),PGt.forEach(t),ZWo=r(zVe," (VisualBERT model)"),zVe.forEach(t),KWo=i(V),zb=n(V,"LI",{});var QVe=s(zb);Zve=n(QVe,"STRONG",{});var BGt=s(Zve);eUo=r(BGt,"vit_mae"),BGt.forEach(t),oUo=r(QVe," \u2014 "),jW=n(QVe,"A",{href:!0});var IGt=s(jW);rUo=r(IGt,"ViTMAEForPreTraining"),IGt.forEach(t),tUo=r(QVe," (ViTMAE model)"),QVe.forEach(t),aUo=i(V),Qb=n(V,"LI",{});var WVe=s(Qb);Kve=n(WVe,"STRONG",{});var NGt=s(Kve);nUo=r(NGt,"wav2vec2"),NGt.forEach(t),sUo=r(WVe," \u2014 "),GW=n(WVe,"A",{href:!0});var qGt=s(GW);lUo=r(qGt,"Wav2Vec2ForPreTraining"),qGt.forEach(t),iUo=r(WVe," (Wav2Vec2 model)"),WVe.forEach(t),dUo=i(V),Wb=n(V,"LI",{});var UVe=s(Wb);eFe=n(UVe,"STRONG",{});var DGt=s(eFe);mUo=r(DGt,"wav2vec2-conformer"),DGt.forEach(t),cUo=r(UVe," \u2014 "),OW=n(UVe,"A",{href:!0});var jGt=s(OW);fUo=r(jGt,"Wav2Vec2ConformerForPreTraining"),jGt.forEach(t),gUo=r(UVe," (Wav2Vec2-Conformer model)"),UVe.forEach(t),hUo=i(V),Ub=n(V,"LI",{});var HVe=s(Ub);oFe=n(HVe,"STRONG",{});var GGt=s(oFe);uUo=r(GGt,"xlm"),GGt.forEach(t),pUo=r(HVe," \u2014 "),VW=n(HVe,"A",{href:!0});var OGt=s(VW);_Uo=r(OGt,"XLMWithLMHeadModel"),OGt.forEach(t),bUo=r(HVe," (XLM model)"),HVe.forEach(t),vUo=i(V),Hb=n(V,"LI",{});var JVe=s(Hb);rFe=n(JVe,"STRONG",{});var VGt=s(rFe);FUo=r(VGt,"xlm-roberta"),VGt.forEach(t),TUo=r(JVe," \u2014 "),XW=n(JVe,"A",{href:!0});var XGt=s(XW);MUo=r(XGt,"XLMRobertaForMaskedLM"),XGt.forEach(t),EUo=r(JVe," (XLM-RoBERTa model)"),JVe.forEach(t),CUo=i(V),Jb=n(V,"LI",{});var YVe=s(Jb);tFe=n(YVe,"STRONG",{});var zGt=s(tFe);wUo=r(zGt,"xlm-roberta-xl"),zGt.forEach(t),AUo=r(YVe," \u2014 "),zW=n(YVe,"A",{href:!0});var QGt=s(zW);LUo=r(QGt,"XLMRobertaXLForMaskedLM"),QGt.forEach(t),yUo=r(YVe," (XLM-RoBERTa-XL model)"),YVe.forEach(t),xUo=i(V),Yb=n(V,"LI",{});var ZVe=s(Yb);aFe=n(ZVe,"STRONG",{});var WGt=s(aFe);$Uo=r(WGt,"xlnet"),WGt.forEach(t),kUo=r(ZVe," \u2014 "),QW=n(ZVe,"A",{href:!0});var UGt=s(QW);SUo=r(UGt,"XLNetLMHeadModel"),UGt.forEach(t),RUo=r(ZVe," (XLNet model)"),ZVe.forEach(t),V.forEach(t),PUo=i(ya),Zb=n(ya,"P",{});var KVe=s(Zb);BUo=r(KVe,"The model is set in evaluation mode by default using "),nFe=n(KVe,"CODE",{});var HGt=s(nFe);IUo=r(HGt,"model.eval()"),HGt.forEach(t),NUo=r(KVe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),sFe=n(KVe,"CODE",{});var JGt=s(sFe);qUo=r(JGt,"model.train()"),JGt.forEach(t),KVe.forEach(t),DUo=i(ya),T(Kb.$$.fragment,ya),ya.forEach(t),ql.forEach(t),Gto=i(c),Nd=n(c,"H2",{class:!0});var nso=s(Nd);ev=n(nso,"A",{id:!0,class:!0,href:!0});var YGt=s(ev);lFe=n(YGt,"SPAN",{});var ZGt=s(lFe);T(z$.$$.fragment,ZGt),ZGt.forEach(t),YGt.forEach(t),jUo=i(nso),iFe=n(nso,"SPAN",{});var KGt=s(iFe);GUo=r(KGt,"AutoModelForCausalLM"),KGt.forEach(t),nso.forEach(t),Oto=i(c),qo=n(c,"DIV",{class:!0});var Dl=s(qo);T(Q$.$$.fragment,Dl),OUo=i(Dl),qd=n(Dl,"P",{});var sme=s(qd);VUo=r(sme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),WW=n(sme,"A",{href:!0});var eOt=s(WW);XUo=r(eOt,"from_pretrained()"),eOt.forEach(t),zUo=r(sme," class method or the "),UW=n(sme,"A",{href:!0});var oOt=s(UW);QUo=r(oOt,"from_config()"),oOt.forEach(t),WUo=r(sme,` class
method.`),sme.forEach(t),UUo=i(Dl),W$=n(Dl,"P",{});var sso=s(W$);HUo=r(sso,"This class cannot be instantiated directly using "),dFe=n(sso,"CODE",{});var rOt=s(dFe);JUo=r(rOt,"__init__()"),rOt.forEach(t),YUo=r(sso," (throws an error)."),sso.forEach(t),ZUo=i(Dl),Ct=n(Dl,"DIV",{class:!0});var a9=s(Ct);T(U$.$$.fragment,a9),KUo=i(a9),mFe=n(a9,"P",{});var tOt=s(mFe);eHo=r(tOt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),tOt.forEach(t),oHo=i(a9),Dd=n(a9,"P",{});var lme=s(Dd);rHo=r(lme,`Note:
Loading a model from its configuration file does `),cFe=n(lme,"STRONG",{});var aOt=s(cFe);tHo=r(aOt,"not"),aOt.forEach(t),aHo=r(lme,` load the model weights. It only affects the
model\u2019s configuration. Use `),HW=n(lme,"A",{href:!0});var nOt=s(HW);nHo=r(nOt,"from_pretrained()"),nOt.forEach(t),sHo=r(lme," to load the model weights."),lme.forEach(t),lHo=i(a9),T(ov.$$.fragment,a9),a9.forEach(t),iHo=i(Dl),oo=n(Dl,"DIV",{class:!0});var xa=s(oo);T(H$.$$.fragment,xa),dHo=i(xa),fFe=n(xa,"P",{});var sOt=s(fFe);mHo=r(sOt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),sOt.forEach(t),cHo=i(xa),ln=n(xa,"P",{});var n9=s(ln);fHo=r(n9,"The model class to instantiate is selected based on the "),gFe=n(n9,"CODE",{});var lOt=s(gFe);gHo=r(lOt,"model_type"),lOt.forEach(t),hHo=r(n9,` property of the config object (either
passed as an argument or loaded from `),hFe=n(n9,"CODE",{});var iOt=s(hFe);uHo=r(iOt,"pretrained_model_name_or_path"),iOt.forEach(t),pHo=r(n9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uFe=n(n9,"CODE",{});var dOt=s(uFe);_Ho=r(dOt,"pretrained_model_name_or_path"),dOt.forEach(t),bHo=r(n9,":"),n9.forEach(t),vHo=i(xa),W=n(xa,"UL",{});var H=s(W);rv=n(H,"LI",{});var eXe=s(rv);pFe=n(eXe,"STRONG",{});var mOt=s(pFe);FHo=r(mOt,"bart"),mOt.forEach(t),THo=r(eXe," \u2014 "),JW=n(eXe,"A",{href:!0});var cOt=s(JW);MHo=r(cOt,"BartForCausalLM"),cOt.forEach(t),EHo=r(eXe," (BART model)"),eXe.forEach(t),CHo=i(H),tv=n(H,"LI",{});var oXe=s(tv);_Fe=n(oXe,"STRONG",{});var fOt=s(_Fe);wHo=r(fOt,"bert"),fOt.forEach(t),AHo=r(oXe," \u2014 "),YW=n(oXe,"A",{href:!0});var gOt=s(YW);LHo=r(gOt,"BertLMHeadModel"),gOt.forEach(t),yHo=r(oXe," (BERT model)"),oXe.forEach(t),xHo=i(H),av=n(H,"LI",{});var rXe=s(av);bFe=n(rXe,"STRONG",{});var hOt=s(bFe);$Ho=r(hOt,"bert-generation"),hOt.forEach(t),kHo=r(rXe," \u2014 "),ZW=n(rXe,"A",{href:!0});var uOt=s(ZW);SHo=r(uOt,"BertGenerationDecoder"),uOt.forEach(t),RHo=r(rXe," (Bert Generation model)"),rXe.forEach(t),PHo=i(H),nv=n(H,"LI",{});var tXe=s(nv);vFe=n(tXe,"STRONG",{});var pOt=s(vFe);BHo=r(pOt,"big_bird"),pOt.forEach(t),IHo=r(tXe," \u2014 "),KW=n(tXe,"A",{href:!0});var _Ot=s(KW);NHo=r(_Ot,"BigBirdForCausalLM"),_Ot.forEach(t),qHo=r(tXe," (BigBird model)"),tXe.forEach(t),DHo=i(H),sv=n(H,"LI",{});var aXe=s(sv);FFe=n(aXe,"STRONG",{});var bOt=s(FFe);jHo=r(bOt,"bigbird_pegasus"),bOt.forEach(t),GHo=r(aXe," \u2014 "),eU=n(aXe,"A",{href:!0});var vOt=s(eU);OHo=r(vOt,"BigBirdPegasusForCausalLM"),vOt.forEach(t),VHo=r(aXe," (BigBird-Pegasus model)"),aXe.forEach(t),XHo=i(H),lv=n(H,"LI",{});var nXe=s(lv);TFe=n(nXe,"STRONG",{});var FOt=s(TFe);zHo=r(FOt,"blenderbot"),FOt.forEach(t),QHo=r(nXe," \u2014 "),oU=n(nXe,"A",{href:!0});var TOt=s(oU);WHo=r(TOt,"BlenderbotForCausalLM"),TOt.forEach(t),UHo=r(nXe," (Blenderbot model)"),nXe.forEach(t),HHo=i(H),iv=n(H,"LI",{});var sXe=s(iv);MFe=n(sXe,"STRONG",{});var MOt=s(MFe);JHo=r(MOt,"blenderbot-small"),MOt.forEach(t),YHo=r(sXe," \u2014 "),rU=n(sXe,"A",{href:!0});var EOt=s(rU);ZHo=r(EOt,"BlenderbotSmallForCausalLM"),EOt.forEach(t),KHo=r(sXe," (BlenderbotSmall model)"),sXe.forEach(t),eJo=i(H),dv=n(H,"LI",{});var lXe=s(dv);EFe=n(lXe,"STRONG",{});var COt=s(EFe);oJo=r(COt,"bloom"),COt.forEach(t),rJo=r(lXe," \u2014 "),tU=n(lXe,"A",{href:!0});var wOt=s(tU);tJo=r(wOt,"BloomForCausalLM"),wOt.forEach(t),aJo=r(lXe," (BLOOM model)"),lXe.forEach(t),nJo=i(H),mv=n(H,"LI",{});var iXe=s(mv);CFe=n(iXe,"STRONG",{});var AOt=s(CFe);sJo=r(AOt,"camembert"),AOt.forEach(t),lJo=r(iXe," \u2014 "),aU=n(iXe,"A",{href:!0});var LOt=s(aU);iJo=r(LOt,"CamembertForCausalLM"),LOt.forEach(t),dJo=r(iXe," (CamemBERT model)"),iXe.forEach(t),mJo=i(H),cv=n(H,"LI",{});var dXe=s(cv);wFe=n(dXe,"STRONG",{});var yOt=s(wFe);cJo=r(yOt,"codegen"),yOt.forEach(t),fJo=r(dXe," \u2014 "),nU=n(dXe,"A",{href:!0});var xOt=s(nU);gJo=r(xOt,"CodeGenForCausalLM"),xOt.forEach(t),hJo=r(dXe," (CodeGen model)"),dXe.forEach(t),uJo=i(H),fv=n(H,"LI",{});var mXe=s(fv);AFe=n(mXe,"STRONG",{});var $Ot=s(AFe);pJo=r($Ot,"ctrl"),$Ot.forEach(t),_Jo=r(mXe," \u2014 "),sU=n(mXe,"A",{href:!0});var kOt=s(sU);bJo=r(kOt,"CTRLLMHeadModel"),kOt.forEach(t),vJo=r(mXe," (CTRL model)"),mXe.forEach(t),FJo=i(H),gv=n(H,"LI",{});var cXe=s(gv);LFe=n(cXe,"STRONG",{});var SOt=s(LFe);TJo=r(SOt,"data2vec-text"),SOt.forEach(t),MJo=r(cXe," \u2014 "),lU=n(cXe,"A",{href:!0});var ROt=s(lU);EJo=r(ROt,"Data2VecTextForCausalLM"),ROt.forEach(t),CJo=r(cXe," (Data2VecText model)"),cXe.forEach(t),wJo=i(H),hv=n(H,"LI",{});var fXe=s(hv);yFe=n(fXe,"STRONG",{});var POt=s(yFe);AJo=r(POt,"electra"),POt.forEach(t),LJo=r(fXe," \u2014 "),iU=n(fXe,"A",{href:!0});var BOt=s(iU);yJo=r(BOt,"ElectraForCausalLM"),BOt.forEach(t),xJo=r(fXe," (ELECTRA model)"),fXe.forEach(t),$Jo=i(H),uv=n(H,"LI",{});var gXe=s(uv);xFe=n(gXe,"STRONG",{});var IOt=s(xFe);kJo=r(IOt,"ernie"),IOt.forEach(t),SJo=r(gXe," \u2014 "),dU=n(gXe,"A",{href:!0});var NOt=s(dU);RJo=r(NOt,"ErnieForCausalLM"),NOt.forEach(t),PJo=r(gXe," (ERNIE model)"),gXe.forEach(t),BJo=i(H),pv=n(H,"LI",{});var hXe=s(pv);$Fe=n(hXe,"STRONG",{});var qOt=s($Fe);IJo=r(qOt,"gpt2"),qOt.forEach(t),NJo=r(hXe," \u2014 "),mU=n(hXe,"A",{href:!0});var DOt=s(mU);qJo=r(DOt,"GPT2LMHeadModel"),DOt.forEach(t),DJo=r(hXe," (OpenAI GPT-2 model)"),hXe.forEach(t),jJo=i(H),_v=n(H,"LI",{});var uXe=s(_v);kFe=n(uXe,"STRONG",{});var jOt=s(kFe);GJo=r(jOt,"gpt_neo"),jOt.forEach(t),OJo=r(uXe," \u2014 "),cU=n(uXe,"A",{href:!0});var GOt=s(cU);VJo=r(GOt,"GPTNeoForCausalLM"),GOt.forEach(t),XJo=r(uXe," (GPT Neo model)"),uXe.forEach(t),zJo=i(H),bv=n(H,"LI",{});var pXe=s(bv);SFe=n(pXe,"STRONG",{});var OOt=s(SFe);QJo=r(OOt,"gpt_neox"),OOt.forEach(t),WJo=r(pXe," \u2014 "),fU=n(pXe,"A",{href:!0});var VOt=s(fU);UJo=r(VOt,"GPTNeoXForCausalLM"),VOt.forEach(t),HJo=r(pXe," (GPT NeoX model)"),pXe.forEach(t),JJo=i(H),vv=n(H,"LI",{});var _Xe=s(vv);RFe=n(_Xe,"STRONG",{});var XOt=s(RFe);YJo=r(XOt,"gpt_neox_japanese"),XOt.forEach(t),ZJo=r(_Xe," \u2014 "),gU=n(_Xe,"A",{href:!0});var zOt=s(gU);KJo=r(zOt,"GPTNeoXJapaneseForCausalLM"),zOt.forEach(t),eYo=r(_Xe," (GPT NeoX Japanese model)"),_Xe.forEach(t),oYo=i(H),Fv=n(H,"LI",{});var bXe=s(Fv);PFe=n(bXe,"STRONG",{});var QOt=s(PFe);rYo=r(QOt,"gptj"),QOt.forEach(t),tYo=r(bXe," \u2014 "),hU=n(bXe,"A",{href:!0});var WOt=s(hU);aYo=r(WOt,"GPTJForCausalLM"),WOt.forEach(t),nYo=r(bXe," (GPT-J model)"),bXe.forEach(t),sYo=i(H),Tv=n(H,"LI",{});var vXe=s(Tv);BFe=n(vXe,"STRONG",{});var UOt=s(BFe);lYo=r(UOt,"marian"),UOt.forEach(t),iYo=r(vXe," \u2014 "),uU=n(vXe,"A",{href:!0});var HOt=s(uU);dYo=r(HOt,"MarianForCausalLM"),HOt.forEach(t),mYo=r(vXe," (Marian model)"),vXe.forEach(t),cYo=i(H),Mv=n(H,"LI",{});var FXe=s(Mv);IFe=n(FXe,"STRONG",{});var JOt=s(IFe);fYo=r(JOt,"mbart"),JOt.forEach(t),gYo=r(FXe," \u2014 "),pU=n(FXe,"A",{href:!0});var YOt=s(pU);hYo=r(YOt,"MBartForCausalLM"),YOt.forEach(t),uYo=r(FXe," (mBART model)"),FXe.forEach(t),pYo=i(H),Ev=n(H,"LI",{});var TXe=s(Ev);NFe=n(TXe,"STRONG",{});var ZOt=s(NFe);_Yo=r(ZOt,"megatron-bert"),ZOt.forEach(t),bYo=r(TXe," \u2014 "),_U=n(TXe,"A",{href:!0});var KOt=s(_U);vYo=r(KOt,"MegatronBertForCausalLM"),KOt.forEach(t),FYo=r(TXe," (Megatron-BERT model)"),TXe.forEach(t),TYo=i(H),Cv=n(H,"LI",{});var MXe=s(Cv);qFe=n(MXe,"STRONG",{});var eVt=s(qFe);MYo=r(eVt,"mvp"),eVt.forEach(t),EYo=r(MXe," \u2014 "),bU=n(MXe,"A",{href:!0});var oVt=s(bU);CYo=r(oVt,"MvpForCausalLM"),oVt.forEach(t),wYo=r(MXe," (MVP model)"),MXe.forEach(t),AYo=i(H),wv=n(H,"LI",{});var EXe=s(wv);DFe=n(EXe,"STRONG",{});var rVt=s(DFe);LYo=r(rVt,"openai-gpt"),rVt.forEach(t),yYo=r(EXe," \u2014 "),vU=n(EXe,"A",{href:!0});var tVt=s(vU);xYo=r(tVt,"OpenAIGPTLMHeadModel"),tVt.forEach(t),$Yo=r(EXe," (OpenAI GPT model)"),EXe.forEach(t),kYo=i(H),Av=n(H,"LI",{});var CXe=s(Av);jFe=n(CXe,"STRONG",{});var aVt=s(jFe);SYo=r(aVt,"opt"),aVt.forEach(t),RYo=r(CXe," \u2014 "),FU=n(CXe,"A",{href:!0});var nVt=s(FU);PYo=r(nVt,"OPTForCausalLM"),nVt.forEach(t),BYo=r(CXe," (OPT model)"),CXe.forEach(t),IYo=i(H),Lv=n(H,"LI",{});var wXe=s(Lv);GFe=n(wXe,"STRONG",{});var sVt=s(GFe);NYo=r(sVt,"pegasus"),sVt.forEach(t),qYo=r(wXe," \u2014 "),TU=n(wXe,"A",{href:!0});var lVt=s(TU);DYo=r(lVt,"PegasusForCausalLM"),lVt.forEach(t),jYo=r(wXe," (Pegasus model)"),wXe.forEach(t),GYo=i(H),yv=n(H,"LI",{});var AXe=s(yv);OFe=n(AXe,"STRONG",{});var iVt=s(OFe);OYo=r(iVt,"plbart"),iVt.forEach(t),VYo=r(AXe," \u2014 "),MU=n(AXe,"A",{href:!0});var dVt=s(MU);XYo=r(dVt,"PLBartForCausalLM"),dVt.forEach(t),zYo=r(AXe," (PLBart model)"),AXe.forEach(t),QYo=i(H),xv=n(H,"LI",{});var LXe=s(xv);VFe=n(LXe,"STRONG",{});var mVt=s(VFe);WYo=r(mVt,"prophetnet"),mVt.forEach(t),UYo=r(LXe," \u2014 "),EU=n(LXe,"A",{href:!0});var cVt=s(EU);HYo=r(cVt,"ProphetNetForCausalLM"),cVt.forEach(t),JYo=r(LXe," (ProphetNet model)"),LXe.forEach(t),YYo=i(H),$v=n(H,"LI",{});var yXe=s($v);XFe=n(yXe,"STRONG",{});var fVt=s(XFe);ZYo=r(fVt,"qdqbert"),fVt.forEach(t),KYo=r(yXe," \u2014 "),CU=n(yXe,"A",{href:!0});var gVt=s(CU);eZo=r(gVt,"QDQBertLMHeadModel"),gVt.forEach(t),oZo=r(yXe," (QDQBert model)"),yXe.forEach(t),rZo=i(H),kv=n(H,"LI",{});var xXe=s(kv);zFe=n(xXe,"STRONG",{});var hVt=s(zFe);tZo=r(hVt,"reformer"),hVt.forEach(t),aZo=r(xXe," \u2014 "),wU=n(xXe,"A",{href:!0});var uVt=s(wU);nZo=r(uVt,"ReformerModelWithLMHead"),uVt.forEach(t),sZo=r(xXe," (Reformer model)"),xXe.forEach(t),lZo=i(H),Sv=n(H,"LI",{});var $Xe=s(Sv);QFe=n($Xe,"STRONG",{});var pVt=s(QFe);iZo=r(pVt,"rembert"),pVt.forEach(t),dZo=r($Xe," \u2014 "),AU=n($Xe,"A",{href:!0});var _Vt=s(AU);mZo=r(_Vt,"RemBertForCausalLM"),_Vt.forEach(t),cZo=r($Xe," (RemBERT model)"),$Xe.forEach(t),fZo=i(H),Rv=n(H,"LI",{});var kXe=s(Rv);WFe=n(kXe,"STRONG",{});var bVt=s(WFe);gZo=r(bVt,"roberta"),bVt.forEach(t),hZo=r(kXe," \u2014 "),LU=n(kXe,"A",{href:!0});var vVt=s(LU);uZo=r(vVt,"RobertaForCausalLM"),vVt.forEach(t),pZo=r(kXe," (RoBERTa model)"),kXe.forEach(t),_Zo=i(H),Pv=n(H,"LI",{});var SXe=s(Pv);UFe=n(SXe,"STRONG",{});var FVt=s(UFe);bZo=r(FVt,"roformer"),FVt.forEach(t),vZo=r(SXe," \u2014 "),yU=n(SXe,"A",{href:!0});var TVt=s(yU);FZo=r(TVt,"RoFormerForCausalLM"),TVt.forEach(t),TZo=r(SXe," (RoFormer model)"),SXe.forEach(t),MZo=i(H),Bv=n(H,"LI",{});var RXe=s(Bv);HFe=n(RXe,"STRONG",{});var MVt=s(HFe);EZo=r(MVt,"speech_to_text_2"),MVt.forEach(t),CZo=r(RXe," \u2014 "),xU=n(RXe,"A",{href:!0});var EVt=s(xU);wZo=r(EVt,"Speech2Text2ForCausalLM"),EVt.forEach(t),AZo=r(RXe," (Speech2Text2 model)"),RXe.forEach(t),LZo=i(H),Iv=n(H,"LI",{});var PXe=s(Iv);JFe=n(PXe,"STRONG",{});var CVt=s(JFe);yZo=r(CVt,"transfo-xl"),CVt.forEach(t),xZo=r(PXe," \u2014 "),$U=n(PXe,"A",{href:!0});var wVt=s($U);$Zo=r(wVt,"TransfoXLLMHeadModel"),wVt.forEach(t),kZo=r(PXe," (Transformer-XL model)"),PXe.forEach(t),SZo=i(H),Nv=n(H,"LI",{});var BXe=s(Nv);YFe=n(BXe,"STRONG",{});var AVt=s(YFe);RZo=r(AVt,"trocr"),AVt.forEach(t),PZo=r(BXe," \u2014 "),kU=n(BXe,"A",{href:!0});var LVt=s(kU);BZo=r(LVt,"TrOCRForCausalLM"),LVt.forEach(t),IZo=r(BXe," (TrOCR model)"),BXe.forEach(t),NZo=i(H),qv=n(H,"LI",{});var IXe=s(qv);ZFe=n(IXe,"STRONG",{});var yVt=s(ZFe);qZo=r(yVt,"xglm"),yVt.forEach(t),DZo=r(IXe," \u2014 "),SU=n(IXe,"A",{href:!0});var xVt=s(SU);jZo=r(xVt,"XGLMForCausalLM"),xVt.forEach(t),GZo=r(IXe," (XGLM model)"),IXe.forEach(t),OZo=i(H),Dv=n(H,"LI",{});var NXe=s(Dv);KFe=n(NXe,"STRONG",{});var $Vt=s(KFe);VZo=r($Vt,"xlm"),$Vt.forEach(t),XZo=r(NXe," \u2014 "),RU=n(NXe,"A",{href:!0});var kVt=s(RU);zZo=r(kVt,"XLMWithLMHeadModel"),kVt.forEach(t),QZo=r(NXe," (XLM model)"),NXe.forEach(t),WZo=i(H),jv=n(H,"LI",{});var qXe=s(jv);eTe=n(qXe,"STRONG",{});var SVt=s(eTe);UZo=r(SVt,"xlm-prophetnet"),SVt.forEach(t),HZo=r(qXe," \u2014 "),PU=n(qXe,"A",{href:!0});var RVt=s(PU);JZo=r(RVt,"XLMProphetNetForCausalLM"),RVt.forEach(t),YZo=r(qXe," (XLM-ProphetNet model)"),qXe.forEach(t),ZZo=i(H),Gv=n(H,"LI",{});var DXe=s(Gv);oTe=n(DXe,"STRONG",{});var PVt=s(oTe);KZo=r(PVt,"xlm-roberta"),PVt.forEach(t),eKo=r(DXe," \u2014 "),BU=n(DXe,"A",{href:!0});var BVt=s(BU);oKo=r(BVt,"XLMRobertaForCausalLM"),BVt.forEach(t),rKo=r(DXe," (XLM-RoBERTa model)"),DXe.forEach(t),tKo=i(H),Ov=n(H,"LI",{});var jXe=s(Ov);rTe=n(jXe,"STRONG",{});var IVt=s(rTe);aKo=r(IVt,"xlm-roberta-xl"),IVt.forEach(t),nKo=r(jXe," \u2014 "),IU=n(jXe,"A",{href:!0});var NVt=s(IU);sKo=r(NVt,"XLMRobertaXLForCausalLM"),NVt.forEach(t),lKo=r(jXe," (XLM-RoBERTa-XL model)"),jXe.forEach(t),iKo=i(H),Vv=n(H,"LI",{});var GXe=s(Vv);tTe=n(GXe,"STRONG",{});var qVt=s(tTe);dKo=r(qVt,"xlnet"),qVt.forEach(t),mKo=r(GXe," \u2014 "),NU=n(GXe,"A",{href:!0});var DVt=s(NU);cKo=r(DVt,"XLNetLMHeadModel"),DVt.forEach(t),fKo=r(GXe," (XLNet model)"),GXe.forEach(t),H.forEach(t),gKo=i(xa),Xv=n(xa,"P",{});var OXe=s(Xv);hKo=r(OXe,"The model is set in evaluation mode by default using "),aTe=n(OXe,"CODE",{});var jVt=s(aTe);uKo=r(jVt,"model.eval()"),jVt.forEach(t),pKo=r(OXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),nTe=n(OXe,"CODE",{});var GVt=s(nTe);_Ko=r(GVt,"model.train()"),GVt.forEach(t),OXe.forEach(t),bKo=i(xa),T(zv.$$.fragment,xa),xa.forEach(t),Dl.forEach(t),Vto=i(c),jd=n(c,"H2",{class:!0});var lso=s(jd);Qv=n(lso,"A",{id:!0,class:!0,href:!0});var OVt=s(Qv);sTe=n(OVt,"SPAN",{});var VVt=s(sTe);T(J$.$$.fragment,VVt),VVt.forEach(t),OVt.forEach(t),vKo=i(lso),lTe=n(lso,"SPAN",{});var XVt=s(lTe);FKo=r(XVt,"AutoModelForDepthEstimation"),XVt.forEach(t),lso.forEach(t),Xto=i(c),Do=n(c,"DIV",{class:!0});var jl=s(Do);T(Y$.$$.fragment,jl),TKo=i(jl),Gd=n(jl,"P",{});var ime=s(Gd);MKo=r(ime,`This is a generic model class that will be instantiated as one of the model classes of the library (with a depth estimation head) when created
with the `),qU=n(ime,"A",{href:!0});var zVt=s(qU);EKo=r(zVt,"from_pretrained()"),zVt.forEach(t),CKo=r(ime," class method or the "),DU=n(ime,"A",{href:!0});var QVt=s(DU);wKo=r(QVt,"from_config()"),QVt.forEach(t),AKo=r(ime,` class
method.`),ime.forEach(t),LKo=i(jl),Z$=n(jl,"P",{});var iso=s(Z$);yKo=r(iso,"This class cannot be instantiated directly using "),iTe=n(iso,"CODE",{});var WVt=s(iTe);xKo=r(WVt,"__init__()"),WVt.forEach(t),$Ko=r(iso," (throws an error)."),iso.forEach(t),kKo=i(jl),wt=n(jl,"DIV",{class:!0});var s9=s(wt);T(K$.$$.fragment,s9),SKo=i(s9),dTe=n(s9,"P",{});var UVt=s(dTe);RKo=r(UVt,"Instantiates one of the model classes of the library (with a depth estimation head) from a configuration."),UVt.forEach(t),PKo=i(s9),Od=n(s9,"P",{});var dme=s(Od);BKo=r(dme,`Note:
Loading a model from its configuration file does `),mTe=n(dme,"STRONG",{});var HVt=s(mTe);IKo=r(HVt,"not"),HVt.forEach(t),NKo=r(dme,` load the model weights. It only affects the
model\u2019s configuration. Use `),jU=n(dme,"A",{href:!0});var JVt=s(jU);qKo=r(JVt,"from_pretrained()"),JVt.forEach(t),DKo=r(dme," to load the model weights."),dme.forEach(t),jKo=i(s9),T(Wv.$$.fragment,s9),s9.forEach(t),GKo=i(jl),ro=n(jl,"DIV",{class:!0});var $a=s(ro);T(ek.$$.fragment,$a),OKo=i($a),cTe=n($a,"P",{});var YVt=s(cTe);VKo=r(YVt,"Instantiate one of the model classes of the library (with a depth estimation head) from a pretrained model."),YVt.forEach(t),XKo=i($a),dn=n($a,"P",{});var l9=s(dn);zKo=r(l9,"The model class to instantiate is selected based on the "),fTe=n(l9,"CODE",{});var ZVt=s(fTe);QKo=r(ZVt,"model_type"),ZVt.forEach(t),WKo=r(l9,` property of the config object (either
passed as an argument or loaded from `),gTe=n(l9,"CODE",{});var KVt=s(gTe);UKo=r(KVt,"pretrained_model_name_or_path"),KVt.forEach(t),HKo=r(l9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hTe=n(l9,"CODE",{});var eXt=s(hTe);JKo=r(eXt,"pretrained_model_name_or_path"),eXt.forEach(t),YKo=r(l9,":"),l9.forEach(t),ZKo=i($a),ok=n($a,"UL",{});var dso=s(ok);Uv=n(dso,"LI",{});var VXe=s(Uv);uTe=n(VXe,"STRONG",{});var oXt=s(uTe);KKo=r(oXt,"dpt"),oXt.forEach(t),eer=r(VXe," \u2014 "),GU=n(VXe,"A",{href:!0});var rXt=s(GU);oer=r(rXt,"DPTForDepthEstimation"),rXt.forEach(t),rer=r(VXe," (DPT model)"),VXe.forEach(t),ter=i(dso),Hv=n(dso,"LI",{});var XXe=s(Hv);pTe=n(XXe,"STRONG",{});var tXt=s(pTe);aer=r(tXt,"glpn"),tXt.forEach(t),ner=r(XXe," \u2014 "),OU=n(XXe,"A",{href:!0});var aXt=s(OU);ser=r(aXt,"GLPNForDepthEstimation"),aXt.forEach(t),ler=r(XXe," (GLPN model)"),XXe.forEach(t),dso.forEach(t),ier=i($a),Jv=n($a,"P",{});var zXe=s(Jv);der=r(zXe,"The model is set in evaluation mode by default using "),_Te=n(zXe,"CODE",{});var nXt=s(_Te);mer=r(nXt,"model.eval()"),nXt.forEach(t),cer=r(zXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),bTe=n(zXe,"CODE",{});var sXt=s(bTe);fer=r(sXt,"model.train()"),sXt.forEach(t),zXe.forEach(t),ger=i($a),T(Yv.$$.fragment,$a),$a.forEach(t),jl.forEach(t),zto=i(c),Vd=n(c,"H2",{class:!0});var mso=s(Vd);Zv=n(mso,"A",{id:!0,class:!0,href:!0});var lXt=s(Zv);vTe=n(lXt,"SPAN",{});var iXt=s(vTe);T(rk.$$.fragment,iXt),iXt.forEach(t),lXt.forEach(t),her=i(mso),FTe=n(mso,"SPAN",{});var dXt=s(FTe);uer=r(dXt,"AutoModelForMaskedLM"),dXt.forEach(t),mso.forEach(t),Qto=i(c),jo=n(c,"DIV",{class:!0});var Gl=s(jo);T(tk.$$.fragment,Gl),per=i(Gl),Xd=n(Gl,"P",{});var mme=s(Xd);_er=r(mme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),VU=n(mme,"A",{href:!0});var mXt=s(VU);ber=r(mXt,"from_pretrained()"),mXt.forEach(t),ver=r(mme," class method or the "),XU=n(mme,"A",{href:!0});var cXt=s(XU);Fer=r(cXt,"from_config()"),cXt.forEach(t),Ter=r(mme,` class
method.`),mme.forEach(t),Mer=i(Gl),ak=n(Gl,"P",{});var cso=s(ak);Eer=r(cso,"This class cannot be instantiated directly using "),TTe=n(cso,"CODE",{});var fXt=s(TTe);Cer=r(fXt,"__init__()"),fXt.forEach(t),wer=r(cso," (throws an error)."),cso.forEach(t),Aer=i(Gl),At=n(Gl,"DIV",{class:!0});var i9=s(At);T(nk.$$.fragment,i9),Ler=i(i9),MTe=n(i9,"P",{});var gXt=s(MTe);yer=r(gXt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),gXt.forEach(t),xer=i(i9),zd=n(i9,"P",{});var cme=s(zd);$er=r(cme,`Note:
Loading a model from its configuration file does `),ETe=n(cme,"STRONG",{});var hXt=s(ETe);ker=r(hXt,"not"),hXt.forEach(t),Ser=r(cme,` load the model weights. It only affects the
model\u2019s configuration. Use `),zU=n(cme,"A",{href:!0});var uXt=s(zU);Rer=r(uXt,"from_pretrained()"),uXt.forEach(t),Per=r(cme," to load the model weights."),cme.forEach(t),Ber=i(i9),T(Kv.$$.fragment,i9),i9.forEach(t),Ier=i(Gl),to=n(Gl,"DIV",{class:!0});var ka=s(to);T(sk.$$.fragment,ka),Ner=i(ka),CTe=n(ka,"P",{});var pXt=s(CTe);qer=r(pXt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),pXt.forEach(t),Der=i(ka),mn=n(ka,"P",{});var d9=s(mn);jer=r(d9,"The model class to instantiate is selected based on the "),wTe=n(d9,"CODE",{});var _Xt=s(wTe);Ger=r(_Xt,"model_type"),_Xt.forEach(t),Oer=r(d9,` property of the config object (either
passed as an argument or loaded from `),ATe=n(d9,"CODE",{});var bXt=s(ATe);Ver=r(bXt,"pretrained_model_name_or_path"),bXt.forEach(t),Xer=r(d9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),LTe=n(d9,"CODE",{});var vXt=s(LTe);zer=r(vXt,"pretrained_model_name_or_path"),vXt.forEach(t),Qer=r(d9,":"),d9.forEach(t),Wer=i(ka),Y=n(ka,"UL",{});var Z=s(Y);eF=n(Z,"LI",{});var QXe=s(eF);yTe=n(QXe,"STRONG",{});var FXt=s(yTe);Uer=r(FXt,"albert"),FXt.forEach(t),Her=r(QXe," \u2014 "),QU=n(QXe,"A",{href:!0});var TXt=s(QU);Jer=r(TXt,"AlbertForMaskedLM"),TXt.forEach(t),Yer=r(QXe," (ALBERT model)"),QXe.forEach(t),Zer=i(Z),oF=n(Z,"LI",{});var WXe=s(oF);xTe=n(WXe,"STRONG",{});var MXt=s(xTe);Ker=r(MXt,"bart"),MXt.forEach(t),eor=r(WXe," \u2014 "),WU=n(WXe,"A",{href:!0});var EXt=s(WU);oor=r(EXt,"BartForConditionalGeneration"),EXt.forEach(t),ror=r(WXe," (BART model)"),WXe.forEach(t),tor=i(Z),rF=n(Z,"LI",{});var UXe=s(rF);$Te=n(UXe,"STRONG",{});var CXt=s($Te);aor=r(CXt,"bert"),CXt.forEach(t),nor=r(UXe," \u2014 "),UU=n(UXe,"A",{href:!0});var wXt=s(UU);sor=r(wXt,"BertForMaskedLM"),wXt.forEach(t),lor=r(UXe," (BERT model)"),UXe.forEach(t),ior=i(Z),tF=n(Z,"LI",{});var HXe=s(tF);kTe=n(HXe,"STRONG",{});var AXt=s(kTe);dor=r(AXt,"big_bird"),AXt.forEach(t),mor=r(HXe," \u2014 "),HU=n(HXe,"A",{href:!0});var LXt=s(HU);cor=r(LXt,"BigBirdForMaskedLM"),LXt.forEach(t),gor=r(HXe," (BigBird model)"),HXe.forEach(t),hor=i(Z),aF=n(Z,"LI",{});var JXe=s(aF);STe=n(JXe,"STRONG",{});var yXt=s(STe);uor=r(yXt,"camembert"),yXt.forEach(t),por=r(JXe," \u2014 "),JU=n(JXe,"A",{href:!0});var xXt=s(JU);_or=r(xXt,"CamembertForMaskedLM"),xXt.forEach(t),bor=r(JXe," (CamemBERT model)"),JXe.forEach(t),vor=i(Z),nF=n(Z,"LI",{});var YXe=s(nF);RTe=n(YXe,"STRONG",{});var $Xt=s(RTe);For=r($Xt,"convbert"),$Xt.forEach(t),Tor=r(YXe," \u2014 "),YU=n(YXe,"A",{href:!0});var kXt=s(YU);Mor=r(kXt,"ConvBertForMaskedLM"),kXt.forEach(t),Eor=r(YXe," (ConvBERT model)"),YXe.forEach(t),Cor=i(Z),sF=n(Z,"LI",{});var ZXe=s(sF);PTe=n(ZXe,"STRONG",{});var SXt=s(PTe);wor=r(SXt,"data2vec-text"),SXt.forEach(t),Aor=r(ZXe," \u2014 "),ZU=n(ZXe,"A",{href:!0});var RXt=s(ZU);Lor=r(RXt,"Data2VecTextForMaskedLM"),RXt.forEach(t),yor=r(ZXe," (Data2VecText model)"),ZXe.forEach(t),xor=i(Z),lF=n(Z,"LI",{});var KXe=s(lF);BTe=n(KXe,"STRONG",{});var PXt=s(BTe);$or=r(PXt,"deberta"),PXt.forEach(t),kor=r(KXe," \u2014 "),KU=n(KXe,"A",{href:!0});var BXt=s(KU);Sor=r(BXt,"DebertaForMaskedLM"),BXt.forEach(t),Ror=r(KXe," (DeBERTa model)"),KXe.forEach(t),Por=i(Z),iF=n(Z,"LI",{});var eze=s(iF);ITe=n(eze,"STRONG",{});var IXt=s(ITe);Bor=r(IXt,"deberta-v2"),IXt.forEach(t),Ior=r(eze," \u2014 "),eH=n(eze,"A",{href:!0});var NXt=s(eH);Nor=r(NXt,"DebertaV2ForMaskedLM"),NXt.forEach(t),qor=r(eze," (DeBERTa-v2 model)"),eze.forEach(t),Dor=i(Z),dF=n(Z,"LI",{});var oze=s(dF);NTe=n(oze,"STRONG",{});var qXt=s(NTe);jor=r(qXt,"distilbert"),qXt.forEach(t),Gor=r(oze," \u2014 "),oH=n(oze,"A",{href:!0});var DXt=s(oH);Oor=r(DXt,"DistilBertForMaskedLM"),DXt.forEach(t),Vor=r(oze," (DistilBERT model)"),oze.forEach(t),Xor=i(Z),mF=n(Z,"LI",{});var rze=s(mF);qTe=n(rze,"STRONG",{});var jXt=s(qTe);zor=r(jXt,"electra"),jXt.forEach(t),Qor=r(rze," \u2014 "),rH=n(rze,"A",{href:!0});var GXt=s(rH);Wor=r(GXt,"ElectraForMaskedLM"),GXt.forEach(t),Uor=r(rze," (ELECTRA model)"),rze.forEach(t),Hor=i(Z),cF=n(Z,"LI",{});var tze=s(cF);DTe=n(tze,"STRONG",{});var OXt=s(DTe);Jor=r(OXt,"ernie"),OXt.forEach(t),Yor=r(tze," \u2014 "),tH=n(tze,"A",{href:!0});var VXt=s(tH);Zor=r(VXt,"ErnieForMaskedLM"),VXt.forEach(t),Kor=r(tze," (ERNIE model)"),tze.forEach(t),err=i(Z),fF=n(Z,"LI",{});var aze=s(fF);jTe=n(aze,"STRONG",{});var XXt=s(jTe);orr=r(XXt,"flaubert"),XXt.forEach(t),rrr=r(aze," \u2014 "),aH=n(aze,"A",{href:!0});var zXt=s(aH);trr=r(zXt,"FlaubertWithLMHeadModel"),zXt.forEach(t),arr=r(aze," (FlauBERT model)"),aze.forEach(t),nrr=i(Z),gF=n(Z,"LI",{});var nze=s(gF);GTe=n(nze,"STRONG",{});var QXt=s(GTe);srr=r(QXt,"fnet"),QXt.forEach(t),lrr=r(nze," \u2014 "),nH=n(nze,"A",{href:!0});var WXt=s(nH);irr=r(WXt,"FNetForMaskedLM"),WXt.forEach(t),drr=r(nze," (FNet model)"),nze.forEach(t),mrr=i(Z),hF=n(Z,"LI",{});var sze=s(hF);OTe=n(sze,"STRONG",{});var UXt=s(OTe);crr=r(UXt,"funnel"),UXt.forEach(t),frr=r(sze," \u2014 "),sH=n(sze,"A",{href:!0});var HXt=s(sH);grr=r(HXt,"FunnelForMaskedLM"),HXt.forEach(t),hrr=r(sze," (Funnel Transformer model)"),sze.forEach(t),urr=i(Z),uF=n(Z,"LI",{});var lze=s(uF);VTe=n(lze,"STRONG",{});var JXt=s(VTe);prr=r(JXt,"ibert"),JXt.forEach(t),_rr=r(lze," \u2014 "),lH=n(lze,"A",{href:!0});var YXt=s(lH);brr=r(YXt,"IBertForMaskedLM"),YXt.forEach(t),vrr=r(lze," (I-BERT model)"),lze.forEach(t),Frr=i(Z),pF=n(Z,"LI",{});var ize=s(pF);XTe=n(ize,"STRONG",{});var ZXt=s(XTe);Trr=r(ZXt,"layoutlm"),ZXt.forEach(t),Mrr=r(ize," \u2014 "),iH=n(ize,"A",{href:!0});var KXt=s(iH);Err=r(KXt,"LayoutLMForMaskedLM"),KXt.forEach(t),Crr=r(ize," (LayoutLM model)"),ize.forEach(t),wrr=i(Z),_F=n(Z,"LI",{});var dze=s(_F);zTe=n(dze,"STRONG",{});var ezt=s(zTe);Arr=r(ezt,"longformer"),ezt.forEach(t),Lrr=r(dze," \u2014 "),dH=n(dze,"A",{href:!0});var ozt=s(dH);yrr=r(ozt,"LongformerForMaskedLM"),ozt.forEach(t),xrr=r(dze," (Longformer model)"),dze.forEach(t),$rr=i(Z),bF=n(Z,"LI",{});var mze=s(bF);QTe=n(mze,"STRONG",{});var rzt=s(QTe);krr=r(rzt,"luke"),rzt.forEach(t),Srr=r(mze," \u2014 "),mH=n(mze,"A",{href:!0});var tzt=s(mH);Rrr=r(tzt,"LukeForMaskedLM"),tzt.forEach(t),Prr=r(mze," (LUKE model)"),mze.forEach(t),Brr=i(Z),vF=n(Z,"LI",{});var cze=s(vF);WTe=n(cze,"STRONG",{});var azt=s(WTe);Irr=r(azt,"mbart"),azt.forEach(t),Nrr=r(cze," \u2014 "),cH=n(cze,"A",{href:!0});var nzt=s(cH);qrr=r(nzt,"MBartForConditionalGeneration"),nzt.forEach(t),Drr=r(cze," (mBART model)"),cze.forEach(t),jrr=i(Z),FF=n(Z,"LI",{});var fze=s(FF);UTe=n(fze,"STRONG",{});var szt=s(UTe);Grr=r(szt,"megatron-bert"),szt.forEach(t),Orr=r(fze," \u2014 "),fH=n(fze,"A",{href:!0});var lzt=s(fH);Vrr=r(lzt,"MegatronBertForMaskedLM"),lzt.forEach(t),Xrr=r(fze," (Megatron-BERT model)"),fze.forEach(t),zrr=i(Z),TF=n(Z,"LI",{});var gze=s(TF);HTe=n(gze,"STRONG",{});var izt=s(HTe);Qrr=r(izt,"mobilebert"),izt.forEach(t),Wrr=r(gze," \u2014 "),gH=n(gze,"A",{href:!0});var dzt=s(gH);Urr=r(dzt,"MobileBertForMaskedLM"),dzt.forEach(t),Hrr=r(gze," (MobileBERT model)"),gze.forEach(t),Jrr=i(Z),MF=n(Z,"LI",{});var hze=s(MF);JTe=n(hze,"STRONG",{});var mzt=s(JTe);Yrr=r(mzt,"mpnet"),mzt.forEach(t),Zrr=r(hze," \u2014 "),hH=n(hze,"A",{href:!0});var czt=s(hH);Krr=r(czt,"MPNetForMaskedLM"),czt.forEach(t),etr=r(hze," (MPNet model)"),hze.forEach(t),otr=i(Z),EF=n(Z,"LI",{});var uze=s(EF);YTe=n(uze,"STRONG",{});var fzt=s(YTe);rtr=r(fzt,"mvp"),fzt.forEach(t),ttr=r(uze," \u2014 "),uH=n(uze,"A",{href:!0});var gzt=s(uH);atr=r(gzt,"MvpForConditionalGeneration"),gzt.forEach(t),ntr=r(uze," (MVP model)"),uze.forEach(t),str=i(Z),CF=n(Z,"LI",{});var pze=s(CF);ZTe=n(pze,"STRONG",{});var hzt=s(ZTe);ltr=r(hzt,"nezha"),hzt.forEach(t),itr=r(pze," \u2014 "),pH=n(pze,"A",{href:!0});var uzt=s(pH);dtr=r(uzt,"NezhaForMaskedLM"),uzt.forEach(t),mtr=r(pze," (Nezha model)"),pze.forEach(t),ctr=i(Z),wF=n(Z,"LI",{});var _ze=s(wF);KTe=n(_ze,"STRONG",{});var pzt=s(KTe);ftr=r(pzt,"nystromformer"),pzt.forEach(t),gtr=r(_ze," \u2014 "),_H=n(_ze,"A",{href:!0});var _zt=s(_H);htr=r(_zt,"NystromformerForMaskedLM"),_zt.forEach(t),utr=r(_ze," (Nystr\xF6mformer model)"),_ze.forEach(t),ptr=i(Z),AF=n(Z,"LI",{});var bze=s(AF);eMe=n(bze,"STRONG",{});var bzt=s(eMe);_tr=r(bzt,"perceiver"),bzt.forEach(t),btr=r(bze," \u2014 "),bH=n(bze,"A",{href:!0});var vzt=s(bH);vtr=r(vzt,"PerceiverForMaskedLM"),vzt.forEach(t),Ftr=r(bze," (Perceiver model)"),bze.forEach(t),Ttr=i(Z),LF=n(Z,"LI",{});var vze=s(LF);oMe=n(vze,"STRONG",{});var Fzt=s(oMe);Mtr=r(Fzt,"qdqbert"),Fzt.forEach(t),Etr=r(vze," \u2014 "),vH=n(vze,"A",{href:!0});var Tzt=s(vH);Ctr=r(Tzt,"QDQBertForMaskedLM"),Tzt.forEach(t),wtr=r(vze," (QDQBert model)"),vze.forEach(t),Atr=i(Z),yF=n(Z,"LI",{});var Fze=s(yF);rMe=n(Fze,"STRONG",{});var Mzt=s(rMe);Ltr=r(Mzt,"reformer"),Mzt.forEach(t),ytr=r(Fze," \u2014 "),FH=n(Fze,"A",{href:!0});var Ezt=s(FH);xtr=r(Ezt,"ReformerForMaskedLM"),Ezt.forEach(t),$tr=r(Fze," (Reformer model)"),Fze.forEach(t),ktr=i(Z),xF=n(Z,"LI",{});var Tze=s(xF);tMe=n(Tze,"STRONG",{});var Czt=s(tMe);Str=r(Czt,"rembert"),Czt.forEach(t),Rtr=r(Tze," \u2014 "),TH=n(Tze,"A",{href:!0});var wzt=s(TH);Ptr=r(wzt,"RemBertForMaskedLM"),wzt.forEach(t),Btr=r(Tze," (RemBERT model)"),Tze.forEach(t),Itr=i(Z),$F=n(Z,"LI",{});var Mze=s($F);aMe=n(Mze,"STRONG",{});var Azt=s(aMe);Ntr=r(Azt,"roberta"),Azt.forEach(t),qtr=r(Mze," \u2014 "),MH=n(Mze,"A",{href:!0});var Lzt=s(MH);Dtr=r(Lzt,"RobertaForMaskedLM"),Lzt.forEach(t),jtr=r(Mze," (RoBERTa model)"),Mze.forEach(t),Gtr=i(Z),kF=n(Z,"LI",{});var Eze=s(kF);nMe=n(Eze,"STRONG",{});var yzt=s(nMe);Otr=r(yzt,"roformer"),yzt.forEach(t),Vtr=r(Eze," \u2014 "),EH=n(Eze,"A",{href:!0});var xzt=s(EH);Xtr=r(xzt,"RoFormerForMaskedLM"),xzt.forEach(t),ztr=r(Eze," (RoFormer model)"),Eze.forEach(t),Qtr=i(Z),SF=n(Z,"LI",{});var Cze=s(SF);sMe=n(Cze,"STRONG",{});var $zt=s(sMe);Wtr=r($zt,"squeezebert"),$zt.forEach(t),Utr=r(Cze," \u2014 "),CH=n(Cze,"A",{href:!0});var kzt=s(CH);Htr=r(kzt,"SqueezeBertForMaskedLM"),kzt.forEach(t),Jtr=r(Cze," (SqueezeBERT model)"),Cze.forEach(t),Ytr=i(Z),RF=n(Z,"LI",{});var wze=s(RF);lMe=n(wze,"STRONG",{});var Szt=s(lMe);Ztr=r(Szt,"tapas"),Szt.forEach(t),Ktr=r(wze," \u2014 "),wH=n(wze,"A",{href:!0});var Rzt=s(wH);ear=r(Rzt,"TapasForMaskedLM"),Rzt.forEach(t),oar=r(wze," (TAPAS model)"),wze.forEach(t),rar=i(Z),PF=n(Z,"LI",{});var Aze=s(PF);iMe=n(Aze,"STRONG",{});var Pzt=s(iMe);tar=r(Pzt,"wav2vec2"),Pzt.forEach(t),aar=r(Aze," \u2014 "),dMe=n(Aze,"CODE",{});var Bzt=s(dMe);nar=r(Bzt,"Wav2Vec2ForMaskedLM"),Bzt.forEach(t),sar=r(Aze," (Wav2Vec2 model)"),Aze.forEach(t),lar=i(Z),BF=n(Z,"LI",{});var Lze=s(BF);mMe=n(Lze,"STRONG",{});var Izt=s(mMe);iar=r(Izt,"xlm"),Izt.forEach(t),dar=r(Lze," \u2014 "),AH=n(Lze,"A",{href:!0});var Nzt=s(AH);mar=r(Nzt,"XLMWithLMHeadModel"),Nzt.forEach(t),car=r(Lze," (XLM model)"),Lze.forEach(t),far=i(Z),IF=n(Z,"LI",{});var yze=s(IF);cMe=n(yze,"STRONG",{});var qzt=s(cMe);gar=r(qzt,"xlm-roberta"),qzt.forEach(t),har=r(yze," \u2014 "),LH=n(yze,"A",{href:!0});var Dzt=s(LH);uar=r(Dzt,"XLMRobertaForMaskedLM"),Dzt.forEach(t),par=r(yze," (XLM-RoBERTa model)"),yze.forEach(t),_ar=i(Z),NF=n(Z,"LI",{});var xze=s(NF);fMe=n(xze,"STRONG",{});var jzt=s(fMe);bar=r(jzt,"xlm-roberta-xl"),jzt.forEach(t),Far=r(xze," \u2014 "),yH=n(xze,"A",{href:!0});var Gzt=s(yH);Tar=r(Gzt,"XLMRobertaXLForMaskedLM"),Gzt.forEach(t),Mar=r(xze," (XLM-RoBERTa-XL model)"),xze.forEach(t),Ear=i(Z),qF=n(Z,"LI",{});var $ze=s(qF);gMe=n($ze,"STRONG",{});var Ozt=s(gMe);Car=r(Ozt,"yoso"),Ozt.forEach(t),war=r($ze," \u2014 "),xH=n($ze,"A",{href:!0});var Vzt=s(xH);Aar=r(Vzt,"YosoForMaskedLM"),Vzt.forEach(t),Lar=r($ze," (YOSO model)"),$ze.forEach(t),Z.forEach(t),yar=i(ka),DF=n(ka,"P",{});var kze=s(DF);xar=r(kze,"The model is set in evaluation mode by default using "),hMe=n(kze,"CODE",{});var Xzt=s(hMe);$ar=r(Xzt,"model.eval()"),Xzt.forEach(t),kar=r(kze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),uMe=n(kze,"CODE",{});var zzt=s(uMe);Sar=r(zzt,"model.train()"),zzt.forEach(t),kze.forEach(t),Rar=i(ka),T(jF.$$.fragment,ka),ka.forEach(t),Gl.forEach(t),Wto=i(c),Qd=n(c,"H2",{class:!0});var fso=s(Qd);GF=n(fso,"A",{id:!0,class:!0,href:!0});var Qzt=s(GF);pMe=n(Qzt,"SPAN",{});var Wzt=s(pMe);T(lk.$$.fragment,Wzt),Wzt.forEach(t),Qzt.forEach(t),Par=i(fso),_Me=n(fso,"SPAN",{});var Uzt=s(_Me);Bar=r(Uzt,"AutoModelForSeq2SeqLM"),Uzt.forEach(t),fso.forEach(t),Uto=i(c),Go=n(c,"DIV",{class:!0});var Ol=s(Go);T(ik.$$.fragment,Ol),Iar=i(Ol),Wd=n(Ol,"P",{});var fme=s(Wd);Nar=r(fme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),$H=n(fme,"A",{href:!0});var Hzt=s($H);qar=r(Hzt,"from_pretrained()"),Hzt.forEach(t),Dar=r(fme," class method or the "),kH=n(fme,"A",{href:!0});var Jzt=s(kH);jar=r(Jzt,"from_config()"),Jzt.forEach(t),Gar=r(fme,` class
method.`),fme.forEach(t),Oar=i(Ol),dk=n(Ol,"P",{});var gso=s(dk);Var=r(gso,"This class cannot be instantiated directly using "),bMe=n(gso,"CODE",{});var Yzt=s(bMe);Xar=r(Yzt,"__init__()"),Yzt.forEach(t),zar=r(gso," (throws an error)."),gso.forEach(t),Qar=i(Ol),Lt=n(Ol,"DIV",{class:!0});var m9=s(Lt);T(mk.$$.fragment,m9),War=i(m9),vMe=n(m9,"P",{});var Zzt=s(vMe);Uar=r(Zzt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Zzt.forEach(t),Har=i(m9),Ud=n(m9,"P",{});var gme=s(Ud);Jar=r(gme,`Note:
Loading a model from its configuration file does `),FMe=n(gme,"STRONG",{});var Kzt=s(FMe);Yar=r(Kzt,"not"),Kzt.forEach(t),Zar=r(gme,` load the model weights. It only affects the
model\u2019s configuration. Use `),SH=n(gme,"A",{href:!0});var eQt=s(SH);Kar=r(eQt,"from_pretrained()"),eQt.forEach(t),enr=r(gme," to load the model weights."),gme.forEach(t),onr=i(m9),T(OF.$$.fragment,m9),m9.forEach(t),rnr=i(Ol),ao=n(Ol,"DIV",{class:!0});var Sa=s(ao);T(ck.$$.fragment,Sa),tnr=i(Sa),TMe=n(Sa,"P",{});var oQt=s(TMe);anr=r(oQt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),oQt.forEach(t),nnr=i(Sa),cn=n(Sa,"P",{});var c9=s(cn);snr=r(c9,"The model class to instantiate is selected based on the "),MMe=n(c9,"CODE",{});var rQt=s(MMe);lnr=r(rQt,"model_type"),rQt.forEach(t),inr=r(c9,` property of the config object (either
passed as an argument or loaded from `),EMe=n(c9,"CODE",{});var tQt=s(EMe);dnr=r(tQt,"pretrained_model_name_or_path"),tQt.forEach(t),mnr=r(c9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),CMe=n(c9,"CODE",{});var aQt=s(CMe);cnr=r(aQt,"pretrained_model_name_or_path"),aQt.forEach(t),fnr=r(c9,":"),c9.forEach(t),gnr=i(Sa),he=n(Sa,"UL",{});var _e=s(he);VF=n(_e,"LI",{});var Sze=s(VF);wMe=n(Sze,"STRONG",{});var nQt=s(wMe);hnr=r(nQt,"bart"),nQt.forEach(t),unr=r(Sze," \u2014 "),RH=n(Sze,"A",{href:!0});var sQt=s(RH);pnr=r(sQt,"BartForConditionalGeneration"),sQt.forEach(t),_nr=r(Sze," (BART model)"),Sze.forEach(t),bnr=i(_e),XF=n(_e,"LI",{});var Rze=s(XF);AMe=n(Rze,"STRONG",{});var lQt=s(AMe);vnr=r(lQt,"bigbird_pegasus"),lQt.forEach(t),Fnr=r(Rze," \u2014 "),PH=n(Rze,"A",{href:!0});var iQt=s(PH);Tnr=r(iQt,"BigBirdPegasusForConditionalGeneration"),iQt.forEach(t),Mnr=r(Rze," (BigBird-Pegasus model)"),Rze.forEach(t),Enr=i(_e),zF=n(_e,"LI",{});var Pze=s(zF);LMe=n(Pze,"STRONG",{});var dQt=s(LMe);Cnr=r(dQt,"blenderbot"),dQt.forEach(t),wnr=r(Pze," \u2014 "),BH=n(Pze,"A",{href:!0});var mQt=s(BH);Anr=r(mQt,"BlenderbotForConditionalGeneration"),mQt.forEach(t),Lnr=r(Pze," (Blenderbot model)"),Pze.forEach(t),ynr=i(_e),QF=n(_e,"LI",{});var Bze=s(QF);yMe=n(Bze,"STRONG",{});var cQt=s(yMe);xnr=r(cQt,"blenderbot-small"),cQt.forEach(t),$nr=r(Bze," \u2014 "),IH=n(Bze,"A",{href:!0});var fQt=s(IH);knr=r(fQt,"BlenderbotSmallForConditionalGeneration"),fQt.forEach(t),Snr=r(Bze," (BlenderbotSmall model)"),Bze.forEach(t),Rnr=i(_e),WF=n(_e,"LI",{});var Ize=s(WF);xMe=n(Ize,"STRONG",{});var gQt=s(xMe);Pnr=r(gQt,"encoder-decoder"),gQt.forEach(t),Bnr=r(Ize," \u2014 "),NH=n(Ize,"A",{href:!0});var hQt=s(NH);Inr=r(hQt,"EncoderDecoderModel"),hQt.forEach(t),Nnr=r(Ize," (Encoder decoder model)"),Ize.forEach(t),qnr=i(_e),UF=n(_e,"LI",{});var Nze=s(UF);$Me=n(Nze,"STRONG",{});var uQt=s($Me);Dnr=r(uQt,"fsmt"),uQt.forEach(t),jnr=r(Nze," \u2014 "),qH=n(Nze,"A",{href:!0});var pQt=s(qH);Gnr=r(pQt,"FSMTForConditionalGeneration"),pQt.forEach(t),Onr=r(Nze," (FairSeq Machine-Translation model)"),Nze.forEach(t),Vnr=i(_e),HF=n(_e,"LI",{});var qze=s(HF);kMe=n(qze,"STRONG",{});var _Qt=s(kMe);Xnr=r(_Qt,"led"),_Qt.forEach(t),znr=r(qze," \u2014 "),DH=n(qze,"A",{href:!0});var bQt=s(DH);Qnr=r(bQt,"LEDForConditionalGeneration"),bQt.forEach(t),Wnr=r(qze," (LED model)"),qze.forEach(t),Unr=i(_e),JF=n(_e,"LI",{});var Dze=s(JF);SMe=n(Dze,"STRONG",{});var vQt=s(SMe);Hnr=r(vQt,"longt5"),vQt.forEach(t),Jnr=r(Dze," \u2014 "),jH=n(Dze,"A",{href:!0});var FQt=s(jH);Ynr=r(FQt,"LongT5ForConditionalGeneration"),FQt.forEach(t),Znr=r(Dze," (LongT5 model)"),Dze.forEach(t),Knr=i(_e),YF=n(_e,"LI",{});var jze=s(YF);RMe=n(jze,"STRONG",{});var TQt=s(RMe);esr=r(TQt,"m2m_100"),TQt.forEach(t),osr=r(jze," \u2014 "),GH=n(jze,"A",{href:!0});var MQt=s(GH);rsr=r(MQt,"M2M100ForConditionalGeneration"),MQt.forEach(t),tsr=r(jze," (M2M100 model)"),jze.forEach(t),asr=i(_e),ZF=n(_e,"LI",{});var Gze=s(ZF);PMe=n(Gze,"STRONG",{});var EQt=s(PMe);nsr=r(EQt,"marian"),EQt.forEach(t),ssr=r(Gze," \u2014 "),OH=n(Gze,"A",{href:!0});var CQt=s(OH);lsr=r(CQt,"MarianMTModel"),CQt.forEach(t),isr=r(Gze," (Marian model)"),Gze.forEach(t),dsr=i(_e),KF=n(_e,"LI",{});var Oze=s(KF);BMe=n(Oze,"STRONG",{});var wQt=s(BMe);msr=r(wQt,"mbart"),wQt.forEach(t),csr=r(Oze," \u2014 "),VH=n(Oze,"A",{href:!0});var AQt=s(VH);fsr=r(AQt,"MBartForConditionalGeneration"),AQt.forEach(t),gsr=r(Oze," (mBART model)"),Oze.forEach(t),hsr=i(_e),eT=n(_e,"LI",{});var Vze=s(eT);IMe=n(Vze,"STRONG",{});var LQt=s(IMe);usr=r(LQt,"mt5"),LQt.forEach(t),psr=r(Vze," \u2014 "),XH=n(Vze,"A",{href:!0});var yQt=s(XH);_sr=r(yQt,"MT5ForConditionalGeneration"),yQt.forEach(t),bsr=r(Vze," (MT5 model)"),Vze.forEach(t),vsr=i(_e),oT=n(_e,"LI",{});var Xze=s(oT);NMe=n(Xze,"STRONG",{});var xQt=s(NMe);Fsr=r(xQt,"mvp"),xQt.forEach(t),Tsr=r(Xze," \u2014 "),zH=n(Xze,"A",{href:!0});var $Qt=s(zH);Msr=r($Qt,"MvpForConditionalGeneration"),$Qt.forEach(t),Esr=r(Xze," (MVP model)"),Xze.forEach(t),Csr=i(_e),rT=n(_e,"LI",{});var zze=s(rT);qMe=n(zze,"STRONG",{});var kQt=s(qMe);wsr=r(kQt,"nllb"),kQt.forEach(t),Asr=r(zze," \u2014 "),QH=n(zze,"A",{href:!0});var SQt=s(QH);Lsr=r(SQt,"M2M100ForConditionalGeneration"),SQt.forEach(t),ysr=r(zze," (NLLB model)"),zze.forEach(t),xsr=i(_e),tT=n(_e,"LI",{});var Qze=s(tT);DMe=n(Qze,"STRONG",{});var RQt=s(DMe);$sr=r(RQt,"pegasus"),RQt.forEach(t),ksr=r(Qze," \u2014 "),WH=n(Qze,"A",{href:!0});var PQt=s(WH);Ssr=r(PQt,"PegasusForConditionalGeneration"),PQt.forEach(t),Rsr=r(Qze," (Pegasus model)"),Qze.forEach(t),Psr=i(_e),aT=n(_e,"LI",{});var Wze=s(aT);jMe=n(Wze,"STRONG",{});var BQt=s(jMe);Bsr=r(BQt,"pegasus_x"),BQt.forEach(t),Isr=r(Wze," \u2014 "),UH=n(Wze,"A",{href:!0});var IQt=s(UH);Nsr=r(IQt,"PegasusXForConditionalGeneration"),IQt.forEach(t),qsr=r(Wze," (PEGASUS-X model)"),Wze.forEach(t),Dsr=i(_e),nT=n(_e,"LI",{});var Uze=s(nT);GMe=n(Uze,"STRONG",{});var NQt=s(GMe);jsr=r(NQt,"plbart"),NQt.forEach(t),Gsr=r(Uze," \u2014 "),HH=n(Uze,"A",{href:!0});var qQt=s(HH);Osr=r(qQt,"PLBartForConditionalGeneration"),qQt.forEach(t),Vsr=r(Uze," (PLBart model)"),Uze.forEach(t),Xsr=i(_e),sT=n(_e,"LI",{});var Hze=s(sT);OMe=n(Hze,"STRONG",{});var DQt=s(OMe);zsr=r(DQt,"prophetnet"),DQt.forEach(t),Qsr=r(Hze," \u2014 "),JH=n(Hze,"A",{href:!0});var jQt=s(JH);Wsr=r(jQt,"ProphetNetForConditionalGeneration"),jQt.forEach(t),Usr=r(Hze," (ProphetNet model)"),Hze.forEach(t),Hsr=i(_e),lT=n(_e,"LI",{});var Jze=s(lT);VMe=n(Jze,"STRONG",{});var GQt=s(VMe);Jsr=r(GQt,"t5"),GQt.forEach(t),Ysr=r(Jze," \u2014 "),YH=n(Jze,"A",{href:!0});var OQt=s(YH);Zsr=r(OQt,"T5ForConditionalGeneration"),OQt.forEach(t),Ksr=r(Jze," (T5 model)"),Jze.forEach(t),elr=i(_e),iT=n(_e,"LI",{});var Yze=s(iT);XMe=n(Yze,"STRONG",{});var VQt=s(XMe);olr=r(VQt,"xlm-prophetnet"),VQt.forEach(t),rlr=r(Yze," \u2014 "),ZH=n(Yze,"A",{href:!0});var XQt=s(ZH);tlr=r(XQt,"XLMProphetNetForConditionalGeneration"),XQt.forEach(t),alr=r(Yze," (XLM-ProphetNet model)"),Yze.forEach(t),_e.forEach(t),nlr=i(Sa),dT=n(Sa,"P",{});var Zze=s(dT);slr=r(Zze,"The model is set in evaluation mode by default using "),zMe=n(Zze,"CODE",{});var zQt=s(zMe);llr=r(zQt,"model.eval()"),zQt.forEach(t),ilr=r(Zze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),QMe=n(Zze,"CODE",{});var QQt=s(QMe);dlr=r(QQt,"model.train()"),QQt.forEach(t),Zze.forEach(t),mlr=i(Sa),T(mT.$$.fragment,Sa),Sa.forEach(t),Ol.forEach(t),Hto=i(c),Hd=n(c,"H2",{class:!0});var hso=s(Hd);cT=n(hso,"A",{id:!0,class:!0,href:!0});var WQt=s(cT);WMe=n(WQt,"SPAN",{});var UQt=s(WMe);T(fk.$$.fragment,UQt),UQt.forEach(t),WQt.forEach(t),clr=i(hso),UMe=n(hso,"SPAN",{});var HQt=s(UMe);flr=r(HQt,"AutoModelForSequenceClassification"),HQt.forEach(t),hso.forEach(t),Jto=i(c),Oo=n(c,"DIV",{class:!0});var Vl=s(Oo);T(gk.$$.fragment,Vl),glr=i(Vl),Jd=n(Vl,"P",{});var hme=s(Jd);hlr=r(hme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),KH=n(hme,"A",{href:!0});var JQt=s(KH);ulr=r(JQt,"from_pretrained()"),JQt.forEach(t),plr=r(hme," class method or the "),eJ=n(hme,"A",{href:!0});var YQt=s(eJ);_lr=r(YQt,"from_config()"),YQt.forEach(t),blr=r(hme,` class
method.`),hme.forEach(t),vlr=i(Vl),hk=n(Vl,"P",{});var uso=s(hk);Flr=r(uso,"This class cannot be instantiated directly using "),HMe=n(uso,"CODE",{});var ZQt=s(HMe);Tlr=r(ZQt,"__init__()"),ZQt.forEach(t),Mlr=r(uso," (throws an error)."),uso.forEach(t),Elr=i(Vl),yt=n(Vl,"DIV",{class:!0});var f9=s(yt);T(uk.$$.fragment,f9),Clr=i(f9),JMe=n(f9,"P",{});var KQt=s(JMe);wlr=r(KQt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),KQt.forEach(t),Alr=i(f9),Yd=n(f9,"P",{});var ume=s(Yd);Llr=r(ume,`Note:
Loading a model from its configuration file does `),YMe=n(ume,"STRONG",{});var eWt=s(YMe);ylr=r(eWt,"not"),eWt.forEach(t),xlr=r(ume,` load the model weights. It only affects the
model\u2019s configuration. Use `),oJ=n(ume,"A",{href:!0});var oWt=s(oJ);$lr=r(oWt,"from_pretrained()"),oWt.forEach(t),klr=r(ume," to load the model weights."),ume.forEach(t),Slr=i(f9),T(fT.$$.fragment,f9),f9.forEach(t),Rlr=i(Vl),no=n(Vl,"DIV",{class:!0});var Ra=s(no);T(pk.$$.fragment,Ra),Plr=i(Ra),ZMe=n(Ra,"P",{});var rWt=s(ZMe);Blr=r(rWt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),rWt.forEach(t),Ilr=i(Ra),fn=n(Ra,"P",{});var g9=s(fn);Nlr=r(g9,"The model class to instantiate is selected based on the "),KMe=n(g9,"CODE",{});var tWt=s(KMe);qlr=r(tWt,"model_type"),tWt.forEach(t),Dlr=r(g9,` property of the config object (either
passed as an argument or loaded from `),eEe=n(g9,"CODE",{});var aWt=s(eEe);jlr=r(aWt,"pretrained_model_name_or_path"),aWt.forEach(t),Glr=r(g9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oEe=n(g9,"CODE",{});var nWt=s(oEe);Olr=r(nWt,"pretrained_model_name_or_path"),nWt.forEach(t),Vlr=r(g9,":"),g9.forEach(t),Xlr=i(Ra),D=n(Ra,"UL",{});var j=s(D);gT=n(j,"LI",{});var Kze=s(gT);rEe=n(Kze,"STRONG",{});var sWt=s(rEe);zlr=r(sWt,"albert"),sWt.forEach(t),Qlr=r(Kze," \u2014 "),rJ=n(Kze,"A",{href:!0});var lWt=s(rJ);Wlr=r(lWt,"AlbertForSequenceClassification"),lWt.forEach(t),Ulr=r(Kze," (ALBERT model)"),Kze.forEach(t),Hlr=i(j),hT=n(j,"LI",{});var eQe=s(hT);tEe=n(eQe,"STRONG",{});var iWt=s(tEe);Jlr=r(iWt,"bart"),iWt.forEach(t),Ylr=r(eQe," \u2014 "),tJ=n(eQe,"A",{href:!0});var dWt=s(tJ);Zlr=r(dWt,"BartForSequenceClassification"),dWt.forEach(t),Klr=r(eQe," (BART model)"),eQe.forEach(t),eir=i(j),uT=n(j,"LI",{});var oQe=s(uT);aEe=n(oQe,"STRONG",{});var mWt=s(aEe);oir=r(mWt,"bert"),mWt.forEach(t),rir=r(oQe," \u2014 "),aJ=n(oQe,"A",{href:!0});var cWt=s(aJ);tir=r(cWt,"BertForSequenceClassification"),cWt.forEach(t),air=r(oQe," (BERT model)"),oQe.forEach(t),nir=i(j),pT=n(j,"LI",{});var rQe=s(pT);nEe=n(rQe,"STRONG",{});var fWt=s(nEe);sir=r(fWt,"big_bird"),fWt.forEach(t),lir=r(rQe," \u2014 "),nJ=n(rQe,"A",{href:!0});var gWt=s(nJ);iir=r(gWt,"BigBirdForSequenceClassification"),gWt.forEach(t),dir=r(rQe," (BigBird model)"),rQe.forEach(t),mir=i(j),_T=n(j,"LI",{});var tQe=s(_T);sEe=n(tQe,"STRONG",{});var hWt=s(sEe);cir=r(hWt,"bigbird_pegasus"),hWt.forEach(t),fir=r(tQe," \u2014 "),sJ=n(tQe,"A",{href:!0});var uWt=s(sJ);gir=r(uWt,"BigBirdPegasusForSequenceClassification"),uWt.forEach(t),hir=r(tQe," (BigBird-Pegasus model)"),tQe.forEach(t),uir=i(j),bT=n(j,"LI",{});var aQe=s(bT);lEe=n(aQe,"STRONG",{});var pWt=s(lEe);pir=r(pWt,"bloom"),pWt.forEach(t),_ir=r(aQe," \u2014 "),lJ=n(aQe,"A",{href:!0});var _Wt=s(lJ);bir=r(_Wt,"BloomForSequenceClassification"),_Wt.forEach(t),vir=r(aQe," (BLOOM model)"),aQe.forEach(t),Fir=i(j),vT=n(j,"LI",{});var nQe=s(vT);iEe=n(nQe,"STRONG",{});var bWt=s(iEe);Tir=r(bWt,"camembert"),bWt.forEach(t),Mir=r(nQe," \u2014 "),iJ=n(nQe,"A",{href:!0});var vWt=s(iJ);Eir=r(vWt,"CamembertForSequenceClassification"),vWt.forEach(t),Cir=r(nQe," (CamemBERT model)"),nQe.forEach(t),wir=i(j),FT=n(j,"LI",{});var sQe=s(FT);dEe=n(sQe,"STRONG",{});var FWt=s(dEe);Air=r(FWt,"canine"),FWt.forEach(t),Lir=r(sQe," \u2014 "),dJ=n(sQe,"A",{href:!0});var TWt=s(dJ);yir=r(TWt,"CanineForSequenceClassification"),TWt.forEach(t),xir=r(sQe," (CANINE model)"),sQe.forEach(t),$ir=i(j),TT=n(j,"LI",{});var lQe=s(TT);mEe=n(lQe,"STRONG",{});var MWt=s(mEe);kir=r(MWt,"convbert"),MWt.forEach(t),Sir=r(lQe," \u2014 "),mJ=n(lQe,"A",{href:!0});var EWt=s(mJ);Rir=r(EWt,"ConvBertForSequenceClassification"),EWt.forEach(t),Pir=r(lQe," (ConvBERT model)"),lQe.forEach(t),Bir=i(j),MT=n(j,"LI",{});var iQe=s(MT);cEe=n(iQe,"STRONG",{});var CWt=s(cEe);Iir=r(CWt,"ctrl"),CWt.forEach(t),Nir=r(iQe," \u2014 "),cJ=n(iQe,"A",{href:!0});var wWt=s(cJ);qir=r(wWt,"CTRLForSequenceClassification"),wWt.forEach(t),Dir=r(iQe," (CTRL model)"),iQe.forEach(t),jir=i(j),ET=n(j,"LI",{});var dQe=s(ET);fEe=n(dQe,"STRONG",{});var AWt=s(fEe);Gir=r(AWt,"data2vec-text"),AWt.forEach(t),Oir=r(dQe," \u2014 "),fJ=n(dQe,"A",{href:!0});var LWt=s(fJ);Vir=r(LWt,"Data2VecTextForSequenceClassification"),LWt.forEach(t),Xir=r(dQe," (Data2VecText model)"),dQe.forEach(t),zir=i(j),CT=n(j,"LI",{});var mQe=s(CT);gEe=n(mQe,"STRONG",{});var yWt=s(gEe);Qir=r(yWt,"deberta"),yWt.forEach(t),Wir=r(mQe," \u2014 "),gJ=n(mQe,"A",{href:!0});var xWt=s(gJ);Uir=r(xWt,"DebertaForSequenceClassification"),xWt.forEach(t),Hir=r(mQe," (DeBERTa model)"),mQe.forEach(t),Jir=i(j),wT=n(j,"LI",{});var cQe=s(wT);hEe=n(cQe,"STRONG",{});var $Wt=s(hEe);Yir=r($Wt,"deberta-v2"),$Wt.forEach(t),Zir=r(cQe," \u2014 "),hJ=n(cQe,"A",{href:!0});var kWt=s(hJ);Kir=r(kWt,"DebertaV2ForSequenceClassification"),kWt.forEach(t),edr=r(cQe," (DeBERTa-v2 model)"),cQe.forEach(t),odr=i(j),AT=n(j,"LI",{});var fQe=s(AT);uEe=n(fQe,"STRONG",{});var SWt=s(uEe);rdr=r(SWt,"distilbert"),SWt.forEach(t),tdr=r(fQe," \u2014 "),uJ=n(fQe,"A",{href:!0});var RWt=s(uJ);adr=r(RWt,"DistilBertForSequenceClassification"),RWt.forEach(t),ndr=r(fQe," (DistilBERT model)"),fQe.forEach(t),sdr=i(j),LT=n(j,"LI",{});var gQe=s(LT);pEe=n(gQe,"STRONG",{});var PWt=s(pEe);ldr=r(PWt,"electra"),PWt.forEach(t),idr=r(gQe," \u2014 "),pJ=n(gQe,"A",{href:!0});var BWt=s(pJ);ddr=r(BWt,"ElectraForSequenceClassification"),BWt.forEach(t),mdr=r(gQe," (ELECTRA model)"),gQe.forEach(t),cdr=i(j),yT=n(j,"LI",{});var hQe=s(yT);_Ee=n(hQe,"STRONG",{});var IWt=s(_Ee);fdr=r(IWt,"ernie"),IWt.forEach(t),gdr=r(hQe," \u2014 "),_J=n(hQe,"A",{href:!0});var NWt=s(_J);hdr=r(NWt,"ErnieForSequenceClassification"),NWt.forEach(t),udr=r(hQe," (ERNIE model)"),hQe.forEach(t),pdr=i(j),xT=n(j,"LI",{});var uQe=s(xT);bEe=n(uQe,"STRONG",{});var qWt=s(bEe);_dr=r(qWt,"esm"),qWt.forEach(t),bdr=r(uQe," \u2014 "),bJ=n(uQe,"A",{href:!0});var DWt=s(bJ);vdr=r(DWt,"EsmForSequenceClassification"),DWt.forEach(t),Fdr=r(uQe," (ESM model)"),uQe.forEach(t),Tdr=i(j),$T=n(j,"LI",{});var pQe=s($T);vEe=n(pQe,"STRONG",{});var jWt=s(vEe);Mdr=r(jWt,"flaubert"),jWt.forEach(t),Edr=r(pQe," \u2014 "),vJ=n(pQe,"A",{href:!0});var GWt=s(vJ);Cdr=r(GWt,"FlaubertForSequenceClassification"),GWt.forEach(t),wdr=r(pQe," (FlauBERT model)"),pQe.forEach(t),Adr=i(j),kT=n(j,"LI",{});var _Qe=s(kT);FEe=n(_Qe,"STRONG",{});var OWt=s(FEe);Ldr=r(OWt,"fnet"),OWt.forEach(t),ydr=r(_Qe," \u2014 "),FJ=n(_Qe,"A",{href:!0});var VWt=s(FJ);xdr=r(VWt,"FNetForSequenceClassification"),VWt.forEach(t),$dr=r(_Qe," (FNet model)"),_Qe.forEach(t),kdr=i(j),ST=n(j,"LI",{});var bQe=s(ST);TEe=n(bQe,"STRONG",{});var XWt=s(TEe);Sdr=r(XWt,"funnel"),XWt.forEach(t),Rdr=r(bQe," \u2014 "),TJ=n(bQe,"A",{href:!0});var zWt=s(TJ);Pdr=r(zWt,"FunnelForSequenceClassification"),zWt.forEach(t),Bdr=r(bQe," (Funnel Transformer model)"),bQe.forEach(t),Idr=i(j),RT=n(j,"LI",{});var vQe=s(RT);MEe=n(vQe,"STRONG",{});var QWt=s(MEe);Ndr=r(QWt,"gpt2"),QWt.forEach(t),qdr=r(vQe," \u2014 "),MJ=n(vQe,"A",{href:!0});var WWt=s(MJ);Ddr=r(WWt,"GPT2ForSequenceClassification"),WWt.forEach(t),jdr=r(vQe," (OpenAI GPT-2 model)"),vQe.forEach(t),Gdr=i(j),PT=n(j,"LI",{});var FQe=s(PT);EEe=n(FQe,"STRONG",{});var UWt=s(EEe);Odr=r(UWt,"gpt_neo"),UWt.forEach(t),Vdr=r(FQe," \u2014 "),EJ=n(FQe,"A",{href:!0});var HWt=s(EJ);Xdr=r(HWt,"GPTNeoForSequenceClassification"),HWt.forEach(t),zdr=r(FQe," (GPT Neo model)"),FQe.forEach(t),Qdr=i(j),BT=n(j,"LI",{});var TQe=s(BT);CEe=n(TQe,"STRONG",{});var JWt=s(CEe);Wdr=r(JWt,"gptj"),JWt.forEach(t),Udr=r(TQe," \u2014 "),CJ=n(TQe,"A",{href:!0});var YWt=s(CJ);Hdr=r(YWt,"GPTJForSequenceClassification"),YWt.forEach(t),Jdr=r(TQe," (GPT-J model)"),TQe.forEach(t),Ydr=i(j),IT=n(j,"LI",{});var MQe=s(IT);wEe=n(MQe,"STRONG",{});var ZWt=s(wEe);Zdr=r(ZWt,"ibert"),ZWt.forEach(t),Kdr=r(MQe," \u2014 "),wJ=n(MQe,"A",{href:!0});var KWt=s(wJ);emr=r(KWt,"IBertForSequenceClassification"),KWt.forEach(t),omr=r(MQe," (I-BERT model)"),MQe.forEach(t),rmr=i(j),NT=n(j,"LI",{});var EQe=s(NT);AEe=n(EQe,"STRONG",{});var eUt=s(AEe);tmr=r(eUt,"layoutlm"),eUt.forEach(t),amr=r(EQe," \u2014 "),AJ=n(EQe,"A",{href:!0});var oUt=s(AJ);nmr=r(oUt,"LayoutLMForSequenceClassification"),oUt.forEach(t),smr=r(EQe," (LayoutLM model)"),EQe.forEach(t),lmr=i(j),qT=n(j,"LI",{});var CQe=s(qT);LEe=n(CQe,"STRONG",{});var rUt=s(LEe);imr=r(rUt,"layoutlmv2"),rUt.forEach(t),dmr=r(CQe," \u2014 "),LJ=n(CQe,"A",{href:!0});var tUt=s(LJ);mmr=r(tUt,"LayoutLMv2ForSequenceClassification"),tUt.forEach(t),cmr=r(CQe," (LayoutLMv2 model)"),CQe.forEach(t),fmr=i(j),DT=n(j,"LI",{});var wQe=s(DT);yEe=n(wQe,"STRONG",{});var aUt=s(yEe);gmr=r(aUt,"layoutlmv3"),aUt.forEach(t),hmr=r(wQe," \u2014 "),yJ=n(wQe,"A",{href:!0});var nUt=s(yJ);umr=r(nUt,"LayoutLMv3ForSequenceClassification"),nUt.forEach(t),pmr=r(wQe," (LayoutLMv3 model)"),wQe.forEach(t),_mr=i(j),jT=n(j,"LI",{});var AQe=s(jT);xEe=n(AQe,"STRONG",{});var sUt=s(xEe);bmr=r(sUt,"led"),sUt.forEach(t),vmr=r(AQe," \u2014 "),xJ=n(AQe,"A",{href:!0});var lUt=s(xJ);Fmr=r(lUt,"LEDForSequenceClassification"),lUt.forEach(t),Tmr=r(AQe," (LED model)"),AQe.forEach(t),Mmr=i(j),GT=n(j,"LI",{});var LQe=s(GT);$Ee=n(LQe,"STRONG",{});var iUt=s($Ee);Emr=r(iUt,"lilt"),iUt.forEach(t),Cmr=r(LQe," \u2014 "),$J=n(LQe,"A",{href:!0});var dUt=s($J);wmr=r(dUt,"LiltForSequenceClassification"),dUt.forEach(t),Amr=r(LQe," (LiLT model)"),LQe.forEach(t),Lmr=i(j),OT=n(j,"LI",{});var yQe=s(OT);kEe=n(yQe,"STRONG",{});var mUt=s(kEe);ymr=r(mUt,"longformer"),mUt.forEach(t),xmr=r(yQe," \u2014 "),kJ=n(yQe,"A",{href:!0});var cUt=s(kJ);$mr=r(cUt,"LongformerForSequenceClassification"),cUt.forEach(t),kmr=r(yQe," (Longformer model)"),yQe.forEach(t),Smr=i(j),VT=n(j,"LI",{});var xQe=s(VT);SEe=n(xQe,"STRONG",{});var fUt=s(SEe);Rmr=r(fUt,"luke"),fUt.forEach(t),Pmr=r(xQe," \u2014 "),SJ=n(xQe,"A",{href:!0});var gUt=s(SJ);Bmr=r(gUt,"LukeForSequenceClassification"),gUt.forEach(t),Imr=r(xQe," (LUKE model)"),xQe.forEach(t),Nmr=i(j),XT=n(j,"LI",{});var $Qe=s(XT);REe=n($Qe,"STRONG",{});var hUt=s(REe);qmr=r(hUt,"markuplm"),hUt.forEach(t),Dmr=r($Qe," \u2014 "),RJ=n($Qe,"A",{href:!0});var uUt=s(RJ);jmr=r(uUt,"MarkupLMForSequenceClassification"),uUt.forEach(t),Gmr=r($Qe," (MarkupLM model)"),$Qe.forEach(t),Omr=i(j),zT=n(j,"LI",{});var kQe=s(zT);PEe=n(kQe,"STRONG",{});var pUt=s(PEe);Vmr=r(pUt,"mbart"),pUt.forEach(t),Xmr=r(kQe," \u2014 "),PJ=n(kQe,"A",{href:!0});var _Ut=s(PJ);zmr=r(_Ut,"MBartForSequenceClassification"),_Ut.forEach(t),Qmr=r(kQe," (mBART model)"),kQe.forEach(t),Wmr=i(j),QT=n(j,"LI",{});var SQe=s(QT);BEe=n(SQe,"STRONG",{});var bUt=s(BEe);Umr=r(bUt,"megatron-bert"),bUt.forEach(t),Hmr=r(SQe," \u2014 "),BJ=n(SQe,"A",{href:!0});var vUt=s(BJ);Jmr=r(vUt,"MegatronBertForSequenceClassification"),vUt.forEach(t),Ymr=r(SQe," (Megatron-BERT model)"),SQe.forEach(t),Zmr=i(j),WT=n(j,"LI",{});var RQe=s(WT);IEe=n(RQe,"STRONG",{});var FUt=s(IEe);Kmr=r(FUt,"mobilebert"),FUt.forEach(t),ecr=r(RQe," \u2014 "),IJ=n(RQe,"A",{href:!0});var TUt=s(IJ);ocr=r(TUt,"MobileBertForSequenceClassification"),TUt.forEach(t),rcr=r(RQe," (MobileBERT model)"),RQe.forEach(t),tcr=i(j),UT=n(j,"LI",{});var PQe=s(UT);NEe=n(PQe,"STRONG",{});var MUt=s(NEe);acr=r(MUt,"mpnet"),MUt.forEach(t),ncr=r(PQe," \u2014 "),NJ=n(PQe,"A",{href:!0});var EUt=s(NJ);scr=r(EUt,"MPNetForSequenceClassification"),EUt.forEach(t),lcr=r(PQe," (MPNet model)"),PQe.forEach(t),icr=i(j),HT=n(j,"LI",{});var BQe=s(HT);qEe=n(BQe,"STRONG",{});var CUt=s(qEe);dcr=r(CUt,"mvp"),CUt.forEach(t),mcr=r(BQe," \u2014 "),qJ=n(BQe,"A",{href:!0});var wUt=s(qJ);ccr=r(wUt,"MvpForSequenceClassification"),wUt.forEach(t),fcr=r(BQe," (MVP model)"),BQe.forEach(t),gcr=i(j),JT=n(j,"LI",{});var IQe=s(JT);DEe=n(IQe,"STRONG",{});var AUt=s(DEe);hcr=r(AUt,"nezha"),AUt.forEach(t),ucr=r(IQe," \u2014 "),DJ=n(IQe,"A",{href:!0});var LUt=s(DJ);pcr=r(LUt,"NezhaForSequenceClassification"),LUt.forEach(t),_cr=r(IQe," (Nezha model)"),IQe.forEach(t),bcr=i(j),YT=n(j,"LI",{});var NQe=s(YT);jEe=n(NQe,"STRONG",{});var yUt=s(jEe);vcr=r(yUt,"nystromformer"),yUt.forEach(t),Fcr=r(NQe," \u2014 "),jJ=n(NQe,"A",{href:!0});var xUt=s(jJ);Tcr=r(xUt,"NystromformerForSequenceClassification"),xUt.forEach(t),Mcr=r(NQe," (Nystr\xF6mformer model)"),NQe.forEach(t),Ecr=i(j),ZT=n(j,"LI",{});var qQe=s(ZT);GEe=n(qQe,"STRONG",{});var $Ut=s(GEe);Ccr=r($Ut,"openai-gpt"),$Ut.forEach(t),wcr=r(qQe," \u2014 "),GJ=n(qQe,"A",{href:!0});var kUt=s(GJ);Acr=r(kUt,"OpenAIGPTForSequenceClassification"),kUt.forEach(t),Lcr=r(qQe," (OpenAI GPT model)"),qQe.forEach(t),ycr=i(j),KT=n(j,"LI",{});var DQe=s(KT);OEe=n(DQe,"STRONG",{});var SUt=s(OEe);xcr=r(SUt,"opt"),SUt.forEach(t),$cr=r(DQe," \u2014 "),OJ=n(DQe,"A",{href:!0});var RUt=s(OJ);kcr=r(RUt,"OPTForSequenceClassification"),RUt.forEach(t),Scr=r(DQe," (OPT model)"),DQe.forEach(t),Rcr=i(j),eM=n(j,"LI",{});var jQe=s(eM);VEe=n(jQe,"STRONG",{});var PUt=s(VEe);Pcr=r(PUt,"perceiver"),PUt.forEach(t),Bcr=r(jQe," \u2014 "),VJ=n(jQe,"A",{href:!0});var BUt=s(VJ);Icr=r(BUt,"PerceiverForSequenceClassification"),BUt.forEach(t),Ncr=r(jQe," (Perceiver model)"),jQe.forEach(t),qcr=i(j),oM=n(j,"LI",{});var GQe=s(oM);XEe=n(GQe,"STRONG",{});var IUt=s(XEe);Dcr=r(IUt,"plbart"),IUt.forEach(t),jcr=r(GQe," \u2014 "),XJ=n(GQe,"A",{href:!0});var NUt=s(XJ);Gcr=r(NUt,"PLBartForSequenceClassification"),NUt.forEach(t),Ocr=r(GQe," (PLBart model)"),GQe.forEach(t),Vcr=i(j),rM=n(j,"LI",{});var OQe=s(rM);zEe=n(OQe,"STRONG",{});var qUt=s(zEe);Xcr=r(qUt,"qdqbert"),qUt.forEach(t),zcr=r(OQe," \u2014 "),zJ=n(OQe,"A",{href:!0});var DUt=s(zJ);Qcr=r(DUt,"QDQBertForSequenceClassification"),DUt.forEach(t),Wcr=r(OQe," (QDQBert model)"),OQe.forEach(t),Ucr=i(j),tM=n(j,"LI",{});var VQe=s(tM);QEe=n(VQe,"STRONG",{});var jUt=s(QEe);Hcr=r(jUt,"reformer"),jUt.forEach(t),Jcr=r(VQe," \u2014 "),QJ=n(VQe,"A",{href:!0});var GUt=s(QJ);Ycr=r(GUt,"ReformerForSequenceClassification"),GUt.forEach(t),Zcr=r(VQe," (Reformer model)"),VQe.forEach(t),Kcr=i(j),aM=n(j,"LI",{});var XQe=s(aM);WEe=n(XQe,"STRONG",{});var OUt=s(WEe);efr=r(OUt,"rembert"),OUt.forEach(t),ofr=r(XQe," \u2014 "),WJ=n(XQe,"A",{href:!0});var VUt=s(WJ);rfr=r(VUt,"RemBertForSequenceClassification"),VUt.forEach(t),tfr=r(XQe," (RemBERT model)"),XQe.forEach(t),afr=i(j),nM=n(j,"LI",{});var zQe=s(nM);UEe=n(zQe,"STRONG",{});var XUt=s(UEe);nfr=r(XUt,"roberta"),XUt.forEach(t),sfr=r(zQe," \u2014 "),UJ=n(zQe,"A",{href:!0});var zUt=s(UJ);lfr=r(zUt,"RobertaForSequenceClassification"),zUt.forEach(t),ifr=r(zQe," (RoBERTa model)"),zQe.forEach(t),dfr=i(j),sM=n(j,"LI",{});var QQe=s(sM);HEe=n(QQe,"STRONG",{});var QUt=s(HEe);mfr=r(QUt,"roformer"),QUt.forEach(t),cfr=r(QQe," \u2014 "),HJ=n(QQe,"A",{href:!0});var WUt=s(HJ);ffr=r(WUt,"RoFormerForSequenceClassification"),WUt.forEach(t),gfr=r(QQe," (RoFormer model)"),QQe.forEach(t),hfr=i(j),lM=n(j,"LI",{});var WQe=s(lM);JEe=n(WQe,"STRONG",{});var UUt=s(JEe);ufr=r(UUt,"squeezebert"),UUt.forEach(t),pfr=r(WQe," \u2014 "),JJ=n(WQe,"A",{href:!0});var HUt=s(JJ);_fr=r(HUt,"SqueezeBertForSequenceClassification"),HUt.forEach(t),bfr=r(WQe," (SqueezeBERT model)"),WQe.forEach(t),vfr=i(j),iM=n(j,"LI",{});var UQe=s(iM);YEe=n(UQe,"STRONG",{});var JUt=s(YEe);Ffr=r(JUt,"tapas"),JUt.forEach(t),Tfr=r(UQe," \u2014 "),YJ=n(UQe,"A",{href:!0});var YUt=s(YJ);Mfr=r(YUt,"TapasForSequenceClassification"),YUt.forEach(t),Efr=r(UQe," (TAPAS model)"),UQe.forEach(t),Cfr=i(j),dM=n(j,"LI",{});var HQe=s(dM);ZEe=n(HQe,"STRONG",{});var ZUt=s(ZEe);wfr=r(ZUt,"transfo-xl"),ZUt.forEach(t),Afr=r(HQe," \u2014 "),ZJ=n(HQe,"A",{href:!0});var KUt=s(ZJ);Lfr=r(KUt,"TransfoXLForSequenceClassification"),KUt.forEach(t),yfr=r(HQe," (Transformer-XL model)"),HQe.forEach(t),xfr=i(j),mM=n(j,"LI",{});var JQe=s(mM);KEe=n(JQe,"STRONG",{});var eHt=s(KEe);$fr=r(eHt,"xlm"),eHt.forEach(t),kfr=r(JQe," \u2014 "),KJ=n(JQe,"A",{href:!0});var oHt=s(KJ);Sfr=r(oHt,"XLMForSequenceClassification"),oHt.forEach(t),Rfr=r(JQe," (XLM model)"),JQe.forEach(t),Pfr=i(j),cM=n(j,"LI",{});var YQe=s(cM);e4e=n(YQe,"STRONG",{});var rHt=s(e4e);Bfr=r(rHt,"xlm-roberta"),rHt.forEach(t),Ifr=r(YQe," \u2014 "),eY=n(YQe,"A",{href:!0});var tHt=s(eY);Nfr=r(tHt,"XLMRobertaForSequenceClassification"),tHt.forEach(t),qfr=r(YQe," (XLM-RoBERTa model)"),YQe.forEach(t),Dfr=i(j),fM=n(j,"LI",{});var ZQe=s(fM);o4e=n(ZQe,"STRONG",{});var aHt=s(o4e);jfr=r(aHt,"xlm-roberta-xl"),aHt.forEach(t),Gfr=r(ZQe," \u2014 "),oY=n(ZQe,"A",{href:!0});var nHt=s(oY);Ofr=r(nHt,"XLMRobertaXLForSequenceClassification"),nHt.forEach(t),Vfr=r(ZQe," (XLM-RoBERTa-XL model)"),ZQe.forEach(t),Xfr=i(j),gM=n(j,"LI",{});var KQe=s(gM);r4e=n(KQe,"STRONG",{});var sHt=s(r4e);zfr=r(sHt,"xlnet"),sHt.forEach(t),Qfr=r(KQe," \u2014 "),rY=n(KQe,"A",{href:!0});var lHt=s(rY);Wfr=r(lHt,"XLNetForSequenceClassification"),lHt.forEach(t),Ufr=r(KQe," (XLNet model)"),KQe.forEach(t),Hfr=i(j),hM=n(j,"LI",{});var eWe=s(hM);t4e=n(eWe,"STRONG",{});var iHt=s(t4e);Jfr=r(iHt,"yoso"),iHt.forEach(t),Yfr=r(eWe," \u2014 "),tY=n(eWe,"A",{href:!0});var dHt=s(tY);Zfr=r(dHt,"YosoForSequenceClassification"),dHt.forEach(t),Kfr=r(eWe," (YOSO model)"),eWe.forEach(t),j.forEach(t),egr=i(Ra),uM=n(Ra,"P",{});var oWe=s(uM);ogr=r(oWe,"The model is set in evaluation mode by default using "),a4e=n(oWe,"CODE",{});var mHt=s(a4e);rgr=r(mHt,"model.eval()"),mHt.forEach(t),tgr=r(oWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),n4e=n(oWe,"CODE",{});var cHt=s(n4e);agr=r(cHt,"model.train()"),cHt.forEach(t),oWe.forEach(t),ngr=i(Ra),T(pM.$$.fragment,Ra),Ra.forEach(t),Vl.forEach(t),Yto=i(c),Zd=n(c,"H2",{class:!0});var pso=s(Zd);_M=n(pso,"A",{id:!0,class:!0,href:!0});var fHt=s(_M);s4e=n(fHt,"SPAN",{});var gHt=s(s4e);T(_k.$$.fragment,gHt),gHt.forEach(t),fHt.forEach(t),sgr=i(pso),l4e=n(pso,"SPAN",{});var hHt=s(l4e);lgr=r(hHt,"AutoModelForMultipleChoice"),hHt.forEach(t),pso.forEach(t),Zto=i(c),Vo=n(c,"DIV",{class:!0});var Xl=s(Vo);T(bk.$$.fragment,Xl),igr=i(Xl),Kd=n(Xl,"P",{});var pme=s(Kd);dgr=r(pme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),aY=n(pme,"A",{href:!0});var uHt=s(aY);mgr=r(uHt,"from_pretrained()"),uHt.forEach(t),cgr=r(pme," class method or the "),nY=n(pme,"A",{href:!0});var pHt=s(nY);fgr=r(pHt,"from_config()"),pHt.forEach(t),ggr=r(pme,` class
method.`),pme.forEach(t),hgr=i(Xl),vk=n(Xl,"P",{});var _so=s(vk);ugr=r(_so,"This class cannot be instantiated directly using "),i4e=n(_so,"CODE",{});var _Ht=s(i4e);pgr=r(_Ht,"__init__()"),_Ht.forEach(t),_gr=r(_so," (throws an error)."),_so.forEach(t),bgr=i(Xl),xt=n(Xl,"DIV",{class:!0});var h9=s(xt);T(Fk.$$.fragment,h9),vgr=i(h9),d4e=n(h9,"P",{});var bHt=s(d4e);Fgr=r(bHt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),bHt.forEach(t),Tgr=i(h9),em=n(h9,"P",{});var _me=s(em);Mgr=r(_me,`Note:
Loading a model from its configuration file does `),m4e=n(_me,"STRONG",{});var vHt=s(m4e);Egr=r(vHt,"not"),vHt.forEach(t),Cgr=r(_me,` load the model weights. It only affects the
model\u2019s configuration. Use `),sY=n(_me,"A",{href:!0});var FHt=s(sY);wgr=r(FHt,"from_pretrained()"),FHt.forEach(t),Agr=r(_me," to load the model weights."),_me.forEach(t),Lgr=i(h9),T(bM.$$.fragment,h9),h9.forEach(t),ygr=i(Xl),so=n(Xl,"DIV",{class:!0});var Pa=s(so);T(Tk.$$.fragment,Pa),xgr=i(Pa),c4e=n(Pa,"P",{});var THt=s(c4e);$gr=r(THt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),THt.forEach(t),kgr=i(Pa),gn=n(Pa,"P",{});var u9=s(gn);Sgr=r(u9,"The model class to instantiate is selected based on the "),f4e=n(u9,"CODE",{});var MHt=s(f4e);Rgr=r(MHt,"model_type"),MHt.forEach(t),Pgr=r(u9,` property of the config object (either
passed as an argument or loaded from `),g4e=n(u9,"CODE",{});var EHt=s(g4e);Bgr=r(EHt,"pretrained_model_name_or_path"),EHt.forEach(t),Igr=r(u9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h4e=n(u9,"CODE",{});var CHt=s(h4e);Ngr=r(CHt,"pretrained_model_name_or_path"),CHt.forEach(t),qgr=r(u9,":"),u9.forEach(t),Dgr=i(Pa),K=n(Pa,"UL",{});var ee=s(K);vM=n(ee,"LI",{});var rWe=s(vM);u4e=n(rWe,"STRONG",{});var wHt=s(u4e);jgr=r(wHt,"albert"),wHt.forEach(t),Ggr=r(rWe," \u2014 "),lY=n(rWe,"A",{href:!0});var AHt=s(lY);Ogr=r(AHt,"AlbertForMultipleChoice"),AHt.forEach(t),Vgr=r(rWe," (ALBERT model)"),rWe.forEach(t),Xgr=i(ee),FM=n(ee,"LI",{});var tWe=s(FM);p4e=n(tWe,"STRONG",{});var LHt=s(p4e);zgr=r(LHt,"bert"),LHt.forEach(t),Qgr=r(tWe," \u2014 "),iY=n(tWe,"A",{href:!0});var yHt=s(iY);Wgr=r(yHt,"BertForMultipleChoice"),yHt.forEach(t),Ugr=r(tWe," (BERT model)"),tWe.forEach(t),Hgr=i(ee),TM=n(ee,"LI",{});var aWe=s(TM);_4e=n(aWe,"STRONG",{});var xHt=s(_4e);Jgr=r(xHt,"big_bird"),xHt.forEach(t),Ygr=r(aWe," \u2014 "),dY=n(aWe,"A",{href:!0});var $Ht=s(dY);Zgr=r($Ht,"BigBirdForMultipleChoice"),$Ht.forEach(t),Kgr=r(aWe," (BigBird model)"),aWe.forEach(t),ehr=i(ee),MM=n(ee,"LI",{});var nWe=s(MM);b4e=n(nWe,"STRONG",{});var kHt=s(b4e);ohr=r(kHt,"camembert"),kHt.forEach(t),rhr=r(nWe," \u2014 "),mY=n(nWe,"A",{href:!0});var SHt=s(mY);thr=r(SHt,"CamembertForMultipleChoice"),SHt.forEach(t),ahr=r(nWe," (CamemBERT model)"),nWe.forEach(t),nhr=i(ee),EM=n(ee,"LI",{});var sWe=s(EM);v4e=n(sWe,"STRONG",{});var RHt=s(v4e);shr=r(RHt,"canine"),RHt.forEach(t),lhr=r(sWe," \u2014 "),cY=n(sWe,"A",{href:!0});var PHt=s(cY);ihr=r(PHt,"CanineForMultipleChoice"),PHt.forEach(t),dhr=r(sWe," (CANINE model)"),sWe.forEach(t),mhr=i(ee),CM=n(ee,"LI",{});var lWe=s(CM);F4e=n(lWe,"STRONG",{});var BHt=s(F4e);chr=r(BHt,"convbert"),BHt.forEach(t),fhr=r(lWe," \u2014 "),fY=n(lWe,"A",{href:!0});var IHt=s(fY);ghr=r(IHt,"ConvBertForMultipleChoice"),IHt.forEach(t),hhr=r(lWe," (ConvBERT model)"),lWe.forEach(t),uhr=i(ee),wM=n(ee,"LI",{});var iWe=s(wM);T4e=n(iWe,"STRONG",{});var NHt=s(T4e);phr=r(NHt,"data2vec-text"),NHt.forEach(t),_hr=r(iWe," \u2014 "),gY=n(iWe,"A",{href:!0});var qHt=s(gY);bhr=r(qHt,"Data2VecTextForMultipleChoice"),qHt.forEach(t),vhr=r(iWe," (Data2VecText model)"),iWe.forEach(t),Fhr=i(ee),AM=n(ee,"LI",{});var dWe=s(AM);M4e=n(dWe,"STRONG",{});var DHt=s(M4e);Thr=r(DHt,"deberta-v2"),DHt.forEach(t),Mhr=r(dWe," \u2014 "),hY=n(dWe,"A",{href:!0});var jHt=s(hY);Ehr=r(jHt,"DebertaV2ForMultipleChoice"),jHt.forEach(t),Chr=r(dWe," (DeBERTa-v2 model)"),dWe.forEach(t),whr=i(ee),LM=n(ee,"LI",{});var mWe=s(LM);E4e=n(mWe,"STRONG",{});var GHt=s(E4e);Ahr=r(GHt,"distilbert"),GHt.forEach(t),Lhr=r(mWe," \u2014 "),uY=n(mWe,"A",{href:!0});var OHt=s(uY);yhr=r(OHt,"DistilBertForMultipleChoice"),OHt.forEach(t),xhr=r(mWe," (DistilBERT model)"),mWe.forEach(t),$hr=i(ee),yM=n(ee,"LI",{});var cWe=s(yM);C4e=n(cWe,"STRONG",{});var VHt=s(C4e);khr=r(VHt,"electra"),VHt.forEach(t),Shr=r(cWe," \u2014 "),pY=n(cWe,"A",{href:!0});var XHt=s(pY);Rhr=r(XHt,"ElectraForMultipleChoice"),XHt.forEach(t),Phr=r(cWe," (ELECTRA model)"),cWe.forEach(t),Bhr=i(ee),xM=n(ee,"LI",{});var fWe=s(xM);w4e=n(fWe,"STRONG",{});var zHt=s(w4e);Ihr=r(zHt,"ernie"),zHt.forEach(t),Nhr=r(fWe," \u2014 "),_Y=n(fWe,"A",{href:!0});var QHt=s(_Y);qhr=r(QHt,"ErnieForMultipleChoice"),QHt.forEach(t),Dhr=r(fWe," (ERNIE model)"),fWe.forEach(t),jhr=i(ee),$M=n(ee,"LI",{});var gWe=s($M);A4e=n(gWe,"STRONG",{});var WHt=s(A4e);Ghr=r(WHt,"flaubert"),WHt.forEach(t),Ohr=r(gWe," \u2014 "),bY=n(gWe,"A",{href:!0});var UHt=s(bY);Vhr=r(UHt,"FlaubertForMultipleChoice"),UHt.forEach(t),Xhr=r(gWe," (FlauBERT model)"),gWe.forEach(t),zhr=i(ee),kM=n(ee,"LI",{});var hWe=s(kM);L4e=n(hWe,"STRONG",{});var HHt=s(L4e);Qhr=r(HHt,"fnet"),HHt.forEach(t),Whr=r(hWe," \u2014 "),vY=n(hWe,"A",{href:!0});var JHt=s(vY);Uhr=r(JHt,"FNetForMultipleChoice"),JHt.forEach(t),Hhr=r(hWe," (FNet model)"),hWe.forEach(t),Jhr=i(ee),SM=n(ee,"LI",{});var uWe=s(SM);y4e=n(uWe,"STRONG",{});var YHt=s(y4e);Yhr=r(YHt,"funnel"),YHt.forEach(t),Zhr=r(uWe," \u2014 "),FY=n(uWe,"A",{href:!0});var ZHt=s(FY);Khr=r(ZHt,"FunnelForMultipleChoice"),ZHt.forEach(t),eur=r(uWe," (Funnel Transformer model)"),uWe.forEach(t),our=i(ee),RM=n(ee,"LI",{});var pWe=s(RM);x4e=n(pWe,"STRONG",{});var KHt=s(x4e);rur=r(KHt,"ibert"),KHt.forEach(t),tur=r(pWe," \u2014 "),TY=n(pWe,"A",{href:!0});var eJt=s(TY);aur=r(eJt,"IBertForMultipleChoice"),eJt.forEach(t),nur=r(pWe," (I-BERT model)"),pWe.forEach(t),sur=i(ee),PM=n(ee,"LI",{});var _We=s(PM);$4e=n(_We,"STRONG",{});var oJt=s($4e);lur=r(oJt,"longformer"),oJt.forEach(t),iur=r(_We," \u2014 "),MY=n(_We,"A",{href:!0});var rJt=s(MY);dur=r(rJt,"LongformerForMultipleChoice"),rJt.forEach(t),mur=r(_We," (Longformer model)"),_We.forEach(t),cur=i(ee),BM=n(ee,"LI",{});var bWe=s(BM);k4e=n(bWe,"STRONG",{});var tJt=s(k4e);fur=r(tJt,"luke"),tJt.forEach(t),gur=r(bWe," \u2014 "),EY=n(bWe,"A",{href:!0});var aJt=s(EY);hur=r(aJt,"LukeForMultipleChoice"),aJt.forEach(t),uur=r(bWe," (LUKE model)"),bWe.forEach(t),pur=i(ee),IM=n(ee,"LI",{});var vWe=s(IM);S4e=n(vWe,"STRONG",{});var nJt=s(S4e);_ur=r(nJt,"megatron-bert"),nJt.forEach(t),bur=r(vWe," \u2014 "),CY=n(vWe,"A",{href:!0});var sJt=s(CY);vur=r(sJt,"MegatronBertForMultipleChoice"),sJt.forEach(t),Fur=r(vWe," (Megatron-BERT model)"),vWe.forEach(t),Tur=i(ee),NM=n(ee,"LI",{});var FWe=s(NM);R4e=n(FWe,"STRONG",{});var lJt=s(R4e);Mur=r(lJt,"mobilebert"),lJt.forEach(t),Eur=r(FWe," \u2014 "),wY=n(FWe,"A",{href:!0});var iJt=s(wY);Cur=r(iJt,"MobileBertForMultipleChoice"),iJt.forEach(t),wur=r(FWe," (MobileBERT model)"),FWe.forEach(t),Aur=i(ee),qM=n(ee,"LI",{});var TWe=s(qM);P4e=n(TWe,"STRONG",{});var dJt=s(P4e);Lur=r(dJt,"mpnet"),dJt.forEach(t),yur=r(TWe," \u2014 "),AY=n(TWe,"A",{href:!0});var mJt=s(AY);xur=r(mJt,"MPNetForMultipleChoice"),mJt.forEach(t),$ur=r(TWe," (MPNet model)"),TWe.forEach(t),kur=i(ee),DM=n(ee,"LI",{});var MWe=s(DM);B4e=n(MWe,"STRONG",{});var cJt=s(B4e);Sur=r(cJt,"nezha"),cJt.forEach(t),Rur=r(MWe," \u2014 "),LY=n(MWe,"A",{href:!0});var fJt=s(LY);Pur=r(fJt,"NezhaForMultipleChoice"),fJt.forEach(t),Bur=r(MWe," (Nezha model)"),MWe.forEach(t),Iur=i(ee),jM=n(ee,"LI",{});var EWe=s(jM);I4e=n(EWe,"STRONG",{});var gJt=s(I4e);Nur=r(gJt,"nystromformer"),gJt.forEach(t),qur=r(EWe," \u2014 "),yY=n(EWe,"A",{href:!0});var hJt=s(yY);Dur=r(hJt,"NystromformerForMultipleChoice"),hJt.forEach(t),jur=r(EWe," (Nystr\xF6mformer model)"),EWe.forEach(t),Gur=i(ee),GM=n(ee,"LI",{});var CWe=s(GM);N4e=n(CWe,"STRONG",{});var uJt=s(N4e);Our=r(uJt,"qdqbert"),uJt.forEach(t),Vur=r(CWe," \u2014 "),xY=n(CWe,"A",{href:!0});var pJt=s(xY);Xur=r(pJt,"QDQBertForMultipleChoice"),pJt.forEach(t),zur=r(CWe," (QDQBert model)"),CWe.forEach(t),Qur=i(ee),OM=n(ee,"LI",{});var wWe=s(OM);q4e=n(wWe,"STRONG",{});var _Jt=s(q4e);Wur=r(_Jt,"rembert"),_Jt.forEach(t),Uur=r(wWe," \u2014 "),$Y=n(wWe,"A",{href:!0});var bJt=s($Y);Hur=r(bJt,"RemBertForMultipleChoice"),bJt.forEach(t),Jur=r(wWe," (RemBERT model)"),wWe.forEach(t),Yur=i(ee),VM=n(ee,"LI",{});var AWe=s(VM);D4e=n(AWe,"STRONG",{});var vJt=s(D4e);Zur=r(vJt,"roberta"),vJt.forEach(t),Kur=r(AWe," \u2014 "),kY=n(AWe,"A",{href:!0});var FJt=s(kY);epr=r(FJt,"RobertaForMultipleChoice"),FJt.forEach(t),opr=r(AWe," (RoBERTa model)"),AWe.forEach(t),rpr=i(ee),XM=n(ee,"LI",{});var LWe=s(XM);j4e=n(LWe,"STRONG",{});var TJt=s(j4e);tpr=r(TJt,"roformer"),TJt.forEach(t),apr=r(LWe," \u2014 "),SY=n(LWe,"A",{href:!0});var MJt=s(SY);npr=r(MJt,"RoFormerForMultipleChoice"),MJt.forEach(t),spr=r(LWe," (RoFormer model)"),LWe.forEach(t),lpr=i(ee),zM=n(ee,"LI",{});var yWe=s(zM);G4e=n(yWe,"STRONG",{});var EJt=s(G4e);ipr=r(EJt,"squeezebert"),EJt.forEach(t),dpr=r(yWe," \u2014 "),RY=n(yWe,"A",{href:!0});var CJt=s(RY);mpr=r(CJt,"SqueezeBertForMultipleChoice"),CJt.forEach(t),cpr=r(yWe," (SqueezeBERT model)"),yWe.forEach(t),fpr=i(ee),QM=n(ee,"LI",{});var xWe=s(QM);O4e=n(xWe,"STRONG",{});var wJt=s(O4e);gpr=r(wJt,"xlm"),wJt.forEach(t),hpr=r(xWe," \u2014 "),PY=n(xWe,"A",{href:!0});var AJt=s(PY);upr=r(AJt,"XLMForMultipleChoice"),AJt.forEach(t),ppr=r(xWe," (XLM model)"),xWe.forEach(t),_pr=i(ee),WM=n(ee,"LI",{});var $We=s(WM);V4e=n($We,"STRONG",{});var LJt=s(V4e);bpr=r(LJt,"xlm-roberta"),LJt.forEach(t),vpr=r($We," \u2014 "),BY=n($We,"A",{href:!0});var yJt=s(BY);Fpr=r(yJt,"XLMRobertaForMultipleChoice"),yJt.forEach(t),Tpr=r($We," (XLM-RoBERTa model)"),$We.forEach(t),Mpr=i(ee),UM=n(ee,"LI",{});var kWe=s(UM);X4e=n(kWe,"STRONG",{});var xJt=s(X4e);Epr=r(xJt,"xlm-roberta-xl"),xJt.forEach(t),Cpr=r(kWe," \u2014 "),IY=n(kWe,"A",{href:!0});var $Jt=s(IY);wpr=r($Jt,"XLMRobertaXLForMultipleChoice"),$Jt.forEach(t),Apr=r(kWe," (XLM-RoBERTa-XL model)"),kWe.forEach(t),Lpr=i(ee),HM=n(ee,"LI",{});var SWe=s(HM);z4e=n(SWe,"STRONG",{});var kJt=s(z4e);ypr=r(kJt,"xlnet"),kJt.forEach(t),xpr=r(SWe," \u2014 "),NY=n(SWe,"A",{href:!0});var SJt=s(NY);$pr=r(SJt,"XLNetForMultipleChoice"),SJt.forEach(t),kpr=r(SWe," (XLNet model)"),SWe.forEach(t),Spr=i(ee),JM=n(ee,"LI",{});var RWe=s(JM);Q4e=n(RWe,"STRONG",{});var RJt=s(Q4e);Rpr=r(RJt,"yoso"),RJt.forEach(t),Ppr=r(RWe," \u2014 "),qY=n(RWe,"A",{href:!0});var PJt=s(qY);Bpr=r(PJt,"YosoForMultipleChoice"),PJt.forEach(t),Ipr=r(RWe," (YOSO model)"),RWe.forEach(t),ee.forEach(t),Npr=i(Pa),YM=n(Pa,"P",{});var PWe=s(YM);qpr=r(PWe,"The model is set in evaluation mode by default using "),W4e=n(PWe,"CODE",{});var BJt=s(W4e);Dpr=r(BJt,"model.eval()"),BJt.forEach(t),jpr=r(PWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),U4e=n(PWe,"CODE",{});var IJt=s(U4e);Gpr=r(IJt,"model.train()"),IJt.forEach(t),PWe.forEach(t),Opr=i(Pa),T(ZM.$$.fragment,Pa),Pa.forEach(t),Xl.forEach(t),Kto=i(c),om=n(c,"H2",{class:!0});var bso=s(om);KM=n(bso,"A",{id:!0,class:!0,href:!0});var NJt=s(KM);H4e=n(NJt,"SPAN",{});var qJt=s(H4e);T(Mk.$$.fragment,qJt),qJt.forEach(t),NJt.forEach(t),Vpr=i(bso),J4e=n(bso,"SPAN",{});var DJt=s(J4e);Xpr=r(DJt,"AutoModelForNextSentencePrediction"),DJt.forEach(t),bso.forEach(t),eao=i(c),Xo=n(c,"DIV",{class:!0});var zl=s(Xo);T(Ek.$$.fragment,zl),zpr=i(zl),rm=n(zl,"P",{});var bme=s(rm);Qpr=r(bme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),DY=n(bme,"A",{href:!0});var jJt=s(DY);Wpr=r(jJt,"from_pretrained()"),jJt.forEach(t),Upr=r(bme," class method or the "),jY=n(bme,"A",{href:!0});var GJt=s(jY);Hpr=r(GJt,"from_config()"),GJt.forEach(t),Jpr=r(bme,` class
method.`),bme.forEach(t),Ypr=i(zl),Ck=n(zl,"P",{});var vso=s(Ck);Zpr=r(vso,"This class cannot be instantiated directly using "),Y4e=n(vso,"CODE",{});var OJt=s(Y4e);Kpr=r(OJt,"__init__()"),OJt.forEach(t),e_r=r(vso," (throws an error)."),vso.forEach(t),o_r=i(zl),$t=n(zl,"DIV",{class:!0});var p9=s($t);T(wk.$$.fragment,p9),r_r=i(p9),Z4e=n(p9,"P",{});var VJt=s(Z4e);t_r=r(VJt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),VJt.forEach(t),a_r=i(p9),tm=n(p9,"P",{});var vme=s(tm);n_r=r(vme,`Note:
Loading a model from its configuration file does `),K4e=n(vme,"STRONG",{});var XJt=s(K4e);s_r=r(XJt,"not"),XJt.forEach(t),l_r=r(vme,` load the model weights. It only affects the
model\u2019s configuration. Use `),GY=n(vme,"A",{href:!0});var zJt=s(GY);i_r=r(zJt,"from_pretrained()"),zJt.forEach(t),d_r=r(vme," to load the model weights."),vme.forEach(t),m_r=i(p9),T(eE.$$.fragment,p9),p9.forEach(t),c_r=i(zl),lo=n(zl,"DIV",{class:!0});var Ba=s(lo);T(Ak.$$.fragment,Ba),f_r=i(Ba),eCe=n(Ba,"P",{});var QJt=s(eCe);g_r=r(QJt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),QJt.forEach(t),h_r=i(Ba),hn=n(Ba,"P",{});var _9=s(hn);u_r=r(_9,"The model class to instantiate is selected based on the "),oCe=n(_9,"CODE",{});var WJt=s(oCe);p_r=r(WJt,"model_type"),WJt.forEach(t),__r=r(_9,` property of the config object (either
passed as an argument or loaded from `),rCe=n(_9,"CODE",{});var UJt=s(rCe);b_r=r(UJt,"pretrained_model_name_or_path"),UJt.forEach(t),v_r=r(_9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tCe=n(_9,"CODE",{});var HJt=s(tCe);F_r=r(HJt,"pretrained_model_name_or_path"),HJt.forEach(t),T_r=r(_9,":"),_9.forEach(t),M_r=i(Ba),Ue=n(Ba,"UL",{});var ht=s(Ue);oE=n(ht,"LI",{});var BWe=s(oE);aCe=n(BWe,"STRONG",{});var JJt=s(aCe);E_r=r(JJt,"bert"),JJt.forEach(t),C_r=r(BWe," \u2014 "),OY=n(BWe,"A",{href:!0});var YJt=s(OY);w_r=r(YJt,"BertForNextSentencePrediction"),YJt.forEach(t),A_r=r(BWe," (BERT model)"),BWe.forEach(t),L_r=i(ht),rE=n(ht,"LI",{});var IWe=s(rE);nCe=n(IWe,"STRONG",{});var ZJt=s(nCe);y_r=r(ZJt,"ernie"),ZJt.forEach(t),x_r=r(IWe," \u2014 "),VY=n(IWe,"A",{href:!0});var KJt=s(VY);$_r=r(KJt,"ErnieForNextSentencePrediction"),KJt.forEach(t),k_r=r(IWe," (ERNIE model)"),IWe.forEach(t),S_r=i(ht),tE=n(ht,"LI",{});var NWe=s(tE);sCe=n(NWe,"STRONG",{});var eYt=s(sCe);R_r=r(eYt,"fnet"),eYt.forEach(t),P_r=r(NWe," \u2014 "),XY=n(NWe,"A",{href:!0});var oYt=s(XY);B_r=r(oYt,"FNetForNextSentencePrediction"),oYt.forEach(t),I_r=r(NWe," (FNet model)"),NWe.forEach(t),N_r=i(ht),aE=n(ht,"LI",{});var qWe=s(aE);lCe=n(qWe,"STRONG",{});var rYt=s(lCe);q_r=r(rYt,"megatron-bert"),rYt.forEach(t),D_r=r(qWe," \u2014 "),zY=n(qWe,"A",{href:!0});var tYt=s(zY);j_r=r(tYt,"MegatronBertForNextSentencePrediction"),tYt.forEach(t),G_r=r(qWe," (Megatron-BERT model)"),qWe.forEach(t),O_r=i(ht),nE=n(ht,"LI",{});var DWe=s(nE);iCe=n(DWe,"STRONG",{});var aYt=s(iCe);V_r=r(aYt,"mobilebert"),aYt.forEach(t),X_r=r(DWe," \u2014 "),QY=n(DWe,"A",{href:!0});var nYt=s(QY);z_r=r(nYt,"MobileBertForNextSentencePrediction"),nYt.forEach(t),Q_r=r(DWe," (MobileBERT model)"),DWe.forEach(t),W_r=i(ht),sE=n(ht,"LI",{});var jWe=s(sE);dCe=n(jWe,"STRONG",{});var sYt=s(dCe);U_r=r(sYt,"nezha"),sYt.forEach(t),H_r=r(jWe," \u2014 "),WY=n(jWe,"A",{href:!0});var lYt=s(WY);J_r=r(lYt,"NezhaForNextSentencePrediction"),lYt.forEach(t),Y_r=r(jWe," (Nezha model)"),jWe.forEach(t),Z_r=i(ht),lE=n(ht,"LI",{});var GWe=s(lE);mCe=n(GWe,"STRONG",{});var iYt=s(mCe);K_r=r(iYt,"qdqbert"),iYt.forEach(t),e1r=r(GWe," \u2014 "),UY=n(GWe,"A",{href:!0});var dYt=s(UY);o1r=r(dYt,"QDQBertForNextSentencePrediction"),dYt.forEach(t),r1r=r(GWe," (QDQBert model)"),GWe.forEach(t),ht.forEach(t),t1r=i(Ba),iE=n(Ba,"P",{});var OWe=s(iE);a1r=r(OWe,"The model is set in evaluation mode by default using "),cCe=n(OWe,"CODE",{});var mYt=s(cCe);n1r=r(mYt,"model.eval()"),mYt.forEach(t),s1r=r(OWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),fCe=n(OWe,"CODE",{});var cYt=s(fCe);l1r=r(cYt,"model.train()"),cYt.forEach(t),OWe.forEach(t),i1r=i(Ba),T(dE.$$.fragment,Ba),Ba.forEach(t),zl.forEach(t),oao=i(c),am=n(c,"H2",{class:!0});var Fso=s(am);mE=n(Fso,"A",{id:!0,class:!0,href:!0});var fYt=s(mE);gCe=n(fYt,"SPAN",{});var gYt=s(gCe);T(Lk.$$.fragment,gYt),gYt.forEach(t),fYt.forEach(t),d1r=i(Fso),hCe=n(Fso,"SPAN",{});var hYt=s(hCe);m1r=r(hYt,"AutoModelForTokenClassification"),hYt.forEach(t),Fso.forEach(t),rao=i(c),zo=n(c,"DIV",{class:!0});var Ql=s(zo);T(yk.$$.fragment,Ql),c1r=i(Ql),nm=n(Ql,"P",{});var Fme=s(nm);f1r=r(Fme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),HY=n(Fme,"A",{href:!0});var uYt=s(HY);g1r=r(uYt,"from_pretrained()"),uYt.forEach(t),h1r=r(Fme," class method or the "),JY=n(Fme,"A",{href:!0});var pYt=s(JY);u1r=r(pYt,"from_config()"),pYt.forEach(t),p1r=r(Fme,` class
method.`),Fme.forEach(t),_1r=i(Ql),xk=n(Ql,"P",{});var Tso=s(xk);b1r=r(Tso,"This class cannot be instantiated directly using "),uCe=n(Tso,"CODE",{});var _Yt=s(uCe);v1r=r(_Yt,"__init__()"),_Yt.forEach(t),F1r=r(Tso," (throws an error)."),Tso.forEach(t),T1r=i(Ql),kt=n(Ql,"DIV",{class:!0});var b9=s(kt);T($k.$$.fragment,b9),M1r=i(b9),pCe=n(b9,"P",{});var bYt=s(pCe);E1r=r(bYt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),bYt.forEach(t),C1r=i(b9),sm=n(b9,"P",{});var Tme=s(sm);w1r=r(Tme,`Note:
Loading a model from its configuration file does `),_Ce=n(Tme,"STRONG",{});var vYt=s(_Ce);A1r=r(vYt,"not"),vYt.forEach(t),L1r=r(Tme,` load the model weights. It only affects the
model\u2019s configuration. Use `),YY=n(Tme,"A",{href:!0});var FYt=s(YY);y1r=r(FYt,"from_pretrained()"),FYt.forEach(t),x1r=r(Tme," to load the model weights."),Tme.forEach(t),$1r=i(b9),T(cE.$$.fragment,b9),b9.forEach(t),k1r=i(Ql),io=n(Ql,"DIV",{class:!0});var Ia=s(io);T(kk.$$.fragment,Ia),S1r=i(Ia),bCe=n(Ia,"P",{});var TYt=s(bCe);R1r=r(TYt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),TYt.forEach(t),P1r=i(Ia),un=n(Ia,"P",{});var v9=s(un);B1r=r(v9,"The model class to instantiate is selected based on the "),vCe=n(v9,"CODE",{});var MYt=s(vCe);I1r=r(MYt,"model_type"),MYt.forEach(t),N1r=r(v9,` property of the config object (either
passed as an argument or loaded from `),FCe=n(v9,"CODE",{});var EYt=s(FCe);q1r=r(EYt,"pretrained_model_name_or_path"),EYt.forEach(t),D1r=r(v9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TCe=n(v9,"CODE",{});var CYt=s(TCe);j1r=r(CYt,"pretrained_model_name_or_path"),CYt.forEach(t),G1r=r(v9,":"),v9.forEach(t),O1r=i(Ia),U=n(Ia,"UL",{});var J=s(U);fE=n(J,"LI",{});var VWe=s(fE);MCe=n(VWe,"STRONG",{});var wYt=s(MCe);V1r=r(wYt,"albert"),wYt.forEach(t),X1r=r(VWe," \u2014 "),ZY=n(VWe,"A",{href:!0});var AYt=s(ZY);z1r=r(AYt,"AlbertForTokenClassification"),AYt.forEach(t),Q1r=r(VWe," (ALBERT model)"),VWe.forEach(t),W1r=i(J),gE=n(J,"LI",{});var XWe=s(gE);ECe=n(XWe,"STRONG",{});var LYt=s(ECe);U1r=r(LYt,"bert"),LYt.forEach(t),H1r=r(XWe," \u2014 "),KY=n(XWe,"A",{href:!0});var yYt=s(KY);J1r=r(yYt,"BertForTokenClassification"),yYt.forEach(t),Y1r=r(XWe," (BERT model)"),XWe.forEach(t),Z1r=i(J),hE=n(J,"LI",{});var zWe=s(hE);CCe=n(zWe,"STRONG",{});var xYt=s(CCe);K1r=r(xYt,"big_bird"),xYt.forEach(t),e2r=r(zWe," \u2014 "),eZ=n(zWe,"A",{href:!0});var $Yt=s(eZ);o2r=r($Yt,"BigBirdForTokenClassification"),$Yt.forEach(t),r2r=r(zWe," (BigBird model)"),zWe.forEach(t),t2r=i(J),uE=n(J,"LI",{});var QWe=s(uE);wCe=n(QWe,"STRONG",{});var kYt=s(wCe);a2r=r(kYt,"bloom"),kYt.forEach(t),n2r=r(QWe," \u2014 "),oZ=n(QWe,"A",{href:!0});var SYt=s(oZ);s2r=r(SYt,"BloomForTokenClassification"),SYt.forEach(t),l2r=r(QWe," (BLOOM model)"),QWe.forEach(t),i2r=i(J),pE=n(J,"LI",{});var WWe=s(pE);ACe=n(WWe,"STRONG",{});var RYt=s(ACe);d2r=r(RYt,"camembert"),RYt.forEach(t),m2r=r(WWe," \u2014 "),rZ=n(WWe,"A",{href:!0});var PYt=s(rZ);c2r=r(PYt,"CamembertForTokenClassification"),PYt.forEach(t),f2r=r(WWe," (CamemBERT model)"),WWe.forEach(t),g2r=i(J),_E=n(J,"LI",{});var UWe=s(_E);LCe=n(UWe,"STRONG",{});var BYt=s(LCe);h2r=r(BYt,"canine"),BYt.forEach(t),u2r=r(UWe," \u2014 "),tZ=n(UWe,"A",{href:!0});var IYt=s(tZ);p2r=r(IYt,"CanineForTokenClassification"),IYt.forEach(t),_2r=r(UWe," (CANINE model)"),UWe.forEach(t),b2r=i(J),bE=n(J,"LI",{});var HWe=s(bE);yCe=n(HWe,"STRONG",{});var NYt=s(yCe);v2r=r(NYt,"convbert"),NYt.forEach(t),F2r=r(HWe," \u2014 "),aZ=n(HWe,"A",{href:!0});var qYt=s(aZ);T2r=r(qYt,"ConvBertForTokenClassification"),qYt.forEach(t),M2r=r(HWe," (ConvBERT model)"),HWe.forEach(t),E2r=i(J),vE=n(J,"LI",{});var JWe=s(vE);xCe=n(JWe,"STRONG",{});var DYt=s(xCe);C2r=r(DYt,"data2vec-text"),DYt.forEach(t),w2r=r(JWe," \u2014 "),nZ=n(JWe,"A",{href:!0});var jYt=s(nZ);A2r=r(jYt,"Data2VecTextForTokenClassification"),jYt.forEach(t),L2r=r(JWe," (Data2VecText model)"),JWe.forEach(t),y2r=i(J),FE=n(J,"LI",{});var YWe=s(FE);$Ce=n(YWe,"STRONG",{});var GYt=s($Ce);x2r=r(GYt,"deberta"),GYt.forEach(t),$2r=r(YWe," \u2014 "),sZ=n(YWe,"A",{href:!0});var OYt=s(sZ);k2r=r(OYt,"DebertaForTokenClassification"),OYt.forEach(t),S2r=r(YWe," (DeBERTa model)"),YWe.forEach(t),R2r=i(J),TE=n(J,"LI",{});var ZWe=s(TE);kCe=n(ZWe,"STRONG",{});var VYt=s(kCe);P2r=r(VYt,"deberta-v2"),VYt.forEach(t),B2r=r(ZWe," \u2014 "),lZ=n(ZWe,"A",{href:!0});var XYt=s(lZ);I2r=r(XYt,"DebertaV2ForTokenClassification"),XYt.forEach(t),N2r=r(ZWe," (DeBERTa-v2 model)"),ZWe.forEach(t),q2r=i(J),ME=n(J,"LI",{});var KWe=s(ME);SCe=n(KWe,"STRONG",{});var zYt=s(SCe);D2r=r(zYt,"distilbert"),zYt.forEach(t),j2r=r(KWe," \u2014 "),iZ=n(KWe,"A",{href:!0});var QYt=s(iZ);G2r=r(QYt,"DistilBertForTokenClassification"),QYt.forEach(t),O2r=r(KWe," (DistilBERT model)"),KWe.forEach(t),V2r=i(J),EE=n(J,"LI",{});var eUe=s(EE);RCe=n(eUe,"STRONG",{});var WYt=s(RCe);X2r=r(WYt,"electra"),WYt.forEach(t),z2r=r(eUe," \u2014 "),dZ=n(eUe,"A",{href:!0});var UYt=s(dZ);Q2r=r(UYt,"ElectraForTokenClassification"),UYt.forEach(t),W2r=r(eUe," (ELECTRA model)"),eUe.forEach(t),U2r=i(J),CE=n(J,"LI",{});var oUe=s(CE);PCe=n(oUe,"STRONG",{});var HYt=s(PCe);H2r=r(HYt,"ernie"),HYt.forEach(t),J2r=r(oUe," \u2014 "),mZ=n(oUe,"A",{href:!0});var JYt=s(mZ);Y2r=r(JYt,"ErnieForTokenClassification"),JYt.forEach(t),Z2r=r(oUe," (ERNIE model)"),oUe.forEach(t),K2r=i(J),wE=n(J,"LI",{});var rUe=s(wE);BCe=n(rUe,"STRONG",{});var YYt=s(BCe);ebr=r(YYt,"esm"),YYt.forEach(t),obr=r(rUe," \u2014 "),cZ=n(rUe,"A",{href:!0});var ZYt=s(cZ);rbr=r(ZYt,"EsmForTokenClassification"),ZYt.forEach(t),tbr=r(rUe," (ESM model)"),rUe.forEach(t),abr=i(J),AE=n(J,"LI",{});var tUe=s(AE);ICe=n(tUe,"STRONG",{});var KYt=s(ICe);nbr=r(KYt,"flaubert"),KYt.forEach(t),sbr=r(tUe," \u2014 "),fZ=n(tUe,"A",{href:!0});var eZt=s(fZ);lbr=r(eZt,"FlaubertForTokenClassification"),eZt.forEach(t),ibr=r(tUe," (FlauBERT model)"),tUe.forEach(t),dbr=i(J),LE=n(J,"LI",{});var aUe=s(LE);NCe=n(aUe,"STRONG",{});var oZt=s(NCe);mbr=r(oZt,"fnet"),oZt.forEach(t),cbr=r(aUe," \u2014 "),gZ=n(aUe,"A",{href:!0});var rZt=s(gZ);fbr=r(rZt,"FNetForTokenClassification"),rZt.forEach(t),gbr=r(aUe," (FNet model)"),aUe.forEach(t),hbr=i(J),yE=n(J,"LI",{});var nUe=s(yE);qCe=n(nUe,"STRONG",{});var tZt=s(qCe);ubr=r(tZt,"funnel"),tZt.forEach(t),pbr=r(nUe," \u2014 "),hZ=n(nUe,"A",{href:!0});var aZt=s(hZ);_br=r(aZt,"FunnelForTokenClassification"),aZt.forEach(t),bbr=r(nUe," (Funnel Transformer model)"),nUe.forEach(t),vbr=i(J),xE=n(J,"LI",{});var sUe=s(xE);DCe=n(sUe,"STRONG",{});var nZt=s(DCe);Fbr=r(nZt,"gpt2"),nZt.forEach(t),Tbr=r(sUe," \u2014 "),uZ=n(sUe,"A",{href:!0});var sZt=s(uZ);Mbr=r(sZt,"GPT2ForTokenClassification"),sZt.forEach(t),Ebr=r(sUe," (OpenAI GPT-2 model)"),sUe.forEach(t),Cbr=i(J),$E=n(J,"LI",{});var lUe=s($E);jCe=n(lUe,"STRONG",{});var lZt=s(jCe);wbr=r(lZt,"ibert"),lZt.forEach(t),Abr=r(lUe," \u2014 "),pZ=n(lUe,"A",{href:!0});var iZt=s(pZ);Lbr=r(iZt,"IBertForTokenClassification"),iZt.forEach(t),ybr=r(lUe," (I-BERT model)"),lUe.forEach(t),xbr=i(J),kE=n(J,"LI",{});var iUe=s(kE);GCe=n(iUe,"STRONG",{});var dZt=s(GCe);$br=r(dZt,"layoutlm"),dZt.forEach(t),kbr=r(iUe," \u2014 "),_Z=n(iUe,"A",{href:!0});var mZt=s(_Z);Sbr=r(mZt,"LayoutLMForTokenClassification"),mZt.forEach(t),Rbr=r(iUe," (LayoutLM model)"),iUe.forEach(t),Pbr=i(J),SE=n(J,"LI",{});var dUe=s(SE);OCe=n(dUe,"STRONG",{});var cZt=s(OCe);Bbr=r(cZt,"layoutlmv2"),cZt.forEach(t),Ibr=r(dUe," \u2014 "),bZ=n(dUe,"A",{href:!0});var fZt=s(bZ);Nbr=r(fZt,"LayoutLMv2ForTokenClassification"),fZt.forEach(t),qbr=r(dUe," (LayoutLMv2 model)"),dUe.forEach(t),Dbr=i(J),RE=n(J,"LI",{});var mUe=s(RE);VCe=n(mUe,"STRONG",{});var gZt=s(VCe);jbr=r(gZt,"layoutlmv3"),gZt.forEach(t),Gbr=r(mUe," \u2014 "),vZ=n(mUe,"A",{href:!0});var hZt=s(vZ);Obr=r(hZt,"LayoutLMv3ForTokenClassification"),hZt.forEach(t),Vbr=r(mUe," (LayoutLMv3 model)"),mUe.forEach(t),Xbr=i(J),PE=n(J,"LI",{});var cUe=s(PE);XCe=n(cUe,"STRONG",{});var uZt=s(XCe);zbr=r(uZt,"lilt"),uZt.forEach(t),Qbr=r(cUe," \u2014 "),FZ=n(cUe,"A",{href:!0});var pZt=s(FZ);Wbr=r(pZt,"LiltForTokenClassification"),pZt.forEach(t),Ubr=r(cUe," (LiLT model)"),cUe.forEach(t),Hbr=i(J),BE=n(J,"LI",{});var fUe=s(BE);zCe=n(fUe,"STRONG",{});var _Zt=s(zCe);Jbr=r(_Zt,"longformer"),_Zt.forEach(t),Ybr=r(fUe," \u2014 "),TZ=n(fUe,"A",{href:!0});var bZt=s(TZ);Zbr=r(bZt,"LongformerForTokenClassification"),bZt.forEach(t),Kbr=r(fUe," (Longformer model)"),fUe.forEach(t),evr=i(J),IE=n(J,"LI",{});var gUe=s(IE);QCe=n(gUe,"STRONG",{});var vZt=s(QCe);ovr=r(vZt,"luke"),vZt.forEach(t),rvr=r(gUe," \u2014 "),MZ=n(gUe,"A",{href:!0});var FZt=s(MZ);tvr=r(FZt,"LukeForTokenClassification"),FZt.forEach(t),avr=r(gUe," (LUKE model)"),gUe.forEach(t),nvr=i(J),NE=n(J,"LI",{});var hUe=s(NE);WCe=n(hUe,"STRONG",{});var TZt=s(WCe);svr=r(TZt,"markuplm"),TZt.forEach(t),lvr=r(hUe," \u2014 "),EZ=n(hUe,"A",{href:!0});var MZt=s(EZ);ivr=r(MZt,"MarkupLMForTokenClassification"),MZt.forEach(t),dvr=r(hUe," (MarkupLM model)"),hUe.forEach(t),mvr=i(J),qE=n(J,"LI",{});var uUe=s(qE);UCe=n(uUe,"STRONG",{});var EZt=s(UCe);cvr=r(EZt,"megatron-bert"),EZt.forEach(t),fvr=r(uUe," \u2014 "),CZ=n(uUe,"A",{href:!0});var CZt=s(CZ);gvr=r(CZt,"MegatronBertForTokenClassification"),CZt.forEach(t),hvr=r(uUe," (Megatron-BERT model)"),uUe.forEach(t),uvr=i(J),DE=n(J,"LI",{});var pUe=s(DE);HCe=n(pUe,"STRONG",{});var wZt=s(HCe);pvr=r(wZt,"mobilebert"),wZt.forEach(t),_vr=r(pUe," \u2014 "),wZ=n(pUe,"A",{href:!0});var AZt=s(wZ);bvr=r(AZt,"MobileBertForTokenClassification"),AZt.forEach(t),vvr=r(pUe," (MobileBERT model)"),pUe.forEach(t),Fvr=i(J),jE=n(J,"LI",{});var _Ue=s(jE);JCe=n(_Ue,"STRONG",{});var LZt=s(JCe);Tvr=r(LZt,"mpnet"),LZt.forEach(t),Mvr=r(_Ue," \u2014 "),AZ=n(_Ue,"A",{href:!0});var yZt=s(AZ);Evr=r(yZt,"MPNetForTokenClassification"),yZt.forEach(t),Cvr=r(_Ue," (MPNet model)"),_Ue.forEach(t),wvr=i(J),GE=n(J,"LI",{});var bUe=s(GE);YCe=n(bUe,"STRONG",{});var xZt=s(YCe);Avr=r(xZt,"nezha"),xZt.forEach(t),Lvr=r(bUe," \u2014 "),LZ=n(bUe,"A",{href:!0});var $Zt=s(LZ);yvr=r($Zt,"NezhaForTokenClassification"),$Zt.forEach(t),xvr=r(bUe," (Nezha model)"),bUe.forEach(t),$vr=i(J),OE=n(J,"LI",{});var vUe=s(OE);ZCe=n(vUe,"STRONG",{});var kZt=s(ZCe);kvr=r(kZt,"nystromformer"),kZt.forEach(t),Svr=r(vUe," \u2014 "),yZ=n(vUe,"A",{href:!0});var SZt=s(yZ);Rvr=r(SZt,"NystromformerForTokenClassification"),SZt.forEach(t),Pvr=r(vUe," (Nystr\xF6mformer model)"),vUe.forEach(t),Bvr=i(J),VE=n(J,"LI",{});var FUe=s(VE);KCe=n(FUe,"STRONG",{});var RZt=s(KCe);Ivr=r(RZt,"qdqbert"),RZt.forEach(t),Nvr=r(FUe," \u2014 "),xZ=n(FUe,"A",{href:!0});var PZt=s(xZ);qvr=r(PZt,"QDQBertForTokenClassification"),PZt.forEach(t),Dvr=r(FUe," (QDQBert model)"),FUe.forEach(t),jvr=i(J),XE=n(J,"LI",{});var TUe=s(XE);e3e=n(TUe,"STRONG",{});var BZt=s(e3e);Gvr=r(BZt,"rembert"),BZt.forEach(t),Ovr=r(TUe," \u2014 "),$Z=n(TUe,"A",{href:!0});var IZt=s($Z);Vvr=r(IZt,"RemBertForTokenClassification"),IZt.forEach(t),Xvr=r(TUe," (RemBERT model)"),TUe.forEach(t),zvr=i(J),zE=n(J,"LI",{});var MUe=s(zE);o3e=n(MUe,"STRONG",{});var NZt=s(o3e);Qvr=r(NZt,"roberta"),NZt.forEach(t),Wvr=r(MUe," \u2014 "),kZ=n(MUe,"A",{href:!0});var qZt=s(kZ);Uvr=r(qZt,"RobertaForTokenClassification"),qZt.forEach(t),Hvr=r(MUe," (RoBERTa model)"),MUe.forEach(t),Jvr=i(J),QE=n(J,"LI",{});var EUe=s(QE);r3e=n(EUe,"STRONG",{});var DZt=s(r3e);Yvr=r(DZt,"roformer"),DZt.forEach(t),Zvr=r(EUe," \u2014 "),SZ=n(EUe,"A",{href:!0});var jZt=s(SZ);Kvr=r(jZt,"RoFormerForTokenClassification"),jZt.forEach(t),eFr=r(EUe," (RoFormer model)"),EUe.forEach(t),oFr=i(J),WE=n(J,"LI",{});var CUe=s(WE);t3e=n(CUe,"STRONG",{});var GZt=s(t3e);rFr=r(GZt,"squeezebert"),GZt.forEach(t),tFr=r(CUe," \u2014 "),RZ=n(CUe,"A",{href:!0});var OZt=s(RZ);aFr=r(OZt,"SqueezeBertForTokenClassification"),OZt.forEach(t),nFr=r(CUe," (SqueezeBERT model)"),CUe.forEach(t),sFr=i(J),UE=n(J,"LI",{});var wUe=s(UE);a3e=n(wUe,"STRONG",{});var VZt=s(a3e);lFr=r(VZt,"xlm"),VZt.forEach(t),iFr=r(wUe," \u2014 "),PZ=n(wUe,"A",{href:!0});var XZt=s(PZ);dFr=r(XZt,"XLMForTokenClassification"),XZt.forEach(t),mFr=r(wUe," (XLM model)"),wUe.forEach(t),cFr=i(J),HE=n(J,"LI",{});var AUe=s(HE);n3e=n(AUe,"STRONG",{});var zZt=s(n3e);fFr=r(zZt,"xlm-roberta"),zZt.forEach(t),gFr=r(AUe," \u2014 "),BZ=n(AUe,"A",{href:!0});var QZt=s(BZ);hFr=r(QZt,"XLMRobertaForTokenClassification"),QZt.forEach(t),uFr=r(AUe," (XLM-RoBERTa model)"),AUe.forEach(t),pFr=i(J),JE=n(J,"LI",{});var LUe=s(JE);s3e=n(LUe,"STRONG",{});var WZt=s(s3e);_Fr=r(WZt,"xlm-roberta-xl"),WZt.forEach(t),bFr=r(LUe," \u2014 "),IZ=n(LUe,"A",{href:!0});var UZt=s(IZ);vFr=r(UZt,"XLMRobertaXLForTokenClassification"),UZt.forEach(t),FFr=r(LUe," (XLM-RoBERTa-XL model)"),LUe.forEach(t),TFr=i(J),YE=n(J,"LI",{});var yUe=s(YE);l3e=n(yUe,"STRONG",{});var HZt=s(l3e);MFr=r(HZt,"xlnet"),HZt.forEach(t),EFr=r(yUe," \u2014 "),NZ=n(yUe,"A",{href:!0});var JZt=s(NZ);CFr=r(JZt,"XLNetForTokenClassification"),JZt.forEach(t),wFr=r(yUe," (XLNet model)"),yUe.forEach(t),AFr=i(J),ZE=n(J,"LI",{});var xUe=s(ZE);i3e=n(xUe,"STRONG",{});var YZt=s(i3e);LFr=r(YZt,"yoso"),YZt.forEach(t),yFr=r(xUe," \u2014 "),qZ=n(xUe,"A",{href:!0});var ZZt=s(qZ);xFr=r(ZZt,"YosoForTokenClassification"),ZZt.forEach(t),$Fr=r(xUe," (YOSO model)"),xUe.forEach(t),J.forEach(t),kFr=i(Ia),KE=n(Ia,"P",{});var $Ue=s(KE);SFr=r($Ue,"The model is set in evaluation mode by default using "),d3e=n($Ue,"CODE",{});var KZt=s(d3e);RFr=r(KZt,"model.eval()"),KZt.forEach(t),PFr=r($Ue,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),m3e=n($Ue,"CODE",{});var eKt=s(m3e);BFr=r(eKt,"model.train()"),eKt.forEach(t),$Ue.forEach(t),IFr=i(Ia),T(e4.$$.fragment,Ia),Ia.forEach(t),Ql.forEach(t),tao=i(c),lm=n(c,"H2",{class:!0});var Mso=s(lm);o4=n(Mso,"A",{id:!0,class:!0,href:!0});var oKt=s(o4);c3e=n(oKt,"SPAN",{});var rKt=s(c3e);T(Sk.$$.fragment,rKt),rKt.forEach(t),oKt.forEach(t),NFr=i(Mso),f3e=n(Mso,"SPAN",{});var tKt=s(f3e);qFr=r(tKt,"AutoModelForQuestionAnswering"),tKt.forEach(t),Mso.forEach(t),aao=i(c),Qo=n(c,"DIV",{class:!0});var Wl=s(Qo);T(Rk.$$.fragment,Wl),DFr=i(Wl),im=n(Wl,"P",{});var Mme=s(im);jFr=r(Mme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),DZ=n(Mme,"A",{href:!0});var aKt=s(DZ);GFr=r(aKt,"from_pretrained()"),aKt.forEach(t),OFr=r(Mme," class method or the "),jZ=n(Mme,"A",{href:!0});var nKt=s(jZ);VFr=r(nKt,"from_config()"),nKt.forEach(t),XFr=r(Mme,` class
method.`),Mme.forEach(t),zFr=i(Wl),Pk=n(Wl,"P",{});var Eso=s(Pk);QFr=r(Eso,"This class cannot be instantiated directly using "),g3e=n(Eso,"CODE",{});var sKt=s(g3e);WFr=r(sKt,"__init__()"),sKt.forEach(t),UFr=r(Eso," (throws an error)."),Eso.forEach(t),HFr=i(Wl),St=n(Wl,"DIV",{class:!0});var F9=s(St);T(Bk.$$.fragment,F9),JFr=i(F9),h3e=n(F9,"P",{});var lKt=s(h3e);YFr=r(lKt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),lKt.forEach(t),ZFr=i(F9),dm=n(F9,"P",{});var Eme=s(dm);KFr=r(Eme,`Note:
Loading a model from its configuration file does `),u3e=n(Eme,"STRONG",{});var iKt=s(u3e);eTr=r(iKt,"not"),iKt.forEach(t),oTr=r(Eme,` load the model weights. It only affects the
model\u2019s configuration. Use `),GZ=n(Eme,"A",{href:!0});var dKt=s(GZ);rTr=r(dKt,"from_pretrained()"),dKt.forEach(t),tTr=r(Eme," to load the model weights."),Eme.forEach(t),aTr=i(F9),T(r4.$$.fragment,F9),F9.forEach(t),nTr=i(Wl),mo=n(Wl,"DIV",{class:!0});var Na=s(mo);T(Ik.$$.fragment,Na),sTr=i(Na),p3e=n(Na,"P",{});var mKt=s(p3e);lTr=r(mKt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),mKt.forEach(t),iTr=i(Na),pn=n(Na,"P",{});var T9=s(pn);dTr=r(T9,"The model class to instantiate is selected based on the "),_3e=n(T9,"CODE",{});var cKt=s(_3e);mTr=r(cKt,"model_type"),cKt.forEach(t),cTr=r(T9,` property of the config object (either
passed as an argument or loaded from `),b3e=n(T9,"CODE",{});var fKt=s(b3e);fTr=r(fKt,"pretrained_model_name_or_path"),fKt.forEach(t),gTr=r(T9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v3e=n(T9,"CODE",{});var gKt=s(v3e);hTr=r(gKt,"pretrained_model_name_or_path"),gKt.forEach(t),uTr=r(T9,":"),T9.forEach(t),pTr=i(Na),O=n(Na,"UL",{});var X=s(O);t4=n(X,"LI",{});var kUe=s(t4);F3e=n(kUe,"STRONG",{});var hKt=s(F3e);_Tr=r(hKt,"albert"),hKt.forEach(t),bTr=r(kUe," \u2014 "),OZ=n(kUe,"A",{href:!0});var uKt=s(OZ);vTr=r(uKt,"AlbertForQuestionAnswering"),uKt.forEach(t),FTr=r(kUe," (ALBERT model)"),kUe.forEach(t),TTr=i(X),a4=n(X,"LI",{});var SUe=s(a4);T3e=n(SUe,"STRONG",{});var pKt=s(T3e);MTr=r(pKt,"bart"),pKt.forEach(t),ETr=r(SUe," \u2014 "),VZ=n(SUe,"A",{href:!0});var _Kt=s(VZ);CTr=r(_Kt,"BartForQuestionAnswering"),_Kt.forEach(t),wTr=r(SUe," (BART model)"),SUe.forEach(t),ATr=i(X),n4=n(X,"LI",{});var RUe=s(n4);M3e=n(RUe,"STRONG",{});var bKt=s(M3e);LTr=r(bKt,"bert"),bKt.forEach(t),yTr=r(RUe," \u2014 "),XZ=n(RUe,"A",{href:!0});var vKt=s(XZ);xTr=r(vKt,"BertForQuestionAnswering"),vKt.forEach(t),$Tr=r(RUe," (BERT model)"),RUe.forEach(t),kTr=i(X),s4=n(X,"LI",{});var PUe=s(s4);E3e=n(PUe,"STRONG",{});var FKt=s(E3e);STr=r(FKt,"big_bird"),FKt.forEach(t),RTr=r(PUe," \u2014 "),zZ=n(PUe,"A",{href:!0});var TKt=s(zZ);PTr=r(TKt,"BigBirdForQuestionAnswering"),TKt.forEach(t),BTr=r(PUe," (BigBird model)"),PUe.forEach(t),ITr=i(X),l4=n(X,"LI",{});var BUe=s(l4);C3e=n(BUe,"STRONG",{});var MKt=s(C3e);NTr=r(MKt,"bigbird_pegasus"),MKt.forEach(t),qTr=r(BUe," \u2014 "),QZ=n(BUe,"A",{href:!0});var EKt=s(QZ);DTr=r(EKt,"BigBirdPegasusForQuestionAnswering"),EKt.forEach(t),jTr=r(BUe," (BigBird-Pegasus model)"),BUe.forEach(t),GTr=i(X),i4=n(X,"LI",{});var IUe=s(i4);w3e=n(IUe,"STRONG",{});var CKt=s(w3e);OTr=r(CKt,"bloom"),CKt.forEach(t),VTr=r(IUe," \u2014 "),WZ=n(IUe,"A",{href:!0});var wKt=s(WZ);XTr=r(wKt,"BloomForQuestionAnswering"),wKt.forEach(t),zTr=r(IUe," (BLOOM model)"),IUe.forEach(t),QTr=i(X),d4=n(X,"LI",{});var NUe=s(d4);A3e=n(NUe,"STRONG",{});var AKt=s(A3e);WTr=r(AKt,"camembert"),AKt.forEach(t),UTr=r(NUe," \u2014 "),UZ=n(NUe,"A",{href:!0});var LKt=s(UZ);HTr=r(LKt,"CamembertForQuestionAnswering"),LKt.forEach(t),JTr=r(NUe," (CamemBERT model)"),NUe.forEach(t),YTr=i(X),m4=n(X,"LI",{});var qUe=s(m4);L3e=n(qUe,"STRONG",{});var yKt=s(L3e);ZTr=r(yKt,"canine"),yKt.forEach(t),KTr=r(qUe," \u2014 "),HZ=n(qUe,"A",{href:!0});var xKt=s(HZ);eMr=r(xKt,"CanineForQuestionAnswering"),xKt.forEach(t),oMr=r(qUe," (CANINE model)"),qUe.forEach(t),rMr=i(X),c4=n(X,"LI",{});var DUe=s(c4);y3e=n(DUe,"STRONG",{});var $Kt=s(y3e);tMr=r($Kt,"convbert"),$Kt.forEach(t),aMr=r(DUe," \u2014 "),JZ=n(DUe,"A",{href:!0});var kKt=s(JZ);nMr=r(kKt,"ConvBertForQuestionAnswering"),kKt.forEach(t),sMr=r(DUe," (ConvBERT model)"),DUe.forEach(t),lMr=i(X),f4=n(X,"LI",{});var jUe=s(f4);x3e=n(jUe,"STRONG",{});var SKt=s(x3e);iMr=r(SKt,"data2vec-text"),SKt.forEach(t),dMr=r(jUe," \u2014 "),YZ=n(jUe,"A",{href:!0});var RKt=s(YZ);mMr=r(RKt,"Data2VecTextForQuestionAnswering"),RKt.forEach(t),cMr=r(jUe," (Data2VecText model)"),jUe.forEach(t),fMr=i(X),g4=n(X,"LI",{});var GUe=s(g4);$3e=n(GUe,"STRONG",{});var PKt=s($3e);gMr=r(PKt,"deberta"),PKt.forEach(t),hMr=r(GUe," \u2014 "),ZZ=n(GUe,"A",{href:!0});var BKt=s(ZZ);uMr=r(BKt,"DebertaForQuestionAnswering"),BKt.forEach(t),pMr=r(GUe," (DeBERTa model)"),GUe.forEach(t),_Mr=i(X),h4=n(X,"LI",{});var OUe=s(h4);k3e=n(OUe,"STRONG",{});var IKt=s(k3e);bMr=r(IKt,"deberta-v2"),IKt.forEach(t),vMr=r(OUe," \u2014 "),KZ=n(OUe,"A",{href:!0});var NKt=s(KZ);FMr=r(NKt,"DebertaV2ForQuestionAnswering"),NKt.forEach(t),TMr=r(OUe," (DeBERTa-v2 model)"),OUe.forEach(t),MMr=i(X),u4=n(X,"LI",{});var VUe=s(u4);S3e=n(VUe,"STRONG",{});var qKt=s(S3e);EMr=r(qKt,"distilbert"),qKt.forEach(t),CMr=r(VUe," \u2014 "),eK=n(VUe,"A",{href:!0});var DKt=s(eK);wMr=r(DKt,"DistilBertForQuestionAnswering"),DKt.forEach(t),AMr=r(VUe," (DistilBERT model)"),VUe.forEach(t),LMr=i(X),p4=n(X,"LI",{});var XUe=s(p4);R3e=n(XUe,"STRONG",{});var jKt=s(R3e);yMr=r(jKt,"electra"),jKt.forEach(t),xMr=r(XUe," \u2014 "),oK=n(XUe,"A",{href:!0});var GKt=s(oK);$Mr=r(GKt,"ElectraForQuestionAnswering"),GKt.forEach(t),kMr=r(XUe," (ELECTRA model)"),XUe.forEach(t),SMr=i(X),_4=n(X,"LI",{});var zUe=s(_4);P3e=n(zUe,"STRONG",{});var OKt=s(P3e);RMr=r(OKt,"ernie"),OKt.forEach(t),PMr=r(zUe," \u2014 "),rK=n(zUe,"A",{href:!0});var VKt=s(rK);BMr=r(VKt,"ErnieForQuestionAnswering"),VKt.forEach(t),IMr=r(zUe," (ERNIE model)"),zUe.forEach(t),NMr=i(X),b4=n(X,"LI",{});var QUe=s(b4);B3e=n(QUe,"STRONG",{});var XKt=s(B3e);qMr=r(XKt,"flaubert"),XKt.forEach(t),DMr=r(QUe," \u2014 "),tK=n(QUe,"A",{href:!0});var zKt=s(tK);jMr=r(zKt,"FlaubertForQuestionAnsweringSimple"),zKt.forEach(t),GMr=r(QUe," (FlauBERT model)"),QUe.forEach(t),OMr=i(X),v4=n(X,"LI",{});var WUe=s(v4);I3e=n(WUe,"STRONG",{});var QKt=s(I3e);VMr=r(QKt,"fnet"),QKt.forEach(t),XMr=r(WUe," \u2014 "),aK=n(WUe,"A",{href:!0});var WKt=s(aK);zMr=r(WKt,"FNetForQuestionAnswering"),WKt.forEach(t),QMr=r(WUe," (FNet model)"),WUe.forEach(t),WMr=i(X),F4=n(X,"LI",{});var UUe=s(F4);N3e=n(UUe,"STRONG",{});var UKt=s(N3e);UMr=r(UKt,"funnel"),UKt.forEach(t),HMr=r(UUe," \u2014 "),nK=n(UUe,"A",{href:!0});var HKt=s(nK);JMr=r(HKt,"FunnelForQuestionAnswering"),HKt.forEach(t),YMr=r(UUe," (Funnel Transformer model)"),UUe.forEach(t),ZMr=i(X),T4=n(X,"LI",{});var HUe=s(T4);q3e=n(HUe,"STRONG",{});var JKt=s(q3e);KMr=r(JKt,"gptj"),JKt.forEach(t),eEr=r(HUe," \u2014 "),sK=n(HUe,"A",{href:!0});var YKt=s(sK);oEr=r(YKt,"GPTJForQuestionAnswering"),YKt.forEach(t),rEr=r(HUe," (GPT-J model)"),HUe.forEach(t),tEr=i(X),M4=n(X,"LI",{});var JUe=s(M4);D3e=n(JUe,"STRONG",{});var ZKt=s(D3e);aEr=r(ZKt,"ibert"),ZKt.forEach(t),nEr=r(JUe," \u2014 "),lK=n(JUe,"A",{href:!0});var KKt=s(lK);sEr=r(KKt,"IBertForQuestionAnswering"),KKt.forEach(t),lEr=r(JUe," (I-BERT model)"),JUe.forEach(t),iEr=i(X),E4=n(X,"LI",{});var YUe=s(E4);j3e=n(YUe,"STRONG",{});var eea=s(j3e);dEr=r(eea,"layoutlmv2"),eea.forEach(t),mEr=r(YUe," \u2014 "),iK=n(YUe,"A",{href:!0});var oea=s(iK);cEr=r(oea,"LayoutLMv2ForQuestionAnswering"),oea.forEach(t),fEr=r(YUe," (LayoutLMv2 model)"),YUe.forEach(t),gEr=i(X),C4=n(X,"LI",{});var ZUe=s(C4);G3e=n(ZUe,"STRONG",{});var rea=s(G3e);hEr=r(rea,"layoutlmv3"),rea.forEach(t),uEr=r(ZUe," \u2014 "),dK=n(ZUe,"A",{href:!0});var tea=s(dK);pEr=r(tea,"LayoutLMv3ForQuestionAnswering"),tea.forEach(t),_Er=r(ZUe," (LayoutLMv3 model)"),ZUe.forEach(t),bEr=i(X),w4=n(X,"LI",{});var KUe=s(w4);O3e=n(KUe,"STRONG",{});var aea=s(O3e);vEr=r(aea,"led"),aea.forEach(t),FEr=r(KUe," \u2014 "),mK=n(KUe,"A",{href:!0});var nea=s(mK);TEr=r(nea,"LEDForQuestionAnswering"),nea.forEach(t),MEr=r(KUe," (LED model)"),KUe.forEach(t),EEr=i(X),A4=n(X,"LI",{});var eHe=s(A4);V3e=n(eHe,"STRONG",{});var sea=s(V3e);CEr=r(sea,"lilt"),sea.forEach(t),wEr=r(eHe," \u2014 "),cK=n(eHe,"A",{href:!0});var lea=s(cK);AEr=r(lea,"LiltForQuestionAnswering"),lea.forEach(t),LEr=r(eHe," (LiLT model)"),eHe.forEach(t),yEr=i(X),L4=n(X,"LI",{});var oHe=s(L4);X3e=n(oHe,"STRONG",{});var iea=s(X3e);xEr=r(iea,"longformer"),iea.forEach(t),$Er=r(oHe," \u2014 "),fK=n(oHe,"A",{href:!0});var dea=s(fK);kEr=r(dea,"LongformerForQuestionAnswering"),dea.forEach(t),SEr=r(oHe," (Longformer model)"),oHe.forEach(t),REr=i(X),y4=n(X,"LI",{});var rHe=s(y4);z3e=n(rHe,"STRONG",{});var mea=s(z3e);PEr=r(mea,"luke"),mea.forEach(t),BEr=r(rHe," \u2014 "),gK=n(rHe,"A",{href:!0});var cea=s(gK);IEr=r(cea,"LukeForQuestionAnswering"),cea.forEach(t),NEr=r(rHe," (LUKE model)"),rHe.forEach(t),qEr=i(X),x4=n(X,"LI",{});var tHe=s(x4);Q3e=n(tHe,"STRONG",{});var fea=s(Q3e);DEr=r(fea,"lxmert"),fea.forEach(t),jEr=r(tHe," \u2014 "),hK=n(tHe,"A",{href:!0});var gea=s(hK);GEr=r(gea,"LxmertForQuestionAnswering"),gea.forEach(t),OEr=r(tHe," (LXMERT model)"),tHe.forEach(t),VEr=i(X),$4=n(X,"LI",{});var aHe=s($4);W3e=n(aHe,"STRONG",{});var hea=s(W3e);XEr=r(hea,"markuplm"),hea.forEach(t),zEr=r(aHe," \u2014 "),uK=n(aHe,"A",{href:!0});var uea=s(uK);QEr=r(uea,"MarkupLMForQuestionAnswering"),uea.forEach(t),WEr=r(aHe," (MarkupLM model)"),aHe.forEach(t),UEr=i(X),k4=n(X,"LI",{});var nHe=s(k4);U3e=n(nHe,"STRONG",{});var pea=s(U3e);HEr=r(pea,"mbart"),pea.forEach(t),JEr=r(nHe," \u2014 "),pK=n(nHe,"A",{href:!0});var _ea=s(pK);YEr=r(_ea,"MBartForQuestionAnswering"),_ea.forEach(t),ZEr=r(nHe," (mBART model)"),nHe.forEach(t),KEr=i(X),S4=n(X,"LI",{});var sHe=s(S4);H3e=n(sHe,"STRONG",{});var bea=s(H3e);e4r=r(bea,"megatron-bert"),bea.forEach(t),o4r=r(sHe," \u2014 "),_K=n(sHe,"A",{href:!0});var vea=s(_K);r4r=r(vea,"MegatronBertForQuestionAnswering"),vea.forEach(t),t4r=r(sHe," (Megatron-BERT model)"),sHe.forEach(t),a4r=i(X),R4=n(X,"LI",{});var lHe=s(R4);J3e=n(lHe,"STRONG",{});var Fea=s(J3e);n4r=r(Fea,"mobilebert"),Fea.forEach(t),s4r=r(lHe," \u2014 "),bK=n(lHe,"A",{href:!0});var Tea=s(bK);l4r=r(Tea,"MobileBertForQuestionAnswering"),Tea.forEach(t),i4r=r(lHe," (MobileBERT model)"),lHe.forEach(t),d4r=i(X),P4=n(X,"LI",{});var iHe=s(P4);Y3e=n(iHe,"STRONG",{});var Mea=s(Y3e);m4r=r(Mea,"mpnet"),Mea.forEach(t),c4r=r(iHe," \u2014 "),vK=n(iHe,"A",{href:!0});var Eea=s(vK);f4r=r(Eea,"MPNetForQuestionAnswering"),Eea.forEach(t),g4r=r(iHe," (MPNet model)"),iHe.forEach(t),h4r=i(X),B4=n(X,"LI",{});var dHe=s(B4);Z3e=n(dHe,"STRONG",{});var Cea=s(Z3e);u4r=r(Cea,"mvp"),Cea.forEach(t),p4r=r(dHe," \u2014 "),FK=n(dHe,"A",{href:!0});var wea=s(FK);_4r=r(wea,"MvpForQuestionAnswering"),wea.forEach(t),b4r=r(dHe," (MVP model)"),dHe.forEach(t),v4r=i(X),I4=n(X,"LI",{});var mHe=s(I4);K3e=n(mHe,"STRONG",{});var Aea=s(K3e);F4r=r(Aea,"nezha"),Aea.forEach(t),T4r=r(mHe," \u2014 "),TK=n(mHe,"A",{href:!0});var Lea=s(TK);M4r=r(Lea,"NezhaForQuestionAnswering"),Lea.forEach(t),E4r=r(mHe," (Nezha model)"),mHe.forEach(t),C4r=i(X),N4=n(X,"LI",{});var cHe=s(N4);e5e=n(cHe,"STRONG",{});var yea=s(e5e);w4r=r(yea,"nystromformer"),yea.forEach(t),A4r=r(cHe," \u2014 "),MK=n(cHe,"A",{href:!0});var xea=s(MK);L4r=r(xea,"NystromformerForQuestionAnswering"),xea.forEach(t),y4r=r(cHe," (Nystr\xF6mformer model)"),cHe.forEach(t),x4r=i(X),q4=n(X,"LI",{});var fHe=s(q4);o5e=n(fHe,"STRONG",{});var $ea=s(o5e);$4r=r($ea,"opt"),$ea.forEach(t),k4r=r(fHe," \u2014 "),EK=n(fHe,"A",{href:!0});var kea=s(EK);S4r=r(kea,"OPTForQuestionAnswering"),kea.forEach(t),R4r=r(fHe," (OPT model)"),fHe.forEach(t),P4r=i(X),D4=n(X,"LI",{});var gHe=s(D4);r5e=n(gHe,"STRONG",{});var Sea=s(r5e);B4r=r(Sea,"qdqbert"),Sea.forEach(t),I4r=r(gHe," \u2014 "),CK=n(gHe,"A",{href:!0});var Rea=s(CK);N4r=r(Rea,"QDQBertForQuestionAnswering"),Rea.forEach(t),q4r=r(gHe," (QDQBert model)"),gHe.forEach(t),D4r=i(X),j4=n(X,"LI",{});var hHe=s(j4);t5e=n(hHe,"STRONG",{});var Pea=s(t5e);j4r=r(Pea,"reformer"),Pea.forEach(t),G4r=r(hHe," \u2014 "),wK=n(hHe,"A",{href:!0});var Bea=s(wK);O4r=r(Bea,"ReformerForQuestionAnswering"),Bea.forEach(t),V4r=r(hHe," (Reformer model)"),hHe.forEach(t),X4r=i(X),G4=n(X,"LI",{});var uHe=s(G4);a5e=n(uHe,"STRONG",{});var Iea=s(a5e);z4r=r(Iea,"rembert"),Iea.forEach(t),Q4r=r(uHe," \u2014 "),AK=n(uHe,"A",{href:!0});var Nea=s(AK);W4r=r(Nea,"RemBertForQuestionAnswering"),Nea.forEach(t),U4r=r(uHe," (RemBERT model)"),uHe.forEach(t),H4r=i(X),O4=n(X,"LI",{});var pHe=s(O4);n5e=n(pHe,"STRONG",{});var qea=s(n5e);J4r=r(qea,"roberta"),qea.forEach(t),Y4r=r(pHe," \u2014 "),LK=n(pHe,"A",{href:!0});var Dea=s(LK);Z4r=r(Dea,"RobertaForQuestionAnswering"),Dea.forEach(t),K4r=r(pHe," (RoBERTa model)"),pHe.forEach(t),eCr=i(X),V4=n(X,"LI",{});var _He=s(V4);s5e=n(_He,"STRONG",{});var jea=s(s5e);oCr=r(jea,"roformer"),jea.forEach(t),rCr=r(_He," \u2014 "),yK=n(_He,"A",{href:!0});var Gea=s(yK);tCr=r(Gea,"RoFormerForQuestionAnswering"),Gea.forEach(t),aCr=r(_He," (RoFormer model)"),_He.forEach(t),nCr=i(X),X4=n(X,"LI",{});var bHe=s(X4);l5e=n(bHe,"STRONG",{});var Oea=s(l5e);sCr=r(Oea,"splinter"),Oea.forEach(t),lCr=r(bHe," \u2014 "),xK=n(bHe,"A",{href:!0});var Vea=s(xK);iCr=r(Vea,"SplinterForQuestionAnswering"),Vea.forEach(t),dCr=r(bHe," (Splinter model)"),bHe.forEach(t),mCr=i(X),z4=n(X,"LI",{});var vHe=s(z4);i5e=n(vHe,"STRONG",{});var Xea=s(i5e);cCr=r(Xea,"squeezebert"),Xea.forEach(t),fCr=r(vHe," \u2014 "),$K=n(vHe,"A",{href:!0});var zea=s($K);gCr=r(zea,"SqueezeBertForQuestionAnswering"),zea.forEach(t),hCr=r(vHe," (SqueezeBERT model)"),vHe.forEach(t),uCr=i(X),Q4=n(X,"LI",{});var FHe=s(Q4);d5e=n(FHe,"STRONG",{});var Qea=s(d5e);pCr=r(Qea,"xlm"),Qea.forEach(t),_Cr=r(FHe," \u2014 "),kK=n(FHe,"A",{href:!0});var Wea=s(kK);bCr=r(Wea,"XLMForQuestionAnsweringSimple"),Wea.forEach(t),vCr=r(FHe," (XLM model)"),FHe.forEach(t),FCr=i(X),W4=n(X,"LI",{});var THe=s(W4);m5e=n(THe,"STRONG",{});var Uea=s(m5e);TCr=r(Uea,"xlm-roberta"),Uea.forEach(t),MCr=r(THe," \u2014 "),SK=n(THe,"A",{href:!0});var Hea=s(SK);ECr=r(Hea,"XLMRobertaForQuestionAnswering"),Hea.forEach(t),CCr=r(THe," (XLM-RoBERTa model)"),THe.forEach(t),wCr=i(X),U4=n(X,"LI",{});var MHe=s(U4);c5e=n(MHe,"STRONG",{});var Jea=s(c5e);ACr=r(Jea,"xlm-roberta-xl"),Jea.forEach(t),LCr=r(MHe," \u2014 "),RK=n(MHe,"A",{href:!0});var Yea=s(RK);yCr=r(Yea,"XLMRobertaXLForQuestionAnswering"),Yea.forEach(t),xCr=r(MHe," (XLM-RoBERTa-XL model)"),MHe.forEach(t),$Cr=i(X),H4=n(X,"LI",{});var EHe=s(H4);f5e=n(EHe,"STRONG",{});var Zea=s(f5e);kCr=r(Zea,"xlnet"),Zea.forEach(t),SCr=r(EHe," \u2014 "),PK=n(EHe,"A",{href:!0});var Kea=s(PK);RCr=r(Kea,"XLNetForQuestionAnsweringSimple"),Kea.forEach(t),PCr=r(EHe," (XLNet model)"),EHe.forEach(t),BCr=i(X),J4=n(X,"LI",{});var CHe=s(J4);g5e=n(CHe,"STRONG",{});var eoa=s(g5e);ICr=r(eoa,"yoso"),eoa.forEach(t),NCr=r(CHe," \u2014 "),BK=n(CHe,"A",{href:!0});var ooa=s(BK);qCr=r(ooa,"YosoForQuestionAnswering"),ooa.forEach(t),DCr=r(CHe," (YOSO model)"),CHe.forEach(t),X.forEach(t),jCr=i(Na),Y4=n(Na,"P",{});var wHe=s(Y4);GCr=r(wHe,"The model is set in evaluation mode by default using "),h5e=n(wHe,"CODE",{});var roa=s(h5e);OCr=r(roa,"model.eval()"),roa.forEach(t),VCr=r(wHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),u5e=n(wHe,"CODE",{});var toa=s(u5e);XCr=r(toa,"model.train()"),toa.forEach(t),wHe.forEach(t),zCr=i(Na),T(Z4.$$.fragment,Na),Na.forEach(t),Wl.forEach(t),nao=i(c),mm=n(c,"H2",{class:!0});var Cso=s(mm);K4=n(Cso,"A",{id:!0,class:!0,href:!0});var aoa=s(K4);p5e=n(aoa,"SPAN",{});var noa=s(p5e);T(Nk.$$.fragment,noa),noa.forEach(t),aoa.forEach(t),QCr=i(Cso),_5e=n(Cso,"SPAN",{});var soa=s(_5e);WCr=r(soa,"AutoModelForTableQuestionAnswering"),soa.forEach(t),Cso.forEach(t),sao=i(c),Wo=n(c,"DIV",{class:!0});var Ul=s(Wo);T(qk.$$.fragment,Ul),UCr=i(Ul),cm=n(Ul,"P",{});var Cme=s(cm);HCr=r(Cme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),IK=n(Cme,"A",{href:!0});var loa=s(IK);JCr=r(loa,"from_pretrained()"),loa.forEach(t),YCr=r(Cme," class method or the "),NK=n(Cme,"A",{href:!0});var ioa=s(NK);ZCr=r(ioa,"from_config()"),ioa.forEach(t),KCr=r(Cme,` class
method.`),Cme.forEach(t),e3r=i(Ul),Dk=n(Ul,"P",{});var wso=s(Dk);o3r=r(wso,"This class cannot be instantiated directly using "),b5e=n(wso,"CODE",{});var doa=s(b5e);r3r=r(doa,"__init__()"),doa.forEach(t),t3r=r(wso," (throws an error)."),wso.forEach(t),a3r=i(Ul),Rt=n(Ul,"DIV",{class:!0});var M9=s(Rt);T(jk.$$.fragment,M9),n3r=i(M9),v5e=n(M9,"P",{});var moa=s(v5e);s3r=r(moa,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),moa.forEach(t),l3r=i(M9),fm=n(M9,"P",{});var wme=s(fm);i3r=r(wme,`Note:
Loading a model from its configuration file does `),F5e=n(wme,"STRONG",{});var coa=s(F5e);d3r=r(coa,"not"),coa.forEach(t),m3r=r(wme,` load the model weights. It only affects the
model\u2019s configuration. Use `),qK=n(wme,"A",{href:!0});var foa=s(qK);c3r=r(foa,"from_pretrained()"),foa.forEach(t),f3r=r(wme," to load the model weights."),wme.forEach(t),g3r=i(M9),T(eC.$$.fragment,M9),M9.forEach(t),h3r=i(Ul),co=n(Ul,"DIV",{class:!0});var qa=s(co);T(Gk.$$.fragment,qa),u3r=i(qa),T5e=n(qa,"P",{});var goa=s(T5e);p3r=r(goa,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),goa.forEach(t),_3r=i(qa),_n=n(qa,"P",{});var E9=s(_n);b3r=r(E9,"The model class to instantiate is selected based on the "),M5e=n(E9,"CODE",{});var hoa=s(M5e);v3r=r(hoa,"model_type"),hoa.forEach(t),F3r=r(E9,` property of the config object (either
passed as an argument or loaded from `),E5e=n(E9,"CODE",{});var uoa=s(E5e);T3r=r(uoa,"pretrained_model_name_or_path"),uoa.forEach(t),M3r=r(E9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C5e=n(E9,"CODE",{});var poa=s(C5e);E3r=r(poa,"pretrained_model_name_or_path"),poa.forEach(t),C3r=r(E9,":"),E9.forEach(t),w3r=i(qa),w5e=n(qa,"UL",{});var _oa=s(w5e);oC=n(_oa,"LI",{});var AHe=s(oC);A5e=n(AHe,"STRONG",{});var boa=s(A5e);A3r=r(boa,"tapas"),boa.forEach(t),L3r=r(AHe," \u2014 "),DK=n(AHe,"A",{href:!0});var voa=s(DK);y3r=r(voa,"TapasForQuestionAnswering"),voa.forEach(t),x3r=r(AHe," (TAPAS model)"),AHe.forEach(t),_oa.forEach(t),$3r=i(qa),rC=n(qa,"P",{});var LHe=s(rC);k3r=r(LHe,"The model is set in evaluation mode by default using "),L5e=n(LHe,"CODE",{});var Foa=s(L5e);S3r=r(Foa,"model.eval()"),Foa.forEach(t),R3r=r(LHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),y5e=n(LHe,"CODE",{});var Toa=s(y5e);P3r=r(Toa,"model.train()"),Toa.forEach(t),LHe.forEach(t),B3r=i(qa),T(tC.$$.fragment,qa),qa.forEach(t),Ul.forEach(t),lao=i(c),gm=n(c,"H2",{class:!0});var Aso=s(gm);aC=n(Aso,"A",{id:!0,class:!0,href:!0});var Moa=s(aC);x5e=n(Moa,"SPAN",{});var Eoa=s(x5e);T(Ok.$$.fragment,Eoa),Eoa.forEach(t),Moa.forEach(t),I3r=i(Aso),$5e=n(Aso,"SPAN",{});var Coa=s($5e);N3r=r(Coa,"AutoModelForDocumentQuestionAnswering"),Coa.forEach(t),Aso.forEach(t),iao=i(c),Uo=n(c,"DIV",{class:!0});var Hl=s(Uo);T(Vk.$$.fragment,Hl),q3r=i(Hl),hm=n(Hl,"P",{});var Ame=s(hm);D3r=r(Ame,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),jK=n(Ame,"A",{href:!0});var woa=s(jK);j3r=r(woa,"from_pretrained()"),woa.forEach(t),G3r=r(Ame," class method or the "),GK=n(Ame,"A",{href:!0});var Aoa=s(GK);O3r=r(Aoa,"from_config()"),Aoa.forEach(t),V3r=r(Ame,` class
method.`),Ame.forEach(t),X3r=i(Hl),Xk=n(Hl,"P",{});var Lso=s(Xk);z3r=r(Lso,"This class cannot be instantiated directly using "),k5e=n(Lso,"CODE",{});var Loa=s(k5e);Q3r=r(Loa,"__init__()"),Loa.forEach(t),W3r=r(Lso," (throws an error)."),Lso.forEach(t),U3r=i(Hl),Pt=n(Hl,"DIV",{class:!0});var C9=s(Pt);T(zk.$$.fragment,C9),H3r=i(C9),S5e=n(C9,"P",{});var yoa=s(S5e);J3r=r(yoa,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),yoa.forEach(t),Y3r=i(C9),um=n(C9,"P",{});var Lme=s(um);Z3r=r(Lme,`Note:
Loading a model from its configuration file does `),R5e=n(Lme,"STRONG",{});var xoa=s(R5e);K3r=r(xoa,"not"),xoa.forEach(t),e5r=r(Lme,` load the model weights. It only affects the
model\u2019s configuration. Use `),OK=n(Lme,"A",{href:!0});var $oa=s(OK);o5r=r($oa,"from_pretrained()"),$oa.forEach(t),r5r=r(Lme," to load the model weights."),Lme.forEach(t),t5r=i(C9),T(nC.$$.fragment,C9),C9.forEach(t),a5r=i(Hl),fo=n(Hl,"DIV",{class:!0});var Da=s(fo);T(Qk.$$.fragment,Da),n5r=i(Da),P5e=n(Da,"P",{});var koa=s(P5e);s5r=r(koa,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),koa.forEach(t),l5r=i(Da),bn=n(Da,"P",{});var w9=s(bn);i5r=r(w9,"The model class to instantiate is selected based on the "),B5e=n(w9,"CODE",{});var Soa=s(B5e);d5r=r(Soa,"model_type"),Soa.forEach(t),m5r=r(w9,` property of the config object (either
passed as an argument or loaded from `),I5e=n(w9,"CODE",{});var Roa=s(I5e);c5r=r(Roa,"pretrained_model_name_or_path"),Roa.forEach(t),f5r=r(w9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N5e=n(w9,"CODE",{});var Poa=s(N5e);g5r=r(Poa,"pretrained_model_name_or_path"),Poa.forEach(t),h5r=r(w9,":"),w9.forEach(t),u5r=i(Da),pm=n(Da,"UL",{});var yme=s(pm);sC=n(yme,"LI",{});var yHe=s(sC);q5e=n(yHe,"STRONG",{});var Boa=s(q5e);p5r=r(Boa,"layoutlm"),Boa.forEach(t),_5r=r(yHe," \u2014 "),VK=n(yHe,"A",{href:!0});var Ioa=s(VK);b5r=r(Ioa,"LayoutLMForQuestionAnswering"),Ioa.forEach(t),v5r=r(yHe," (LayoutLM model)"),yHe.forEach(t),F5r=i(yme),lC=n(yme,"LI",{});var xHe=s(lC);D5e=n(xHe,"STRONG",{});var Noa=s(D5e);T5r=r(Noa,"layoutlmv2"),Noa.forEach(t),M5r=r(xHe," \u2014 "),XK=n(xHe,"A",{href:!0});var qoa=s(XK);E5r=r(qoa,"LayoutLMv2ForQuestionAnswering"),qoa.forEach(t),C5r=r(xHe," (LayoutLMv2 model)"),xHe.forEach(t),w5r=i(yme),iC=n(yme,"LI",{});var $He=s(iC);j5e=n($He,"STRONG",{});var Doa=s(j5e);A5r=r(Doa,"layoutlmv3"),Doa.forEach(t),L5r=r($He," \u2014 "),zK=n($He,"A",{href:!0});var joa=s(zK);y5r=r(joa,"LayoutLMv3ForQuestionAnswering"),joa.forEach(t),x5r=r($He," (LayoutLMv3 model)"),$He.forEach(t),yme.forEach(t),$5r=i(Da),dC=n(Da,"P",{});var kHe=s(dC);k5r=r(kHe,"The model is set in evaluation mode by default using "),G5e=n(kHe,"CODE",{});var Goa=s(G5e);S5r=r(Goa,"model.eval()"),Goa.forEach(t),R5r=r(kHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),O5e=n(kHe,"CODE",{});var Ooa=s(O5e);P5r=r(Ooa,"model.train()"),Ooa.forEach(t),kHe.forEach(t),B5r=i(Da),T(mC.$$.fragment,Da),Da.forEach(t),Hl.forEach(t),dao=i(c),_m=n(c,"H2",{class:!0});var yso=s(_m);cC=n(yso,"A",{id:!0,class:!0,href:!0});var Voa=s(cC);V5e=n(Voa,"SPAN",{});var Xoa=s(V5e);T(Wk.$$.fragment,Xoa),Xoa.forEach(t),Voa.forEach(t),I5r=i(yso),X5e=n(yso,"SPAN",{});var zoa=s(X5e);N5r=r(zoa,"AutoModelForImageClassification"),zoa.forEach(t),yso.forEach(t),mao=i(c),Ho=n(c,"DIV",{class:!0});var Jl=s(Ho);T(Uk.$$.fragment,Jl),q5r=i(Jl),bm=n(Jl,"P",{});var xme=s(bm);D5r=r(xme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),QK=n(xme,"A",{href:!0});var Qoa=s(QK);j5r=r(Qoa,"from_pretrained()"),Qoa.forEach(t),G5r=r(xme," class method or the "),WK=n(xme,"A",{href:!0});var Woa=s(WK);O5r=r(Woa,"from_config()"),Woa.forEach(t),V5r=r(xme,` class
method.`),xme.forEach(t),X5r=i(Jl),Hk=n(Jl,"P",{});var xso=s(Hk);z5r=r(xso,"This class cannot be instantiated directly using "),z5e=n(xso,"CODE",{});var Uoa=s(z5e);Q5r=r(Uoa,"__init__()"),Uoa.forEach(t),W5r=r(xso," (throws an error)."),xso.forEach(t),U5r=i(Jl),Bt=n(Jl,"DIV",{class:!0});var A9=s(Bt);T(Jk.$$.fragment,A9),H5r=i(A9),Q5e=n(A9,"P",{});var Hoa=s(Q5e);J5r=r(Hoa,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Hoa.forEach(t),Y5r=i(A9),vm=n(A9,"P",{});var $me=s(vm);Z5r=r($me,`Note:
Loading a model from its configuration file does `),W5e=n($me,"STRONG",{});var Joa=s(W5e);K5r=r(Joa,"not"),Joa.forEach(t),e0r=r($me,` load the model weights. It only affects the
model\u2019s configuration. Use `),UK=n($me,"A",{href:!0});var Yoa=s(UK);o0r=r(Yoa,"from_pretrained()"),Yoa.forEach(t),r0r=r($me," to load the model weights."),$me.forEach(t),t0r=i(A9),T(fC.$$.fragment,A9),A9.forEach(t),a0r=i(Jl),go=n(Jl,"DIV",{class:!0});var ja=s(go);T(Yk.$$.fragment,ja),n0r=i(ja),U5e=n(ja,"P",{});var Zoa=s(U5e);s0r=r(Zoa,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Zoa.forEach(t),l0r=i(ja),vn=n(ja,"P",{});var L9=s(vn);i0r=r(L9,"The model class to instantiate is selected based on the "),H5e=n(L9,"CODE",{});var Koa=s(H5e);d0r=r(Koa,"model_type"),Koa.forEach(t),m0r=r(L9,` property of the config object (either
passed as an argument or loaded from `),J5e=n(L9,"CODE",{});var era=s(J5e);c0r=r(era,"pretrained_model_name_or_path"),era.forEach(t),f0r=r(L9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Y5e=n(L9,"CODE",{});var ora=s(Y5e);g0r=r(ora,"pretrained_model_name_or_path"),ora.forEach(t),h0r=r(L9,":"),L9.forEach(t),u0r=i(ja),be=n(ja,"UL",{});var Fe=s(be);gC=n(Fe,"LI",{});var SHe=s(gC);Z5e=n(SHe,"STRONG",{});var rra=s(Z5e);p0r=r(rra,"beit"),rra.forEach(t),_0r=r(SHe," \u2014 "),HK=n(SHe,"A",{href:!0});var tra=s(HK);b0r=r(tra,"BeitForImageClassification"),tra.forEach(t),v0r=r(SHe," (BEiT model)"),SHe.forEach(t),F0r=i(Fe),hC=n(Fe,"LI",{});var RHe=s(hC);K5e=n(RHe,"STRONG",{});var ara=s(K5e);T0r=r(ara,"convnext"),ara.forEach(t),M0r=r(RHe," \u2014 "),JK=n(RHe,"A",{href:!0});var nra=s(JK);E0r=r(nra,"ConvNextForImageClassification"),nra.forEach(t),C0r=r(RHe," (ConvNeXT model)"),RHe.forEach(t),w0r=i(Fe),uC=n(Fe,"LI",{});var PHe=s(uC);e0e=n(PHe,"STRONG",{});var sra=s(e0e);A0r=r(sra,"cvt"),sra.forEach(t),L0r=r(PHe," \u2014 "),YK=n(PHe,"A",{href:!0});var lra=s(YK);y0r=r(lra,"CvtForImageClassification"),lra.forEach(t),x0r=r(PHe," (CvT model)"),PHe.forEach(t),$0r=i(Fe),pC=n(Fe,"LI",{});var BHe=s(pC);o0e=n(BHe,"STRONG",{});var ira=s(o0e);k0r=r(ira,"data2vec-vision"),ira.forEach(t),S0r=r(BHe," \u2014 "),ZK=n(BHe,"A",{href:!0});var dra=s(ZK);R0r=r(dra,"Data2VecVisionForImageClassification"),dra.forEach(t),P0r=r(BHe," (Data2VecVision model)"),BHe.forEach(t),B0r=i(Fe),xl=n(Fe,"LI",{});var _N=s(xl);r0e=n(_N,"STRONG",{});var mra=s(r0e);I0r=r(mra,"deit"),mra.forEach(t),N0r=r(_N," \u2014 "),KK=n(_N,"A",{href:!0});var cra=s(KK);q0r=r(cra,"DeiTForImageClassification"),cra.forEach(t),D0r=r(_N," or "),eee=n(_N,"A",{href:!0});var fra=s(eee);j0r=r(fra,"DeiTForImageClassificationWithTeacher"),fra.forEach(t),G0r=r(_N," (DeiT model)"),_N.forEach(t),O0r=i(Fe),_C=n(Fe,"LI",{});var IHe=s(_C);t0e=n(IHe,"STRONG",{});var gra=s(t0e);V0r=r(gra,"imagegpt"),gra.forEach(t),X0r=r(IHe," \u2014 "),oee=n(IHe,"A",{href:!0});var hra=s(oee);z0r=r(hra,"ImageGPTForImageClassification"),hra.forEach(t),Q0r=r(IHe," (ImageGPT model)"),IHe.forEach(t),W0r=i(Fe),$l=n(Fe,"LI",{});var bN=s($l);a0e=n(bN,"STRONG",{});var ura=s(a0e);U0r=r(ura,"levit"),ura.forEach(t),H0r=r(bN," \u2014 "),ree=n(bN,"A",{href:!0});var pra=s(ree);J0r=r(pra,"LevitForImageClassification"),pra.forEach(t),Y0r=r(bN," or "),tee=n(bN,"A",{href:!0});var _ra=s(tee);Z0r=r(_ra,"LevitForImageClassificationWithTeacher"),_ra.forEach(t),K0r=r(bN," (LeViT model)"),bN.forEach(t),ewr=i(Fe),bC=n(Fe,"LI",{});var NHe=s(bC);n0e=n(NHe,"STRONG",{});var bra=s(n0e);owr=r(bra,"mobilevit"),bra.forEach(t),rwr=r(NHe," \u2014 "),aee=n(NHe,"A",{href:!0});var vra=s(aee);twr=r(vra,"MobileViTForImageClassification"),vra.forEach(t),awr=r(NHe," (MobileViT model)"),NHe.forEach(t),nwr=i(Fe),It=n(Fe,"LI",{});var Vf=s(It);s0e=n(Vf,"STRONG",{});var Fra=s(s0e);swr=r(Fra,"perceiver"),Fra.forEach(t),lwr=r(Vf," \u2014 "),nee=n(Vf,"A",{href:!0});var Tra=s(nee);iwr=r(Tra,"PerceiverForImageClassificationLearned"),Tra.forEach(t),dwr=r(Vf," or "),see=n(Vf,"A",{href:!0});var Mra=s(see);mwr=r(Mra,"PerceiverForImageClassificationFourier"),Mra.forEach(t),cwr=r(Vf," or "),lee=n(Vf,"A",{href:!0});var Era=s(lee);fwr=r(Era,"PerceiverForImageClassificationConvProcessing"),Era.forEach(t),gwr=r(Vf," (Perceiver model)"),Vf.forEach(t),hwr=i(Fe),vC=n(Fe,"LI",{});var qHe=s(vC);l0e=n(qHe,"STRONG",{});var Cra=s(l0e);uwr=r(Cra,"poolformer"),Cra.forEach(t),pwr=r(qHe," \u2014 "),iee=n(qHe,"A",{href:!0});var wra=s(iee);_wr=r(wra,"PoolFormerForImageClassification"),wra.forEach(t),bwr=r(qHe," (PoolFormer model)"),qHe.forEach(t),vwr=i(Fe),FC=n(Fe,"LI",{});var DHe=s(FC);i0e=n(DHe,"STRONG",{});var Ara=s(i0e);Fwr=r(Ara,"regnet"),Ara.forEach(t),Twr=r(DHe," \u2014 "),dee=n(DHe,"A",{href:!0});var Lra=s(dee);Mwr=r(Lra,"RegNetForImageClassification"),Lra.forEach(t),Ewr=r(DHe," (RegNet model)"),DHe.forEach(t),Cwr=i(Fe),TC=n(Fe,"LI",{});var jHe=s(TC);d0e=n(jHe,"STRONG",{});var yra=s(d0e);wwr=r(yra,"resnet"),yra.forEach(t),Awr=r(jHe," \u2014 "),mee=n(jHe,"A",{href:!0});var xra=s(mee);Lwr=r(xra,"ResNetForImageClassification"),xra.forEach(t),ywr=r(jHe," (ResNet model)"),jHe.forEach(t),xwr=i(Fe),MC=n(Fe,"LI",{});var GHe=s(MC);m0e=n(GHe,"STRONG",{});var $ra=s(m0e);$wr=r($ra,"segformer"),$ra.forEach(t),kwr=r(GHe," \u2014 "),cee=n(GHe,"A",{href:!0});var kra=s(cee);Swr=r(kra,"SegformerForImageClassification"),kra.forEach(t),Rwr=r(GHe," (SegFormer model)"),GHe.forEach(t),Pwr=i(Fe),EC=n(Fe,"LI",{});var OHe=s(EC);c0e=n(OHe,"STRONG",{});var Sra=s(c0e);Bwr=r(Sra,"swin"),Sra.forEach(t),Iwr=r(OHe," \u2014 "),fee=n(OHe,"A",{href:!0});var Rra=s(fee);Nwr=r(Rra,"SwinForImageClassification"),Rra.forEach(t),qwr=r(OHe," (Swin Transformer model)"),OHe.forEach(t),Dwr=i(Fe),CC=n(Fe,"LI",{});var VHe=s(CC);f0e=n(VHe,"STRONG",{});var Pra=s(f0e);jwr=r(Pra,"swinv2"),Pra.forEach(t),Gwr=r(VHe," \u2014 "),gee=n(VHe,"A",{href:!0});var Bra=s(gee);Owr=r(Bra,"Swinv2ForImageClassification"),Bra.forEach(t),Vwr=r(VHe," (Swin Transformer V2 model)"),VHe.forEach(t),Xwr=i(Fe),wC=n(Fe,"LI",{});var XHe=s(wC);g0e=n(XHe,"STRONG",{});var Ira=s(g0e);zwr=r(Ira,"van"),Ira.forEach(t),Qwr=r(XHe," \u2014 "),hee=n(XHe,"A",{href:!0});var Nra=s(hee);Wwr=r(Nra,"VanForImageClassification"),Nra.forEach(t),Uwr=r(XHe," (VAN model)"),XHe.forEach(t),Hwr=i(Fe),AC=n(Fe,"LI",{});var zHe=s(AC);h0e=n(zHe,"STRONG",{});var qra=s(h0e);Jwr=r(qra,"vit"),qra.forEach(t),Ywr=r(zHe," \u2014 "),uee=n(zHe,"A",{href:!0});var Dra=s(uee);Zwr=r(Dra,"ViTForImageClassification"),Dra.forEach(t),Kwr=r(zHe," (ViT model)"),zHe.forEach(t),eAr=i(Fe),LC=n(Fe,"LI",{});var QHe=s(LC);u0e=n(QHe,"STRONG",{});var jra=s(u0e);oAr=r(jra,"vit_msn"),jra.forEach(t),rAr=r(QHe," \u2014 "),pee=n(QHe,"A",{href:!0});var Gra=s(pee);tAr=r(Gra,"ViTMSNForImageClassification"),Gra.forEach(t),aAr=r(QHe," (ViTMSN model)"),QHe.forEach(t),Fe.forEach(t),nAr=i(ja),yC=n(ja,"P",{});var WHe=s(yC);sAr=r(WHe,"The model is set in evaluation mode by default using "),p0e=n(WHe,"CODE",{});var Ora=s(p0e);lAr=r(Ora,"model.eval()"),Ora.forEach(t),iAr=r(WHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_0e=n(WHe,"CODE",{});var Vra=s(_0e);dAr=r(Vra,"model.train()"),Vra.forEach(t),WHe.forEach(t),mAr=i(ja),T(xC.$$.fragment,ja),ja.forEach(t),Jl.forEach(t),cao=i(c),Fm=n(c,"H2",{class:!0});var $so=s(Fm);$C=n($so,"A",{id:!0,class:!0,href:!0});var Xra=s($C);b0e=n(Xra,"SPAN",{});var zra=s(b0e);T(Zk.$$.fragment,zra),zra.forEach(t),Xra.forEach(t),cAr=i($so),v0e=n($so,"SPAN",{});var Qra=s(v0e);fAr=r(Qra,"AutoModelForVideoClassification"),Qra.forEach(t),$so.forEach(t),fao=i(c),Jo=n(c,"DIV",{class:!0});var Yl=s(Jo);T(Kk.$$.fragment,Yl),gAr=i(Yl),Tm=n(Yl,"P",{});var kme=s(Tm);hAr=r(kme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),_ee=n(kme,"A",{href:!0});var Wra=s(_ee);uAr=r(Wra,"from_pretrained()"),Wra.forEach(t),pAr=r(kme," class method or the "),bee=n(kme,"A",{href:!0});var Ura=s(bee);_Ar=r(Ura,"from_config()"),Ura.forEach(t),bAr=r(kme,` class
method.`),kme.forEach(t),vAr=i(Yl),eS=n(Yl,"P",{});var kso=s(eS);FAr=r(kso,"This class cannot be instantiated directly using "),F0e=n(kso,"CODE",{});var Hra=s(F0e);TAr=r(Hra,"__init__()"),Hra.forEach(t),MAr=r(kso," (throws an error)."),kso.forEach(t),EAr=i(Yl),Nt=n(Yl,"DIV",{class:!0});var y9=s(Nt);T(oS.$$.fragment,y9),CAr=i(y9),T0e=n(y9,"P",{});var Jra=s(T0e);wAr=r(Jra,"Instantiates one of the model classes of the library (with a video classification head) from a configuration."),Jra.forEach(t),AAr=i(y9),Mm=n(y9,"P",{});var Sme=s(Mm);LAr=r(Sme,`Note:
Loading a model from its configuration file does `),M0e=n(Sme,"STRONG",{});var Yra=s(M0e);yAr=r(Yra,"not"),Yra.forEach(t),xAr=r(Sme,` load the model weights. It only affects the
model\u2019s configuration. Use `),vee=n(Sme,"A",{href:!0});var Zra=s(vee);$Ar=r(Zra,"from_pretrained()"),Zra.forEach(t),kAr=r(Sme," to load the model weights."),Sme.forEach(t),SAr=i(y9),T(kC.$$.fragment,y9),y9.forEach(t),RAr=i(Yl),ho=n(Yl,"DIV",{class:!0});var Ga=s(ho);T(rS.$$.fragment,Ga),PAr=i(Ga),E0e=n(Ga,"P",{});var Kra=s(E0e);BAr=r(Kra,"Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),Kra.forEach(t),IAr=i(Ga),Fn=n(Ga,"P",{});var x9=s(Fn);NAr=r(x9,"The model class to instantiate is selected based on the "),C0e=n(x9,"CODE",{});var eta=s(C0e);qAr=r(eta,"model_type"),eta.forEach(t),DAr=r(x9,` property of the config object (either
passed as an argument or loaded from `),w0e=n(x9,"CODE",{});var ota=s(w0e);jAr=r(ota,"pretrained_model_name_or_path"),ota.forEach(t),GAr=r(x9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),A0e=n(x9,"CODE",{});var rta=s(A0e);OAr=r(rta,"pretrained_model_name_or_path"),rta.forEach(t),VAr=r(x9,":"),x9.forEach(t),XAr=i(Ga),L0e=n(Ga,"UL",{});var tta=s(L0e);SC=n(tta,"LI",{});var UHe=s(SC);y0e=n(UHe,"STRONG",{});var ata=s(y0e);zAr=r(ata,"videomae"),ata.forEach(t),QAr=r(UHe," \u2014 "),Fee=n(UHe,"A",{href:!0});var nta=s(Fee);WAr=r(nta,"VideoMAEForVideoClassification"),nta.forEach(t),UAr=r(UHe," (VideoMAE model)"),UHe.forEach(t),tta.forEach(t),HAr=i(Ga),RC=n(Ga,"P",{});var HHe=s(RC);JAr=r(HHe,"The model is set in evaluation mode by default using "),x0e=n(HHe,"CODE",{});var sta=s(x0e);YAr=r(sta,"model.eval()"),sta.forEach(t),ZAr=r(HHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$0e=n(HHe,"CODE",{});var lta=s($0e);KAr=r(lta,"model.train()"),lta.forEach(t),HHe.forEach(t),e6r=i(Ga),T(PC.$$.fragment,Ga),Ga.forEach(t),Yl.forEach(t),gao=i(c),Em=n(c,"H2",{class:!0});var Sso=s(Em);BC=n(Sso,"A",{id:!0,class:!0,href:!0});var ita=s(BC);k0e=n(ita,"SPAN",{});var dta=s(k0e);T(tS.$$.fragment,dta),dta.forEach(t),ita.forEach(t),o6r=i(Sso),S0e=n(Sso,"SPAN",{});var mta=s(S0e);r6r=r(mta,"AutoModelForVision2Seq"),mta.forEach(t),Sso.forEach(t),hao=i(c),Yo=n(c,"DIV",{class:!0});var Zl=s(Yo);T(aS.$$.fragment,Zl),t6r=i(Zl),Cm=n(Zl,"P",{});var Rme=s(Cm);a6r=r(Rme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Tee=n(Rme,"A",{href:!0});var cta=s(Tee);n6r=r(cta,"from_pretrained()"),cta.forEach(t),s6r=r(Rme," class method or the "),Mee=n(Rme,"A",{href:!0});var fta=s(Mee);l6r=r(fta,"from_config()"),fta.forEach(t),i6r=r(Rme,` class
method.`),Rme.forEach(t),d6r=i(Zl),nS=n(Zl,"P",{});var Rso=s(nS);m6r=r(Rso,"This class cannot be instantiated directly using "),R0e=n(Rso,"CODE",{});var gta=s(R0e);c6r=r(gta,"__init__()"),gta.forEach(t),f6r=r(Rso," (throws an error)."),Rso.forEach(t),g6r=i(Zl),qt=n(Zl,"DIV",{class:!0});var $9=s(qt);T(sS.$$.fragment,$9),h6r=i($9),P0e=n($9,"P",{});var hta=s(P0e);u6r=r(hta,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),hta.forEach(t),p6r=i($9),wm=n($9,"P",{});var Pme=s(wm);_6r=r(Pme,`Note:
Loading a model from its configuration file does `),B0e=n(Pme,"STRONG",{});var uta=s(B0e);b6r=r(uta,"not"),uta.forEach(t),v6r=r(Pme,` load the model weights. It only affects the
model\u2019s configuration. Use `),Eee=n(Pme,"A",{href:!0});var pta=s(Eee);F6r=r(pta,"from_pretrained()"),pta.forEach(t),T6r=r(Pme," to load the model weights."),Pme.forEach(t),M6r=i($9),T(IC.$$.fragment,$9),$9.forEach(t),E6r=i(Zl),uo=n(Zl,"DIV",{class:!0});var Oa=s(uo);T(lS.$$.fragment,Oa),C6r=i(Oa),I0e=n(Oa,"P",{});var _ta=s(I0e);w6r=r(_ta,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),_ta.forEach(t),A6r=i(Oa),Tn=n(Oa,"P",{});var k9=s(Tn);L6r=r(k9,"The model class to instantiate is selected based on the "),N0e=n(k9,"CODE",{});var bta=s(N0e);y6r=r(bta,"model_type"),bta.forEach(t),x6r=r(k9,` property of the config object (either
passed as an argument or loaded from `),q0e=n(k9,"CODE",{});var vta=s(q0e);$6r=r(vta,"pretrained_model_name_or_path"),vta.forEach(t),k6r=r(k9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),D0e=n(k9,"CODE",{});var Fta=s(D0e);S6r=r(Fta,"pretrained_model_name_or_path"),Fta.forEach(t),R6r=r(k9,":"),k9.forEach(t),P6r=i(Oa),j0e=n(Oa,"UL",{});var Tta=s(j0e);NC=n(Tta,"LI",{});var JHe=s(NC);G0e=n(JHe,"STRONG",{});var Mta=s(G0e);B6r=r(Mta,"vision-encoder-decoder"),Mta.forEach(t),I6r=r(JHe," \u2014 "),Cee=n(JHe,"A",{href:!0});var Eta=s(Cee);N6r=r(Eta,"VisionEncoderDecoderModel"),Eta.forEach(t),q6r=r(JHe," (Vision Encoder decoder model)"),JHe.forEach(t),Tta.forEach(t),D6r=i(Oa),qC=n(Oa,"P",{});var YHe=s(qC);j6r=r(YHe,"The model is set in evaluation mode by default using "),O0e=n(YHe,"CODE",{});var Cta=s(O0e);G6r=r(Cta,"model.eval()"),Cta.forEach(t),O6r=r(YHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),V0e=n(YHe,"CODE",{});var wta=s(V0e);V6r=r(wta,"model.train()"),wta.forEach(t),YHe.forEach(t),X6r=i(Oa),T(DC.$$.fragment,Oa),Oa.forEach(t),Zl.forEach(t),uao=i(c),Am=n(c,"H2",{class:!0});var Pso=s(Am);jC=n(Pso,"A",{id:!0,class:!0,href:!0});var Ata=s(jC);X0e=n(Ata,"SPAN",{});var Lta=s(X0e);T(iS.$$.fragment,Lta),Lta.forEach(t),Ata.forEach(t),z6r=i(Pso),z0e=n(Pso,"SPAN",{});var yta=s(z0e);Q6r=r(yta,"AutoModelForVisualQuestionAnswering"),yta.forEach(t),Pso.forEach(t),pao=i(c),Zo=n(c,"DIV",{class:!0});var Kl=s(Zo);T(dS.$$.fragment,Kl),W6r=i(Kl),Lm=n(Kl,"P",{});var Bme=s(Lm);U6r=r(Bme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),wee=n(Bme,"A",{href:!0});var xta=s(wee);H6r=r(xta,"from_pretrained()"),xta.forEach(t),J6r=r(Bme," class method or the "),Aee=n(Bme,"A",{href:!0});var $ta=s(Aee);Y6r=r($ta,"from_config()"),$ta.forEach(t),Z6r=r(Bme,` class
method.`),Bme.forEach(t),K6r=i(Kl),mS=n(Kl,"P",{});var Bso=s(mS);e7r=r(Bso,"This class cannot be instantiated directly using "),Q0e=n(Bso,"CODE",{});var kta=s(Q0e);o7r=r(kta,"__init__()"),kta.forEach(t),r7r=r(Bso," (throws an error)."),Bso.forEach(t),t7r=i(Kl),Dt=n(Kl,"DIV",{class:!0});var S9=s(Dt);T(cS.$$.fragment,S9),a7r=i(S9),W0e=n(S9,"P",{});var Sta=s(W0e);n7r=r(Sta,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),Sta.forEach(t),s7r=i(S9),ym=n(S9,"P",{});var Ime=s(ym);l7r=r(Ime,`Note:
Loading a model from its configuration file does `),U0e=n(Ime,"STRONG",{});var Rta=s(U0e);i7r=r(Rta,"not"),Rta.forEach(t),d7r=r(Ime,` load the model weights. It only affects the
model\u2019s configuration. Use `),Lee=n(Ime,"A",{href:!0});var Pta=s(Lee);m7r=r(Pta,"from_pretrained()"),Pta.forEach(t),c7r=r(Ime," to load the model weights."),Ime.forEach(t),f7r=i(S9),T(GC.$$.fragment,S9),S9.forEach(t),g7r=i(Kl),po=n(Kl,"DIV",{class:!0});var Va=s(po);T(fS.$$.fragment,Va),h7r=i(Va),H0e=n(Va,"P",{});var Bta=s(H0e);u7r=r(Bta,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),Bta.forEach(t),p7r=i(Va),Mn=n(Va,"P",{});var R9=s(Mn);_7r=r(R9,"The model class to instantiate is selected based on the "),J0e=n(R9,"CODE",{});var Ita=s(J0e);b7r=r(Ita,"model_type"),Ita.forEach(t),v7r=r(R9,` property of the config object (either
passed as an argument or loaded from `),Y0e=n(R9,"CODE",{});var Nta=s(Y0e);F7r=r(Nta,"pretrained_model_name_or_path"),Nta.forEach(t),T7r=r(R9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Z0e=n(R9,"CODE",{});var qta=s(Z0e);M7r=r(qta,"pretrained_model_name_or_path"),qta.forEach(t),E7r=r(R9,":"),R9.forEach(t),C7r=i(Va),K0e=n(Va,"UL",{});var Dta=s(K0e);OC=n(Dta,"LI",{});var ZHe=s(OC);ewe=n(ZHe,"STRONG",{});var jta=s(ewe);w7r=r(jta,"vilt"),jta.forEach(t),A7r=r(ZHe," \u2014 "),yee=n(ZHe,"A",{href:!0});var Gta=s(yee);L7r=r(Gta,"ViltForQuestionAnswering"),Gta.forEach(t),y7r=r(ZHe," (ViLT model)"),ZHe.forEach(t),Dta.forEach(t),x7r=i(Va),VC=n(Va,"P",{});var KHe=s(VC);$7r=r(KHe,"The model is set in evaluation mode by default using "),owe=n(KHe,"CODE",{});var Ota=s(owe);k7r=r(Ota,"model.eval()"),Ota.forEach(t),S7r=r(KHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),rwe=n(KHe,"CODE",{});var Vta=s(rwe);R7r=r(Vta,"model.train()"),Vta.forEach(t),KHe.forEach(t),P7r=i(Va),T(XC.$$.fragment,Va),Va.forEach(t),Kl.forEach(t),_ao=i(c),xm=n(c,"H2",{class:!0});var Iso=s(xm);zC=n(Iso,"A",{id:!0,class:!0,href:!0});var Xta=s(zC);twe=n(Xta,"SPAN",{});var zta=s(twe);T(gS.$$.fragment,zta),zta.forEach(t),Xta.forEach(t),B7r=i(Iso),awe=n(Iso,"SPAN",{});var Qta=s(awe);I7r=r(Qta,"AutoModelForAudioClassification"),Qta.forEach(t),Iso.forEach(t),bao=i(c),Ko=n(c,"DIV",{class:!0});var ei=s(Ko);T(hS.$$.fragment,ei),N7r=i(ei),$m=n(ei,"P",{});var Nme=s($m);q7r=r(Nme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),xee=n(Nme,"A",{href:!0});var Wta=s(xee);D7r=r(Wta,"from_pretrained()"),Wta.forEach(t),j7r=r(Nme," class method or the "),$ee=n(Nme,"A",{href:!0});var Uta=s($ee);G7r=r(Uta,"from_config()"),Uta.forEach(t),O7r=r(Nme,` class
method.`),Nme.forEach(t),V7r=i(ei),uS=n(ei,"P",{});var Nso=s(uS);X7r=r(Nso,"This class cannot be instantiated directly using "),nwe=n(Nso,"CODE",{});var Hta=s(nwe);z7r=r(Hta,"__init__()"),Hta.forEach(t),Q7r=r(Nso," (throws an error)."),Nso.forEach(t),W7r=i(ei),jt=n(ei,"DIV",{class:!0});var P9=s(jt);T(pS.$$.fragment,P9),U7r=i(P9),swe=n(P9,"P",{});var Jta=s(swe);H7r=r(Jta,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),Jta.forEach(t),J7r=i(P9),km=n(P9,"P",{});var qme=s(km);Y7r=r(qme,`Note:
Loading a model from its configuration file does `),lwe=n(qme,"STRONG",{});var Yta=s(lwe);Z7r=r(Yta,"not"),Yta.forEach(t),K7r=r(qme,` load the model weights. It only affects the
model\u2019s configuration. Use `),kee=n(qme,"A",{href:!0});var Zta=s(kee);e8r=r(Zta,"from_pretrained()"),Zta.forEach(t),o8r=r(qme," to load the model weights."),qme.forEach(t),r8r=i(P9),T(QC.$$.fragment,P9),P9.forEach(t),t8r=i(ei),_o=n(ei,"DIV",{class:!0});var Xa=s(_o);T(_S.$$.fragment,Xa),a8r=i(Xa),iwe=n(Xa,"P",{});var Kta=s(iwe);n8r=r(Kta,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),Kta.forEach(t),s8r=i(Xa),En=n(Xa,"P",{});var B9=s(En);l8r=r(B9,"The model class to instantiate is selected based on the "),dwe=n(B9,"CODE",{});var eaa=s(dwe);i8r=r(eaa,"model_type"),eaa.forEach(t),d8r=r(B9,` property of the config object (either
passed as an argument or loaded from `),mwe=n(B9,"CODE",{});var oaa=s(mwe);m8r=r(oaa,"pretrained_model_name_or_path"),oaa.forEach(t),c8r=r(B9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cwe=n(B9,"CODE",{});var raa=s(cwe);f8r=r(raa,"pretrained_model_name_or_path"),raa.forEach(t),g8r=r(B9,":"),B9.forEach(t),h8r=i(Xa),Be=n(Xa,"UL",{});var We=s(Be);WC=n(We,"LI",{});var eJe=s(WC);fwe=n(eJe,"STRONG",{});var taa=s(fwe);u8r=r(taa,"data2vec-audio"),taa.forEach(t),p8r=r(eJe," \u2014 "),See=n(eJe,"A",{href:!0});var aaa=s(See);_8r=r(aaa,"Data2VecAudioForSequenceClassification"),aaa.forEach(t),b8r=r(eJe," (Data2VecAudio model)"),eJe.forEach(t),v8r=i(We),UC=n(We,"LI",{});var oJe=s(UC);gwe=n(oJe,"STRONG",{});var naa=s(gwe);F8r=r(naa,"hubert"),naa.forEach(t),T8r=r(oJe," \u2014 "),Ree=n(oJe,"A",{href:!0});var saa=s(Ree);M8r=r(saa,"HubertForSequenceClassification"),saa.forEach(t),E8r=r(oJe," (Hubert model)"),oJe.forEach(t),C8r=i(We),HC=n(We,"LI",{});var rJe=s(HC);hwe=n(rJe,"STRONG",{});var laa=s(hwe);w8r=r(laa,"sew"),laa.forEach(t),A8r=r(rJe," \u2014 "),Pee=n(rJe,"A",{href:!0});var iaa=s(Pee);L8r=r(iaa,"SEWForSequenceClassification"),iaa.forEach(t),y8r=r(rJe," (SEW model)"),rJe.forEach(t),x8r=i(We),JC=n(We,"LI",{});var tJe=s(JC);uwe=n(tJe,"STRONG",{});var daa=s(uwe);$8r=r(daa,"sew-d"),daa.forEach(t),k8r=r(tJe," \u2014 "),Bee=n(tJe,"A",{href:!0});var maa=s(Bee);S8r=r(maa,"SEWDForSequenceClassification"),maa.forEach(t),R8r=r(tJe," (SEW-D model)"),tJe.forEach(t),P8r=i(We),YC=n(We,"LI",{});var aJe=s(YC);pwe=n(aJe,"STRONG",{});var caa=s(pwe);B8r=r(caa,"unispeech"),caa.forEach(t),I8r=r(aJe," \u2014 "),Iee=n(aJe,"A",{href:!0});var faa=s(Iee);N8r=r(faa,"UniSpeechForSequenceClassification"),faa.forEach(t),q8r=r(aJe," (UniSpeech model)"),aJe.forEach(t),D8r=i(We),ZC=n(We,"LI",{});var nJe=s(ZC);_we=n(nJe,"STRONG",{});var gaa=s(_we);j8r=r(gaa,"unispeech-sat"),gaa.forEach(t),G8r=r(nJe," \u2014 "),Nee=n(nJe,"A",{href:!0});var haa=s(Nee);O8r=r(haa,"UniSpeechSatForSequenceClassification"),haa.forEach(t),V8r=r(nJe," (UniSpeechSat model)"),nJe.forEach(t),X8r=i(We),KC=n(We,"LI",{});var sJe=s(KC);bwe=n(sJe,"STRONG",{});var uaa=s(bwe);z8r=r(uaa,"wav2vec2"),uaa.forEach(t),Q8r=r(sJe," \u2014 "),qee=n(sJe,"A",{href:!0});var paa=s(qee);W8r=r(paa,"Wav2Vec2ForSequenceClassification"),paa.forEach(t),U8r=r(sJe," (Wav2Vec2 model)"),sJe.forEach(t),H8r=i(We),e3=n(We,"LI",{});var lJe=s(e3);vwe=n(lJe,"STRONG",{});var _aa=s(vwe);J8r=r(_aa,"wav2vec2-conformer"),_aa.forEach(t),Y8r=r(lJe," \u2014 "),Dee=n(lJe,"A",{href:!0});var baa=s(Dee);Z8r=r(baa,"Wav2Vec2ConformerForSequenceClassification"),baa.forEach(t),K8r=r(lJe," (Wav2Vec2-Conformer model)"),lJe.forEach(t),eLr=i(We),o3=n(We,"LI",{});var iJe=s(o3);Fwe=n(iJe,"STRONG",{});var vaa=s(Fwe);oLr=r(vaa,"wavlm"),vaa.forEach(t),rLr=r(iJe," \u2014 "),jee=n(iJe,"A",{href:!0});var Faa=s(jee);tLr=r(Faa,"WavLMForSequenceClassification"),Faa.forEach(t),aLr=r(iJe," (WavLM model)"),iJe.forEach(t),We.forEach(t),nLr=i(Xa),r3=n(Xa,"P",{});var dJe=s(r3);sLr=r(dJe,"The model is set in evaluation mode by default using "),Twe=n(dJe,"CODE",{});var Taa=s(Twe);lLr=r(Taa,"model.eval()"),Taa.forEach(t),iLr=r(dJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Mwe=n(dJe,"CODE",{});var Maa=s(Mwe);dLr=r(Maa,"model.train()"),Maa.forEach(t),dJe.forEach(t),mLr=i(Xa),T(t3.$$.fragment,Xa),Xa.forEach(t),ei.forEach(t),vao=i(c),Sm=n(c,"H2",{class:!0});var qso=s(Sm);a3=n(qso,"A",{id:!0,class:!0,href:!0});var Eaa=s(a3);Ewe=n(Eaa,"SPAN",{});var Caa=s(Ewe);T(bS.$$.fragment,Caa),Caa.forEach(t),Eaa.forEach(t),cLr=i(qso),Cwe=n(qso,"SPAN",{});var waa=s(Cwe);fLr=r(waa,"AutoModelForAudioFrameClassification"),waa.forEach(t),qso.forEach(t),Fao=i(c),er=n(c,"DIV",{class:!0});var oi=s(er);T(vS.$$.fragment,oi),gLr=i(oi),Rm=n(oi,"P",{});var Dme=s(Rm);hLr=r(Dme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),Gee=n(Dme,"A",{href:!0});var Aaa=s(Gee);uLr=r(Aaa,"from_pretrained()"),Aaa.forEach(t),pLr=r(Dme," class method or the "),Oee=n(Dme,"A",{href:!0});var Laa=s(Oee);_Lr=r(Laa,"from_config()"),Laa.forEach(t),bLr=r(Dme,` class
method.`),Dme.forEach(t),vLr=i(oi),FS=n(oi,"P",{});var Dso=s(FS);FLr=r(Dso,"This class cannot be instantiated directly using "),wwe=n(Dso,"CODE",{});var yaa=s(wwe);TLr=r(yaa,"__init__()"),yaa.forEach(t),MLr=r(Dso," (throws an error)."),Dso.forEach(t),ELr=i(oi),Gt=n(oi,"DIV",{class:!0});var I9=s(Gt);T(TS.$$.fragment,I9),CLr=i(I9),Awe=n(I9,"P",{});var xaa=s(Awe);wLr=r(xaa,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),xaa.forEach(t),ALr=i(I9),Pm=n(I9,"P",{});var jme=s(Pm);LLr=r(jme,`Note:
Loading a model from its configuration file does `),Lwe=n(jme,"STRONG",{});var $aa=s(Lwe);yLr=r($aa,"not"),$aa.forEach(t),xLr=r(jme,` load the model weights. It only affects the
model\u2019s configuration. Use `),Vee=n(jme,"A",{href:!0});var kaa=s(Vee);$Lr=r(kaa,"from_pretrained()"),kaa.forEach(t),kLr=r(jme," to load the model weights."),jme.forEach(t),SLr=i(I9),T(n3.$$.fragment,I9),I9.forEach(t),RLr=i(oi),bo=n(oi,"DIV",{class:!0});var za=s(bo);T(MS.$$.fragment,za),PLr=i(za),ywe=n(za,"P",{});var Saa=s(ywe);BLr=r(Saa,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),Saa.forEach(t),ILr=i(za),Cn=n(za,"P",{});var N9=s(Cn);NLr=r(N9,"The model class to instantiate is selected based on the "),xwe=n(N9,"CODE",{});var Raa=s(xwe);qLr=r(Raa,"model_type"),Raa.forEach(t),DLr=r(N9,` property of the config object (either
passed as an argument or loaded from `),$we=n(N9,"CODE",{});var Paa=s($we);jLr=r(Paa,"pretrained_model_name_or_path"),Paa.forEach(t),GLr=r(N9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kwe=n(N9,"CODE",{});var Baa=s(kwe);OLr=r(Baa,"pretrained_model_name_or_path"),Baa.forEach(t),VLr=r(N9,":"),N9.forEach(t),XLr=i(za),ut=n(za,"UL",{});var ri=s(ut);s3=n(ri,"LI",{});var mJe=s(s3);Swe=n(mJe,"STRONG",{});var Iaa=s(Swe);zLr=r(Iaa,"data2vec-audio"),Iaa.forEach(t),QLr=r(mJe," \u2014 "),Xee=n(mJe,"A",{href:!0});var Naa=s(Xee);WLr=r(Naa,"Data2VecAudioForAudioFrameClassification"),Naa.forEach(t),ULr=r(mJe," (Data2VecAudio model)"),mJe.forEach(t),HLr=i(ri),l3=n(ri,"LI",{});var cJe=s(l3);Rwe=n(cJe,"STRONG",{});var qaa=s(Rwe);JLr=r(qaa,"unispeech-sat"),qaa.forEach(t),YLr=r(cJe," \u2014 "),zee=n(cJe,"A",{href:!0});var Daa=s(zee);ZLr=r(Daa,"UniSpeechSatForAudioFrameClassification"),Daa.forEach(t),KLr=r(cJe," (UniSpeechSat model)"),cJe.forEach(t),eyr=i(ri),i3=n(ri,"LI",{});var fJe=s(i3);Pwe=n(fJe,"STRONG",{});var jaa=s(Pwe);oyr=r(jaa,"wav2vec2"),jaa.forEach(t),ryr=r(fJe," \u2014 "),Qee=n(fJe,"A",{href:!0});var Gaa=s(Qee);tyr=r(Gaa,"Wav2Vec2ForAudioFrameClassification"),Gaa.forEach(t),ayr=r(fJe," (Wav2Vec2 model)"),fJe.forEach(t),nyr=i(ri),d3=n(ri,"LI",{});var gJe=s(d3);Bwe=n(gJe,"STRONG",{});var Oaa=s(Bwe);syr=r(Oaa,"wav2vec2-conformer"),Oaa.forEach(t),lyr=r(gJe," \u2014 "),Wee=n(gJe,"A",{href:!0});var Vaa=s(Wee);iyr=r(Vaa,"Wav2Vec2ConformerForAudioFrameClassification"),Vaa.forEach(t),dyr=r(gJe," (Wav2Vec2-Conformer model)"),gJe.forEach(t),myr=i(ri),m3=n(ri,"LI",{});var hJe=s(m3);Iwe=n(hJe,"STRONG",{});var Xaa=s(Iwe);cyr=r(Xaa,"wavlm"),Xaa.forEach(t),fyr=r(hJe," \u2014 "),Uee=n(hJe,"A",{href:!0});var zaa=s(Uee);gyr=r(zaa,"WavLMForAudioFrameClassification"),zaa.forEach(t),hyr=r(hJe," (WavLM model)"),hJe.forEach(t),ri.forEach(t),uyr=i(za),c3=n(za,"P",{});var uJe=s(c3);pyr=r(uJe,"The model is set in evaluation mode by default using "),Nwe=n(uJe,"CODE",{});var Qaa=s(Nwe);_yr=r(Qaa,"model.eval()"),Qaa.forEach(t),byr=r(uJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qwe=n(uJe,"CODE",{});var Waa=s(qwe);vyr=r(Waa,"model.train()"),Waa.forEach(t),uJe.forEach(t),Fyr=i(za),T(f3.$$.fragment,za),za.forEach(t),oi.forEach(t),Tao=i(c),Bm=n(c,"H2",{class:!0});var jso=s(Bm);g3=n(jso,"A",{id:!0,class:!0,href:!0});var Uaa=s(g3);Dwe=n(Uaa,"SPAN",{});var Haa=s(Dwe);T(ES.$$.fragment,Haa),Haa.forEach(t),Uaa.forEach(t),Tyr=i(jso),jwe=n(jso,"SPAN",{});var Jaa=s(jwe);Myr=r(Jaa,"AutoModelForCTC"),Jaa.forEach(t),jso.forEach(t),Mao=i(c),or=n(c,"DIV",{class:!0});var ti=s(or);T(CS.$$.fragment,ti),Eyr=i(ti),Im=n(ti,"P",{});var Gme=s(Im);Cyr=r(Gme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),Hee=n(Gme,"A",{href:!0});var Yaa=s(Hee);wyr=r(Yaa,"from_pretrained()"),Yaa.forEach(t),Ayr=r(Gme," class method or the "),Jee=n(Gme,"A",{href:!0});var Zaa=s(Jee);Lyr=r(Zaa,"from_config()"),Zaa.forEach(t),yyr=r(Gme,` class
method.`),Gme.forEach(t),xyr=i(ti),wS=n(ti,"P",{});var Gso=s(wS);$yr=r(Gso,"This class cannot be instantiated directly using "),Gwe=n(Gso,"CODE",{});var Kaa=s(Gwe);kyr=r(Kaa,"__init__()"),Kaa.forEach(t),Syr=r(Gso," (throws an error)."),Gso.forEach(t),Ryr=i(ti),Ot=n(ti,"DIV",{class:!0});var q9=s(Ot);T(AS.$$.fragment,q9),Pyr=i(q9),Owe=n(q9,"P",{});var ena=s(Owe);Byr=r(ena,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),ena.forEach(t),Iyr=i(q9),Nm=n(q9,"P",{});var Ome=s(Nm);Nyr=r(Ome,`Note:
Loading a model from its configuration file does `),Vwe=n(Ome,"STRONG",{});var ona=s(Vwe);qyr=r(ona,"not"),ona.forEach(t),Dyr=r(Ome,` load the model weights. It only affects the
model\u2019s configuration. Use `),Yee=n(Ome,"A",{href:!0});var rna=s(Yee);jyr=r(rna,"from_pretrained()"),rna.forEach(t),Gyr=r(Ome," to load the model weights."),Ome.forEach(t),Oyr=i(q9),T(h3.$$.fragment,q9),q9.forEach(t),Vyr=i(ti),vo=n(ti,"DIV",{class:!0});var Qa=s(vo);T(LS.$$.fragment,Qa),Xyr=i(Qa),Xwe=n(Qa,"P",{});var tna=s(Xwe);zyr=r(tna,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),tna.forEach(t),Qyr=i(Qa),wn=n(Qa,"P",{});var D9=s(wn);Wyr=r(D9,"The model class to instantiate is selected based on the "),zwe=n(D9,"CODE",{});var ana=s(zwe);Uyr=r(ana,"model_type"),ana.forEach(t),Hyr=r(D9,` property of the config object (either
passed as an argument or loaded from `),Qwe=n(D9,"CODE",{});var nna=s(Qwe);Jyr=r(nna,"pretrained_model_name_or_path"),nna.forEach(t),Yyr=r(D9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wwe=n(D9,"CODE",{});var sna=s(Wwe);Zyr=r(sna,"pretrained_model_name_or_path"),sna.forEach(t),Kyr=r(D9,":"),D9.forEach(t),e9r=i(Qa),Le=n(Qa,"UL",{});var Ie=s(Le);u3=n(Ie,"LI",{});var pJe=s(u3);Uwe=n(pJe,"STRONG",{});var lna=s(Uwe);o9r=r(lna,"data2vec-audio"),lna.forEach(t),r9r=r(pJe," \u2014 "),Zee=n(pJe,"A",{href:!0});var ina=s(Zee);t9r=r(ina,"Data2VecAudioForCTC"),ina.forEach(t),a9r=r(pJe," (Data2VecAudio model)"),pJe.forEach(t),n9r=i(Ie),p3=n(Ie,"LI",{});var _Je=s(p3);Hwe=n(_Je,"STRONG",{});var dna=s(Hwe);s9r=r(dna,"hubert"),dna.forEach(t),l9r=r(_Je," \u2014 "),Kee=n(_Je,"A",{href:!0});var mna=s(Kee);i9r=r(mna,"HubertForCTC"),mna.forEach(t),d9r=r(_Je," (Hubert model)"),_Je.forEach(t),m9r=i(Ie),_3=n(Ie,"LI",{});var bJe=s(_3);Jwe=n(bJe,"STRONG",{});var cna=s(Jwe);c9r=r(cna,"mctct"),cna.forEach(t),f9r=r(bJe," \u2014 "),eoe=n(bJe,"A",{href:!0});var fna=s(eoe);g9r=r(fna,"MCTCTForCTC"),fna.forEach(t),h9r=r(bJe," (M-CTC-T model)"),bJe.forEach(t),u9r=i(Ie),b3=n(Ie,"LI",{});var vJe=s(b3);Ywe=n(vJe,"STRONG",{});var gna=s(Ywe);p9r=r(gna,"sew"),gna.forEach(t),_9r=r(vJe," \u2014 "),ooe=n(vJe,"A",{href:!0});var hna=s(ooe);b9r=r(hna,"SEWForCTC"),hna.forEach(t),v9r=r(vJe," (SEW model)"),vJe.forEach(t),F9r=i(Ie),v3=n(Ie,"LI",{});var FJe=s(v3);Zwe=n(FJe,"STRONG",{});var una=s(Zwe);T9r=r(una,"sew-d"),una.forEach(t),M9r=r(FJe," \u2014 "),roe=n(FJe,"A",{href:!0});var pna=s(roe);E9r=r(pna,"SEWDForCTC"),pna.forEach(t),C9r=r(FJe," (SEW-D model)"),FJe.forEach(t),w9r=i(Ie),F3=n(Ie,"LI",{});var TJe=s(F3);Kwe=n(TJe,"STRONG",{});var _na=s(Kwe);A9r=r(_na,"unispeech"),_na.forEach(t),L9r=r(TJe," \u2014 "),toe=n(TJe,"A",{href:!0});var bna=s(toe);y9r=r(bna,"UniSpeechForCTC"),bna.forEach(t),x9r=r(TJe," (UniSpeech model)"),TJe.forEach(t),$9r=i(Ie),T3=n(Ie,"LI",{});var MJe=s(T3);eAe=n(MJe,"STRONG",{});var vna=s(eAe);k9r=r(vna,"unispeech-sat"),vna.forEach(t),S9r=r(MJe," \u2014 "),aoe=n(MJe,"A",{href:!0});var Fna=s(aoe);R9r=r(Fna,"UniSpeechSatForCTC"),Fna.forEach(t),P9r=r(MJe," (UniSpeechSat model)"),MJe.forEach(t),B9r=i(Ie),M3=n(Ie,"LI",{});var EJe=s(M3);oAe=n(EJe,"STRONG",{});var Tna=s(oAe);I9r=r(Tna,"wav2vec2"),Tna.forEach(t),N9r=r(EJe," \u2014 "),noe=n(EJe,"A",{href:!0});var Mna=s(noe);q9r=r(Mna,"Wav2Vec2ForCTC"),Mna.forEach(t),D9r=r(EJe," (Wav2Vec2 model)"),EJe.forEach(t),j9r=i(Ie),E3=n(Ie,"LI",{});var CJe=s(E3);rAe=n(CJe,"STRONG",{});var Ena=s(rAe);G9r=r(Ena,"wav2vec2-conformer"),Ena.forEach(t),O9r=r(CJe," \u2014 "),soe=n(CJe,"A",{href:!0});var Cna=s(soe);V9r=r(Cna,"Wav2Vec2ConformerForCTC"),Cna.forEach(t),X9r=r(CJe," (Wav2Vec2-Conformer model)"),CJe.forEach(t),z9r=i(Ie),C3=n(Ie,"LI",{});var wJe=s(C3);tAe=n(wJe,"STRONG",{});var wna=s(tAe);Q9r=r(wna,"wavlm"),wna.forEach(t),W9r=r(wJe," \u2014 "),loe=n(wJe,"A",{href:!0});var Ana=s(loe);U9r=r(Ana,"WavLMForCTC"),Ana.forEach(t),H9r=r(wJe," (WavLM model)"),wJe.forEach(t),Ie.forEach(t),J9r=i(Qa),w3=n(Qa,"P",{});var AJe=s(w3);Y9r=r(AJe,"The model is set in evaluation mode by default using "),aAe=n(AJe,"CODE",{});var Lna=s(aAe);Z9r=r(Lna,"model.eval()"),Lna.forEach(t),K9r=r(AJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),nAe=n(AJe,"CODE",{});var yna=s(nAe);exr=r(yna,"model.train()"),yna.forEach(t),AJe.forEach(t),oxr=i(Qa),T(A3.$$.fragment,Qa),Qa.forEach(t),ti.forEach(t),Eao=i(c),qm=n(c,"H2",{class:!0});var Oso=s(qm);L3=n(Oso,"A",{id:!0,class:!0,href:!0});var xna=s(L3);sAe=n(xna,"SPAN",{});var $na=s(sAe);T(yS.$$.fragment,$na),$na.forEach(t),xna.forEach(t),rxr=i(Oso),lAe=n(Oso,"SPAN",{});var kna=s(lAe);txr=r(kna,"AutoModelForSpeechSeq2Seq"),kna.forEach(t),Oso.forEach(t),Cao=i(c),rr=n(c,"DIV",{class:!0});var ai=s(rr);T(xS.$$.fragment,ai),axr=i(ai),Dm=n(ai,"P",{});var Vme=s(Dm);nxr=r(Vme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),ioe=n(Vme,"A",{href:!0});var Sna=s(ioe);sxr=r(Sna,"from_pretrained()"),Sna.forEach(t),lxr=r(Vme," class method or the "),doe=n(Vme,"A",{href:!0});var Rna=s(doe);ixr=r(Rna,"from_config()"),Rna.forEach(t),dxr=r(Vme,` class
method.`),Vme.forEach(t),mxr=i(ai),$S=n(ai,"P",{});var Vso=s($S);cxr=r(Vso,"This class cannot be instantiated directly using "),iAe=n(Vso,"CODE",{});var Pna=s(iAe);fxr=r(Pna,"__init__()"),Pna.forEach(t),gxr=r(Vso," (throws an error)."),Vso.forEach(t),hxr=i(ai),Vt=n(ai,"DIV",{class:!0});var j9=s(Vt);T(kS.$$.fragment,j9),uxr=i(j9),dAe=n(j9,"P",{});var Bna=s(dAe);pxr=r(Bna,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Bna.forEach(t),_xr=i(j9),jm=n(j9,"P",{});var Xme=s(jm);bxr=r(Xme,`Note:
Loading a model from its configuration file does `),mAe=n(Xme,"STRONG",{});var Ina=s(mAe);vxr=r(Ina,"not"),Ina.forEach(t),Fxr=r(Xme,` load the model weights. It only affects the
model\u2019s configuration. Use `),moe=n(Xme,"A",{href:!0});var Nna=s(moe);Txr=r(Nna,"from_pretrained()"),Nna.forEach(t),Mxr=r(Xme," to load the model weights."),Xme.forEach(t),Exr=i(j9),T(y3.$$.fragment,j9),j9.forEach(t),Cxr=i(ai),Fo=n(ai,"DIV",{class:!0});var Wa=s(Fo);T(SS.$$.fragment,Wa),wxr=i(Wa),cAe=n(Wa,"P",{});var qna=s(cAe);Axr=r(qna,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),qna.forEach(t),Lxr=i(Wa),An=n(Wa,"P",{});var G9=s(An);yxr=r(G9,"The model class to instantiate is selected based on the "),fAe=n(G9,"CODE",{});var Dna=s(fAe);xxr=r(Dna,"model_type"),Dna.forEach(t),$xr=r(G9,` property of the config object (either
passed as an argument or loaded from `),gAe=n(G9,"CODE",{});var jna=s(gAe);kxr=r(jna,"pretrained_model_name_or_path"),jna.forEach(t),Sxr=r(G9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hAe=n(G9,"CODE",{});var Gna=s(hAe);Rxr=r(Gna,"pretrained_model_name_or_path"),Gna.forEach(t),Pxr=r(G9,":"),G9.forEach(t),Bxr=i(Wa),Gm=n(Wa,"UL",{});var zme=s(Gm);x3=n(zme,"LI",{});var LJe=s(x3);uAe=n(LJe,"STRONG",{});var Ona=s(uAe);Ixr=r(Ona,"speech-encoder-decoder"),Ona.forEach(t),Nxr=r(LJe," \u2014 "),coe=n(LJe,"A",{href:!0});var Vna=s(coe);qxr=r(Vna,"SpeechEncoderDecoderModel"),Vna.forEach(t),Dxr=r(LJe," (Speech Encoder decoder model)"),LJe.forEach(t),jxr=i(zme),$3=n(zme,"LI",{});var yJe=s($3);pAe=n(yJe,"STRONG",{});var Xna=s(pAe);Gxr=r(Xna,"speech_to_text"),Xna.forEach(t),Oxr=r(yJe," \u2014 "),foe=n(yJe,"A",{href:!0});var zna=s(foe);Vxr=r(zna,"Speech2TextForConditionalGeneration"),zna.forEach(t),Xxr=r(yJe," (Speech2Text model)"),yJe.forEach(t),zxr=i(zme),k3=n(zme,"LI",{});var xJe=s(k3);_Ae=n(xJe,"STRONG",{});var Qna=s(_Ae);Qxr=r(Qna,"whisper"),Qna.forEach(t),Wxr=r(xJe," \u2014 "),goe=n(xJe,"A",{href:!0});var Wna=s(goe);Uxr=r(Wna,"WhisperForConditionalGeneration"),Wna.forEach(t),Hxr=r(xJe," (Whisper model)"),xJe.forEach(t),zme.forEach(t),Jxr=i(Wa),S3=n(Wa,"P",{});var $Je=s(S3);Yxr=r($Je,"The model is set in evaluation mode by default using "),bAe=n($Je,"CODE",{});var Una=s(bAe);Zxr=r(Una,"model.eval()"),Una.forEach(t),Kxr=r($Je,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),vAe=n($Je,"CODE",{});var Hna=s(vAe);e$r=r(Hna,"model.train()"),Hna.forEach(t),$Je.forEach(t),o$r=i(Wa),T(R3.$$.fragment,Wa),Wa.forEach(t),ai.forEach(t),wao=i(c),Om=n(c,"H2",{class:!0});var Xso=s(Om);P3=n(Xso,"A",{id:!0,class:!0,href:!0});var Jna=s(P3);FAe=n(Jna,"SPAN",{});var Yna=s(FAe);T(RS.$$.fragment,Yna),Yna.forEach(t),Jna.forEach(t),r$r=i(Xso),TAe=n(Xso,"SPAN",{});var Zna=s(TAe);t$r=r(Zna,"AutoModelForAudioXVector"),Zna.forEach(t),Xso.forEach(t),Aao=i(c),tr=n(c,"DIV",{class:!0});var ni=s(tr);T(PS.$$.fragment,ni),a$r=i(ni),Vm=n(ni,"P",{});var Qme=s(Vm);n$r=r(Qme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),hoe=n(Qme,"A",{href:!0});var Kna=s(hoe);s$r=r(Kna,"from_pretrained()"),Kna.forEach(t),l$r=r(Qme," class method or the "),uoe=n(Qme,"A",{href:!0});var esa=s(uoe);i$r=r(esa,"from_config()"),esa.forEach(t),d$r=r(Qme,` class
method.`),Qme.forEach(t),m$r=i(ni),BS=n(ni,"P",{});var zso=s(BS);c$r=r(zso,"This class cannot be instantiated directly using "),MAe=n(zso,"CODE",{});var osa=s(MAe);f$r=r(osa,"__init__()"),osa.forEach(t),g$r=r(zso," (throws an error)."),zso.forEach(t),h$r=i(ni),Xt=n(ni,"DIV",{class:!0});var O9=s(Xt);T(IS.$$.fragment,O9),u$r=i(O9),EAe=n(O9,"P",{});var rsa=s(EAe);p$r=r(rsa,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),rsa.forEach(t),_$r=i(O9),Xm=n(O9,"P",{});var Wme=s(Xm);b$r=r(Wme,`Note:
Loading a model from its configuration file does `),CAe=n(Wme,"STRONG",{});var tsa=s(CAe);v$r=r(tsa,"not"),tsa.forEach(t),F$r=r(Wme,` load the model weights. It only affects the
model\u2019s configuration. Use `),poe=n(Wme,"A",{href:!0});var asa=s(poe);T$r=r(asa,"from_pretrained()"),asa.forEach(t),M$r=r(Wme," to load the model weights."),Wme.forEach(t),E$r=i(O9),T(B3.$$.fragment,O9),O9.forEach(t),C$r=i(ni),To=n(ni,"DIV",{class:!0});var Ua=s(To);T(NS.$$.fragment,Ua),w$r=i(Ua),wAe=n(Ua,"P",{});var nsa=s(wAe);A$r=r(nsa,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),nsa.forEach(t),L$r=i(Ua),Ln=n(Ua,"P",{});var V9=s(Ln);y$r=r(V9,"The model class to instantiate is selected based on the "),AAe=n(V9,"CODE",{});var ssa=s(AAe);x$r=r(ssa,"model_type"),ssa.forEach(t),$$r=r(V9,` property of the config object (either
passed as an argument or loaded from `),LAe=n(V9,"CODE",{});var lsa=s(LAe);k$r=r(lsa,"pretrained_model_name_or_path"),lsa.forEach(t),S$r=r(V9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yAe=n(V9,"CODE",{});var isa=s(yAe);R$r=r(isa,"pretrained_model_name_or_path"),isa.forEach(t),P$r=r(V9,":"),V9.forEach(t),B$r=i(Ua),pt=n(Ua,"UL",{});var si=s(pt);I3=n(si,"LI",{});var kJe=s(I3);xAe=n(kJe,"STRONG",{});var dsa=s(xAe);I$r=r(dsa,"data2vec-audio"),dsa.forEach(t),N$r=r(kJe," \u2014 "),_oe=n(kJe,"A",{href:!0});var msa=s(_oe);q$r=r(msa,"Data2VecAudioForXVector"),msa.forEach(t),D$r=r(kJe," (Data2VecAudio model)"),kJe.forEach(t),j$r=i(si),N3=n(si,"LI",{});var SJe=s(N3);$Ae=n(SJe,"STRONG",{});var csa=s($Ae);G$r=r(csa,"unispeech-sat"),csa.forEach(t),O$r=r(SJe," \u2014 "),boe=n(SJe,"A",{href:!0});var fsa=s(boe);V$r=r(fsa,"UniSpeechSatForXVector"),fsa.forEach(t),X$r=r(SJe," (UniSpeechSat model)"),SJe.forEach(t),z$r=i(si),q3=n(si,"LI",{});var RJe=s(q3);kAe=n(RJe,"STRONG",{});var gsa=s(kAe);Q$r=r(gsa,"wav2vec2"),gsa.forEach(t),W$r=r(RJe," \u2014 "),voe=n(RJe,"A",{href:!0});var hsa=s(voe);U$r=r(hsa,"Wav2Vec2ForXVector"),hsa.forEach(t),H$r=r(RJe," (Wav2Vec2 model)"),RJe.forEach(t),J$r=i(si),D3=n(si,"LI",{});var PJe=s(D3);SAe=n(PJe,"STRONG",{});var usa=s(SAe);Y$r=r(usa,"wav2vec2-conformer"),usa.forEach(t),Z$r=r(PJe," \u2014 "),Foe=n(PJe,"A",{href:!0});var psa=s(Foe);K$r=r(psa,"Wav2Vec2ConformerForXVector"),psa.forEach(t),ekr=r(PJe," (Wav2Vec2-Conformer model)"),PJe.forEach(t),okr=i(si),j3=n(si,"LI",{});var BJe=s(j3);RAe=n(BJe,"STRONG",{});var _sa=s(RAe);rkr=r(_sa,"wavlm"),_sa.forEach(t),tkr=r(BJe," \u2014 "),Toe=n(BJe,"A",{href:!0});var bsa=s(Toe);akr=r(bsa,"WavLMForXVector"),bsa.forEach(t),nkr=r(BJe," (WavLM model)"),BJe.forEach(t),si.forEach(t),skr=i(Ua),G3=n(Ua,"P",{});var IJe=s(G3);lkr=r(IJe,"The model is set in evaluation mode by default using "),PAe=n(IJe,"CODE",{});var vsa=s(PAe);ikr=r(vsa,"model.eval()"),vsa.forEach(t),dkr=r(IJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),BAe=n(IJe,"CODE",{});var Fsa=s(BAe);mkr=r(Fsa,"model.train()"),Fsa.forEach(t),IJe.forEach(t),ckr=i(Ua),T(O3.$$.fragment,Ua),Ua.forEach(t),ni.forEach(t),Lao=i(c),zm=n(c,"H2",{class:!0});var Qso=s(zm);V3=n(Qso,"A",{id:!0,class:!0,href:!0});var Tsa=s(V3);IAe=n(Tsa,"SPAN",{});var Msa=s(IAe);T(qS.$$.fragment,Msa),Msa.forEach(t),Tsa.forEach(t),fkr=i(Qso),NAe=n(Qso,"SPAN",{});var Esa=s(NAe);gkr=r(Esa,"AutoModelForMaskedImageModeling"),Esa.forEach(t),Qso.forEach(t),yao=i(c),ar=n(c,"DIV",{class:!0});var li=s(ar);T(DS.$$.fragment,li),hkr=i(li),Qm=n(li,"P",{});var Ume=s(Qm);ukr=r(Ume,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),Moe=n(Ume,"A",{href:!0});var Csa=s(Moe);pkr=r(Csa,"from_pretrained()"),Csa.forEach(t),_kr=r(Ume," class method or the "),Eoe=n(Ume,"A",{href:!0});var wsa=s(Eoe);bkr=r(wsa,"from_config()"),wsa.forEach(t),vkr=r(Ume,` class
method.`),Ume.forEach(t),Fkr=i(li),jS=n(li,"P",{});var Wso=s(jS);Tkr=r(Wso,"This class cannot be instantiated directly using "),qAe=n(Wso,"CODE",{});var Asa=s(qAe);Mkr=r(Asa,"__init__()"),Asa.forEach(t),Ekr=r(Wso," (throws an error)."),Wso.forEach(t),Ckr=i(li),zt=n(li,"DIV",{class:!0});var X9=s(zt);T(GS.$$.fragment,X9),wkr=i(X9),DAe=n(X9,"P",{});var Lsa=s(DAe);Akr=r(Lsa,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),Lsa.forEach(t),Lkr=i(X9),Wm=n(X9,"P",{});var Hme=s(Wm);ykr=r(Hme,`Note:
Loading a model from its configuration file does `),jAe=n(Hme,"STRONG",{});var ysa=s(jAe);xkr=r(ysa,"not"),ysa.forEach(t),$kr=r(Hme,` load the model weights. It only affects the
model\u2019s configuration. Use `),Coe=n(Hme,"A",{href:!0});var xsa=s(Coe);kkr=r(xsa,"from_pretrained()"),xsa.forEach(t),Skr=r(Hme," to load the model weights."),Hme.forEach(t),Rkr=i(X9),T(X3.$$.fragment,X9),X9.forEach(t),Pkr=i(li),Mo=n(li,"DIV",{class:!0});var Ha=s(Mo);T(OS.$$.fragment,Ha),Bkr=i(Ha),GAe=n(Ha,"P",{});var $sa=s(GAe);Ikr=r($sa,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),$sa.forEach(t),Nkr=i(Ha),yn=n(Ha,"P",{});var z9=s(yn);qkr=r(z9,"The model class to instantiate is selected based on the "),OAe=n(z9,"CODE",{});var ksa=s(OAe);Dkr=r(ksa,"model_type"),ksa.forEach(t),jkr=r(z9,` property of the config object (either
passed as an argument or loaded from `),VAe=n(z9,"CODE",{});var Ssa=s(VAe);Gkr=r(Ssa,"pretrained_model_name_or_path"),Ssa.forEach(t),Okr=r(z9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),XAe=n(z9,"CODE",{});var Rsa=s(XAe);Vkr=r(Rsa,"pretrained_model_name_or_path"),Rsa.forEach(t),Xkr=r(z9,":"),z9.forEach(t),zkr=i(Ha),xn=n(Ha,"UL",{});var Q9=s(xn);z3=n(Q9,"LI",{});var NJe=s(z3);zAe=n(NJe,"STRONG",{});var Psa=s(zAe);Qkr=r(Psa,"deit"),Psa.forEach(t),Wkr=r(NJe," \u2014 "),woe=n(NJe,"A",{href:!0});var Bsa=s(woe);Ukr=r(Bsa,"DeiTForMaskedImageModeling"),Bsa.forEach(t),Hkr=r(NJe," (DeiT model)"),NJe.forEach(t),Jkr=i(Q9),Q3=n(Q9,"LI",{});var qJe=s(Q3);QAe=n(qJe,"STRONG",{});var Isa=s(QAe);Ykr=r(Isa,"swin"),Isa.forEach(t),Zkr=r(qJe," \u2014 "),Aoe=n(qJe,"A",{href:!0});var Nsa=s(Aoe);Kkr=r(Nsa,"SwinForMaskedImageModeling"),Nsa.forEach(t),eSr=r(qJe," (Swin Transformer model)"),qJe.forEach(t),oSr=i(Q9),W3=n(Q9,"LI",{});var DJe=s(W3);WAe=n(DJe,"STRONG",{});var qsa=s(WAe);rSr=r(qsa,"swinv2"),qsa.forEach(t),tSr=r(DJe," \u2014 "),Loe=n(DJe,"A",{href:!0});var Dsa=s(Loe);aSr=r(Dsa,"Swinv2ForMaskedImageModeling"),Dsa.forEach(t),nSr=r(DJe," (Swin Transformer V2 model)"),DJe.forEach(t),sSr=i(Q9),U3=n(Q9,"LI",{});var jJe=s(U3);UAe=n(jJe,"STRONG",{});var jsa=s(UAe);lSr=r(jsa,"vit"),jsa.forEach(t),iSr=r(jJe," \u2014 "),yoe=n(jJe,"A",{href:!0});var Gsa=s(yoe);dSr=r(Gsa,"ViTForMaskedImageModeling"),Gsa.forEach(t),mSr=r(jJe," (ViT model)"),jJe.forEach(t),Q9.forEach(t),cSr=i(Ha),H3=n(Ha,"P",{});var GJe=s(H3);fSr=r(GJe,"The model is set in evaluation mode by default using "),HAe=n(GJe,"CODE",{});var Osa=s(HAe);gSr=r(Osa,"model.eval()"),Osa.forEach(t),hSr=r(GJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),JAe=n(GJe,"CODE",{});var Vsa=s(JAe);uSr=r(Vsa,"model.train()"),Vsa.forEach(t),GJe.forEach(t),pSr=i(Ha),T(J3.$$.fragment,Ha),Ha.forEach(t),li.forEach(t),xao=i(c),Um=n(c,"H2",{class:!0});var Uso=s(Um);Y3=n(Uso,"A",{id:!0,class:!0,href:!0});var Xsa=s(Y3);YAe=n(Xsa,"SPAN",{});var zsa=s(YAe);T(VS.$$.fragment,zsa),zsa.forEach(t),Xsa.forEach(t),_Sr=i(Uso),ZAe=n(Uso,"SPAN",{});var Qsa=s(ZAe);bSr=r(Qsa,"AutoModelForObjectDetection"),Qsa.forEach(t),Uso.forEach(t),$ao=i(c),nr=n(c,"DIV",{class:!0});var ii=s(nr);T(XS.$$.fragment,ii),vSr=i(ii),Hm=n(ii,"P",{});var Jme=s(Hm);FSr=r(Jme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),xoe=n(Jme,"A",{href:!0});var Wsa=s(xoe);TSr=r(Wsa,"from_pretrained()"),Wsa.forEach(t),MSr=r(Jme," class method or the "),$oe=n(Jme,"A",{href:!0});var Usa=s($oe);ESr=r(Usa,"from_config()"),Usa.forEach(t),CSr=r(Jme,` class
method.`),Jme.forEach(t),wSr=i(ii),zS=n(ii,"P",{});var Hso=s(zS);ASr=r(Hso,"This class cannot be instantiated directly using "),KAe=n(Hso,"CODE",{});var Hsa=s(KAe);LSr=r(Hsa,"__init__()"),Hsa.forEach(t),ySr=r(Hso," (throws an error)."),Hso.forEach(t),xSr=i(ii),Qt=n(ii,"DIV",{class:!0});var W9=s(Qt);T(QS.$$.fragment,W9),$Sr=i(W9),e6e=n(W9,"P",{});var Jsa=s(e6e);kSr=r(Jsa,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),Jsa.forEach(t),SSr=i(W9),Jm=n(W9,"P",{});var Yme=s(Jm);RSr=r(Yme,`Note:
Loading a model from its configuration file does `),o6e=n(Yme,"STRONG",{});var Ysa=s(o6e);PSr=r(Ysa,"not"),Ysa.forEach(t),BSr=r(Yme,` load the model weights. It only affects the
model\u2019s configuration. Use `),koe=n(Yme,"A",{href:!0});var Zsa=s(koe);ISr=r(Zsa,"from_pretrained()"),Zsa.forEach(t),NSr=r(Yme," to load the model weights."),Yme.forEach(t),qSr=i(W9),T(Z3.$$.fragment,W9),W9.forEach(t),DSr=i(ii),Eo=n(ii,"DIV",{class:!0});var Ja=s(Eo);T(WS.$$.fragment,Ja),jSr=i(Ja),r6e=n(Ja,"P",{});var Ksa=s(r6e);GSr=r(Ksa,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),Ksa.forEach(t),OSr=i(Ja),$n=n(Ja,"P",{});var U9=s($n);VSr=r(U9,"The model class to instantiate is selected based on the "),t6e=n(U9,"CODE",{});var ela=s(t6e);XSr=r(ela,"model_type"),ela.forEach(t),zSr=r(U9,` property of the config object (either
passed as an argument or loaded from `),a6e=n(U9,"CODE",{});var ola=s(a6e);QSr=r(ola,"pretrained_model_name_or_path"),ola.forEach(t),WSr=r(U9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n6e=n(U9,"CODE",{});var rla=s(n6e);USr=r(rla,"pretrained_model_name_or_path"),rla.forEach(t),HSr=r(U9,":"),U9.forEach(t),JSr=i(Ja),_t=n(Ja,"UL",{});var di=s(_t);K3=n(di,"LI",{});var OJe=s(K3);s6e=n(OJe,"STRONG",{});var tla=s(s6e);YSr=r(tla,"conditional_detr"),tla.forEach(t),ZSr=r(OJe," \u2014 "),Soe=n(OJe,"A",{href:!0});var ala=s(Soe);KSr=r(ala,"ConditionalDetrForObjectDetection"),ala.forEach(t),eRr=r(OJe," (Conditional DETR model)"),OJe.forEach(t),oRr=i(di),e5=n(di,"LI",{});var VJe=s(e5);l6e=n(VJe,"STRONG",{});var nla=s(l6e);rRr=r(nla,"deformable_detr"),nla.forEach(t),tRr=r(VJe," \u2014 "),Roe=n(VJe,"A",{href:!0});var sla=s(Roe);aRr=r(sla,"DeformableDetrForObjectDetection"),sla.forEach(t),nRr=r(VJe," (Deformable DETR model)"),VJe.forEach(t),sRr=i(di),o5=n(di,"LI",{});var XJe=s(o5);i6e=n(XJe,"STRONG",{});var lla=s(i6e);lRr=r(lla,"detr"),lla.forEach(t),iRr=r(XJe," \u2014 "),Poe=n(XJe,"A",{href:!0});var ila=s(Poe);dRr=r(ila,"DetrForObjectDetection"),ila.forEach(t),mRr=r(XJe," (DETR model)"),XJe.forEach(t),cRr=i(di),r5=n(di,"LI",{});var zJe=s(r5);d6e=n(zJe,"STRONG",{});var dla=s(d6e);fRr=r(dla,"table-transformer"),dla.forEach(t),gRr=r(zJe," \u2014 "),Boe=n(zJe,"A",{href:!0});var mla=s(Boe);hRr=r(mla,"TableTransformerForObjectDetection"),mla.forEach(t),uRr=r(zJe," (Table Transformer model)"),zJe.forEach(t),pRr=i(di),t5=n(di,"LI",{});var QJe=s(t5);m6e=n(QJe,"STRONG",{});var cla=s(m6e);_Rr=r(cla,"yolos"),cla.forEach(t),bRr=r(QJe," \u2014 "),Ioe=n(QJe,"A",{href:!0});var fla=s(Ioe);vRr=r(fla,"YolosForObjectDetection"),fla.forEach(t),FRr=r(QJe," (YOLOS model)"),QJe.forEach(t),di.forEach(t),TRr=i(Ja),a5=n(Ja,"P",{});var WJe=s(a5);MRr=r(WJe,"The model is set in evaluation mode by default using "),c6e=n(WJe,"CODE",{});var gla=s(c6e);ERr=r(gla,"model.eval()"),gla.forEach(t),CRr=r(WJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),f6e=n(WJe,"CODE",{});var hla=s(f6e);wRr=r(hla,"model.train()"),hla.forEach(t),WJe.forEach(t),ARr=i(Ja),T(n5.$$.fragment,Ja),Ja.forEach(t),ii.forEach(t),kao=i(c),Ym=n(c,"H2",{class:!0});var Jso=s(Ym);s5=n(Jso,"A",{id:!0,class:!0,href:!0});var ula=s(s5);g6e=n(ula,"SPAN",{});var pla=s(g6e);T(US.$$.fragment,pla),pla.forEach(t),ula.forEach(t),LRr=i(Jso),h6e=n(Jso,"SPAN",{});var _la=s(h6e);yRr=r(_la,"AutoModelForImageSegmentation"),_la.forEach(t),Jso.forEach(t),Sao=i(c),sr=n(c,"DIV",{class:!0});var mi=s(sr);T(HS.$$.fragment,mi),xRr=i(mi),Zm=n(mi,"P",{});var Zme=s(Zm);$Rr=r(Zme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),Noe=n(Zme,"A",{href:!0});var bla=s(Noe);kRr=r(bla,"from_pretrained()"),bla.forEach(t),SRr=r(Zme," class method or the "),qoe=n(Zme,"A",{href:!0});var vla=s(qoe);RRr=r(vla,"from_config()"),vla.forEach(t),PRr=r(Zme,` class
method.`),Zme.forEach(t),BRr=i(mi),JS=n(mi,"P",{});var Yso=s(JS);IRr=r(Yso,"This class cannot be instantiated directly using "),u6e=n(Yso,"CODE",{});var Fla=s(u6e);NRr=r(Fla,"__init__()"),Fla.forEach(t),qRr=r(Yso," (throws an error)."),Yso.forEach(t),DRr=i(mi),Wt=n(mi,"DIV",{class:!0});var H9=s(Wt);T(YS.$$.fragment,H9),jRr=i(H9),p6e=n(H9,"P",{});var Tla=s(p6e);GRr=r(Tla,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),Tla.forEach(t),ORr=i(H9),Km=n(H9,"P",{});var Kme=s(Km);VRr=r(Kme,`Note:
Loading a model from its configuration file does `),_6e=n(Kme,"STRONG",{});var Mla=s(_6e);XRr=r(Mla,"not"),Mla.forEach(t),zRr=r(Kme,` load the model weights. It only affects the
model\u2019s configuration. Use `),Doe=n(Kme,"A",{href:!0});var Ela=s(Doe);QRr=r(Ela,"from_pretrained()"),Ela.forEach(t),WRr=r(Kme," to load the model weights."),Kme.forEach(t),URr=i(H9),T(l5.$$.fragment,H9),H9.forEach(t),HRr=i(mi),Co=n(mi,"DIV",{class:!0});var Ya=s(Co);T(ZS.$$.fragment,Ya),JRr=i(Ya),b6e=n(Ya,"P",{});var Cla=s(b6e);YRr=r(Cla,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),Cla.forEach(t),ZRr=i(Ya),kn=n(Ya,"P",{});var J9=s(kn);KRr=r(J9,"The model class to instantiate is selected based on the "),v6e=n(J9,"CODE",{});var wla=s(v6e);ePr=r(wla,"model_type"),wla.forEach(t),oPr=r(J9,` property of the config object (either
passed as an argument or loaded from `),F6e=n(J9,"CODE",{});var Ala=s(F6e);rPr=r(Ala,"pretrained_model_name_or_path"),Ala.forEach(t),tPr=r(J9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T6e=n(J9,"CODE",{});var Lla=s(T6e);aPr=r(Lla,"pretrained_model_name_or_path"),Lla.forEach(t),nPr=r(J9,":"),J9.forEach(t),sPr=i(Ya),M6e=n(Ya,"UL",{});var yla=s(M6e);i5=n(yla,"LI",{});var UJe=s(i5);E6e=n(UJe,"STRONG",{});var xla=s(E6e);lPr=r(xla,"detr"),xla.forEach(t),iPr=r(UJe," \u2014 "),joe=n(UJe,"A",{href:!0});var $la=s(joe);dPr=r($la,"DetrForSegmentation"),$la.forEach(t),mPr=r(UJe," (DETR model)"),UJe.forEach(t),yla.forEach(t),cPr=i(Ya),d5=n(Ya,"P",{});var HJe=s(d5);fPr=r(HJe,"The model is set in evaluation mode by default using "),C6e=n(HJe,"CODE",{});var kla=s(C6e);gPr=r(kla,"model.eval()"),kla.forEach(t),hPr=r(HJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),w6e=n(HJe,"CODE",{});var Sla=s(w6e);uPr=r(Sla,"model.train()"),Sla.forEach(t),HJe.forEach(t),pPr=i(Ya),T(m5.$$.fragment,Ya),Ya.forEach(t),mi.forEach(t),Rao=i(c),ec=n(c,"H2",{class:!0});var Zso=s(ec);c5=n(Zso,"A",{id:!0,class:!0,href:!0});var Rla=s(c5);A6e=n(Rla,"SPAN",{});var Pla=s(A6e);T(KS.$$.fragment,Pla),Pla.forEach(t),Rla.forEach(t),_Pr=i(Zso),L6e=n(Zso,"SPAN",{});var Bla=s(L6e);bPr=r(Bla,"AutoModelForSemanticSegmentation"),Bla.forEach(t),Zso.forEach(t),Pao=i(c),lr=n(c,"DIV",{class:!0});var ci=s(lr);T(eR.$$.fragment,ci),vPr=i(ci),oc=n(ci,"P",{});var ece=s(oc);FPr=r(ece,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),Goe=n(ece,"A",{href:!0});var Ila=s(Goe);TPr=r(Ila,"from_pretrained()"),Ila.forEach(t),MPr=r(ece," class method or the "),Ooe=n(ece,"A",{href:!0});var Nla=s(Ooe);EPr=r(Nla,"from_config()"),Nla.forEach(t),CPr=r(ece,` class
method.`),ece.forEach(t),wPr=i(ci),oR=n(ci,"P",{});var Kso=s(oR);APr=r(Kso,"This class cannot be instantiated directly using "),y6e=n(Kso,"CODE",{});var qla=s(y6e);LPr=r(qla,"__init__()"),qla.forEach(t),yPr=r(Kso," (throws an error)."),Kso.forEach(t),xPr=i(ci),Ut=n(ci,"DIV",{class:!0});var Y9=s(Ut);T(rR.$$.fragment,Y9),$Pr=i(Y9),x6e=n(Y9,"P",{});var Dla=s(x6e);kPr=r(Dla,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),Dla.forEach(t),SPr=i(Y9),rc=n(Y9,"P",{});var oce=s(rc);RPr=r(oce,`Note:
Loading a model from its configuration file does `),$6e=n(oce,"STRONG",{});var jla=s($6e);PPr=r(jla,"not"),jla.forEach(t),BPr=r(oce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Voe=n(oce,"A",{href:!0});var Gla=s(Voe);IPr=r(Gla,"from_pretrained()"),Gla.forEach(t),NPr=r(oce," to load the model weights."),oce.forEach(t),qPr=i(Y9),T(f5.$$.fragment,Y9),Y9.forEach(t),DPr=i(ci),wo=n(ci,"DIV",{class:!0});var Za=s(wo);T(tR.$$.fragment,Za),jPr=i(Za),k6e=n(Za,"P",{});var Ola=s(k6e);GPr=r(Ola,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Ola.forEach(t),OPr=i(Za),Sn=n(Za,"P",{});var Z9=s(Sn);VPr=r(Z9,"The model class to instantiate is selected based on the "),S6e=n(Z9,"CODE",{});var Vla=s(S6e);XPr=r(Vla,"model_type"),Vla.forEach(t),zPr=r(Z9,` property of the config object (either
passed as an argument or loaded from `),R6e=n(Z9,"CODE",{});var Xla=s(R6e);QPr=r(Xla,"pretrained_model_name_or_path"),Xla.forEach(t),WPr=r(Z9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P6e=n(Z9,"CODE",{});var zla=s(P6e);UPr=r(zla,"pretrained_model_name_or_path"),zla.forEach(t),HPr=r(Z9,":"),Z9.forEach(t),JPr=i(Za),bt=n(Za,"UL",{});var fi=s(bt);g5=n(fi,"LI",{});var JJe=s(g5);B6e=n(JJe,"STRONG",{});var Qla=s(B6e);YPr=r(Qla,"beit"),Qla.forEach(t),ZPr=r(JJe," \u2014 "),Xoe=n(JJe,"A",{href:!0});var Wla=s(Xoe);KPr=r(Wla,"BeitForSemanticSegmentation"),Wla.forEach(t),eBr=r(JJe," (BEiT model)"),JJe.forEach(t),oBr=i(fi),h5=n(fi,"LI",{});var YJe=s(h5);I6e=n(YJe,"STRONG",{});var Ula=s(I6e);rBr=r(Ula,"data2vec-vision"),Ula.forEach(t),tBr=r(YJe," \u2014 "),zoe=n(YJe,"A",{href:!0});var Hla=s(zoe);aBr=r(Hla,"Data2VecVisionForSemanticSegmentation"),Hla.forEach(t),nBr=r(YJe," (Data2VecVision model)"),YJe.forEach(t),sBr=i(fi),u5=n(fi,"LI",{});var ZJe=s(u5);N6e=n(ZJe,"STRONG",{});var Jla=s(N6e);lBr=r(Jla,"dpt"),Jla.forEach(t),iBr=r(ZJe," \u2014 "),Qoe=n(ZJe,"A",{href:!0});var Yla=s(Qoe);dBr=r(Yla,"DPTForSemanticSegmentation"),Yla.forEach(t),mBr=r(ZJe," (DPT model)"),ZJe.forEach(t),cBr=i(fi),p5=n(fi,"LI",{});var KJe=s(p5);q6e=n(KJe,"STRONG",{});var Zla=s(q6e);fBr=r(Zla,"mobilevit"),Zla.forEach(t),gBr=r(KJe," \u2014 "),Woe=n(KJe,"A",{href:!0});var Kla=s(Woe);hBr=r(Kla,"MobileViTForSemanticSegmentation"),Kla.forEach(t),uBr=r(KJe," (MobileViT model)"),KJe.forEach(t),pBr=i(fi),_5=n(fi,"LI",{});var eYe=s(_5);D6e=n(eYe,"STRONG",{});var eia=s(D6e);_Br=r(eia,"segformer"),eia.forEach(t),bBr=r(eYe," \u2014 "),Uoe=n(eYe,"A",{href:!0});var oia=s(Uoe);vBr=r(oia,"SegformerForSemanticSegmentation"),oia.forEach(t),FBr=r(eYe," (SegFormer model)"),eYe.forEach(t),fi.forEach(t),TBr=i(Za),b5=n(Za,"P",{});var oYe=s(b5);MBr=r(oYe,"The model is set in evaluation mode by default using "),j6e=n(oYe,"CODE",{});var ria=s(j6e);EBr=r(ria,"model.eval()"),ria.forEach(t),CBr=r(oYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),G6e=n(oYe,"CODE",{});var tia=s(G6e);wBr=r(tia,"model.train()"),tia.forEach(t),oYe.forEach(t),ABr=i(Za),T(v5.$$.fragment,Za),Za.forEach(t),ci.forEach(t),Bao=i(c),tc=n(c,"H2",{class:!0});var elo=s(tc);F5=n(elo,"A",{id:!0,class:!0,href:!0});var aia=s(F5);O6e=n(aia,"SPAN",{});var nia=s(O6e);T(aR.$$.fragment,nia),nia.forEach(t),aia.forEach(t),LBr=i(elo),V6e=n(elo,"SPAN",{});var sia=s(V6e);yBr=r(sia,"AutoModelForInstanceSegmentation"),sia.forEach(t),elo.forEach(t),Iao=i(c),ir=n(c,"DIV",{class:!0});var gi=s(ir);T(nR.$$.fragment,gi),xBr=i(gi),ac=n(gi,"P",{});var rce=s(ac);$Br=r(rce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),Hoe=n(rce,"A",{href:!0});var lia=s(Hoe);kBr=r(lia,"from_pretrained()"),lia.forEach(t),SBr=r(rce," class method or the "),Joe=n(rce,"A",{href:!0});var iia=s(Joe);RBr=r(iia,"from_config()"),iia.forEach(t),PBr=r(rce,` class
method.`),rce.forEach(t),BBr=i(gi),sR=n(gi,"P",{});var olo=s(sR);IBr=r(olo,"This class cannot be instantiated directly using "),X6e=n(olo,"CODE",{});var dia=s(X6e);NBr=r(dia,"__init__()"),dia.forEach(t),qBr=r(olo," (throws an error)."),olo.forEach(t),DBr=i(gi),Ht=n(gi,"DIV",{class:!0});var K9=s(Ht);T(lR.$$.fragment,K9),jBr=i(K9),z6e=n(K9,"P",{});var mia=s(z6e);GBr=r(mia,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),mia.forEach(t),OBr=i(K9),nc=n(K9,"P",{});var tce=s(nc);VBr=r(tce,`Note:
Loading a model from its configuration file does `),Q6e=n(tce,"STRONG",{});var cia=s(Q6e);XBr=r(cia,"not"),cia.forEach(t),zBr=r(tce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Yoe=n(tce,"A",{href:!0});var fia=s(Yoe);QBr=r(fia,"from_pretrained()"),fia.forEach(t),WBr=r(tce," to load the model weights."),tce.forEach(t),UBr=i(K9),T(T5.$$.fragment,K9),K9.forEach(t),HBr=i(gi),Ao=n(gi,"DIV",{class:!0});var Ka=s(Ao);T(iR.$$.fragment,Ka),JBr=i(Ka),W6e=n(Ka,"P",{});var gia=s(W6e);YBr=r(gia,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),gia.forEach(t),ZBr=i(Ka),Rn=n(Ka,"P",{});var ex=s(Rn);KBr=r(ex,"The model class to instantiate is selected based on the "),U6e=n(ex,"CODE",{});var hia=s(U6e);eIr=r(hia,"model_type"),hia.forEach(t),oIr=r(ex,` property of the config object (either
passed as an argument or loaded from `),H6e=n(ex,"CODE",{});var uia=s(H6e);rIr=r(uia,"pretrained_model_name_or_path"),uia.forEach(t),tIr=r(ex,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),J6e=n(ex,"CODE",{});var pia=s(J6e);aIr=r(pia,"pretrained_model_name_or_path"),pia.forEach(t),nIr=r(ex,":"),ex.forEach(t),sIr=i(Ka),Y6e=n(Ka,"UL",{});var _ia=s(Y6e);M5=n(_ia,"LI",{});var rYe=s(M5);Z6e=n(rYe,"STRONG",{});var bia=s(Z6e);lIr=r(bia,"maskformer"),bia.forEach(t),iIr=r(rYe," \u2014 "),Zoe=n(rYe,"A",{href:!0});var via=s(Zoe);dIr=r(via,"MaskFormerForInstanceSegmentation"),via.forEach(t),mIr=r(rYe," (MaskFormer model)"),rYe.forEach(t),_ia.forEach(t),cIr=i(Ka),E5=n(Ka,"P",{});var tYe=s(E5);fIr=r(tYe,"The model is set in evaluation mode by default using "),K6e=n(tYe,"CODE",{});var Fia=s(K6e);gIr=r(Fia,"model.eval()"),Fia.forEach(t),hIr=r(tYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),e7e=n(tYe,"CODE",{});var Tia=s(e7e);uIr=r(Tia,"model.train()"),Tia.forEach(t),tYe.forEach(t),pIr=i(Ka),T(C5.$$.fragment,Ka),Ka.forEach(t),gi.forEach(t),Nao=i(c),sc=n(c,"H2",{class:!0});var rlo=s(sc);w5=n(rlo,"A",{id:!0,class:!0,href:!0});var Mia=s(w5);o7e=n(Mia,"SPAN",{});var Eia=s(o7e);T(dR.$$.fragment,Eia),Eia.forEach(t),Mia.forEach(t),_Ir=i(rlo),r7e=n(rlo,"SPAN",{});var Cia=s(r7e);bIr=r(Cia,"AutoModelForZeroShotObjectDetection"),Cia.forEach(t),rlo.forEach(t),qao=i(c),dr=n(c,"DIV",{class:!0});var hi=s(dr);T(mR.$$.fragment,hi),vIr=i(hi),lc=n(hi,"P",{});var ace=s(lc);FIr=r(ace,`This is a generic model class that will be instantiated as one of the model classes of the library (with a zero-shot object detection head) when created
with the `),Koe=n(ace,"A",{href:!0});var wia=s(Koe);TIr=r(wia,"from_pretrained()"),wia.forEach(t),MIr=r(ace," class method or the "),ere=n(ace,"A",{href:!0});var Aia=s(ere);EIr=r(Aia,"from_config()"),Aia.forEach(t),CIr=r(ace,` class
method.`),ace.forEach(t),wIr=i(hi),cR=n(hi,"P",{});var tlo=s(cR);AIr=r(tlo,"This class cannot be instantiated directly using "),t7e=n(tlo,"CODE",{});var Lia=s(t7e);LIr=r(Lia,"__init__()"),Lia.forEach(t),yIr=r(tlo," (throws an error)."),tlo.forEach(t),xIr=i(hi),Jt=n(hi,"DIV",{class:!0});var ox=s(Jt);T(fR.$$.fragment,ox),$Ir=i(ox),a7e=n(ox,"P",{});var yia=s(a7e);kIr=r(yia,"Instantiates one of the model classes of the library (with a zero-shot object detection head) from a configuration."),yia.forEach(t),SIr=i(ox),ic=n(ox,"P",{});var nce=s(ic);RIr=r(nce,`Note:
Loading a model from its configuration file does `),n7e=n(nce,"STRONG",{});var xia=s(n7e);PIr=r(xia,"not"),xia.forEach(t),BIr=r(nce,` load the model weights. It only affects the
model\u2019s configuration. Use `),ore=n(nce,"A",{href:!0});var $ia=s(ore);IIr=r($ia,"from_pretrained()"),$ia.forEach(t),NIr=r(nce," to load the model weights."),nce.forEach(t),qIr=i(ox),T(A5.$$.fragment,ox),ox.forEach(t),DIr=i(hi),Lo=n(hi,"DIV",{class:!0});var en=s(Lo);T(gR.$$.fragment,en),jIr=i(en),s7e=n(en,"P",{});var kia=s(s7e);GIr=r(kia,"Instantiate one of the model classes of the library (with a zero-shot object detection head) from a pretrained model."),kia.forEach(t),OIr=i(en),Pn=n(en,"P",{});var rx=s(Pn);VIr=r(rx,"The model class to instantiate is selected based on the "),l7e=n(rx,"CODE",{});var Sia=s(l7e);XIr=r(Sia,"model_type"),Sia.forEach(t),zIr=r(rx,` property of the config object (either
passed as an argument or loaded from `),i7e=n(rx,"CODE",{});var Ria=s(i7e);QIr=r(Ria,"pretrained_model_name_or_path"),Ria.forEach(t),WIr=r(rx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d7e=n(rx,"CODE",{});var Pia=s(d7e);UIr=r(Pia,"pretrained_model_name_or_path"),Pia.forEach(t),HIr=r(rx,":"),rx.forEach(t),JIr=i(en),m7e=n(en,"UL",{});var Bia=s(m7e);L5=n(Bia,"LI",{});var aYe=s(L5);c7e=n(aYe,"STRONG",{});var Iia=s(c7e);YIr=r(Iia,"owlvit"),Iia.forEach(t),ZIr=r(aYe," \u2014 "),rre=n(aYe,"A",{href:!0});var Nia=s(rre);KIr=r(Nia,"OwlViTForObjectDetection"),Nia.forEach(t),eNr=r(aYe," (OWL-ViT model)"),aYe.forEach(t),Bia.forEach(t),oNr=i(en),y5=n(en,"P",{});var nYe=s(y5);rNr=r(nYe,"The model is set in evaluation mode by default using "),f7e=n(nYe,"CODE",{});var qia=s(f7e);tNr=r(qia,"model.eval()"),qia.forEach(t),aNr=r(nYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),g7e=n(nYe,"CODE",{});var Dia=s(g7e);nNr=r(Dia,"model.train()"),Dia.forEach(t),nYe.forEach(t),sNr=i(en),T(x5.$$.fragment,en),en.forEach(t),hi.forEach(t),Dao=i(c),dc=n(c,"H2",{class:!0});var alo=s(dc);$5=n(alo,"A",{id:!0,class:!0,href:!0});var jia=s($5);h7e=n(jia,"SPAN",{});var Gia=s(h7e);T(hR.$$.fragment,Gia),Gia.forEach(t),jia.forEach(t),lNr=i(alo),u7e=n(alo,"SPAN",{});var Oia=s(u7e);iNr=r(Oia,"TFAutoModel"),Oia.forEach(t),alo.forEach(t),jao=i(c),mr=n(c,"DIV",{class:!0});var ui=s(mr);T(uR.$$.fragment,ui),dNr=i(ui),mc=n(ui,"P",{});var sce=s(mc);mNr=r(sce,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),tre=n(sce,"A",{href:!0});var Via=s(tre);cNr=r(Via,"from_pretrained()"),Via.forEach(t),fNr=r(sce," class method or the "),are=n(sce,"A",{href:!0});var Xia=s(are);gNr=r(Xia,"from_config()"),Xia.forEach(t),hNr=r(sce,` class
method.`),sce.forEach(t),uNr=i(ui),pR=n(ui,"P",{});var nlo=s(pR);pNr=r(nlo,"This class cannot be instantiated directly using "),p7e=n(nlo,"CODE",{});var zia=s(p7e);_Nr=r(zia,"__init__()"),zia.forEach(t),bNr=r(nlo," (throws an error)."),nlo.forEach(t),vNr=i(ui),Yt=n(ui,"DIV",{class:!0});var tx=s(Yt);T(_R.$$.fragment,tx),FNr=i(tx),_7e=n(tx,"P",{});var Qia=s(_7e);TNr=r(Qia,"Instantiates one of the base model classes of the library from a configuration."),Qia.forEach(t),MNr=i(tx),cc=n(tx,"P",{});var lce=s(cc);ENr=r(lce,`Note:
Loading a model from its configuration file does `),b7e=n(lce,"STRONG",{});var Wia=s(b7e);CNr=r(Wia,"not"),Wia.forEach(t),wNr=r(lce,` load the model weights. It only affects the
model\u2019s configuration. Use `),nre=n(lce,"A",{href:!0});var Uia=s(nre);ANr=r(Uia,"from_pretrained()"),Uia.forEach(t),LNr=r(lce," to load the model weights."),lce.forEach(t),yNr=i(tx),T(k5.$$.fragment,tx),tx.forEach(t),xNr=i(ui),jr=n(ui,"DIV",{class:!0});var pi=s(jr);T(bR.$$.fragment,pi),$Nr=i(pi),v7e=n(pi,"P",{});var Hia=s(v7e);kNr=r(Hia,"Instantiate one of the base model classes of the library from a pretrained model."),Hia.forEach(t),SNr=i(pi),Bn=n(pi,"P",{});var ax=s(Bn);RNr=r(ax,"The model class to instantiate is selected based on the "),F7e=n(ax,"CODE",{});var Jia=s(F7e);PNr=r(Jia,"model_type"),Jia.forEach(t),BNr=r(ax,` property of the config object (either
passed as an argument or loaded from `),T7e=n(ax,"CODE",{});var Yia=s(T7e);INr=r(Yia,"pretrained_model_name_or_path"),Yia.forEach(t),NNr=r(ax,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),M7e=n(ax,"CODE",{});var Zia=s(M7e);qNr=r(Zia,"pretrained_model_name_or_path"),Zia.forEach(t),DNr=r(ax,":"),ax.forEach(t),jNr=i(pi),P=n(pi,"UL",{});var I=s(P);S5=n(I,"LI",{});var sYe=s(S5);E7e=n(sYe,"STRONG",{});var Kia=s(E7e);GNr=r(Kia,"albert"),Kia.forEach(t),ONr=r(sYe," \u2014 "),sre=n(sYe,"A",{href:!0});var eda=s(sre);VNr=r(eda,"TFAlbertModel"),eda.forEach(t),XNr=r(sYe," (ALBERT model)"),sYe.forEach(t),zNr=i(I),R5=n(I,"LI",{});var lYe=s(R5);C7e=n(lYe,"STRONG",{});var oda=s(C7e);QNr=r(oda,"bart"),oda.forEach(t),WNr=r(lYe," \u2014 "),lre=n(lYe,"A",{href:!0});var rda=s(lre);UNr=r(rda,"TFBartModel"),rda.forEach(t),HNr=r(lYe," (BART model)"),lYe.forEach(t),JNr=i(I),P5=n(I,"LI",{});var iYe=s(P5);w7e=n(iYe,"STRONG",{});var tda=s(w7e);YNr=r(tda,"bert"),tda.forEach(t),ZNr=r(iYe," \u2014 "),ire=n(iYe,"A",{href:!0});var ada=s(ire);KNr=r(ada,"TFBertModel"),ada.forEach(t),eqr=r(iYe," (BERT model)"),iYe.forEach(t),oqr=i(I),B5=n(I,"LI",{});var dYe=s(B5);A7e=n(dYe,"STRONG",{});var nda=s(A7e);rqr=r(nda,"blenderbot"),nda.forEach(t),tqr=r(dYe," \u2014 "),dre=n(dYe,"A",{href:!0});var sda=s(dre);aqr=r(sda,"TFBlenderbotModel"),sda.forEach(t),nqr=r(dYe," (Blenderbot model)"),dYe.forEach(t),sqr=i(I),I5=n(I,"LI",{});var mYe=s(I5);L7e=n(mYe,"STRONG",{});var lda=s(L7e);lqr=r(lda,"blenderbot-small"),lda.forEach(t),iqr=r(mYe," \u2014 "),mre=n(mYe,"A",{href:!0});var ida=s(mre);dqr=r(ida,"TFBlenderbotSmallModel"),ida.forEach(t),mqr=r(mYe," (BlenderbotSmall model)"),mYe.forEach(t),cqr=i(I),N5=n(I,"LI",{});var cYe=s(N5);y7e=n(cYe,"STRONG",{});var dda=s(y7e);fqr=r(dda,"camembert"),dda.forEach(t),gqr=r(cYe," \u2014 "),cre=n(cYe,"A",{href:!0});var mda=s(cre);hqr=r(mda,"TFCamembertModel"),mda.forEach(t),uqr=r(cYe," (CamemBERT model)"),cYe.forEach(t),pqr=i(I),q5=n(I,"LI",{});var fYe=s(q5);x7e=n(fYe,"STRONG",{});var cda=s(x7e);_qr=r(cda,"clip"),cda.forEach(t),bqr=r(fYe," \u2014 "),fre=n(fYe,"A",{href:!0});var fda=s(fre);vqr=r(fda,"TFCLIPModel"),fda.forEach(t),Fqr=r(fYe," (CLIP model)"),fYe.forEach(t),Tqr=i(I),D5=n(I,"LI",{});var gYe=s(D5);$7e=n(gYe,"STRONG",{});var gda=s($7e);Mqr=r(gda,"convbert"),gda.forEach(t),Eqr=r(gYe," \u2014 "),gre=n(gYe,"A",{href:!0});var hda=s(gre);Cqr=r(hda,"TFConvBertModel"),hda.forEach(t),wqr=r(gYe," (ConvBERT model)"),gYe.forEach(t),Aqr=i(I),j5=n(I,"LI",{});var hYe=s(j5);k7e=n(hYe,"STRONG",{});var uda=s(k7e);Lqr=r(uda,"convnext"),uda.forEach(t),yqr=r(hYe," \u2014 "),hre=n(hYe,"A",{href:!0});var pda=s(hre);xqr=r(pda,"TFConvNextModel"),pda.forEach(t),$qr=r(hYe," (ConvNeXT model)"),hYe.forEach(t),kqr=i(I),G5=n(I,"LI",{});var uYe=s(G5);S7e=n(uYe,"STRONG",{});var _da=s(S7e);Sqr=r(_da,"ctrl"),_da.forEach(t),Rqr=r(uYe," \u2014 "),ure=n(uYe,"A",{href:!0});var bda=s(ure);Pqr=r(bda,"TFCTRLModel"),bda.forEach(t),Bqr=r(uYe," (CTRL model)"),uYe.forEach(t),Iqr=i(I),O5=n(I,"LI",{});var pYe=s(O5);R7e=n(pYe,"STRONG",{});var vda=s(R7e);Nqr=r(vda,"cvt"),vda.forEach(t),qqr=r(pYe," \u2014 "),pre=n(pYe,"A",{href:!0});var Fda=s(pre);Dqr=r(Fda,"TFCvtModel"),Fda.forEach(t),jqr=r(pYe," (CvT model)"),pYe.forEach(t),Gqr=i(I),V5=n(I,"LI",{});var _Ye=s(V5);P7e=n(_Ye,"STRONG",{});var Tda=s(P7e);Oqr=r(Tda,"data2vec-vision"),Tda.forEach(t),Vqr=r(_Ye," \u2014 "),_re=n(_Ye,"A",{href:!0});var Mda=s(_re);Xqr=r(Mda,"TFData2VecVisionModel"),Mda.forEach(t),zqr=r(_Ye," (Data2VecVision model)"),_Ye.forEach(t),Qqr=i(I),X5=n(I,"LI",{});var bYe=s(X5);B7e=n(bYe,"STRONG",{});var Eda=s(B7e);Wqr=r(Eda,"deberta"),Eda.forEach(t),Uqr=r(bYe," \u2014 "),bre=n(bYe,"A",{href:!0});var Cda=s(bre);Hqr=r(Cda,"TFDebertaModel"),Cda.forEach(t),Jqr=r(bYe," (DeBERTa model)"),bYe.forEach(t),Yqr=i(I),z5=n(I,"LI",{});var vYe=s(z5);I7e=n(vYe,"STRONG",{});var wda=s(I7e);Zqr=r(wda,"deberta-v2"),wda.forEach(t),Kqr=r(vYe," \u2014 "),vre=n(vYe,"A",{href:!0});var Ada=s(vre);eDr=r(Ada,"TFDebertaV2Model"),Ada.forEach(t),oDr=r(vYe," (DeBERTa-v2 model)"),vYe.forEach(t),rDr=i(I),Q5=n(I,"LI",{});var FYe=s(Q5);N7e=n(FYe,"STRONG",{});var Lda=s(N7e);tDr=r(Lda,"deit"),Lda.forEach(t),aDr=r(FYe," \u2014 "),Fre=n(FYe,"A",{href:!0});var yda=s(Fre);nDr=r(yda,"TFDeiTModel"),yda.forEach(t),sDr=r(FYe," (DeiT model)"),FYe.forEach(t),lDr=i(I),W5=n(I,"LI",{});var TYe=s(W5);q7e=n(TYe,"STRONG",{});var xda=s(q7e);iDr=r(xda,"distilbert"),xda.forEach(t),dDr=r(TYe," \u2014 "),Tre=n(TYe,"A",{href:!0});var $da=s(Tre);mDr=r($da,"TFDistilBertModel"),$da.forEach(t),cDr=r(TYe," (DistilBERT model)"),TYe.forEach(t),fDr=i(I),U5=n(I,"LI",{});var MYe=s(U5);D7e=n(MYe,"STRONG",{});var kda=s(D7e);gDr=r(kda,"dpr"),kda.forEach(t),hDr=r(MYe," \u2014 "),Mre=n(MYe,"A",{href:!0});var Sda=s(Mre);uDr=r(Sda,"TFDPRQuestionEncoder"),Sda.forEach(t),pDr=r(MYe," (DPR model)"),MYe.forEach(t),_Dr=i(I),H5=n(I,"LI",{});var EYe=s(H5);j7e=n(EYe,"STRONG",{});var Rda=s(j7e);bDr=r(Rda,"electra"),Rda.forEach(t),vDr=r(EYe," \u2014 "),Ere=n(EYe,"A",{href:!0});var Pda=s(Ere);FDr=r(Pda,"TFElectraModel"),Pda.forEach(t),TDr=r(EYe," (ELECTRA model)"),EYe.forEach(t),MDr=i(I),J5=n(I,"LI",{});var CYe=s(J5);G7e=n(CYe,"STRONG",{});var Bda=s(G7e);EDr=r(Bda,"esm"),Bda.forEach(t),CDr=r(CYe," \u2014 "),Cre=n(CYe,"A",{href:!0});var Ida=s(Cre);wDr=r(Ida,"TFEsmModel"),Ida.forEach(t),ADr=r(CYe," (ESM model)"),CYe.forEach(t),LDr=i(I),Y5=n(I,"LI",{});var wYe=s(Y5);O7e=n(wYe,"STRONG",{});var Nda=s(O7e);yDr=r(Nda,"flaubert"),Nda.forEach(t),xDr=r(wYe," \u2014 "),wre=n(wYe,"A",{href:!0});var qda=s(wre);$Dr=r(qda,"TFFlaubertModel"),qda.forEach(t),kDr=r(wYe," (FlauBERT model)"),wYe.forEach(t),SDr=i(I),kl=n(I,"LI",{});var vN=s(kl);V7e=n(vN,"STRONG",{});var Dda=s(V7e);RDr=r(Dda,"funnel"),Dda.forEach(t),PDr=r(vN," \u2014 "),Are=n(vN,"A",{href:!0});var jda=s(Are);BDr=r(jda,"TFFunnelModel"),jda.forEach(t),IDr=r(vN," or "),Lre=n(vN,"A",{href:!0});var Gda=s(Lre);NDr=r(Gda,"TFFunnelBaseModel"),Gda.forEach(t),qDr=r(vN," (Funnel Transformer model)"),vN.forEach(t),DDr=i(I),Z5=n(I,"LI",{});var AYe=s(Z5);X7e=n(AYe,"STRONG",{});var Oda=s(X7e);jDr=r(Oda,"gpt2"),Oda.forEach(t),GDr=r(AYe," \u2014 "),yre=n(AYe,"A",{href:!0});var Vda=s(yre);ODr=r(Vda,"TFGPT2Model"),Vda.forEach(t),VDr=r(AYe," (OpenAI GPT-2 model)"),AYe.forEach(t),XDr=i(I),K5=n(I,"LI",{});var LYe=s(K5);z7e=n(LYe,"STRONG",{});var Xda=s(z7e);zDr=r(Xda,"gptj"),Xda.forEach(t),QDr=r(LYe," \u2014 "),xre=n(LYe,"A",{href:!0});var zda=s(xre);WDr=r(zda,"TFGPTJModel"),zda.forEach(t),UDr=r(LYe," (GPT-J model)"),LYe.forEach(t),HDr=i(I),e0=n(I,"LI",{});var yYe=s(e0);Q7e=n(yYe,"STRONG",{});var Qda=s(Q7e);JDr=r(Qda,"groupvit"),Qda.forEach(t),YDr=r(yYe," \u2014 "),$re=n(yYe,"A",{href:!0});var Wda=s($re);ZDr=r(Wda,"TFGroupViTModel"),Wda.forEach(t),KDr=r(yYe," (GroupViT model)"),yYe.forEach(t),ejr=i(I),o0=n(I,"LI",{});var xYe=s(o0);W7e=n(xYe,"STRONG",{});var Uda=s(W7e);ojr=r(Uda,"hubert"),Uda.forEach(t),rjr=r(xYe," \u2014 "),kre=n(xYe,"A",{href:!0});var Hda=s(kre);tjr=r(Hda,"TFHubertModel"),Hda.forEach(t),ajr=r(xYe," (Hubert model)"),xYe.forEach(t),njr=i(I),r0=n(I,"LI",{});var $Ye=s(r0);U7e=n($Ye,"STRONG",{});var Jda=s(U7e);sjr=r(Jda,"layoutlm"),Jda.forEach(t),ljr=r($Ye," \u2014 "),Sre=n($Ye,"A",{href:!0});var Yda=s(Sre);ijr=r(Yda,"TFLayoutLMModel"),Yda.forEach(t),djr=r($Ye," (LayoutLM model)"),$Ye.forEach(t),mjr=i(I),t0=n(I,"LI",{});var kYe=s(t0);H7e=n(kYe,"STRONG",{});var Zda=s(H7e);cjr=r(Zda,"layoutlmv3"),Zda.forEach(t),fjr=r(kYe," \u2014 "),Rre=n(kYe,"A",{href:!0});var Kda=s(Rre);gjr=r(Kda,"TFLayoutLMv3Model"),Kda.forEach(t),hjr=r(kYe," (LayoutLMv3 model)"),kYe.forEach(t),ujr=i(I),a0=n(I,"LI",{});var SYe=s(a0);J7e=n(SYe,"STRONG",{});var ema=s(J7e);pjr=r(ema,"led"),ema.forEach(t),_jr=r(SYe," \u2014 "),Pre=n(SYe,"A",{href:!0});var oma=s(Pre);bjr=r(oma,"TFLEDModel"),oma.forEach(t),vjr=r(SYe," (LED model)"),SYe.forEach(t),Fjr=i(I),n0=n(I,"LI",{});var RYe=s(n0);Y7e=n(RYe,"STRONG",{});var rma=s(Y7e);Tjr=r(rma,"longformer"),rma.forEach(t),Mjr=r(RYe," \u2014 "),Bre=n(RYe,"A",{href:!0});var tma=s(Bre);Ejr=r(tma,"TFLongformerModel"),tma.forEach(t),Cjr=r(RYe," (Longformer model)"),RYe.forEach(t),wjr=i(I),s0=n(I,"LI",{});var PYe=s(s0);Z7e=n(PYe,"STRONG",{});var ama=s(Z7e);Ajr=r(ama,"lxmert"),ama.forEach(t),Ljr=r(PYe," \u2014 "),Ire=n(PYe,"A",{href:!0});var nma=s(Ire);yjr=r(nma,"TFLxmertModel"),nma.forEach(t),xjr=r(PYe," (LXMERT model)"),PYe.forEach(t),$jr=i(I),l0=n(I,"LI",{});var BYe=s(l0);K7e=n(BYe,"STRONG",{});var sma=s(K7e);kjr=r(sma,"marian"),sma.forEach(t),Sjr=r(BYe," \u2014 "),Nre=n(BYe,"A",{href:!0});var lma=s(Nre);Rjr=r(lma,"TFMarianModel"),lma.forEach(t),Pjr=r(BYe," (Marian model)"),BYe.forEach(t),Bjr=i(I),i0=n(I,"LI",{});var IYe=s(i0);e8e=n(IYe,"STRONG",{});var ima=s(e8e);Ijr=r(ima,"mbart"),ima.forEach(t),Njr=r(IYe," \u2014 "),qre=n(IYe,"A",{href:!0});var dma=s(qre);qjr=r(dma,"TFMBartModel"),dma.forEach(t),Djr=r(IYe," (mBART model)"),IYe.forEach(t),jjr=i(I),d0=n(I,"LI",{});var NYe=s(d0);o8e=n(NYe,"STRONG",{});var mma=s(o8e);Gjr=r(mma,"mobilebert"),mma.forEach(t),Ojr=r(NYe," \u2014 "),Dre=n(NYe,"A",{href:!0});var cma=s(Dre);Vjr=r(cma,"TFMobileBertModel"),cma.forEach(t),Xjr=r(NYe," (MobileBERT model)"),NYe.forEach(t),zjr=i(I),m0=n(I,"LI",{});var qYe=s(m0);r8e=n(qYe,"STRONG",{});var fma=s(r8e);Qjr=r(fma,"mobilevit"),fma.forEach(t),Wjr=r(qYe," \u2014 "),jre=n(qYe,"A",{href:!0});var gma=s(jre);Ujr=r(gma,"TFMobileViTModel"),gma.forEach(t),Hjr=r(qYe," (MobileViT model)"),qYe.forEach(t),Jjr=i(I),c0=n(I,"LI",{});var DYe=s(c0);t8e=n(DYe,"STRONG",{});var hma=s(t8e);Yjr=r(hma,"mpnet"),hma.forEach(t),Zjr=r(DYe," \u2014 "),Gre=n(DYe,"A",{href:!0});var uma=s(Gre);Kjr=r(uma,"TFMPNetModel"),uma.forEach(t),eGr=r(DYe," (MPNet model)"),DYe.forEach(t),oGr=i(I),f0=n(I,"LI",{});var jYe=s(f0);a8e=n(jYe,"STRONG",{});var pma=s(a8e);rGr=r(pma,"mt5"),pma.forEach(t),tGr=r(jYe," \u2014 "),Ore=n(jYe,"A",{href:!0});var _ma=s(Ore);aGr=r(_ma,"TFMT5Model"),_ma.forEach(t),nGr=r(jYe," (MT5 model)"),jYe.forEach(t),sGr=i(I),g0=n(I,"LI",{});var GYe=s(g0);n8e=n(GYe,"STRONG",{});var bma=s(n8e);lGr=r(bma,"openai-gpt"),bma.forEach(t),iGr=r(GYe," \u2014 "),Vre=n(GYe,"A",{href:!0});var vma=s(Vre);dGr=r(vma,"TFOpenAIGPTModel"),vma.forEach(t),mGr=r(GYe," (OpenAI GPT model)"),GYe.forEach(t),cGr=i(I),h0=n(I,"LI",{});var OYe=s(h0);s8e=n(OYe,"STRONG",{});var Fma=s(s8e);fGr=r(Fma,"opt"),Fma.forEach(t),gGr=r(OYe," \u2014 "),Xre=n(OYe,"A",{href:!0});var Tma=s(Xre);hGr=r(Tma,"TFOPTModel"),Tma.forEach(t),uGr=r(OYe," (OPT model)"),OYe.forEach(t),pGr=i(I),u0=n(I,"LI",{});var VYe=s(u0);l8e=n(VYe,"STRONG",{});var Mma=s(l8e);_Gr=r(Mma,"pegasus"),Mma.forEach(t),bGr=r(VYe," \u2014 "),zre=n(VYe,"A",{href:!0});var Ema=s(zre);vGr=r(Ema,"TFPegasusModel"),Ema.forEach(t),FGr=r(VYe," (Pegasus model)"),VYe.forEach(t),TGr=i(I),p0=n(I,"LI",{});var XYe=s(p0);i8e=n(XYe,"STRONG",{});var Cma=s(i8e);MGr=r(Cma,"regnet"),Cma.forEach(t),EGr=r(XYe," \u2014 "),Qre=n(XYe,"A",{href:!0});var wma=s(Qre);CGr=r(wma,"TFRegNetModel"),wma.forEach(t),wGr=r(XYe," (RegNet model)"),XYe.forEach(t),AGr=i(I),_0=n(I,"LI",{});var zYe=s(_0);d8e=n(zYe,"STRONG",{});var Ama=s(d8e);LGr=r(Ama,"rembert"),Ama.forEach(t),yGr=r(zYe," \u2014 "),Wre=n(zYe,"A",{href:!0});var Lma=s(Wre);xGr=r(Lma,"TFRemBertModel"),Lma.forEach(t),$Gr=r(zYe," (RemBERT model)"),zYe.forEach(t),kGr=i(I),b0=n(I,"LI",{});var QYe=s(b0);m8e=n(QYe,"STRONG",{});var yma=s(m8e);SGr=r(yma,"resnet"),yma.forEach(t),RGr=r(QYe," \u2014 "),Ure=n(QYe,"A",{href:!0});var xma=s(Ure);PGr=r(xma,"TFResNetModel"),xma.forEach(t),BGr=r(QYe," (ResNet model)"),QYe.forEach(t),IGr=i(I),v0=n(I,"LI",{});var WYe=s(v0);c8e=n(WYe,"STRONG",{});var $ma=s(c8e);NGr=r($ma,"roberta"),$ma.forEach(t),qGr=r(WYe," \u2014 "),Hre=n(WYe,"A",{href:!0});var kma=s(Hre);DGr=r(kma,"TFRobertaModel"),kma.forEach(t),jGr=r(WYe," (RoBERTa model)"),WYe.forEach(t),GGr=i(I),F0=n(I,"LI",{});var UYe=s(F0);f8e=n(UYe,"STRONG",{});var Sma=s(f8e);OGr=r(Sma,"roformer"),Sma.forEach(t),VGr=r(UYe," \u2014 "),Jre=n(UYe,"A",{href:!0});var Rma=s(Jre);XGr=r(Rma,"TFRoFormerModel"),Rma.forEach(t),zGr=r(UYe," (RoFormer model)"),UYe.forEach(t),QGr=i(I),T0=n(I,"LI",{});var HYe=s(T0);g8e=n(HYe,"STRONG",{});var Pma=s(g8e);WGr=r(Pma,"segformer"),Pma.forEach(t),UGr=r(HYe," \u2014 "),Yre=n(HYe,"A",{href:!0});var Bma=s(Yre);HGr=r(Bma,"TFSegformerModel"),Bma.forEach(t),JGr=r(HYe," (SegFormer model)"),HYe.forEach(t),YGr=i(I),M0=n(I,"LI",{});var JYe=s(M0);h8e=n(JYe,"STRONG",{});var Ima=s(h8e);ZGr=r(Ima,"speech_to_text"),Ima.forEach(t),KGr=r(JYe," \u2014 "),Zre=n(JYe,"A",{href:!0});var Nma=s(Zre);eOr=r(Nma,"TFSpeech2TextModel"),Nma.forEach(t),oOr=r(JYe," (Speech2Text model)"),JYe.forEach(t),rOr=i(I),E0=n(I,"LI",{});var YYe=s(E0);u8e=n(YYe,"STRONG",{});var qma=s(u8e);tOr=r(qma,"swin"),qma.forEach(t),aOr=r(YYe," \u2014 "),Kre=n(YYe,"A",{href:!0});var Dma=s(Kre);nOr=r(Dma,"TFSwinModel"),Dma.forEach(t),sOr=r(YYe," (Swin Transformer model)"),YYe.forEach(t),lOr=i(I),C0=n(I,"LI",{});var ZYe=s(C0);p8e=n(ZYe,"STRONG",{});var jma=s(p8e);iOr=r(jma,"t5"),jma.forEach(t),dOr=r(ZYe," \u2014 "),ete=n(ZYe,"A",{href:!0});var Gma=s(ete);mOr=r(Gma,"TFT5Model"),Gma.forEach(t),cOr=r(ZYe," (T5 model)"),ZYe.forEach(t),fOr=i(I),w0=n(I,"LI",{});var KYe=s(w0);_8e=n(KYe,"STRONG",{});var Oma=s(_8e);gOr=r(Oma,"tapas"),Oma.forEach(t),hOr=r(KYe," \u2014 "),ote=n(KYe,"A",{href:!0});var Vma=s(ote);uOr=r(Vma,"TFTapasModel"),Vma.forEach(t),pOr=r(KYe," (TAPAS model)"),KYe.forEach(t),_Or=i(I),A0=n(I,"LI",{});var eZe=s(A0);b8e=n(eZe,"STRONG",{});var Xma=s(b8e);bOr=r(Xma,"transfo-xl"),Xma.forEach(t),vOr=r(eZe," \u2014 "),rte=n(eZe,"A",{href:!0});var zma=s(rte);FOr=r(zma,"TFTransfoXLModel"),zma.forEach(t),TOr=r(eZe," (Transformer-XL model)"),eZe.forEach(t),MOr=i(I),L0=n(I,"LI",{});var oZe=s(L0);v8e=n(oZe,"STRONG",{});var Qma=s(v8e);EOr=r(Qma,"vit"),Qma.forEach(t),COr=r(oZe," \u2014 "),tte=n(oZe,"A",{href:!0});var Wma=s(tte);wOr=r(Wma,"TFViTModel"),Wma.forEach(t),AOr=r(oZe," (ViT model)"),oZe.forEach(t),LOr=i(I),y0=n(I,"LI",{});var rZe=s(y0);F8e=n(rZe,"STRONG",{});var Uma=s(F8e);yOr=r(Uma,"vit_mae"),Uma.forEach(t),xOr=r(rZe," \u2014 "),ate=n(rZe,"A",{href:!0});var Hma=s(ate);$Or=r(Hma,"TFViTMAEModel"),Hma.forEach(t),kOr=r(rZe," (ViTMAE model)"),rZe.forEach(t),SOr=i(I),x0=n(I,"LI",{});var tZe=s(x0);T8e=n(tZe,"STRONG",{});var Jma=s(T8e);ROr=r(Jma,"wav2vec2"),Jma.forEach(t),POr=r(tZe," \u2014 "),nte=n(tZe,"A",{href:!0});var Yma=s(nte);BOr=r(Yma,"TFWav2Vec2Model"),Yma.forEach(t),IOr=r(tZe," (Wav2Vec2 model)"),tZe.forEach(t),NOr=i(I),$0=n(I,"LI",{});var aZe=s($0);M8e=n(aZe,"STRONG",{});var Zma=s(M8e);qOr=r(Zma,"whisper"),Zma.forEach(t),DOr=r(aZe," \u2014 "),ste=n(aZe,"A",{href:!0});var Kma=s(ste);jOr=r(Kma,"TFWhisperModel"),Kma.forEach(t),GOr=r(aZe," (Whisper model)"),aZe.forEach(t),OOr=i(I),k0=n(I,"LI",{});var nZe=s(k0);E8e=n(nZe,"STRONG",{});var eca=s(E8e);VOr=r(eca,"xglm"),eca.forEach(t),XOr=r(nZe," \u2014 "),lte=n(nZe,"A",{href:!0});var oca=s(lte);zOr=r(oca,"TFXGLMModel"),oca.forEach(t),QOr=r(nZe," (XGLM model)"),nZe.forEach(t),WOr=i(I),S0=n(I,"LI",{});var sZe=s(S0);C8e=n(sZe,"STRONG",{});var rca=s(C8e);UOr=r(rca,"xlm"),rca.forEach(t),HOr=r(sZe," \u2014 "),ite=n(sZe,"A",{href:!0});var tca=s(ite);JOr=r(tca,"TFXLMModel"),tca.forEach(t),YOr=r(sZe," (XLM model)"),sZe.forEach(t),ZOr=i(I),R0=n(I,"LI",{});var lZe=s(R0);w8e=n(lZe,"STRONG",{});var aca=s(w8e);KOr=r(aca,"xlm-roberta"),aca.forEach(t),eVr=r(lZe," \u2014 "),dte=n(lZe,"A",{href:!0});var nca=s(dte);oVr=r(nca,"TFXLMRobertaModel"),nca.forEach(t),rVr=r(lZe," (XLM-RoBERTa model)"),lZe.forEach(t),tVr=i(I),P0=n(I,"LI",{});var iZe=s(P0);A8e=n(iZe,"STRONG",{});var sca=s(A8e);aVr=r(sca,"xlnet"),sca.forEach(t),nVr=r(iZe," \u2014 "),mte=n(iZe,"A",{href:!0});var lca=s(mte);sVr=r(lca,"TFXLNetModel"),lca.forEach(t),lVr=r(iZe," (XLNet model)"),iZe.forEach(t),I.forEach(t),iVr=i(pi),T(B0.$$.fragment,pi),pi.forEach(t),ui.forEach(t),Gao=i(c),fc=n(c,"H2",{class:!0});var slo=s(fc);I0=n(slo,"A",{id:!0,class:!0,href:!0});var ica=s(I0);L8e=n(ica,"SPAN",{});var dca=s(L8e);T(vR.$$.fragment,dca),dca.forEach(t),ica.forEach(t),dVr=i(slo),y8e=n(slo,"SPAN",{});var mca=s(y8e);mVr=r(mca,"TFAutoModelForPreTraining"),mca.forEach(t),slo.forEach(t),Oao=i(c),cr=n(c,"DIV",{class:!0});var _i=s(cr);T(FR.$$.fragment,_i),cVr=i(_i),gc=n(_i,"P",{});var ice=s(gc);fVr=r(ice,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),cte=n(ice,"A",{href:!0});var cca=s(cte);gVr=r(cca,"from_pretrained()"),cca.forEach(t),hVr=r(ice," class method or the "),fte=n(ice,"A",{href:!0});var fca=s(fte);uVr=r(fca,"from_config()"),fca.forEach(t),pVr=r(ice,` class
method.`),ice.forEach(t),_Vr=i(_i),TR=n(_i,"P",{});var llo=s(TR);bVr=r(llo,"This class cannot be instantiated directly using "),x8e=n(llo,"CODE",{});var gca=s(x8e);vVr=r(gca,"__init__()"),gca.forEach(t),FVr=r(llo," (throws an error)."),llo.forEach(t),TVr=i(_i),Zt=n(_i,"DIV",{class:!0});var nx=s(Zt);T(MR.$$.fragment,nx),MVr=i(nx),$8e=n(nx,"P",{});var hca=s($8e);EVr=r(hca,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),hca.forEach(t),CVr=i(nx),hc=n(nx,"P",{});var dce=s(hc);wVr=r(dce,`Note:
Loading a model from its configuration file does `),k8e=n(dce,"STRONG",{});var uca=s(k8e);AVr=r(uca,"not"),uca.forEach(t),LVr=r(dce,` load the model weights. It only affects the
model\u2019s configuration. Use `),gte=n(dce,"A",{href:!0});var pca=s(gte);yVr=r(pca,"from_pretrained()"),pca.forEach(t),xVr=r(dce," to load the model weights."),dce.forEach(t),$Vr=i(nx),T(N0.$$.fragment,nx),nx.forEach(t),kVr=i(_i),Gr=n(_i,"DIV",{class:!0});var bi=s(Gr);T(ER.$$.fragment,bi),SVr=i(bi),S8e=n(bi,"P",{});var _ca=s(S8e);RVr=r(_ca,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),_ca.forEach(t),PVr=i(bi),In=n(bi,"P",{});var sx=s(In);BVr=r(sx,"The model class to instantiate is selected based on the "),R8e=n(sx,"CODE",{});var bca=s(R8e);IVr=r(bca,"model_type"),bca.forEach(t),NVr=r(sx,` property of the config object (either
passed as an argument or loaded from `),P8e=n(sx,"CODE",{});var vca=s(P8e);qVr=r(vca,"pretrained_model_name_or_path"),vca.forEach(t),DVr=r(sx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),B8e=n(sx,"CODE",{});var Fca=s(B8e);jVr=r(Fca,"pretrained_model_name_or_path"),Fca.forEach(t),GVr=r(sx,":"),sx.forEach(t),OVr=i(bi),le=n(bi,"UL",{});var me=s(le);q0=n(me,"LI",{});var dZe=s(q0);I8e=n(dZe,"STRONG",{});var Tca=s(I8e);VVr=r(Tca,"albert"),Tca.forEach(t),XVr=r(dZe," \u2014 "),hte=n(dZe,"A",{href:!0});var Mca=s(hte);zVr=r(Mca,"TFAlbertForPreTraining"),Mca.forEach(t),QVr=r(dZe," (ALBERT model)"),dZe.forEach(t),WVr=i(me),D0=n(me,"LI",{});var mZe=s(D0);N8e=n(mZe,"STRONG",{});var Eca=s(N8e);UVr=r(Eca,"bart"),Eca.forEach(t),HVr=r(mZe," \u2014 "),ute=n(mZe,"A",{href:!0});var Cca=s(ute);JVr=r(Cca,"TFBartForConditionalGeneration"),Cca.forEach(t),YVr=r(mZe," (BART model)"),mZe.forEach(t),ZVr=i(me),j0=n(me,"LI",{});var cZe=s(j0);q8e=n(cZe,"STRONG",{});var wca=s(q8e);KVr=r(wca,"bert"),wca.forEach(t),eXr=r(cZe," \u2014 "),pte=n(cZe,"A",{href:!0});var Aca=s(pte);oXr=r(Aca,"TFBertForPreTraining"),Aca.forEach(t),rXr=r(cZe," (BERT model)"),cZe.forEach(t),tXr=i(me),G0=n(me,"LI",{});var fZe=s(G0);D8e=n(fZe,"STRONG",{});var Lca=s(D8e);aXr=r(Lca,"camembert"),Lca.forEach(t),nXr=r(fZe," \u2014 "),_te=n(fZe,"A",{href:!0});var yca=s(_te);sXr=r(yca,"TFCamembertForMaskedLM"),yca.forEach(t),lXr=r(fZe," (CamemBERT model)"),fZe.forEach(t),iXr=i(me),O0=n(me,"LI",{});var gZe=s(O0);j8e=n(gZe,"STRONG",{});var xca=s(j8e);dXr=r(xca,"ctrl"),xca.forEach(t),mXr=r(gZe," \u2014 "),bte=n(gZe,"A",{href:!0});var $ca=s(bte);cXr=r($ca,"TFCTRLLMHeadModel"),$ca.forEach(t),fXr=r(gZe," (CTRL model)"),gZe.forEach(t),gXr=i(me),V0=n(me,"LI",{});var hZe=s(V0);G8e=n(hZe,"STRONG",{});var kca=s(G8e);hXr=r(kca,"distilbert"),kca.forEach(t),uXr=r(hZe," \u2014 "),vte=n(hZe,"A",{href:!0});var Sca=s(vte);pXr=r(Sca,"TFDistilBertForMaskedLM"),Sca.forEach(t),_Xr=r(hZe," (DistilBERT model)"),hZe.forEach(t),bXr=i(me),X0=n(me,"LI",{});var uZe=s(X0);O8e=n(uZe,"STRONG",{});var Rca=s(O8e);vXr=r(Rca,"electra"),Rca.forEach(t),FXr=r(uZe," \u2014 "),Fte=n(uZe,"A",{href:!0});var Pca=s(Fte);TXr=r(Pca,"TFElectraForPreTraining"),Pca.forEach(t),MXr=r(uZe," (ELECTRA model)"),uZe.forEach(t),EXr=i(me),z0=n(me,"LI",{});var pZe=s(z0);V8e=n(pZe,"STRONG",{});var Bca=s(V8e);CXr=r(Bca,"flaubert"),Bca.forEach(t),wXr=r(pZe," \u2014 "),Tte=n(pZe,"A",{href:!0});var Ica=s(Tte);AXr=r(Ica,"TFFlaubertWithLMHeadModel"),Ica.forEach(t),LXr=r(pZe," (FlauBERT model)"),pZe.forEach(t),yXr=i(me),Q0=n(me,"LI",{});var _Ze=s(Q0);X8e=n(_Ze,"STRONG",{});var Nca=s(X8e);xXr=r(Nca,"funnel"),Nca.forEach(t),$Xr=r(_Ze," \u2014 "),Mte=n(_Ze,"A",{href:!0});var qca=s(Mte);kXr=r(qca,"TFFunnelForPreTraining"),qca.forEach(t),SXr=r(_Ze," (Funnel Transformer model)"),_Ze.forEach(t),RXr=i(me),W0=n(me,"LI",{});var bZe=s(W0);z8e=n(bZe,"STRONG",{});var Dca=s(z8e);PXr=r(Dca,"gpt2"),Dca.forEach(t),BXr=r(bZe," \u2014 "),Ete=n(bZe,"A",{href:!0});var jca=s(Ete);IXr=r(jca,"TFGPT2LMHeadModel"),jca.forEach(t),NXr=r(bZe," (OpenAI GPT-2 model)"),bZe.forEach(t),qXr=i(me),U0=n(me,"LI",{});var vZe=s(U0);Q8e=n(vZe,"STRONG",{});var Gca=s(Q8e);DXr=r(Gca,"layoutlm"),Gca.forEach(t),jXr=r(vZe," \u2014 "),Cte=n(vZe,"A",{href:!0});var Oca=s(Cte);GXr=r(Oca,"TFLayoutLMForMaskedLM"),Oca.forEach(t),OXr=r(vZe," (LayoutLM model)"),vZe.forEach(t),VXr=i(me),H0=n(me,"LI",{});var FZe=s(H0);W8e=n(FZe,"STRONG",{});var Vca=s(W8e);XXr=r(Vca,"lxmert"),Vca.forEach(t),zXr=r(FZe," \u2014 "),wte=n(FZe,"A",{href:!0});var Xca=s(wte);QXr=r(Xca,"TFLxmertForPreTraining"),Xca.forEach(t),WXr=r(FZe," (LXMERT model)"),FZe.forEach(t),UXr=i(me),J0=n(me,"LI",{});var TZe=s(J0);U8e=n(TZe,"STRONG",{});var zca=s(U8e);HXr=r(zca,"mobilebert"),zca.forEach(t),JXr=r(TZe," \u2014 "),Ate=n(TZe,"A",{href:!0});var Qca=s(Ate);YXr=r(Qca,"TFMobileBertForPreTraining"),Qca.forEach(t),ZXr=r(TZe," (MobileBERT model)"),TZe.forEach(t),KXr=i(me),Y0=n(me,"LI",{});var MZe=s(Y0);H8e=n(MZe,"STRONG",{});var Wca=s(H8e);ezr=r(Wca,"mpnet"),Wca.forEach(t),ozr=r(MZe," \u2014 "),Lte=n(MZe,"A",{href:!0});var Uca=s(Lte);rzr=r(Uca,"TFMPNetForMaskedLM"),Uca.forEach(t),tzr=r(MZe," (MPNet model)"),MZe.forEach(t),azr=i(me),Z0=n(me,"LI",{});var EZe=s(Z0);J8e=n(EZe,"STRONG",{});var Hca=s(J8e);nzr=r(Hca,"openai-gpt"),Hca.forEach(t),szr=r(EZe," \u2014 "),yte=n(EZe,"A",{href:!0});var Jca=s(yte);lzr=r(Jca,"TFOpenAIGPTLMHeadModel"),Jca.forEach(t),izr=r(EZe," (OpenAI GPT model)"),EZe.forEach(t),dzr=i(me),K0=n(me,"LI",{});var CZe=s(K0);Y8e=n(CZe,"STRONG",{});var Yca=s(Y8e);mzr=r(Yca,"roberta"),Yca.forEach(t),czr=r(CZe," \u2014 "),xte=n(CZe,"A",{href:!0});var Zca=s(xte);fzr=r(Zca,"TFRobertaForMaskedLM"),Zca.forEach(t),gzr=r(CZe," (RoBERTa model)"),CZe.forEach(t),hzr=i(me),ew=n(me,"LI",{});var wZe=s(ew);Z8e=n(wZe,"STRONG",{});var Kca=s(Z8e);uzr=r(Kca,"t5"),Kca.forEach(t),pzr=r(wZe," \u2014 "),$te=n(wZe,"A",{href:!0});var efa=s($te);_zr=r(efa,"TFT5ForConditionalGeneration"),efa.forEach(t),bzr=r(wZe," (T5 model)"),wZe.forEach(t),vzr=i(me),ow=n(me,"LI",{});var AZe=s(ow);K8e=n(AZe,"STRONG",{});var ofa=s(K8e);Fzr=r(ofa,"tapas"),ofa.forEach(t),Tzr=r(AZe," \u2014 "),kte=n(AZe,"A",{href:!0});var rfa=s(kte);Mzr=r(rfa,"TFTapasForMaskedLM"),rfa.forEach(t),Ezr=r(AZe," (TAPAS model)"),AZe.forEach(t),Czr=i(me),rw=n(me,"LI",{});var LZe=s(rw);eLe=n(LZe,"STRONG",{});var tfa=s(eLe);wzr=r(tfa,"transfo-xl"),tfa.forEach(t),Azr=r(LZe," \u2014 "),Ste=n(LZe,"A",{href:!0});var afa=s(Ste);Lzr=r(afa,"TFTransfoXLLMHeadModel"),afa.forEach(t),yzr=r(LZe," (Transformer-XL model)"),LZe.forEach(t),xzr=i(me),tw=n(me,"LI",{});var yZe=s(tw);oLe=n(yZe,"STRONG",{});var nfa=s(oLe);$zr=r(nfa,"vit_mae"),nfa.forEach(t),kzr=r(yZe," \u2014 "),Rte=n(yZe,"A",{href:!0});var sfa=s(Rte);Szr=r(sfa,"TFViTMAEForPreTraining"),sfa.forEach(t),Rzr=r(yZe," (ViTMAE model)"),yZe.forEach(t),Pzr=i(me),aw=n(me,"LI",{});var xZe=s(aw);rLe=n(xZe,"STRONG",{});var lfa=s(rLe);Bzr=r(lfa,"xlm"),lfa.forEach(t),Izr=r(xZe," \u2014 "),Pte=n(xZe,"A",{href:!0});var ifa=s(Pte);Nzr=r(ifa,"TFXLMWithLMHeadModel"),ifa.forEach(t),qzr=r(xZe," (XLM model)"),xZe.forEach(t),Dzr=i(me),nw=n(me,"LI",{});var $Ze=s(nw);tLe=n($Ze,"STRONG",{});var dfa=s(tLe);jzr=r(dfa,"xlm-roberta"),dfa.forEach(t),Gzr=r($Ze," \u2014 "),Bte=n($Ze,"A",{href:!0});var mfa=s(Bte);Ozr=r(mfa,"TFXLMRobertaForMaskedLM"),mfa.forEach(t),Vzr=r($Ze," (XLM-RoBERTa model)"),$Ze.forEach(t),Xzr=i(me),sw=n(me,"LI",{});var kZe=s(sw);aLe=n(kZe,"STRONG",{});var cfa=s(aLe);zzr=r(cfa,"xlnet"),cfa.forEach(t),Qzr=r(kZe," \u2014 "),Ite=n(kZe,"A",{href:!0});var ffa=s(Ite);Wzr=r(ffa,"TFXLNetLMHeadModel"),ffa.forEach(t),Uzr=r(kZe," (XLNet model)"),kZe.forEach(t),me.forEach(t),Hzr=i(bi),T(lw.$$.fragment,bi),bi.forEach(t),_i.forEach(t),Vao=i(c),uc=n(c,"H2",{class:!0});var ilo=s(uc);iw=n(ilo,"A",{id:!0,class:!0,href:!0});var gfa=s(iw);nLe=n(gfa,"SPAN",{});var hfa=s(nLe);T(CR.$$.fragment,hfa),hfa.forEach(t),gfa.forEach(t),Jzr=i(ilo),sLe=n(ilo,"SPAN",{});var ufa=s(sLe);Yzr=r(ufa,"TFAutoModelForCausalLM"),ufa.forEach(t),ilo.forEach(t),Xao=i(c),fr=n(c,"DIV",{class:!0});var vi=s(fr);T(wR.$$.fragment,vi),Zzr=i(vi),pc=n(vi,"P",{});var mce=s(pc);Kzr=r(mce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Nte=n(mce,"A",{href:!0});var pfa=s(Nte);eQr=r(pfa,"from_pretrained()"),pfa.forEach(t),oQr=r(mce," class method or the "),qte=n(mce,"A",{href:!0});var _fa=s(qte);rQr=r(_fa,"from_config()"),_fa.forEach(t),tQr=r(mce,` class
method.`),mce.forEach(t),aQr=i(vi),AR=n(vi,"P",{});var dlo=s(AR);nQr=r(dlo,"This class cannot be instantiated directly using "),lLe=n(dlo,"CODE",{});var bfa=s(lLe);sQr=r(bfa,"__init__()"),bfa.forEach(t),lQr=r(dlo," (throws an error)."),dlo.forEach(t),iQr=i(vi),Kt=n(vi,"DIV",{class:!0});var lx=s(Kt);T(LR.$$.fragment,lx),dQr=i(lx),iLe=n(lx,"P",{});var vfa=s(iLe);mQr=r(vfa,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),vfa.forEach(t),cQr=i(lx),_c=n(lx,"P",{});var cce=s(_c);fQr=r(cce,`Note:
Loading a model from its configuration file does `),dLe=n(cce,"STRONG",{});var Ffa=s(dLe);gQr=r(Ffa,"not"),Ffa.forEach(t),hQr=r(cce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Dte=n(cce,"A",{href:!0});var Tfa=s(Dte);uQr=r(Tfa,"from_pretrained()"),Tfa.forEach(t),pQr=r(cce," to load the model weights."),cce.forEach(t),_Qr=i(lx),T(dw.$$.fragment,lx),lx.forEach(t),bQr=i(vi),Or=n(vi,"DIV",{class:!0});var Fi=s(Or);T(yR.$$.fragment,Fi),vQr=i(Fi),mLe=n(Fi,"P",{});var Mfa=s(mLe);FQr=r(Mfa,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Mfa.forEach(t),TQr=i(Fi),Nn=n(Fi,"P",{});var ix=s(Nn);MQr=r(ix,"The model class to instantiate is selected based on the "),cLe=n(ix,"CODE",{});var Efa=s(cLe);EQr=r(Efa,"model_type"),Efa.forEach(t),CQr=r(ix,` property of the config object (either
passed as an argument or loaded from `),fLe=n(ix,"CODE",{});var Cfa=s(fLe);wQr=r(Cfa,"pretrained_model_name_or_path"),Cfa.forEach(t),AQr=r(ix,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gLe=n(ix,"CODE",{});var wfa=s(gLe);LQr=r(wfa,"pretrained_model_name_or_path"),wfa.forEach(t),yQr=r(ix,":"),ix.forEach(t),xQr=i(Fi),Me=n(Fi,"UL",{});var Ce=s(Me);mw=n(Ce,"LI",{});var SZe=s(mw);hLe=n(SZe,"STRONG",{});var Afa=s(hLe);$Qr=r(Afa,"bert"),Afa.forEach(t),kQr=r(SZe," \u2014 "),jte=n(SZe,"A",{href:!0});var Lfa=s(jte);SQr=r(Lfa,"TFBertLMHeadModel"),Lfa.forEach(t),RQr=r(SZe," (BERT model)"),SZe.forEach(t),PQr=i(Ce),cw=n(Ce,"LI",{});var RZe=s(cw);uLe=n(RZe,"STRONG",{});var yfa=s(uLe);BQr=r(yfa,"camembert"),yfa.forEach(t),IQr=r(RZe," \u2014 "),Gte=n(RZe,"A",{href:!0});var xfa=s(Gte);NQr=r(xfa,"TFCamembertForCausalLM"),xfa.forEach(t),qQr=r(RZe," (CamemBERT model)"),RZe.forEach(t),DQr=i(Ce),fw=n(Ce,"LI",{});var PZe=s(fw);pLe=n(PZe,"STRONG",{});var $fa=s(pLe);jQr=r($fa,"ctrl"),$fa.forEach(t),GQr=r(PZe," \u2014 "),Ote=n(PZe,"A",{href:!0});var kfa=s(Ote);OQr=r(kfa,"TFCTRLLMHeadModel"),kfa.forEach(t),VQr=r(PZe," (CTRL model)"),PZe.forEach(t),XQr=i(Ce),gw=n(Ce,"LI",{});var BZe=s(gw);_Le=n(BZe,"STRONG",{});var Sfa=s(_Le);zQr=r(Sfa,"gpt2"),Sfa.forEach(t),QQr=r(BZe," \u2014 "),Vte=n(BZe,"A",{href:!0});var Rfa=s(Vte);WQr=r(Rfa,"TFGPT2LMHeadModel"),Rfa.forEach(t),UQr=r(BZe," (OpenAI GPT-2 model)"),BZe.forEach(t),HQr=i(Ce),hw=n(Ce,"LI",{});var IZe=s(hw);bLe=n(IZe,"STRONG",{});var Pfa=s(bLe);JQr=r(Pfa,"gptj"),Pfa.forEach(t),YQr=r(IZe," \u2014 "),Xte=n(IZe,"A",{href:!0});var Bfa=s(Xte);ZQr=r(Bfa,"TFGPTJForCausalLM"),Bfa.forEach(t),KQr=r(IZe," (GPT-J model)"),IZe.forEach(t),eWr=i(Ce),uw=n(Ce,"LI",{});var NZe=s(uw);vLe=n(NZe,"STRONG",{});var Ifa=s(vLe);oWr=r(Ifa,"openai-gpt"),Ifa.forEach(t),rWr=r(NZe," \u2014 "),zte=n(NZe,"A",{href:!0});var Nfa=s(zte);tWr=r(Nfa,"TFOpenAIGPTLMHeadModel"),Nfa.forEach(t),aWr=r(NZe," (OpenAI GPT model)"),NZe.forEach(t),nWr=i(Ce),pw=n(Ce,"LI",{});var qZe=s(pw);FLe=n(qZe,"STRONG",{});var qfa=s(FLe);sWr=r(qfa,"opt"),qfa.forEach(t),lWr=r(qZe," \u2014 "),Qte=n(qZe,"A",{href:!0});var Dfa=s(Qte);iWr=r(Dfa,"TFOPTForCausalLM"),Dfa.forEach(t),dWr=r(qZe," (OPT model)"),qZe.forEach(t),mWr=i(Ce),_w=n(Ce,"LI",{});var DZe=s(_w);TLe=n(DZe,"STRONG",{});var jfa=s(TLe);cWr=r(jfa,"rembert"),jfa.forEach(t),fWr=r(DZe," \u2014 "),Wte=n(DZe,"A",{href:!0});var Gfa=s(Wte);gWr=r(Gfa,"TFRemBertForCausalLM"),Gfa.forEach(t),hWr=r(DZe," (RemBERT model)"),DZe.forEach(t),uWr=i(Ce),bw=n(Ce,"LI",{});var jZe=s(bw);MLe=n(jZe,"STRONG",{});var Ofa=s(MLe);pWr=r(Ofa,"roberta"),Ofa.forEach(t),_Wr=r(jZe," \u2014 "),Ute=n(jZe,"A",{href:!0});var Vfa=s(Ute);bWr=r(Vfa,"TFRobertaForCausalLM"),Vfa.forEach(t),vWr=r(jZe," (RoBERTa model)"),jZe.forEach(t),FWr=i(Ce),vw=n(Ce,"LI",{});var GZe=s(vw);ELe=n(GZe,"STRONG",{});var Xfa=s(ELe);TWr=r(Xfa,"roformer"),Xfa.forEach(t),MWr=r(GZe," \u2014 "),Hte=n(GZe,"A",{href:!0});var zfa=s(Hte);EWr=r(zfa,"TFRoFormerForCausalLM"),zfa.forEach(t),CWr=r(GZe," (RoFormer model)"),GZe.forEach(t),wWr=i(Ce),Fw=n(Ce,"LI",{});var OZe=s(Fw);CLe=n(OZe,"STRONG",{});var Qfa=s(CLe);AWr=r(Qfa,"transfo-xl"),Qfa.forEach(t),LWr=r(OZe," \u2014 "),Jte=n(OZe,"A",{href:!0});var Wfa=s(Jte);yWr=r(Wfa,"TFTransfoXLLMHeadModel"),Wfa.forEach(t),xWr=r(OZe," (Transformer-XL model)"),OZe.forEach(t),$Wr=i(Ce),Tw=n(Ce,"LI",{});var VZe=s(Tw);wLe=n(VZe,"STRONG",{});var Ufa=s(wLe);kWr=r(Ufa,"xglm"),Ufa.forEach(t),SWr=r(VZe," \u2014 "),Yte=n(VZe,"A",{href:!0});var Hfa=s(Yte);RWr=r(Hfa,"TFXGLMForCausalLM"),Hfa.forEach(t),PWr=r(VZe," (XGLM model)"),VZe.forEach(t),BWr=i(Ce),Mw=n(Ce,"LI",{});var XZe=s(Mw);ALe=n(XZe,"STRONG",{});var Jfa=s(ALe);IWr=r(Jfa,"xlm"),Jfa.forEach(t),NWr=r(XZe," \u2014 "),Zte=n(XZe,"A",{href:!0});var Yfa=s(Zte);qWr=r(Yfa,"TFXLMWithLMHeadModel"),Yfa.forEach(t),DWr=r(XZe," (XLM model)"),XZe.forEach(t),jWr=i(Ce),Ew=n(Ce,"LI",{});var zZe=s(Ew);LLe=n(zZe,"STRONG",{});var Zfa=s(LLe);GWr=r(Zfa,"xlnet"),Zfa.forEach(t),OWr=r(zZe," \u2014 "),Kte=n(zZe,"A",{href:!0});var Kfa=s(Kte);VWr=r(Kfa,"TFXLNetLMHeadModel"),Kfa.forEach(t),XWr=r(zZe," (XLNet model)"),zZe.forEach(t),Ce.forEach(t),zWr=i(Fi),T(Cw.$$.fragment,Fi),Fi.forEach(t),vi.forEach(t),zao=i(c),bc=n(c,"H2",{class:!0});var mlo=s(bc);ww=n(mlo,"A",{id:!0,class:!0,href:!0});var ega=s(ww);yLe=n(ega,"SPAN",{});var oga=s(yLe);T(xR.$$.fragment,oga),oga.forEach(t),ega.forEach(t),QWr=i(mlo),xLe=n(mlo,"SPAN",{});var rga=s(xLe);WWr=r(rga,"TFAutoModelForImageClassification"),rga.forEach(t),mlo.forEach(t),Qao=i(c),gr=n(c,"DIV",{class:!0});var Ti=s(gr);T($R.$$.fragment,Ti),UWr=i(Ti),vc=n(Ti,"P",{});var fce=s(vc);HWr=r(fce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),eae=n(fce,"A",{href:!0});var tga=s(eae);JWr=r(tga,"from_pretrained()"),tga.forEach(t),YWr=r(fce," class method or the "),oae=n(fce,"A",{href:!0});var aga=s(oae);ZWr=r(aga,"from_config()"),aga.forEach(t),KWr=r(fce,` class
method.`),fce.forEach(t),eUr=i(Ti),kR=n(Ti,"P",{});var clo=s(kR);oUr=r(clo,"This class cannot be instantiated directly using "),$Le=n(clo,"CODE",{});var nga=s($Le);rUr=r(nga,"__init__()"),nga.forEach(t),tUr=r(clo," (throws an error)."),clo.forEach(t),aUr=i(Ti),ea=n(Ti,"DIV",{class:!0});var dx=s(ea);T(SR.$$.fragment,dx),nUr=i(dx),kLe=n(dx,"P",{});var sga=s(kLe);sUr=r(sga,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),sga.forEach(t),lUr=i(dx),Fc=n(dx,"P",{});var gce=s(Fc);iUr=r(gce,`Note:
Loading a model from its configuration file does `),SLe=n(gce,"STRONG",{});var lga=s(SLe);dUr=r(lga,"not"),lga.forEach(t),mUr=r(gce,` load the model weights. It only affects the
model\u2019s configuration. Use `),rae=n(gce,"A",{href:!0});var iga=s(rae);cUr=r(iga,"from_pretrained()"),iga.forEach(t),fUr=r(gce," to load the model weights."),gce.forEach(t),gUr=i(dx),T(Aw.$$.fragment,dx),dx.forEach(t),hUr=i(Ti),Vr=n(Ti,"DIV",{class:!0});var Mi=s(Vr);T(RR.$$.fragment,Mi),uUr=i(Mi),RLe=n(Mi,"P",{});var dga=s(RLe);pUr=r(dga,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),dga.forEach(t),_Ur=i(Mi),qn=n(Mi,"P",{});var mx=s(qn);bUr=r(mx,"The model class to instantiate is selected based on the "),PLe=n(mx,"CODE",{});var mga=s(PLe);vUr=r(mga,"model_type"),mga.forEach(t),FUr=r(mx,` property of the config object (either
passed as an argument or loaded from `),BLe=n(mx,"CODE",{});var cga=s(BLe);TUr=r(cga,"pretrained_model_name_or_path"),cga.forEach(t),MUr=r(mx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ILe=n(mx,"CODE",{});var fga=s(ILe);EUr=r(fga,"pretrained_model_name_or_path"),fga.forEach(t),CUr=r(mx,":"),mx.forEach(t),wUr=i(Mi),ye=n(Mi,"UL",{});var Ne=s(ye);Lw=n(Ne,"LI",{});var QZe=s(Lw);NLe=n(QZe,"STRONG",{});var gga=s(NLe);AUr=r(gga,"convnext"),gga.forEach(t),LUr=r(QZe," \u2014 "),tae=n(QZe,"A",{href:!0});var hga=s(tae);yUr=r(hga,"TFConvNextForImageClassification"),hga.forEach(t),xUr=r(QZe," (ConvNeXT model)"),QZe.forEach(t),$Ur=i(Ne),yw=n(Ne,"LI",{});var WZe=s(yw);qLe=n(WZe,"STRONG",{});var uga=s(qLe);kUr=r(uga,"cvt"),uga.forEach(t),SUr=r(WZe," \u2014 "),aae=n(WZe,"A",{href:!0});var pga=s(aae);RUr=r(pga,"TFCvtForImageClassification"),pga.forEach(t),PUr=r(WZe," (CvT model)"),WZe.forEach(t),BUr=i(Ne),xw=n(Ne,"LI",{});var UZe=s(xw);DLe=n(UZe,"STRONG",{});var _ga=s(DLe);IUr=r(_ga,"data2vec-vision"),_ga.forEach(t),NUr=r(UZe," \u2014 "),nae=n(UZe,"A",{href:!0});var bga=s(nae);qUr=r(bga,"TFData2VecVisionForImageClassification"),bga.forEach(t),DUr=r(UZe," (Data2VecVision model)"),UZe.forEach(t),jUr=i(Ne),Sl=n(Ne,"LI",{});var FN=s(Sl);jLe=n(FN,"STRONG",{});var vga=s(jLe);GUr=r(vga,"deit"),vga.forEach(t),OUr=r(FN," \u2014 "),sae=n(FN,"A",{href:!0});var Fga=s(sae);VUr=r(Fga,"TFDeiTForImageClassification"),Fga.forEach(t),XUr=r(FN," or "),lae=n(FN,"A",{href:!0});var Tga=s(lae);zUr=r(Tga,"TFDeiTForImageClassificationWithTeacher"),Tga.forEach(t),QUr=r(FN," (DeiT model)"),FN.forEach(t),WUr=i(Ne),$w=n(Ne,"LI",{});var HZe=s($w);GLe=n(HZe,"STRONG",{});var Mga=s(GLe);UUr=r(Mga,"mobilevit"),Mga.forEach(t),HUr=r(HZe," \u2014 "),iae=n(HZe,"A",{href:!0});var Ega=s(iae);JUr=r(Ega,"TFMobileViTForImageClassification"),Ega.forEach(t),YUr=r(HZe," (MobileViT model)"),HZe.forEach(t),ZUr=i(Ne),kw=n(Ne,"LI",{});var JZe=s(kw);OLe=n(JZe,"STRONG",{});var Cga=s(OLe);KUr=r(Cga,"regnet"),Cga.forEach(t),eHr=r(JZe," \u2014 "),dae=n(JZe,"A",{href:!0});var wga=s(dae);oHr=r(wga,"TFRegNetForImageClassification"),wga.forEach(t),rHr=r(JZe," (RegNet model)"),JZe.forEach(t),tHr=i(Ne),Sw=n(Ne,"LI",{});var YZe=s(Sw);VLe=n(YZe,"STRONG",{});var Aga=s(VLe);aHr=r(Aga,"resnet"),Aga.forEach(t),nHr=r(YZe," \u2014 "),mae=n(YZe,"A",{href:!0});var Lga=s(mae);sHr=r(Lga,"TFResNetForImageClassification"),Lga.forEach(t),lHr=r(YZe," (ResNet model)"),YZe.forEach(t),iHr=i(Ne),Rw=n(Ne,"LI",{});var ZZe=s(Rw);XLe=n(ZZe,"STRONG",{});var yga=s(XLe);dHr=r(yga,"segformer"),yga.forEach(t),mHr=r(ZZe," \u2014 "),cae=n(ZZe,"A",{href:!0});var xga=s(cae);cHr=r(xga,"TFSegformerForImageClassification"),xga.forEach(t),fHr=r(ZZe," (SegFormer model)"),ZZe.forEach(t),gHr=i(Ne),Pw=n(Ne,"LI",{});var KZe=s(Pw);zLe=n(KZe,"STRONG",{});var $ga=s(zLe);hHr=r($ga,"swin"),$ga.forEach(t),uHr=r(KZe," \u2014 "),fae=n(KZe,"A",{href:!0});var kga=s(fae);pHr=r(kga,"TFSwinForImageClassification"),kga.forEach(t),_Hr=r(KZe," (Swin Transformer model)"),KZe.forEach(t),bHr=i(Ne),Bw=n(Ne,"LI",{});var eKe=s(Bw);QLe=n(eKe,"STRONG",{});var Sga=s(QLe);vHr=r(Sga,"vit"),Sga.forEach(t),FHr=r(eKe," \u2014 "),gae=n(eKe,"A",{href:!0});var Rga=s(gae);THr=r(Rga,"TFViTForImageClassification"),Rga.forEach(t),MHr=r(eKe," (ViT model)"),eKe.forEach(t),Ne.forEach(t),EHr=i(Mi),T(Iw.$$.fragment,Mi),Mi.forEach(t),Ti.forEach(t),Wao=i(c),Tc=n(c,"H2",{class:!0});var flo=s(Tc);Nw=n(flo,"A",{id:!0,class:!0,href:!0});var Pga=s(Nw);WLe=n(Pga,"SPAN",{});var Bga=s(WLe);T(PR.$$.fragment,Bga),Bga.forEach(t),Pga.forEach(t),CHr=i(flo),ULe=n(flo,"SPAN",{});var Iga=s(ULe);wHr=r(Iga,"TFAutoModelForSemanticSegmentation"),Iga.forEach(t),flo.forEach(t),Uao=i(c),hr=n(c,"DIV",{class:!0});var Ei=s(hr);T(BR.$$.fragment,Ei),AHr=i(Ei),Mc=n(Ei,"P",{});var hce=s(Mc);LHr=r(hce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),hae=n(hce,"A",{href:!0});var Nga=s(hae);yHr=r(Nga,"from_pretrained()"),Nga.forEach(t),xHr=r(hce," class method or the "),uae=n(hce,"A",{href:!0});var qga=s(uae);$Hr=r(qga,"from_config()"),qga.forEach(t),kHr=r(hce,` class
method.`),hce.forEach(t),SHr=i(Ei),IR=n(Ei,"P",{});var glo=s(IR);RHr=r(glo,"This class cannot be instantiated directly using "),HLe=n(glo,"CODE",{});var Dga=s(HLe);PHr=r(Dga,"__init__()"),Dga.forEach(t),BHr=r(glo," (throws an error)."),glo.forEach(t),IHr=i(Ei),oa=n(Ei,"DIV",{class:!0});var cx=s(oa);T(NR.$$.fragment,cx),NHr=i(cx),JLe=n(cx,"P",{});var jga=s(JLe);qHr=r(jga,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),jga.forEach(t),DHr=i(cx),Ec=n(cx,"P",{});var uce=s(Ec);jHr=r(uce,`Note:
Loading a model from its configuration file does `),YLe=n(uce,"STRONG",{});var Gga=s(YLe);GHr=r(Gga,"not"),Gga.forEach(t),OHr=r(uce,` load the model weights. It only affects the
model\u2019s configuration. Use `),pae=n(uce,"A",{href:!0});var Oga=s(pae);VHr=r(Oga,"from_pretrained()"),Oga.forEach(t),XHr=r(uce," to load the model weights."),uce.forEach(t),zHr=i(cx),T(qw.$$.fragment,cx),cx.forEach(t),QHr=i(Ei),Xr=n(Ei,"DIV",{class:!0});var Ci=s(Xr);T(qR.$$.fragment,Ci),WHr=i(Ci),ZLe=n(Ci,"P",{});var Vga=s(ZLe);UHr=r(Vga,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Vga.forEach(t),HHr=i(Ci),Dn=n(Ci,"P",{});var fx=s(Dn);JHr=r(fx,"The model class to instantiate is selected based on the "),KLe=n(fx,"CODE",{});var Xga=s(KLe);YHr=r(Xga,"model_type"),Xga.forEach(t),ZHr=r(fx,` property of the config object (either
passed as an argument or loaded from `),eye=n(fx,"CODE",{});var zga=s(eye);KHr=r(zga,"pretrained_model_name_or_path"),zga.forEach(t),eJr=r(fx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oye=n(fx,"CODE",{});var Qga=s(oye);oJr=r(Qga,"pretrained_model_name_or_path"),Qga.forEach(t),rJr=r(fx,":"),fx.forEach(t),tJr=i(Ci),Cc=n(Ci,"UL",{});var pce=s(Cc);Dw=n(pce,"LI",{});var oKe=s(Dw);rye=n(oKe,"STRONG",{});var Wga=s(rye);aJr=r(Wga,"data2vec-vision"),Wga.forEach(t),nJr=r(oKe," \u2014 "),_ae=n(oKe,"A",{href:!0});var Uga=s(_ae);sJr=r(Uga,"TFData2VecVisionForSemanticSegmentation"),Uga.forEach(t),lJr=r(oKe," (Data2VecVision model)"),oKe.forEach(t),iJr=i(pce),jw=n(pce,"LI",{});var rKe=s(jw);tye=n(rKe,"STRONG",{});var Hga=s(tye);dJr=r(Hga,"mobilevit"),Hga.forEach(t),mJr=r(rKe," \u2014 "),bae=n(rKe,"A",{href:!0});var Jga=s(bae);cJr=r(Jga,"TFMobileViTForSemanticSegmentation"),Jga.forEach(t),fJr=r(rKe," (MobileViT model)"),rKe.forEach(t),gJr=i(pce),Gw=n(pce,"LI",{});var tKe=s(Gw);aye=n(tKe,"STRONG",{});var Yga=s(aye);hJr=r(Yga,"segformer"),Yga.forEach(t),uJr=r(tKe," \u2014 "),vae=n(tKe,"A",{href:!0});var Zga=s(vae);pJr=r(Zga,"TFSegformerForSemanticSegmentation"),Zga.forEach(t),_Jr=r(tKe," (SegFormer model)"),tKe.forEach(t),pce.forEach(t),bJr=i(Ci),T(Ow.$$.fragment,Ci),Ci.forEach(t),Ei.forEach(t),Hao=i(c),wc=n(c,"H2",{class:!0});var hlo=s(wc);Vw=n(hlo,"A",{id:!0,class:!0,href:!0});var Kga=s(Vw);nye=n(Kga,"SPAN",{});var eha=s(nye);T(DR.$$.fragment,eha),eha.forEach(t),Kga.forEach(t),vJr=i(hlo),sye=n(hlo,"SPAN",{});var oha=s(sye);FJr=r(oha,"TFAutoModelForMaskedLM"),oha.forEach(t),hlo.forEach(t),Jao=i(c),ur=n(c,"DIV",{class:!0});var wi=s(ur);T(jR.$$.fragment,wi),TJr=i(wi),Ac=n(wi,"P",{});var _ce=s(Ac);MJr=r(_ce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Fae=n(_ce,"A",{href:!0});var rha=s(Fae);EJr=r(rha,"from_pretrained()"),rha.forEach(t),CJr=r(_ce," class method or the "),Tae=n(_ce,"A",{href:!0});var tha=s(Tae);wJr=r(tha,"from_config()"),tha.forEach(t),AJr=r(_ce,` class
method.`),_ce.forEach(t),LJr=i(wi),GR=n(wi,"P",{});var ulo=s(GR);yJr=r(ulo,"This class cannot be instantiated directly using "),lye=n(ulo,"CODE",{});var aha=s(lye);xJr=r(aha,"__init__()"),aha.forEach(t),$Jr=r(ulo," (throws an error)."),ulo.forEach(t),kJr=i(wi),ra=n(wi,"DIV",{class:!0});var gx=s(ra);T(OR.$$.fragment,gx),SJr=i(gx),iye=n(gx,"P",{});var nha=s(iye);RJr=r(nha,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),nha.forEach(t),PJr=i(gx),Lc=n(gx,"P",{});var bce=s(Lc);BJr=r(bce,`Note:
Loading a model from its configuration file does `),dye=n(bce,"STRONG",{});var sha=s(dye);IJr=r(sha,"not"),sha.forEach(t),NJr=r(bce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Mae=n(bce,"A",{href:!0});var lha=s(Mae);qJr=r(lha,"from_pretrained()"),lha.forEach(t),DJr=r(bce," to load the model weights."),bce.forEach(t),jJr=i(gx),T(Xw.$$.fragment,gx),gx.forEach(t),GJr=i(wi),zr=n(wi,"DIV",{class:!0});var Ai=s(zr);T(VR.$$.fragment,Ai),OJr=i(Ai),mye=n(Ai,"P",{});var iha=s(mye);VJr=r(iha,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),iha.forEach(t),XJr=i(Ai),jn=n(Ai,"P",{});var hx=s(jn);zJr=r(hx,"The model class to instantiate is selected based on the "),cye=n(hx,"CODE",{});var dha=s(cye);QJr=r(dha,"model_type"),dha.forEach(t),WJr=r(hx,` property of the config object (either
passed as an argument or loaded from `),fye=n(hx,"CODE",{});var mha=s(fye);UJr=r(mha,"pretrained_model_name_or_path"),mha.forEach(t),HJr=r(hx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gye=n(hx,"CODE",{});var cha=s(gye);JJr=r(cha,"pretrained_model_name_or_path"),cha.forEach(t),YJr=r(hx,":"),hx.forEach(t),ZJr=i(Ai),ce=n(Ai,"UL",{});var ue=s(ce);zw=n(ue,"LI",{});var aKe=s(zw);hye=n(aKe,"STRONG",{});var fha=s(hye);KJr=r(fha,"albert"),fha.forEach(t),eYr=r(aKe," \u2014 "),Eae=n(aKe,"A",{href:!0});var gha=s(Eae);oYr=r(gha,"TFAlbertForMaskedLM"),gha.forEach(t),rYr=r(aKe," (ALBERT model)"),aKe.forEach(t),tYr=i(ue),Qw=n(ue,"LI",{});var nKe=s(Qw);uye=n(nKe,"STRONG",{});var hha=s(uye);aYr=r(hha,"bert"),hha.forEach(t),nYr=r(nKe," \u2014 "),Cae=n(nKe,"A",{href:!0});var uha=s(Cae);sYr=r(uha,"TFBertForMaskedLM"),uha.forEach(t),lYr=r(nKe," (BERT model)"),nKe.forEach(t),iYr=i(ue),Ww=n(ue,"LI",{});var sKe=s(Ww);pye=n(sKe,"STRONG",{});var pha=s(pye);dYr=r(pha,"camembert"),pha.forEach(t),mYr=r(sKe," \u2014 "),wae=n(sKe,"A",{href:!0});var _ha=s(wae);cYr=r(_ha,"TFCamembertForMaskedLM"),_ha.forEach(t),fYr=r(sKe," (CamemBERT model)"),sKe.forEach(t),gYr=i(ue),Uw=n(ue,"LI",{});var lKe=s(Uw);_ye=n(lKe,"STRONG",{});var bha=s(_ye);hYr=r(bha,"convbert"),bha.forEach(t),uYr=r(lKe," \u2014 "),Aae=n(lKe,"A",{href:!0});var vha=s(Aae);pYr=r(vha,"TFConvBertForMaskedLM"),vha.forEach(t),_Yr=r(lKe," (ConvBERT model)"),lKe.forEach(t),bYr=i(ue),Hw=n(ue,"LI",{});var iKe=s(Hw);bye=n(iKe,"STRONG",{});var Fha=s(bye);vYr=r(Fha,"deberta"),Fha.forEach(t),FYr=r(iKe," \u2014 "),Lae=n(iKe,"A",{href:!0});var Tha=s(Lae);TYr=r(Tha,"TFDebertaForMaskedLM"),Tha.forEach(t),MYr=r(iKe," (DeBERTa model)"),iKe.forEach(t),EYr=i(ue),Jw=n(ue,"LI",{});var dKe=s(Jw);vye=n(dKe,"STRONG",{});var Mha=s(vye);CYr=r(Mha,"deberta-v2"),Mha.forEach(t),wYr=r(dKe," \u2014 "),yae=n(dKe,"A",{href:!0});var Eha=s(yae);AYr=r(Eha,"TFDebertaV2ForMaskedLM"),Eha.forEach(t),LYr=r(dKe," (DeBERTa-v2 model)"),dKe.forEach(t),yYr=i(ue),Yw=n(ue,"LI",{});var mKe=s(Yw);Fye=n(mKe,"STRONG",{});var Cha=s(Fye);xYr=r(Cha,"distilbert"),Cha.forEach(t),$Yr=r(mKe," \u2014 "),xae=n(mKe,"A",{href:!0});var wha=s(xae);kYr=r(wha,"TFDistilBertForMaskedLM"),wha.forEach(t),SYr=r(mKe," (DistilBERT model)"),mKe.forEach(t),RYr=i(ue),Zw=n(ue,"LI",{});var cKe=s(Zw);Tye=n(cKe,"STRONG",{});var Aha=s(Tye);PYr=r(Aha,"electra"),Aha.forEach(t),BYr=r(cKe," \u2014 "),$ae=n(cKe,"A",{href:!0});var Lha=s($ae);IYr=r(Lha,"TFElectraForMaskedLM"),Lha.forEach(t),NYr=r(cKe," (ELECTRA model)"),cKe.forEach(t),qYr=i(ue),Kw=n(ue,"LI",{});var fKe=s(Kw);Mye=n(fKe,"STRONG",{});var yha=s(Mye);DYr=r(yha,"esm"),yha.forEach(t),jYr=r(fKe," \u2014 "),kae=n(fKe,"A",{href:!0});var xha=s(kae);GYr=r(xha,"TFEsmForMaskedLM"),xha.forEach(t),OYr=r(fKe," (ESM model)"),fKe.forEach(t),VYr=i(ue),eA=n(ue,"LI",{});var gKe=s(eA);Eye=n(gKe,"STRONG",{});var $ha=s(Eye);XYr=r($ha,"flaubert"),$ha.forEach(t),zYr=r(gKe," \u2014 "),Sae=n(gKe,"A",{href:!0});var kha=s(Sae);QYr=r(kha,"TFFlaubertWithLMHeadModel"),kha.forEach(t),WYr=r(gKe," (FlauBERT model)"),gKe.forEach(t),UYr=i(ue),oA=n(ue,"LI",{});var hKe=s(oA);Cye=n(hKe,"STRONG",{});var Sha=s(Cye);HYr=r(Sha,"funnel"),Sha.forEach(t),JYr=r(hKe," \u2014 "),Rae=n(hKe,"A",{href:!0});var Rha=s(Rae);YYr=r(Rha,"TFFunnelForMaskedLM"),Rha.forEach(t),ZYr=r(hKe," (Funnel Transformer model)"),hKe.forEach(t),KYr=i(ue),rA=n(ue,"LI",{});var uKe=s(rA);wye=n(uKe,"STRONG",{});var Pha=s(wye);eZr=r(Pha,"layoutlm"),Pha.forEach(t),oZr=r(uKe," \u2014 "),Pae=n(uKe,"A",{href:!0});var Bha=s(Pae);rZr=r(Bha,"TFLayoutLMForMaskedLM"),Bha.forEach(t),tZr=r(uKe," (LayoutLM model)"),uKe.forEach(t),aZr=i(ue),tA=n(ue,"LI",{});var pKe=s(tA);Aye=n(pKe,"STRONG",{});var Iha=s(Aye);nZr=r(Iha,"longformer"),Iha.forEach(t),sZr=r(pKe," \u2014 "),Bae=n(pKe,"A",{href:!0});var Nha=s(Bae);lZr=r(Nha,"TFLongformerForMaskedLM"),Nha.forEach(t),iZr=r(pKe," (Longformer model)"),pKe.forEach(t),dZr=i(ue),aA=n(ue,"LI",{});var _Ke=s(aA);Lye=n(_Ke,"STRONG",{});var qha=s(Lye);mZr=r(qha,"mobilebert"),qha.forEach(t),cZr=r(_Ke," \u2014 "),Iae=n(_Ke,"A",{href:!0});var Dha=s(Iae);fZr=r(Dha,"TFMobileBertForMaskedLM"),Dha.forEach(t),gZr=r(_Ke," (MobileBERT model)"),_Ke.forEach(t),hZr=i(ue),nA=n(ue,"LI",{});var bKe=s(nA);yye=n(bKe,"STRONG",{});var jha=s(yye);uZr=r(jha,"mpnet"),jha.forEach(t),pZr=r(bKe," \u2014 "),Nae=n(bKe,"A",{href:!0});var Gha=s(Nae);_Zr=r(Gha,"TFMPNetForMaskedLM"),Gha.forEach(t),bZr=r(bKe," (MPNet model)"),bKe.forEach(t),vZr=i(ue),sA=n(ue,"LI",{});var vKe=s(sA);xye=n(vKe,"STRONG",{});var Oha=s(xye);FZr=r(Oha,"rembert"),Oha.forEach(t),TZr=r(vKe," \u2014 "),qae=n(vKe,"A",{href:!0});var Vha=s(qae);MZr=r(Vha,"TFRemBertForMaskedLM"),Vha.forEach(t),EZr=r(vKe," (RemBERT model)"),vKe.forEach(t),CZr=i(ue),lA=n(ue,"LI",{});var FKe=s(lA);$ye=n(FKe,"STRONG",{});var Xha=s($ye);wZr=r(Xha,"roberta"),Xha.forEach(t),AZr=r(FKe," \u2014 "),Dae=n(FKe,"A",{href:!0});var zha=s(Dae);LZr=r(zha,"TFRobertaForMaskedLM"),zha.forEach(t),yZr=r(FKe," (RoBERTa model)"),FKe.forEach(t),xZr=i(ue),iA=n(ue,"LI",{});var TKe=s(iA);kye=n(TKe,"STRONG",{});var Qha=s(kye);$Zr=r(Qha,"roformer"),Qha.forEach(t),kZr=r(TKe," \u2014 "),jae=n(TKe,"A",{href:!0});var Wha=s(jae);SZr=r(Wha,"TFRoFormerForMaskedLM"),Wha.forEach(t),RZr=r(TKe," (RoFormer model)"),TKe.forEach(t),PZr=i(ue),dA=n(ue,"LI",{});var MKe=s(dA);Sye=n(MKe,"STRONG",{});var Uha=s(Sye);BZr=r(Uha,"tapas"),Uha.forEach(t),IZr=r(MKe," \u2014 "),Gae=n(MKe,"A",{href:!0});var Hha=s(Gae);NZr=r(Hha,"TFTapasForMaskedLM"),Hha.forEach(t),qZr=r(MKe," (TAPAS model)"),MKe.forEach(t),DZr=i(ue),mA=n(ue,"LI",{});var EKe=s(mA);Rye=n(EKe,"STRONG",{});var Jha=s(Rye);jZr=r(Jha,"xlm"),Jha.forEach(t),GZr=r(EKe," \u2014 "),Oae=n(EKe,"A",{href:!0});var Yha=s(Oae);OZr=r(Yha,"TFXLMWithLMHeadModel"),Yha.forEach(t),VZr=r(EKe," (XLM model)"),EKe.forEach(t),XZr=i(ue),cA=n(ue,"LI",{});var CKe=s(cA);Pye=n(CKe,"STRONG",{});var Zha=s(Pye);zZr=r(Zha,"xlm-roberta"),Zha.forEach(t),QZr=r(CKe," \u2014 "),Vae=n(CKe,"A",{href:!0});var Kha=s(Vae);WZr=r(Kha,"TFXLMRobertaForMaskedLM"),Kha.forEach(t),UZr=r(CKe," (XLM-RoBERTa model)"),CKe.forEach(t),ue.forEach(t),HZr=i(Ai),T(fA.$$.fragment,Ai),Ai.forEach(t),wi.forEach(t),Yao=i(c),yc=n(c,"H2",{class:!0});var plo=s(yc);gA=n(plo,"A",{id:!0,class:!0,href:!0});var eua=s(gA);Bye=n(eua,"SPAN",{});var oua=s(Bye);T(XR.$$.fragment,oua),oua.forEach(t),eua.forEach(t),JZr=i(plo),Iye=n(plo,"SPAN",{});var rua=s(Iye);YZr=r(rua,"TFAutoModelForSeq2SeqLM"),rua.forEach(t),plo.forEach(t),Zao=i(c),pr=n(c,"DIV",{class:!0});var Li=s(pr);T(zR.$$.fragment,Li),ZZr=i(Li),xc=n(Li,"P",{});var vce=s(xc);KZr=r(vce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Xae=n(vce,"A",{href:!0});var tua=s(Xae);eKr=r(tua,"from_pretrained()"),tua.forEach(t),oKr=r(vce," class method or the "),zae=n(vce,"A",{href:!0});var aua=s(zae);rKr=r(aua,"from_config()"),aua.forEach(t),tKr=r(vce,` class
method.`),vce.forEach(t),aKr=i(Li),QR=n(Li,"P",{});var _lo=s(QR);nKr=r(_lo,"This class cannot be instantiated directly using "),Nye=n(_lo,"CODE",{});var nua=s(Nye);sKr=r(nua,"__init__()"),nua.forEach(t),lKr=r(_lo," (throws an error)."),_lo.forEach(t),iKr=i(Li),ta=n(Li,"DIV",{class:!0});var ux=s(ta);T(WR.$$.fragment,ux),dKr=i(ux),qye=n(ux,"P",{});var sua=s(qye);mKr=r(sua,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),sua.forEach(t),cKr=i(ux),$c=n(ux,"P",{});var Fce=s($c);fKr=r(Fce,`Note:
Loading a model from its configuration file does `),Dye=n(Fce,"STRONG",{});var lua=s(Dye);gKr=r(lua,"not"),lua.forEach(t),hKr=r(Fce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Qae=n(Fce,"A",{href:!0});var iua=s(Qae);uKr=r(iua,"from_pretrained()"),iua.forEach(t),pKr=r(Fce," to load the model weights."),Fce.forEach(t),_Kr=i(ux),T(hA.$$.fragment,ux),ux.forEach(t),bKr=i(Li),Qr=n(Li,"DIV",{class:!0});var yi=s(Qr);T(UR.$$.fragment,yi),vKr=i(yi),jye=n(yi,"P",{});var dua=s(jye);FKr=r(dua,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),dua.forEach(t),TKr=i(yi),Gn=n(yi,"P",{});var px=s(Gn);MKr=r(px,"The model class to instantiate is selected based on the "),Gye=n(px,"CODE",{});var mua=s(Gye);EKr=r(mua,"model_type"),mua.forEach(t),CKr=r(px,` property of the config object (either
passed as an argument or loaded from `),Oye=n(px,"CODE",{});var cua=s(Oye);wKr=r(cua,"pretrained_model_name_or_path"),cua.forEach(t),AKr=r(px,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Vye=n(px,"CODE",{});var fua=s(Vye);LKr=r(fua,"pretrained_model_name_or_path"),fua.forEach(t),yKr=r(px,":"),px.forEach(t),xKr=i(yi),xe=n(yi,"UL",{});var qe=s(xe);uA=n(qe,"LI",{});var wKe=s(uA);Xye=n(wKe,"STRONG",{});var gua=s(Xye);$Kr=r(gua,"bart"),gua.forEach(t),kKr=r(wKe," \u2014 "),Wae=n(wKe,"A",{href:!0});var hua=s(Wae);SKr=r(hua,"TFBartForConditionalGeneration"),hua.forEach(t),RKr=r(wKe," (BART model)"),wKe.forEach(t),PKr=i(qe),pA=n(qe,"LI",{});var AKe=s(pA);zye=n(AKe,"STRONG",{});var uua=s(zye);BKr=r(uua,"blenderbot"),uua.forEach(t),IKr=r(AKe," \u2014 "),Uae=n(AKe,"A",{href:!0});var pua=s(Uae);NKr=r(pua,"TFBlenderbotForConditionalGeneration"),pua.forEach(t),qKr=r(AKe," (Blenderbot model)"),AKe.forEach(t),DKr=i(qe),_A=n(qe,"LI",{});var LKe=s(_A);Qye=n(LKe,"STRONG",{});var _ua=s(Qye);jKr=r(_ua,"blenderbot-small"),_ua.forEach(t),GKr=r(LKe," \u2014 "),Hae=n(LKe,"A",{href:!0});var bua=s(Hae);OKr=r(bua,"TFBlenderbotSmallForConditionalGeneration"),bua.forEach(t),VKr=r(LKe," (BlenderbotSmall model)"),LKe.forEach(t),XKr=i(qe),bA=n(qe,"LI",{});var yKe=s(bA);Wye=n(yKe,"STRONG",{});var vua=s(Wye);zKr=r(vua,"encoder-decoder"),vua.forEach(t),QKr=r(yKe," \u2014 "),Jae=n(yKe,"A",{href:!0});var Fua=s(Jae);WKr=r(Fua,"TFEncoderDecoderModel"),Fua.forEach(t),UKr=r(yKe," (Encoder decoder model)"),yKe.forEach(t),HKr=i(qe),vA=n(qe,"LI",{});var xKe=s(vA);Uye=n(xKe,"STRONG",{});var Tua=s(Uye);JKr=r(Tua,"led"),Tua.forEach(t),YKr=r(xKe," \u2014 "),Yae=n(xKe,"A",{href:!0});var Mua=s(Yae);ZKr=r(Mua,"TFLEDForConditionalGeneration"),Mua.forEach(t),KKr=r(xKe," (LED model)"),xKe.forEach(t),eet=i(qe),FA=n(qe,"LI",{});var $Ke=s(FA);Hye=n($Ke,"STRONG",{});var Eua=s(Hye);oet=r(Eua,"marian"),Eua.forEach(t),ret=r($Ke," \u2014 "),Zae=n($Ke,"A",{href:!0});var Cua=s(Zae);tet=r(Cua,"TFMarianMTModel"),Cua.forEach(t),aet=r($Ke," (Marian model)"),$Ke.forEach(t),net=i(qe),TA=n(qe,"LI",{});var kKe=s(TA);Jye=n(kKe,"STRONG",{});var wua=s(Jye);set=r(wua,"mbart"),wua.forEach(t),iet=r(kKe," \u2014 "),Kae=n(kKe,"A",{href:!0});var Aua=s(Kae);det=r(Aua,"TFMBartForConditionalGeneration"),Aua.forEach(t),met=r(kKe," (mBART model)"),kKe.forEach(t),cet=i(qe),MA=n(qe,"LI",{});var SKe=s(MA);Yye=n(SKe,"STRONG",{});var Lua=s(Yye);fet=r(Lua,"mt5"),Lua.forEach(t),get=r(SKe," \u2014 "),ene=n(SKe,"A",{href:!0});var yua=s(ene);het=r(yua,"TFMT5ForConditionalGeneration"),yua.forEach(t),uet=r(SKe," (MT5 model)"),SKe.forEach(t),pet=i(qe),EA=n(qe,"LI",{});var RKe=s(EA);Zye=n(RKe,"STRONG",{});var xua=s(Zye);_et=r(xua,"pegasus"),xua.forEach(t),bet=r(RKe," \u2014 "),one=n(RKe,"A",{href:!0});var $ua=s(one);vet=r($ua,"TFPegasusForConditionalGeneration"),$ua.forEach(t),Fet=r(RKe," (Pegasus model)"),RKe.forEach(t),Tet=i(qe),CA=n(qe,"LI",{});var PKe=s(CA);Kye=n(PKe,"STRONG",{});var kua=s(Kye);Met=r(kua,"t5"),kua.forEach(t),Eet=r(PKe," \u2014 "),rne=n(PKe,"A",{href:!0});var Sua=s(rne);Cet=r(Sua,"TFT5ForConditionalGeneration"),Sua.forEach(t),wet=r(PKe," (T5 model)"),PKe.forEach(t),qe.forEach(t),Aet=i(yi),T(wA.$$.fragment,yi),yi.forEach(t),Li.forEach(t),Kao=i(c),kc=n(c,"H2",{class:!0});var blo=s(kc);AA=n(blo,"A",{id:!0,class:!0,href:!0});var Rua=s(AA);e9e=n(Rua,"SPAN",{});var Pua=s(e9e);T(HR.$$.fragment,Pua),Pua.forEach(t),Rua.forEach(t),Let=i(blo),o9e=n(blo,"SPAN",{});var Bua=s(o9e);yet=r(Bua,"TFAutoModelForSequenceClassification"),Bua.forEach(t),blo.forEach(t),eno=i(c),_r=n(c,"DIV",{class:!0});var xi=s(_r);T(JR.$$.fragment,xi),xet=i(xi),Sc=n(xi,"P",{});var Tce=s(Sc);$et=r(Tce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),tne=n(Tce,"A",{href:!0});var Iua=s(tne);ket=r(Iua,"from_pretrained()"),Iua.forEach(t),Set=r(Tce," class method or the "),ane=n(Tce,"A",{href:!0});var Nua=s(ane);Ret=r(Nua,"from_config()"),Nua.forEach(t),Pet=r(Tce,` class
method.`),Tce.forEach(t),Bet=i(xi),YR=n(xi,"P",{});var vlo=s(YR);Iet=r(vlo,"This class cannot be instantiated directly using "),r9e=n(vlo,"CODE",{});var qua=s(r9e);Net=r(qua,"__init__()"),qua.forEach(t),qet=r(vlo," (throws an error)."),vlo.forEach(t),Det=i(xi),aa=n(xi,"DIV",{class:!0});var _x=s(aa);T(ZR.$$.fragment,_x),jet=i(_x),t9e=n(_x,"P",{});var Dua=s(t9e);Get=r(Dua,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Dua.forEach(t),Oet=i(_x),Rc=n(_x,"P",{});var Mce=s(Rc);Vet=r(Mce,`Note:
Loading a model from its configuration file does `),a9e=n(Mce,"STRONG",{});var jua=s(a9e);Xet=r(jua,"not"),jua.forEach(t),zet=r(Mce,` load the model weights. It only affects the
model\u2019s configuration. Use `),nne=n(Mce,"A",{href:!0});var Gua=s(nne);Qet=r(Gua,"from_pretrained()"),Gua.forEach(t),Wet=r(Mce," to load the model weights."),Mce.forEach(t),Uet=i(_x),T(LA.$$.fragment,_x),_x.forEach(t),Het=i(xi),Wr=n(xi,"DIV",{class:!0});var $i=s(Wr);T(KR.$$.fragment,$i),Jet=i($i),n9e=n($i,"P",{});var Oua=s(n9e);Yet=r(Oua,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Oua.forEach(t),Zet=i($i),On=n($i,"P",{});var bx=s(On);Ket=r(bx,"The model class to instantiate is selected based on the "),s9e=n(bx,"CODE",{});var Vua=s(s9e);eot=r(Vua,"model_type"),Vua.forEach(t),oot=r(bx,` property of the config object (either
passed as an argument or loaded from `),l9e=n(bx,"CODE",{});var Xua=s(l9e);rot=r(Xua,"pretrained_model_name_or_path"),Xua.forEach(t),tot=r(bx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i9e=n(bx,"CODE",{});var zua=s(i9e);aot=r(zua,"pretrained_model_name_or_path"),zua.forEach(t),not=r(bx,":"),bx.forEach(t),sot=i($i),re=n($i,"UL",{});var ae=s(re);yA=n(ae,"LI",{});var BKe=s(yA);d9e=n(BKe,"STRONG",{});var Qua=s(d9e);lot=r(Qua,"albert"),Qua.forEach(t),iot=r(BKe," \u2014 "),sne=n(BKe,"A",{href:!0});var Wua=s(sne);dot=r(Wua,"TFAlbertForSequenceClassification"),Wua.forEach(t),mot=r(BKe," (ALBERT model)"),BKe.forEach(t),cot=i(ae),xA=n(ae,"LI",{});var IKe=s(xA);m9e=n(IKe,"STRONG",{});var Uua=s(m9e);fot=r(Uua,"bert"),Uua.forEach(t),got=r(IKe," \u2014 "),lne=n(IKe,"A",{href:!0});var Hua=s(lne);hot=r(Hua,"TFBertForSequenceClassification"),Hua.forEach(t),uot=r(IKe," (BERT model)"),IKe.forEach(t),pot=i(ae),$A=n(ae,"LI",{});var NKe=s($A);c9e=n(NKe,"STRONG",{});var Jua=s(c9e);_ot=r(Jua,"camembert"),Jua.forEach(t),bot=r(NKe," \u2014 "),ine=n(NKe,"A",{href:!0});var Yua=s(ine);vot=r(Yua,"TFCamembertForSequenceClassification"),Yua.forEach(t),Fot=r(NKe," (CamemBERT model)"),NKe.forEach(t),Tot=i(ae),kA=n(ae,"LI",{});var qKe=s(kA);f9e=n(qKe,"STRONG",{});var Zua=s(f9e);Mot=r(Zua,"convbert"),Zua.forEach(t),Eot=r(qKe," \u2014 "),dne=n(qKe,"A",{href:!0});var Kua=s(dne);Cot=r(Kua,"TFConvBertForSequenceClassification"),Kua.forEach(t),wot=r(qKe," (ConvBERT model)"),qKe.forEach(t),Aot=i(ae),SA=n(ae,"LI",{});var DKe=s(SA);g9e=n(DKe,"STRONG",{});var epa=s(g9e);Lot=r(epa,"ctrl"),epa.forEach(t),yot=r(DKe," \u2014 "),mne=n(DKe,"A",{href:!0});var opa=s(mne);xot=r(opa,"TFCTRLForSequenceClassification"),opa.forEach(t),$ot=r(DKe," (CTRL model)"),DKe.forEach(t),kot=i(ae),RA=n(ae,"LI",{});var jKe=s(RA);h9e=n(jKe,"STRONG",{});var rpa=s(h9e);Sot=r(rpa,"deberta"),rpa.forEach(t),Rot=r(jKe," \u2014 "),cne=n(jKe,"A",{href:!0});var tpa=s(cne);Pot=r(tpa,"TFDebertaForSequenceClassification"),tpa.forEach(t),Bot=r(jKe," (DeBERTa model)"),jKe.forEach(t),Iot=i(ae),PA=n(ae,"LI",{});var GKe=s(PA);u9e=n(GKe,"STRONG",{});var apa=s(u9e);Not=r(apa,"deberta-v2"),apa.forEach(t),qot=r(GKe," \u2014 "),fne=n(GKe,"A",{href:!0});var npa=s(fne);Dot=r(npa,"TFDebertaV2ForSequenceClassification"),npa.forEach(t),jot=r(GKe," (DeBERTa-v2 model)"),GKe.forEach(t),Got=i(ae),BA=n(ae,"LI",{});var OKe=s(BA);p9e=n(OKe,"STRONG",{});var spa=s(p9e);Oot=r(spa,"distilbert"),spa.forEach(t),Vot=r(OKe," \u2014 "),gne=n(OKe,"A",{href:!0});var lpa=s(gne);Xot=r(lpa,"TFDistilBertForSequenceClassification"),lpa.forEach(t),zot=r(OKe," (DistilBERT model)"),OKe.forEach(t),Qot=i(ae),IA=n(ae,"LI",{});var VKe=s(IA);_9e=n(VKe,"STRONG",{});var ipa=s(_9e);Wot=r(ipa,"electra"),ipa.forEach(t),Uot=r(VKe," \u2014 "),hne=n(VKe,"A",{href:!0});var dpa=s(hne);Hot=r(dpa,"TFElectraForSequenceClassification"),dpa.forEach(t),Jot=r(VKe," (ELECTRA model)"),VKe.forEach(t),Yot=i(ae),NA=n(ae,"LI",{});var XKe=s(NA);b9e=n(XKe,"STRONG",{});var mpa=s(b9e);Zot=r(mpa,"esm"),mpa.forEach(t),Kot=r(XKe," \u2014 "),une=n(XKe,"A",{href:!0});var cpa=s(une);ert=r(cpa,"TFEsmForSequenceClassification"),cpa.forEach(t),ort=r(XKe," (ESM model)"),XKe.forEach(t),rrt=i(ae),qA=n(ae,"LI",{});var zKe=s(qA);v9e=n(zKe,"STRONG",{});var fpa=s(v9e);trt=r(fpa,"flaubert"),fpa.forEach(t),art=r(zKe," \u2014 "),pne=n(zKe,"A",{href:!0});var gpa=s(pne);nrt=r(gpa,"TFFlaubertForSequenceClassification"),gpa.forEach(t),srt=r(zKe," (FlauBERT model)"),zKe.forEach(t),lrt=i(ae),DA=n(ae,"LI",{});var QKe=s(DA);F9e=n(QKe,"STRONG",{});var hpa=s(F9e);irt=r(hpa,"funnel"),hpa.forEach(t),drt=r(QKe," \u2014 "),_ne=n(QKe,"A",{href:!0});var upa=s(_ne);mrt=r(upa,"TFFunnelForSequenceClassification"),upa.forEach(t),crt=r(QKe," (Funnel Transformer model)"),QKe.forEach(t),frt=i(ae),jA=n(ae,"LI",{});var WKe=s(jA);T9e=n(WKe,"STRONG",{});var ppa=s(T9e);grt=r(ppa,"gpt2"),ppa.forEach(t),hrt=r(WKe," \u2014 "),bne=n(WKe,"A",{href:!0});var _pa=s(bne);urt=r(_pa,"TFGPT2ForSequenceClassification"),_pa.forEach(t),prt=r(WKe," (OpenAI GPT-2 model)"),WKe.forEach(t),_rt=i(ae),GA=n(ae,"LI",{});var UKe=s(GA);M9e=n(UKe,"STRONG",{});var bpa=s(M9e);brt=r(bpa,"gptj"),bpa.forEach(t),vrt=r(UKe," \u2014 "),vne=n(UKe,"A",{href:!0});var vpa=s(vne);Frt=r(vpa,"TFGPTJForSequenceClassification"),vpa.forEach(t),Trt=r(UKe," (GPT-J model)"),UKe.forEach(t),Mrt=i(ae),OA=n(ae,"LI",{});var HKe=s(OA);E9e=n(HKe,"STRONG",{});var Fpa=s(E9e);Ert=r(Fpa,"layoutlm"),Fpa.forEach(t),Crt=r(HKe," \u2014 "),Fne=n(HKe,"A",{href:!0});var Tpa=s(Fne);wrt=r(Tpa,"TFLayoutLMForSequenceClassification"),Tpa.forEach(t),Art=r(HKe," (LayoutLM model)"),HKe.forEach(t),Lrt=i(ae),VA=n(ae,"LI",{});var JKe=s(VA);C9e=n(JKe,"STRONG",{});var Mpa=s(C9e);yrt=r(Mpa,"layoutlmv3"),Mpa.forEach(t),xrt=r(JKe," \u2014 "),Tne=n(JKe,"A",{href:!0});var Epa=s(Tne);$rt=r(Epa,"TFLayoutLMv3ForSequenceClassification"),Epa.forEach(t),krt=r(JKe," (LayoutLMv3 model)"),JKe.forEach(t),Srt=i(ae),XA=n(ae,"LI",{});var YKe=s(XA);w9e=n(YKe,"STRONG",{});var Cpa=s(w9e);Rrt=r(Cpa,"longformer"),Cpa.forEach(t),Prt=r(YKe," \u2014 "),Mne=n(YKe,"A",{href:!0});var wpa=s(Mne);Brt=r(wpa,"TFLongformerForSequenceClassification"),wpa.forEach(t),Irt=r(YKe," (Longformer model)"),YKe.forEach(t),Nrt=i(ae),zA=n(ae,"LI",{});var ZKe=s(zA);A9e=n(ZKe,"STRONG",{});var Apa=s(A9e);qrt=r(Apa,"mobilebert"),Apa.forEach(t),Drt=r(ZKe," \u2014 "),Ene=n(ZKe,"A",{href:!0});var Lpa=s(Ene);jrt=r(Lpa,"TFMobileBertForSequenceClassification"),Lpa.forEach(t),Grt=r(ZKe," (MobileBERT model)"),ZKe.forEach(t),Ort=i(ae),QA=n(ae,"LI",{});var KKe=s(QA);L9e=n(KKe,"STRONG",{});var ypa=s(L9e);Vrt=r(ypa,"mpnet"),ypa.forEach(t),Xrt=r(KKe," \u2014 "),Cne=n(KKe,"A",{href:!0});var xpa=s(Cne);zrt=r(xpa,"TFMPNetForSequenceClassification"),xpa.forEach(t),Qrt=r(KKe," (MPNet model)"),KKe.forEach(t),Wrt=i(ae),WA=n(ae,"LI",{});var eeo=s(WA);y9e=n(eeo,"STRONG",{});var $pa=s(y9e);Urt=r($pa,"openai-gpt"),$pa.forEach(t),Hrt=r(eeo," \u2014 "),wne=n(eeo,"A",{href:!0});var kpa=s(wne);Jrt=r(kpa,"TFOpenAIGPTForSequenceClassification"),kpa.forEach(t),Yrt=r(eeo," (OpenAI GPT model)"),eeo.forEach(t),Zrt=i(ae),UA=n(ae,"LI",{});var oeo=s(UA);x9e=n(oeo,"STRONG",{});var Spa=s(x9e);Krt=r(Spa,"rembert"),Spa.forEach(t),ett=r(oeo," \u2014 "),Ane=n(oeo,"A",{href:!0});var Rpa=s(Ane);ott=r(Rpa,"TFRemBertForSequenceClassification"),Rpa.forEach(t),rtt=r(oeo," (RemBERT model)"),oeo.forEach(t),ttt=i(ae),HA=n(ae,"LI",{});var reo=s(HA);$9e=n(reo,"STRONG",{});var Ppa=s($9e);att=r(Ppa,"roberta"),Ppa.forEach(t),ntt=r(reo," \u2014 "),Lne=n(reo,"A",{href:!0});var Bpa=s(Lne);stt=r(Bpa,"TFRobertaForSequenceClassification"),Bpa.forEach(t),ltt=r(reo," (RoBERTa model)"),reo.forEach(t),itt=i(ae),JA=n(ae,"LI",{});var teo=s(JA);k9e=n(teo,"STRONG",{});var Ipa=s(k9e);dtt=r(Ipa,"roformer"),Ipa.forEach(t),mtt=r(teo," \u2014 "),yne=n(teo,"A",{href:!0});var Npa=s(yne);ctt=r(Npa,"TFRoFormerForSequenceClassification"),Npa.forEach(t),ftt=r(teo," (RoFormer model)"),teo.forEach(t),gtt=i(ae),YA=n(ae,"LI",{});var aeo=s(YA);S9e=n(aeo,"STRONG",{});var qpa=s(S9e);htt=r(qpa,"tapas"),qpa.forEach(t),utt=r(aeo," \u2014 "),xne=n(aeo,"A",{href:!0});var Dpa=s(xne);ptt=r(Dpa,"TFTapasForSequenceClassification"),Dpa.forEach(t),_tt=r(aeo," (TAPAS model)"),aeo.forEach(t),btt=i(ae),ZA=n(ae,"LI",{});var neo=s(ZA);R9e=n(neo,"STRONG",{});var jpa=s(R9e);vtt=r(jpa,"transfo-xl"),jpa.forEach(t),Ftt=r(neo," \u2014 "),$ne=n(neo,"A",{href:!0});var Gpa=s($ne);Ttt=r(Gpa,"TFTransfoXLForSequenceClassification"),Gpa.forEach(t),Mtt=r(neo," (Transformer-XL model)"),neo.forEach(t),Ett=i(ae),KA=n(ae,"LI",{});var seo=s(KA);P9e=n(seo,"STRONG",{});var Opa=s(P9e);Ctt=r(Opa,"xlm"),Opa.forEach(t),wtt=r(seo," \u2014 "),kne=n(seo,"A",{href:!0});var Vpa=s(kne);Att=r(Vpa,"TFXLMForSequenceClassification"),Vpa.forEach(t),Ltt=r(seo," (XLM model)"),seo.forEach(t),ytt=i(ae),e6=n(ae,"LI",{});var leo=s(e6);B9e=n(leo,"STRONG",{});var Xpa=s(B9e);xtt=r(Xpa,"xlm-roberta"),Xpa.forEach(t),$tt=r(leo," \u2014 "),Sne=n(leo,"A",{href:!0});var zpa=s(Sne);ktt=r(zpa,"TFXLMRobertaForSequenceClassification"),zpa.forEach(t),Stt=r(leo," (XLM-RoBERTa model)"),leo.forEach(t),Rtt=i(ae),o6=n(ae,"LI",{});var ieo=s(o6);I9e=n(ieo,"STRONG",{});var Qpa=s(I9e);Ptt=r(Qpa,"xlnet"),Qpa.forEach(t),Btt=r(ieo," \u2014 "),Rne=n(ieo,"A",{href:!0});var Wpa=s(Rne);Itt=r(Wpa,"TFXLNetForSequenceClassification"),Wpa.forEach(t),Ntt=r(ieo," (XLNet model)"),ieo.forEach(t),ae.forEach(t),qtt=i($i),T(r6.$$.fragment,$i),$i.forEach(t),xi.forEach(t),ono=i(c),Pc=n(c,"H2",{class:!0});var Flo=s(Pc);t6=n(Flo,"A",{id:!0,class:!0,href:!0});var Upa=s(t6);N9e=n(Upa,"SPAN",{});var Hpa=s(N9e);T(eP.$$.fragment,Hpa),Hpa.forEach(t),Upa.forEach(t),Dtt=i(Flo),q9e=n(Flo,"SPAN",{});var Jpa=s(q9e);jtt=r(Jpa,"TFAutoModelForMultipleChoice"),Jpa.forEach(t),Flo.forEach(t),rno=i(c),br=n(c,"DIV",{class:!0});var ki=s(br);T(oP.$$.fragment,ki),Gtt=i(ki),Bc=n(ki,"P",{});var Ece=s(Bc);Ott=r(Ece,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Pne=n(Ece,"A",{href:!0});var Ypa=s(Pne);Vtt=r(Ypa,"from_pretrained()"),Ypa.forEach(t),Xtt=r(Ece," class method or the "),Bne=n(Ece,"A",{href:!0});var Zpa=s(Bne);ztt=r(Zpa,"from_config()"),Zpa.forEach(t),Qtt=r(Ece,` class
method.`),Ece.forEach(t),Wtt=i(ki),rP=n(ki,"P",{});var Tlo=s(rP);Utt=r(Tlo,"This class cannot be instantiated directly using "),D9e=n(Tlo,"CODE",{});var Kpa=s(D9e);Htt=r(Kpa,"__init__()"),Kpa.forEach(t),Jtt=r(Tlo," (throws an error)."),Tlo.forEach(t),Ytt=i(ki),na=n(ki,"DIV",{class:!0});var vx=s(na);T(tP.$$.fragment,vx),Ztt=i(vx),j9e=n(vx,"P",{});var e_a=s(j9e);Ktt=r(e_a,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),e_a.forEach(t),eat=i(vx),Ic=n(vx,"P",{});var Cce=s(Ic);oat=r(Cce,`Note:
Loading a model from its configuration file does `),G9e=n(Cce,"STRONG",{});var o_a=s(G9e);rat=r(o_a,"not"),o_a.forEach(t),tat=r(Cce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ine=n(Cce,"A",{href:!0});var r_a=s(Ine);aat=r(r_a,"from_pretrained()"),r_a.forEach(t),nat=r(Cce," to load the model weights."),Cce.forEach(t),sat=i(vx),T(a6.$$.fragment,vx),vx.forEach(t),lat=i(ki),Ur=n(ki,"DIV",{class:!0});var Si=s(Ur);T(aP.$$.fragment,Si),iat=i(Si),O9e=n(Si,"P",{});var t_a=s(O9e);dat=r(t_a,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),t_a.forEach(t),mat=i(Si),Vn=n(Si,"P",{});var Fx=s(Vn);cat=r(Fx,"The model class to instantiate is selected based on the "),V9e=n(Fx,"CODE",{});var a_a=s(V9e);fat=r(a_a,"model_type"),a_a.forEach(t),gat=r(Fx,` property of the config object (either
passed as an argument or loaded from `),X9e=n(Fx,"CODE",{});var n_a=s(X9e);hat=r(n_a,"pretrained_model_name_or_path"),n_a.forEach(t),uat=r(Fx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z9e=n(Fx,"CODE",{});var s_a=s(z9e);pat=r(s_a,"pretrained_model_name_or_path"),s_a.forEach(t),_at=r(Fx,":"),Fx.forEach(t),bat=i(Si),ve=n(Si,"UL",{});var Te=s(ve);n6=n(Te,"LI",{});var deo=s(n6);Q9e=n(deo,"STRONG",{});var l_a=s(Q9e);vat=r(l_a,"albert"),l_a.forEach(t),Fat=r(deo," \u2014 "),Nne=n(deo,"A",{href:!0});var i_a=s(Nne);Tat=r(i_a,"TFAlbertForMultipleChoice"),i_a.forEach(t),Mat=r(deo," (ALBERT model)"),deo.forEach(t),Eat=i(Te),s6=n(Te,"LI",{});var meo=s(s6);W9e=n(meo,"STRONG",{});var d_a=s(W9e);Cat=r(d_a,"bert"),d_a.forEach(t),wat=r(meo," \u2014 "),qne=n(meo,"A",{href:!0});var m_a=s(qne);Aat=r(m_a,"TFBertForMultipleChoice"),m_a.forEach(t),Lat=r(meo," (BERT model)"),meo.forEach(t),yat=i(Te),l6=n(Te,"LI",{});var ceo=s(l6);U9e=n(ceo,"STRONG",{});var c_a=s(U9e);xat=r(c_a,"camembert"),c_a.forEach(t),$at=r(ceo," \u2014 "),Dne=n(ceo,"A",{href:!0});var f_a=s(Dne);kat=r(f_a,"TFCamembertForMultipleChoice"),f_a.forEach(t),Sat=r(ceo," (CamemBERT model)"),ceo.forEach(t),Rat=i(Te),i6=n(Te,"LI",{});var feo=s(i6);H9e=n(feo,"STRONG",{});var g_a=s(H9e);Pat=r(g_a,"convbert"),g_a.forEach(t),Bat=r(feo," \u2014 "),jne=n(feo,"A",{href:!0});var h_a=s(jne);Iat=r(h_a,"TFConvBertForMultipleChoice"),h_a.forEach(t),Nat=r(feo," (ConvBERT model)"),feo.forEach(t),qat=i(Te),d6=n(Te,"LI",{});var geo=s(d6);J9e=n(geo,"STRONG",{});var u_a=s(J9e);Dat=r(u_a,"distilbert"),u_a.forEach(t),jat=r(geo," \u2014 "),Gne=n(geo,"A",{href:!0});var p_a=s(Gne);Gat=r(p_a,"TFDistilBertForMultipleChoice"),p_a.forEach(t),Oat=r(geo," (DistilBERT model)"),geo.forEach(t),Vat=i(Te),m6=n(Te,"LI",{});var heo=s(m6);Y9e=n(heo,"STRONG",{});var __a=s(Y9e);Xat=r(__a,"electra"),__a.forEach(t),zat=r(heo," \u2014 "),One=n(heo,"A",{href:!0});var b_a=s(One);Qat=r(b_a,"TFElectraForMultipleChoice"),b_a.forEach(t),Wat=r(heo," (ELECTRA model)"),heo.forEach(t),Uat=i(Te),c6=n(Te,"LI",{});var ueo=s(c6);Z9e=n(ueo,"STRONG",{});var v_a=s(Z9e);Hat=r(v_a,"flaubert"),v_a.forEach(t),Jat=r(ueo," \u2014 "),Vne=n(ueo,"A",{href:!0});var F_a=s(Vne);Yat=r(F_a,"TFFlaubertForMultipleChoice"),F_a.forEach(t),Zat=r(ueo," (FlauBERT model)"),ueo.forEach(t),Kat=i(Te),f6=n(Te,"LI",{});var peo=s(f6);K9e=n(peo,"STRONG",{});var T_a=s(K9e);ent=r(T_a,"funnel"),T_a.forEach(t),ont=r(peo," \u2014 "),Xne=n(peo,"A",{href:!0});var M_a=s(Xne);rnt=r(M_a,"TFFunnelForMultipleChoice"),M_a.forEach(t),tnt=r(peo," (Funnel Transformer model)"),peo.forEach(t),ant=i(Te),g6=n(Te,"LI",{});var _eo=s(g6);exe=n(_eo,"STRONG",{});var E_a=s(exe);nnt=r(E_a,"longformer"),E_a.forEach(t),snt=r(_eo," \u2014 "),zne=n(_eo,"A",{href:!0});var C_a=s(zne);lnt=r(C_a,"TFLongformerForMultipleChoice"),C_a.forEach(t),int=r(_eo," (Longformer model)"),_eo.forEach(t),dnt=i(Te),h6=n(Te,"LI",{});var beo=s(h6);oxe=n(beo,"STRONG",{});var w_a=s(oxe);mnt=r(w_a,"mobilebert"),w_a.forEach(t),cnt=r(beo," \u2014 "),Qne=n(beo,"A",{href:!0});var A_a=s(Qne);fnt=r(A_a,"TFMobileBertForMultipleChoice"),A_a.forEach(t),gnt=r(beo," (MobileBERT model)"),beo.forEach(t),hnt=i(Te),u6=n(Te,"LI",{});var veo=s(u6);rxe=n(veo,"STRONG",{});var L_a=s(rxe);unt=r(L_a,"mpnet"),L_a.forEach(t),pnt=r(veo," \u2014 "),Wne=n(veo,"A",{href:!0});var y_a=s(Wne);_nt=r(y_a,"TFMPNetForMultipleChoice"),y_a.forEach(t),bnt=r(veo," (MPNet model)"),veo.forEach(t),vnt=i(Te),p6=n(Te,"LI",{});var Feo=s(p6);txe=n(Feo,"STRONG",{});var x_a=s(txe);Fnt=r(x_a,"rembert"),x_a.forEach(t),Tnt=r(Feo," \u2014 "),Une=n(Feo,"A",{href:!0});var $_a=s(Une);Mnt=r($_a,"TFRemBertForMultipleChoice"),$_a.forEach(t),Ent=r(Feo," (RemBERT model)"),Feo.forEach(t),Cnt=i(Te),_6=n(Te,"LI",{});var Teo=s(_6);axe=n(Teo,"STRONG",{});var k_a=s(axe);wnt=r(k_a,"roberta"),k_a.forEach(t),Ant=r(Teo," \u2014 "),Hne=n(Teo,"A",{href:!0});var S_a=s(Hne);Lnt=r(S_a,"TFRobertaForMultipleChoice"),S_a.forEach(t),ynt=r(Teo," (RoBERTa model)"),Teo.forEach(t),xnt=i(Te),b6=n(Te,"LI",{});var Meo=s(b6);nxe=n(Meo,"STRONG",{});var R_a=s(nxe);$nt=r(R_a,"roformer"),R_a.forEach(t),knt=r(Meo," \u2014 "),Jne=n(Meo,"A",{href:!0});var P_a=s(Jne);Snt=r(P_a,"TFRoFormerForMultipleChoice"),P_a.forEach(t),Rnt=r(Meo," (RoFormer model)"),Meo.forEach(t),Pnt=i(Te),v6=n(Te,"LI",{});var Eeo=s(v6);sxe=n(Eeo,"STRONG",{});var B_a=s(sxe);Bnt=r(B_a,"xlm"),B_a.forEach(t),Int=r(Eeo," \u2014 "),Yne=n(Eeo,"A",{href:!0});var I_a=s(Yne);Nnt=r(I_a,"TFXLMForMultipleChoice"),I_a.forEach(t),qnt=r(Eeo," (XLM model)"),Eeo.forEach(t),Dnt=i(Te),F6=n(Te,"LI",{});var Ceo=s(F6);lxe=n(Ceo,"STRONG",{});var N_a=s(lxe);jnt=r(N_a,"xlm-roberta"),N_a.forEach(t),Gnt=r(Ceo," \u2014 "),Zne=n(Ceo,"A",{href:!0});var q_a=s(Zne);Ont=r(q_a,"TFXLMRobertaForMultipleChoice"),q_a.forEach(t),Vnt=r(Ceo," (XLM-RoBERTa model)"),Ceo.forEach(t),Xnt=i(Te),T6=n(Te,"LI",{});var weo=s(T6);ixe=n(weo,"STRONG",{});var D_a=s(ixe);znt=r(D_a,"xlnet"),D_a.forEach(t),Qnt=r(weo," \u2014 "),Kne=n(weo,"A",{href:!0});var j_a=s(Kne);Wnt=r(j_a,"TFXLNetForMultipleChoice"),j_a.forEach(t),Unt=r(weo," (XLNet model)"),weo.forEach(t),Te.forEach(t),Hnt=i(Si),T(M6.$$.fragment,Si),Si.forEach(t),ki.forEach(t),tno=i(c),Nc=n(c,"H2",{class:!0});var Mlo=s(Nc);E6=n(Mlo,"A",{id:!0,class:!0,href:!0});var G_a=s(E6);dxe=n(G_a,"SPAN",{});var O_a=s(dxe);T(nP.$$.fragment,O_a),O_a.forEach(t),G_a.forEach(t),Jnt=i(Mlo),mxe=n(Mlo,"SPAN",{});var V_a=s(mxe);Ynt=r(V_a,"TFAutoModelForNextSentencePrediction"),V_a.forEach(t),Mlo.forEach(t),ano=i(c),vr=n(c,"DIV",{class:!0});var Ri=s(vr);T(sP.$$.fragment,Ri),Znt=i(Ri),qc=n(Ri,"P",{});var wce=s(qc);Knt=r(wce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),ese=n(wce,"A",{href:!0});var X_a=s(ese);est=r(X_a,"from_pretrained()"),X_a.forEach(t),ost=r(wce," class method or the "),ose=n(wce,"A",{href:!0});var z_a=s(ose);rst=r(z_a,"from_config()"),z_a.forEach(t),tst=r(wce,` class
method.`),wce.forEach(t),ast=i(Ri),lP=n(Ri,"P",{});var Elo=s(lP);nst=r(Elo,"This class cannot be instantiated directly using "),cxe=n(Elo,"CODE",{});var Q_a=s(cxe);sst=r(Q_a,"__init__()"),Q_a.forEach(t),lst=r(Elo," (throws an error)."),Elo.forEach(t),ist=i(Ri),sa=n(Ri,"DIV",{class:!0});var Tx=s(sa);T(iP.$$.fragment,Tx),dst=i(Tx),fxe=n(Tx,"P",{});var W_a=s(fxe);mst=r(W_a,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),W_a.forEach(t),cst=i(Tx),Dc=n(Tx,"P",{});var Ace=s(Dc);fst=r(Ace,`Note:
Loading a model from its configuration file does `),gxe=n(Ace,"STRONG",{});var U_a=s(gxe);gst=r(U_a,"not"),U_a.forEach(t),hst=r(Ace,` load the model weights. It only affects the
model\u2019s configuration. Use `),rse=n(Ace,"A",{href:!0});var H_a=s(rse);ust=r(H_a,"from_pretrained()"),H_a.forEach(t),pst=r(Ace," to load the model weights."),Ace.forEach(t),_st=i(Tx),T(C6.$$.fragment,Tx),Tx.forEach(t),bst=i(Ri),Hr=n(Ri,"DIV",{class:!0});var Pi=s(Hr);T(dP.$$.fragment,Pi),vst=i(Pi),hxe=n(Pi,"P",{});var J_a=s(hxe);Fst=r(J_a,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),J_a.forEach(t),Tst=i(Pi),Xn=n(Pi,"P",{});var Mx=s(Xn);Mst=r(Mx,"The model class to instantiate is selected based on the "),uxe=n(Mx,"CODE",{});var Y_a=s(uxe);Est=r(Y_a,"model_type"),Y_a.forEach(t),Cst=r(Mx,` property of the config object (either
passed as an argument or loaded from `),pxe=n(Mx,"CODE",{});var Z_a=s(pxe);wst=r(Z_a,"pretrained_model_name_or_path"),Z_a.forEach(t),Ast=r(Mx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_xe=n(Mx,"CODE",{});var K_a=s(_xe);Lst=r(K_a,"pretrained_model_name_or_path"),K_a.forEach(t),yst=r(Mx,":"),Mx.forEach(t),xst=i(Pi),mP=n(Pi,"UL",{});var Clo=s(mP);w6=n(Clo,"LI",{});var Aeo=s(w6);bxe=n(Aeo,"STRONG",{});var e1a=s(bxe);$st=r(e1a,"bert"),e1a.forEach(t),kst=r(Aeo," \u2014 "),tse=n(Aeo,"A",{href:!0});var o1a=s(tse);Sst=r(o1a,"TFBertForNextSentencePrediction"),o1a.forEach(t),Rst=r(Aeo," (BERT model)"),Aeo.forEach(t),Pst=i(Clo),A6=n(Clo,"LI",{});var Leo=s(A6);vxe=n(Leo,"STRONG",{});var r1a=s(vxe);Bst=r(r1a,"mobilebert"),r1a.forEach(t),Ist=r(Leo," \u2014 "),ase=n(Leo,"A",{href:!0});var t1a=s(ase);Nst=r(t1a,"TFMobileBertForNextSentencePrediction"),t1a.forEach(t),qst=r(Leo," (MobileBERT model)"),Leo.forEach(t),Clo.forEach(t),Dst=i(Pi),T(L6.$$.fragment,Pi),Pi.forEach(t),Ri.forEach(t),nno=i(c),jc=n(c,"H2",{class:!0});var wlo=s(jc);y6=n(wlo,"A",{id:!0,class:!0,href:!0});var a1a=s(y6);Fxe=n(a1a,"SPAN",{});var n1a=s(Fxe);T(cP.$$.fragment,n1a),n1a.forEach(t),a1a.forEach(t),jst=i(wlo),Txe=n(wlo,"SPAN",{});var s1a=s(Txe);Gst=r(s1a,"TFAutoModelForTableQuestionAnswering"),s1a.forEach(t),wlo.forEach(t),sno=i(c),Fr=n(c,"DIV",{class:!0});var Bi=s(Fr);T(fP.$$.fragment,Bi),Ost=i(Bi),Gc=n(Bi,"P",{});var Lce=s(Gc);Vst=r(Lce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),nse=n(Lce,"A",{href:!0});var l1a=s(nse);Xst=r(l1a,"from_pretrained()"),l1a.forEach(t),zst=r(Lce," class method or the "),sse=n(Lce,"A",{href:!0});var i1a=s(sse);Qst=r(i1a,"from_config()"),i1a.forEach(t),Wst=r(Lce,` class
method.`),Lce.forEach(t),Ust=i(Bi),gP=n(Bi,"P",{});var Alo=s(gP);Hst=r(Alo,"This class cannot be instantiated directly using "),Mxe=n(Alo,"CODE",{});var d1a=s(Mxe);Jst=r(d1a,"__init__()"),d1a.forEach(t),Yst=r(Alo," (throws an error)."),Alo.forEach(t),Zst=i(Bi),la=n(Bi,"DIV",{class:!0});var Ex=s(la);T(hP.$$.fragment,Ex),Kst=i(Ex),Exe=n(Ex,"P",{});var m1a=s(Exe);elt=r(m1a,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),m1a.forEach(t),olt=i(Ex),Oc=n(Ex,"P",{});var yce=s(Oc);rlt=r(yce,`Note:
Loading a model from its configuration file does `),Cxe=n(yce,"STRONG",{});var c1a=s(Cxe);tlt=r(c1a,"not"),c1a.forEach(t),alt=r(yce,` load the model weights. It only affects the
model\u2019s configuration. Use `),lse=n(yce,"A",{href:!0});var f1a=s(lse);nlt=r(f1a,"from_pretrained()"),f1a.forEach(t),slt=r(yce," to load the model weights."),yce.forEach(t),llt=i(Ex),T(x6.$$.fragment,Ex),Ex.forEach(t),ilt=i(Bi),Jr=n(Bi,"DIV",{class:!0});var Ii=s(Jr);T(uP.$$.fragment,Ii),dlt=i(Ii),wxe=n(Ii,"P",{});var g1a=s(wxe);mlt=r(g1a,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),g1a.forEach(t),clt=i(Ii),zn=n(Ii,"P",{});var Cx=s(zn);flt=r(Cx,"The model class to instantiate is selected based on the "),Axe=n(Cx,"CODE",{});var h1a=s(Axe);glt=r(h1a,"model_type"),h1a.forEach(t),hlt=r(Cx,` property of the config object (either
passed as an argument or loaded from `),Lxe=n(Cx,"CODE",{});var u1a=s(Lxe);ult=r(u1a,"pretrained_model_name_or_path"),u1a.forEach(t),plt=r(Cx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yxe=n(Cx,"CODE",{});var p1a=s(yxe);_lt=r(p1a,"pretrained_model_name_or_path"),p1a.forEach(t),blt=r(Cx,":"),Cx.forEach(t),vlt=i(Ii),xxe=n(Ii,"UL",{});var _1a=s(xxe);$6=n(_1a,"LI",{});var yeo=s($6);$xe=n(yeo,"STRONG",{});var b1a=s($xe);Flt=r(b1a,"tapas"),b1a.forEach(t),Tlt=r(yeo," \u2014 "),ise=n(yeo,"A",{href:!0});var v1a=s(ise);Mlt=r(v1a,"TFTapasForQuestionAnswering"),v1a.forEach(t),Elt=r(yeo," (TAPAS model)"),yeo.forEach(t),_1a.forEach(t),Clt=i(Ii),T(k6.$$.fragment,Ii),Ii.forEach(t),Bi.forEach(t),lno=i(c),Vc=n(c,"H2",{class:!0});var Llo=s(Vc);S6=n(Llo,"A",{id:!0,class:!0,href:!0});var F1a=s(S6);kxe=n(F1a,"SPAN",{});var T1a=s(kxe);T(pP.$$.fragment,T1a),T1a.forEach(t),F1a.forEach(t),wlt=i(Llo),Sxe=n(Llo,"SPAN",{});var M1a=s(Sxe);Alt=r(M1a,"TFAutoModelForDocumentQuestionAnswering"),M1a.forEach(t),Llo.forEach(t),ino=i(c),Tr=n(c,"DIV",{class:!0});var Ni=s(Tr);T(_P.$$.fragment,Ni),Llt=i(Ni),Xc=n(Ni,"P",{});var xce=s(Xc);ylt=r(xce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),dse=n(xce,"A",{href:!0});var E1a=s(dse);xlt=r(E1a,"from_pretrained()"),E1a.forEach(t),$lt=r(xce," class method or the "),mse=n(xce,"A",{href:!0});var C1a=s(mse);klt=r(C1a,"from_config()"),C1a.forEach(t),Slt=r(xce,` class
method.`),xce.forEach(t),Rlt=i(Ni),bP=n(Ni,"P",{});var ylo=s(bP);Plt=r(ylo,"This class cannot be instantiated directly using "),Rxe=n(ylo,"CODE",{});var w1a=s(Rxe);Blt=r(w1a,"__init__()"),w1a.forEach(t),Ilt=r(ylo," (throws an error)."),ylo.forEach(t),Nlt=i(Ni),ia=n(Ni,"DIV",{class:!0});var wx=s(ia);T(vP.$$.fragment,wx),qlt=i(wx),Pxe=n(wx,"P",{});var A1a=s(Pxe);Dlt=r(A1a,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),A1a.forEach(t),jlt=i(wx),zc=n(wx,"P",{});var $ce=s(zc);Glt=r($ce,`Note:
Loading a model from its configuration file does `),Bxe=n($ce,"STRONG",{});var L1a=s(Bxe);Olt=r(L1a,"not"),L1a.forEach(t),Vlt=r($ce,` load the model weights. It only affects the
model\u2019s configuration. Use `),cse=n($ce,"A",{href:!0});var y1a=s(cse);Xlt=r(y1a,"from_pretrained()"),y1a.forEach(t),zlt=r($ce," to load the model weights."),$ce.forEach(t),Qlt=i(wx),T(R6.$$.fragment,wx),wx.forEach(t),Wlt=i(Ni),Yr=n(Ni,"DIV",{class:!0});var qi=s(Yr);T(FP.$$.fragment,qi),Ult=i(qi),Ixe=n(qi,"P",{});var x1a=s(Ixe);Hlt=r(x1a,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),x1a.forEach(t),Jlt=i(qi),Qn=n(qi,"P",{});var Ax=s(Qn);Ylt=r(Ax,"The model class to instantiate is selected based on the "),Nxe=n(Ax,"CODE",{});var $1a=s(Nxe);Zlt=r($1a,"model_type"),$1a.forEach(t),Klt=r(Ax,` property of the config object (either
passed as an argument or loaded from `),qxe=n(Ax,"CODE",{});var k1a=s(qxe);eit=r(k1a,"pretrained_model_name_or_path"),k1a.forEach(t),oit=r(Ax,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Dxe=n(Ax,"CODE",{});var S1a=s(Dxe);rit=r(S1a,"pretrained_model_name_or_path"),S1a.forEach(t),tit=r(Ax,":"),Ax.forEach(t),ait=i(qi),jxe=n(qi,"UL",{});var R1a=s(jxe);P6=n(R1a,"LI",{});var xeo=s(P6);Gxe=n(xeo,"STRONG",{});var P1a=s(Gxe);nit=r(P1a,"layoutlm"),P1a.forEach(t),sit=r(xeo," \u2014 "),fse=n(xeo,"A",{href:!0});var B1a=s(fse);lit=r(B1a,"TFLayoutLMForQuestionAnswering"),B1a.forEach(t),iit=r(xeo," (LayoutLM model)"),xeo.forEach(t),R1a.forEach(t),dit=i(qi),T(B6.$$.fragment,qi),qi.forEach(t),Ni.forEach(t),dno=i(c),Qc=n(c,"H2",{class:!0});var xlo=s(Qc);I6=n(xlo,"A",{id:!0,class:!0,href:!0});var I1a=s(I6);Oxe=n(I1a,"SPAN",{});var N1a=s(Oxe);T(TP.$$.fragment,N1a),N1a.forEach(t),I1a.forEach(t),mit=i(xlo),Vxe=n(xlo,"SPAN",{});var q1a=s(Vxe);cit=r(q1a,"TFAutoModelForTokenClassification"),q1a.forEach(t),xlo.forEach(t),mno=i(c),Mr=n(c,"DIV",{class:!0});var Di=s(Mr);T(MP.$$.fragment,Di),fit=i(Di),Wc=n(Di,"P",{});var kce=s(Wc);git=r(kce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),gse=n(kce,"A",{href:!0});var D1a=s(gse);hit=r(D1a,"from_pretrained()"),D1a.forEach(t),uit=r(kce," class method or the "),hse=n(kce,"A",{href:!0});var j1a=s(hse);pit=r(j1a,"from_config()"),j1a.forEach(t),_it=r(kce,` class
method.`),kce.forEach(t),bit=i(Di),EP=n(Di,"P",{});var $lo=s(EP);vit=r($lo,"This class cannot be instantiated directly using "),Xxe=n($lo,"CODE",{});var G1a=s(Xxe);Fit=r(G1a,"__init__()"),G1a.forEach(t),Tit=r($lo," (throws an error)."),$lo.forEach(t),Mit=i(Di),da=n(Di,"DIV",{class:!0});var Lx=s(da);T(CP.$$.fragment,Lx),Eit=i(Lx),zxe=n(Lx,"P",{});var O1a=s(zxe);Cit=r(O1a,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),O1a.forEach(t),wit=i(Lx),Uc=n(Lx,"P",{});var Sce=s(Uc);Ait=r(Sce,`Note:
Loading a model from its configuration file does `),Qxe=n(Sce,"STRONG",{});var V1a=s(Qxe);Lit=r(V1a,"not"),V1a.forEach(t),yit=r(Sce,` load the model weights. It only affects the
model\u2019s configuration. Use `),use=n(Sce,"A",{href:!0});var X1a=s(use);xit=r(X1a,"from_pretrained()"),X1a.forEach(t),$it=r(Sce," to load the model weights."),Sce.forEach(t),kit=i(Lx),T(N6.$$.fragment,Lx),Lx.forEach(t),Sit=i(Di),Zr=n(Di,"DIV",{class:!0});var ji=s(Zr);T(wP.$$.fragment,ji),Rit=i(ji),Wxe=n(ji,"P",{});var z1a=s(Wxe);Pit=r(z1a,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),z1a.forEach(t),Bit=i(ji),Wn=n(ji,"P",{});var yx=s(Wn);Iit=r(yx,"The model class to instantiate is selected based on the "),Uxe=n(yx,"CODE",{});var Q1a=s(Uxe);Nit=r(Q1a,"model_type"),Q1a.forEach(t),qit=r(yx,` property of the config object (either
passed as an argument or loaded from `),Hxe=n(yx,"CODE",{});var W1a=s(Hxe);Dit=r(W1a,"pretrained_model_name_or_path"),W1a.forEach(t),jit=r(yx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jxe=n(yx,"CODE",{});var U1a=s(Jxe);Git=r(U1a,"pretrained_model_name_or_path"),U1a.forEach(t),Oit=r(yx,":"),yx.forEach(t),Vit=i(ji),ie=n(ji,"UL",{});var ge=s(ie);q6=n(ge,"LI",{});var $eo=s(q6);Yxe=n($eo,"STRONG",{});var H1a=s(Yxe);Xit=r(H1a,"albert"),H1a.forEach(t),zit=r($eo," \u2014 "),pse=n($eo,"A",{href:!0});var J1a=s(pse);Qit=r(J1a,"TFAlbertForTokenClassification"),J1a.forEach(t),Wit=r($eo," (ALBERT model)"),$eo.forEach(t),Uit=i(ge),D6=n(ge,"LI",{});var keo=s(D6);Zxe=n(keo,"STRONG",{});var Y1a=s(Zxe);Hit=r(Y1a,"bert"),Y1a.forEach(t),Jit=r(keo," \u2014 "),_se=n(keo,"A",{href:!0});var Z1a=s(_se);Yit=r(Z1a,"TFBertForTokenClassification"),Z1a.forEach(t),Zit=r(keo," (BERT model)"),keo.forEach(t),Kit=i(ge),j6=n(ge,"LI",{});var Seo=s(j6);Kxe=n(Seo,"STRONG",{});var K1a=s(Kxe);edt=r(K1a,"camembert"),K1a.forEach(t),odt=r(Seo," \u2014 "),bse=n(Seo,"A",{href:!0});var e2a=s(bse);rdt=r(e2a,"TFCamembertForTokenClassification"),e2a.forEach(t),tdt=r(Seo," (CamemBERT model)"),Seo.forEach(t),adt=i(ge),G6=n(ge,"LI",{});var Reo=s(G6);e$e=n(Reo,"STRONG",{});var o2a=s(e$e);ndt=r(o2a,"convbert"),o2a.forEach(t),sdt=r(Reo," \u2014 "),vse=n(Reo,"A",{href:!0});var r2a=s(vse);ldt=r(r2a,"TFConvBertForTokenClassification"),r2a.forEach(t),idt=r(Reo," (ConvBERT model)"),Reo.forEach(t),ddt=i(ge),O6=n(ge,"LI",{});var Peo=s(O6);o$e=n(Peo,"STRONG",{});var t2a=s(o$e);mdt=r(t2a,"deberta"),t2a.forEach(t),cdt=r(Peo," \u2014 "),Fse=n(Peo,"A",{href:!0});var a2a=s(Fse);fdt=r(a2a,"TFDebertaForTokenClassification"),a2a.forEach(t),gdt=r(Peo," (DeBERTa model)"),Peo.forEach(t),hdt=i(ge),V6=n(ge,"LI",{});var Beo=s(V6);r$e=n(Beo,"STRONG",{});var n2a=s(r$e);udt=r(n2a,"deberta-v2"),n2a.forEach(t),pdt=r(Beo," \u2014 "),Tse=n(Beo,"A",{href:!0});var s2a=s(Tse);_dt=r(s2a,"TFDebertaV2ForTokenClassification"),s2a.forEach(t),bdt=r(Beo," (DeBERTa-v2 model)"),Beo.forEach(t),vdt=i(ge),X6=n(ge,"LI",{});var Ieo=s(X6);t$e=n(Ieo,"STRONG",{});var l2a=s(t$e);Fdt=r(l2a,"distilbert"),l2a.forEach(t),Tdt=r(Ieo," \u2014 "),Mse=n(Ieo,"A",{href:!0});var i2a=s(Mse);Mdt=r(i2a,"TFDistilBertForTokenClassification"),i2a.forEach(t),Edt=r(Ieo," (DistilBERT model)"),Ieo.forEach(t),Cdt=i(ge),z6=n(ge,"LI",{});var Neo=s(z6);a$e=n(Neo,"STRONG",{});var d2a=s(a$e);wdt=r(d2a,"electra"),d2a.forEach(t),Adt=r(Neo," \u2014 "),Ese=n(Neo,"A",{href:!0});var m2a=s(Ese);Ldt=r(m2a,"TFElectraForTokenClassification"),m2a.forEach(t),ydt=r(Neo," (ELECTRA model)"),Neo.forEach(t),xdt=i(ge),Q6=n(ge,"LI",{});var qeo=s(Q6);n$e=n(qeo,"STRONG",{});var c2a=s(n$e);$dt=r(c2a,"esm"),c2a.forEach(t),kdt=r(qeo," \u2014 "),Cse=n(qeo,"A",{href:!0});var f2a=s(Cse);Sdt=r(f2a,"TFEsmForTokenClassification"),f2a.forEach(t),Rdt=r(qeo," (ESM model)"),qeo.forEach(t),Pdt=i(ge),W6=n(ge,"LI",{});var Deo=s(W6);s$e=n(Deo,"STRONG",{});var g2a=s(s$e);Bdt=r(g2a,"flaubert"),g2a.forEach(t),Idt=r(Deo," \u2014 "),wse=n(Deo,"A",{href:!0});var h2a=s(wse);Ndt=r(h2a,"TFFlaubertForTokenClassification"),h2a.forEach(t),qdt=r(Deo," (FlauBERT model)"),Deo.forEach(t),Ddt=i(ge),U6=n(ge,"LI",{});var jeo=s(U6);l$e=n(jeo,"STRONG",{});var u2a=s(l$e);jdt=r(u2a,"funnel"),u2a.forEach(t),Gdt=r(jeo," \u2014 "),Ase=n(jeo,"A",{href:!0});var p2a=s(Ase);Odt=r(p2a,"TFFunnelForTokenClassification"),p2a.forEach(t),Vdt=r(jeo," (Funnel Transformer model)"),jeo.forEach(t),Xdt=i(ge),H6=n(ge,"LI",{});var Geo=s(H6);i$e=n(Geo,"STRONG",{});var _2a=s(i$e);zdt=r(_2a,"layoutlm"),_2a.forEach(t),Qdt=r(Geo," \u2014 "),Lse=n(Geo,"A",{href:!0});var b2a=s(Lse);Wdt=r(b2a,"TFLayoutLMForTokenClassification"),b2a.forEach(t),Udt=r(Geo," (LayoutLM model)"),Geo.forEach(t),Hdt=i(ge),J6=n(ge,"LI",{});var Oeo=s(J6);d$e=n(Oeo,"STRONG",{});var v2a=s(d$e);Jdt=r(v2a,"layoutlmv3"),v2a.forEach(t),Ydt=r(Oeo," \u2014 "),yse=n(Oeo,"A",{href:!0});var F2a=s(yse);Zdt=r(F2a,"TFLayoutLMv3ForTokenClassification"),F2a.forEach(t),Kdt=r(Oeo," (LayoutLMv3 model)"),Oeo.forEach(t),emt=i(ge),Y6=n(ge,"LI",{});var Veo=s(Y6);m$e=n(Veo,"STRONG",{});var T2a=s(m$e);omt=r(T2a,"longformer"),T2a.forEach(t),rmt=r(Veo," \u2014 "),xse=n(Veo,"A",{href:!0});var M2a=s(xse);tmt=r(M2a,"TFLongformerForTokenClassification"),M2a.forEach(t),amt=r(Veo," (Longformer model)"),Veo.forEach(t),nmt=i(ge),Z6=n(ge,"LI",{});var Xeo=s(Z6);c$e=n(Xeo,"STRONG",{});var E2a=s(c$e);smt=r(E2a,"mobilebert"),E2a.forEach(t),lmt=r(Xeo," \u2014 "),$se=n(Xeo,"A",{href:!0});var C2a=s($se);imt=r(C2a,"TFMobileBertForTokenClassification"),C2a.forEach(t),dmt=r(Xeo," (MobileBERT model)"),Xeo.forEach(t),mmt=i(ge),K6=n(ge,"LI",{});var zeo=s(K6);f$e=n(zeo,"STRONG",{});var w2a=s(f$e);cmt=r(w2a,"mpnet"),w2a.forEach(t),fmt=r(zeo," \u2014 "),kse=n(zeo,"A",{href:!0});var A2a=s(kse);gmt=r(A2a,"TFMPNetForTokenClassification"),A2a.forEach(t),hmt=r(zeo," (MPNet model)"),zeo.forEach(t),umt=i(ge),e7=n(ge,"LI",{});var Qeo=s(e7);g$e=n(Qeo,"STRONG",{});var L2a=s(g$e);pmt=r(L2a,"rembert"),L2a.forEach(t),_mt=r(Qeo," \u2014 "),Sse=n(Qeo,"A",{href:!0});var y2a=s(Sse);bmt=r(y2a,"TFRemBertForTokenClassification"),y2a.forEach(t),vmt=r(Qeo," (RemBERT model)"),Qeo.forEach(t),Fmt=i(ge),o7=n(ge,"LI",{});var Weo=s(o7);h$e=n(Weo,"STRONG",{});var x2a=s(h$e);Tmt=r(x2a,"roberta"),x2a.forEach(t),Mmt=r(Weo," \u2014 "),Rse=n(Weo,"A",{href:!0});var $2a=s(Rse);Emt=r($2a,"TFRobertaForTokenClassification"),$2a.forEach(t),Cmt=r(Weo," (RoBERTa model)"),Weo.forEach(t),wmt=i(ge),r7=n(ge,"LI",{});var Ueo=s(r7);u$e=n(Ueo,"STRONG",{});var k2a=s(u$e);Amt=r(k2a,"roformer"),k2a.forEach(t),Lmt=r(Ueo," \u2014 "),Pse=n(Ueo,"A",{href:!0});var S2a=s(Pse);ymt=r(S2a,"TFRoFormerForTokenClassification"),S2a.forEach(t),xmt=r(Ueo," (RoFormer model)"),Ueo.forEach(t),$mt=i(ge),t7=n(ge,"LI",{});var Heo=s(t7);p$e=n(Heo,"STRONG",{});var R2a=s(p$e);kmt=r(R2a,"xlm"),R2a.forEach(t),Smt=r(Heo," \u2014 "),Bse=n(Heo,"A",{href:!0});var P2a=s(Bse);Rmt=r(P2a,"TFXLMForTokenClassification"),P2a.forEach(t),Pmt=r(Heo," (XLM model)"),Heo.forEach(t),Bmt=i(ge),a7=n(ge,"LI",{});var Jeo=s(a7);_$e=n(Jeo,"STRONG",{});var B2a=s(_$e);Imt=r(B2a,"xlm-roberta"),B2a.forEach(t),Nmt=r(Jeo," \u2014 "),Ise=n(Jeo,"A",{href:!0});var I2a=s(Ise);qmt=r(I2a,"TFXLMRobertaForTokenClassification"),I2a.forEach(t),Dmt=r(Jeo," (XLM-RoBERTa model)"),Jeo.forEach(t),jmt=i(ge),n7=n(ge,"LI",{});var Yeo=s(n7);b$e=n(Yeo,"STRONG",{});var N2a=s(b$e);Gmt=r(N2a,"xlnet"),N2a.forEach(t),Omt=r(Yeo," \u2014 "),Nse=n(Yeo,"A",{href:!0});var q2a=s(Nse);Vmt=r(q2a,"TFXLNetForTokenClassification"),q2a.forEach(t),Xmt=r(Yeo," (XLNet model)"),Yeo.forEach(t),ge.forEach(t),zmt=i(ji),T(s7.$$.fragment,ji),ji.forEach(t),Di.forEach(t),cno=i(c),Hc=n(c,"H2",{class:!0});var klo=s(Hc);l7=n(klo,"A",{id:!0,class:!0,href:!0});var D2a=s(l7);v$e=n(D2a,"SPAN",{});var j2a=s(v$e);T(AP.$$.fragment,j2a),j2a.forEach(t),D2a.forEach(t),Qmt=i(klo),F$e=n(klo,"SPAN",{});var G2a=s(F$e);Wmt=r(G2a,"TFAutoModelForQuestionAnswering"),G2a.forEach(t),klo.forEach(t),fno=i(c),Er=n(c,"DIV",{class:!0});var Gi=s(Er);T(LP.$$.fragment,Gi),Umt=i(Gi),Jc=n(Gi,"P",{});var Rce=s(Jc);Hmt=r(Rce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),qse=n(Rce,"A",{href:!0});var O2a=s(qse);Jmt=r(O2a,"from_pretrained()"),O2a.forEach(t),Ymt=r(Rce," class method or the "),Dse=n(Rce,"A",{href:!0});var V2a=s(Dse);Zmt=r(V2a,"from_config()"),V2a.forEach(t),Kmt=r(Rce,` class
method.`),Rce.forEach(t),ect=i(Gi),yP=n(Gi,"P",{});var Slo=s(yP);oct=r(Slo,"This class cannot be instantiated directly using "),T$e=n(Slo,"CODE",{});var X2a=s(T$e);rct=r(X2a,"__init__()"),X2a.forEach(t),tct=r(Slo," (throws an error)."),Slo.forEach(t),act=i(Gi),ma=n(Gi,"DIV",{class:!0});var xx=s(ma);T(xP.$$.fragment,xx),nct=i(xx),M$e=n(xx,"P",{});var z2a=s(M$e);sct=r(z2a,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),z2a.forEach(t),lct=i(xx),Yc=n(xx,"P",{});var Pce=s(Yc);ict=r(Pce,`Note:
Loading a model from its configuration file does `),E$e=n(Pce,"STRONG",{});var Q2a=s(E$e);dct=r(Q2a,"not"),Q2a.forEach(t),mct=r(Pce,` load the model weights. It only affects the
model\u2019s configuration. Use `),jse=n(Pce,"A",{href:!0});var W2a=s(jse);cct=r(W2a,"from_pretrained()"),W2a.forEach(t),fct=r(Pce," to load the model weights."),Pce.forEach(t),gct=i(xx),T(i7.$$.fragment,xx),xx.forEach(t),hct=i(Gi),Kr=n(Gi,"DIV",{class:!0});var Oi=s(Kr);T($P.$$.fragment,Oi),uct=i(Oi),C$e=n(Oi,"P",{});var U2a=s(C$e);pct=r(U2a,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),U2a.forEach(t),_ct=i(Oi),Un=n(Oi,"P",{});var $x=s(Un);bct=r($x,"The model class to instantiate is selected based on the "),w$e=n($x,"CODE",{});var H2a=s(w$e);vct=r(H2a,"model_type"),H2a.forEach(t),Fct=r($x,` property of the config object (either
passed as an argument or loaded from `),A$e=n($x,"CODE",{});var J2a=s(A$e);Tct=r(J2a,"pretrained_model_name_or_path"),J2a.forEach(t),Mct=r($x,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L$e=n($x,"CODE",{});var Y2a=s(L$e);Ect=r(Y2a,"pretrained_model_name_or_path"),Y2a.forEach(t),Cct=r($x,":"),$x.forEach(t),wct=i(Oi),fe=n(Oi,"UL",{});var pe=s(fe);d7=n(pe,"LI",{});var Zeo=s(d7);y$e=n(Zeo,"STRONG",{});var Z2a=s(y$e);Act=r(Z2a,"albert"),Z2a.forEach(t),Lct=r(Zeo," \u2014 "),Gse=n(Zeo,"A",{href:!0});var K2a=s(Gse);yct=r(K2a,"TFAlbertForQuestionAnswering"),K2a.forEach(t),xct=r(Zeo," (ALBERT model)"),Zeo.forEach(t),$ct=i(pe),m7=n(pe,"LI",{});var Keo=s(m7);x$e=n(Keo,"STRONG",{});var eba=s(x$e);kct=r(eba,"bert"),eba.forEach(t),Sct=r(Keo," \u2014 "),Ose=n(Keo,"A",{href:!0});var oba=s(Ose);Rct=r(oba,"TFBertForQuestionAnswering"),oba.forEach(t),Pct=r(Keo," (BERT model)"),Keo.forEach(t),Bct=i(pe),c7=n(pe,"LI",{});var eoo=s(c7);$$e=n(eoo,"STRONG",{});var rba=s($$e);Ict=r(rba,"camembert"),rba.forEach(t),Nct=r(eoo," \u2014 "),Vse=n(eoo,"A",{href:!0});var tba=s(Vse);qct=r(tba,"TFCamembertForQuestionAnswering"),tba.forEach(t),Dct=r(eoo," (CamemBERT model)"),eoo.forEach(t),jct=i(pe),f7=n(pe,"LI",{});var ooo=s(f7);k$e=n(ooo,"STRONG",{});var aba=s(k$e);Gct=r(aba,"convbert"),aba.forEach(t),Oct=r(ooo," \u2014 "),Xse=n(ooo,"A",{href:!0});var nba=s(Xse);Vct=r(nba,"TFConvBertForQuestionAnswering"),nba.forEach(t),Xct=r(ooo," (ConvBERT model)"),ooo.forEach(t),zct=i(pe),g7=n(pe,"LI",{});var roo=s(g7);S$e=n(roo,"STRONG",{});var sba=s(S$e);Qct=r(sba,"deberta"),sba.forEach(t),Wct=r(roo," \u2014 "),zse=n(roo,"A",{href:!0});var lba=s(zse);Uct=r(lba,"TFDebertaForQuestionAnswering"),lba.forEach(t),Hct=r(roo," (DeBERTa model)"),roo.forEach(t),Jct=i(pe),h7=n(pe,"LI",{});var too=s(h7);R$e=n(too,"STRONG",{});var iba=s(R$e);Yct=r(iba,"deberta-v2"),iba.forEach(t),Zct=r(too," \u2014 "),Qse=n(too,"A",{href:!0});var dba=s(Qse);Kct=r(dba,"TFDebertaV2ForQuestionAnswering"),dba.forEach(t),eft=r(too," (DeBERTa-v2 model)"),too.forEach(t),oft=i(pe),u7=n(pe,"LI",{});var aoo=s(u7);P$e=n(aoo,"STRONG",{});var mba=s(P$e);rft=r(mba,"distilbert"),mba.forEach(t),tft=r(aoo," \u2014 "),Wse=n(aoo,"A",{href:!0});var cba=s(Wse);aft=r(cba,"TFDistilBertForQuestionAnswering"),cba.forEach(t),nft=r(aoo," (DistilBERT model)"),aoo.forEach(t),sft=i(pe),p7=n(pe,"LI",{});var noo=s(p7);B$e=n(noo,"STRONG",{});var fba=s(B$e);lft=r(fba,"electra"),fba.forEach(t),ift=r(noo," \u2014 "),Use=n(noo,"A",{href:!0});var gba=s(Use);dft=r(gba,"TFElectraForQuestionAnswering"),gba.forEach(t),mft=r(noo," (ELECTRA model)"),noo.forEach(t),cft=i(pe),_7=n(pe,"LI",{});var soo=s(_7);I$e=n(soo,"STRONG",{});var hba=s(I$e);fft=r(hba,"flaubert"),hba.forEach(t),gft=r(soo," \u2014 "),Hse=n(soo,"A",{href:!0});var uba=s(Hse);hft=r(uba,"TFFlaubertForQuestionAnsweringSimple"),uba.forEach(t),uft=r(soo," (FlauBERT model)"),soo.forEach(t),pft=i(pe),b7=n(pe,"LI",{});var loo=s(b7);N$e=n(loo,"STRONG",{});var pba=s(N$e);_ft=r(pba,"funnel"),pba.forEach(t),bft=r(loo," \u2014 "),Jse=n(loo,"A",{href:!0});var _ba=s(Jse);vft=r(_ba,"TFFunnelForQuestionAnswering"),_ba.forEach(t),Fft=r(loo," (Funnel Transformer model)"),loo.forEach(t),Tft=i(pe),v7=n(pe,"LI",{});var ioo=s(v7);q$e=n(ioo,"STRONG",{});var bba=s(q$e);Mft=r(bba,"gptj"),bba.forEach(t),Eft=r(ioo," \u2014 "),Yse=n(ioo,"A",{href:!0});var vba=s(Yse);Cft=r(vba,"TFGPTJForQuestionAnswering"),vba.forEach(t),wft=r(ioo," (GPT-J model)"),ioo.forEach(t),Aft=i(pe),F7=n(pe,"LI",{});var doo=s(F7);D$e=n(doo,"STRONG",{});var Fba=s(D$e);Lft=r(Fba,"layoutlmv3"),Fba.forEach(t),yft=r(doo," \u2014 "),Zse=n(doo,"A",{href:!0});var Tba=s(Zse);xft=r(Tba,"TFLayoutLMv3ForQuestionAnswering"),Tba.forEach(t),$ft=r(doo," (LayoutLMv3 model)"),doo.forEach(t),kft=i(pe),T7=n(pe,"LI",{});var moo=s(T7);j$e=n(moo,"STRONG",{});var Mba=s(j$e);Sft=r(Mba,"longformer"),Mba.forEach(t),Rft=r(moo," \u2014 "),Kse=n(moo,"A",{href:!0});var Eba=s(Kse);Pft=r(Eba,"TFLongformerForQuestionAnswering"),Eba.forEach(t),Bft=r(moo," (Longformer model)"),moo.forEach(t),Ift=i(pe),M7=n(pe,"LI",{});var coo=s(M7);G$e=n(coo,"STRONG",{});var Cba=s(G$e);Nft=r(Cba,"mobilebert"),Cba.forEach(t),qft=r(coo," \u2014 "),ele=n(coo,"A",{href:!0});var wba=s(ele);Dft=r(wba,"TFMobileBertForQuestionAnswering"),wba.forEach(t),jft=r(coo," (MobileBERT model)"),coo.forEach(t),Gft=i(pe),E7=n(pe,"LI",{});var foo=s(E7);O$e=n(foo,"STRONG",{});var Aba=s(O$e);Oft=r(Aba,"mpnet"),Aba.forEach(t),Vft=r(foo," \u2014 "),ole=n(foo,"A",{href:!0});var Lba=s(ole);Xft=r(Lba,"TFMPNetForQuestionAnswering"),Lba.forEach(t),zft=r(foo," (MPNet model)"),foo.forEach(t),Qft=i(pe),C7=n(pe,"LI",{});var goo=s(C7);V$e=n(goo,"STRONG",{});var yba=s(V$e);Wft=r(yba,"rembert"),yba.forEach(t),Uft=r(goo," \u2014 "),rle=n(goo,"A",{href:!0});var xba=s(rle);Hft=r(xba,"TFRemBertForQuestionAnswering"),xba.forEach(t),Jft=r(goo," (RemBERT model)"),goo.forEach(t),Yft=i(pe),w7=n(pe,"LI",{});var hoo=s(w7);X$e=n(hoo,"STRONG",{});var $ba=s(X$e);Zft=r($ba,"roberta"),$ba.forEach(t),Kft=r(hoo," \u2014 "),tle=n(hoo,"A",{href:!0});var kba=s(tle);egt=r(kba,"TFRobertaForQuestionAnswering"),kba.forEach(t),ogt=r(hoo," (RoBERTa model)"),hoo.forEach(t),rgt=i(pe),A7=n(pe,"LI",{});var uoo=s(A7);z$e=n(uoo,"STRONG",{});var Sba=s(z$e);tgt=r(Sba,"roformer"),Sba.forEach(t),agt=r(uoo," \u2014 "),ale=n(uoo,"A",{href:!0});var Rba=s(ale);ngt=r(Rba,"TFRoFormerForQuestionAnswering"),Rba.forEach(t),sgt=r(uoo," (RoFormer model)"),uoo.forEach(t),lgt=i(pe),L7=n(pe,"LI",{});var poo=s(L7);Q$e=n(poo,"STRONG",{});var Pba=s(Q$e);igt=r(Pba,"xlm"),Pba.forEach(t),dgt=r(poo," \u2014 "),nle=n(poo,"A",{href:!0});var Bba=s(nle);mgt=r(Bba,"TFXLMForQuestionAnsweringSimple"),Bba.forEach(t),cgt=r(poo," (XLM model)"),poo.forEach(t),fgt=i(pe),y7=n(pe,"LI",{});var _oo=s(y7);W$e=n(_oo,"STRONG",{});var Iba=s(W$e);ggt=r(Iba,"xlm-roberta"),Iba.forEach(t),hgt=r(_oo," \u2014 "),sle=n(_oo,"A",{href:!0});var Nba=s(sle);ugt=r(Nba,"TFXLMRobertaForQuestionAnswering"),Nba.forEach(t),pgt=r(_oo," (XLM-RoBERTa model)"),_oo.forEach(t),_gt=i(pe),x7=n(pe,"LI",{});var boo=s(x7);U$e=n(boo,"STRONG",{});var qba=s(U$e);bgt=r(qba,"xlnet"),qba.forEach(t),vgt=r(boo," \u2014 "),lle=n(boo,"A",{href:!0});var Dba=s(lle);Fgt=r(Dba,"TFXLNetForQuestionAnsweringSimple"),Dba.forEach(t),Tgt=r(boo," (XLNet model)"),boo.forEach(t),pe.forEach(t),Mgt=i(Oi),T($7.$$.fragment,Oi),Oi.forEach(t),Gi.forEach(t),gno=i(c),Zc=n(c,"H2",{class:!0});var Rlo=s(Zc);k7=n(Rlo,"A",{id:!0,class:!0,href:!0});var jba=s(k7);H$e=n(jba,"SPAN",{});var Gba=s(H$e);T(kP.$$.fragment,Gba),Gba.forEach(t),jba.forEach(t),Egt=i(Rlo),J$e=n(Rlo,"SPAN",{});var Oba=s(J$e);Cgt=r(Oba,"TFAutoModelForVision2Seq"),Oba.forEach(t),Rlo.forEach(t),hno=i(c),Cr=n(c,"DIV",{class:!0});var Vi=s(Cr);T(SP.$$.fragment,Vi),wgt=i(Vi),Kc=n(Vi,"P",{});var Bce=s(Kc);Agt=r(Bce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),ile=n(Bce,"A",{href:!0});var Vba=s(ile);Lgt=r(Vba,"from_pretrained()"),Vba.forEach(t),ygt=r(Bce," class method or the "),dle=n(Bce,"A",{href:!0});var Xba=s(dle);xgt=r(Xba,"from_config()"),Xba.forEach(t),$gt=r(Bce,` class
method.`),Bce.forEach(t),kgt=i(Vi),RP=n(Vi,"P",{});var Plo=s(RP);Sgt=r(Plo,"This class cannot be instantiated directly using "),Y$e=n(Plo,"CODE",{});var zba=s(Y$e);Rgt=r(zba,"__init__()"),zba.forEach(t),Pgt=r(Plo," (throws an error)."),Plo.forEach(t),Bgt=i(Vi),ca=n(Vi,"DIV",{class:!0});var kx=s(ca);T(PP.$$.fragment,kx),Igt=i(kx),Z$e=n(kx,"P",{});var Qba=s(Z$e);Ngt=r(Qba,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Qba.forEach(t),qgt=i(kx),ef=n(kx,"P",{});var Ice=s(ef);Dgt=r(Ice,`Note:
Loading a model from its configuration file does `),K$e=n(Ice,"STRONG",{});var Wba=s(K$e);jgt=r(Wba,"not"),Wba.forEach(t),Ggt=r(Ice,` load the model weights. It only affects the
model\u2019s configuration. Use `),mle=n(Ice,"A",{href:!0});var Uba=s(mle);Ogt=r(Uba,"from_pretrained()"),Uba.forEach(t),Vgt=r(Ice," to load the model weights."),Ice.forEach(t),Xgt=i(kx),T(S7.$$.fragment,kx),kx.forEach(t),zgt=i(Vi),et=n(Vi,"DIV",{class:!0});var Xi=s(et);T(BP.$$.fragment,Xi),Qgt=i(Xi),eke=n(Xi,"P",{});var Hba=s(eke);Wgt=r(Hba,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Hba.forEach(t),Ugt=i(Xi),Hn=n(Xi,"P",{});var Sx=s(Hn);Hgt=r(Sx,"The model class to instantiate is selected based on the "),oke=n(Sx,"CODE",{});var Jba=s(oke);Jgt=r(Jba,"model_type"),Jba.forEach(t),Ygt=r(Sx,` property of the config object (either
passed as an argument or loaded from `),rke=n(Sx,"CODE",{});var Yba=s(rke);Zgt=r(Yba,"pretrained_model_name_or_path"),Yba.forEach(t),Kgt=r(Sx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tke=n(Sx,"CODE",{});var Zba=s(tke);eht=r(Zba,"pretrained_model_name_or_path"),Zba.forEach(t),oht=r(Sx,":"),Sx.forEach(t),rht=i(Xi),ake=n(Xi,"UL",{});var Kba=s(ake);R7=n(Kba,"LI",{});var voo=s(R7);nke=n(voo,"STRONG",{});var eva=s(nke);tht=r(eva,"vision-encoder-decoder"),eva.forEach(t),aht=r(voo," \u2014 "),cle=n(voo,"A",{href:!0});var ova=s(cle);nht=r(ova,"TFVisionEncoderDecoderModel"),ova.forEach(t),sht=r(voo," (Vision Encoder decoder model)"),voo.forEach(t),Kba.forEach(t),lht=i(Xi),T(P7.$$.fragment,Xi),Xi.forEach(t),Vi.forEach(t),uno=i(c),of=n(c,"H2",{class:!0});var Blo=s(of);B7=n(Blo,"A",{id:!0,class:!0,href:!0});var rva=s(B7);ske=n(rva,"SPAN",{});var tva=s(ske);T(IP.$$.fragment,tva),tva.forEach(t),rva.forEach(t),iht=i(Blo),lke=n(Blo,"SPAN",{});var ava=s(lke);dht=r(ava,"TFAutoModelForSpeechSeq2Seq"),ava.forEach(t),Blo.forEach(t),pno=i(c),wr=n(c,"DIV",{class:!0});var zi=s(wr);T(NP.$$.fragment,zi),mht=i(zi),rf=n(zi,"P",{});var Nce=s(rf);cht=r(Nce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),fle=n(Nce,"A",{href:!0});var nva=s(fle);fht=r(nva,"from_pretrained()"),nva.forEach(t),ght=r(Nce," class method or the "),gle=n(Nce,"A",{href:!0});var sva=s(gle);hht=r(sva,"from_config()"),sva.forEach(t),uht=r(Nce,` class
method.`),Nce.forEach(t),pht=i(zi),qP=n(zi,"P",{});var Ilo=s(qP);_ht=r(Ilo,"This class cannot be instantiated directly using "),ike=n(Ilo,"CODE",{});var lva=s(ike);bht=r(lva,"__init__()"),lva.forEach(t),vht=r(Ilo," (throws an error)."),Ilo.forEach(t),Fht=i(zi),fa=n(zi,"DIV",{class:!0});var Rx=s(fa);T(DP.$$.fragment,Rx),Tht=i(Rx),dke=n(Rx,"P",{});var iva=s(dke);Mht=r(iva,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),iva.forEach(t),Eht=i(Rx),tf=n(Rx,"P",{});var qce=s(tf);Cht=r(qce,`Note:
Loading a model from its configuration file does `),mke=n(qce,"STRONG",{});var dva=s(mke);wht=r(dva,"not"),dva.forEach(t),Aht=r(qce,` load the model weights. It only affects the
model\u2019s configuration. Use `),hle=n(qce,"A",{href:!0});var mva=s(hle);Lht=r(mva,"from_pretrained()"),mva.forEach(t),yht=r(qce," to load the model weights."),qce.forEach(t),xht=i(Rx),T(I7.$$.fragment,Rx),Rx.forEach(t),$ht=i(zi),ot=n(zi,"DIV",{class:!0});var Qi=s(ot);T(jP.$$.fragment,Qi),kht=i(Qi),cke=n(Qi,"P",{});var cva=s(cke);Sht=r(cva,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),cva.forEach(t),Rht=i(Qi),Jn=n(Qi,"P",{});var Px=s(Jn);Pht=r(Px,"The model class to instantiate is selected based on the "),fke=n(Px,"CODE",{});var fva=s(fke);Bht=r(fva,"model_type"),fva.forEach(t),Iht=r(Px,` property of the config object (either
passed as an argument or loaded from `),gke=n(Px,"CODE",{});var gva=s(gke);Nht=r(gva,"pretrained_model_name_or_path"),gva.forEach(t),qht=r(Px,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hke=n(Px,"CODE",{});var hva=s(hke);Dht=r(hva,"pretrained_model_name_or_path"),hva.forEach(t),jht=r(Px,":"),Px.forEach(t),Ght=i(Qi),GP=n(Qi,"UL",{});var Nlo=s(GP);N7=n(Nlo,"LI",{});var Foo=s(N7);uke=n(Foo,"STRONG",{});var uva=s(uke);Oht=r(uva,"speech_to_text"),uva.forEach(t),Vht=r(Foo," \u2014 "),ule=n(Foo,"A",{href:!0});var pva=s(ule);Xht=r(pva,"TFSpeech2TextForConditionalGeneration"),pva.forEach(t),zht=r(Foo," (Speech2Text model)"),Foo.forEach(t),Qht=i(Nlo),q7=n(Nlo,"LI",{});var Too=s(q7);pke=n(Too,"STRONG",{});var _va=s(pke);Wht=r(_va,"whisper"),_va.forEach(t),Uht=r(Too," \u2014 "),ple=n(Too,"A",{href:!0});var bva=s(ple);Hht=r(bva,"TFWhisperForConditionalGeneration"),bva.forEach(t),Jht=r(Too," (Whisper model)"),Too.forEach(t),Nlo.forEach(t),Yht=i(Qi),T(D7.$$.fragment,Qi),Qi.forEach(t),zi.forEach(t),_no=i(c),af=n(c,"H2",{class:!0});var qlo=s(af);j7=n(qlo,"A",{id:!0,class:!0,href:!0});var vva=s(j7);_ke=n(vva,"SPAN",{});var Fva=s(_ke);T(OP.$$.fragment,Fva),Fva.forEach(t),vva.forEach(t),Zht=i(qlo),bke=n(qlo,"SPAN",{});var Tva=s(bke);Kht=r(Tva,"FlaxAutoModel"),Tva.forEach(t),qlo.forEach(t),bno=i(c),Ar=n(c,"DIV",{class:!0});var Wi=s(Ar);T(VP.$$.fragment,Wi),eut=i(Wi),nf=n(Wi,"P",{});var Dce=s(nf);out=r(Dce,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),_le=n(Dce,"A",{href:!0});var Mva=s(_le);rut=r(Mva,"from_pretrained()"),Mva.forEach(t),tut=r(Dce," class method or the "),ble=n(Dce,"A",{href:!0});var Eva=s(ble);aut=r(Eva,"from_config()"),Eva.forEach(t),nut=r(Dce,` class
method.`),Dce.forEach(t),sut=i(Wi),XP=n(Wi,"P",{});var Dlo=s(XP);lut=r(Dlo,"This class cannot be instantiated directly using "),vke=n(Dlo,"CODE",{});var Cva=s(vke);iut=r(Cva,"__init__()"),Cva.forEach(t),dut=r(Dlo," (throws an error)."),Dlo.forEach(t),mut=i(Wi),ga=n(Wi,"DIV",{class:!0});var Bx=s(ga);T(zP.$$.fragment,Bx),cut=i(Bx),Fke=n(Bx,"P",{});var wva=s(Fke);fut=r(wva,"Instantiates one of the base model classes of the library from a configuration."),wva.forEach(t),gut=i(Bx),sf=n(Bx,"P",{});var jce=s(sf);hut=r(jce,`Note:
Loading a model from its configuration file does `),Tke=n(jce,"STRONG",{});var Ava=s(Tke);uut=r(Ava,"not"),Ava.forEach(t),put=r(jce,` load the model weights. It only affects the
model\u2019s configuration. Use `),vle=n(jce,"A",{href:!0});var Lva=s(vle);_ut=r(Lva,"from_pretrained()"),Lva.forEach(t),but=r(jce," to load the model weights."),jce.forEach(t),vut=i(Bx),T(G7.$$.fragment,Bx),Bx.forEach(t),Fut=i(Wi),rt=n(Wi,"DIV",{class:!0});var Ui=s(rt);T(QP.$$.fragment,Ui),Tut=i(Ui),Mke=n(Ui,"P",{});var yva=s(Mke);Mut=r(yva,"Instantiate one of the base model classes of the library from a pretrained model."),yva.forEach(t),Eut=i(Ui),Yn=n(Ui,"P",{});var Ix=s(Yn);Cut=r(Ix,"The model class to instantiate is selected based on the "),Eke=n(Ix,"CODE",{});var xva=s(Eke);wut=r(xva,"model_type"),xva.forEach(t),Aut=r(Ix,` property of the config object (either
passed as an argument or loaded from `),Cke=n(Ix,"CODE",{});var $va=s(Cke);Lut=r($va,"pretrained_model_name_or_path"),$va.forEach(t),yut=r(Ix,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wke=n(Ix,"CODE",{});var kva=s(wke);xut=r(kva,"pretrained_model_name_or_path"),kva.forEach(t),$ut=r(Ix,":"),Ix.forEach(t),kut=i(Ui),te=n(Ui,"UL",{});var ne=s(te);O7=n(ne,"LI",{});var Moo=s(O7);Ake=n(Moo,"STRONG",{});var Sva=s(Ake);Sut=r(Sva,"albert"),Sva.forEach(t),Rut=r(Moo," \u2014 "),Fle=n(Moo,"A",{href:!0});var Rva=s(Fle);Put=r(Rva,"FlaxAlbertModel"),Rva.forEach(t),But=r(Moo," (ALBERT model)"),Moo.forEach(t),Iut=i(ne),V7=n(ne,"LI",{});var Eoo=s(V7);Lke=n(Eoo,"STRONG",{});var Pva=s(Lke);Nut=r(Pva,"bart"),Pva.forEach(t),qut=r(Eoo," \u2014 "),Tle=n(Eoo,"A",{href:!0});var Bva=s(Tle);Dut=r(Bva,"FlaxBartModel"),Bva.forEach(t),jut=r(Eoo," (BART model)"),Eoo.forEach(t),Gut=i(ne),X7=n(ne,"LI",{});var Coo=s(X7);yke=n(Coo,"STRONG",{});var Iva=s(yke);Out=r(Iva,"beit"),Iva.forEach(t),Vut=r(Coo," \u2014 "),Mle=n(Coo,"A",{href:!0});var Nva=s(Mle);Xut=r(Nva,"FlaxBeitModel"),Nva.forEach(t),zut=r(Coo," (BEiT model)"),Coo.forEach(t),Qut=i(ne),z7=n(ne,"LI",{});var woo=s(z7);xke=n(woo,"STRONG",{});var qva=s(xke);Wut=r(qva,"bert"),qva.forEach(t),Uut=r(woo," \u2014 "),Ele=n(woo,"A",{href:!0});var Dva=s(Ele);Hut=r(Dva,"FlaxBertModel"),Dva.forEach(t),Jut=r(woo," (BERT model)"),woo.forEach(t),Yut=i(ne),Q7=n(ne,"LI",{});var Aoo=s(Q7);$ke=n(Aoo,"STRONG",{});var jva=s($ke);Zut=r(jva,"big_bird"),jva.forEach(t),Kut=r(Aoo," \u2014 "),Cle=n(Aoo,"A",{href:!0});var Gva=s(Cle);ept=r(Gva,"FlaxBigBirdModel"),Gva.forEach(t),opt=r(Aoo," (BigBird model)"),Aoo.forEach(t),rpt=i(ne),W7=n(ne,"LI",{});var Loo=s(W7);kke=n(Loo,"STRONG",{});var Ova=s(kke);tpt=r(Ova,"blenderbot"),Ova.forEach(t),apt=r(Loo," \u2014 "),wle=n(Loo,"A",{href:!0});var Vva=s(wle);npt=r(Vva,"FlaxBlenderbotModel"),Vva.forEach(t),spt=r(Loo," (Blenderbot model)"),Loo.forEach(t),lpt=i(ne),U7=n(ne,"LI",{});var yoo=s(U7);Ske=n(yoo,"STRONG",{});var Xva=s(Ske);ipt=r(Xva,"blenderbot-small"),Xva.forEach(t),dpt=r(yoo," \u2014 "),Ale=n(yoo,"A",{href:!0});var zva=s(Ale);mpt=r(zva,"FlaxBlenderbotSmallModel"),zva.forEach(t),cpt=r(yoo," (BlenderbotSmall model)"),yoo.forEach(t),fpt=i(ne),H7=n(ne,"LI",{});var xoo=s(H7);Rke=n(xoo,"STRONG",{});var Qva=s(Rke);gpt=r(Qva,"clip"),Qva.forEach(t),hpt=r(xoo," \u2014 "),Lle=n(xoo,"A",{href:!0});var Wva=s(Lle);upt=r(Wva,"FlaxCLIPModel"),Wva.forEach(t),ppt=r(xoo," (CLIP model)"),xoo.forEach(t),_pt=i(ne),J7=n(ne,"LI",{});var $oo=s(J7);Pke=n($oo,"STRONG",{});var Uva=s(Pke);bpt=r(Uva,"distilbert"),Uva.forEach(t),vpt=r($oo," \u2014 "),yle=n($oo,"A",{href:!0});var Hva=s(yle);Fpt=r(Hva,"FlaxDistilBertModel"),Hva.forEach(t),Tpt=r($oo," (DistilBERT model)"),$oo.forEach(t),Mpt=i(ne),Y7=n(ne,"LI",{});var koo=s(Y7);Bke=n(koo,"STRONG",{});var Jva=s(Bke);Ept=r(Jva,"electra"),Jva.forEach(t),Cpt=r(koo," \u2014 "),xle=n(koo,"A",{href:!0});var Yva=s(xle);wpt=r(Yva,"FlaxElectraModel"),Yva.forEach(t),Apt=r(koo," (ELECTRA model)"),koo.forEach(t),Lpt=i(ne),Z7=n(ne,"LI",{});var Soo=s(Z7);Ike=n(Soo,"STRONG",{});var Zva=s(Ike);ypt=r(Zva,"gpt2"),Zva.forEach(t),xpt=r(Soo," \u2014 "),$le=n(Soo,"A",{href:!0});var Kva=s($le);$pt=r(Kva,"FlaxGPT2Model"),Kva.forEach(t),kpt=r(Soo," (OpenAI GPT-2 model)"),Soo.forEach(t),Spt=i(ne),K7=n(ne,"LI",{});var Roo=s(K7);Nke=n(Roo,"STRONG",{});var eFa=s(Nke);Rpt=r(eFa,"gpt_neo"),eFa.forEach(t),Ppt=r(Roo," \u2014 "),kle=n(Roo,"A",{href:!0});var oFa=s(kle);Bpt=r(oFa,"FlaxGPTNeoModel"),oFa.forEach(t),Ipt=r(Roo," (GPT Neo model)"),Roo.forEach(t),Npt=i(ne),e8=n(ne,"LI",{});var Poo=s(e8);qke=n(Poo,"STRONG",{});var rFa=s(qke);qpt=r(rFa,"gptj"),rFa.forEach(t),Dpt=r(Poo," \u2014 "),Sle=n(Poo,"A",{href:!0});var tFa=s(Sle);jpt=r(tFa,"FlaxGPTJModel"),tFa.forEach(t),Gpt=r(Poo," (GPT-J model)"),Poo.forEach(t),Opt=i(ne),o8=n(ne,"LI",{});var Boo=s(o8);Dke=n(Boo,"STRONG",{});var aFa=s(Dke);Vpt=r(aFa,"longt5"),aFa.forEach(t),Xpt=r(Boo," \u2014 "),Rle=n(Boo,"A",{href:!0});var nFa=s(Rle);zpt=r(nFa,"FlaxLongT5Model"),nFa.forEach(t),Qpt=r(Boo," (LongT5 model)"),Boo.forEach(t),Wpt=i(ne),r8=n(ne,"LI",{});var Ioo=s(r8);jke=n(Ioo,"STRONG",{});var sFa=s(jke);Upt=r(sFa,"marian"),sFa.forEach(t),Hpt=r(Ioo," \u2014 "),Ple=n(Ioo,"A",{href:!0});var lFa=s(Ple);Jpt=r(lFa,"FlaxMarianModel"),lFa.forEach(t),Ypt=r(Ioo," (Marian model)"),Ioo.forEach(t),Zpt=i(ne),t8=n(ne,"LI",{});var Noo=s(t8);Gke=n(Noo,"STRONG",{});var iFa=s(Gke);Kpt=r(iFa,"mbart"),iFa.forEach(t),e_t=r(Noo," \u2014 "),Ble=n(Noo,"A",{href:!0});var dFa=s(Ble);o_t=r(dFa,"FlaxMBartModel"),dFa.forEach(t),r_t=r(Noo," (mBART model)"),Noo.forEach(t),t_t=i(ne),a8=n(ne,"LI",{});var qoo=s(a8);Oke=n(qoo,"STRONG",{});var mFa=s(Oke);a_t=r(mFa,"mt5"),mFa.forEach(t),n_t=r(qoo," \u2014 "),Ile=n(qoo,"A",{href:!0});var cFa=s(Ile);s_t=r(cFa,"FlaxMT5Model"),cFa.forEach(t),l_t=r(qoo," (MT5 model)"),qoo.forEach(t),i_t=i(ne),n8=n(ne,"LI",{});var Doo=s(n8);Vke=n(Doo,"STRONG",{});var fFa=s(Vke);d_t=r(fFa,"opt"),fFa.forEach(t),m_t=r(Doo," \u2014 "),Nle=n(Doo,"A",{href:!0});var gFa=s(Nle);c_t=r(gFa,"FlaxOPTModel"),gFa.forEach(t),f_t=r(Doo," (OPT model)"),Doo.forEach(t),g_t=i(ne),s8=n(ne,"LI",{});var joo=s(s8);Xke=n(joo,"STRONG",{});var hFa=s(Xke);h_t=r(hFa,"pegasus"),hFa.forEach(t),u_t=r(joo," \u2014 "),qle=n(joo,"A",{href:!0});var uFa=s(qle);p_t=r(uFa,"FlaxPegasusModel"),uFa.forEach(t),__t=r(joo," (Pegasus model)"),joo.forEach(t),b_t=i(ne),l8=n(ne,"LI",{});var Goo=s(l8);zke=n(Goo,"STRONG",{});var pFa=s(zke);v_t=r(pFa,"roberta"),pFa.forEach(t),F_t=r(Goo," \u2014 "),Dle=n(Goo,"A",{href:!0});var _Fa=s(Dle);T_t=r(_Fa,"FlaxRobertaModel"),_Fa.forEach(t),M_t=r(Goo," (RoBERTa model)"),Goo.forEach(t),E_t=i(ne),i8=n(ne,"LI",{});var Ooo=s(i8);Qke=n(Ooo,"STRONG",{});var bFa=s(Qke);C_t=r(bFa,"roformer"),bFa.forEach(t),w_t=r(Ooo," \u2014 "),jle=n(Ooo,"A",{href:!0});var vFa=s(jle);A_t=r(vFa,"FlaxRoFormerModel"),vFa.forEach(t),L_t=r(Ooo," (RoFormer model)"),Ooo.forEach(t),y_t=i(ne),d8=n(ne,"LI",{});var Voo=s(d8);Wke=n(Voo,"STRONG",{});var FFa=s(Wke);x_t=r(FFa,"t5"),FFa.forEach(t),$_t=r(Voo," \u2014 "),Gle=n(Voo,"A",{href:!0});var TFa=s(Gle);k_t=r(TFa,"FlaxT5Model"),TFa.forEach(t),S_t=r(Voo," (T5 model)"),Voo.forEach(t),R_t=i(ne),m8=n(ne,"LI",{});var Xoo=s(m8);Uke=n(Xoo,"STRONG",{});var MFa=s(Uke);P_t=r(MFa,"vision-text-dual-encoder"),MFa.forEach(t),B_t=r(Xoo," \u2014 "),Ole=n(Xoo,"A",{href:!0});var EFa=s(Ole);I_t=r(EFa,"FlaxVisionTextDualEncoderModel"),EFa.forEach(t),N_t=r(Xoo," (VisionTextDualEncoder model)"),Xoo.forEach(t),q_t=i(ne),c8=n(ne,"LI",{});var zoo=s(c8);Hke=n(zoo,"STRONG",{});var CFa=s(Hke);D_t=r(CFa,"vit"),CFa.forEach(t),j_t=r(zoo," \u2014 "),Vle=n(zoo,"A",{href:!0});var wFa=s(Vle);G_t=r(wFa,"FlaxViTModel"),wFa.forEach(t),O_t=r(zoo," (ViT model)"),zoo.forEach(t),V_t=i(ne),f8=n(ne,"LI",{});var Qoo=s(f8);Jke=n(Qoo,"STRONG",{});var AFa=s(Jke);X_t=r(AFa,"wav2vec2"),AFa.forEach(t),z_t=r(Qoo," \u2014 "),Xle=n(Qoo,"A",{href:!0});var LFa=s(Xle);Q_t=r(LFa,"FlaxWav2Vec2Model"),LFa.forEach(t),W_t=r(Qoo," (Wav2Vec2 model)"),Qoo.forEach(t),U_t=i(ne),g8=n(ne,"LI",{});var Woo=s(g8);Yke=n(Woo,"STRONG",{});var yFa=s(Yke);H_t=r(yFa,"xglm"),yFa.forEach(t),J_t=r(Woo," \u2014 "),zle=n(Woo,"A",{href:!0});var xFa=s(zle);Y_t=r(xFa,"FlaxXGLMModel"),xFa.forEach(t),Z_t=r(Woo," (XGLM model)"),Woo.forEach(t),K_t=i(ne),h8=n(ne,"LI",{});var Uoo=s(h8);Zke=n(Uoo,"STRONG",{});var $Fa=s(Zke);e1t=r($Fa,"xlm-roberta"),$Fa.forEach(t),o1t=r(Uoo," \u2014 "),Qle=n(Uoo,"A",{href:!0});var kFa=s(Qle);r1t=r(kFa,"FlaxXLMRobertaModel"),kFa.forEach(t),t1t=r(Uoo," (XLM-RoBERTa model)"),Uoo.forEach(t),ne.forEach(t),a1t=i(Ui),T(u8.$$.fragment,Ui),Ui.forEach(t),Wi.forEach(t),vno=i(c),lf=n(c,"H2",{class:!0});var jlo=s(lf);p8=n(jlo,"A",{id:!0,class:!0,href:!0});var SFa=s(p8);Kke=n(SFa,"SPAN",{});var RFa=s(Kke);T(WP.$$.fragment,RFa),RFa.forEach(t),SFa.forEach(t),n1t=i(jlo),eSe=n(jlo,"SPAN",{});var PFa=s(eSe);s1t=r(PFa,"FlaxAutoModelForCausalLM"),PFa.forEach(t),jlo.forEach(t),Fno=i(c),Lr=n(c,"DIV",{class:!0});var Hi=s(Lr);T(UP.$$.fragment,Hi),l1t=i(Hi),df=n(Hi,"P",{});var Gce=s(df);i1t=r(Gce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Wle=n(Gce,"A",{href:!0});var BFa=s(Wle);d1t=r(BFa,"from_pretrained()"),BFa.forEach(t),m1t=r(Gce," class method or the "),Ule=n(Gce,"A",{href:!0});var IFa=s(Ule);c1t=r(IFa,"from_config()"),IFa.forEach(t),f1t=r(Gce,` class
method.`),Gce.forEach(t),g1t=i(Hi),HP=n(Hi,"P",{});var Glo=s(HP);h1t=r(Glo,"This class cannot be instantiated directly using "),oSe=n(Glo,"CODE",{});var NFa=s(oSe);u1t=r(NFa,"__init__()"),NFa.forEach(t),p1t=r(Glo," (throws an error)."),Glo.forEach(t),_1t=i(Hi),ha=n(Hi,"DIV",{class:!0});var Nx=s(ha);T(JP.$$.fragment,Nx),b1t=i(Nx),rSe=n(Nx,"P",{});var qFa=s(rSe);v1t=r(qFa,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),qFa.forEach(t),F1t=i(Nx),mf=n(Nx,"P",{});var Oce=s(mf);T1t=r(Oce,`Note:
Loading a model from its configuration file does `),tSe=n(Oce,"STRONG",{});var DFa=s(tSe);M1t=r(DFa,"not"),DFa.forEach(t),E1t=r(Oce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Hle=n(Oce,"A",{href:!0});var jFa=s(Hle);C1t=r(jFa,"from_pretrained()"),jFa.forEach(t),w1t=r(Oce," to load the model weights."),Oce.forEach(t),A1t=i(Nx),T(_8.$$.fragment,Nx),Nx.forEach(t),L1t=i(Hi),tt=n(Hi,"DIV",{class:!0});var Ji=s(tt);T(YP.$$.fragment,Ji),y1t=i(Ji),aSe=n(Ji,"P",{});var GFa=s(aSe);x1t=r(GFa,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),GFa.forEach(t),$1t=i(Ji),Zn=n(Ji,"P",{});var qx=s(Zn);k1t=r(qx,"The model class to instantiate is selected based on the "),nSe=n(qx,"CODE",{});var OFa=s(nSe);S1t=r(OFa,"model_type"),OFa.forEach(t),R1t=r(qx,` property of the config object (either
passed as an argument or loaded from `),sSe=n(qx,"CODE",{});var VFa=s(sSe);P1t=r(VFa,"pretrained_model_name_or_path"),VFa.forEach(t),B1t=r(qx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lSe=n(qx,"CODE",{});var XFa=s(lSe);I1t=r(XFa,"pretrained_model_name_or_path"),XFa.forEach(t),N1t=r(qx,":"),qx.forEach(t),q1t=i(Ji),$e=n(Ji,"UL",{});var De=s($e);b8=n(De,"LI",{});var Hoo=s(b8);iSe=n(Hoo,"STRONG",{});var zFa=s(iSe);D1t=r(zFa,"bart"),zFa.forEach(t),j1t=r(Hoo," \u2014 "),Jle=n(Hoo,"A",{href:!0});var QFa=s(Jle);G1t=r(QFa,"FlaxBartForCausalLM"),QFa.forEach(t),O1t=r(Hoo," (BART model)"),Hoo.forEach(t),V1t=i(De),v8=n(De,"LI",{});var Joo=s(v8);dSe=n(Joo,"STRONG",{});var WFa=s(dSe);X1t=r(WFa,"bert"),WFa.forEach(t),z1t=r(Joo," \u2014 "),Yle=n(Joo,"A",{href:!0});var UFa=s(Yle);Q1t=r(UFa,"FlaxBertForCausalLM"),UFa.forEach(t),W1t=r(Joo," (BERT model)"),Joo.forEach(t),U1t=i(De),F8=n(De,"LI",{});var Yoo=s(F8);mSe=n(Yoo,"STRONG",{});var HFa=s(mSe);H1t=r(HFa,"big_bird"),HFa.forEach(t),J1t=r(Yoo," \u2014 "),Zle=n(Yoo,"A",{href:!0});var JFa=s(Zle);Y1t=r(JFa,"FlaxBigBirdForCausalLM"),JFa.forEach(t),Z1t=r(Yoo," (BigBird model)"),Yoo.forEach(t),K1t=i(De),T8=n(De,"LI",{});var Zoo=s(T8);cSe=n(Zoo,"STRONG",{});var YFa=s(cSe);e2t=r(YFa,"electra"),YFa.forEach(t),o2t=r(Zoo," \u2014 "),Kle=n(Zoo,"A",{href:!0});var ZFa=s(Kle);r2t=r(ZFa,"FlaxElectraForCausalLM"),ZFa.forEach(t),t2t=r(Zoo," (ELECTRA model)"),Zoo.forEach(t),a2t=i(De),M8=n(De,"LI",{});var Koo=s(M8);fSe=n(Koo,"STRONG",{});var KFa=s(fSe);n2t=r(KFa,"gpt2"),KFa.forEach(t),s2t=r(Koo," \u2014 "),eie=n(Koo,"A",{href:!0});var eTa=s(eie);l2t=r(eTa,"FlaxGPT2LMHeadModel"),eTa.forEach(t),i2t=r(Koo," (OpenAI GPT-2 model)"),Koo.forEach(t),d2t=i(De),E8=n(De,"LI",{});var ero=s(E8);gSe=n(ero,"STRONG",{});var oTa=s(gSe);m2t=r(oTa,"gpt_neo"),oTa.forEach(t),c2t=r(ero," \u2014 "),oie=n(ero,"A",{href:!0});var rTa=s(oie);f2t=r(rTa,"FlaxGPTNeoForCausalLM"),rTa.forEach(t),g2t=r(ero," (GPT Neo model)"),ero.forEach(t),h2t=i(De),C8=n(De,"LI",{});var oro=s(C8);hSe=n(oro,"STRONG",{});var tTa=s(hSe);u2t=r(tTa,"gptj"),tTa.forEach(t),p2t=r(oro," \u2014 "),rie=n(oro,"A",{href:!0});var aTa=s(rie);_2t=r(aTa,"FlaxGPTJForCausalLM"),aTa.forEach(t),b2t=r(oro," (GPT-J model)"),oro.forEach(t),v2t=i(De),w8=n(De,"LI",{});var rro=s(w8);uSe=n(rro,"STRONG",{});var nTa=s(uSe);F2t=r(nTa,"opt"),nTa.forEach(t),T2t=r(rro," \u2014 "),tie=n(rro,"A",{href:!0});var sTa=s(tie);M2t=r(sTa,"FlaxOPTForCausalLM"),sTa.forEach(t),E2t=r(rro," (OPT model)"),rro.forEach(t),C2t=i(De),A8=n(De,"LI",{});var tro=s(A8);pSe=n(tro,"STRONG",{});var lTa=s(pSe);w2t=r(lTa,"roberta"),lTa.forEach(t),A2t=r(tro," \u2014 "),aie=n(tro,"A",{href:!0});var iTa=s(aie);L2t=r(iTa,"FlaxRobertaForCausalLM"),iTa.forEach(t),y2t=r(tro," (RoBERTa model)"),tro.forEach(t),x2t=i(De),L8=n(De,"LI",{});var aro=s(L8);_Se=n(aro,"STRONG",{});var dTa=s(_Se);$2t=r(dTa,"xglm"),dTa.forEach(t),k2t=r(aro," \u2014 "),nie=n(aro,"A",{href:!0});var mTa=s(nie);S2t=r(mTa,"FlaxXGLMForCausalLM"),mTa.forEach(t),R2t=r(aro," (XGLM model)"),aro.forEach(t),De.forEach(t),P2t=i(Ji),T(y8.$$.fragment,Ji),Ji.forEach(t),Hi.forEach(t),Tno=i(c),cf=n(c,"H2",{class:!0});var Olo=s(cf);x8=n(Olo,"A",{id:!0,class:!0,href:!0});var cTa=s(x8);bSe=n(cTa,"SPAN",{});var fTa=s(bSe);T(ZP.$$.fragment,fTa),fTa.forEach(t),cTa.forEach(t),B2t=i(Olo),vSe=n(Olo,"SPAN",{});var gTa=s(vSe);I2t=r(gTa,"FlaxAutoModelForPreTraining"),gTa.forEach(t),Olo.forEach(t),Mno=i(c),yr=n(c,"DIV",{class:!0});var Yi=s(yr);T(KP.$$.fragment,Yi),N2t=i(Yi),ff=n(Yi,"P",{});var Vce=s(ff);q2t=r(Vce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),sie=n(Vce,"A",{href:!0});var hTa=s(sie);D2t=r(hTa,"from_pretrained()"),hTa.forEach(t),j2t=r(Vce," class method or the "),lie=n(Vce,"A",{href:!0});var uTa=s(lie);G2t=r(uTa,"from_config()"),uTa.forEach(t),O2t=r(Vce,` class
method.`),Vce.forEach(t),V2t=i(Yi),eB=n(Yi,"P",{});var Vlo=s(eB);X2t=r(Vlo,"This class cannot be instantiated directly using "),FSe=n(Vlo,"CODE",{});var pTa=s(FSe);z2t=r(pTa,"__init__()"),pTa.forEach(t),Q2t=r(Vlo," (throws an error)."),Vlo.forEach(t),W2t=i(Yi),ua=n(Yi,"DIV",{class:!0});var Dx=s(ua);T(oB.$$.fragment,Dx),U2t=i(Dx),TSe=n(Dx,"P",{});var _Ta=s(TSe);H2t=r(_Ta,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),_Ta.forEach(t),J2t=i(Dx),gf=n(Dx,"P",{});var Xce=s(gf);Y2t=r(Xce,`Note:
Loading a model from its configuration file does `),MSe=n(Xce,"STRONG",{});var bTa=s(MSe);Z2t=r(bTa,"not"),bTa.forEach(t),K2t=r(Xce,` load the model weights. It only affects the
model\u2019s configuration. Use `),iie=n(Xce,"A",{href:!0});var vTa=s(iie);ebt=r(vTa,"from_pretrained()"),vTa.forEach(t),obt=r(Xce," to load the model weights."),Xce.forEach(t),rbt=i(Dx),T($8.$$.fragment,Dx),Dx.forEach(t),tbt=i(Yi),at=n(Yi,"DIV",{class:!0});var Zi=s(at);T(rB.$$.fragment,Zi),abt=i(Zi),ESe=n(Zi,"P",{});var FTa=s(ESe);nbt=r(FTa,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),FTa.forEach(t),sbt=i(Zi),Kn=n(Zi,"P",{});var jx=s(Kn);lbt=r(jx,"The model class to instantiate is selected based on the "),CSe=n(jx,"CODE",{});var TTa=s(CSe);ibt=r(TTa,"model_type"),TTa.forEach(t),dbt=r(jx,` property of the config object (either
passed as an argument or loaded from `),wSe=n(jx,"CODE",{});var MTa=s(wSe);mbt=r(MTa,"pretrained_model_name_or_path"),MTa.forEach(t),cbt=r(jx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ASe=n(jx,"CODE",{});var ETa=s(ASe);fbt=r(ETa,"pretrained_model_name_or_path"),ETa.forEach(t),gbt=r(jx,":"),jx.forEach(t),hbt=i(Zi),Ee=n(Zi,"UL",{});var we=s(Ee);k8=n(we,"LI",{});var nro=s(k8);LSe=n(nro,"STRONG",{});var CTa=s(LSe);ubt=r(CTa,"albert"),CTa.forEach(t),pbt=r(nro," \u2014 "),die=n(nro,"A",{href:!0});var wTa=s(die);_bt=r(wTa,"FlaxAlbertForPreTraining"),wTa.forEach(t),bbt=r(nro," (ALBERT model)"),nro.forEach(t),vbt=i(we),S8=n(we,"LI",{});var sro=s(S8);ySe=n(sro,"STRONG",{});var ATa=s(ySe);Fbt=r(ATa,"bart"),ATa.forEach(t),Tbt=r(sro," \u2014 "),mie=n(sro,"A",{href:!0});var LTa=s(mie);Mbt=r(LTa,"FlaxBartForConditionalGeneration"),LTa.forEach(t),Ebt=r(sro," (BART model)"),sro.forEach(t),Cbt=i(we),R8=n(we,"LI",{});var lro=s(R8);xSe=n(lro,"STRONG",{});var yTa=s(xSe);wbt=r(yTa,"bert"),yTa.forEach(t),Abt=r(lro," \u2014 "),cie=n(lro,"A",{href:!0});var xTa=s(cie);Lbt=r(xTa,"FlaxBertForPreTraining"),xTa.forEach(t),ybt=r(lro," (BERT model)"),lro.forEach(t),xbt=i(we),P8=n(we,"LI",{});var iro=s(P8);$Se=n(iro,"STRONG",{});var $Ta=s($Se);$bt=r($Ta,"big_bird"),$Ta.forEach(t),kbt=r(iro," \u2014 "),fie=n(iro,"A",{href:!0});var kTa=s(fie);Sbt=r(kTa,"FlaxBigBirdForPreTraining"),kTa.forEach(t),Rbt=r(iro," (BigBird model)"),iro.forEach(t),Pbt=i(we),B8=n(we,"LI",{});var dro=s(B8);kSe=n(dro,"STRONG",{});var STa=s(kSe);Bbt=r(STa,"electra"),STa.forEach(t),Ibt=r(dro," \u2014 "),gie=n(dro,"A",{href:!0});var RTa=s(gie);Nbt=r(RTa,"FlaxElectraForPreTraining"),RTa.forEach(t),qbt=r(dro," (ELECTRA model)"),dro.forEach(t),Dbt=i(we),I8=n(we,"LI",{});var mro=s(I8);SSe=n(mro,"STRONG",{});var PTa=s(SSe);jbt=r(PTa,"longt5"),PTa.forEach(t),Gbt=r(mro," \u2014 "),hie=n(mro,"A",{href:!0});var BTa=s(hie);Obt=r(BTa,"FlaxLongT5ForConditionalGeneration"),BTa.forEach(t),Vbt=r(mro," (LongT5 model)"),mro.forEach(t),Xbt=i(we),N8=n(we,"LI",{});var cro=s(N8);RSe=n(cro,"STRONG",{});var ITa=s(RSe);zbt=r(ITa,"mbart"),ITa.forEach(t),Qbt=r(cro," \u2014 "),uie=n(cro,"A",{href:!0});var NTa=s(uie);Wbt=r(NTa,"FlaxMBartForConditionalGeneration"),NTa.forEach(t),Ubt=r(cro," (mBART model)"),cro.forEach(t),Hbt=i(we),q8=n(we,"LI",{});var fro=s(q8);PSe=n(fro,"STRONG",{});var qTa=s(PSe);Jbt=r(qTa,"mt5"),qTa.forEach(t),Ybt=r(fro," \u2014 "),pie=n(fro,"A",{href:!0});var DTa=s(pie);Zbt=r(DTa,"FlaxMT5ForConditionalGeneration"),DTa.forEach(t),Kbt=r(fro," (MT5 model)"),fro.forEach(t),evt=i(we),D8=n(we,"LI",{});var gro=s(D8);BSe=n(gro,"STRONG",{});var jTa=s(BSe);ovt=r(jTa,"roberta"),jTa.forEach(t),rvt=r(gro," \u2014 "),_ie=n(gro,"A",{href:!0});var GTa=s(_ie);tvt=r(GTa,"FlaxRobertaForMaskedLM"),GTa.forEach(t),avt=r(gro," (RoBERTa model)"),gro.forEach(t),nvt=i(we),j8=n(we,"LI",{});var hro=s(j8);ISe=n(hro,"STRONG",{});var OTa=s(ISe);svt=r(OTa,"roformer"),OTa.forEach(t),lvt=r(hro," \u2014 "),bie=n(hro,"A",{href:!0});var VTa=s(bie);ivt=r(VTa,"FlaxRoFormerForMaskedLM"),VTa.forEach(t),dvt=r(hro," (RoFormer model)"),hro.forEach(t),mvt=i(we),G8=n(we,"LI",{});var uro=s(G8);NSe=n(uro,"STRONG",{});var XTa=s(NSe);cvt=r(XTa,"t5"),XTa.forEach(t),fvt=r(uro," \u2014 "),vie=n(uro,"A",{href:!0});var zTa=s(vie);gvt=r(zTa,"FlaxT5ForConditionalGeneration"),zTa.forEach(t),hvt=r(uro," (T5 model)"),uro.forEach(t),uvt=i(we),O8=n(we,"LI",{});var pro=s(O8);qSe=n(pro,"STRONG",{});var QTa=s(qSe);pvt=r(QTa,"wav2vec2"),QTa.forEach(t),_vt=r(pro," \u2014 "),Fie=n(pro,"A",{href:!0});var WTa=s(Fie);bvt=r(WTa,"FlaxWav2Vec2ForPreTraining"),WTa.forEach(t),vvt=r(pro," (Wav2Vec2 model)"),pro.forEach(t),Fvt=i(we),V8=n(we,"LI",{});var _ro=s(V8);DSe=n(_ro,"STRONG",{});var UTa=s(DSe);Tvt=r(UTa,"xlm-roberta"),UTa.forEach(t),Mvt=r(_ro," \u2014 "),Tie=n(_ro,"A",{href:!0});var HTa=s(Tie);Evt=r(HTa,"FlaxXLMRobertaForMaskedLM"),HTa.forEach(t),Cvt=r(_ro," (XLM-RoBERTa model)"),_ro.forEach(t),we.forEach(t),wvt=i(Zi),T(X8.$$.fragment,Zi),Zi.forEach(t),Yi.forEach(t),Eno=i(c),hf=n(c,"H2",{class:!0});var Xlo=s(hf);z8=n(Xlo,"A",{id:!0,class:!0,href:!0});var JTa=s(z8);jSe=n(JTa,"SPAN",{});var YTa=s(jSe);T(tB.$$.fragment,YTa),YTa.forEach(t),JTa.forEach(t),Avt=i(Xlo),GSe=n(Xlo,"SPAN",{});var ZTa=s(GSe);Lvt=r(ZTa,"FlaxAutoModelForMaskedLM"),ZTa.forEach(t),Xlo.forEach(t),Cno=i(c),xr=n(c,"DIV",{class:!0});var Ki=s(xr);T(aB.$$.fragment,Ki),yvt=i(Ki),uf=n(Ki,"P",{});var zce=s(uf);xvt=r(zce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Mie=n(zce,"A",{href:!0});var KTa=s(Mie);$vt=r(KTa,"from_pretrained()"),KTa.forEach(t),kvt=r(zce," class method or the "),Eie=n(zce,"A",{href:!0});var eMa=s(Eie);Svt=r(eMa,"from_config()"),eMa.forEach(t),Rvt=r(zce,` class
method.`),zce.forEach(t),Pvt=i(Ki),nB=n(Ki,"P",{});var zlo=s(nB);Bvt=r(zlo,"This class cannot be instantiated directly using "),OSe=n(zlo,"CODE",{});var oMa=s(OSe);Ivt=r(oMa,"__init__()"),oMa.forEach(t),Nvt=r(zlo," (throws an error)."),zlo.forEach(t),qvt=i(Ki),pa=n(Ki,"DIV",{class:!0});var Gx=s(pa);T(sB.$$.fragment,Gx),Dvt=i(Gx),VSe=n(Gx,"P",{});var rMa=s(VSe);jvt=r(rMa,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),rMa.forEach(t),Gvt=i(Gx),pf=n(Gx,"P",{});var Qce=s(pf);Ovt=r(Qce,`Note:
Loading a model from its configuration file does `),XSe=n(Qce,"STRONG",{});var tMa=s(XSe);Vvt=r(tMa,"not"),tMa.forEach(t),Xvt=r(Qce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Cie=n(Qce,"A",{href:!0});var aMa=s(Cie);zvt=r(aMa,"from_pretrained()"),aMa.forEach(t),Qvt=r(Qce," to load the model weights."),Qce.forEach(t),Wvt=i(Gx),T(Q8.$$.fragment,Gx),Gx.forEach(t),Uvt=i(Ki),nt=n(Ki,"DIV",{class:!0});var ed=s(nt);T(lB.$$.fragment,ed),Hvt=i(ed),zSe=n(ed,"P",{});var nMa=s(zSe);Jvt=r(nMa,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),nMa.forEach(t),Yvt=i(ed),es=n(ed,"P",{});var Ox=s(es);Zvt=r(Ox,"The model class to instantiate is selected based on the "),QSe=n(Ox,"CODE",{});var sMa=s(QSe);Kvt=r(sMa,"model_type"),sMa.forEach(t),eFt=r(Ox,` property of the config object (either
passed as an argument or loaded from `),WSe=n(Ox,"CODE",{});var lMa=s(WSe);oFt=r(lMa,"pretrained_model_name_or_path"),lMa.forEach(t),rFt=r(Ox,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),USe=n(Ox,"CODE",{});var iMa=s(USe);tFt=r(iMa,"pretrained_model_name_or_path"),iMa.forEach(t),aFt=r(Ox,":"),Ox.forEach(t),nFt=i(ed),ke=n(ed,"UL",{});var je=s(ke);W8=n(je,"LI",{});var bro=s(W8);HSe=n(bro,"STRONG",{});var dMa=s(HSe);sFt=r(dMa,"albert"),dMa.forEach(t),lFt=r(bro," \u2014 "),wie=n(bro,"A",{href:!0});var mMa=s(wie);iFt=r(mMa,"FlaxAlbertForMaskedLM"),mMa.forEach(t),dFt=r(bro," (ALBERT model)"),bro.forEach(t),mFt=i(je),U8=n(je,"LI",{});var vro=s(U8);JSe=n(vro,"STRONG",{});var cMa=s(JSe);cFt=r(cMa,"bart"),cMa.forEach(t),fFt=r(vro," \u2014 "),Aie=n(vro,"A",{href:!0});var fMa=s(Aie);gFt=r(fMa,"FlaxBartForConditionalGeneration"),fMa.forEach(t),hFt=r(vro," (BART model)"),vro.forEach(t),uFt=i(je),H8=n(je,"LI",{});var Fro=s(H8);YSe=n(Fro,"STRONG",{});var gMa=s(YSe);pFt=r(gMa,"bert"),gMa.forEach(t),_Ft=r(Fro," \u2014 "),Lie=n(Fro,"A",{href:!0});var hMa=s(Lie);bFt=r(hMa,"FlaxBertForMaskedLM"),hMa.forEach(t),vFt=r(Fro," (BERT model)"),Fro.forEach(t),FFt=i(je),J8=n(je,"LI",{});var Tro=s(J8);ZSe=n(Tro,"STRONG",{});var uMa=s(ZSe);TFt=r(uMa,"big_bird"),uMa.forEach(t),MFt=r(Tro," \u2014 "),yie=n(Tro,"A",{href:!0});var pMa=s(yie);EFt=r(pMa,"FlaxBigBirdForMaskedLM"),pMa.forEach(t),CFt=r(Tro," (BigBird model)"),Tro.forEach(t),wFt=i(je),Y8=n(je,"LI",{});var Mro=s(Y8);KSe=n(Mro,"STRONG",{});var _Ma=s(KSe);AFt=r(_Ma,"distilbert"),_Ma.forEach(t),LFt=r(Mro," \u2014 "),xie=n(Mro,"A",{href:!0});var bMa=s(xie);yFt=r(bMa,"FlaxDistilBertForMaskedLM"),bMa.forEach(t),xFt=r(Mro," (DistilBERT model)"),Mro.forEach(t),$Ft=i(je),Z8=n(je,"LI",{});var Ero=s(Z8);eRe=n(Ero,"STRONG",{});var vMa=s(eRe);kFt=r(vMa,"electra"),vMa.forEach(t),SFt=r(Ero," \u2014 "),$ie=n(Ero,"A",{href:!0});var FMa=s($ie);RFt=r(FMa,"FlaxElectraForMaskedLM"),FMa.forEach(t),PFt=r(Ero," (ELECTRA model)"),Ero.forEach(t),BFt=i(je),K8=n(je,"LI",{});var Cro=s(K8);oRe=n(Cro,"STRONG",{});var TMa=s(oRe);IFt=r(TMa,"mbart"),TMa.forEach(t),NFt=r(Cro," \u2014 "),kie=n(Cro,"A",{href:!0});var MMa=s(kie);qFt=r(MMa,"FlaxMBartForConditionalGeneration"),MMa.forEach(t),DFt=r(Cro," (mBART model)"),Cro.forEach(t),jFt=i(je),eL=n(je,"LI",{});var wro=s(eL);rRe=n(wro,"STRONG",{});var EMa=s(rRe);GFt=r(EMa,"roberta"),EMa.forEach(t),OFt=r(wro," \u2014 "),Sie=n(wro,"A",{href:!0});var CMa=s(Sie);VFt=r(CMa,"FlaxRobertaForMaskedLM"),CMa.forEach(t),XFt=r(wro," (RoBERTa model)"),wro.forEach(t),zFt=i(je),oL=n(je,"LI",{});var Aro=s(oL);tRe=n(Aro,"STRONG",{});var wMa=s(tRe);QFt=r(wMa,"roformer"),wMa.forEach(t),WFt=r(Aro," \u2014 "),Rie=n(Aro,"A",{href:!0});var AMa=s(Rie);UFt=r(AMa,"FlaxRoFormerForMaskedLM"),AMa.forEach(t),HFt=r(Aro," (RoFormer model)"),Aro.forEach(t),JFt=i(je),rL=n(je,"LI",{});var Lro=s(rL);aRe=n(Lro,"STRONG",{});var LMa=s(aRe);YFt=r(LMa,"xlm-roberta"),LMa.forEach(t),ZFt=r(Lro," \u2014 "),Pie=n(Lro,"A",{href:!0});var yMa=s(Pie);KFt=r(yMa,"FlaxXLMRobertaForMaskedLM"),yMa.forEach(t),eTt=r(Lro," (XLM-RoBERTa model)"),Lro.forEach(t),je.forEach(t),oTt=i(ed),T(tL.$$.fragment,ed),ed.forEach(t),Ki.forEach(t),wno=i(c),_f=n(c,"H2",{class:!0});var Qlo=s(_f);aL=n(Qlo,"A",{id:!0,class:!0,href:!0});var xMa=s(aL);nRe=n(xMa,"SPAN",{});var $Ma=s(nRe);T(iB.$$.fragment,$Ma),$Ma.forEach(t),xMa.forEach(t),rTt=i(Qlo),sRe=n(Qlo,"SPAN",{});var kMa=s(sRe);tTt=r(kMa,"FlaxAutoModelForSeq2SeqLM"),kMa.forEach(t),Qlo.forEach(t),Ano=i(c),$r=n(c,"DIV",{class:!0});var od=s($r);T(dB.$$.fragment,od),aTt=i(od),bf=n(od,"P",{});var Wce=s(bf);nTt=r(Wce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Bie=n(Wce,"A",{href:!0});var SMa=s(Bie);sTt=r(SMa,"from_pretrained()"),SMa.forEach(t),lTt=r(Wce," class method or the "),Iie=n(Wce,"A",{href:!0});var RMa=s(Iie);iTt=r(RMa,"from_config()"),RMa.forEach(t),dTt=r(Wce,` class
method.`),Wce.forEach(t),mTt=i(od),mB=n(od,"P",{});var Wlo=s(mB);cTt=r(Wlo,"This class cannot be instantiated directly using "),lRe=n(Wlo,"CODE",{});var PMa=s(lRe);fTt=r(PMa,"__init__()"),PMa.forEach(t),gTt=r(Wlo," (throws an error)."),Wlo.forEach(t),hTt=i(od),_a=n(od,"DIV",{class:!0});var Vx=s(_a);T(cB.$$.fragment,Vx),uTt=i(Vx),iRe=n(Vx,"P",{});var BMa=s(iRe);pTt=r(BMa,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),BMa.forEach(t),_Tt=i(Vx),vf=n(Vx,"P",{});var Uce=s(vf);bTt=r(Uce,`Note:
Loading a model from its configuration file does `),dRe=n(Uce,"STRONG",{});var IMa=s(dRe);vTt=r(IMa,"not"),IMa.forEach(t),FTt=r(Uce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Nie=n(Uce,"A",{href:!0});var NMa=s(Nie);TTt=r(NMa,"from_pretrained()"),NMa.forEach(t),MTt=r(Uce," to load the model weights."),Uce.forEach(t),ETt=i(Vx),T(nL.$$.fragment,Vx),Vx.forEach(t),CTt=i(od),st=n(od,"DIV",{class:!0});var rd=s(st);T(fB.$$.fragment,rd),wTt=i(rd),mRe=n(rd,"P",{});var qMa=s(mRe);ATt=r(qMa,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),qMa.forEach(t),LTt=i(rd),os=n(rd,"P",{});var Xx=s(os);yTt=r(Xx,"The model class to instantiate is selected based on the "),cRe=n(Xx,"CODE",{});var DMa=s(cRe);xTt=r(DMa,"model_type"),DMa.forEach(t),$Tt=r(Xx,` property of the config object (either
passed as an argument or loaded from `),fRe=n(Xx,"CODE",{});var jMa=s(fRe);kTt=r(jMa,"pretrained_model_name_or_path"),jMa.forEach(t),STt=r(Xx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gRe=n(Xx,"CODE",{});var GMa=s(gRe);RTt=r(GMa,"pretrained_model_name_or_path"),GMa.forEach(t),PTt=r(Xx,":"),Xx.forEach(t),BTt=i(rd),Se=n(rd,"UL",{});var Ge=s(Se);sL=n(Ge,"LI",{});var yro=s(sL);hRe=n(yro,"STRONG",{});var OMa=s(hRe);ITt=r(OMa,"bart"),OMa.forEach(t),NTt=r(yro," \u2014 "),qie=n(yro,"A",{href:!0});var VMa=s(qie);qTt=r(VMa,"FlaxBartForConditionalGeneration"),VMa.forEach(t),DTt=r(yro," (BART model)"),yro.forEach(t),jTt=i(Ge),lL=n(Ge,"LI",{});var xro=s(lL);uRe=n(xro,"STRONG",{});var XMa=s(uRe);GTt=r(XMa,"blenderbot"),XMa.forEach(t),OTt=r(xro," \u2014 "),Die=n(xro,"A",{href:!0});var zMa=s(Die);VTt=r(zMa,"FlaxBlenderbotForConditionalGeneration"),zMa.forEach(t),XTt=r(xro," (Blenderbot model)"),xro.forEach(t),zTt=i(Ge),iL=n(Ge,"LI",{});var $ro=s(iL);pRe=n($ro,"STRONG",{});var QMa=s(pRe);QTt=r(QMa,"blenderbot-small"),QMa.forEach(t),WTt=r($ro," \u2014 "),jie=n($ro,"A",{href:!0});var WMa=s(jie);UTt=r(WMa,"FlaxBlenderbotSmallForConditionalGeneration"),WMa.forEach(t),HTt=r($ro," (BlenderbotSmall model)"),$ro.forEach(t),JTt=i(Ge),dL=n(Ge,"LI",{});var kro=s(dL);_Re=n(kro,"STRONG",{});var UMa=s(_Re);YTt=r(UMa,"encoder-decoder"),UMa.forEach(t),ZTt=r(kro," \u2014 "),Gie=n(kro,"A",{href:!0});var HMa=s(Gie);KTt=r(HMa,"FlaxEncoderDecoderModel"),HMa.forEach(t),eMt=r(kro," (Encoder decoder model)"),kro.forEach(t),oMt=i(Ge),mL=n(Ge,"LI",{});var Sro=s(mL);bRe=n(Sro,"STRONG",{});var JMa=s(bRe);rMt=r(JMa,"longt5"),JMa.forEach(t),tMt=r(Sro," \u2014 "),Oie=n(Sro,"A",{href:!0});var YMa=s(Oie);aMt=r(YMa,"FlaxLongT5ForConditionalGeneration"),YMa.forEach(t),nMt=r(Sro," (LongT5 model)"),Sro.forEach(t),sMt=i(Ge),cL=n(Ge,"LI",{});var Rro=s(cL);vRe=n(Rro,"STRONG",{});var ZMa=s(vRe);lMt=r(ZMa,"marian"),ZMa.forEach(t),iMt=r(Rro," \u2014 "),Vie=n(Rro,"A",{href:!0});var KMa=s(Vie);dMt=r(KMa,"FlaxMarianMTModel"),KMa.forEach(t),mMt=r(Rro," (Marian model)"),Rro.forEach(t),cMt=i(Ge),fL=n(Ge,"LI",{});var Pro=s(fL);FRe=n(Pro,"STRONG",{});var eEa=s(FRe);fMt=r(eEa,"mbart"),eEa.forEach(t),gMt=r(Pro," \u2014 "),Xie=n(Pro,"A",{href:!0});var oEa=s(Xie);hMt=r(oEa,"FlaxMBartForConditionalGeneration"),oEa.forEach(t),uMt=r(Pro," (mBART model)"),Pro.forEach(t),pMt=i(Ge),gL=n(Ge,"LI",{});var Bro=s(gL);TRe=n(Bro,"STRONG",{});var rEa=s(TRe);_Mt=r(rEa,"mt5"),rEa.forEach(t),bMt=r(Bro," \u2014 "),zie=n(Bro,"A",{href:!0});var tEa=s(zie);vMt=r(tEa,"FlaxMT5ForConditionalGeneration"),tEa.forEach(t),FMt=r(Bro," (MT5 model)"),Bro.forEach(t),TMt=i(Ge),hL=n(Ge,"LI",{});var Iro=s(hL);MRe=n(Iro,"STRONG",{});var aEa=s(MRe);MMt=r(aEa,"pegasus"),aEa.forEach(t),EMt=r(Iro," \u2014 "),Qie=n(Iro,"A",{href:!0});var nEa=s(Qie);CMt=r(nEa,"FlaxPegasusForConditionalGeneration"),nEa.forEach(t),wMt=r(Iro," (Pegasus model)"),Iro.forEach(t),AMt=i(Ge),uL=n(Ge,"LI",{});var Nro=s(uL);ERe=n(Nro,"STRONG",{});var sEa=s(ERe);LMt=r(sEa,"t5"),sEa.forEach(t),yMt=r(Nro," \u2014 "),Wie=n(Nro,"A",{href:!0});var lEa=s(Wie);xMt=r(lEa,"FlaxT5ForConditionalGeneration"),lEa.forEach(t),$Mt=r(Nro," (T5 model)"),Nro.forEach(t),Ge.forEach(t),kMt=i(rd),T(pL.$$.fragment,rd),rd.forEach(t),od.forEach(t),Lno=i(c),Ff=n(c,"H2",{class:!0});var Ulo=s(Ff);_L=n(Ulo,"A",{id:!0,class:!0,href:!0});var iEa=s(_L);CRe=n(iEa,"SPAN",{});var dEa=s(CRe);T(gB.$$.fragment,dEa),dEa.forEach(t),iEa.forEach(t),SMt=i(Ulo),wRe=n(Ulo,"SPAN",{});var mEa=s(wRe);RMt=r(mEa,"FlaxAutoModelForSequenceClassification"),mEa.forEach(t),Ulo.forEach(t),yno=i(c),kr=n(c,"DIV",{class:!0});var td=s(kr);T(hB.$$.fragment,td),PMt=i(td),Tf=n(td,"P",{});var Hce=s(Tf);BMt=r(Hce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Uie=n(Hce,"A",{href:!0});var cEa=s(Uie);IMt=r(cEa,"from_pretrained()"),cEa.forEach(t),NMt=r(Hce," class method or the "),Hie=n(Hce,"A",{href:!0});var fEa=s(Hie);qMt=r(fEa,"from_config()"),fEa.forEach(t),DMt=r(Hce,` class
method.`),Hce.forEach(t),jMt=i(td),uB=n(td,"P",{});var Hlo=s(uB);GMt=r(Hlo,"This class cannot be instantiated directly using "),ARe=n(Hlo,"CODE",{});var gEa=s(ARe);OMt=r(gEa,"__init__()"),gEa.forEach(t),VMt=r(Hlo," (throws an error)."),Hlo.forEach(t),XMt=i(td),ba=n(td,"DIV",{class:!0});var zx=s(ba);T(pB.$$.fragment,zx),zMt=i(zx),LRe=n(zx,"P",{});var hEa=s(LRe);QMt=r(hEa,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),hEa.forEach(t),WMt=i(zx),Mf=n(zx,"P",{});var Jce=s(Mf);UMt=r(Jce,`Note:
Loading a model from its configuration file does `),yRe=n(Jce,"STRONG",{});var uEa=s(yRe);HMt=r(uEa,"not"),uEa.forEach(t),JMt=r(Jce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Jie=n(Jce,"A",{href:!0});var pEa=s(Jie);YMt=r(pEa,"from_pretrained()"),pEa.forEach(t),ZMt=r(Jce," to load the model weights."),Jce.forEach(t),KMt=i(zx),T(bL.$$.fragment,zx),zx.forEach(t),eEt=i(td),lt=n(td,"DIV",{class:!0});var ad=s(lt);T(_B.$$.fragment,ad),oEt=i(ad),xRe=n(ad,"P",{});var _Ea=s(xRe);rEt=r(_Ea,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),_Ea.forEach(t),tEt=i(ad),rs=n(ad,"P",{});var Qx=s(rs);aEt=r(Qx,"The model class to instantiate is selected based on the "),$Re=n(Qx,"CODE",{});var bEa=s($Re);nEt=r(bEa,"model_type"),bEa.forEach(t),sEt=r(Qx,` property of the config object (either
passed as an argument or loaded from `),kRe=n(Qx,"CODE",{});var vEa=s(kRe);lEt=r(vEa,"pretrained_model_name_or_path"),vEa.forEach(t),iEt=r(Qx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),SRe=n(Qx,"CODE",{});var FEa=s(SRe);dEt=r(FEa,"pretrained_model_name_or_path"),FEa.forEach(t),mEt=r(Qx,":"),Qx.forEach(t),cEt=i(ad),Re=n(ad,"UL",{});var Oe=s(Re);vL=n(Oe,"LI",{});var qro=s(vL);RRe=n(qro,"STRONG",{});var TEa=s(RRe);fEt=r(TEa,"albert"),TEa.forEach(t),gEt=r(qro," \u2014 "),Yie=n(qro,"A",{href:!0});var MEa=s(Yie);hEt=r(MEa,"FlaxAlbertForSequenceClassification"),MEa.forEach(t),uEt=r(qro," (ALBERT model)"),qro.forEach(t),pEt=i(Oe),FL=n(Oe,"LI",{});var Dro=s(FL);PRe=n(Dro,"STRONG",{});var EEa=s(PRe);_Et=r(EEa,"bart"),EEa.forEach(t),bEt=r(Dro," \u2014 "),Zie=n(Dro,"A",{href:!0});var CEa=s(Zie);vEt=r(CEa,"FlaxBartForSequenceClassification"),CEa.forEach(t),FEt=r(Dro," (BART model)"),Dro.forEach(t),TEt=i(Oe),TL=n(Oe,"LI",{});var jro=s(TL);BRe=n(jro,"STRONG",{});var wEa=s(BRe);MEt=r(wEa,"bert"),wEa.forEach(t),EEt=r(jro," \u2014 "),Kie=n(jro,"A",{href:!0});var AEa=s(Kie);CEt=r(AEa,"FlaxBertForSequenceClassification"),AEa.forEach(t),wEt=r(jro," (BERT model)"),jro.forEach(t),AEt=i(Oe),ML=n(Oe,"LI",{});var Gro=s(ML);IRe=n(Gro,"STRONG",{});var LEa=s(IRe);LEt=r(LEa,"big_bird"),LEa.forEach(t),yEt=r(Gro," \u2014 "),ede=n(Gro,"A",{href:!0});var yEa=s(ede);xEt=r(yEa,"FlaxBigBirdForSequenceClassification"),yEa.forEach(t),$Et=r(Gro," (BigBird model)"),Gro.forEach(t),kEt=i(Oe),EL=n(Oe,"LI",{});var Oro=s(EL);NRe=n(Oro,"STRONG",{});var xEa=s(NRe);SEt=r(xEa,"distilbert"),xEa.forEach(t),REt=r(Oro," \u2014 "),ode=n(Oro,"A",{href:!0});var $Ea=s(ode);PEt=r($Ea,"FlaxDistilBertForSequenceClassification"),$Ea.forEach(t),BEt=r(Oro," (DistilBERT model)"),Oro.forEach(t),IEt=i(Oe),CL=n(Oe,"LI",{});var Vro=s(CL);qRe=n(Vro,"STRONG",{});var kEa=s(qRe);NEt=r(kEa,"electra"),kEa.forEach(t),qEt=r(Vro," \u2014 "),rde=n(Vro,"A",{href:!0});var SEa=s(rde);DEt=r(SEa,"FlaxElectraForSequenceClassification"),SEa.forEach(t),jEt=r(Vro," (ELECTRA model)"),Vro.forEach(t),GEt=i(Oe),wL=n(Oe,"LI",{});var Xro=s(wL);DRe=n(Xro,"STRONG",{});var REa=s(DRe);OEt=r(REa,"mbart"),REa.forEach(t),VEt=r(Xro," \u2014 "),tde=n(Xro,"A",{href:!0});var PEa=s(tde);XEt=r(PEa,"FlaxMBartForSequenceClassification"),PEa.forEach(t),zEt=r(Xro," (mBART model)"),Xro.forEach(t),QEt=i(Oe),AL=n(Oe,"LI",{});var zro=s(AL);jRe=n(zro,"STRONG",{});var BEa=s(jRe);WEt=r(BEa,"roberta"),BEa.forEach(t),UEt=r(zro," \u2014 "),ade=n(zro,"A",{href:!0});var IEa=s(ade);HEt=r(IEa,"FlaxRobertaForSequenceClassification"),IEa.forEach(t),JEt=r(zro," (RoBERTa model)"),zro.forEach(t),YEt=i(Oe),LL=n(Oe,"LI",{});var Qro=s(LL);GRe=n(Qro,"STRONG",{});var NEa=s(GRe);ZEt=r(NEa,"roformer"),NEa.forEach(t),KEt=r(Qro," \u2014 "),nde=n(Qro,"A",{href:!0});var qEa=s(nde);e4t=r(qEa,"FlaxRoFormerForSequenceClassification"),qEa.forEach(t),o4t=r(Qro," (RoFormer model)"),Qro.forEach(t),r4t=i(Oe),yL=n(Oe,"LI",{});var Wro=s(yL);ORe=n(Wro,"STRONG",{});var DEa=s(ORe);t4t=r(DEa,"xlm-roberta"),DEa.forEach(t),a4t=r(Wro," \u2014 "),sde=n(Wro,"A",{href:!0});var jEa=s(sde);n4t=r(jEa,"FlaxXLMRobertaForSequenceClassification"),jEa.forEach(t),s4t=r(Wro," (XLM-RoBERTa model)"),Wro.forEach(t),Oe.forEach(t),l4t=i(ad),T(xL.$$.fragment,ad),ad.forEach(t),td.forEach(t),xno=i(c),Ef=n(c,"H2",{class:!0});var Jlo=s(Ef);$L=n(Jlo,"A",{id:!0,class:!0,href:!0});var GEa=s($L);VRe=n(GEa,"SPAN",{});var OEa=s(VRe);T(bB.$$.fragment,OEa),OEa.forEach(t),GEa.forEach(t),i4t=i(Jlo),XRe=n(Jlo,"SPAN",{});var VEa=s(XRe);d4t=r(VEa,"FlaxAutoModelForQuestionAnswering"),VEa.forEach(t),Jlo.forEach(t),$no=i(c),Sr=n(c,"DIV",{class:!0});var nd=s(Sr);T(vB.$$.fragment,nd),m4t=i(nd),Cf=n(nd,"P",{});var Yce=s(Cf);c4t=r(Yce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),lde=n(Yce,"A",{href:!0});var XEa=s(lde);f4t=r(XEa,"from_pretrained()"),XEa.forEach(t),g4t=r(Yce," class method or the "),ide=n(Yce,"A",{href:!0});var zEa=s(ide);h4t=r(zEa,"from_config()"),zEa.forEach(t),u4t=r(Yce,` class
method.`),Yce.forEach(t),p4t=i(nd),FB=n(nd,"P",{});var Ylo=s(FB);_4t=r(Ylo,"This class cannot be instantiated directly using "),zRe=n(Ylo,"CODE",{});var QEa=s(zRe);b4t=r(QEa,"__init__()"),QEa.forEach(t),v4t=r(Ylo," (throws an error)."),Ylo.forEach(t),F4t=i(nd),va=n(nd,"DIV",{class:!0});var Wx=s(va);T(TB.$$.fragment,Wx),T4t=i(Wx),QRe=n(Wx,"P",{});var WEa=s(QRe);M4t=r(WEa,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),WEa.forEach(t),E4t=i(Wx),wf=n(Wx,"P",{});var Zce=s(wf);C4t=r(Zce,`Note:
Loading a model from its configuration file does `),WRe=n(Zce,"STRONG",{});var UEa=s(WRe);w4t=r(UEa,"not"),UEa.forEach(t),A4t=r(Zce,` load the model weights. It only affects the
model\u2019s configuration. Use `),dde=n(Zce,"A",{href:!0});var HEa=s(dde);L4t=r(HEa,"from_pretrained()"),HEa.forEach(t),y4t=r(Zce," to load the model weights."),Zce.forEach(t),x4t=i(Wx),T(kL.$$.fragment,Wx),Wx.forEach(t),$4t=i(nd),it=n(nd,"DIV",{class:!0});var sd=s(it);T(MB.$$.fragment,sd),k4t=i(sd),URe=n(sd,"P",{});var JEa=s(URe);S4t=r(JEa,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),JEa.forEach(t),R4t=i(sd),ts=n(sd,"P",{});var Ux=s(ts);P4t=r(Ux,"The model class to instantiate is selected based on the "),HRe=n(Ux,"CODE",{});var YEa=s(HRe);B4t=r(YEa,"model_type"),YEa.forEach(t),I4t=r(Ux,` property of the config object (either
passed as an argument or loaded from `),JRe=n(Ux,"CODE",{});var ZEa=s(JRe);N4t=r(ZEa,"pretrained_model_name_or_path"),ZEa.forEach(t),q4t=r(Ux,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),YRe=n(Ux,"CODE",{});var KEa=s(YRe);D4t=r(KEa,"pretrained_model_name_or_path"),KEa.forEach(t),j4t=r(Ux,":"),Ux.forEach(t),G4t=i(sd),Pe=n(sd,"UL",{});var Ve=s(Pe);SL=n(Ve,"LI",{});var Uro=s(SL);ZRe=n(Uro,"STRONG",{});var e4a=s(ZRe);O4t=r(e4a,"albert"),e4a.forEach(t),V4t=r(Uro," \u2014 "),mde=n(Uro,"A",{href:!0});var o4a=s(mde);X4t=r(o4a,"FlaxAlbertForQuestionAnswering"),o4a.forEach(t),z4t=r(Uro," (ALBERT model)"),Uro.forEach(t),Q4t=i(Ve),RL=n(Ve,"LI",{});var Hro=s(RL);KRe=n(Hro,"STRONG",{});var r4a=s(KRe);W4t=r(r4a,"bart"),r4a.forEach(t),U4t=r(Hro," \u2014 "),cde=n(Hro,"A",{href:!0});var t4a=s(cde);H4t=r(t4a,"FlaxBartForQuestionAnswering"),t4a.forEach(t),J4t=r(Hro," (BART model)"),Hro.forEach(t),Y4t=i(Ve),PL=n(Ve,"LI",{});var Jro=s(PL);ePe=n(Jro,"STRONG",{});var a4a=s(ePe);Z4t=r(a4a,"bert"),a4a.forEach(t),K4t=r(Jro," \u2014 "),fde=n(Jro,"A",{href:!0});var n4a=s(fde);eCt=r(n4a,"FlaxBertForQuestionAnswering"),n4a.forEach(t),oCt=r(Jro," (BERT model)"),Jro.forEach(t),rCt=i(Ve),BL=n(Ve,"LI",{});var Yro=s(BL);oPe=n(Yro,"STRONG",{});var s4a=s(oPe);tCt=r(s4a,"big_bird"),s4a.forEach(t),aCt=r(Yro," \u2014 "),gde=n(Yro,"A",{href:!0});var l4a=s(gde);nCt=r(l4a,"FlaxBigBirdForQuestionAnswering"),l4a.forEach(t),sCt=r(Yro," (BigBird model)"),Yro.forEach(t),lCt=i(Ve),IL=n(Ve,"LI",{});var Zro=s(IL);rPe=n(Zro,"STRONG",{});var i4a=s(rPe);iCt=r(i4a,"distilbert"),i4a.forEach(t),dCt=r(Zro," \u2014 "),hde=n(Zro,"A",{href:!0});var d4a=s(hde);mCt=r(d4a,"FlaxDistilBertForQuestionAnswering"),d4a.forEach(t),cCt=r(Zro," (DistilBERT model)"),Zro.forEach(t),fCt=i(Ve),NL=n(Ve,"LI",{});var Kro=s(NL);tPe=n(Kro,"STRONG",{});var m4a=s(tPe);gCt=r(m4a,"electra"),m4a.forEach(t),hCt=r(Kro," \u2014 "),ude=n(Kro,"A",{href:!0});var c4a=s(ude);uCt=r(c4a,"FlaxElectraForQuestionAnswering"),c4a.forEach(t),pCt=r(Kro," (ELECTRA model)"),Kro.forEach(t),_Ct=i(Ve),qL=n(Ve,"LI",{});var eto=s(qL);aPe=n(eto,"STRONG",{});var f4a=s(aPe);bCt=r(f4a,"mbart"),f4a.forEach(t),vCt=r(eto," \u2014 "),pde=n(eto,"A",{href:!0});var g4a=s(pde);FCt=r(g4a,"FlaxMBartForQuestionAnswering"),g4a.forEach(t),TCt=r(eto," (mBART model)"),eto.forEach(t),MCt=i(Ve),DL=n(Ve,"LI",{});var oto=s(DL);nPe=n(oto,"STRONG",{});var h4a=s(nPe);ECt=r(h4a,"roberta"),h4a.forEach(t),CCt=r(oto," \u2014 "),_de=n(oto,"A",{href:!0});var u4a=s(_de);wCt=r(u4a,"FlaxRobertaForQuestionAnswering"),u4a.forEach(t),ACt=r(oto," (RoBERTa model)"),oto.forEach(t),LCt=i(Ve),jL=n(Ve,"LI",{});var rto=s(jL);sPe=n(rto,"STRONG",{});var p4a=s(sPe);yCt=r(p4a,"roformer"),p4a.forEach(t),xCt=r(rto," \u2014 "),bde=n(rto,"A",{href:!0});var _4a=s(bde);$Ct=r(_4a,"FlaxRoFormerForQuestionAnswering"),_4a.forEach(t),kCt=r(rto," (RoFormer model)"),rto.forEach(t),SCt=i(Ve),GL=n(Ve,"LI",{});var tto=s(GL);lPe=n(tto,"STRONG",{});var b4a=s(lPe);RCt=r(b4a,"xlm-roberta"),b4a.forEach(t),PCt=r(tto," \u2014 "),vde=n(tto,"A",{href:!0});var v4a=s(vde);BCt=r(v4a,"FlaxXLMRobertaForQuestionAnswering"),v4a.forEach(t),ICt=r(tto," (XLM-RoBERTa model)"),tto.forEach(t),Ve.forEach(t),NCt=i(sd),T(OL.$$.fragment,sd),sd.forEach(t),nd.forEach(t),kno=i(c),Af=n(c,"H2",{class:!0});var Zlo=s(Af);VL=n(Zlo,"A",{id:!0,class:!0,href:!0});var F4a=s(VL);iPe=n(F4a,"SPAN",{});var T4a=s(iPe);T(EB.$$.fragment,T4a),T4a.forEach(t),F4a.forEach(t),qCt=i(Zlo),dPe=n(Zlo,"SPAN",{});var M4a=s(dPe);DCt=r(M4a,"FlaxAutoModelForTokenClassification"),M4a.forEach(t),Zlo.forEach(t),Sno=i(c),Rr=n(c,"DIV",{class:!0});var ld=s(Rr);T(CB.$$.fragment,ld),jCt=i(ld),Lf=n(ld,"P",{});var Kce=s(Lf);GCt=r(Kce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Fde=n(Kce,"A",{href:!0});var E4a=s(Fde);OCt=r(E4a,"from_pretrained()"),E4a.forEach(t),VCt=r(Kce," class method or the "),Tde=n(Kce,"A",{href:!0});var C4a=s(Tde);XCt=r(C4a,"from_config()"),C4a.forEach(t),zCt=r(Kce,` class
method.`),Kce.forEach(t),QCt=i(ld),wB=n(ld,"P",{});var Klo=s(wB);WCt=r(Klo,"This class cannot be instantiated directly using "),mPe=n(Klo,"CODE",{});var w4a=s(mPe);UCt=r(w4a,"__init__()"),w4a.forEach(t),HCt=r(Klo," (throws an error)."),Klo.forEach(t),JCt=i(ld),Fa=n(ld,"DIV",{class:!0});var Hx=s(Fa);T(AB.$$.fragment,Hx),YCt=i(Hx),cPe=n(Hx,"P",{});var A4a=s(cPe);ZCt=r(A4a,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),A4a.forEach(t),KCt=i(Hx),yf=n(Hx,"P",{});var efe=s(yf);e3t=r(efe,`Note:
Loading a model from its configuration file does `),fPe=n(efe,"STRONG",{});var L4a=s(fPe);o3t=r(L4a,"not"),L4a.forEach(t),r3t=r(efe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Mde=n(efe,"A",{href:!0});var y4a=s(Mde);t3t=r(y4a,"from_pretrained()"),y4a.forEach(t),a3t=r(efe," to load the model weights."),efe.forEach(t),n3t=i(Hx),T(XL.$$.fragment,Hx),Hx.forEach(t),s3t=i(ld),dt=n(ld,"DIV",{class:!0});var id=s(dt);T(LB.$$.fragment,id),l3t=i(id),gPe=n(id,"P",{});var x4a=s(gPe);i3t=r(x4a,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),x4a.forEach(t),d3t=i(id),as=n(id,"P",{});var Jx=s(as);m3t=r(Jx,"The model class to instantiate is selected based on the "),hPe=n(Jx,"CODE",{});var $4a=s(hPe);c3t=r($4a,"model_type"),$4a.forEach(t),f3t=r(Jx,` property of the config object (either
passed as an argument or loaded from `),uPe=n(Jx,"CODE",{});var k4a=s(uPe);g3t=r(k4a,"pretrained_model_name_or_path"),k4a.forEach(t),h3t=r(Jx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pPe=n(Jx,"CODE",{});var S4a=s(pPe);u3t=r(S4a,"pretrained_model_name_or_path"),S4a.forEach(t),p3t=r(Jx,":"),Jx.forEach(t),_3t=i(id),ze=n(id,"UL",{});var yo=s(ze);zL=n(yo,"LI",{});var ato=s(zL);_Pe=n(ato,"STRONG",{});var R4a=s(_Pe);b3t=r(R4a,"albert"),R4a.forEach(t),v3t=r(ato," \u2014 "),Ede=n(ato,"A",{href:!0});var P4a=s(Ede);F3t=r(P4a,"FlaxAlbertForTokenClassification"),P4a.forEach(t),T3t=r(ato," (ALBERT model)"),ato.forEach(t),M3t=i(yo),QL=n(yo,"LI",{});var nto=s(QL);bPe=n(nto,"STRONG",{});var B4a=s(bPe);E3t=r(B4a,"bert"),B4a.forEach(t),C3t=r(nto," \u2014 "),Cde=n(nto,"A",{href:!0});var I4a=s(Cde);w3t=r(I4a,"FlaxBertForTokenClassification"),I4a.forEach(t),A3t=r(nto," (BERT model)"),nto.forEach(t),L3t=i(yo),WL=n(yo,"LI",{});var sto=s(WL);vPe=n(sto,"STRONG",{});var N4a=s(vPe);y3t=r(N4a,"big_bird"),N4a.forEach(t),x3t=r(sto," \u2014 "),wde=n(sto,"A",{href:!0});var q4a=s(wde);$3t=r(q4a,"FlaxBigBirdForTokenClassification"),q4a.forEach(t),k3t=r(sto," (BigBird model)"),sto.forEach(t),S3t=i(yo),UL=n(yo,"LI",{});var lto=s(UL);FPe=n(lto,"STRONG",{});var D4a=s(FPe);R3t=r(D4a,"distilbert"),D4a.forEach(t),P3t=r(lto," \u2014 "),Ade=n(lto,"A",{href:!0});var j4a=s(Ade);B3t=r(j4a,"FlaxDistilBertForTokenClassification"),j4a.forEach(t),I3t=r(lto," (DistilBERT model)"),lto.forEach(t),N3t=i(yo),HL=n(yo,"LI",{});var ito=s(HL);TPe=n(ito,"STRONG",{});var G4a=s(TPe);q3t=r(G4a,"electra"),G4a.forEach(t),D3t=r(ito," \u2014 "),Lde=n(ito,"A",{href:!0});var O4a=s(Lde);j3t=r(O4a,"FlaxElectraForTokenClassification"),O4a.forEach(t),G3t=r(ito," (ELECTRA model)"),ito.forEach(t),O3t=i(yo),JL=n(yo,"LI",{});var dto=s(JL);MPe=n(dto,"STRONG",{});var V4a=s(MPe);V3t=r(V4a,"roberta"),V4a.forEach(t),X3t=r(dto," \u2014 "),yde=n(dto,"A",{href:!0});var X4a=s(yde);z3t=r(X4a,"FlaxRobertaForTokenClassification"),X4a.forEach(t),Q3t=r(dto," (RoBERTa model)"),dto.forEach(t),W3t=i(yo),YL=n(yo,"LI",{});var mto=s(YL);EPe=n(mto,"STRONG",{});var z4a=s(EPe);U3t=r(z4a,"roformer"),z4a.forEach(t),H3t=r(mto," \u2014 "),xde=n(mto,"A",{href:!0});var Q4a=s(xde);J3t=r(Q4a,"FlaxRoFormerForTokenClassification"),Q4a.forEach(t),Y3t=r(mto," (RoFormer model)"),mto.forEach(t),Z3t=i(yo),ZL=n(yo,"LI",{});var cto=s(ZL);CPe=n(cto,"STRONG",{});var W4a=s(CPe);K3t=r(W4a,"xlm-roberta"),W4a.forEach(t),e5t=r(cto," \u2014 "),$de=n(cto,"A",{href:!0});var U4a=s($de);o5t=r(U4a,"FlaxXLMRobertaForTokenClassification"),U4a.forEach(t),r5t=r(cto," (XLM-RoBERTa model)"),cto.forEach(t),yo.forEach(t),t5t=i(id),T(KL.$$.fragment,id),id.forEach(t),ld.forEach(t),Rno=i(c),xf=n(c,"H2",{class:!0});var eio=s(xf);ey=n(eio,"A",{id:!0,class:!0,href:!0});var H4a=s(ey);wPe=n(H4a,"SPAN",{});var J4a=s(wPe);T(yB.$$.fragment,J4a),J4a.forEach(t),H4a.forEach(t),a5t=i(eio),APe=n(eio,"SPAN",{});var Y4a=s(APe);n5t=r(Y4a,"FlaxAutoModelForMultipleChoice"),Y4a.forEach(t),eio.forEach(t),Pno=i(c),Pr=n(c,"DIV",{class:!0});var dd=s(Pr);T(xB.$$.fragment,dd),s5t=i(dd),$f=n(dd,"P",{});var ofe=s($f);l5t=r(ofe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),kde=n(ofe,"A",{href:!0});var Z4a=s(kde);i5t=r(Z4a,"from_pretrained()"),Z4a.forEach(t),d5t=r(ofe," class method or the "),Sde=n(ofe,"A",{href:!0});var K4a=s(Sde);m5t=r(K4a,"from_config()"),K4a.forEach(t),c5t=r(ofe,` class
method.`),ofe.forEach(t),f5t=i(dd),$B=n(dd,"P",{});var oio=s($B);g5t=r(oio,"This class cannot be instantiated directly using "),LPe=n(oio,"CODE",{});var eCa=s(LPe);h5t=r(eCa,"__init__()"),eCa.forEach(t),u5t=r(oio," (throws an error)."),oio.forEach(t),p5t=i(dd),Ta=n(dd,"DIV",{class:!0});var Yx=s(Ta);T(kB.$$.fragment,Yx),_5t=i(Yx),yPe=n(Yx,"P",{});var oCa=s(yPe);b5t=r(oCa,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),oCa.forEach(t),v5t=i(Yx),kf=n(Yx,"P",{});var rfe=s(kf);F5t=r(rfe,`Note:
Loading a model from its configuration file does `),xPe=n(rfe,"STRONG",{});var rCa=s(xPe);T5t=r(rCa,"not"),rCa.forEach(t),M5t=r(rfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Rde=n(rfe,"A",{href:!0});var tCa=s(Rde);E5t=r(tCa,"from_pretrained()"),tCa.forEach(t),C5t=r(rfe," to load the model weights."),rfe.forEach(t),w5t=i(Yx),T(oy.$$.fragment,Yx),Yx.forEach(t),A5t=i(dd),mt=n(dd,"DIV",{class:!0});var md=s(mt);T(SB.$$.fragment,md),L5t=i(md),$Pe=n(md,"P",{});var aCa=s($Pe);y5t=r(aCa,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),aCa.forEach(t),x5t=i(md),ns=n(md,"P",{});var Zx=s(ns);$5t=r(Zx,"The model class to instantiate is selected based on the "),kPe=n(Zx,"CODE",{});var nCa=s(kPe);k5t=r(nCa,"model_type"),nCa.forEach(t),S5t=r(Zx,` property of the config object (either
passed as an argument or loaded from `),SPe=n(Zx,"CODE",{});var sCa=s(SPe);R5t=r(sCa,"pretrained_model_name_or_path"),sCa.forEach(t),P5t=r(Zx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RPe=n(Zx,"CODE",{});var lCa=s(RPe);B5t=r(lCa,"pretrained_model_name_or_path"),lCa.forEach(t),I5t=r(Zx,":"),Zx.forEach(t),N5t=i(md),Qe=n(md,"UL",{});var xo=s(Qe);ry=n(xo,"LI",{});var fto=s(ry);PPe=n(fto,"STRONG",{});var iCa=s(PPe);q5t=r(iCa,"albert"),iCa.forEach(t),D5t=r(fto," \u2014 "),Pde=n(fto,"A",{href:!0});var dCa=s(Pde);j5t=r(dCa,"FlaxAlbertForMultipleChoice"),dCa.forEach(t),G5t=r(fto," (ALBERT model)"),fto.forEach(t),O5t=i(xo),ty=n(xo,"LI",{});var gto=s(ty);BPe=n(gto,"STRONG",{});var mCa=s(BPe);V5t=r(mCa,"bert"),mCa.forEach(t),X5t=r(gto," \u2014 "),Bde=n(gto,"A",{href:!0});var cCa=s(Bde);z5t=r(cCa,"FlaxBertForMultipleChoice"),cCa.forEach(t),Q5t=r(gto," (BERT model)"),gto.forEach(t),W5t=i(xo),ay=n(xo,"LI",{});var hto=s(ay);IPe=n(hto,"STRONG",{});var fCa=s(IPe);U5t=r(fCa,"big_bird"),fCa.forEach(t),H5t=r(hto," \u2014 "),Ide=n(hto,"A",{href:!0});var gCa=s(Ide);J5t=r(gCa,"FlaxBigBirdForMultipleChoice"),gCa.forEach(t),Y5t=r(hto," (BigBird model)"),hto.forEach(t),Z5t=i(xo),ny=n(xo,"LI",{});var uto=s(ny);NPe=n(uto,"STRONG",{});var hCa=s(NPe);K5t=r(hCa,"distilbert"),hCa.forEach(t),e0t=r(uto," \u2014 "),Nde=n(uto,"A",{href:!0});var uCa=s(Nde);o0t=r(uCa,"FlaxDistilBertForMultipleChoice"),uCa.forEach(t),r0t=r(uto," (DistilBERT model)"),uto.forEach(t),t0t=i(xo),sy=n(xo,"LI",{});var pto=s(sy);qPe=n(pto,"STRONG",{});var pCa=s(qPe);a0t=r(pCa,"electra"),pCa.forEach(t),n0t=r(pto," \u2014 "),qde=n(pto,"A",{href:!0});var _Ca=s(qde);s0t=r(_Ca,"FlaxElectraForMultipleChoice"),_Ca.forEach(t),l0t=r(pto," (ELECTRA model)"),pto.forEach(t),i0t=i(xo),ly=n(xo,"LI",{});var _to=s(ly);DPe=n(_to,"STRONG",{});var bCa=s(DPe);d0t=r(bCa,"roberta"),bCa.forEach(t),m0t=r(_to," \u2014 "),Dde=n(_to,"A",{href:!0});var vCa=s(Dde);c0t=r(vCa,"FlaxRobertaForMultipleChoice"),vCa.forEach(t),f0t=r(_to," (RoBERTa model)"),_to.forEach(t),g0t=i(xo),iy=n(xo,"LI",{});var bto=s(iy);jPe=n(bto,"STRONG",{});var FCa=s(jPe);h0t=r(FCa,"roformer"),FCa.forEach(t),u0t=r(bto," \u2014 "),jde=n(bto,"A",{href:!0});var TCa=s(jde);p0t=r(TCa,"FlaxRoFormerForMultipleChoice"),TCa.forEach(t),_0t=r(bto," (RoFormer model)"),bto.forEach(t),b0t=i(xo),dy=n(xo,"LI",{});var vto=s(dy);GPe=n(vto,"STRONG",{});var MCa=s(GPe);v0t=r(MCa,"xlm-roberta"),MCa.forEach(t),F0t=r(vto," \u2014 "),Gde=n(vto,"A",{href:!0});var ECa=s(Gde);T0t=r(ECa,"FlaxXLMRobertaForMultipleChoice"),ECa.forEach(t),M0t=r(vto," (XLM-RoBERTa model)"),vto.forEach(t),xo.forEach(t),E0t=i(md),T(my.$$.fragment,md),md.forEach(t),dd.forEach(t),Bno=i(c),Sf=n(c,"H2",{class:!0});var rio=s(Sf);cy=n(rio,"A",{id:!0,class:!0,href:!0});var CCa=s(cy);OPe=n(CCa,"SPAN",{});var wCa=s(OPe);T(RB.$$.fragment,wCa),wCa.forEach(t),CCa.forEach(t),C0t=i(rio),VPe=n(rio,"SPAN",{});var ACa=s(VPe);w0t=r(ACa,"FlaxAutoModelForNextSentencePrediction"),ACa.forEach(t),rio.forEach(t),Ino=i(c),Br=n(c,"DIV",{class:!0});var cd=s(Br);T(PB.$$.fragment,cd),A0t=i(cd),Rf=n(cd,"P",{});var tfe=s(Rf);L0t=r(tfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Ode=n(tfe,"A",{href:!0});var LCa=s(Ode);y0t=r(LCa,"from_pretrained()"),LCa.forEach(t),x0t=r(tfe," class method or the "),Vde=n(tfe,"A",{href:!0});var yCa=s(Vde);$0t=r(yCa,"from_config()"),yCa.forEach(t),k0t=r(tfe,` class
method.`),tfe.forEach(t),S0t=i(cd),BB=n(cd,"P",{});var tio=s(BB);R0t=r(tio,"This class cannot be instantiated directly using "),XPe=n(tio,"CODE",{});var xCa=s(XPe);P0t=r(xCa,"__init__()"),xCa.forEach(t),B0t=r(tio," (throws an error)."),tio.forEach(t),I0t=i(cd),Ma=n(cd,"DIV",{class:!0});var Kx=s(Ma);T(IB.$$.fragment,Kx),N0t=i(Kx),zPe=n(Kx,"P",{});var $Ca=s(zPe);q0t=r($Ca,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),$Ca.forEach(t),D0t=i(Kx),Pf=n(Kx,"P",{});var afe=s(Pf);j0t=r(afe,`Note:
Loading a model from its configuration file does `),QPe=n(afe,"STRONG",{});var kCa=s(QPe);G0t=r(kCa,"not"),kCa.forEach(t),O0t=r(afe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Xde=n(afe,"A",{href:!0});var SCa=s(Xde);V0t=r(SCa,"from_pretrained()"),SCa.forEach(t),X0t=r(afe," to load the model weights."),afe.forEach(t),z0t=i(Kx),T(fy.$$.fragment,Kx),Kx.forEach(t),Q0t=i(cd),ct=n(cd,"DIV",{class:!0});var fd=s(ct);T(NB.$$.fragment,fd),W0t=i(fd),WPe=n(fd,"P",{});var RCa=s(WPe);U0t=r(RCa,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),RCa.forEach(t),H0t=i(fd),ss=n(fd,"P",{});var e$=s(ss);J0t=r(e$,"The model class to instantiate is selected based on the "),UPe=n(e$,"CODE",{});var PCa=s(UPe);Y0t=r(PCa,"model_type"),PCa.forEach(t),Z0t=r(e$,` property of the config object (either
passed as an argument or loaded from `),HPe=n(e$,"CODE",{});var BCa=s(HPe);K0t=r(BCa,"pretrained_model_name_or_path"),BCa.forEach(t),ewt=r(e$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JPe=n(e$,"CODE",{});var ICa=s(JPe);owt=r(ICa,"pretrained_model_name_or_path"),ICa.forEach(t),rwt=r(e$,":"),e$.forEach(t),twt=i(fd),YPe=n(fd,"UL",{});var NCa=s(YPe);gy=n(NCa,"LI",{});var Fto=s(gy);ZPe=n(Fto,"STRONG",{});var qCa=s(ZPe);awt=r(qCa,"bert"),qCa.forEach(t),nwt=r(Fto," \u2014 "),zde=n(Fto,"A",{href:!0});var DCa=s(zde);swt=r(DCa,"FlaxBertForNextSentencePrediction"),DCa.forEach(t),lwt=r(Fto," (BERT model)"),Fto.forEach(t),NCa.forEach(t),iwt=i(fd),T(hy.$$.fragment,fd),fd.forEach(t),cd.forEach(t),Nno=i(c),Bf=n(c,"H2",{class:!0});var aio=s(Bf);uy=n(aio,"A",{id:!0,class:!0,href:!0});var jCa=s(uy);KPe=n(jCa,"SPAN",{});var GCa=s(KPe);T(qB.$$.fragment,GCa),GCa.forEach(t),jCa.forEach(t),dwt=i(aio),eBe=n(aio,"SPAN",{});var OCa=s(eBe);mwt=r(OCa,"FlaxAutoModelForImageClassification"),OCa.forEach(t),aio.forEach(t),qno=i(c),Ir=n(c,"DIV",{class:!0});var gd=s(Ir);T(DB.$$.fragment,gd),cwt=i(gd),If=n(gd,"P",{});var nfe=s(If);fwt=r(nfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Qde=n(nfe,"A",{href:!0});var VCa=s(Qde);gwt=r(VCa,"from_pretrained()"),VCa.forEach(t),hwt=r(nfe," class method or the "),Wde=n(nfe,"A",{href:!0});var XCa=s(Wde);uwt=r(XCa,"from_config()"),XCa.forEach(t),pwt=r(nfe,` class
method.`),nfe.forEach(t),_wt=i(gd),jB=n(gd,"P",{});var nio=s(jB);bwt=r(nio,"This class cannot be instantiated directly using "),oBe=n(nio,"CODE",{});var zCa=s(oBe);vwt=r(zCa,"__init__()"),zCa.forEach(t),Fwt=r(nio," (throws an error)."),nio.forEach(t),Twt=i(gd),Ea=n(gd,"DIV",{class:!0});var o$=s(Ea);T(GB.$$.fragment,o$),Mwt=i(o$),rBe=n(o$,"P",{});var QCa=s(rBe);Ewt=r(QCa,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),QCa.forEach(t),Cwt=i(o$),Nf=n(o$,"P",{});var sfe=s(Nf);wwt=r(sfe,`Note:
Loading a model from its configuration file does `),tBe=n(sfe,"STRONG",{});var WCa=s(tBe);Awt=r(WCa,"not"),WCa.forEach(t),Lwt=r(sfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ude=n(sfe,"A",{href:!0});var UCa=s(Ude);ywt=r(UCa,"from_pretrained()"),UCa.forEach(t),xwt=r(sfe," to load the model weights."),sfe.forEach(t),$wt=i(o$),T(py.$$.fragment,o$),o$.forEach(t),kwt=i(gd),ft=n(gd,"DIV",{class:!0});var hd=s(ft);T(OB.$$.fragment,hd),Swt=i(hd),aBe=n(hd,"P",{});var HCa=s(aBe);Rwt=r(HCa,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),HCa.forEach(t),Pwt=i(hd),ls=n(hd,"P",{});var r$=s(ls);Bwt=r(r$,"The model class to instantiate is selected based on the "),nBe=n(r$,"CODE",{});var JCa=s(nBe);Iwt=r(JCa,"model_type"),JCa.forEach(t),Nwt=r(r$,` property of the config object (either
passed as an argument or loaded from `),sBe=n(r$,"CODE",{});var YCa=s(sBe);qwt=r(YCa,"pretrained_model_name_or_path"),YCa.forEach(t),Dwt=r(r$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lBe=n(r$,"CODE",{});var ZCa=s(lBe);jwt=r(ZCa,"pretrained_model_name_or_path"),ZCa.forEach(t),Gwt=r(r$,":"),r$.forEach(t),Owt=i(hd),VB=n(hd,"UL",{});var sio=s(VB);_y=n(sio,"LI",{});var Tto=s(_y);iBe=n(Tto,"STRONG",{});var KCa=s(iBe);Vwt=r(KCa,"beit"),KCa.forEach(t),Xwt=r(Tto," \u2014 "),Hde=n(Tto,"A",{href:!0});var e3a=s(Hde);zwt=r(e3a,"FlaxBeitForImageClassification"),e3a.forEach(t),Qwt=r(Tto," (BEiT model)"),Tto.forEach(t),Wwt=i(sio),by=n(sio,"LI",{});var Mto=s(by);dBe=n(Mto,"STRONG",{});var o3a=s(dBe);Uwt=r(o3a,"vit"),o3a.forEach(t),Hwt=r(Mto," \u2014 "),Jde=n(Mto,"A",{href:!0});var r3a=s(Jde);Jwt=r(r3a,"FlaxViTForImageClassification"),r3a.forEach(t),Ywt=r(Mto," (ViT model)"),Mto.forEach(t),sio.forEach(t),Zwt=i(hd),T(vy.$$.fragment,hd),hd.forEach(t),gd.forEach(t),Dno=i(c),qf=n(c,"H2",{class:!0});var lio=s(qf);Fy=n(lio,"A",{id:!0,class:!0,href:!0});var t3a=s(Fy);mBe=n(t3a,"SPAN",{});var a3a=s(mBe);T(XB.$$.fragment,a3a),a3a.forEach(t),t3a.forEach(t),Kwt=i(lio),cBe=n(lio,"SPAN",{});var n3a=s(cBe);eAt=r(n3a,"FlaxAutoModelForVision2Seq"),n3a.forEach(t),lio.forEach(t),jno=i(c),Nr=n(c,"DIV",{class:!0});var ud=s(Nr);T(zB.$$.fragment,ud),oAt=i(ud),Df=n(ud,"P",{});var lfe=s(Df);rAt=r(lfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Yde=n(lfe,"A",{href:!0});var s3a=s(Yde);tAt=r(s3a,"from_pretrained()"),s3a.forEach(t),aAt=r(lfe," class method or the "),Zde=n(lfe,"A",{href:!0});var l3a=s(Zde);nAt=r(l3a,"from_config()"),l3a.forEach(t),sAt=r(lfe,` class
method.`),lfe.forEach(t),lAt=i(ud),QB=n(ud,"P",{});var iio=s(QB);iAt=r(iio,"This class cannot be instantiated directly using "),fBe=n(iio,"CODE",{});var i3a=s(fBe);dAt=r(i3a,"__init__()"),i3a.forEach(t),mAt=r(iio," (throws an error)."),iio.forEach(t),cAt=i(ud),Ca=n(ud,"DIV",{class:!0});var t$=s(Ca);T(WB.$$.fragment,t$),fAt=i(t$),gBe=n(t$,"P",{});var d3a=s(gBe);gAt=r(d3a,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),d3a.forEach(t),hAt=i(t$),jf=n(t$,"P",{});var ife=s(jf);uAt=r(ife,`Note:
Loading a model from its configuration file does `),hBe=n(ife,"STRONG",{});var m3a=s(hBe);pAt=r(m3a,"not"),m3a.forEach(t),_At=r(ife,` load the model weights. It only affects the
model\u2019s configuration. Use `),Kde=n(ife,"A",{href:!0});var c3a=s(Kde);bAt=r(c3a,"from_pretrained()"),c3a.forEach(t),vAt=r(ife," to load the model weights."),ife.forEach(t),FAt=i(t$),T(Ty.$$.fragment,t$),t$.forEach(t),TAt=i(ud),gt=n(ud,"DIV",{class:!0});var pd=s(gt);T(UB.$$.fragment,pd),MAt=i(pd),uBe=n(pd,"P",{});var f3a=s(uBe);EAt=r(f3a,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),f3a.forEach(t),CAt=i(pd),is=n(pd,"P",{});var a$=s(is);wAt=r(a$,"The model class to instantiate is selected based on the "),pBe=n(a$,"CODE",{});var g3a=s(pBe);AAt=r(g3a,"model_type"),g3a.forEach(t),LAt=r(a$,` property of the config object (either
passed as an argument or loaded from `),_Be=n(a$,"CODE",{});var h3a=s(_Be);yAt=r(h3a,"pretrained_model_name_or_path"),h3a.forEach(t),xAt=r(a$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bBe=n(a$,"CODE",{});var u3a=s(bBe);$At=r(u3a,"pretrained_model_name_or_path"),u3a.forEach(t),kAt=r(a$,":"),a$.forEach(t),SAt=i(pd),vBe=n(pd,"UL",{});var p3a=s(vBe);My=n(p3a,"LI",{});var Eto=s(My);FBe=n(Eto,"STRONG",{});var _3a=s(FBe);RAt=r(_3a,"vision-encoder-decoder"),_3a.forEach(t),PAt=r(Eto," \u2014 "),eme=n(Eto,"A",{href:!0});var b3a=s(eme);BAt=r(b3a,"FlaxVisionEncoderDecoderModel"),b3a.forEach(t),IAt=r(Eto," (Vision Encoder decoder model)"),Eto.forEach(t),p3a.forEach(t),NAt=i(pd),T(Ey.$$.fragment,pd),pd.forEach(t),ud.forEach(t),this.h()},h(){m(g,"name","hf:doc:metadata"),m(g,"content",JSON.stringify(I0a)),m(f,"id","auto-classes"),m(f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(f,"href","#auto-classes"),m(u,"class","relative group"),m(ms,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig"),m(fs,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoModel"),m(gs,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer"),m(Ed,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),m(Uf,"id","extending-the-auto-classes"),m(Uf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Uf,"href","#extending-the-auto-classes"),m(Cd,"class","relative group"),m(Jf,"id","transformers.AutoConfig"),m(Jf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Jf,"href","#transformers.AutoConfig"),m(wd,"class","relative group"),m(LN,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),m(yN,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig"),m(xN,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartConfig"),m($N,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig"),m(kN,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertConfig"),m(SN,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig"),m(RN,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig"),m(PN,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),m(BN,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig"),m(IN,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),m(NN,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig"),m(qN,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig"),m(DN,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig"),m(jN,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig"),m(GN,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig"),m(ON,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig"),m(VN,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig"),m(XN,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig"),m(zN,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig"),m(QN,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig"),m(WN,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),m(UN,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig"),m(HN,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),m(JN,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig"),m(YN,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config"),m(ZN,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),m(KN,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig"),m(eq,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig"),m(oq,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig"),m(rq,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig"),m(tq,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig"),m(aq,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig"),m(nq,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig"),m(sq,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig"),m(lq,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),m(iq,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig"),m(dq,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig"),m(mq,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig"),m(cq,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig"),m(fq,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig"),m(gq,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig"),m(hq,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig"),m(uq,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig"),m(pq,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config"),m(_q,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),m(bq,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),m(vq,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig"),m(Fq,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig"),m(Tq,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig"),m(Mq,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig"),m(Eq,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig"),m(Cq,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig"),m(wq,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig"),m(Aq,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),m(Lq,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),m(yq,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDConfig"),m(xq,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig"),m($q,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig"),m(kq,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig"),m(Sq,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config"),m(Rq,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig"),m(Pq,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig"),m(Bq,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config"),m(Iq,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig"),m(Nq,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig"),m(qq,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig"),m(Dq,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig"),m(jq,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig"),m(Gq,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),m(Oq,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig"),m(Vq,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig"),m(Xq,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig"),m(zq,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config"),m(Qq,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig"),m(Wq,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig"),m(Uq,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig"),m(Hq,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),m(Jq,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig"),m(Yq,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig"),m(Zq,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig"),m(Kq,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig"),m(eD,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig"),m(oD,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig"),m(rD,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig"),m(tD,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig"),m(aD,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig"),m(nD,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagConfig"),m(sD,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmConfig"),m(lD,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig"),m(iD,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig"),m(dD,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig"),m(mD,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig"),m(cD,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig"),m(fD,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig"),m(gD,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig"),m(hD,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig"),m(uD,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig"),m(pD,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig"),m(_D,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),m(bD,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),m(vD,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),m(FD,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig"),m(TD,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),m(MD,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig"),m(ED,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config"),m(CD,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Config"),m(wD,"href","/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerConfig"),m(AD,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig"),m(LD,"href","/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig"),m(yD,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),m(xD,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),m($D,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig"),m(kD,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig"),m(SD,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),m(RD,"href","/docs/transformers/main/en/model_doc/van#transformers.VanConfig"),m(PD,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig"),m(BD,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig"),m(ID,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),m(ND,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),m(qD,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig"),m(DD,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig"),m(jD,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig"),m(GD,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig"),m(OD,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),m(VD,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),m(XD,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig"),m(zD,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig"),m(QD,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig"),m(WD,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig"),m(UD,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig"),m(HD,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),m(JD,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),m(YD,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),m(ZD,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig"),m(KD,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig"),m(ej,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig"),m(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(wu,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Au,"id","transformers.AutoTokenizer"),m(Au,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Au,"href","#transformers.AutoTokenizer"),m(Ld,"class","relative group"),m(oj,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),m(rj,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),m(tj,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),m(aj,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizer"),m(nj,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizerFast"),m(sj,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizer"),m(lj,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizerFast"),m(ij,"href","/docs/transformers/main/en/model_doc/bartpho#transformers.BartphoTokenizer"),m(dj,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(mj,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(cj,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),m(fj,"href","/docs/transformers/main/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),m(gj,"href","/docs/transformers/main/en/model_doc/bertweet#transformers.BertweetTokenizer"),m(hj,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizer"),m(uj,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),m(pj,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),m(_j,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),m(bj,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),m(vj,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),m(Fj,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),m(Tj,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomTokenizerFast"),m(Mj,"href","/docs/transformers/main/en/model_doc/byt5#transformers.ByT5Tokenizer"),m(Ej,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizer"),m(Cj,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizerFast"),m(wj,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineTokenizer"),m(Aj,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),m(Lj,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),m(yj,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizer"),m(xj,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizerFast"),m($j,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizer"),m(kj,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),m(Sj,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizer"),m(Rj,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizerFast"),m(Pj,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLTokenizer"),m(Bj,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),m(Ij,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),m(Nj,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizer"),m(qj,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizerFast"),m(Dj,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),m(jj,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),m(Gj,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizer"),m(Oj,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),m(Vj,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),m(Xj,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),m(zj,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizer"),m(Qj,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizerFast"),m(Wj,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(Uj,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(Hj,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmTokenizer"),m(Jj,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertTokenizer"),m(Yj,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizer"),m(Zj,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizerFast"),m(Kj,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTTokenizer"),m(eG,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizer"),m(oG,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizerFast"),m(rG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),m(tG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),m(aG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),m(nG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),m(sG,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),m(lG,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseTokenizer"),m(iG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),m(dG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),m(mG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),m(cG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),m(fG,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizer"),m(gG,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizerFast"),m(hG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),m(uG,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),m(pG,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),m(_G,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),m(bG,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),m(vG,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),m(FG,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),m(TG,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),m(MG,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),m(EG,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),m(CG,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),m(wG,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizer"),m(AG,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizerFast"),m(LG,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),m(yG,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),m(xG,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizer"),m($G,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizerFast"),m(kG,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),m(SG,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),m(RG,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeTokenizer"),m(PG,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizer"),m(BG,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),m(IG,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),m(NG,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianTokenizer"),m(qG,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizer"),m(DG,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizerFast"),m(jG,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50Tokenizer"),m(GG,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50TokenizerFast"),m(OG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(VG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(XG,"href","/docs/transformers/main/en/model_doc/mluke#transformers.MLukeTokenizer"),m(zG,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),m(QG,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),m(WG,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizer"),m(UG,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),m(HG,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),m(JG,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),m(YG,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizer"),m(ZG,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizerFast"),m(KG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(eO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(oO,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizer"),m(rO,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizerFast"),m(tO,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),m(aO,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),m(nO,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),m(sO,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),m(lO,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),m(iO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),m(dO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),m(mO,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),m(cO,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),m(fO,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverTokenizer"),m(gO,"href","/docs/transformers/main/en/model_doc/phobert#transformers.PhobertTokenizer"),m(hO,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartTokenizer"),m(uO,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),m(pO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(_O,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(bO,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagTokenizer"),m(vO,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizer"),m(FO,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizerFast"),m(TO,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizer"),m(MO,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizerFast"),m(EO,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizer"),m(CO,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizerFast"),m(wO,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizer"),m(AO,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),m(LO,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),m(yO,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),m(xO,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizer"),m($O,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),m(kO,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),m(SO,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),m(RO,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizer"),m(PO,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizerFast"),m(BO,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),m(IO,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),m(NO,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),m(qO,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),m(DO,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasTokenizer"),m(jO,"href","/docs/transformers/main/en/model_doc/tapex#transformers.TapexTokenizer"),m(GO,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),m(OO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(VO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(XO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(zO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(QO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),m(WO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),m(UO,"href","/docs/transformers/main/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),m(HO,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperTokenizer"),m(JO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),m(YO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),m(ZO,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizer"),m(KO,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizerFast"),m(eV,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMTokenizer"),m(oV,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),m(rV,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),m(tV,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),m(aV,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),m(nV,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),m(sV,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizer"),m(lV,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),m(iV,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),m(dV,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),m(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(mp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(cp,"id","transformers.AutoFeatureExtractor"),m(cp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(cp,"href","#transformers.AutoFeatureExtractor"),m(yd,"class","relative group"),m(mV,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),m(cV,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitFeatureExtractor"),m(fV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPFeatureExtractor"),m(gV,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrFeatureExtractor"),m(hV,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),m(uV,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),m(pV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),m(_V,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitFeatureExtractor"),m(bV,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrFeatureExtractor"),m(vV,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTFeatureExtractor"),m(FV,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrFeatureExtractor"),m(TV,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutFeatureExtractor"),m(MV,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTFeatureExtractor"),m(EV,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaFeatureExtractor"),m(CV,"href","/docs/transformers/main/en/model_doc/glpn#transformers.models.glpn.image_processing_glpn.GLPNImageProcessor"),m(wV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPFeatureExtractor"),m(AV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),m(LV,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor"),m(yV,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),m(xV,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),m($V,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitFeatureExtractor"),m(kV,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),m(SV,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),m(RV,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTFeatureExtractor"),m(PV,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTFeatureExtractor"),m(BV,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),m(IV,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),m(NV,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),m(qV,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),m(DV,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),m(jV,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),m(GV,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),m(OV,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),m(VV,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrFeatureExtractor"),m(XV,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),m(zV,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEFeatureExtractor"),m(QV,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltFeatureExtractor"),m(WV,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),m(UV,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),m(HV,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTFeatureExtractor"),m(JV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),m(YV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),m(ZV,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperFeatureExtractor"),m(KV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPFeatureExtractor"),m(eX,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosFeatureExtractor"),m(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(a_,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(n_,"id","transformers.AutoProcessor"),m(n_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(n_,"href","#transformers.AutoProcessor"),m(xd,"class","relative group"),m(oX,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),m(rX,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),m(tX,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutProcessor"),m(aX,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaProcessor"),m(nX,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),m(sX,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),m(lX,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),m(iX,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),m(dX,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMProcessor"),m(mX,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTProcessor"),m(cX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(fX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(gX,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),m(hX,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),m(uX,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRProcessor"),m(pX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(_X,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(bX,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltProcessor"),m(vX,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),m(FX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(TX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(MX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(EX,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperProcessor"),m(CX,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPProcessor"),m(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(k_,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(S_,"id","transformers.AutoModel"),m(S_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(S_,"href","#transformers.AutoModel"),m(kd,"class","relative group"),m(wX,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(AX,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(LX,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(yX,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel"),m(xX,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartModel"),m($X,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitModel"),m(kX,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),m(SX,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),m(RX,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel"),m(PX,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),m(BX,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel"),m(IX,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),m(NX,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel"),m(qX,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel"),m(DX,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineModel"),m(jX,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel"),m(GX,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel"),m(OX,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrModel"),m(VX,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel"),m(XX,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel"),m(zX,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel"),m(QX,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel"),m(WX,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel"),m(UX,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel"),m(HX,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel"),m(JX,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel"),m(YX,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model"),m(ZX,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),m(KX,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrModel"),m(ez,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel"),m(oz,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrModel"),m(rz,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel"),m(tz,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel"),m(az,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder"),m(nz,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel"),m(sz,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel"),m(lz,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel"),m(iz,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmModel"),m(dz,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel"),m(mz,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel"),m(cz,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel"),m(fz,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel"),m(gz,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel"),m(hz,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel"),m(uz,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel"),m(pz,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model"),m(_z,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel"),m(bz,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),m(vz,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel"),m(Fz,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel"),m(Tz,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel"),m(Mz,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel"),m(Ez,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel"),m(Cz,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel"),m(wz,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel"),m(Az,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),m(Lz,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),m(yz,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDModel"),m(xz,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitModel"),m($z,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltModel"),m(kz,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel"),m(Sz,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model"),m(Rz,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeModel"),m(Pz,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel"),m(Bz,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),m(Iz,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianModel"),m(Nz,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMModel"),m(qz,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel"),m(Dz,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel"),m(jz,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel"),m(Gz,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel"),m(Oz,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel"),m(Vz,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel"),m(Xz,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel"),m(zz,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model"),m(Qz,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel"),m(Wz,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel"),m(Uz,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),m(Hz,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel"),m(Jz,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),m(Yz,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTModel"),m(Zz,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel"),m(Kz,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel"),m(eQ,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel"),m(oQ,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel"),m(rQ,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel"),m(tQ,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel"),m(aQ,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel"),m(nQ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel"),m(sQ,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel"),m(lQ,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel"),m(iQ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel"),m(dQ,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel"),m(mQ,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),m(cQ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel"),m(fQ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel"),m(gQ,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel"),m(hQ,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWModel"),m(uQ,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel"),m(pQ,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel"),m(_Q,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel"),m(bQ,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel"),m(vQ,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinModel"),m(FQ,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model"),m(TQ,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Model"),m(MQ,"href","/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerModel"),m(EQ,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel"),m(CQ,"href","/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel"),m(wQ,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),m(AQ,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel"),m(LQ,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel"),m(yQ,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),m(xQ,"href","/docs/transformers/main/en/model_doc/van#transformers.VanModel"),m($Q,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel"),m(kQ,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel"),m(SQ,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),m(RQ,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel"),m(PQ,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTModel"),m(BQ,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel"),m(IQ,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNModel"),m(NQ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),m(qQ,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),m(DQ,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel"),m(jQ,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperModel"),m(GQ,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel"),m(OQ,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel"),m(VQ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel"),m(XQ,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),m(zQ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),m(QQ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),m(WQ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel"),m(UQ,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel"),m(HQ,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel"),m(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(rb,"id","transformers.AutoModelForPreTraining"),m(rb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(rb,"href","#transformers.AutoModelForPreTraining"),m(Pd,"class","relative group"),m(JQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(YQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(ZQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(KQ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining"),m(eW,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),m(oW,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining"),m(rW,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),m(tW,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),m(aW,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),m(nW,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),m(sW,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),m(lW,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),m(iW,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),m(dW,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),m(mW,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining"),m(cW,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining"),m(fW,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),m(gW,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining"),m(hW,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining"),m(uW,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),m(pW,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining"),m(_W,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),m(bW,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),m(vW,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),m(FW,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),m(TW,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),m(MW,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining"),m(EW,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),m(CW,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),m(wW,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),m(AW,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),m(LW,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining"),m(yW,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),m(xW,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),m($W,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),m(kW,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining"),m(SW,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),m(RW,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),m(PW,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),m(BW,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),m(IW,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),m(NW,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),m(qW,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining"),m(DW,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),m(jW,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),m(GW,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),m(OW,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),m(VW,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),m(XW,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),m(zW,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),m(QW,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),m(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ev,"id","transformers.AutoModelForCausalLM"),m(ev,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ev,"href","#transformers.AutoModelForCausalLM"),m(Nd,"class","relative group"),m(WW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(UW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(HW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(JW,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM"),m(YW,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel"),m(ZW,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),m(KW,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),m(eU,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),m(oU,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),m(rU,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),m(tU,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),m(aU,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM"),m(nU,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM"),m(sU,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),m(lU,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),m(iU,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM"),m(dU,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM"),m(mU,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),m(cU,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),m(fU,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),m(gU,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM"),m(hU,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM"),m(uU,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM"),m(pU,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM"),m(_U,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),m(bU,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM"),m(vU,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),m(FU,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM"),m(TU,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM"),m(MU,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM"),m(EU,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),m(CU,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),m(wU,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),m(AU,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM"),m(LU,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM"),m(yU,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM"),m(xU,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),m($U,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),m(kU,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM"),m(SU,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM"),m(RU,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),m(PU,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),m(BU,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),m(IU,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),m(NU,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),m(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Qv,"id","transformers.AutoModelForDepthEstimation"),m(Qv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Qv,"href","#transformers.AutoModelForDepthEstimation"),m(jd,"class","relative group"),m(qU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(DU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(jU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(GU,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTForDepthEstimation"),m(OU,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNForDepthEstimation"),m(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Zv,"id","transformers.AutoModelForMaskedLM"),m(Zv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Zv,"href","#transformers.AutoModelForMaskedLM"),m(Vd,"class","relative group"),m(VU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(XU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(zU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(QU,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM"),m(WU,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),m(UU,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM"),m(HU,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),m(JU,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),m(YU,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),m(ZU,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),m(KU,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),m(eH,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),m(oH,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),m(rH,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM"),m(tH,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM"),m(aH,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),m(nH,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM"),m(sH,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM"),m(lH,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),m(iH,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),m(dH,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),m(mH,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),m(cH,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),m(fH,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),m(gH,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),m(hH,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),m(uH,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),m(pH,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM"),m(_H,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),m(bH,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),m(vH,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),m(FH,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM"),m(TH,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM"),m(MH,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),m(EH,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),m(CH,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),m(wH,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),m(AH,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),m(LH,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),m(yH,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),m(xH,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM"),m(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(GF,"id","transformers.AutoModelForSeq2SeqLM"),m(GF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(GF,"href","#transformers.AutoModelForSeq2SeqLM"),m(Qd,"class","relative group"),m($H,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(kH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(SH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(RH,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),m(PH,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),m(BH,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),m(IH,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),m(NH,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),m(qH,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),m(DH,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration"),m(jH,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),m(GH,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),m(OH,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel"),m(VH,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),m(XH,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),m(zH,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),m(QH,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),m(WH,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),m(UH,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration"),m(HH,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),m(JH,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),m(YH,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),m(ZH,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),m(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(cT,"id","transformers.AutoModelForSequenceClassification"),m(cT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(cT,"href","#transformers.AutoModelForSequenceClassification"),m(Hd,"class","relative group"),m(KH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(eJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(oJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(rJ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification"),m(tJ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification"),m(aJ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification"),m(nJ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),m(sJ,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),m(lJ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification"),m(iJ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),m(dJ,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification"),m(mJ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),m(cJ,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),m(fJ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),m(gJ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),m(hJ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),m(uJ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),m(pJ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification"),m(_J,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification"),m(bJ,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmForSequenceClassification"),m(vJ,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),m(FJ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification"),m(TJ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),m(MJ,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),m(EJ,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),m(CJ,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),m(wJ,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification"),m(AJ,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),m(LJ,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),m(yJ,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),m(xJ,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification"),m($J,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltForSequenceClassification"),m(kJ,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),m(SJ,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification"),m(RJ,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification"),m(PJ,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification"),m(BJ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),m(IJ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),m(NJ,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),m(qJ,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification"),m(DJ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification"),m(jJ,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),m(GJ,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),m(OJ,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification"),m(VJ,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),m(XJ,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),m(zJ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),m(QJ,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),m(WJ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),m(UJ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),m(HJ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),m(JJ,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),m(YJ,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification"),m(ZJ,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),m(KJ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification"),m(eY,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),m(oY,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),m(rY,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),m(tY,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification"),m(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(_M,"id","transformers.AutoModelForMultipleChoice"),m(_M,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(_M,"href","#transformers.AutoModelForMultipleChoice"),m(Zd,"class","relative group"),m(aY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(nY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(sY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(lY,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice"),m(iY,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice"),m(dY,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),m(mY,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),m(cY,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice"),m(fY,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),m(gY,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),m(hY,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),m(uY,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),m(pY,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice"),m(_Y,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice"),m(bY,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),m(vY,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice"),m(FY,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),m(TY,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice"),m(MY,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),m(EY,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice"),m(CY,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),m(wY,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),m(AY,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),m(LY,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice"),m(yY,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),m(xY,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),m($Y,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),m(kY,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),m(SY,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),m(RY,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),m(PY,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice"),m(BY,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),m(IY,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),m(NY,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),m(qY,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice"),m(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(KM,"id","transformers.AutoModelForNextSentencePrediction"),m(KM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(KM,"href","#transformers.AutoModelForNextSentencePrediction"),m(om,"class","relative group"),m(DY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(jY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(GY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(OY,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction"),m(VY,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction"),m(XY,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),m(zY,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),m(QY,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),m(WY,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction"),m(UY,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),m(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(mE,"id","transformers.AutoModelForTokenClassification"),m(mE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(mE,"href","#transformers.AutoModelForTokenClassification"),m(am,"class","relative group"),m(HY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(JY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(YY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ZY,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification"),m(KY,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification"),m(eZ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),m(oZ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification"),m(rZ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification"),m(tZ,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification"),m(aZ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),m(nZ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),m(sZ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification"),m(lZ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),m(iZ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),m(dZ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification"),m(mZ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification"),m(cZ,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmForTokenClassification"),m(fZ,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),m(gZ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification"),m(hZ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification"),m(uZ,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),m(pZ,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification"),m(_Z,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),m(bZ,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),m(vZ,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),m(FZ,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltForTokenClassification"),m(TZ,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification"),m(MZ,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification"),m(EZ,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification"),m(CZ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),m(wZ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),m(AZ,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),m(LZ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification"),m(yZ,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),m(xZ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),m($Z,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification"),m(kZ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification"),m(SZ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),m(RZ,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),m(PZ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification"),m(BZ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),m(IZ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),m(NZ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),m(qZ,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification"),m(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(o4,"id","transformers.AutoModelForQuestionAnswering"),m(o4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(o4,"href","#transformers.AutoModelForQuestionAnswering"),m(lm,"class","relative group"),m(DZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(jZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(GZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(OZ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),m(VZ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering"),m(XZ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering"),m(zZ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),m(QZ,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),m(WZ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForQuestionAnswering"),m(UZ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),m(HZ,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering"),m(JZ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),m(YZ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),m(ZZ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),m(KZ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),m(eK,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),m(oK,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),m(rK,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering"),m(tK,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),m(aK,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),m(nK,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),m(sK,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),m(lK,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),m(iK,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),m(dK,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),m(mK,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering"),m(cK,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltForQuestionAnswering"),m(fK,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),m(gK,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering"),m(hK,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),m(uK,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering"),m(pK,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),m(_K,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),m(bK,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),m(vK,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),m(FK,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering"),m(TK,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering"),m(MK,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),m(EK,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForQuestionAnswering"),m(CK,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),m(wK,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),m(AK,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),m(LK,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),m(yK,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),m(xK,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),m($K,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),m(kK,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),m(SK,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),m(RK,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),m(PK,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),m(BK,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),m(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(K4,"id","transformers.AutoModelForTableQuestionAnswering"),m(K4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(K4,"href","#transformers.AutoModelForTableQuestionAnswering"),m(mm,"class","relative group"),m(IK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(NK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(qK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(DK,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),m(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(aC,"id","transformers.AutoModelForDocumentQuestionAnswering"),m(aC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(aC,"href","#transformers.AutoModelForDocumentQuestionAnswering"),m(gm,"class","relative group"),m(jK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(GK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(OK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(VK,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering"),m(XK,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),m(zK,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),m(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(cC,"id","transformers.AutoModelForImageClassification"),m(cC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(cC,"href","#transformers.AutoModelForImageClassification"),m(_m,"class","relative group"),m(QK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(WK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(UK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(HK,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification"),m(JK,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification"),m(YK,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification"),m(ZK,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),m(KK,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification"),m(eee,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),m(oee,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),m(ree,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification"),m(tee,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),m(aee,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification"),m(nee,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),m(see,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),m(lee,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),m(iee,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),m(dee,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification"),m(mee,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification"),m(cee,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification"),m(fee,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification"),m(gee,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification"),m(hee,"href","/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification"),m(uee,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification"),m(pee,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification"),m(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m($C,"id","transformers.AutoModelForVideoClassification"),m($C,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m($C,"href","#transformers.AutoModelForVideoClassification"),m(Fm,"class","relative group"),m(_ee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(bee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(vee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Fee,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification"),m(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(BC,"id","transformers.AutoModelForVision2Seq"),m(BC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(BC,"href","#transformers.AutoModelForVision2Seq"),m(Em,"class","relative group"),m(Tee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Mee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Eee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Cee,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),m(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(jC,"id","transformers.AutoModelForVisualQuestionAnswering"),m(jC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(jC,"href","#transformers.AutoModelForVisualQuestionAnswering"),m(Am,"class","relative group"),m(wee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Aee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Lee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(yee,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),m(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(zC,"id","transformers.AutoModelForAudioClassification"),m(zC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(zC,"href","#transformers.AutoModelForAudioClassification"),m(xm,"class","relative group"),m(xee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m($ee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(kee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(See,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),m(Ree,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification"),m(Pee,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification"),m(Bee,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),m(Iee,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),m(Nee,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),m(qee,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),m(Dee,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),m(jee,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),m(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(a3,"id","transformers.AutoModelForAudioFrameClassification"),m(a3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(a3,"href","#transformers.AutoModelForAudioFrameClassification"),m(Sm,"class","relative group"),m(Gee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Oee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Vee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Xee,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),m(zee,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),m(Qee,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),m(Wee,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),m(Uee,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),m(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(g3,"id","transformers.AutoModelForCTC"),m(g3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(g3,"href","#transformers.AutoModelForCTC"),m(Bm,"class","relative group"),m(Hee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Jee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Yee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Zee,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),m(Kee,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC"),m(eoe,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC"),m(ooe,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC"),m(roe,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC"),m(toe,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC"),m(aoe,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),m(noe,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),m(soe,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),m(loe,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC"),m(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(L3,"id","transformers.AutoModelForSpeechSeq2Seq"),m(L3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(L3,"href","#transformers.AutoModelForSpeechSeq2Seq"),m(qm,"class","relative group"),m(ioe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(doe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(moe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(coe,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),m(foe,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),m(goe,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperForConditionalGeneration"),m(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(P3,"id","transformers.AutoModelForAudioXVector"),m(P3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(P3,"href","#transformers.AutoModelForAudioXVector"),m(Om,"class","relative group"),m(hoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(uoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(poe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(_oe,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),m(boe,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),m(voe,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),m(Foe,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),m(Toe,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector"),m(To,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(V3,"id","transformers.AutoModelForMaskedImageModeling"),m(V3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(V3,"href","#transformers.AutoModelForMaskedImageModeling"),m(zm,"class","relative group"),m(Moe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Eoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Coe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(woe,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),m(Aoe,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),m(Loe,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling"),m(yoe,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),m(Mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Y3,"id","transformers.AutoModelForObjectDetection"),m(Y3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Y3,"href","#transformers.AutoModelForObjectDetection"),m(Um,"class","relative group"),m(xoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m($oe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(koe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Soe,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection"),m(Roe,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection"),m(Poe,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection"),m(Boe,"href","/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerForObjectDetection"),m(Ioe,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection"),m(Eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(s5,"id","transformers.AutoModelForImageSegmentation"),m(s5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(s5,"href","#transformers.AutoModelForImageSegmentation"),m(Ym,"class","relative group"),m(Noe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(qoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Doe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(joe,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation"),m(Co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(c5,"id","transformers.AutoModelForSemanticSegmentation"),m(c5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(c5,"href","#transformers.AutoModelForSemanticSegmentation"),m(ec,"class","relative group"),m(Goe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ooe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Voe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Xoe,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),m(zoe,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),m(Qoe,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),m(Woe,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation"),m(Uoe,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),m(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(F5,"id","transformers.AutoModelForInstanceSegmentation"),m(F5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(F5,"href","#transformers.AutoModelForInstanceSegmentation"),m(tc,"class","relative group"),m(Hoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Joe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Yoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Zoe,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),m(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(w5,"id","transformers.AutoModelForZeroShotObjectDetection"),m(w5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(w5,"href","#transformers.AutoModelForZeroShotObjectDetection"),m(sc,"class","relative group"),m(Koe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ere,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(ore,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(rre,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTForObjectDetection"),m(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m($5,"id","transformers.TFAutoModel"),m($5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m($5,"href","#transformers.TFAutoModel"),m(dc,"class","relative group"),m(tre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(are,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(nre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(sre,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel"),m(lre,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel"),m(ire,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel"),m(dre,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),m(mre,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),m(cre,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel"),m(fre,"href","/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel"),m(gre,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel"),m(hre,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel"),m(ure,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel"),m(pre,"href","/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtModel"),m(_re,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),m(bre,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel"),m(vre,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),m(Fre,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel"),m(Tre,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel"),m(Mre,"href","/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),m(Ere,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel"),m(Cre,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmModel"),m(wre,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel"),m(Are,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel"),m(Lre,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel"),m(yre,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model"),m(xre,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel"),m($re,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.TFGroupViTModel"),m(kre,"href","/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel"),m(Sre,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),m(Rre,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model"),m(Pre,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel"),m(Bre,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel"),m(Ire,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel"),m(Nre,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel"),m(qre,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel"),m(Dre,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel"),m(jre,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel"),m(Gre,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel"),m(Ore,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model"),m(Vre,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),m(Xre,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel"),m(zre,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel"),m(Qre,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel"),m(Wre,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel"),m(Ure,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel"),m(Hre,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel"),m(Jre,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel"),m(Yre,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel"),m(Zre,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),m(Kre,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel"),m(ete,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model"),m(ote,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel"),m(rte,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),m(tte,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel"),m(ate,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel"),m(nte,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),m(ste,"href","/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperModel"),m(lte,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel"),m(ite,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel"),m(dte,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),m(mte,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel"),m(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(I0,"id","transformers.TFAutoModelForPreTraining"),m(I0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(I0,"href","#transformers.TFAutoModelForPreTraining"),m(fc,"class","relative group"),m(cte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(fte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(gte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(hte,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining"),m(ute,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),m(pte,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining"),m(_te,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),m(bte,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),m(vte,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),m(Fte,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining"),m(Tte,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),m(Mte,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),m(Ete,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),m(Cte,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),m(wte,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),m(Ate,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),m(Lte,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),m(yte,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),m(xte,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),m($te,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),m(kte,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),m(Ste,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),m(Rte,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),m(Pte,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),m(Bte,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),m(Ite,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),m(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(iw,"id","transformers.TFAutoModelForCausalLM"),m(iw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(iw,"href","#transformers.TFAutoModelForCausalLM"),m(uc,"class","relative group"),m(Nte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(qte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Dte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(jte,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel"),m(Gte,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),m(Ote,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),m(Vte,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),m(Xte,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),m(zte,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),m(Qte,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM"),m(Wte,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),m(Ute,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),m(Hte,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),m(Jte,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),m(Yte,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM"),m(Zte,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),m(Kte,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),m(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ww,"id","transformers.TFAutoModelForImageClassification"),m(ww,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ww,"href","#transformers.TFAutoModelForImageClassification"),m(bc,"class","relative group"),m(eae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(oae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(rae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(tae,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),m(aae,"href","/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtForImageClassification"),m(nae,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),m(sae,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification"),m(lae,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher"),m(iae,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification"),m(dae,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification"),m(mae,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification"),m(cae,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification"),m(fae,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification"),m(gae,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification"),m(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Nw,"id","transformers.TFAutoModelForSemanticSegmentation"),m(Nw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Nw,"href","#transformers.TFAutoModelForSemanticSegmentation"),m(Tc,"class","relative group"),m(hae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(uae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(pae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(_ae,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation"),m(bae,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation"),m(vae,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation"),m(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Vw,"id","transformers.TFAutoModelForMaskedLM"),m(Vw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Vw,"href","#transformers.TFAutoModelForMaskedLM"),m(wc,"class","relative group"),m(Fae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Tae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Mae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ra,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Eae,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),m(Cae,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM"),m(wae,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),m(Aae,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),m(Lae,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),m(yae,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),m(xae,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),m($ae,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM"),m(kae,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForMaskedLM"),m(Sae,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),m(Rae,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),m(Pae,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),m(Bae,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),m(Iae,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),m(Nae,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),m(qae,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),m(Dae,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),m(jae,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),m(Gae,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),m(Oae,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),m(Vae,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),m(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(gA,"id","transformers.TFAutoModelForSeq2SeqLM"),m(gA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(gA,"href","#transformers.TFAutoModelForSeq2SeqLM"),m(yc,"class","relative group"),m(Xae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(zae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Qae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Wae,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),m(Uae,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),m(Hae,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),m(Jae,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),m(Yae,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),m(Zae,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel"),m(Kae,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),m(ene,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),m(one,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),m(rne,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),m(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(AA,"id","transformers.TFAutoModelForSequenceClassification"),m(AA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(AA,"href","#transformers.TFAutoModelForSequenceClassification"),m(kc,"class","relative group"),m(tne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ane,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(nne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(aa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(sne,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),m(lne,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification"),m(ine,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),m(dne,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),m(mne,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),m(cne,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),m(fne,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),m(gne,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),m(hne,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),m(une,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForSequenceClassification"),m(pne,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),m(_ne,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),m(bne,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),m(vne,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),m(Fne,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),m(Tne,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification"),m(Mne,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),m(Ene,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),m(Cne,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),m(wne,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),m(Ane,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),m(Lne,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),m(yne,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),m(xne,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),m($ne,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),m(kne,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),m(Sne,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),m(Rne,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),m(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(t6,"id","transformers.TFAutoModelForMultipleChoice"),m(t6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(t6,"href","#transformers.TFAutoModelForMultipleChoice"),m(Pc,"class","relative group"),m(Pne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Bne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Ine,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(na,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Nne,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),m(qne,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice"),m(Dne,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),m(jne,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),m(Gne,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),m(One,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),m(Vne,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),m(Xne,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),m(zne,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),m(Qne,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),m(Wne,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),m(Une,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),m(Hne,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),m(Jne,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),m(Yne,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),m(Zne,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),m(Kne,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),m(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(E6,"id","transformers.TFAutoModelForNextSentencePrediction"),m(E6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(E6,"href","#transformers.TFAutoModelForNextSentencePrediction"),m(Nc,"class","relative group"),m(ese,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ose,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(rse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(sa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(tse,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),m(ase,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),m(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(y6,"id","transformers.TFAutoModelForTableQuestionAnswering"),m(y6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(y6,"href","#transformers.TFAutoModelForTableQuestionAnswering"),m(jc,"class","relative group"),m(nse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(sse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(lse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(la,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ise,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),m(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(S6,"id","transformers.TFAutoModelForDocumentQuestionAnswering"),m(S6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(S6,"href","#transformers.TFAutoModelForDocumentQuestionAnswering"),m(Vc,"class","relative group"),m(dse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(mse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(cse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ia,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(fse,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering"),m(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(I6,"id","transformers.TFAutoModelForTokenClassification"),m(I6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(I6,"href","#transformers.TFAutoModelForTokenClassification"),m(Qc,"class","relative group"),m(gse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(hse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(use,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(da,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(pse,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),m(_se,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification"),m(bse,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),m(vse,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),m(Fse,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),m(Tse,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),m(Mse,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),m(Ese,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification"),m(Cse,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForTokenClassification"),m(wse,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),m(Ase,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),m(Lse,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),m(yse,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification"),m(xse,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),m($se,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),m(kse,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),m(Sse,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),m(Rse,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),m(Pse,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),m(Bse,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),m(Ise,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),m(Nse,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),m(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(l7,"id","transformers.TFAutoModelForQuestionAnswering"),m(l7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(l7,"href","#transformers.TFAutoModelForQuestionAnswering"),m(Hc,"class","relative group"),m(qse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Dse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(jse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ma,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Gse,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),m(Ose,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),m(Vse,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),m(Xse,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),m(zse,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),m(Qse,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),m(Wse,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),m(Use,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),m(Hse,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),m(Jse,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),m(Yse,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),m(Zse,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering"),m(Kse,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),m(ele,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),m(ole,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),m(rle,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),m(tle,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),m(ale,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),m(nle,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),m(sle,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),m(lle,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),m(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(k7,"id","transformers.TFAutoModelForVision2Seq"),m(k7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(k7,"href","#transformers.TFAutoModelForVision2Seq"),m(Zc,"class","relative group"),m(ile,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(dle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(mle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ca,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(cle,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),m(et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(B7,"id","transformers.TFAutoModelForSpeechSeq2Seq"),m(B7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(B7,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),m(of,"class","relative group"),m(fle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(gle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(hle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(fa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ule,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),m(ple,"href","/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration"),m(ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(j7,"id","transformers.FlaxAutoModel"),m(j7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(j7,"href","#transformers.FlaxAutoModel"),m(af,"class","relative group"),m(_le,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ble,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(vle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ga,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Fle,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel"),m(Tle,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel"),m(Mle,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel"),m(Ele,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel"),m(Cle,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),m(wle,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),m(Ale,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),m(Lle,"href","/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel"),m(yle,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),m(xle,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel"),m($le,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model"),m(kle,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),m(Sle,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel"),m(Rle,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model"),m(Ple,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel"),m(Ble,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel"),m(Ile,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model"),m(Nle,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel"),m(qle,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel"),m(Dle,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel"),m(jle,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel"),m(Gle,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model"),m(Ole,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),m(Vle,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel"),m(Xle,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),m(zle,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel"),m(Qle,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),m(rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(p8,"id","transformers.FlaxAutoModelForCausalLM"),m(p8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(p8,"href","#transformers.FlaxAutoModelForCausalLM"),m(lf,"class","relative group"),m(Wle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ule,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Hle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ha,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Jle,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM"),m(Yle,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM"),m(Zle,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),m(Kle,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),m(eie,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),m(oie,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),m(rie,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),m(tie,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),m(aie,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),m(nie,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),m(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(x8,"id","transformers.FlaxAutoModelForPreTraining"),m(x8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(x8,"href","#transformers.FlaxAutoModelForPreTraining"),m(cf,"class","relative group"),m(sie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(lie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(iie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ua,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(die,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),m(mie,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),m(cie,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining"),m(fie,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),m(gie,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),m(hie,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),m(uie,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),m(pie,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),m(_ie,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),m(bie,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),m(vie,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),m(Fie,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),m(Tie,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),m(at,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(z8,"id","transformers.FlaxAutoModelForMaskedLM"),m(z8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(z8,"href","#transformers.FlaxAutoModelForMaskedLM"),m(hf,"class","relative group"),m(Mie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Eie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Cie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(pa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(wie,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),m(Aie,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),m(Lie,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),m(yie,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),m(xie,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),m($ie,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),m(kie,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),m(Sie,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),m(Rie,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),m(Pie,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),m(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(aL,"id","transformers.FlaxAutoModelForSeq2SeqLM"),m(aL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(aL,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),m(_f,"class","relative group"),m(Bie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Iie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Nie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(_a,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(qie,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),m(Die,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),m(jie,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),m(Gie,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),m(Oie,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),m(Vie,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel"),m(Xie,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),m(zie,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),m(Qie,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),m(Wie,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),m(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(_L,"id","transformers.FlaxAutoModelForSequenceClassification"),m(_L,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(_L,"href","#transformers.FlaxAutoModelForSequenceClassification"),m(Ff,"class","relative group"),m(Uie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Hie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Jie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ba,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Yie,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),m(Zie,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),m(Kie,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),m(ede,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),m(ode,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),m(rde,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),m(tde,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),m(ade,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),m(nde,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),m(sde,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),m(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m($L,"id","transformers.FlaxAutoModelForQuestionAnswering"),m($L,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m($L,"href","#transformers.FlaxAutoModelForQuestionAnswering"),m(Ef,"class","relative group"),m(lde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ide,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(dde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(va,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(mde,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),m(cde,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),m(fde,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),m(gde,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),m(hde,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),m(ude,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),m(pde,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),m(_de,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),m(bde,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),m(vde,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),m(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(VL,"id","transformers.FlaxAutoModelForTokenClassification"),m(VL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(VL,"href","#transformers.FlaxAutoModelForTokenClassification"),m(Af,"class","relative group"),m(Fde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Tde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Mde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Fa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ede,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),m(Cde,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),m(wde,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),m(Ade,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),m(Lde,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),m(yde,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),m(xde,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),m($de,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),m(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ey,"id","transformers.FlaxAutoModelForMultipleChoice"),m(ey,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ey,"href","#transformers.FlaxAutoModelForMultipleChoice"),m(xf,"class","relative group"),m(kde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Sde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Rde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Pde,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),m(Bde,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),m(Ide,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),m(Nde,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),m(qde,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),m(Dde,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),m(jde,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),m(Gde,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),m(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(cy,"id","transformers.FlaxAutoModelForNextSentencePrediction"),m(cy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(cy,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),m(Sf,"class","relative group"),m(Ode,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Vde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Xde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ma,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(zde,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),m(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(uy,"id","transformers.FlaxAutoModelForImageClassification"),m(uy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(uy,"href","#transformers.FlaxAutoModelForImageClassification"),m(Bf,"class","relative group"),m(Qde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Wde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Ude,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Hde,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),m(Jde,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification"),m(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Fy,"id","transformers.FlaxAutoModelForVision2Seq"),m(Fy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Fy,"href","#transformers.FlaxAutoModelForVision2Seq"),m(qf,"class","relative group"),m(Yde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Zde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Kde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ca,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(eme,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),m(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(c,_){e(document.head,g),b(c,v,_),b(c,u,_),e(u,f),e(f,p),M(d,p,null),e(u,h),e(u,$o),e($o,_d),b(c,Xf,_),b(c,Tt,_),e(Tt,bd),e(Tt,vd),e(vd,n$),e(Tt,zf),b(c,Xe,_),b(c,He,_),e(He,Fd),e(He,ms),e(ms,s$),e(He,cs),e(He,fs),e(fs,l$),e(He,Td),e(He,gs),e(gs,i$),e(He,Md),b(c,Qf,_),M(on,c,_),b(c,Je,_),b(c,Ae,_),e(Ae,TN),e(Ae,Ed),e(Ed,MN),e(Ae,EN),b(c,ko,_),b(c,rn,_),e(rn,CN),e(rn,Wf),e(Wf,wN),e(rn,dio),b(c,Cto,_),b(c,Cd,_),e(Cd,Uf),e(Uf,dfe),M(d$,dfe,null),e(Cd,mio),e(Cd,mfe),e(mfe,cio),b(c,wto,_),b(c,hs,_),e(hs,fio),e(hs,cfe),e(cfe,gio),e(hs,hio),e(hs,ffe),e(ffe,uio),e(hs,pio),b(c,Ato,_),M(m$,c,_),b(c,Lto,_),b(c,AN,_),e(AN,_io),b(c,yto,_),M(Hf,c,_),b(c,xto,_),b(c,wd,_),e(wd,Jf),e(Jf,gfe),M(c$,gfe,null),e(wd,bio),e(wd,hfe),e(hfe,vio),b(c,$to,_),b(c,So,_),M(f$,So,null),e(So,Fio),e(So,g$),e(g$,Tio),e(g$,LN),e(LN,Mio),e(g$,Eio),e(So,Cio),e(So,h$),e(h$,wio),e(h$,ufe),e(ufe,Aio),e(h$,Lio),e(So,yio),e(So,qr),M(u$,qr,null),e(qr,xio),e(qr,pfe),e(pfe,$io),e(qr,kio),e(qr,Ad),e(Ad,Sio),e(Ad,_fe),e(_fe,Rio),e(Ad,Pio),e(Ad,bfe),e(bfe,Bio),e(Ad,Iio),e(qr,Nio),e(qr,A),e(A,Yf),e(Yf,vfe),e(vfe,qio),e(Yf,Dio),e(Yf,yN),e(yN,jio),e(Yf,Gio),e(A,Oio),e(A,Zf),e(Zf,Ffe),e(Ffe,Vio),e(Zf,Xio),e(Zf,xN),e(xN,zio),e(Zf,Qio),e(A,Wio),e(A,Kf),e(Kf,Tfe),e(Tfe,Uio),e(Kf,Hio),e(Kf,$N),e($N,Jio),e(Kf,Yio),e(A,Zio),e(A,eg),e(eg,Mfe),e(Mfe,Kio),e(eg,edo),e(eg,kN),e(kN,odo),e(eg,rdo),e(A,tdo),e(A,og),e(og,Efe),e(Efe,ado),e(og,ndo),e(og,SN),e(SN,sdo),e(og,ldo),e(A,ido),e(A,rg),e(rg,Cfe),e(Cfe,ddo),e(rg,mdo),e(rg,RN),e(RN,cdo),e(rg,fdo),e(A,gdo),e(A,tg),e(tg,wfe),e(wfe,hdo),e(tg,udo),e(tg,PN),e(PN,pdo),e(tg,_do),e(A,bdo),e(A,ag),e(ag,Afe),e(Afe,vdo),e(ag,Fdo),e(ag,BN),e(BN,Tdo),e(ag,Mdo),e(A,Edo),e(A,ng),e(ng,Lfe),e(Lfe,Cdo),e(ng,wdo),e(ng,IN),e(IN,Ado),e(ng,Ldo),e(A,ydo),e(A,sg),e(sg,yfe),e(yfe,xdo),e(sg,$do),e(sg,NN),e(NN,kdo),e(sg,Sdo),e(A,Rdo),e(A,lg),e(lg,xfe),e(xfe,Pdo),e(lg,Bdo),e(lg,qN),e(qN,Ido),e(lg,Ndo),e(A,qdo),e(A,ig),e(ig,$fe),e($fe,Ddo),e(ig,jdo),e(ig,DN),e(DN,Gdo),e(ig,Odo),e(A,Vdo),e(A,dg),e(dg,kfe),e(kfe,Xdo),e(dg,zdo),e(dg,jN),e(jN,Qdo),e(dg,Wdo),e(A,Udo),e(A,mg),e(mg,Sfe),e(Sfe,Hdo),e(mg,Jdo),e(mg,GN),e(GN,Ydo),e(mg,Zdo),e(A,Kdo),e(A,cg),e(cg,Rfe),e(Rfe,emo),e(cg,omo),e(cg,ON),e(ON,rmo),e(cg,tmo),e(A,amo),e(A,fg),e(fg,Pfe),e(Pfe,nmo),e(fg,smo),e(fg,VN),e(VN,lmo),e(fg,imo),e(A,dmo),e(A,gg),e(gg,Bfe),e(Bfe,mmo),e(gg,cmo),e(gg,XN),e(XN,fmo),e(gg,gmo),e(A,hmo),e(A,hg),e(hg,Ife),e(Ife,umo),e(hg,pmo),e(hg,zN),e(zN,_mo),e(hg,bmo),e(A,vmo),e(A,ug),e(ug,Nfe),e(Nfe,Fmo),e(ug,Tmo),e(ug,QN),e(QN,Mmo),e(ug,Emo),e(A,Cmo),e(A,pg),e(pg,qfe),e(qfe,wmo),e(pg,Amo),e(pg,WN),e(WN,Lmo),e(pg,ymo),e(A,xmo),e(A,_g),e(_g,Dfe),e(Dfe,$mo),e(_g,kmo),e(_g,UN),e(UN,Smo),e(_g,Rmo),e(A,Pmo),e(A,bg),e(bg,jfe),e(jfe,Bmo),e(bg,Imo),e(bg,HN),e(HN,Nmo),e(bg,qmo),e(A,Dmo),e(A,vg),e(vg,Gfe),e(Gfe,jmo),e(vg,Gmo),e(vg,JN),e(JN,Omo),e(vg,Vmo),e(A,Xmo),e(A,Fg),e(Fg,Ofe),e(Ofe,zmo),e(Fg,Qmo),e(Fg,YN),e(YN,Wmo),e(Fg,Umo),e(A,Hmo),e(A,Tg),e(Tg,Vfe),e(Vfe,Jmo),e(Tg,Ymo),e(Tg,ZN),e(ZN,Zmo),e(Tg,Kmo),e(A,eco),e(A,Mg),e(Mg,Xfe),e(Xfe,oco),e(Mg,rco),e(Mg,KN),e(KN,tco),e(Mg,aco),e(A,nco),e(A,Eg),e(Eg,zfe),e(zfe,sco),e(Eg,lco),e(Eg,eq),e(eq,ico),e(Eg,dco),e(A,mco),e(A,Cg),e(Cg,Qfe),e(Qfe,cco),e(Cg,fco),e(Cg,oq),e(oq,gco),e(Cg,hco),e(A,uco),e(A,wg),e(wg,Wfe),e(Wfe,pco),e(wg,_co),e(wg,rq),e(rq,bco),e(wg,vco),e(A,Fco),e(A,Ag),e(Ag,Ufe),e(Ufe,Tco),e(Ag,Mco),e(Ag,tq),e(tq,Eco),e(Ag,Cco),e(A,wco),e(A,Lg),e(Lg,Hfe),e(Hfe,Aco),e(Lg,Lco),e(Lg,aq),e(aq,yco),e(Lg,xco),e(A,$co),e(A,yg),e(yg,Jfe),e(Jfe,kco),e(yg,Sco),e(yg,nq),e(nq,Rco),e(yg,Pco),e(A,Bco),e(A,xg),e(xg,Yfe),e(Yfe,Ico),e(xg,Nco),e(xg,sq),e(sq,qco),e(xg,Dco),e(A,jco),e(A,$g),e($g,Zfe),e(Zfe,Gco),e($g,Oco),e($g,lq),e(lq,Vco),e($g,Xco),e(A,zco),e(A,kg),e(kg,Kfe),e(Kfe,Qco),e(kg,Wco),e(kg,iq),e(iq,Uco),e(kg,Hco),e(A,Jco),e(A,Sg),e(Sg,ege),e(ege,Yco),e(Sg,Zco),e(Sg,dq),e(dq,Kco),e(Sg,efo),e(A,ofo),e(A,Rg),e(Rg,oge),e(oge,rfo),e(Rg,tfo),e(Rg,mq),e(mq,afo),e(Rg,nfo),e(A,sfo),e(A,Pg),e(Pg,rge),e(rge,lfo),e(Pg,ifo),e(Pg,cq),e(cq,dfo),e(Pg,mfo),e(A,cfo),e(A,Bg),e(Bg,tge),e(tge,ffo),e(Bg,gfo),e(Bg,fq),e(fq,hfo),e(Bg,ufo),e(A,pfo),e(A,Ig),e(Ig,age),e(age,_fo),e(Ig,bfo),e(Ig,gq),e(gq,vfo),e(Ig,Ffo),e(A,Tfo),e(A,Ng),e(Ng,nge),e(nge,Mfo),e(Ng,Efo),e(Ng,hq),e(hq,Cfo),e(Ng,wfo),e(A,Afo),e(A,qg),e(qg,sge),e(sge,Lfo),e(qg,yfo),e(qg,uq),e(uq,xfo),e(qg,$fo),e(A,kfo),e(A,Dg),e(Dg,lge),e(lge,Sfo),e(Dg,Rfo),e(Dg,pq),e(pq,Pfo),e(Dg,Bfo),e(A,Ifo),e(A,jg),e(jg,ige),e(ige,Nfo),e(jg,qfo),e(jg,_q),e(_q,Dfo),e(jg,jfo),e(A,Gfo),e(A,Gg),e(Gg,dge),e(dge,Ofo),e(Gg,Vfo),e(Gg,bq),e(bq,Xfo),e(Gg,zfo),e(A,Qfo),e(A,Og),e(Og,mge),e(mge,Wfo),e(Og,Ufo),e(Og,vq),e(vq,Hfo),e(Og,Jfo),e(A,Yfo),e(A,Vg),e(Vg,cge),e(cge,Zfo),e(Vg,Kfo),e(Vg,Fq),e(Fq,ego),e(Vg,ogo),e(A,rgo),e(A,Xg),e(Xg,fge),e(fge,tgo),e(Xg,ago),e(Xg,Tq),e(Tq,ngo),e(Xg,sgo),e(A,lgo),e(A,zg),e(zg,gge),e(gge,igo),e(zg,dgo),e(zg,Mq),e(Mq,mgo),e(zg,cgo),e(A,fgo),e(A,Qg),e(Qg,hge),e(hge,ggo),e(Qg,hgo),e(Qg,Eq),e(Eq,ugo),e(Qg,pgo),e(A,_go),e(A,Wg),e(Wg,uge),e(uge,bgo),e(Wg,vgo),e(Wg,Cq),e(Cq,Fgo),e(Wg,Tgo),e(A,Mgo),e(A,Ug),e(Ug,pge),e(pge,Ego),e(Ug,Cgo),e(Ug,wq),e(wq,wgo),e(Ug,Ago),e(A,Lgo),e(A,Hg),e(Hg,_ge),e(_ge,ygo),e(Hg,xgo),e(Hg,Aq),e(Aq,$go),e(Hg,kgo),e(A,Sgo),e(A,Jg),e(Jg,bge),e(bge,Rgo),e(Jg,Pgo),e(Jg,Lq),e(Lq,Bgo),e(Jg,Igo),e(A,Ngo),e(A,Yg),e(Yg,vge),e(vge,qgo),e(Yg,Dgo),e(Yg,yq),e(yq,jgo),e(Yg,Ggo),e(A,Ogo),e(A,Zg),e(Zg,Fge),e(Fge,Vgo),e(Zg,Xgo),e(Zg,xq),e(xq,zgo),e(Zg,Qgo),e(A,Wgo),e(A,Kg),e(Kg,Tge),e(Tge,Ugo),e(Kg,Hgo),e(Kg,$q),e($q,Jgo),e(Kg,Ygo),e(A,Zgo),e(A,eh),e(eh,Mge),e(Mge,Kgo),e(eh,eho),e(eh,kq),e(kq,oho),e(eh,rho),e(A,tho),e(A,oh),e(oh,Ege),e(Ege,aho),e(oh,nho),e(oh,Sq),e(Sq,sho),e(oh,lho),e(A,iho),e(A,rh),e(rh,Cge),e(Cge,dho),e(rh,mho),e(rh,Rq),e(Rq,cho),e(rh,fho),e(A,gho),e(A,th),e(th,wge),e(wge,hho),e(th,uho),e(th,Pq),e(Pq,pho),e(th,_ho),e(A,bho),e(A,ah),e(ah,Age),e(Age,vho),e(ah,Fho),e(ah,Bq),e(Bq,Tho),e(ah,Mho),e(A,Eho),e(A,nh),e(nh,Lge),e(Lge,Cho),e(nh,who),e(nh,Iq),e(Iq,Aho),e(nh,Lho),e(A,yho),e(A,sh),e(sh,yge),e(yge,xho),e(sh,$ho),e(sh,Nq),e(Nq,kho),e(sh,Sho),e(A,Rho),e(A,lh),e(lh,xge),e(xge,Pho),e(lh,Bho),e(lh,qq),e(qq,Iho),e(lh,Nho),e(A,qho),e(A,ih),e(ih,$ge),e($ge,Dho),e(ih,jho),e(ih,Dq),e(Dq,Gho),e(ih,Oho),e(A,Vho),e(A,dh),e(dh,kge),e(kge,Xho),e(dh,zho),e(dh,jq),e(jq,Qho),e(dh,Who),e(A,Uho),e(A,mh),e(mh,Sge),e(Sge,Hho),e(mh,Jho),e(mh,Gq),e(Gq,Yho),e(mh,Zho),e(A,Kho),e(A,ch),e(ch,Rge),e(Rge,euo),e(ch,ouo),e(ch,Oq),e(Oq,ruo),e(ch,tuo),e(A,auo),e(A,fh),e(fh,Pge),e(Pge,nuo),e(fh,suo),e(fh,Vq),e(Vq,luo),e(fh,iuo),e(A,duo),e(A,gh),e(gh,Bge),e(Bge,muo),e(gh,cuo),e(gh,Xq),e(Xq,fuo),e(gh,guo),e(A,huo),e(A,hh),e(hh,Ige),e(Ige,uuo),e(hh,puo),e(hh,zq),e(zq,_uo),e(hh,buo),e(A,vuo),e(A,uh),e(uh,Nge),e(Nge,Fuo),e(uh,Tuo),e(uh,Qq),e(Qq,Muo),e(uh,Euo),e(A,Cuo),e(A,ph),e(ph,qge),e(qge,wuo),e(ph,Auo),e(ph,Wq),e(Wq,Luo),e(ph,yuo),e(A,xuo),e(A,_h),e(_h,Dge),e(Dge,$uo),e(_h,kuo),e(_h,Uq),e(Uq,Suo),e(_h,Ruo),e(A,Puo),e(A,bh),e(bh,jge),e(jge,Buo),e(bh,Iuo),e(bh,Hq),e(Hq,Nuo),e(bh,quo),e(A,Duo),e(A,vh),e(vh,Gge),e(Gge,juo),e(vh,Guo),e(vh,Jq),e(Jq,Ouo),e(vh,Vuo),e(A,Xuo),e(A,Fh),e(Fh,Oge),e(Oge,zuo),e(Fh,Quo),e(Fh,Yq),e(Yq,Wuo),e(Fh,Uuo),e(A,Huo),e(A,Th),e(Th,Vge),e(Vge,Juo),e(Th,Yuo),e(Th,Zq),e(Zq,Zuo),e(Th,Kuo),e(A,epo),e(A,Mh),e(Mh,Xge),e(Xge,opo),e(Mh,rpo),e(Mh,Kq),e(Kq,tpo),e(Mh,apo),e(A,npo),e(A,Eh),e(Eh,zge),e(zge,spo),e(Eh,lpo),e(Eh,eD),e(eD,ipo),e(Eh,dpo),e(A,mpo),e(A,Ch),e(Ch,Qge),e(Qge,cpo),e(Ch,fpo),e(Ch,oD),e(oD,gpo),e(Ch,hpo),e(A,upo),e(A,wh),e(wh,Wge),e(Wge,ppo),e(wh,_po),e(wh,rD),e(rD,bpo),e(wh,vpo),e(A,Fpo),e(A,Ah),e(Ah,Uge),e(Uge,Tpo),e(Ah,Mpo),e(Ah,tD),e(tD,Epo),e(Ah,Cpo),e(A,wpo),e(A,Lh),e(Lh,Hge),e(Hge,Apo),e(Lh,Lpo),e(Lh,aD),e(aD,ypo),e(Lh,xpo),e(A,$po),e(A,yh),e(yh,Jge),e(Jge,kpo),e(yh,Spo),e(yh,nD),e(nD,Rpo),e(yh,Ppo),e(A,Bpo),e(A,xh),e(xh,Yge),e(Yge,Ipo),e(xh,Npo),e(xh,sD),e(sD,qpo),e(xh,Dpo),e(A,jpo),e(A,$h),e($h,Zge),e(Zge,Gpo),e($h,Opo),e($h,lD),e(lD,Vpo),e($h,Xpo),e(A,zpo),e(A,kh),e(kh,Kge),e(Kge,Qpo),e(kh,Wpo),e(kh,iD),e(iD,Upo),e(kh,Hpo),e(A,Jpo),e(A,Sh),e(Sh,ehe),e(ehe,Ypo),e(Sh,Zpo),e(Sh,dD),e(dD,Kpo),e(Sh,e_o),e(A,o_o),e(A,Rh),e(Rh,ohe),e(ohe,r_o),e(Rh,t_o),e(Rh,mD),e(mD,a_o),e(Rh,n_o),e(A,s_o),e(A,Ph),e(Ph,rhe),e(rhe,l_o),e(Ph,i_o),e(Ph,cD),e(cD,d_o),e(Ph,m_o),e(A,c_o),e(A,Bh),e(Bh,the),e(the,f_o),e(Bh,g_o),e(Bh,fD),e(fD,h_o),e(Bh,u_o),e(A,p_o),e(A,Ih),e(Ih,ahe),e(ahe,__o),e(Ih,b_o),e(Ih,gD),e(gD,v_o),e(Ih,F_o),e(A,T_o),e(A,Nh),e(Nh,nhe),e(nhe,M_o),e(Nh,E_o),e(Nh,hD),e(hD,C_o),e(Nh,w_o),e(A,A_o),e(A,qh),e(qh,she),e(she,L_o),e(qh,y_o),e(qh,uD),e(uD,x_o),e(qh,$_o),e(A,k_o),e(A,Dh),e(Dh,lhe),e(lhe,S_o),e(Dh,R_o),e(Dh,pD),e(pD,P_o),e(Dh,B_o),e(A,I_o),e(A,jh),e(jh,ihe),e(ihe,N_o),e(jh,q_o),e(jh,_D),e(_D,D_o),e(jh,j_o),e(A,G_o),e(A,Gh),e(Gh,dhe),e(dhe,O_o),e(Gh,V_o),e(Gh,bD),e(bD,X_o),e(Gh,z_o),e(A,Q_o),e(A,Oh),e(Oh,mhe),e(mhe,W_o),e(Oh,U_o),e(Oh,vD),e(vD,H_o),e(Oh,J_o),e(A,Y_o),e(A,Vh),e(Vh,che),e(che,Z_o),e(Vh,K_o),e(Vh,FD),e(FD,e1o),e(Vh,o1o),e(A,r1o),e(A,Xh),e(Xh,fhe),e(fhe,t1o),e(Xh,a1o),e(Xh,TD),e(TD,n1o),e(Xh,s1o),e(A,l1o),e(A,zh),e(zh,ghe),e(ghe,i1o),e(zh,d1o),e(zh,MD),e(MD,m1o),e(zh,c1o),e(A,f1o),e(A,Qh),e(Qh,hhe),e(hhe,g1o),e(Qh,h1o),e(Qh,ED),e(ED,u1o),e(Qh,p1o),e(A,_1o),e(A,Wh),e(Wh,uhe),e(uhe,b1o),e(Wh,v1o),e(Wh,CD),e(CD,F1o),e(Wh,T1o),e(A,M1o),e(A,Uh),e(Uh,phe),e(phe,E1o),e(Uh,C1o),e(Uh,wD),e(wD,w1o),e(Uh,A1o),e(A,L1o),e(A,Hh),e(Hh,_he),e(_he,y1o),e(Hh,x1o),e(Hh,AD),e(AD,$1o),e(Hh,k1o),e(A,S1o),e(A,Jh),e(Jh,bhe),e(bhe,R1o),e(Jh,P1o),e(Jh,LD),e(LD,B1o),e(Jh,I1o),e(A,N1o),e(A,Yh),e(Yh,vhe),e(vhe,q1o),e(Yh,D1o),e(Yh,yD),e(yD,j1o),e(Yh,G1o),e(A,O1o),e(A,Zh),e(Zh,Fhe),e(Fhe,V1o),e(Zh,X1o),e(Zh,xD),e(xD,z1o),e(Zh,Q1o),e(A,W1o),e(A,Kh),e(Kh,The),e(The,U1o),e(Kh,H1o),e(Kh,$D),e($D,J1o),e(Kh,Y1o),e(A,Z1o),e(A,eu),e(eu,Mhe),e(Mhe,K1o),e(eu,e2o),e(eu,kD),e(kD,o2o),e(eu,r2o),e(A,t2o),e(A,ou),e(ou,Ehe),e(Ehe,a2o),e(ou,n2o),e(ou,SD),e(SD,s2o),e(ou,l2o),e(A,i2o),e(A,ru),e(ru,Che),e(Che,d2o),e(ru,m2o),e(ru,RD),e(RD,c2o),e(ru,f2o),e(A,g2o),e(A,tu),e(tu,whe),e(whe,h2o),e(tu,u2o),e(tu,PD),e(PD,p2o),e(tu,_2o),e(A,b2o),e(A,au),e(au,Ahe),e(Ahe,v2o),e(au,F2o),e(au,BD),e(BD,T2o),e(au,M2o),e(A,E2o),e(A,nu),e(nu,Lhe),e(Lhe,C2o),e(nu,w2o),e(nu,ID),e(ID,A2o),e(nu,L2o),e(A,y2o),e(A,su),e(su,yhe),e(yhe,x2o),e(su,$2o),e(su,ND),e(ND,k2o),e(su,S2o),e(A,R2o),e(A,lu),e(lu,xhe),e(xhe,P2o),e(lu,B2o),e(lu,qD),e(qD,I2o),e(lu,N2o),e(A,q2o),e(A,iu),e(iu,$he),e($he,D2o),e(iu,j2o),e(iu,DD),e(DD,G2o),e(iu,O2o),e(A,V2o),e(A,du),e(du,khe),e(khe,X2o),e(du,z2o),e(du,jD),e(jD,Q2o),e(du,W2o),e(A,U2o),e(A,mu),e(mu,She),e(She,H2o),e(mu,J2o),e(mu,GD),e(GD,Y2o),e(mu,Z2o),e(A,K2o),e(A,cu),e(cu,Rhe),e(Rhe,ebo),e(cu,obo),e(cu,OD),e(OD,rbo),e(cu,tbo),e(A,abo),e(A,fu),e(fu,Phe),e(Phe,nbo),e(fu,sbo),e(fu,VD),e(VD,lbo),e(fu,ibo),e(A,dbo),e(A,gu),e(gu,Bhe),e(Bhe,mbo),e(gu,cbo),e(gu,XD),e(XD,fbo),e(gu,gbo),e(A,hbo),e(A,hu),e(hu,Ihe),e(Ihe,ubo),e(hu,pbo),e(hu,zD),e(zD,_bo),e(hu,bbo),e(A,vbo),e(A,uu),e(uu,Nhe),e(Nhe,Fbo),e(uu,Tbo),e(uu,QD),e(QD,Mbo),e(uu,Ebo),e(A,Cbo),e(A,pu),e(pu,qhe),e(qhe,wbo),e(pu,Abo),e(pu,WD),e(WD,Lbo),e(pu,ybo),e(A,xbo),e(A,_u),e(_u,Dhe),e(Dhe,$bo),e(_u,kbo),e(_u,UD),e(UD,Sbo),e(_u,Rbo),e(A,Pbo),e(A,bu),e(bu,jhe),e(jhe,Bbo),e(bu,Ibo),e(bu,HD),e(HD,Nbo),e(bu,qbo),e(A,Dbo),e(A,vu),e(vu,Ghe),e(Ghe,jbo),e(vu,Gbo),e(vu,JD),e(JD,Obo),e(vu,Vbo),e(A,Xbo),e(A,Fu),e(Fu,Ohe),e(Ohe,zbo),e(Fu,Qbo),e(Fu,YD),e(YD,Wbo),e(Fu,Ubo),e(A,Hbo),e(A,Tu),e(Tu,Vhe),e(Vhe,Jbo),e(Tu,Ybo),e(Tu,ZD),e(ZD,Zbo),e(Tu,Kbo),e(A,evo),e(A,Mu),e(Mu,Xhe),e(Xhe,ovo),e(Mu,rvo),e(Mu,KD),e(KD,tvo),e(Mu,avo),e(A,nvo),e(A,Eu),e(Eu,zhe),e(zhe,svo),e(Eu,lvo),e(Eu,ej),e(ej,ivo),e(Eu,dvo),e(qr,mvo),M(Cu,qr,null),e(So,cvo),e(So,wu),M(p$,wu,null),e(wu,fvo),e(wu,Qhe),e(Qhe,gvo),b(c,kto,_),b(c,Ld,_),e(Ld,Au),e(Au,Whe),M(_$,Whe,null),e(Ld,hvo),e(Ld,Uhe),e(Uhe,uvo),b(c,Sto,_),b(c,Ro,_),M(b$,Ro,null),e(Ro,pvo),e(Ro,v$),e(v$,_vo),e(v$,oj),e(oj,bvo),e(v$,vvo),e(Ro,Fvo),e(Ro,F$),e(F$,Tvo),e(F$,Hhe),e(Hhe,Mvo),e(F$,Evo),e(Ro,Cvo),e(Ro,Dr),M(T$,Dr,null),e(Dr,wvo),e(Dr,Jhe),e(Jhe,Avo),e(Dr,Lvo),e(Dr,tn),e(tn,yvo),e(tn,Yhe),e(Yhe,xvo),e(tn,$vo),e(tn,Zhe),e(Zhe,kvo),e(tn,Svo),e(tn,Khe),e(Khe,Rvo),e(tn,Pvo),e(Dr,Bvo),e(Dr,k),e(k,us),e(us,eue),e(eue,Ivo),e(us,Nvo),e(us,rj),e(rj,qvo),e(us,Dvo),e(us,tj),e(tj,jvo),e(us,Gvo),e(k,Ovo),e(k,ps),e(ps,oue),e(oue,Vvo),e(ps,Xvo),e(ps,aj),e(aj,zvo),e(ps,Qvo),e(ps,nj),e(nj,Wvo),e(ps,Uvo),e(k,Hvo),e(k,_s),e(_s,rue),e(rue,Jvo),e(_s,Yvo),e(_s,sj),e(sj,Zvo),e(_s,Kvo),e(_s,lj),e(lj,eFo),e(_s,oFo),e(k,rFo),e(k,Lu),e(Lu,tue),e(tue,tFo),e(Lu,aFo),e(Lu,ij),e(ij,nFo),e(Lu,sFo),e(k,lFo),e(k,bs),e(bs,aue),e(aue,iFo),e(bs,dFo),e(bs,dj),e(dj,mFo),e(bs,cFo),e(bs,mj),e(mj,fFo),e(bs,gFo),e(k,hFo),e(k,yu),e(yu,nue),e(nue,uFo),e(yu,pFo),e(yu,cj),e(cj,_Fo),e(yu,bFo),e(k,vFo),e(k,xu),e(xu,sue),e(sue,FFo),e(xu,TFo),e(xu,fj),e(fj,MFo),e(xu,EFo),e(k,CFo),e(k,$u),e($u,lue),e(lue,wFo),e($u,AFo),e($u,gj),e(gj,LFo),e($u,yFo),e(k,xFo),e(k,vs),e(vs,iue),e(iue,$Fo),e(vs,kFo),e(vs,hj),e(hj,SFo),e(vs,RFo),e(vs,uj),e(uj,PFo),e(vs,BFo),e(k,IFo),e(k,Fs),e(Fs,due),e(due,NFo),e(Fs,qFo),e(Fs,pj),e(pj,DFo),e(Fs,jFo),e(Fs,_j),e(_j,GFo),e(Fs,OFo),e(k,VFo),e(k,Ts),e(Ts,mue),e(mue,XFo),e(Ts,zFo),e(Ts,bj),e(bj,QFo),e(Ts,WFo),e(Ts,vj),e(vj,UFo),e(Ts,HFo),e(k,JFo),e(k,ku),e(ku,cue),e(cue,YFo),e(ku,ZFo),e(ku,Fj),e(Fj,KFo),e(ku,eTo),e(k,oTo),e(k,Su),e(Su,fue),e(fue,rTo),e(Su,tTo),e(Su,Tj),e(Tj,aTo),e(Su,nTo),e(k,sTo),e(k,Ru),e(Ru,gue),e(gue,lTo),e(Ru,iTo),e(Ru,Mj),e(Mj,dTo),e(Ru,mTo),e(k,cTo),e(k,Ms),e(Ms,hue),e(hue,fTo),e(Ms,gTo),e(Ms,Ej),e(Ej,hTo),e(Ms,uTo),e(Ms,Cj),e(Cj,pTo),e(Ms,_To),e(k,bTo),e(k,Pu),e(Pu,uue),e(uue,vTo),e(Pu,FTo),e(Pu,wj),e(wj,TTo),e(Pu,MTo),e(k,ETo),e(k,Es),e(Es,pue),e(pue,CTo),e(Es,wTo),e(Es,Aj),e(Aj,ATo),e(Es,LTo),e(Es,Lj),e(Lj,yTo),e(Es,xTo),e(k,$To),e(k,Cs),e(Cs,_ue),e(_ue,kTo),e(Cs,STo),e(Cs,yj),e(yj,RTo),e(Cs,PTo),e(Cs,xj),e(xj,BTo),e(Cs,ITo),e(k,NTo),e(k,ws),e(ws,bue),e(bue,qTo),e(ws,DTo),e(ws,$j),e($j,jTo),e(ws,GTo),e(ws,kj),e(kj,OTo),e(ws,VTo),e(k,XTo),e(k,As),e(As,vue),e(vue,zTo),e(As,QTo),e(As,Sj),e(Sj,WTo),e(As,UTo),e(As,Rj),e(Rj,HTo),e(As,JTo),e(k,YTo),e(k,Bu),e(Bu,Fue),e(Fue,ZTo),e(Bu,KTo),e(Bu,Pj),e(Pj,eMo),e(Bu,oMo),e(k,rMo),e(k,Ls),e(Ls,Tue),e(Tue,tMo),e(Ls,aMo),e(Ls,Bj),e(Bj,nMo),e(Ls,sMo),e(Ls,Ij),e(Ij,lMo),e(Ls,iMo),e(k,dMo),e(k,ys),e(ys,Mue),e(Mue,mMo),e(ys,cMo),e(ys,Nj),e(Nj,fMo),e(ys,gMo),e(ys,qj),e(qj,hMo),e(ys,uMo),e(k,pMo),e(k,xs),e(xs,Eue),e(Eue,_Mo),e(xs,bMo),e(xs,Dj),e(Dj,vMo),e(xs,FMo),e(xs,jj),e(jj,TMo),e(xs,MMo),e(k,EMo),e(k,$s),e($s,Cue),e(Cue,CMo),e($s,wMo),e($s,Gj),e(Gj,AMo),e($s,LMo),e($s,Oj),e(Oj,yMo),e($s,xMo),e(k,$Mo),e(k,ks),e(ks,wue),e(wue,kMo),e(ks,SMo),e(ks,Vj),e(Vj,RMo),e(ks,PMo),e(ks,Xj),e(Xj,BMo),e(ks,IMo),e(k,NMo),e(k,Ss),e(Ss,Aue),e(Aue,qMo),e(Ss,DMo),e(Ss,zj),e(zj,jMo),e(Ss,GMo),e(Ss,Qj),e(Qj,OMo),e(Ss,VMo),e(k,XMo),e(k,Rs),e(Rs,Lue),e(Lue,zMo),e(Rs,QMo),e(Rs,Wj),e(Wj,WMo),e(Rs,UMo),e(Rs,Uj),e(Uj,HMo),e(Rs,JMo),e(k,YMo),e(k,Iu),e(Iu,yue),e(yue,ZMo),e(Iu,KMo),e(Iu,Hj),e(Hj,eEo),e(Iu,oEo),e(k,rEo),e(k,Nu),e(Nu,xue),e(xue,tEo),e(Nu,aEo),e(Nu,Jj),e(Jj,nEo),e(Nu,sEo),e(k,lEo),e(k,Ps),e(Ps,$ue),e($ue,iEo),e(Ps,dEo),e(Ps,Yj),e(Yj,mEo),e(Ps,cEo),e(Ps,Zj),e(Zj,fEo),e(Ps,gEo),e(k,hEo),e(k,qu),e(qu,kue),e(kue,uEo),e(qu,pEo),e(qu,Kj),e(Kj,_Eo),e(qu,bEo),e(k,vEo),e(k,Bs),e(Bs,Sue),e(Sue,FEo),e(Bs,TEo),e(Bs,eG),e(eG,MEo),e(Bs,EEo),e(Bs,oG),e(oG,CEo),e(Bs,wEo),e(k,AEo),e(k,Is),e(Is,Rue),e(Rue,LEo),e(Is,yEo),e(Is,rG),e(rG,xEo),e(Is,$Eo),e(Is,tG),e(tG,kEo),e(Is,SEo),e(k,REo),e(k,Ns),e(Ns,Pue),e(Pue,PEo),e(Ns,BEo),e(Ns,aG),e(aG,IEo),e(Ns,NEo),e(Ns,nG),e(nG,qEo),e(Ns,DEo),e(k,jEo),e(k,Du),e(Du,Bue),e(Bue,GEo),e(Du,OEo),e(Du,sG),e(sG,VEo),e(Du,XEo),e(k,zEo),e(k,ju),e(ju,Iue),e(Iue,QEo),e(ju,WEo),e(ju,lG),e(lG,UEo),e(ju,HEo),e(k,JEo),e(k,qs),e(qs,Nue),e(Nue,YEo),e(qs,ZEo),e(qs,iG),e(iG,KEo),e(qs,e4o),e(qs,dG),e(dG,o4o),e(qs,r4o),e(k,t4o),e(k,Ds),e(Ds,que),e(que,a4o),e(Ds,n4o),e(Ds,mG),e(mG,s4o),e(Ds,l4o),e(Ds,cG),e(cG,i4o),e(Ds,d4o),e(k,m4o),e(k,js),e(js,Due),e(Due,c4o),e(js,f4o),e(js,fG),e(fG,g4o),e(js,h4o),e(js,gG),e(gG,u4o),e(js,p4o),e(k,_4o),e(k,Gu),e(Gu,jue),e(jue,b4o),e(Gu,v4o),e(Gu,hG),e(hG,F4o),e(Gu,T4o),e(k,M4o),e(k,Gs),e(Gs,Gue),e(Gue,E4o),e(Gs,C4o),e(Gs,uG),e(uG,w4o),e(Gs,A4o),e(Gs,pG),e(pG,L4o),e(Gs,y4o),e(k,x4o),e(k,Os),e(Os,Oue),e(Oue,$4o),e(Os,k4o),e(Os,_G),e(_G,S4o),e(Os,R4o),e(Os,bG),e(bG,P4o),e(Os,B4o),e(k,I4o),e(k,Vs),e(Vs,Vue),e(Vue,N4o),e(Vs,q4o),e(Vs,vG),e(vG,D4o),e(Vs,j4o),e(Vs,FG),e(FG,G4o),e(Vs,O4o),e(k,V4o),e(k,Xs),e(Xs,Xue),e(Xue,X4o),e(Xs,z4o),e(Xs,TG),e(TG,Q4o),e(Xs,W4o),e(Xs,MG),e(MG,U4o),e(Xs,H4o),e(k,J4o),e(k,zs),e(zs,zue),e(zue,Y4o),e(zs,Z4o),e(zs,EG),e(EG,K4o),e(zs,eCo),e(zs,CG),e(CG,oCo),e(zs,rCo),e(k,tCo),e(k,Qs),e(Qs,Que),e(Que,aCo),e(Qs,nCo),e(Qs,wG),e(wG,sCo),e(Qs,lCo),e(Qs,AG),e(AG,iCo),e(Qs,dCo),e(k,mCo),e(k,Ws),e(Ws,Wue),e(Wue,cCo),e(Ws,fCo),e(Ws,LG),e(LG,gCo),e(Ws,hCo),e(Ws,yG),e(yG,uCo),e(Ws,pCo),e(k,_Co),e(k,Us),e(Us,Uue),e(Uue,bCo),e(Us,vCo),e(Us,xG),e(xG,FCo),e(Us,TCo),e(Us,$G),e($G,MCo),e(Us,ECo),e(k,CCo),e(k,Hs),e(Hs,Hue),e(Hue,wCo),e(Hs,ACo),e(Hs,kG),e(kG,LCo),e(Hs,yCo),e(Hs,SG),e(SG,xCo),e(Hs,$Co),e(k,kCo),e(k,Ou),e(Ou,Jue),e(Jue,SCo),e(Ou,RCo),e(Ou,RG),e(RG,PCo),e(Ou,BCo),e(k,ICo),e(k,Js),e(Js,Yue),e(Yue,NCo),e(Js,qCo),e(Js,PG),e(PG,DCo),e(Js,jCo),e(Js,BG),e(BG,GCo),e(Js,OCo),e(k,VCo),e(k,Vu),e(Vu,Zue),e(Zue,XCo),e(Vu,zCo),e(Vu,IG),e(IG,QCo),e(Vu,WCo),e(k,UCo),e(k,Xu),e(Xu,Kue),e(Kue,HCo),e(Xu,JCo),e(Xu,NG),e(NG,YCo),e(Xu,ZCo),e(k,KCo),e(k,Ys),e(Ys,epe),e(epe,e3o),e(Ys,o3o),e(Ys,qG),e(qG,r3o),e(Ys,t3o),e(Ys,DG),e(DG,a3o),e(Ys,n3o),e(k,s3o),e(k,Zs),e(Zs,ope),e(ope,l3o),e(Zs,i3o),e(Zs,jG),e(jG,d3o),e(Zs,m3o),e(Zs,GG),e(GG,c3o),e(Zs,f3o),e(k,g3o),e(k,Ks),e(Ks,rpe),e(rpe,h3o),e(Ks,u3o),e(Ks,OG),e(OG,p3o),e(Ks,_3o),e(Ks,VG),e(VG,b3o),e(Ks,v3o),e(k,F3o),e(k,zu),e(zu,tpe),e(tpe,T3o),e(zu,M3o),e(zu,XG),e(XG,E3o),e(zu,C3o),e(k,w3o),e(k,el),e(el,ape),e(ape,A3o),e(el,L3o),e(el,zG),e(zG,y3o),e(el,x3o),e(el,QG),e(QG,$3o),e(el,k3o),e(k,S3o),e(k,ol),e(ol,npe),e(npe,R3o),e(ol,P3o),e(ol,WG),e(WG,B3o),e(ol,I3o),e(ol,UG),e(UG,N3o),e(ol,q3o),e(k,D3o),e(k,rl),e(rl,spe),e(spe,j3o),e(rl,G3o),e(rl,HG),e(HG,O3o),e(rl,V3o),e(rl,JG),e(JG,X3o),e(rl,z3o),e(k,Q3o),e(k,tl),e(tl,lpe),e(lpe,W3o),e(tl,U3o),e(tl,YG),e(YG,H3o),e(tl,J3o),e(tl,ZG),e(ZG,Y3o),e(tl,Z3o),e(k,K3o),e(k,al),e(al,ipe),e(ipe,e5o),e(al,o5o),e(al,KG),e(KG,r5o),e(al,t5o),e(al,eO),e(eO,a5o),e(al,n5o),e(k,s5o),e(k,nl),e(nl,dpe),e(dpe,l5o),e(nl,i5o),e(nl,oO),e(oO,d5o),e(nl,m5o),e(nl,rO),e(rO,c5o),e(nl,f5o),e(k,g5o),e(k,sl),e(sl,mpe),e(mpe,h5o),e(sl,u5o),e(sl,tO),e(tO,p5o),e(sl,_5o),e(sl,aO),e(aO,b5o),e(sl,v5o),e(k,F5o),e(k,ll),e(ll,cpe),e(cpe,T5o),e(ll,M5o),e(ll,nO),e(nO,E5o),e(ll,C5o),e(ll,sO),e(sO,w5o),e(ll,A5o),e(k,L5o),e(k,Qu),e(Qu,fpe),e(fpe,y5o),e(Qu,x5o),e(Qu,lO),e(lO,$5o),e(Qu,k5o),e(k,S5o),e(k,il),e(il,gpe),e(gpe,R5o),e(il,P5o),e(il,iO),e(iO,B5o),e(il,I5o),e(il,dO),e(dO,N5o),e(il,q5o),e(k,D5o),e(k,dl),e(dl,hpe),e(hpe,j5o),e(dl,G5o),e(dl,mO),e(mO,O5o),e(dl,V5o),e(dl,cO),e(cO,X5o),e(dl,z5o),e(k,Q5o),e(k,Wu),e(Wu,upe),e(upe,W5o),e(Wu,U5o),e(Wu,fO),e(fO,H5o),e(Wu,J5o),e(k,Y5o),e(k,Uu),e(Uu,ppe),e(ppe,Z5o),e(Uu,K5o),e(Uu,gO),e(gO,e0o),e(Uu,o0o),e(k,r0o),e(k,Hu),e(Hu,_pe),e(_pe,t0o),e(Hu,a0o),e(Hu,hO),e(hO,n0o),e(Hu,s0o),e(k,l0o),e(k,Ju),e(Ju,bpe),e(bpe,i0o),e(Ju,d0o),e(Ju,uO),e(uO,m0o),e(Ju,c0o),e(k,f0o),e(k,ml),e(ml,vpe),e(vpe,g0o),e(ml,h0o),e(ml,pO),e(pO,u0o),e(ml,p0o),e(ml,_O),e(_O,_0o),e(ml,b0o),e(k,v0o),e(k,Yu),e(Yu,Fpe),e(Fpe,F0o),e(Yu,T0o),e(Yu,bO),e(bO,M0o),e(Yu,E0o),e(k,C0o),e(k,cl),e(cl,Tpe),e(Tpe,w0o),e(cl,A0o),e(cl,vO),e(vO,L0o),e(cl,y0o),e(cl,FO),e(FO,x0o),e(cl,$0o),e(k,k0o),e(k,fl),e(fl,Mpe),e(Mpe,S0o),e(fl,R0o),e(fl,TO),e(TO,P0o),e(fl,B0o),e(fl,MO),e(MO,I0o),e(fl,N0o),e(k,q0o),e(k,gl),e(gl,Epe),e(Epe,D0o),e(gl,j0o),e(gl,EO),e(EO,G0o),e(gl,O0o),e(gl,CO),e(CO,V0o),e(gl,X0o),e(k,z0o),e(k,hl),e(hl,Cpe),e(Cpe,Q0o),e(hl,W0o),e(hl,wO),e(wO,U0o),e(hl,H0o),e(hl,AO),e(AO,J0o),e(hl,Y0o),e(k,Z0o),e(k,ul),e(ul,wpe),e(wpe,K0o),e(ul,ewo),e(ul,LO),e(LO,owo),e(ul,rwo),e(ul,yO),e(yO,two),e(ul,awo),e(k,nwo),e(k,pl),e(pl,Ape),e(Ape,swo),e(pl,lwo),e(pl,xO),e(xO,iwo),e(pl,dwo),e(pl,$O),e($O,mwo),e(pl,cwo),e(k,fwo),e(k,Zu),e(Zu,Lpe),e(Lpe,gwo),e(Zu,hwo),e(Zu,kO),e(kO,uwo),e(Zu,pwo),e(k,_wo),e(k,Ku),e(Ku,ype),e(ype,bwo),e(Ku,vwo),e(Ku,SO),e(SO,Fwo),e(Ku,Two),e(k,Mwo),e(k,_l),e(_l,xpe),e(xpe,Ewo),e(_l,Cwo),e(_l,RO),e(RO,wwo),e(_l,Awo),e(_l,PO),e(PO,Lwo),e(_l,ywo),e(k,xwo),e(k,bl),e(bl,$pe),e($pe,$wo),e(bl,kwo),e(bl,BO),e(BO,Swo),e(bl,Rwo),e(bl,IO),e(IO,Pwo),e(bl,Bwo),e(k,Iwo),e(k,vl),e(vl,kpe),e(kpe,Nwo),e(vl,qwo),e(vl,NO),e(NO,Dwo),e(vl,jwo),e(vl,qO),e(qO,Gwo),e(vl,Owo),e(k,Vwo),e(k,ep),e(ep,Spe),e(Spe,Xwo),e(ep,zwo),e(ep,DO),e(DO,Qwo),e(ep,Wwo),e(k,Uwo),e(k,op),e(op,Rpe),e(Rpe,Hwo),e(op,Jwo),e(op,jO),e(jO,Ywo),e(op,Zwo),e(k,Kwo),e(k,rp),e(rp,Ppe),e(Ppe,eAo),e(rp,oAo),e(rp,GO),e(GO,rAo),e(rp,tAo),e(k,aAo),e(k,Fl),e(Fl,Bpe),e(Bpe,nAo),e(Fl,sAo),e(Fl,OO),e(OO,lAo),e(Fl,iAo),e(Fl,VO),e(VO,dAo),e(Fl,mAo),e(k,cAo),e(k,Tl),e(Tl,Ipe),e(Ipe,fAo),e(Tl,gAo),e(Tl,XO),e(XO,hAo),e(Tl,uAo),e(Tl,zO),e(zO,pAo),e(Tl,_Ao),e(k,bAo),e(k,tp),e(tp,Npe),e(Npe,vAo),e(tp,FAo),e(tp,QO),e(QO,TAo),e(tp,MAo),e(k,EAo),e(k,ap),e(ap,qpe),e(qpe,CAo),e(ap,wAo),e(ap,WO),e(WO,AAo),e(ap,LAo),e(k,yAo),e(k,np),e(np,Dpe),e(Dpe,xAo),e(np,$Ao),e(np,UO),e(UO,kAo),e(np,SAo),e(k,RAo),e(k,sp),e(sp,jpe),e(jpe,PAo),e(sp,BAo),e(sp,HO),e(HO,IAo),e(sp,NAo),e(k,qAo),e(k,Ml),e(Ml,Gpe),e(Gpe,DAo),e(Ml,jAo),e(Ml,JO),e(JO,GAo),e(Ml,OAo),e(Ml,YO),e(YO,VAo),e(Ml,XAo),e(k,zAo),e(k,El),e(El,Ope),e(Ope,QAo),e(El,WAo),e(El,ZO),e(ZO,UAo),e(El,HAo),e(El,KO),e(KO,JAo),e(El,YAo),e(k,ZAo),e(k,lp),e(lp,Vpe),e(Vpe,KAo),e(lp,e6o),e(lp,eV),e(eV,o6o),e(lp,r6o),e(k,t6o),e(k,ip),e(ip,Xpe),e(Xpe,a6o),e(ip,n6o),e(ip,oV),e(oV,s6o),e(ip,l6o),e(k,i6o),e(k,Cl),e(Cl,zpe),e(zpe,d6o),e(Cl,m6o),e(Cl,rV),e(rV,c6o),e(Cl,f6o),e(Cl,tV),e(tV,g6o),e(Cl,h6o),e(k,u6o),e(k,wl),e(wl,Qpe),e(Qpe,p6o),e(wl,_6o),e(wl,aV),e(aV,b6o),e(wl,v6o),e(wl,nV),e(nV,F6o),e(wl,T6o),e(k,M6o),e(k,Al),e(Al,Wpe),e(Wpe,E6o),e(Al,C6o),e(Al,sV),e(sV,w6o),e(Al,A6o),e(Al,lV),e(lV,L6o),e(Al,y6o),e(k,x6o),e(k,Ll),e(Ll,Upe),e(Upe,$6o),e(Ll,k6o),e(Ll,iV),e(iV,S6o),e(Ll,R6o),e(Ll,dV),e(dV,P6o),e(Ll,B6o),e(Dr,I6o),M(dp,Dr,null),e(Ro,N6o),e(Ro,mp),M(M$,mp,null),e(mp,q6o),e(mp,Hpe),e(Hpe,D6o),b(c,Rto,_),b(c,yd,_),e(yd,cp),e(cp,Jpe),M(E$,Jpe,null),e(yd,j6o),e(yd,Ype),e(Ype,G6o),b(c,Pto,_),b(c,Po,_),M(C$,Po,null),e(Po,O6o),e(Po,w$),e(w$,V6o),e(w$,mV),e(mV,X6o),e(w$,z6o),e(Po,Q6o),e(Po,A$),e(A$,W6o),e(A$,Zpe),e(Zpe,U6o),e(A$,H6o),e(Po,J6o),e(Po,Ye),M(L$,Ye,null),e(Ye,Y6o),e(Ye,Kpe),e(Kpe,Z6o),e(Ye,K6o),e(Ye,an),e(an,e7o),e(an,e_e),e(e_e,o7o),e(an,r7o),e(an,o_e),e(o_e,t7o),e(an,a7o),e(an,r_e),e(r_e,n7o),e(an,s7o),e(Ye,l7o),e(Ye,z),e(z,fp),e(fp,t_e),e(t_e,i7o),e(fp,d7o),e(fp,cV),e(cV,m7o),e(fp,c7o),e(z,f7o),e(z,gp),e(gp,a_e),e(a_e,g7o),e(gp,h7o),e(gp,fV),e(fV,u7o),e(gp,p7o),e(z,_7o),e(z,hp),e(hp,n_e),e(n_e,b7o),e(hp,v7o),e(hp,gV),e(gV,F7o),e(hp,T7o),e(z,M7o),e(z,up),e(up,s_e),e(s_e,E7o),e(up,C7o),e(up,hV),e(hV,w7o),e(up,A7o),e(z,L7o),e(z,pp),e(pp,l_e),e(l_e,y7o),e(pp,x7o),e(pp,uV),e(uV,$7o),e(pp,k7o),e(z,S7o),e(z,_p),e(_p,i_e),e(i_e,R7o),e(_p,P7o),e(_p,pV),e(pV,B7o),e(_p,I7o),e(z,N7o),e(z,bp),e(bp,d_e),e(d_e,q7o),e(bp,D7o),e(bp,_V),e(_V,j7o),e(bp,G7o),e(z,O7o),e(z,vp),e(vp,m_e),e(m_e,V7o),e(vp,X7o),e(vp,bV),e(bV,z7o),e(vp,Q7o),e(z,W7o),e(z,Fp),e(Fp,c_e),e(c_e,U7o),e(Fp,H7o),e(Fp,vV),e(vV,J7o),e(Fp,Y7o),e(z,Z7o),e(z,Tp),e(Tp,f_e),e(f_e,K7o),e(Tp,e8o),e(Tp,FV),e(FV,o8o),e(Tp,r8o),e(z,t8o),e(z,Mp),e(Mp,g_e),e(g_e,a8o),e(Mp,n8o),e(Mp,TV),e(TV,s8o),e(Mp,l8o),e(z,i8o),e(z,Ep),e(Ep,h_e),e(h_e,d8o),e(Ep,m8o),e(Ep,MV),e(MV,c8o),e(Ep,f8o),e(z,g8o),e(z,Cp),e(Cp,u_e),e(u_e,h8o),e(Cp,u8o),e(Cp,EV),e(EV,p8o),e(Cp,_8o),e(z,b8o),e(z,wp),e(wp,p_e),e(p_e,v8o),e(wp,F8o),e(wp,CV),e(CV,T8o),e(wp,M8o),e(z,E8o),e(z,Ap),e(Ap,__e),e(__e,C8o),e(Ap,w8o),e(Ap,wV),e(wV,A8o),e(Ap,L8o),e(z,y8o),e(z,Lp),e(Lp,b_e),e(b_e,x8o),e(Lp,$8o),e(Lp,AV),e(AV,k8o),e(Lp,S8o),e(z,R8o),e(z,yp),e(yp,v_e),e(v_e,P8o),e(yp,B8o),e(yp,LV),e(LV,I8o),e(yp,N8o),e(z,q8o),e(z,xp),e(xp,F_e),e(F_e,D8o),e(xp,j8o),e(xp,yV),e(yV,G8o),e(xp,O8o),e(z,V8o),e(z,$p),e($p,T_e),e(T_e,X8o),e($p,z8o),e($p,xV),e(xV,Q8o),e($p,W8o),e(z,U8o),e(z,kp),e(kp,M_e),e(M_e,H8o),e(kp,J8o),e(kp,$V),e($V,Y8o),e(kp,Z8o),e(z,K8o),e(z,Sp),e(Sp,E_e),e(E_e,eLo),e(Sp,oLo),e(Sp,kV),e(kV,rLo),e(Sp,tLo),e(z,aLo),e(z,Rp),e(Rp,C_e),e(C_e,nLo),e(Rp,sLo),e(Rp,SV),e(SV,lLo),e(Rp,iLo),e(z,dLo),e(z,Pp),e(Pp,w_e),e(w_e,mLo),e(Pp,cLo),e(Pp,RV),e(RV,fLo),e(Pp,gLo),e(z,hLo),e(z,Bp),e(Bp,A_e),e(A_e,uLo),e(Bp,pLo),e(Bp,PV),e(PV,_Lo),e(Bp,bLo),e(z,vLo),e(z,Ip),e(Ip,L_e),e(L_e,FLo),e(Ip,TLo),e(Ip,BV),e(BV,MLo),e(Ip,ELo),e(z,CLo),e(z,Np),e(Np,y_e),e(y_e,wLo),e(Np,ALo),e(Np,IV),e(IV,LLo),e(Np,yLo),e(z,xLo),e(z,qp),e(qp,x_e),e(x_e,$Lo),e(qp,kLo),e(qp,NV),e(NV,SLo),e(qp,RLo),e(z,PLo),e(z,Dp),e(Dp,$_e),e($_e,BLo),e(Dp,ILo),e(Dp,qV),e(qV,NLo),e(Dp,qLo),e(z,DLo),e(z,jp),e(jp,k_e),e(k_e,jLo),e(jp,GLo),e(jp,DV),e(DV,OLo),e(jp,VLo),e(z,XLo),e(z,Gp),e(Gp,S_e),e(S_e,zLo),e(Gp,QLo),e(Gp,jV),e(jV,WLo),e(Gp,ULo),e(z,HLo),e(z,Op),e(Op,R_e),e(R_e,JLo),e(Op,YLo),e(Op,GV),e(GV,ZLo),e(Op,KLo),e(z,eyo),e(z,Vp),e(Vp,P_e),e(P_e,oyo),e(Vp,ryo),e(Vp,OV),e(OV,tyo),e(Vp,ayo),e(z,nyo),e(z,Xp),e(Xp,B_e),e(B_e,syo),e(Xp,lyo),e(Xp,VV),e(VV,iyo),e(Xp,dyo),e(z,myo),e(z,zp),e(zp,I_e),e(I_e,cyo),e(zp,fyo),e(zp,XV),e(XV,gyo),e(zp,hyo),e(z,uyo),e(z,Qp),e(Qp,N_e),e(N_e,pyo),e(Qp,_yo),e(Qp,zV),e(zV,byo),e(Qp,vyo),e(z,Fyo),e(z,Wp),e(Wp,q_e),e(q_e,Tyo),e(Wp,Myo),e(Wp,QV),e(QV,Eyo),e(Wp,Cyo),e(z,wyo),e(z,Up),e(Up,D_e),e(D_e,Ayo),e(Up,Lyo),e(Up,WV),e(WV,yyo),e(Up,xyo),e(z,$yo),e(z,Hp),e(Hp,j_e),e(j_e,kyo),e(Hp,Syo),e(Hp,UV),e(UV,Ryo),e(Hp,Pyo),e(z,Byo),e(z,Jp),e(Jp,G_e),e(G_e,Iyo),e(Jp,Nyo),e(Jp,HV),e(HV,qyo),e(Jp,Dyo),e(z,jyo),e(z,Yp),e(Yp,O_e),e(O_e,Gyo),e(Yp,Oyo),e(Yp,JV),e(JV,Vyo),e(Yp,Xyo),e(z,zyo),e(z,Zp),e(Zp,V_e),e(V_e,Qyo),e(Zp,Wyo),e(Zp,YV),e(YV,Uyo),e(Zp,Hyo),e(z,Jyo),e(z,Kp),e(Kp,X_e),e(X_e,Yyo),e(Kp,Zyo),e(Kp,ZV),e(ZV,Kyo),e(Kp,e9o),e(z,o9o),e(z,e_),e(e_,z_e),e(z_e,r9o),e(e_,t9o),e(e_,KV),e(KV,a9o),e(e_,n9o),e(z,s9o),e(z,o_),e(o_,Q_e),e(Q_e,l9o),e(o_,i9o),e(o_,eX),e(eX,d9o),e(o_,m9o),e(Ye,c9o),M(r_,Ye,null),e(Ye,f9o),M(t_,Ye,null),e(Po,g9o),e(Po,a_),M(y$,a_,null),e(a_,h9o),e(a_,W_e),e(W_e,u9o),b(c,Bto,_),b(c,xd,_),e(xd,n_),e(n_,U_e),M(x$,U_e,null),e(xd,p9o),e(xd,H_e),e(H_e,_9o),b(c,Ito,_),b(c,Bo,_),M($$,Bo,null),e(Bo,b9o),e(Bo,k$),e(k$,v9o),e(k$,oX),e(oX,F9o),e(k$,T9o),e(Bo,M9o),e(Bo,S$),e(S$,E9o),e(S$,J_e),e(J_e,C9o),e(S$,w9o),e(Bo,A9o),e(Bo,Ze),M(R$,Ze,null),e(Ze,L9o),e(Ze,Y_e),e(Y_e,y9o),e(Ze,x9o),e(Ze,$d),e($d,$9o),e($d,Z_e),e(Z_e,k9o),e($d,S9o),e($d,K_e),e(K_e,R9o),e($d,P9o),e(Ze,B9o),e(Ze,se),e(se,s_),e(s_,e1e),e(e1e,I9o),e(s_,N9o),e(s_,rX),e(rX,q9o),e(s_,D9o),e(se,j9o),e(se,l_),e(l_,o1e),e(o1e,G9o),e(l_,O9o),e(l_,tX),e(tX,V9o),e(l_,X9o),e(se,z9o),e(se,i_),e(i_,r1e),e(r1e,Q9o),e(i_,W9o),e(i_,aX),e(aX,U9o),e(i_,H9o),e(se,J9o),e(se,d_),e(d_,t1e),e(t1e,Y9o),e(d_,Z9o),e(d_,nX),e(nX,K9o),e(d_,exo),e(se,oxo),e(se,m_),e(m_,a1e),e(a1e,rxo),e(m_,txo),e(m_,sX),e(sX,axo),e(m_,nxo),e(se,sxo),e(se,c_),e(c_,n1e),e(n1e,lxo),e(c_,ixo),e(c_,lX),e(lX,dxo),e(c_,mxo),e(se,cxo),e(se,f_),e(f_,s1e),e(s1e,fxo),e(f_,gxo),e(f_,iX),e(iX,hxo),e(f_,uxo),e(se,pxo),e(se,g_),e(g_,l1e),e(l1e,_xo),e(g_,bxo),e(g_,dX),e(dX,vxo),e(g_,Fxo),e(se,Txo),e(se,h_),e(h_,i1e),e(i1e,Mxo),e(h_,Exo),e(h_,mX),e(mX,Cxo),e(h_,wxo),e(se,Axo),e(se,u_),e(u_,d1e),e(d1e,Lxo),e(u_,yxo),e(u_,cX),e(cX,xxo),e(u_,$xo),e(se,kxo),e(se,p_),e(p_,m1e),e(m1e,Sxo),e(p_,Rxo),e(p_,fX),e(fX,Pxo),e(p_,Bxo),e(se,Ixo),e(se,__),e(__,c1e),e(c1e,Nxo),e(__,qxo),e(__,gX),e(gX,Dxo),e(__,jxo),e(se,Gxo),e(se,b_),e(b_,f1e),e(f1e,Oxo),e(b_,Vxo),e(b_,hX),e(hX,Xxo),e(b_,zxo),e(se,Qxo),e(se,v_),e(v_,g1e),e(g1e,Wxo),e(v_,Uxo),e(v_,uX),e(uX,Hxo),e(v_,Jxo),e(se,Yxo),e(se,F_),e(F_,h1e),e(h1e,Zxo),e(F_,Kxo),e(F_,pX),e(pX,e$o),e(F_,o$o),e(se,r$o),e(se,T_),e(T_,u1e),e(u1e,t$o),e(T_,a$o),e(T_,_X),e(_X,n$o),e(T_,s$o),e(se,l$o),e(se,M_),e(M_,p1e),e(p1e,i$o),e(M_,d$o),e(M_,bX),e(bX,m$o),e(M_,c$o),e(se,f$o),e(se,E_),e(E_,_1e),e(_1e,g$o),e(E_,h$o),e(E_,vX),e(vX,u$o),e(E_,p$o),e(se,_$o),e(se,C_),e(C_,b1e),e(b1e,b$o),e(C_,v$o),e(C_,FX),e(FX,F$o),e(C_,T$o),e(se,M$o),e(se,w_),e(w_,v1e),e(v1e,E$o),e(w_,C$o),e(w_,TX),e(TX,w$o),e(w_,A$o),e(se,L$o),e(se,A_),e(A_,F1e),e(F1e,y$o),e(A_,x$o),e(A_,MX),e(MX,$$o),e(A_,k$o),e(se,S$o),e(se,L_),e(L_,T1e),e(T1e,R$o),e(L_,P$o),e(L_,EX),e(EX,B$o),e(L_,I$o),e(se,N$o),e(se,y_),e(y_,M1e),e(M1e,q$o),e(y_,D$o),e(y_,CX),e(CX,j$o),e(y_,G$o),e(Ze,O$o),M(x_,Ze,null),e(Ze,V$o),M($_,Ze,null),e(Bo,X$o),e(Bo,k_),M(P$,k_,null),e(k_,z$o),e(k_,E1e),e(E1e,Q$o),b(c,Nto,_),b(c,kd,_),e(kd,S_),e(S_,C1e),M(B$,C1e,null),e(kd,W$o),e(kd,w1e),e(w1e,U$o),b(c,qto,_),b(c,Io,_),M(I$,Io,null),e(Io,H$o),e(Io,Sd),e(Sd,J$o),e(Sd,wX),e(wX,Y$o),e(Sd,Z$o),e(Sd,AX),e(AX,K$o),e(Sd,eko),e(Io,oko),e(Io,N$),e(N$,rko),e(N$,A1e),e(A1e,tko),e(N$,ako),e(Io,nko),e(Io,Mt),M(q$,Mt,null),e(Mt,sko),e(Mt,L1e),e(L1e,lko),e(Mt,iko),e(Mt,Rd),e(Rd,dko),e(Rd,y1e),e(y1e,mko),e(Rd,cko),e(Rd,LX),e(LX,fko),e(Rd,gko),e(Mt,hko),M(R_,Mt,null),e(Io,uko),e(Io,Ke),M(D$,Ke,null),e(Ke,pko),e(Ke,x1e),e(x1e,_ko),e(Ke,bko),e(Ke,nn),e(nn,vko),e(nn,$1e),e($1e,Fko),e(nn,Tko),e(nn,k1e),e(k1e,Mko),e(nn,Eko),e(nn,S1e),e(S1e,Cko),e(nn,wko),e(Ke,Ako),e(Ke,y),e(y,P_),e(P_,R1e),e(R1e,Lko),e(P_,yko),e(P_,yX),e(yX,xko),e(P_,$ko),e(y,kko),e(y,B_),e(B_,P1e),e(P1e,Sko),e(B_,Rko),e(B_,xX),e(xX,Pko),e(B_,Bko),e(y,Iko),e(y,I_),e(I_,B1e),e(B1e,Nko),e(I_,qko),e(I_,$X),e($X,Dko),e(I_,jko),e(y,Gko),e(y,N_),e(N_,I1e),e(I1e,Oko),e(N_,Vko),e(N_,kX),e(kX,Xko),e(N_,zko),e(y,Qko),e(y,q_),e(q_,N1e),e(N1e,Wko),e(q_,Uko),e(q_,SX),e(SX,Hko),e(q_,Jko),e(y,Yko),e(y,D_),e(D_,q1e),e(q1e,Zko),e(D_,Kko),e(D_,RX),e(RX,eSo),e(D_,oSo),e(y,rSo),e(y,j_),e(j_,D1e),e(D1e,tSo),e(j_,aSo),e(j_,PX),e(PX,nSo),e(j_,sSo),e(y,lSo),e(y,G_),e(G_,j1e),e(j1e,iSo),e(G_,dSo),e(G_,BX),e(BX,mSo),e(G_,cSo),e(y,fSo),e(y,O_),e(O_,G1e),e(G1e,gSo),e(O_,hSo),e(O_,IX),e(IX,uSo),e(O_,pSo),e(y,_So),e(y,V_),e(V_,O1e),e(O1e,bSo),e(V_,vSo),e(V_,NX),e(NX,FSo),e(V_,TSo),e(y,MSo),e(y,X_),e(X_,V1e),e(V1e,ESo),e(X_,CSo),e(X_,qX),e(qX,wSo),e(X_,ASo),e(y,LSo),e(y,z_),e(z_,X1e),e(X1e,ySo),e(z_,xSo),e(z_,DX),e(DX,$So),e(z_,kSo),e(y,SSo),e(y,Q_),e(Q_,z1e),e(z1e,RSo),e(Q_,PSo),e(Q_,jX),e(jX,BSo),e(Q_,ISo),e(y,NSo),e(y,W_),e(W_,Q1e),e(Q1e,qSo),e(W_,DSo),e(W_,GX),e(GX,jSo),e(W_,GSo),e(y,OSo),e(y,U_),e(U_,W1e),e(W1e,VSo),e(U_,XSo),e(U_,OX),e(OX,zSo),e(U_,QSo),e(y,WSo),e(y,H_),e(H_,U1e),e(U1e,USo),e(H_,HSo),e(H_,VX),e(VX,JSo),e(H_,YSo),e(y,ZSo),e(y,J_),e(J_,H1e),e(H1e,KSo),e(J_,eRo),e(J_,XX),e(XX,oRo),e(J_,rRo),e(y,tRo),e(y,Y_),e(Y_,J1e),e(J1e,aRo),e(Y_,nRo),e(Y_,zX),e(zX,sRo),e(Y_,lRo),e(y,iRo),e(y,Z_),e(Z_,Y1e),e(Y1e,dRo),e(Z_,mRo),e(Z_,QX),e(QX,cRo),e(Z_,fRo),e(y,gRo),e(y,K_),e(K_,Z1e),e(Z1e,hRo),e(K_,uRo),e(K_,WX),e(WX,pRo),e(K_,_Ro),e(y,bRo),e(y,e1),e(e1,K1e),e(K1e,vRo),e(e1,FRo),e(e1,UX),e(UX,TRo),e(e1,MRo),e(y,ERo),e(y,o1),e(o1,e2e),e(e2e,CRo),e(o1,wRo),e(o1,HX),e(HX,ARo),e(o1,LRo),e(y,yRo),e(y,r1),e(r1,o2e),e(o2e,xRo),e(r1,$Ro),e(r1,JX),e(JX,kRo),e(r1,SRo),e(y,RRo),e(y,t1),e(t1,r2e),e(r2e,PRo),e(t1,BRo),e(t1,YX),e(YX,IRo),e(t1,NRo),e(y,qRo),e(y,a1),e(a1,t2e),e(t2e,DRo),e(a1,jRo),e(a1,ZX),e(ZX,GRo),e(a1,ORo),e(y,VRo),e(y,n1),e(n1,a2e),e(a2e,XRo),e(n1,zRo),e(n1,KX),e(KX,QRo),e(n1,WRo),e(y,URo),e(y,s1),e(s1,n2e),e(n2e,HRo),e(s1,JRo),e(s1,ez),e(ez,YRo),e(s1,ZRo),e(y,KRo),e(y,l1),e(l1,s2e),e(s2e,ePo),e(l1,oPo),e(l1,oz),e(oz,rPo),e(l1,tPo),e(y,aPo),e(y,i1),e(i1,l2e),e(l2e,nPo),e(i1,sPo),e(i1,rz),e(rz,lPo),e(i1,iPo),e(y,dPo),e(y,d1),e(d1,i2e),e(i2e,mPo),e(d1,cPo),e(d1,tz),e(tz,fPo),e(d1,gPo),e(y,hPo),e(y,m1),e(m1,d2e),e(d2e,uPo),e(m1,pPo),e(m1,az),e(az,_Po),e(m1,bPo),e(y,vPo),e(y,c1),e(c1,m2e),e(m2e,FPo),e(c1,TPo),e(c1,nz),e(nz,MPo),e(c1,EPo),e(y,CPo),e(y,f1),e(f1,c2e),e(c2e,wPo),e(f1,APo),e(f1,sz),e(sz,LPo),e(f1,yPo),e(y,xPo),e(y,g1),e(g1,f2e),e(f2e,$Po),e(g1,kPo),e(g1,lz),e(lz,SPo),e(g1,RPo),e(y,PPo),e(y,h1),e(h1,g2e),e(g2e,BPo),e(h1,IPo),e(h1,iz),e(iz,NPo),e(h1,qPo),e(y,DPo),e(y,u1),e(u1,h2e),e(h2e,jPo),e(u1,GPo),e(u1,dz),e(dz,OPo),e(u1,VPo),e(y,XPo),e(y,p1),e(p1,u2e),e(u2e,zPo),e(p1,QPo),e(p1,mz),e(mz,WPo),e(p1,UPo),e(y,HPo),e(y,_1),e(_1,p2e),e(p2e,JPo),e(_1,YPo),e(_1,cz),e(cz,ZPo),e(_1,KPo),e(y,eBo),e(y,b1),e(b1,_2e),e(_2e,oBo),e(b1,rBo),e(b1,fz),e(fz,tBo),e(b1,aBo),e(y,nBo),e(y,yl),e(yl,b2e),e(b2e,sBo),e(yl,lBo),e(yl,gz),e(gz,iBo),e(yl,dBo),e(yl,hz),e(hz,mBo),e(yl,cBo),e(y,fBo),e(y,v1),e(v1,v2e),e(v2e,gBo),e(v1,hBo),e(v1,uz),e(uz,uBo),e(v1,pBo),e(y,_Bo),e(y,F1),e(F1,F2e),e(F2e,bBo),e(F1,vBo),e(F1,pz),e(pz,FBo),e(F1,TBo),e(y,MBo),e(y,T1),e(T1,T2e),e(T2e,EBo),e(T1,CBo),e(T1,_z),e(_z,wBo),e(T1,ABo),e(y,LBo),e(y,M1),e(M1,M2e),e(M2e,yBo),e(M1,xBo),e(M1,bz),e(bz,$Bo),e(M1,kBo),e(y,SBo),e(y,E1),e(E1,E2e),e(E2e,RBo),e(E1,PBo),e(E1,vz),e(vz,BBo),e(E1,IBo),e(y,NBo),e(y,C1),e(C1,C2e),e(C2e,qBo),e(C1,DBo),e(C1,Fz),e(Fz,jBo),e(C1,GBo),e(y,OBo),e(y,w1),e(w1,w2e),e(w2e,VBo),e(w1,XBo),e(w1,Tz),e(Tz,zBo),e(w1,QBo),e(y,WBo),e(y,A1),e(A1,A2e),e(A2e,UBo),e(A1,HBo),e(A1,Mz),e(Mz,JBo),e(A1,YBo),e(y,ZBo),e(y,L1),e(L1,L2e),e(L2e,KBo),e(L1,eIo),e(L1,Ez),e(Ez,oIo),e(L1,rIo),e(y,tIo),e(y,y1),e(y1,y2e),e(y2e,aIo),e(y1,nIo),e(y1,Cz),e(Cz,sIo),e(y1,lIo),e(y,iIo),e(y,x1),e(x1,x2e),e(x2e,dIo),e(x1,mIo),e(x1,wz),e(wz,cIo),e(x1,fIo),e(y,gIo),e(y,$1),e($1,$2e),e($2e,hIo),e($1,uIo),e($1,Az),e(Az,pIo),e($1,_Io),e(y,bIo),e(y,k1),e(k1,k2e),e(k2e,vIo),e(k1,FIo),e(k1,Lz),e(Lz,TIo),e(k1,MIo),e(y,EIo),e(y,S1),e(S1,S2e),e(S2e,CIo),e(S1,wIo),e(S1,yz),e(yz,AIo),e(S1,LIo),e(y,yIo),e(y,R1),e(R1,R2e),e(R2e,xIo),e(R1,$Io),e(R1,xz),e(xz,kIo),e(R1,SIo),e(y,RIo),e(y,P1),e(P1,P2e),e(P2e,PIo),e(P1,BIo),e(P1,$z),e($z,IIo),e(P1,NIo),e(y,qIo),e(y,B1),e(B1,B2e),e(B2e,DIo),e(B1,jIo),e(B1,kz),e(kz,GIo),e(B1,OIo),e(y,VIo),e(y,I1),e(I1,I2e),e(I2e,XIo),e(I1,zIo),e(I1,Sz),e(Sz,QIo),e(I1,WIo),e(y,UIo),e(y,N1),e(N1,N2e),e(N2e,HIo),e(N1,JIo),e(N1,Rz),e(Rz,YIo),e(N1,ZIo),e(y,KIo),e(y,q1),e(q1,q2e),e(q2e,eNo),e(q1,oNo),e(q1,Pz),e(Pz,rNo),e(q1,tNo),e(y,aNo),e(y,D1),e(D1,D2e),e(D2e,nNo),e(D1,sNo),e(D1,Bz),e(Bz,lNo),e(D1,iNo),e(y,dNo),e(y,j1),e(j1,j2e),e(j2e,mNo),e(j1,cNo),e(j1,Iz),e(Iz,fNo),e(j1,gNo),e(y,hNo),e(y,G1),e(G1,G2e),e(G2e,uNo),e(G1,pNo),e(G1,Nz),e(Nz,_No),e(G1,bNo),e(y,vNo),e(y,O1),e(O1,O2e),e(O2e,FNo),e(O1,TNo),e(O1,qz),e(qz,MNo),e(O1,ENo),e(y,CNo),e(y,V1),e(V1,V2e),e(V2e,wNo),e(V1,ANo),e(V1,Dz),e(Dz,LNo),e(V1,yNo),e(y,xNo),e(y,X1),e(X1,X2e),e(X2e,$No),e(X1,kNo),e(X1,jz),e(jz,SNo),e(X1,RNo),e(y,PNo),e(y,z1),e(z1,z2e),e(z2e,BNo),e(z1,INo),e(z1,Gz),e(Gz,NNo),e(z1,qNo),e(y,DNo),e(y,Q1),e(Q1,Q2e),e(Q2e,jNo),e(Q1,GNo),e(Q1,Oz),e(Oz,ONo),e(Q1,VNo),e(y,XNo),e(y,W1),e(W1,W2e),e(W2e,zNo),e(W1,QNo),e(W1,Vz),e(Vz,WNo),e(W1,UNo),e(y,HNo),e(y,U1),e(U1,U2e),e(U2e,JNo),e(U1,YNo),e(U1,Xz),e(Xz,ZNo),e(U1,KNo),e(y,eqo),e(y,H1),e(H1,H2e),e(H2e,oqo),e(H1,rqo),e(H1,zz),e(zz,tqo),e(H1,aqo),e(y,nqo),e(y,J1),e(J1,J2e),e(J2e,sqo),e(J1,lqo),e(J1,Qz),e(Qz,iqo),e(J1,dqo),e(y,mqo),e(y,Y1),e(Y1,Y2e),e(Y2e,cqo),e(Y1,fqo),e(Y1,Wz),e(Wz,gqo),e(Y1,hqo),e(y,uqo),e(y,Z1),e(Z1,Z2e),e(Z2e,pqo),e(Z1,_qo),e(Z1,Uz),e(Uz,bqo),e(Z1,vqo),e(y,Fqo),e(y,K1),e(K1,K2e),e(K2e,Tqo),e(K1,Mqo),e(K1,Hz),e(Hz,Eqo),e(K1,Cqo),e(y,wqo),e(y,e2),e(e2,ebe),e(ebe,Aqo),e(e2,Lqo),e(e2,Jz),e(Jz,yqo),e(e2,xqo),e(y,$qo),e(y,o2),e(o2,obe),e(obe,kqo),e(o2,Sqo),e(o2,Yz),e(Yz,Rqo),e(o2,Pqo),e(y,Bqo),e(y,r2),e(r2,rbe),e(rbe,Iqo),e(r2,Nqo),e(r2,Zz),e(Zz,qqo),e(r2,Dqo),e(y,jqo),e(y,t2),e(t2,tbe),e(tbe,Gqo),e(t2,Oqo),e(t2,Kz),e(Kz,Vqo),e(t2,Xqo),e(y,zqo),e(y,a2),e(a2,abe),e(abe,Qqo),e(a2,Wqo),e(a2,eQ),e(eQ,Uqo),e(a2,Hqo),e(y,Jqo),e(y,n2),e(n2,nbe),e(nbe,Yqo),e(n2,Zqo),e(n2,oQ),e(oQ,Kqo),e(n2,eDo),e(y,oDo),e(y,s2),e(s2,sbe),e(sbe,rDo),e(s2,tDo),e(s2,rQ),e(rQ,aDo),e(s2,nDo),e(y,sDo),e(y,l2),e(l2,lbe),e(lbe,lDo),e(l2,iDo),e(l2,tQ),e(tQ,dDo),e(l2,mDo),e(y,cDo),e(y,i2),e(i2,ibe),e(ibe,fDo),e(i2,gDo),e(i2,aQ),e(aQ,hDo),e(i2,uDo),e(y,pDo),e(y,d2),e(d2,dbe),e(dbe,_Do),e(d2,bDo),e(d2,nQ),e(nQ,vDo),e(d2,FDo),e(y,TDo),e(y,m2),e(m2,mbe),e(mbe,MDo),e(m2,EDo),e(m2,sQ),e(sQ,CDo),e(m2,wDo),e(y,ADo),e(y,c2),e(c2,cbe),e(cbe,LDo),e(c2,yDo),e(c2,lQ),e(lQ,xDo),e(c2,$Do),e(y,kDo),e(y,f2),e(f2,fbe),e(fbe,SDo),e(f2,RDo),e(f2,iQ),e(iQ,PDo),e(f2,BDo),e(y,IDo),e(y,g2),e(g2,gbe),e(gbe,NDo),e(g2,qDo),e(g2,dQ),e(dQ,DDo),e(g2,jDo),e(y,GDo),e(y,h2),e(h2,hbe),e(hbe,ODo),e(h2,VDo),e(h2,mQ),e(mQ,XDo),e(h2,zDo),e(y,QDo),e(y,u2),e(u2,ube),e(ube,WDo),e(u2,UDo),e(u2,cQ),e(cQ,HDo),e(u2,JDo),e(y,YDo),e(y,p2),e(p2,pbe),e(pbe,ZDo),e(p2,KDo),e(p2,fQ),e(fQ,ejo),e(p2,ojo),e(y,rjo),e(y,_2),e(_2,_be),e(_be,tjo),e(_2,ajo),e(_2,gQ),e(gQ,njo),e(_2,sjo),e(y,ljo),e(y,b2),e(b2,bbe),e(bbe,ijo),e(b2,djo),e(b2,hQ),e(hQ,mjo),e(b2,cjo),e(y,fjo),e(y,v2),e(v2,vbe),e(vbe,gjo),e(v2,hjo),e(v2,uQ),e(uQ,ujo),e(v2,pjo),e(y,_jo),e(y,F2),e(F2,Fbe),e(Fbe,bjo),e(F2,vjo),e(F2,pQ),e(pQ,Fjo),e(F2,Tjo),e(y,Mjo),e(y,T2),e(T2,Tbe),e(Tbe,Ejo),e(T2,Cjo),e(T2,_Q),e(_Q,wjo),e(T2,Ajo),e(y,Ljo),e(y,M2),e(M2,Mbe),e(Mbe,yjo),e(M2,xjo),e(M2,bQ),e(bQ,$jo),e(M2,kjo),e(y,Sjo),e(y,E2),e(E2,Ebe),e(Ebe,Rjo),e(E2,Pjo),e(E2,vQ),e(vQ,Bjo),e(E2,Ijo),e(y,Njo),e(y,C2),e(C2,Cbe),e(Cbe,qjo),e(C2,Djo),e(C2,FQ),e(FQ,jjo),e(C2,Gjo),e(y,Ojo),e(y,w2),e(w2,wbe),e(wbe,Vjo),e(w2,Xjo),e(w2,TQ),e(TQ,zjo),e(w2,Qjo),e(y,Wjo),e(y,A2),e(A2,Abe),e(Abe,Ujo),e(A2,Hjo),e(A2,MQ),e(MQ,Jjo),e(A2,Yjo),e(y,Zjo),e(y,L2),e(L2,Lbe),e(Lbe,Kjo),e(L2,eGo),e(L2,EQ),e(EQ,oGo),e(L2,rGo),e(y,tGo),e(y,y2),e(y2,ybe),e(ybe,aGo),e(y2,nGo),e(y2,CQ),e(CQ,sGo),e(y2,lGo),e(y,iGo),e(y,x2),e(x2,xbe),e(xbe,dGo),e(x2,mGo),e(x2,wQ),e(wQ,cGo),e(x2,fGo),e(y,gGo),e(y,$2),e($2,$be),e($be,hGo),e($2,uGo),e($2,AQ),e(AQ,pGo),e($2,_Go),e(y,bGo),e(y,k2),e(k2,kbe),e(kbe,vGo),e(k2,FGo),e(k2,LQ),e(LQ,TGo),e(k2,MGo),e(y,EGo),e(y,S2),e(S2,Sbe),e(Sbe,CGo),e(S2,wGo),e(S2,yQ),e(yQ,AGo),e(S2,LGo),e(y,yGo),e(y,R2),e(R2,Rbe),e(Rbe,xGo),e(R2,$Go),e(R2,xQ),e(xQ,kGo),e(R2,SGo),e(y,RGo),e(y,P2),e(P2,Pbe),e(Pbe,PGo),e(P2,BGo),e(P2,$Q),e($Q,IGo),e(P2,NGo),e(y,qGo),e(y,B2),e(B2,Bbe),e(Bbe,DGo),e(B2,jGo),e(B2,kQ),e(kQ,GGo),e(B2,OGo),e(y,VGo),e(y,I2),e(I2,Ibe),e(Ibe,XGo),e(I2,zGo),e(I2,SQ),e(SQ,QGo),e(I2,WGo),e(y,UGo),e(y,N2),e(N2,Nbe),e(Nbe,HGo),e(N2,JGo),e(N2,RQ),e(RQ,YGo),e(N2,ZGo),e(y,KGo),e(y,q2),e(q2,qbe),e(qbe,eOo),e(q2,oOo),e(q2,PQ),e(PQ,rOo),e(q2,tOo),e(y,aOo),e(y,D2),e(D2,Dbe),e(Dbe,nOo),e(D2,sOo),e(D2,BQ),e(BQ,lOo),e(D2,iOo),e(y,dOo),e(y,j2),e(j2,jbe),e(jbe,mOo),e(j2,cOo),e(j2,IQ),e(IQ,fOo),e(j2,gOo),e(y,hOo),e(y,G2),e(G2,Gbe),e(Gbe,uOo),e(G2,pOo),e(G2,NQ),e(NQ,_Oo),e(G2,bOo),e(y,vOo),e(y,O2),e(O2,Obe),e(Obe,FOo),e(O2,TOo),e(O2,qQ),e(qQ,MOo),e(O2,EOo),e(y,COo),e(y,V2),e(V2,Vbe),e(Vbe,wOo),e(V2,AOo),e(V2,DQ),e(DQ,LOo),e(V2,yOo),e(y,xOo),e(y,X2),e(X2,Xbe),e(Xbe,$Oo),e(X2,kOo),e(X2,jQ),e(jQ,SOo),e(X2,ROo),e(y,POo),e(y,z2),e(z2,zbe),e(zbe,BOo),e(z2,IOo),e(z2,GQ),e(GQ,NOo),e(z2,qOo),e(y,DOo),e(y,Q2),e(Q2,Qbe),e(Qbe,jOo),e(Q2,GOo),e(Q2,OQ),e(OQ,OOo),e(Q2,VOo),e(y,XOo),e(y,W2),e(W2,Wbe),e(Wbe,zOo),e(W2,QOo),e(W2,VQ),e(VQ,WOo),e(W2,UOo),e(y,HOo),e(y,U2),e(U2,Ube),e(Ube,JOo),e(U2,YOo),e(U2,XQ),e(XQ,ZOo),e(U2,KOo),e(y,eVo),e(y,H2),e(H2,Hbe),e(Hbe,oVo),e(H2,rVo),e(H2,zQ),e(zQ,tVo),e(H2,aVo),e(y,nVo),e(y,J2),e(J2,Jbe),e(Jbe,sVo),e(J2,lVo),e(J2,QQ),e(QQ,iVo),e(J2,dVo),e(y,mVo),e(y,Y2),e(Y2,Ybe),e(Ybe,cVo),e(Y2,fVo),e(Y2,WQ),e(WQ,gVo),e(Y2,hVo),e(y,uVo),e(y,Z2),e(Z2,Zbe),e(Zbe,pVo),e(Z2,_Vo),e(Z2,UQ),e(UQ,bVo),e(Z2,vVo),e(y,FVo),e(y,K2),e(K2,Kbe),e(Kbe,TVo),e(K2,MVo),e(K2,HQ),e(HQ,EVo),e(K2,CVo),e(Ke,wVo),e(Ke,eb),e(eb,AVo),e(eb,eve),e(eve,LVo),e(eb,yVo),e(eb,ove),e(ove,xVo),e(Ke,$Vo),M(ob,Ke,null),b(c,Dto,_),b(c,Pd,_),e(Pd,rb),e(rb,rve),M(j$,rve,null),e(Pd,kVo),e(Pd,tve),e(tve,SVo),b(c,jto,_),b(c,No,_),M(G$,No,null),e(No,RVo),e(No,Bd),e(Bd,PVo),e(Bd,JQ),e(JQ,BVo),e(Bd,IVo),e(Bd,YQ),e(YQ,NVo),e(Bd,qVo),e(No,DVo),e(No,O$),e(O$,jVo),e(O$,ave),e(ave,GVo),e(O$,OVo),e(No,VVo),e(No,Et),M(V$,Et,null),e(Et,XVo),e(Et,nve),e(nve,zVo),e(Et,QVo),e(Et,Id),e(Id,WVo),e(Id,sve),e(sve,UVo),e(Id,HVo),e(Id,ZQ),e(ZQ,JVo),e(Id,YVo),e(Et,ZVo),M(tb,Et,null),e(No,KVo),e(No,eo),M(X$,eo,null),e(eo,eXo),e(eo,lve),e(lve,oXo),e(eo,rXo),e(eo,sn),e(sn,tXo),e(sn,ive),e(ive,aXo),e(sn,nXo),e(sn,dve),e(dve,sXo),e(sn,lXo),e(sn,mve),e(mve,iXo),e(sn,dXo),e(eo,mXo),e(eo,G),e(G,ab),e(ab,cve),e(cve,cXo),e(ab,fXo),e(ab,KQ),e(KQ,gXo),e(ab,hXo),e(G,uXo),e(G,nb),e(nb,fve),e(fve,pXo),e(nb,_Xo),e(nb,eW),e(eW,bXo),e(nb,vXo),e(G,FXo),e(G,sb),e(sb,gve),e(gve,TXo),e(sb,MXo),e(sb,oW),e(oW,EXo),e(sb,CXo),e(G,wXo),e(G,lb),e(lb,hve),e(hve,AXo),e(lb,LXo),e(lb,rW),e(rW,yXo),e(lb,xXo),e(G,$Xo),e(G,ib),e(ib,uve),e(uve,kXo),e(ib,SXo),e(ib,tW),e(tW,RXo),e(ib,PXo),e(G,BXo),e(G,db),e(db,pve),e(pve,IXo),e(db,NXo),e(db,aW),e(aW,qXo),e(db,DXo),e(G,jXo),e(G,mb),e(mb,_ve),e(_ve,GXo),e(mb,OXo),e(mb,nW),e(nW,VXo),e(mb,XXo),e(G,zXo),e(G,cb),e(cb,bve),e(bve,QXo),e(cb,WXo),e(cb,sW),e(sW,UXo),e(cb,HXo),e(G,JXo),e(G,fb),e(fb,vve),e(vve,YXo),e(fb,ZXo),e(fb,lW),e(lW,KXo),e(fb,ezo),e(G,ozo),e(G,gb),e(gb,Fve),e(Fve,rzo),e(gb,tzo),e(gb,iW),e(iW,azo),e(gb,nzo),e(G,szo),e(G,hb),e(hb,Tve),e(Tve,lzo),e(hb,izo),e(hb,dW),e(dW,dzo),e(hb,mzo),e(G,czo),e(G,ub),e(ub,Mve),e(Mve,fzo),e(ub,gzo),e(ub,mW),e(mW,hzo),e(ub,uzo),e(G,pzo),e(G,pb),e(pb,Eve),e(Eve,_zo),e(pb,bzo),e(pb,cW),e(cW,vzo),e(pb,Fzo),e(G,Tzo),e(G,_b),e(_b,Cve),e(Cve,Mzo),e(_b,Ezo),e(_b,fW),e(fW,Czo),e(_b,wzo),e(G,Azo),e(G,bb),e(bb,wve),e(wve,Lzo),e(bb,yzo),e(bb,gW),e(gW,xzo),e(bb,$zo),e(G,kzo),e(G,vb),e(vb,Ave),e(Ave,Szo),e(vb,Rzo),e(vb,hW),e(hW,Pzo),e(vb,Bzo),e(G,Izo),e(G,Fb),e(Fb,Lve),e(Lve,Nzo),e(Fb,qzo),e(Fb,uW),e(uW,Dzo),e(Fb,jzo),e(G,Gzo),e(G,Tb),e(Tb,yve),e(yve,Ozo),e(Tb,Vzo),e(Tb,pW),e(pW,Xzo),e(Tb,zzo),e(G,Qzo),e(G,Mb),e(Mb,xve),e(xve,Wzo),e(Mb,Uzo),e(Mb,_W),e(_W,Hzo),e(Mb,Jzo),e(G,Yzo),e(G,Eb),e(Eb,$ve),e($ve,Zzo),e(Eb,Kzo),e(Eb,bW),e(bW,eQo),e(Eb,oQo),e(G,rQo),e(G,Cb),e(Cb,kve),e(kve,tQo),e(Cb,aQo),e(Cb,vW),e(vW,nQo),e(Cb,sQo),e(G,lQo),e(G,wb),e(wb,Sve),e(Sve,iQo),e(wb,dQo),e(wb,FW),e(FW,mQo),e(wb,cQo),e(G,fQo),e(G,Ab),e(Ab,Rve),e(Rve,gQo),e(Ab,hQo),e(Ab,TW),e(TW,uQo),e(Ab,pQo),e(G,_Qo),e(G,Lb),e(Lb,Pve),e(Pve,bQo),e(Lb,vQo),e(Lb,MW),e(MW,FQo),e(Lb,TQo),e(G,MQo),e(G,yb),e(yb,Bve),e(Bve,EQo),e(yb,CQo),e(yb,EW),e(EW,wQo),e(yb,AQo),e(G,LQo),e(G,xb),e(xb,Ive),e(Ive,yQo),e(xb,xQo),e(xb,CW),e(CW,$Qo),e(xb,kQo),e(G,SQo),e(G,$b),e($b,Nve),e(Nve,RQo),e($b,PQo),e($b,wW),e(wW,BQo),e($b,IQo),e(G,NQo),e(G,kb),e(kb,qve),e(qve,qQo),e(kb,DQo),e(kb,AW),e(AW,jQo),e(kb,GQo),e(G,OQo),e(G,Sb),e(Sb,Dve),e(Dve,VQo),e(Sb,XQo),e(Sb,LW),e(LW,zQo),e(Sb,QQo),e(G,WQo),e(G,Rb),e(Rb,jve),e(jve,UQo),e(Rb,HQo),e(Rb,yW),e(yW,JQo),e(Rb,YQo),e(G,ZQo),e(G,Pb),e(Pb,Gve),e(Gve,KQo),e(Pb,eWo),e(Pb,xW),e(xW,oWo),e(Pb,rWo),e(G,tWo),e(G,Bb),e(Bb,Ove),e(Ove,aWo),e(Bb,nWo),e(Bb,$W),e($W,sWo),e(Bb,lWo),e(G,iWo),e(G,Ib),e(Ib,Vve),e(Vve,dWo),e(Ib,mWo),e(Ib,kW),e(kW,cWo),e(Ib,fWo),e(G,gWo),e(G,Nb),e(Nb,Xve),e(Xve,hWo),e(Nb,uWo),e(Nb,SW),e(SW,pWo),e(Nb,_Wo),e(G,bWo),e(G,qb),e(qb,zve),e(zve,vWo),e(qb,FWo),e(qb,RW),e(RW,TWo),e(qb,MWo),e(G,EWo),e(G,Db),e(Db,Qve),e(Qve,CWo),e(Db,wWo),e(Db,PW),e(PW,AWo),e(Db,LWo),e(G,yWo),e(G,jb),e(jb,Wve),e(Wve,xWo),e(jb,$Wo),e(jb,BW),e(BW,kWo),e(jb,SWo),e(G,RWo),e(G,Gb),e(Gb,Uve),e(Uve,PWo),e(Gb,BWo),e(Gb,IW),e(IW,IWo),e(Gb,NWo),e(G,qWo),e(G,Ob),e(Ob,Hve),e(Hve,DWo),e(Ob,jWo),e(Ob,NW),e(NW,GWo),e(Ob,OWo),e(G,VWo),e(G,Vb),e(Vb,Jve),e(Jve,XWo),e(Vb,zWo),e(Vb,qW),e(qW,QWo),e(Vb,WWo),e(G,UWo),e(G,Xb),e(Xb,Yve),e(Yve,HWo),e(Xb,JWo),e(Xb,DW),e(DW,YWo),e(Xb,ZWo),e(G,KWo),e(G,zb),e(zb,Zve),e(Zve,eUo),e(zb,oUo),e(zb,jW),e(jW,rUo),e(zb,tUo),e(G,aUo),e(G,Qb),e(Qb,Kve),e(Kve,nUo),e(Qb,sUo),e(Qb,GW),e(GW,lUo),e(Qb,iUo),e(G,dUo),e(G,Wb),e(Wb,eFe),e(eFe,mUo),e(Wb,cUo),e(Wb,OW),e(OW,fUo),e(Wb,gUo),e(G,hUo),e(G,Ub),e(Ub,oFe),e(oFe,uUo),e(Ub,pUo),e(Ub,VW),e(VW,_Uo),e(Ub,bUo),e(G,vUo),e(G,Hb),e(Hb,rFe),e(rFe,FUo),e(Hb,TUo),e(Hb,XW),e(XW,MUo),e(Hb,EUo),e(G,CUo),e(G,Jb),e(Jb,tFe),e(tFe,wUo),e(Jb,AUo),e(Jb,zW),e(zW,LUo),e(Jb,yUo),e(G,xUo),e(G,Yb),e(Yb,aFe),e(aFe,$Uo),e(Yb,kUo),e(Yb,QW),e(QW,SUo),e(Yb,RUo),e(eo,PUo),e(eo,Zb),e(Zb,BUo),e(Zb,nFe),e(nFe,IUo),e(Zb,NUo),e(Zb,sFe),e(sFe,qUo),e(eo,DUo),M(Kb,eo,null),b(c,Gto,_),b(c,Nd,_),e(Nd,ev),e(ev,lFe),M(z$,lFe,null),e(Nd,jUo),e(Nd,iFe),e(iFe,GUo),b(c,Oto,_),b(c,qo,_),M(Q$,qo,null),e(qo,OUo),e(qo,qd),e(qd,VUo),e(qd,WW),e(WW,XUo),e(qd,zUo),e(qd,UW),e(UW,QUo),e(qd,WUo),e(qo,UUo),e(qo,W$),e(W$,HUo),e(W$,dFe),e(dFe,JUo),e(W$,YUo),e(qo,ZUo),e(qo,Ct),M(U$,Ct,null),e(Ct,KUo),e(Ct,mFe),e(mFe,eHo),e(Ct,oHo),e(Ct,Dd),e(Dd,rHo),e(Dd,cFe),e(cFe,tHo),e(Dd,aHo),e(Dd,HW),e(HW,nHo),e(Dd,sHo),e(Ct,lHo),M(ov,Ct,null),e(qo,iHo),e(qo,oo),M(H$,oo,null),e(oo,dHo),e(oo,fFe),e(fFe,mHo),e(oo,cHo),e(oo,ln),e(ln,fHo),e(ln,gFe),e(gFe,gHo),e(ln,hHo),e(ln,hFe),e(hFe,uHo),e(ln,pHo),e(ln,uFe),e(uFe,_Ho),e(ln,bHo),e(oo,vHo),e(oo,W),e(W,rv),e(rv,pFe),e(pFe,FHo),e(rv,THo),e(rv,JW),e(JW,MHo),e(rv,EHo),e(W,CHo),e(W,tv),e(tv,_Fe),e(_Fe,wHo),e(tv,AHo),e(tv,YW),e(YW,LHo),e(tv,yHo),e(W,xHo),e(W,av),e(av,bFe),e(bFe,$Ho),e(av,kHo),e(av,ZW),e(ZW,SHo),e(av,RHo),e(W,PHo),e(W,nv),e(nv,vFe),e(vFe,BHo),e(nv,IHo),e(nv,KW),e(KW,NHo),e(nv,qHo),e(W,DHo),e(W,sv),e(sv,FFe),e(FFe,jHo),e(sv,GHo),e(sv,eU),e(eU,OHo),e(sv,VHo),e(W,XHo),e(W,lv),e(lv,TFe),e(TFe,zHo),e(lv,QHo),e(lv,oU),e(oU,WHo),e(lv,UHo),e(W,HHo),e(W,iv),e(iv,MFe),e(MFe,JHo),e(iv,YHo),e(iv,rU),e(rU,ZHo),e(iv,KHo),e(W,eJo),e(W,dv),e(dv,EFe),e(EFe,oJo),e(dv,rJo),e(dv,tU),e(tU,tJo),e(dv,aJo),e(W,nJo),e(W,mv),e(mv,CFe),e(CFe,sJo),e(mv,lJo),e(mv,aU),e(aU,iJo),e(mv,dJo),e(W,mJo),e(W,cv),e(cv,wFe),e(wFe,cJo),e(cv,fJo),e(cv,nU),e(nU,gJo),e(cv,hJo),e(W,uJo),e(W,fv),e(fv,AFe),e(AFe,pJo),e(fv,_Jo),e(fv,sU),e(sU,bJo),e(fv,vJo),e(W,FJo),e(W,gv),e(gv,LFe),e(LFe,TJo),e(gv,MJo),e(gv,lU),e(lU,EJo),e(gv,CJo),e(W,wJo),e(W,hv),e(hv,yFe),e(yFe,AJo),e(hv,LJo),e(hv,iU),e(iU,yJo),e(hv,xJo),e(W,$Jo),e(W,uv),e(uv,xFe),e(xFe,kJo),e(uv,SJo),e(uv,dU),e(dU,RJo),e(uv,PJo),e(W,BJo),e(W,pv),e(pv,$Fe),e($Fe,IJo),e(pv,NJo),e(pv,mU),e(mU,qJo),e(pv,DJo),e(W,jJo),e(W,_v),e(_v,kFe),e(kFe,GJo),e(_v,OJo),e(_v,cU),e(cU,VJo),e(_v,XJo),e(W,zJo),e(W,bv),e(bv,SFe),e(SFe,QJo),e(bv,WJo),e(bv,fU),e(fU,UJo),e(bv,HJo),e(W,JJo),e(W,vv),e(vv,RFe),e(RFe,YJo),e(vv,ZJo),e(vv,gU),e(gU,KJo),e(vv,eYo),e(W,oYo),e(W,Fv),e(Fv,PFe),e(PFe,rYo),e(Fv,tYo),e(Fv,hU),e(hU,aYo),e(Fv,nYo),e(W,sYo),e(W,Tv),e(Tv,BFe),e(BFe,lYo),e(Tv,iYo),e(Tv,uU),e(uU,dYo),e(Tv,mYo),e(W,cYo),e(W,Mv),e(Mv,IFe),e(IFe,fYo),e(Mv,gYo),e(Mv,pU),e(pU,hYo),e(Mv,uYo),e(W,pYo),e(W,Ev),e(Ev,NFe),e(NFe,_Yo),e(Ev,bYo),e(Ev,_U),e(_U,vYo),e(Ev,FYo),e(W,TYo),e(W,Cv),e(Cv,qFe),e(qFe,MYo),e(Cv,EYo),e(Cv,bU),e(bU,CYo),e(Cv,wYo),e(W,AYo),e(W,wv),e(wv,DFe),e(DFe,LYo),e(wv,yYo),e(wv,vU),e(vU,xYo),e(wv,$Yo),e(W,kYo),e(W,Av),e(Av,jFe),e(jFe,SYo),e(Av,RYo),e(Av,FU),e(FU,PYo),e(Av,BYo),e(W,IYo),e(W,Lv),e(Lv,GFe),e(GFe,NYo),e(Lv,qYo),e(Lv,TU),e(TU,DYo),e(Lv,jYo),e(W,GYo),e(W,yv),e(yv,OFe),e(OFe,OYo),e(yv,VYo),e(yv,MU),e(MU,XYo),e(yv,zYo),e(W,QYo),e(W,xv),e(xv,VFe),e(VFe,WYo),e(xv,UYo),e(xv,EU),e(EU,HYo),e(xv,JYo),e(W,YYo),e(W,$v),e($v,XFe),e(XFe,ZYo),e($v,KYo),e($v,CU),e(CU,eZo),e($v,oZo),e(W,rZo),e(W,kv),e(kv,zFe),e(zFe,tZo),e(kv,aZo),e(kv,wU),e(wU,nZo),e(kv,sZo),e(W,lZo),e(W,Sv),e(Sv,QFe),e(QFe,iZo),e(Sv,dZo),e(Sv,AU),e(AU,mZo),e(Sv,cZo),e(W,fZo),e(W,Rv),e(Rv,WFe),e(WFe,gZo),e(Rv,hZo),e(Rv,LU),e(LU,uZo),e(Rv,pZo),e(W,_Zo),e(W,Pv),e(Pv,UFe),e(UFe,bZo),e(Pv,vZo),e(Pv,yU),e(yU,FZo),e(Pv,TZo),e(W,MZo),e(W,Bv),e(Bv,HFe),e(HFe,EZo),e(Bv,CZo),e(Bv,xU),e(xU,wZo),e(Bv,AZo),e(W,LZo),e(W,Iv),e(Iv,JFe),e(JFe,yZo),e(Iv,xZo),e(Iv,$U),e($U,$Zo),e(Iv,kZo),e(W,SZo),e(W,Nv),e(Nv,YFe),e(YFe,RZo),e(Nv,PZo),e(Nv,kU),e(kU,BZo),e(Nv,IZo),e(W,NZo),e(W,qv),e(qv,ZFe),e(ZFe,qZo),e(qv,DZo),e(qv,SU),e(SU,jZo),e(qv,GZo),e(W,OZo),e(W,Dv),e(Dv,KFe),e(KFe,VZo),e(Dv,XZo),e(Dv,RU),e(RU,zZo),e(Dv,QZo),e(W,WZo),e(W,jv),e(jv,eTe),e(eTe,UZo),e(jv,HZo),e(jv,PU),e(PU,JZo),e(jv,YZo),e(W,ZZo),e(W,Gv),e(Gv,oTe),e(oTe,KZo),e(Gv,eKo),e(Gv,BU),e(BU,oKo),e(Gv,rKo),e(W,tKo),e(W,Ov),e(Ov,rTe),e(rTe,aKo),e(Ov,nKo),e(Ov,IU),e(IU,sKo),e(Ov,lKo),e(W,iKo),e(W,Vv),e(Vv,tTe),e(tTe,dKo),e(Vv,mKo),e(Vv,NU),e(NU,cKo),e(Vv,fKo),e(oo,gKo),e(oo,Xv),e(Xv,hKo),e(Xv,aTe),e(aTe,uKo),e(Xv,pKo),e(Xv,nTe),e(nTe,_Ko),e(oo,bKo),M(zv,oo,null),b(c,Vto,_),b(c,jd,_),e(jd,Qv),e(Qv,sTe),M(J$,sTe,null),e(jd,vKo),e(jd,lTe),e(lTe,FKo),b(c,Xto,_),b(c,Do,_),M(Y$,Do,null),e(Do,TKo),e(Do,Gd),e(Gd,MKo),e(Gd,qU),e(qU,EKo),e(Gd,CKo),e(Gd,DU),e(DU,wKo),e(Gd,AKo),e(Do,LKo),e(Do,Z$),e(Z$,yKo),e(Z$,iTe),e(iTe,xKo),e(Z$,$Ko),e(Do,kKo),e(Do,wt),M(K$,wt,null),e(wt,SKo),e(wt,dTe),e(dTe,RKo),e(wt,PKo),e(wt,Od),e(Od,BKo),e(Od,mTe),e(mTe,IKo),e(Od,NKo),e(Od,jU),e(jU,qKo),e(Od,DKo),e(wt,jKo),M(Wv,wt,null),e(Do,GKo),e(Do,ro),M(ek,ro,null),e(ro,OKo),e(ro,cTe),e(cTe,VKo),e(ro,XKo),e(ro,dn),e(dn,zKo),e(dn,fTe),e(fTe,QKo),e(dn,WKo),e(dn,gTe),e(gTe,UKo),e(dn,HKo),e(dn,hTe),e(hTe,JKo),e(dn,YKo),e(ro,ZKo),e(ro,ok),e(ok,Uv),e(Uv,uTe),e(uTe,KKo),e(Uv,eer),e(Uv,GU),e(GU,oer),e(Uv,rer),e(ok,ter),e(ok,Hv),e(Hv,pTe),e(pTe,aer),e(Hv,ner),e(Hv,OU),e(OU,ser),e(Hv,ler),e(ro,ier),e(ro,Jv),e(Jv,der),e(Jv,_Te),e(_Te,mer),e(Jv,cer),e(Jv,bTe),e(bTe,fer),e(ro,ger),M(Yv,ro,null),b(c,zto,_),b(c,Vd,_),e(Vd,Zv),e(Zv,vTe),M(rk,vTe,null),e(Vd,her),e(Vd,FTe),e(FTe,uer),b(c,Qto,_),b(c,jo,_),M(tk,jo,null),e(jo,per),e(jo,Xd),e(Xd,_er),e(Xd,VU),e(VU,ber),e(Xd,ver),e(Xd,XU),e(XU,Fer),e(Xd,Ter),e(jo,Mer),e(jo,ak),e(ak,Eer),e(ak,TTe),e(TTe,Cer),e(ak,wer),e(jo,Aer),e(jo,At),M(nk,At,null),e(At,Ler),e(At,MTe),e(MTe,yer),e(At,xer),e(At,zd),e(zd,$er),e(zd,ETe),e(ETe,ker),e(zd,Ser),e(zd,zU),e(zU,Rer),e(zd,Per),e(At,Ber),M(Kv,At,null),e(jo,Ier),e(jo,to),M(sk,to,null),e(to,Ner),e(to,CTe),e(CTe,qer),e(to,Der),e(to,mn),e(mn,jer),e(mn,wTe),e(wTe,Ger),e(mn,Oer),e(mn,ATe),e(ATe,Ver),e(mn,Xer),e(mn,LTe),e(LTe,zer),e(mn,Qer),e(to,Wer),e(to,Y),e(Y,eF),e(eF,yTe),e(yTe,Uer),e(eF,Her),e(eF,QU),e(QU,Jer),e(eF,Yer),e(Y,Zer),e(Y,oF),e(oF,xTe),e(xTe,Ker),e(oF,eor),e(oF,WU),e(WU,oor),e(oF,ror),e(Y,tor),e(Y,rF),e(rF,$Te),e($Te,aor),e(rF,nor),e(rF,UU),e(UU,sor),e(rF,lor),e(Y,ior),e(Y,tF),e(tF,kTe),e(kTe,dor),e(tF,mor),e(tF,HU),e(HU,cor),e(tF,gor),e(Y,hor),e(Y,aF),e(aF,STe),e(STe,uor),e(aF,por),e(aF,JU),e(JU,_or),e(aF,bor),e(Y,vor),e(Y,nF),e(nF,RTe),e(RTe,For),e(nF,Tor),e(nF,YU),e(YU,Mor),e(nF,Eor),e(Y,Cor),e(Y,sF),e(sF,PTe),e(PTe,wor),e(sF,Aor),e(sF,ZU),e(ZU,Lor),e(sF,yor),e(Y,xor),e(Y,lF),e(lF,BTe),e(BTe,$or),e(lF,kor),e(lF,KU),e(KU,Sor),e(lF,Ror),e(Y,Por),e(Y,iF),e(iF,ITe),e(ITe,Bor),e(iF,Ior),e(iF,eH),e(eH,Nor),e(iF,qor),e(Y,Dor),e(Y,dF),e(dF,NTe),e(NTe,jor),e(dF,Gor),e(dF,oH),e(oH,Oor),e(dF,Vor),e(Y,Xor),e(Y,mF),e(mF,qTe),e(qTe,zor),e(mF,Qor),e(mF,rH),e(rH,Wor),e(mF,Uor),e(Y,Hor),e(Y,cF),e(cF,DTe),e(DTe,Jor),e(cF,Yor),e(cF,tH),e(tH,Zor),e(cF,Kor),e(Y,err),e(Y,fF),e(fF,jTe),e(jTe,orr),e(fF,rrr),e(fF,aH),e(aH,trr),e(fF,arr),e(Y,nrr),e(Y,gF),e(gF,GTe),e(GTe,srr),e(gF,lrr),e(gF,nH),e(nH,irr),e(gF,drr),e(Y,mrr),e(Y,hF),e(hF,OTe),e(OTe,crr),e(hF,frr),e(hF,sH),e(sH,grr),e(hF,hrr),e(Y,urr),e(Y,uF),e(uF,VTe),e(VTe,prr),e(uF,_rr),e(uF,lH),e(lH,brr),e(uF,vrr),e(Y,Frr),e(Y,pF),e(pF,XTe),e(XTe,Trr),e(pF,Mrr),e(pF,iH),e(iH,Err),e(pF,Crr),e(Y,wrr),e(Y,_F),e(_F,zTe),e(zTe,Arr),e(_F,Lrr),e(_F,dH),e(dH,yrr),e(_F,xrr),e(Y,$rr),e(Y,bF),e(bF,QTe),e(QTe,krr),e(bF,Srr),e(bF,mH),e(mH,Rrr),e(bF,Prr),e(Y,Brr),e(Y,vF),e(vF,WTe),e(WTe,Irr),e(vF,Nrr),e(vF,cH),e(cH,qrr),e(vF,Drr),e(Y,jrr),e(Y,FF),e(FF,UTe),e(UTe,Grr),e(FF,Orr),e(FF,fH),e(fH,Vrr),e(FF,Xrr),e(Y,zrr),e(Y,TF),e(TF,HTe),e(HTe,Qrr),e(TF,Wrr),e(TF,gH),e(gH,Urr),e(TF,Hrr),e(Y,Jrr),e(Y,MF),e(MF,JTe),e(JTe,Yrr),e(MF,Zrr),e(MF,hH),e(hH,Krr),e(MF,etr),e(Y,otr),e(Y,EF),e(EF,YTe),e(YTe,rtr),e(EF,ttr),e(EF,uH),e(uH,atr),e(EF,ntr),e(Y,str),e(Y,CF),e(CF,ZTe),e(ZTe,ltr),e(CF,itr),e(CF,pH),e(pH,dtr),e(CF,mtr),e(Y,ctr),e(Y,wF),e(wF,KTe),e(KTe,ftr),e(wF,gtr),e(wF,_H),e(_H,htr),e(wF,utr),e(Y,ptr),e(Y,AF),e(AF,eMe),e(eMe,_tr),e(AF,btr),e(AF,bH),e(bH,vtr),e(AF,Ftr),e(Y,Ttr),e(Y,LF),e(LF,oMe),e(oMe,Mtr),e(LF,Etr),e(LF,vH),e(vH,Ctr),e(LF,wtr),e(Y,Atr),e(Y,yF),e(yF,rMe),e(rMe,Ltr),e(yF,ytr),e(yF,FH),e(FH,xtr),e(yF,$tr),e(Y,ktr),e(Y,xF),e(xF,tMe),e(tMe,Str),e(xF,Rtr),e(xF,TH),e(TH,Ptr),e(xF,Btr),e(Y,Itr),e(Y,$F),e($F,aMe),e(aMe,Ntr),e($F,qtr),e($F,MH),e(MH,Dtr),e($F,jtr),e(Y,Gtr),e(Y,kF),e(kF,nMe),e(nMe,Otr),e(kF,Vtr),e(kF,EH),e(EH,Xtr),e(kF,ztr),e(Y,Qtr),e(Y,SF),e(SF,sMe),e(sMe,Wtr),e(SF,Utr),e(SF,CH),e(CH,Htr),e(SF,Jtr),e(Y,Ytr),e(Y,RF),e(RF,lMe),e(lMe,Ztr),e(RF,Ktr),e(RF,wH),e(wH,ear),e(RF,oar),e(Y,rar),e(Y,PF),e(PF,iMe),e(iMe,tar),e(PF,aar),e(PF,dMe),e(dMe,nar),e(PF,sar),e(Y,lar),e(Y,BF),e(BF,mMe),e(mMe,iar),e(BF,dar),e(BF,AH),e(AH,mar),e(BF,car),e(Y,far),e(Y,IF),e(IF,cMe),e(cMe,gar),e(IF,har),e(IF,LH),e(LH,uar),e(IF,par),e(Y,_ar),e(Y,NF),e(NF,fMe),e(fMe,bar),e(NF,Far),e(NF,yH),e(yH,Tar),e(NF,Mar),e(Y,Ear),e(Y,qF),e(qF,gMe),e(gMe,Car),e(qF,war),e(qF,xH),e(xH,Aar),e(qF,Lar),e(to,yar),e(to,DF),e(DF,xar),e(DF,hMe),e(hMe,$ar),e(DF,kar),e(DF,uMe),e(uMe,Sar),e(to,Rar),M(jF,to,null),b(c,Wto,_),b(c,Qd,_),e(Qd,GF),e(GF,pMe),M(lk,pMe,null),e(Qd,Par),e(Qd,_Me),e(_Me,Bar),b(c,Uto,_),b(c,Go,_),M(ik,Go,null),e(Go,Iar),e(Go,Wd),e(Wd,Nar),e(Wd,$H),e($H,qar),e(Wd,Dar),e(Wd,kH),e(kH,jar),e(Wd,Gar),e(Go,Oar),e(Go,dk),e(dk,Var),e(dk,bMe),e(bMe,Xar),e(dk,zar),e(Go,Qar),e(Go,Lt),M(mk,Lt,null),e(Lt,War),e(Lt,vMe),e(vMe,Uar),e(Lt,Har),e(Lt,Ud),e(Ud,Jar),e(Ud,FMe),e(FMe,Yar),e(Ud,Zar),e(Ud,SH),e(SH,Kar),e(Ud,enr),e(Lt,onr),M(OF,Lt,null),e(Go,rnr),e(Go,ao),M(ck,ao,null),e(ao,tnr),e(ao,TMe),e(TMe,anr),e(ao,nnr),e(ao,cn),e(cn,snr),e(cn,MMe),e(MMe,lnr),e(cn,inr),e(cn,EMe),e(EMe,dnr),e(cn,mnr),e(cn,CMe),e(CMe,cnr),e(cn,fnr),e(ao,gnr),e(ao,he),e(he,VF),e(VF,wMe),e(wMe,hnr),e(VF,unr),e(VF,RH),e(RH,pnr),e(VF,_nr),e(he,bnr),e(he,XF),e(XF,AMe),e(AMe,vnr),e(XF,Fnr),e(XF,PH),e(PH,Tnr),e(XF,Mnr),e(he,Enr),e(he,zF),e(zF,LMe),e(LMe,Cnr),e(zF,wnr),e(zF,BH),e(BH,Anr),e(zF,Lnr),e(he,ynr),e(he,QF),e(QF,yMe),e(yMe,xnr),e(QF,$nr),e(QF,IH),e(IH,knr),e(QF,Snr),e(he,Rnr),e(he,WF),e(WF,xMe),e(xMe,Pnr),e(WF,Bnr),e(WF,NH),e(NH,Inr),e(WF,Nnr),e(he,qnr),e(he,UF),e(UF,$Me),e($Me,Dnr),e(UF,jnr),e(UF,qH),e(qH,Gnr),e(UF,Onr),e(he,Vnr),e(he,HF),e(HF,kMe),e(kMe,Xnr),e(HF,znr),e(HF,DH),e(DH,Qnr),e(HF,Wnr),e(he,Unr),e(he,JF),e(JF,SMe),e(SMe,Hnr),e(JF,Jnr),e(JF,jH),e(jH,Ynr),e(JF,Znr),e(he,Knr),e(he,YF),e(YF,RMe),e(RMe,esr),e(YF,osr),e(YF,GH),e(GH,rsr),e(YF,tsr),e(he,asr),e(he,ZF),e(ZF,PMe),e(PMe,nsr),e(ZF,ssr),e(ZF,OH),e(OH,lsr),e(ZF,isr),e(he,dsr),e(he,KF),e(KF,BMe),e(BMe,msr),e(KF,csr),e(KF,VH),e(VH,fsr),e(KF,gsr),e(he,hsr),e(he,eT),e(eT,IMe),e(IMe,usr),e(eT,psr),e(eT,XH),e(XH,_sr),e(eT,bsr),e(he,vsr),e(he,oT),e(oT,NMe),e(NMe,Fsr),e(oT,Tsr),e(oT,zH),e(zH,Msr),e(oT,Esr),e(he,Csr),e(he,rT),e(rT,qMe),e(qMe,wsr),e(rT,Asr),e(rT,QH),e(QH,Lsr),e(rT,ysr),e(he,xsr),e(he,tT),e(tT,DMe),e(DMe,$sr),e(tT,ksr),e(tT,WH),e(WH,Ssr),e(tT,Rsr),e(he,Psr),e(he,aT),e(aT,jMe),e(jMe,Bsr),e(aT,Isr),e(aT,UH),e(UH,Nsr),e(aT,qsr),e(he,Dsr),e(he,nT),e(nT,GMe),e(GMe,jsr),e(nT,Gsr),e(nT,HH),e(HH,Osr),e(nT,Vsr),e(he,Xsr),e(he,sT),e(sT,OMe),e(OMe,zsr),e(sT,Qsr),e(sT,JH),e(JH,Wsr),e(sT,Usr),e(he,Hsr),e(he,lT),e(lT,VMe),e(VMe,Jsr),e(lT,Ysr),e(lT,YH),e(YH,Zsr),e(lT,Ksr),e(he,elr),e(he,iT),e(iT,XMe),e(XMe,olr),e(iT,rlr),e(iT,ZH),e(ZH,tlr),e(iT,alr),e(ao,nlr),e(ao,dT),e(dT,slr),e(dT,zMe),e(zMe,llr),e(dT,ilr),e(dT,QMe),e(QMe,dlr),e(ao,mlr),M(mT,ao,null),b(c,Hto,_),b(c,Hd,_),e(Hd,cT),e(cT,WMe),M(fk,WMe,null),e(Hd,clr),e(Hd,UMe),e(UMe,flr),b(c,Jto,_),b(c,Oo,_),M(gk,Oo,null),e(Oo,glr),e(Oo,Jd),e(Jd,hlr),e(Jd,KH),e(KH,ulr),e(Jd,plr),e(Jd,eJ),e(eJ,_lr),e(Jd,blr),e(Oo,vlr),e(Oo,hk),e(hk,Flr),e(hk,HMe),e(HMe,Tlr),e(hk,Mlr),e(Oo,Elr),e(Oo,yt),M(uk,yt,null),e(yt,Clr),e(yt,JMe),e(JMe,wlr),e(yt,Alr),e(yt,Yd),e(Yd,Llr),e(Yd,YMe),e(YMe,ylr),e(Yd,xlr),e(Yd,oJ),e(oJ,$lr),e(Yd,klr),e(yt,Slr),M(fT,yt,null),e(Oo,Rlr),e(Oo,no),M(pk,no,null),e(no,Plr),e(no,ZMe),e(ZMe,Blr),e(no,Ilr),e(no,fn),e(fn,Nlr),e(fn,KMe),e(KMe,qlr),e(fn,Dlr),e(fn,eEe),e(eEe,jlr),e(fn,Glr),e(fn,oEe),e(oEe,Olr),e(fn,Vlr),e(no,Xlr),e(no,D),e(D,gT),e(gT,rEe),e(rEe,zlr),e(gT,Qlr),e(gT,rJ),e(rJ,Wlr),e(gT,Ulr),e(D,Hlr),e(D,hT),e(hT,tEe),e(tEe,Jlr),e(hT,Ylr),e(hT,tJ),e(tJ,Zlr),e(hT,Klr),e(D,eir),e(D,uT),e(uT,aEe),e(aEe,oir),e(uT,rir),e(uT,aJ),e(aJ,tir),e(uT,air),e(D,nir),e(D,pT),e(pT,nEe),e(nEe,sir),e(pT,lir),e(pT,nJ),e(nJ,iir),e(pT,dir),e(D,mir),e(D,_T),e(_T,sEe),e(sEe,cir),e(_T,fir),e(_T,sJ),e(sJ,gir),e(_T,hir),e(D,uir),e(D,bT),e(bT,lEe),e(lEe,pir),e(bT,_ir),e(bT,lJ),e(lJ,bir),e(bT,vir),e(D,Fir),e(D,vT),e(vT,iEe),e(iEe,Tir),e(vT,Mir),e(vT,iJ),e(iJ,Eir),e(vT,Cir),e(D,wir),e(D,FT),e(FT,dEe),e(dEe,Air),e(FT,Lir),e(FT,dJ),e(dJ,yir),e(FT,xir),e(D,$ir),e(D,TT),e(TT,mEe),e(mEe,kir),e(TT,Sir),e(TT,mJ),e(mJ,Rir),e(TT,Pir),e(D,Bir),e(D,MT),e(MT,cEe),e(cEe,Iir),e(MT,Nir),e(MT,cJ),e(cJ,qir),e(MT,Dir),e(D,jir),e(D,ET),e(ET,fEe),e(fEe,Gir),e(ET,Oir),e(ET,fJ),e(fJ,Vir),e(ET,Xir),e(D,zir),e(D,CT),e(CT,gEe),e(gEe,Qir),e(CT,Wir),e(CT,gJ),e(gJ,Uir),e(CT,Hir),e(D,Jir),e(D,wT),e(wT,hEe),e(hEe,Yir),e(wT,Zir),e(wT,hJ),e(hJ,Kir),e(wT,edr),e(D,odr),e(D,AT),e(AT,uEe),e(uEe,rdr),e(AT,tdr),e(AT,uJ),e(uJ,adr),e(AT,ndr),e(D,sdr),e(D,LT),e(LT,pEe),e(pEe,ldr),e(LT,idr),e(LT,pJ),e(pJ,ddr),e(LT,mdr),e(D,cdr),e(D,yT),e(yT,_Ee),e(_Ee,fdr),e(yT,gdr),e(yT,_J),e(_J,hdr),e(yT,udr),e(D,pdr),e(D,xT),e(xT,bEe),e(bEe,_dr),e(xT,bdr),e(xT,bJ),e(bJ,vdr),e(xT,Fdr),e(D,Tdr),e(D,$T),e($T,vEe),e(vEe,Mdr),e($T,Edr),e($T,vJ),e(vJ,Cdr),e($T,wdr),e(D,Adr),e(D,kT),e(kT,FEe),e(FEe,Ldr),e(kT,ydr),e(kT,FJ),e(FJ,xdr),e(kT,$dr),e(D,kdr),e(D,ST),e(ST,TEe),e(TEe,Sdr),e(ST,Rdr),e(ST,TJ),e(TJ,Pdr),e(ST,Bdr),e(D,Idr),e(D,RT),e(RT,MEe),e(MEe,Ndr),e(RT,qdr),e(RT,MJ),e(MJ,Ddr),e(RT,jdr),e(D,Gdr),e(D,PT),e(PT,EEe),e(EEe,Odr),e(PT,Vdr),e(PT,EJ),e(EJ,Xdr),e(PT,zdr),e(D,Qdr),e(D,BT),e(BT,CEe),e(CEe,Wdr),e(BT,Udr),e(BT,CJ),e(CJ,Hdr),e(BT,Jdr),e(D,Ydr),e(D,IT),e(IT,wEe),e(wEe,Zdr),e(IT,Kdr),e(IT,wJ),e(wJ,emr),e(IT,omr),e(D,rmr),e(D,NT),e(NT,AEe),e(AEe,tmr),e(NT,amr),e(NT,AJ),e(AJ,nmr),e(NT,smr),e(D,lmr),e(D,qT),e(qT,LEe),e(LEe,imr),e(qT,dmr),e(qT,LJ),e(LJ,mmr),e(qT,cmr),e(D,fmr),e(D,DT),e(DT,yEe),e(yEe,gmr),e(DT,hmr),e(DT,yJ),e(yJ,umr),e(DT,pmr),e(D,_mr),e(D,jT),e(jT,xEe),e(xEe,bmr),e(jT,vmr),e(jT,xJ),e(xJ,Fmr),e(jT,Tmr),e(D,Mmr),e(D,GT),e(GT,$Ee),e($Ee,Emr),e(GT,Cmr),e(GT,$J),e($J,wmr),e(GT,Amr),e(D,Lmr),e(D,OT),e(OT,kEe),e(kEe,ymr),e(OT,xmr),e(OT,kJ),e(kJ,$mr),e(OT,kmr),e(D,Smr),e(D,VT),e(VT,SEe),e(SEe,Rmr),e(VT,Pmr),e(VT,SJ),e(SJ,Bmr),e(VT,Imr),e(D,Nmr),e(D,XT),e(XT,REe),e(REe,qmr),e(XT,Dmr),e(XT,RJ),e(RJ,jmr),e(XT,Gmr),e(D,Omr),e(D,zT),e(zT,PEe),e(PEe,Vmr),e(zT,Xmr),e(zT,PJ),e(PJ,zmr),e(zT,Qmr),e(D,Wmr),e(D,QT),e(QT,BEe),e(BEe,Umr),e(QT,Hmr),e(QT,BJ),e(BJ,Jmr),e(QT,Ymr),e(D,Zmr),e(D,WT),e(WT,IEe),e(IEe,Kmr),e(WT,ecr),e(WT,IJ),e(IJ,ocr),e(WT,rcr),e(D,tcr),e(D,UT),e(UT,NEe),e(NEe,acr),e(UT,ncr),e(UT,NJ),e(NJ,scr),e(UT,lcr),e(D,icr),e(D,HT),e(HT,qEe),e(qEe,dcr),e(HT,mcr),e(HT,qJ),e(qJ,ccr),e(HT,fcr),e(D,gcr),e(D,JT),e(JT,DEe),e(DEe,hcr),e(JT,ucr),e(JT,DJ),e(DJ,pcr),e(JT,_cr),e(D,bcr),e(D,YT),e(YT,jEe),e(jEe,vcr),e(YT,Fcr),e(YT,jJ),e(jJ,Tcr),e(YT,Mcr),e(D,Ecr),e(D,ZT),e(ZT,GEe),e(GEe,Ccr),e(ZT,wcr),e(ZT,GJ),e(GJ,Acr),e(ZT,Lcr),e(D,ycr),e(D,KT),e(KT,OEe),e(OEe,xcr),e(KT,$cr),e(KT,OJ),e(OJ,kcr),e(KT,Scr),e(D,Rcr),e(D,eM),e(eM,VEe),e(VEe,Pcr),e(eM,Bcr),e(eM,VJ),e(VJ,Icr),e(eM,Ncr),e(D,qcr),e(D,oM),e(oM,XEe),e(XEe,Dcr),e(oM,jcr),e(oM,XJ),e(XJ,Gcr),e(oM,Ocr),e(D,Vcr),e(D,rM),e(rM,zEe),e(zEe,Xcr),e(rM,zcr),e(rM,zJ),e(zJ,Qcr),e(rM,Wcr),e(D,Ucr),e(D,tM),e(tM,QEe),e(QEe,Hcr),e(tM,Jcr),e(tM,QJ),e(QJ,Ycr),e(tM,Zcr),e(D,Kcr),e(D,aM),e(aM,WEe),e(WEe,efr),e(aM,ofr),e(aM,WJ),e(WJ,rfr),e(aM,tfr),e(D,afr),e(D,nM),e(nM,UEe),e(UEe,nfr),e(nM,sfr),e(nM,UJ),e(UJ,lfr),e(nM,ifr),e(D,dfr),e(D,sM),e(sM,HEe),e(HEe,mfr),e(sM,cfr),e(sM,HJ),e(HJ,ffr),e(sM,gfr),e(D,hfr),e(D,lM),e(lM,JEe),e(JEe,ufr),e(lM,pfr),e(lM,JJ),e(JJ,_fr),e(lM,bfr),e(D,vfr),e(D,iM),e(iM,YEe),e(YEe,Ffr),e(iM,Tfr),e(iM,YJ),e(YJ,Mfr),e(iM,Efr),e(D,Cfr),e(D,dM),e(dM,ZEe),e(ZEe,wfr),e(dM,Afr),e(dM,ZJ),e(ZJ,Lfr),e(dM,yfr),e(D,xfr),e(D,mM),e(mM,KEe),e(KEe,$fr),e(mM,kfr),e(mM,KJ),e(KJ,Sfr),e(mM,Rfr),e(D,Pfr),e(D,cM),e(cM,e4e),e(e4e,Bfr),e(cM,Ifr),e(cM,eY),e(eY,Nfr),e(cM,qfr),e(D,Dfr),e(D,fM),e(fM,o4e),e(o4e,jfr),e(fM,Gfr),e(fM,oY),e(oY,Ofr),e(fM,Vfr),e(D,Xfr),e(D,gM),e(gM,r4e),e(r4e,zfr),e(gM,Qfr),e(gM,rY),e(rY,Wfr),e(gM,Ufr),e(D,Hfr),e(D,hM),e(hM,t4e),e(t4e,Jfr),e(hM,Yfr),e(hM,tY),e(tY,Zfr),e(hM,Kfr),e(no,egr),e(no,uM),e(uM,ogr),e(uM,a4e),e(a4e,rgr),e(uM,tgr),e(uM,n4e),e(n4e,agr),e(no,ngr),M(pM,no,null),b(c,Yto,_),b(c,Zd,_),e(Zd,_M),e(_M,s4e),M(_k,s4e,null),e(Zd,sgr),e(Zd,l4e),e(l4e,lgr),b(c,Zto,_),b(c,Vo,_),M(bk,Vo,null),e(Vo,igr),e(Vo,Kd),e(Kd,dgr),e(Kd,aY),e(aY,mgr),e(Kd,cgr),e(Kd,nY),e(nY,fgr),e(Kd,ggr),e(Vo,hgr),e(Vo,vk),e(vk,ugr),e(vk,i4e),e(i4e,pgr),e(vk,_gr),e(Vo,bgr),e(Vo,xt),M(Fk,xt,null),e(xt,vgr),e(xt,d4e),e(d4e,Fgr),e(xt,Tgr),e(xt,em),e(em,Mgr),e(em,m4e),e(m4e,Egr),e(em,Cgr),e(em,sY),e(sY,wgr),e(em,Agr),e(xt,Lgr),M(bM,xt,null),e(Vo,ygr),e(Vo,so),M(Tk,so,null),e(so,xgr),e(so,c4e),e(c4e,$gr),e(so,kgr),e(so,gn),e(gn,Sgr),e(gn,f4e),e(f4e,Rgr),e(gn,Pgr),e(gn,g4e),e(g4e,Bgr),e(gn,Igr),e(gn,h4e),e(h4e,Ngr),e(gn,qgr),e(so,Dgr),e(so,K),e(K,vM),e(vM,u4e),e(u4e,jgr),e(vM,Ggr),e(vM,lY),e(lY,Ogr),e(vM,Vgr),e(K,Xgr),e(K,FM),e(FM,p4e),e(p4e,zgr),e(FM,Qgr),e(FM,iY),e(iY,Wgr),e(FM,Ugr),e(K,Hgr),e(K,TM),e(TM,_4e),e(_4e,Jgr),e(TM,Ygr),e(TM,dY),e(dY,Zgr),e(TM,Kgr),e(K,ehr),e(K,MM),e(MM,b4e),e(b4e,ohr),e(MM,rhr),e(MM,mY),e(mY,thr),e(MM,ahr),e(K,nhr),e(K,EM),e(EM,v4e),e(v4e,shr),e(EM,lhr),e(EM,cY),e(cY,ihr),e(EM,dhr),e(K,mhr),e(K,CM),e(CM,F4e),e(F4e,chr),e(CM,fhr),e(CM,fY),e(fY,ghr),e(CM,hhr),e(K,uhr),e(K,wM),e(wM,T4e),e(T4e,phr),e(wM,_hr),e(wM,gY),e(gY,bhr),e(wM,vhr),e(K,Fhr),e(K,AM),e(AM,M4e),e(M4e,Thr),e(AM,Mhr),e(AM,hY),e(hY,Ehr),e(AM,Chr),e(K,whr),e(K,LM),e(LM,E4e),e(E4e,Ahr),e(LM,Lhr),e(LM,uY),e(uY,yhr),e(LM,xhr),e(K,$hr),e(K,yM),e(yM,C4e),e(C4e,khr),e(yM,Shr),e(yM,pY),e(pY,Rhr),e(yM,Phr),e(K,Bhr),e(K,xM),e(xM,w4e),e(w4e,Ihr),e(xM,Nhr),e(xM,_Y),e(_Y,qhr),e(xM,Dhr),e(K,jhr),e(K,$M),e($M,A4e),e(A4e,Ghr),e($M,Ohr),e($M,bY),e(bY,Vhr),e($M,Xhr),e(K,zhr),e(K,kM),e(kM,L4e),e(L4e,Qhr),e(kM,Whr),e(kM,vY),e(vY,Uhr),e(kM,Hhr),e(K,Jhr),e(K,SM),e(SM,y4e),e(y4e,Yhr),e(SM,Zhr),e(SM,FY),e(FY,Khr),e(SM,eur),e(K,our),e(K,RM),e(RM,x4e),e(x4e,rur),e(RM,tur),e(RM,TY),e(TY,aur),e(RM,nur),e(K,sur),e(K,PM),e(PM,$4e),e($4e,lur),e(PM,iur),e(PM,MY),e(MY,dur),e(PM,mur),e(K,cur),e(K,BM),e(BM,k4e),e(k4e,fur),e(BM,gur),e(BM,EY),e(EY,hur),e(BM,uur),e(K,pur),e(K,IM),e(IM,S4e),e(S4e,_ur),e(IM,bur),e(IM,CY),e(CY,vur),e(IM,Fur),e(K,Tur),e(K,NM),e(NM,R4e),e(R4e,Mur),e(NM,Eur),e(NM,wY),e(wY,Cur),e(NM,wur),e(K,Aur),e(K,qM),e(qM,P4e),e(P4e,Lur),e(qM,yur),e(qM,AY),e(AY,xur),e(qM,$ur),e(K,kur),e(K,DM),e(DM,B4e),e(B4e,Sur),e(DM,Rur),e(DM,LY),e(LY,Pur),e(DM,Bur),e(K,Iur),e(K,jM),e(jM,I4e),e(I4e,Nur),e(jM,qur),e(jM,yY),e(yY,Dur),e(jM,jur),e(K,Gur),e(K,GM),e(GM,N4e),e(N4e,Our),e(GM,Vur),e(GM,xY),e(xY,Xur),e(GM,zur),e(K,Qur),e(K,OM),e(OM,q4e),e(q4e,Wur),e(OM,Uur),e(OM,$Y),e($Y,Hur),e(OM,Jur),e(K,Yur),e(K,VM),e(VM,D4e),e(D4e,Zur),e(VM,Kur),e(VM,kY),e(kY,epr),e(VM,opr),e(K,rpr),e(K,XM),e(XM,j4e),e(j4e,tpr),e(XM,apr),e(XM,SY),e(SY,npr),e(XM,spr),e(K,lpr),e(K,zM),e(zM,G4e),e(G4e,ipr),e(zM,dpr),e(zM,RY),e(RY,mpr),e(zM,cpr),e(K,fpr),e(K,QM),e(QM,O4e),e(O4e,gpr),e(QM,hpr),e(QM,PY),e(PY,upr),e(QM,ppr),e(K,_pr),e(K,WM),e(WM,V4e),e(V4e,bpr),e(WM,vpr),e(WM,BY),e(BY,Fpr),e(WM,Tpr),e(K,Mpr),e(K,UM),e(UM,X4e),e(X4e,Epr),e(UM,Cpr),e(UM,IY),e(IY,wpr),e(UM,Apr),e(K,Lpr),e(K,HM),e(HM,z4e),e(z4e,ypr),e(HM,xpr),e(HM,NY),e(NY,$pr),e(HM,kpr),e(K,Spr),e(K,JM),e(JM,Q4e),e(Q4e,Rpr),e(JM,Ppr),e(JM,qY),e(qY,Bpr),e(JM,Ipr),e(so,Npr),e(so,YM),e(YM,qpr),e(YM,W4e),e(W4e,Dpr),e(YM,jpr),e(YM,U4e),e(U4e,Gpr),e(so,Opr),M(ZM,so,null),b(c,Kto,_),b(c,om,_),e(om,KM),e(KM,H4e),M(Mk,H4e,null),e(om,Vpr),e(om,J4e),e(J4e,Xpr),b(c,eao,_),b(c,Xo,_),M(Ek,Xo,null),e(Xo,zpr),e(Xo,rm),e(rm,Qpr),e(rm,DY),e(DY,Wpr),e(rm,Upr),e(rm,jY),e(jY,Hpr),e(rm,Jpr),e(Xo,Ypr),e(Xo,Ck),e(Ck,Zpr),e(Ck,Y4e),e(Y4e,Kpr),e(Ck,e_r),e(Xo,o_r),e(Xo,$t),M(wk,$t,null),e($t,r_r),e($t,Z4e),e(Z4e,t_r),e($t,a_r),e($t,tm),e(tm,n_r),e(tm,K4e),e(K4e,s_r),e(tm,l_r),e(tm,GY),e(GY,i_r),e(tm,d_r),e($t,m_r),M(eE,$t,null),e(Xo,c_r),e(Xo,lo),M(Ak,lo,null),e(lo,f_r),e(lo,eCe),e(eCe,g_r),e(lo,h_r),e(lo,hn),e(hn,u_r),e(hn,oCe),e(oCe,p_r),e(hn,__r),e(hn,rCe),e(rCe,b_r),e(hn,v_r),e(hn,tCe),e(tCe,F_r),e(hn,T_r),e(lo,M_r),e(lo,Ue),e(Ue,oE),e(oE,aCe),e(aCe,E_r),e(oE,C_r),e(oE,OY),e(OY,w_r),e(oE,A_r),e(Ue,L_r),e(Ue,rE),e(rE,nCe),e(nCe,y_r),e(rE,x_r),e(rE,VY),e(VY,$_r),e(rE,k_r),e(Ue,S_r),e(Ue,tE),e(tE,sCe),e(sCe,R_r),e(tE,P_r),e(tE,XY),e(XY,B_r),e(tE,I_r),e(Ue,N_r),e(Ue,aE),e(aE,lCe),e(lCe,q_r),e(aE,D_r),e(aE,zY),e(zY,j_r),e(aE,G_r),e(Ue,O_r),e(Ue,nE),e(nE,iCe),e(iCe,V_r),e(nE,X_r),e(nE,QY),e(QY,z_r),e(nE,Q_r),e(Ue,W_r),e(Ue,sE),e(sE,dCe),e(dCe,U_r),e(sE,H_r),e(sE,WY),e(WY,J_r),e(sE,Y_r),e(Ue,Z_r),e(Ue,lE),e(lE,mCe),e(mCe,K_r),e(lE,e1r),e(lE,UY),e(UY,o1r),e(lE,r1r),e(lo,t1r),e(lo,iE),e(iE,a1r),e(iE,cCe),e(cCe,n1r),e(iE,s1r),e(iE,fCe),e(fCe,l1r),e(lo,i1r),M(dE,lo,null),b(c,oao,_),b(c,am,_),e(am,mE),e(mE,gCe),M(Lk,gCe,null),e(am,d1r),e(am,hCe),e(hCe,m1r),b(c,rao,_),b(c,zo,_),M(yk,zo,null),e(zo,c1r),e(zo,nm),e(nm,f1r),e(nm,HY),e(HY,g1r),e(nm,h1r),e(nm,JY),e(JY,u1r),e(nm,p1r),e(zo,_1r),e(zo,xk),e(xk,b1r),e(xk,uCe),e(uCe,v1r),e(xk,F1r),e(zo,T1r),e(zo,kt),M($k,kt,null),e(kt,M1r),e(kt,pCe),e(pCe,E1r),e(kt,C1r),e(kt,sm),e(sm,w1r),e(sm,_Ce),e(_Ce,A1r),e(sm,L1r),e(sm,YY),e(YY,y1r),e(sm,x1r),e(kt,$1r),M(cE,kt,null),e(zo,k1r),e(zo,io),M(kk,io,null),e(io,S1r),e(io,bCe),e(bCe,R1r),e(io,P1r),e(io,un),e(un,B1r),e(un,vCe),e(vCe,I1r),e(un,N1r),e(un,FCe),e(FCe,q1r),e(un,D1r),e(un,TCe),e(TCe,j1r),e(un,G1r),e(io,O1r),e(io,U),e(U,fE),e(fE,MCe),e(MCe,V1r),e(fE,X1r),e(fE,ZY),e(ZY,z1r),e(fE,Q1r),e(U,W1r),e(U,gE),e(gE,ECe),e(ECe,U1r),e(gE,H1r),e(gE,KY),e(KY,J1r),e(gE,Y1r),e(U,Z1r),e(U,hE),e(hE,CCe),e(CCe,K1r),e(hE,e2r),e(hE,eZ),e(eZ,o2r),e(hE,r2r),e(U,t2r),e(U,uE),e(uE,wCe),e(wCe,a2r),e(uE,n2r),e(uE,oZ),e(oZ,s2r),e(uE,l2r),e(U,i2r),e(U,pE),e(pE,ACe),e(ACe,d2r),e(pE,m2r),e(pE,rZ),e(rZ,c2r),e(pE,f2r),e(U,g2r),e(U,_E),e(_E,LCe),e(LCe,h2r),e(_E,u2r),e(_E,tZ),e(tZ,p2r),e(_E,_2r),e(U,b2r),e(U,bE),e(bE,yCe),e(yCe,v2r),e(bE,F2r),e(bE,aZ),e(aZ,T2r),e(bE,M2r),e(U,E2r),e(U,vE),e(vE,xCe),e(xCe,C2r),e(vE,w2r),e(vE,nZ),e(nZ,A2r),e(vE,L2r),e(U,y2r),e(U,FE),e(FE,$Ce),e($Ce,x2r),e(FE,$2r),e(FE,sZ),e(sZ,k2r),e(FE,S2r),e(U,R2r),e(U,TE),e(TE,kCe),e(kCe,P2r),e(TE,B2r),e(TE,lZ),e(lZ,I2r),e(TE,N2r),e(U,q2r),e(U,ME),e(ME,SCe),e(SCe,D2r),e(ME,j2r),e(ME,iZ),e(iZ,G2r),e(ME,O2r),e(U,V2r),e(U,EE),e(EE,RCe),e(RCe,X2r),e(EE,z2r),e(EE,dZ),e(dZ,Q2r),e(EE,W2r),e(U,U2r),e(U,CE),e(CE,PCe),e(PCe,H2r),e(CE,J2r),e(CE,mZ),e(mZ,Y2r),e(CE,Z2r),e(U,K2r),e(U,wE),e(wE,BCe),e(BCe,ebr),e(wE,obr),e(wE,cZ),e(cZ,rbr),e(wE,tbr),e(U,abr),e(U,AE),e(AE,ICe),e(ICe,nbr),e(AE,sbr),e(AE,fZ),e(fZ,lbr),e(AE,ibr),e(U,dbr),e(U,LE),e(LE,NCe),e(NCe,mbr),e(LE,cbr),e(LE,gZ),e(gZ,fbr),e(LE,gbr),e(U,hbr),e(U,yE),e(yE,qCe),e(qCe,ubr),e(yE,pbr),e(yE,hZ),e(hZ,_br),e(yE,bbr),e(U,vbr),e(U,xE),e(xE,DCe),e(DCe,Fbr),e(xE,Tbr),e(xE,uZ),e(uZ,Mbr),e(xE,Ebr),e(U,Cbr),e(U,$E),e($E,jCe),e(jCe,wbr),e($E,Abr),e($E,pZ),e(pZ,Lbr),e($E,ybr),e(U,xbr),e(U,kE),e(kE,GCe),e(GCe,$br),e(kE,kbr),e(kE,_Z),e(_Z,Sbr),e(kE,Rbr),e(U,Pbr),e(U,SE),e(SE,OCe),e(OCe,Bbr),e(SE,Ibr),e(SE,bZ),e(bZ,Nbr),e(SE,qbr),e(U,Dbr),e(U,RE),e(RE,VCe),e(VCe,jbr),e(RE,Gbr),e(RE,vZ),e(vZ,Obr),e(RE,Vbr),e(U,Xbr),e(U,PE),e(PE,XCe),e(XCe,zbr),e(PE,Qbr),e(PE,FZ),e(FZ,Wbr),e(PE,Ubr),e(U,Hbr),e(U,BE),e(BE,zCe),e(zCe,Jbr),e(BE,Ybr),e(BE,TZ),e(TZ,Zbr),e(BE,Kbr),e(U,evr),e(U,IE),e(IE,QCe),e(QCe,ovr),e(IE,rvr),e(IE,MZ),e(MZ,tvr),e(IE,avr),e(U,nvr),e(U,NE),e(NE,WCe),e(WCe,svr),e(NE,lvr),e(NE,EZ),e(EZ,ivr),e(NE,dvr),e(U,mvr),e(U,qE),e(qE,UCe),e(UCe,cvr),e(qE,fvr),e(qE,CZ),e(CZ,gvr),e(qE,hvr),e(U,uvr),e(U,DE),e(DE,HCe),e(HCe,pvr),e(DE,_vr),e(DE,wZ),e(wZ,bvr),e(DE,vvr),e(U,Fvr),e(U,jE),e(jE,JCe),e(JCe,Tvr),e(jE,Mvr),e(jE,AZ),e(AZ,Evr),e(jE,Cvr),e(U,wvr),e(U,GE),e(GE,YCe),e(YCe,Avr),e(GE,Lvr),e(GE,LZ),e(LZ,yvr),e(GE,xvr),e(U,$vr),e(U,OE),e(OE,ZCe),e(ZCe,kvr),e(OE,Svr),e(OE,yZ),e(yZ,Rvr),e(OE,Pvr),e(U,Bvr),e(U,VE),e(VE,KCe),e(KCe,Ivr),e(VE,Nvr),e(VE,xZ),e(xZ,qvr),e(VE,Dvr),e(U,jvr),e(U,XE),e(XE,e3e),e(e3e,Gvr),e(XE,Ovr),e(XE,$Z),e($Z,Vvr),e(XE,Xvr),e(U,zvr),e(U,zE),e(zE,o3e),e(o3e,Qvr),e(zE,Wvr),e(zE,kZ),e(kZ,Uvr),e(zE,Hvr),e(U,Jvr),e(U,QE),e(QE,r3e),e(r3e,Yvr),e(QE,Zvr),e(QE,SZ),e(SZ,Kvr),e(QE,eFr),e(U,oFr),e(U,WE),e(WE,t3e),e(t3e,rFr),e(WE,tFr),e(WE,RZ),e(RZ,aFr),e(WE,nFr),e(U,sFr),e(U,UE),e(UE,a3e),e(a3e,lFr),e(UE,iFr),e(UE,PZ),e(PZ,dFr),e(UE,mFr),e(U,cFr),e(U,HE),e(HE,n3e),e(n3e,fFr),e(HE,gFr),e(HE,BZ),e(BZ,hFr),e(HE,uFr),e(U,pFr),e(U,JE),e(JE,s3e),e(s3e,_Fr),e(JE,bFr),e(JE,IZ),e(IZ,vFr),e(JE,FFr),e(U,TFr),e(U,YE),e(YE,l3e),e(l3e,MFr),e(YE,EFr),e(YE,NZ),e(NZ,CFr),e(YE,wFr),e(U,AFr),e(U,ZE),e(ZE,i3e),e(i3e,LFr),e(ZE,yFr),e(ZE,qZ),e(qZ,xFr),e(ZE,$Fr),e(io,kFr),e(io,KE),e(KE,SFr),e(KE,d3e),e(d3e,RFr),e(KE,PFr),e(KE,m3e),e(m3e,BFr),e(io,IFr),M(e4,io,null),b(c,tao,_),b(c,lm,_),e(lm,o4),e(o4,c3e),M(Sk,c3e,null),e(lm,NFr),e(lm,f3e),e(f3e,qFr),b(c,aao,_),b(c,Qo,_),M(Rk,Qo,null),e(Qo,DFr),e(Qo,im),e(im,jFr),e(im,DZ),e(DZ,GFr),e(im,OFr),e(im,jZ),e(jZ,VFr),e(im,XFr),e(Qo,zFr),e(Qo,Pk),e(Pk,QFr),e(Pk,g3e),e(g3e,WFr),e(Pk,UFr),e(Qo,HFr),e(Qo,St),M(Bk,St,null),e(St,JFr),e(St,h3e),e(h3e,YFr),e(St,ZFr),e(St,dm),e(dm,KFr),e(dm,u3e),e(u3e,eTr),e(dm,oTr),e(dm,GZ),e(GZ,rTr),e(dm,tTr),e(St,aTr),M(r4,St,null),e(Qo,nTr),e(Qo,mo),M(Ik,mo,null),e(mo,sTr),e(mo,p3e),e(p3e,lTr),e(mo,iTr),e(mo,pn),e(pn,dTr),e(pn,_3e),e(_3e,mTr),e(pn,cTr),e(pn,b3e),e(b3e,fTr),e(pn,gTr),e(pn,v3e),e(v3e,hTr),e(pn,uTr),e(mo,pTr),e(mo,O),e(O,t4),e(t4,F3e),e(F3e,_Tr),e(t4,bTr),e(t4,OZ),e(OZ,vTr),e(t4,FTr),e(O,TTr),e(O,a4),e(a4,T3e),e(T3e,MTr),e(a4,ETr),e(a4,VZ),e(VZ,CTr),e(a4,wTr),e(O,ATr),e(O,n4),e(n4,M3e),e(M3e,LTr),e(n4,yTr),e(n4,XZ),e(XZ,xTr),e(n4,$Tr),e(O,kTr),e(O,s4),e(s4,E3e),e(E3e,STr),e(s4,RTr),e(s4,zZ),e(zZ,PTr),e(s4,BTr),e(O,ITr),e(O,l4),e(l4,C3e),e(C3e,NTr),e(l4,qTr),e(l4,QZ),e(QZ,DTr),e(l4,jTr),e(O,GTr),e(O,i4),e(i4,w3e),e(w3e,OTr),e(i4,VTr),e(i4,WZ),e(WZ,XTr),e(i4,zTr),e(O,QTr),e(O,d4),e(d4,A3e),e(A3e,WTr),e(d4,UTr),e(d4,UZ),e(UZ,HTr),e(d4,JTr),e(O,YTr),e(O,m4),e(m4,L3e),e(L3e,ZTr),e(m4,KTr),e(m4,HZ),e(HZ,eMr),e(m4,oMr),e(O,rMr),e(O,c4),e(c4,y3e),e(y3e,tMr),e(c4,aMr),e(c4,JZ),e(JZ,nMr),e(c4,sMr),e(O,lMr),e(O,f4),e(f4,x3e),e(x3e,iMr),e(f4,dMr),e(f4,YZ),e(YZ,mMr),e(f4,cMr),e(O,fMr),e(O,g4),e(g4,$3e),e($3e,gMr),e(g4,hMr),e(g4,ZZ),e(ZZ,uMr),e(g4,pMr),e(O,_Mr),e(O,h4),e(h4,k3e),e(k3e,bMr),e(h4,vMr),e(h4,KZ),e(KZ,FMr),e(h4,TMr),e(O,MMr),e(O,u4),e(u4,S3e),e(S3e,EMr),e(u4,CMr),e(u4,eK),e(eK,wMr),e(u4,AMr),e(O,LMr),e(O,p4),e(p4,R3e),e(R3e,yMr),e(p4,xMr),e(p4,oK),e(oK,$Mr),e(p4,kMr),e(O,SMr),e(O,_4),e(_4,P3e),e(P3e,RMr),e(_4,PMr),e(_4,rK),e(rK,BMr),e(_4,IMr),e(O,NMr),e(O,b4),e(b4,B3e),e(B3e,qMr),e(b4,DMr),e(b4,tK),e(tK,jMr),e(b4,GMr),e(O,OMr),e(O,v4),e(v4,I3e),e(I3e,VMr),e(v4,XMr),e(v4,aK),e(aK,zMr),e(v4,QMr),e(O,WMr),e(O,F4),e(F4,N3e),e(N3e,UMr),e(F4,HMr),e(F4,nK),e(nK,JMr),e(F4,YMr),e(O,ZMr),e(O,T4),e(T4,q3e),e(q3e,KMr),e(T4,eEr),e(T4,sK),e(sK,oEr),e(T4,rEr),e(O,tEr),e(O,M4),e(M4,D3e),e(D3e,aEr),e(M4,nEr),e(M4,lK),e(lK,sEr),e(M4,lEr),e(O,iEr),e(O,E4),e(E4,j3e),e(j3e,dEr),e(E4,mEr),e(E4,iK),e(iK,cEr),e(E4,fEr),e(O,gEr),e(O,C4),e(C4,G3e),e(G3e,hEr),e(C4,uEr),e(C4,dK),e(dK,pEr),e(C4,_Er),e(O,bEr),e(O,w4),e(w4,O3e),e(O3e,vEr),e(w4,FEr),e(w4,mK),e(mK,TEr),e(w4,MEr),e(O,EEr),e(O,A4),e(A4,V3e),e(V3e,CEr),e(A4,wEr),e(A4,cK),e(cK,AEr),e(A4,LEr),e(O,yEr),e(O,L4),e(L4,X3e),e(X3e,xEr),e(L4,$Er),e(L4,fK),e(fK,kEr),e(L4,SEr),e(O,REr),e(O,y4),e(y4,z3e),e(z3e,PEr),e(y4,BEr),e(y4,gK),e(gK,IEr),e(y4,NEr),e(O,qEr),e(O,x4),e(x4,Q3e),e(Q3e,DEr),e(x4,jEr),e(x4,hK),e(hK,GEr),e(x4,OEr),e(O,VEr),e(O,$4),e($4,W3e),e(W3e,XEr),e($4,zEr),e($4,uK),e(uK,QEr),e($4,WEr),e(O,UEr),e(O,k4),e(k4,U3e),e(U3e,HEr),e(k4,JEr),e(k4,pK),e(pK,YEr),e(k4,ZEr),e(O,KEr),e(O,S4),e(S4,H3e),e(H3e,e4r),e(S4,o4r),e(S4,_K),e(_K,r4r),e(S4,t4r),e(O,a4r),e(O,R4),e(R4,J3e),e(J3e,n4r),e(R4,s4r),e(R4,bK),e(bK,l4r),e(R4,i4r),e(O,d4r),e(O,P4),e(P4,Y3e),e(Y3e,m4r),e(P4,c4r),e(P4,vK),e(vK,f4r),e(P4,g4r),e(O,h4r),e(O,B4),e(B4,Z3e),e(Z3e,u4r),e(B4,p4r),e(B4,FK),e(FK,_4r),e(B4,b4r),e(O,v4r),e(O,I4),e(I4,K3e),e(K3e,F4r),e(I4,T4r),e(I4,TK),e(TK,M4r),e(I4,E4r),e(O,C4r),e(O,N4),e(N4,e5e),e(e5e,w4r),e(N4,A4r),e(N4,MK),e(MK,L4r),e(N4,y4r),e(O,x4r),e(O,q4),e(q4,o5e),e(o5e,$4r),e(q4,k4r),e(q4,EK),e(EK,S4r),e(q4,R4r),e(O,P4r),e(O,D4),e(D4,r5e),e(r5e,B4r),e(D4,I4r),e(D4,CK),e(CK,N4r),e(D4,q4r),e(O,D4r),e(O,j4),e(j4,t5e),e(t5e,j4r),e(j4,G4r),e(j4,wK),e(wK,O4r),e(j4,V4r),e(O,X4r),e(O,G4),e(G4,a5e),e(a5e,z4r),e(G4,Q4r),e(G4,AK),e(AK,W4r),e(G4,U4r),e(O,H4r),e(O,O4),e(O4,n5e),e(n5e,J4r),e(O4,Y4r),e(O4,LK),e(LK,Z4r),e(O4,K4r),e(O,eCr),e(O,V4),e(V4,s5e),e(s5e,oCr),e(V4,rCr),e(V4,yK),e(yK,tCr),e(V4,aCr),e(O,nCr),e(O,X4),e(X4,l5e),e(l5e,sCr),e(X4,lCr),e(X4,xK),e(xK,iCr),e(X4,dCr),e(O,mCr),e(O,z4),e(z4,i5e),e(i5e,cCr),e(z4,fCr),e(z4,$K),e($K,gCr),e(z4,hCr),e(O,uCr),e(O,Q4),e(Q4,d5e),e(d5e,pCr),e(Q4,_Cr),e(Q4,kK),e(kK,bCr),e(Q4,vCr),e(O,FCr),e(O,W4),e(W4,m5e),e(m5e,TCr),e(W4,MCr),e(W4,SK),e(SK,ECr),e(W4,CCr),e(O,wCr),e(O,U4),e(U4,c5e),e(c5e,ACr),e(U4,LCr),e(U4,RK),e(RK,yCr),e(U4,xCr),e(O,$Cr),e(O,H4),e(H4,f5e),e(f5e,kCr),e(H4,SCr),e(H4,PK),e(PK,RCr),e(H4,PCr),e(O,BCr),e(O,J4),e(J4,g5e),e(g5e,ICr),e(J4,NCr),e(J4,BK),e(BK,qCr),e(J4,DCr),e(mo,jCr),e(mo,Y4),e(Y4,GCr),e(Y4,h5e),e(h5e,OCr),e(Y4,VCr),e(Y4,u5e),e(u5e,XCr),e(mo,zCr),M(Z4,mo,null),b(c,nao,_),b(c,mm,_),e(mm,K4),e(K4,p5e),M(Nk,p5e,null),e(mm,QCr),e(mm,_5e),e(_5e,WCr),b(c,sao,_),b(c,Wo,_),M(qk,Wo,null),e(Wo,UCr),e(Wo,cm),e(cm,HCr),e(cm,IK),e(IK,JCr),e(cm,YCr),e(cm,NK),e(NK,ZCr),e(cm,KCr),e(Wo,e3r),e(Wo,Dk),e(Dk,o3r),e(Dk,b5e),e(b5e,r3r),e(Dk,t3r),e(Wo,a3r),e(Wo,Rt),M(jk,Rt,null),e(Rt,n3r),e(Rt,v5e),e(v5e,s3r),e(Rt,l3r),e(Rt,fm),e(fm,i3r),e(fm,F5e),e(F5e,d3r),e(fm,m3r),e(fm,qK),e(qK,c3r),e(fm,f3r),e(Rt,g3r),M(eC,Rt,null),e(Wo,h3r),e(Wo,co),M(Gk,co,null),e(co,u3r),e(co,T5e),e(T5e,p3r),e(co,_3r),e(co,_n),e(_n,b3r),e(_n,M5e),e(M5e,v3r),e(_n,F3r),e(_n,E5e),e(E5e,T3r),e(_n,M3r),e(_n,C5e),e(C5e,E3r),e(_n,C3r),e(co,w3r),e(co,w5e),e(w5e,oC),e(oC,A5e),e(A5e,A3r),e(oC,L3r),e(oC,DK),e(DK,y3r),e(oC,x3r),e(co,$3r),e(co,rC),e(rC,k3r),e(rC,L5e),e(L5e,S3r),e(rC,R3r),e(rC,y5e),e(y5e,P3r),e(co,B3r),M(tC,co,null),b(c,lao,_),b(c,gm,_),e(gm,aC),e(aC,x5e),M(Ok,x5e,null),e(gm,I3r),e(gm,$5e),e($5e,N3r),b(c,iao,_),b(c,Uo,_),M(Vk,Uo,null),e(Uo,q3r),e(Uo,hm),e(hm,D3r),e(hm,jK),e(jK,j3r),e(hm,G3r),e(hm,GK),e(GK,O3r),e(hm,V3r),e(Uo,X3r),e(Uo,Xk),e(Xk,z3r),e(Xk,k5e),e(k5e,Q3r),e(Xk,W3r),e(Uo,U3r),e(Uo,Pt),M(zk,Pt,null),e(Pt,H3r),e(Pt,S5e),e(S5e,J3r),e(Pt,Y3r),e(Pt,um),e(um,Z3r),e(um,R5e),e(R5e,K3r),e(um,e5r),e(um,OK),e(OK,o5r),e(um,r5r),e(Pt,t5r),M(nC,Pt,null),e(Uo,a5r),e(Uo,fo),M(Qk,fo,null),e(fo,n5r),e(fo,P5e),e(P5e,s5r),e(fo,l5r),e(fo,bn),e(bn,i5r),e(bn,B5e),e(B5e,d5r),e(bn,m5r),e(bn,I5e),e(I5e,c5r),e(bn,f5r),e(bn,N5e),e(N5e,g5r),e(bn,h5r),e(fo,u5r),e(fo,pm),e(pm,sC),e(sC,q5e),e(q5e,p5r),e(sC,_5r),e(sC,VK),e(VK,b5r),e(sC,v5r),e(pm,F5r),e(pm,lC),e(lC,D5e),e(D5e,T5r),e(lC,M5r),e(lC,XK),e(XK,E5r),e(lC,C5r),e(pm,w5r),e(pm,iC),e(iC,j5e),e(j5e,A5r),e(iC,L5r),e(iC,zK),e(zK,y5r),e(iC,x5r),e(fo,$5r),e(fo,dC),e(dC,k5r),e(dC,G5e),e(G5e,S5r),e(dC,R5r),e(dC,O5e),e(O5e,P5r),e(fo,B5r),M(mC,fo,null),b(c,dao,_),b(c,_m,_),e(_m,cC),e(cC,V5e),M(Wk,V5e,null),e(_m,I5r),e(_m,X5e),e(X5e,N5r),b(c,mao,_),b(c,Ho,_),M(Uk,Ho,null),e(Ho,q5r),e(Ho,bm),e(bm,D5r),e(bm,QK),e(QK,j5r),e(bm,G5r),e(bm,WK),e(WK,O5r),e(bm,V5r),e(Ho,X5r),e(Ho,Hk),e(Hk,z5r),e(Hk,z5e),e(z5e,Q5r),e(Hk,W5r),e(Ho,U5r),e(Ho,Bt),M(Jk,Bt,null),e(Bt,H5r),e(Bt,Q5e),e(Q5e,J5r),e(Bt,Y5r),e(Bt,vm),e(vm,Z5r),e(vm,W5e),e(W5e,K5r),e(vm,e0r),e(vm,UK),e(UK,o0r),e(vm,r0r),e(Bt,t0r),M(fC,Bt,null),e(Ho,a0r),e(Ho,go),M(Yk,go,null),e(go,n0r),e(go,U5e),e(U5e,s0r),e(go,l0r),e(go,vn),e(vn,i0r),e(vn,H5e),e(H5e,d0r),e(vn,m0r),e(vn,J5e),e(J5e,c0r),e(vn,f0r),e(vn,Y5e),e(Y5e,g0r),e(vn,h0r),e(go,u0r),e(go,be),e(be,gC),e(gC,Z5e),e(Z5e,p0r),e(gC,_0r),e(gC,HK),e(HK,b0r),e(gC,v0r),e(be,F0r),e(be,hC),e(hC,K5e),e(K5e,T0r),e(hC,M0r),e(hC,JK),e(JK,E0r),e(hC,C0r),e(be,w0r),e(be,uC),e(uC,e0e),e(e0e,A0r),e(uC,L0r),e(uC,YK),e(YK,y0r),e(uC,x0r),e(be,$0r),e(be,pC),e(pC,o0e),e(o0e,k0r),e(pC,S0r),e(pC,ZK),e(ZK,R0r),e(pC,P0r),e(be,B0r),e(be,xl),e(xl,r0e),e(r0e,I0r),e(xl,N0r),e(xl,KK),e(KK,q0r),e(xl,D0r),e(xl,eee),e(eee,j0r),e(xl,G0r),e(be,O0r),e(be,_C),e(_C,t0e),e(t0e,V0r),e(_C,X0r),e(_C,oee),e(oee,z0r),e(_C,Q0r),e(be,W0r),e(be,$l),e($l,a0e),e(a0e,U0r),e($l,H0r),e($l,ree),e(ree,J0r),e($l,Y0r),e($l,tee),e(tee,Z0r),e($l,K0r),e(be,ewr),e(be,bC),e(bC,n0e),e(n0e,owr),e(bC,rwr),e(bC,aee),e(aee,twr),e(bC,awr),e(be,nwr),e(be,It),e(It,s0e),e(s0e,swr),e(It,lwr),e(It,nee),e(nee,iwr),e(It,dwr),e(It,see),e(see,mwr),e(It,cwr),e(It,lee),e(lee,fwr),e(It,gwr),e(be,hwr),e(be,vC),e(vC,l0e),e(l0e,uwr),e(vC,pwr),e(vC,iee),e(iee,_wr),e(vC,bwr),e(be,vwr),e(be,FC),e(FC,i0e),e(i0e,Fwr),e(FC,Twr),e(FC,dee),e(dee,Mwr),e(FC,Ewr),e(be,Cwr),e(be,TC),e(TC,d0e),e(d0e,wwr),e(TC,Awr),e(TC,mee),e(mee,Lwr),e(TC,ywr),e(be,xwr),e(be,MC),e(MC,m0e),e(m0e,$wr),e(MC,kwr),e(MC,cee),e(cee,Swr),e(MC,Rwr),e(be,Pwr),e(be,EC),e(EC,c0e),e(c0e,Bwr),e(EC,Iwr),e(EC,fee),e(fee,Nwr),e(EC,qwr),e(be,Dwr),e(be,CC),e(CC,f0e),e(f0e,jwr),e(CC,Gwr),e(CC,gee),e(gee,Owr),e(CC,Vwr),e(be,Xwr),e(be,wC),e(wC,g0e),e(g0e,zwr),e(wC,Qwr),e(wC,hee),e(hee,Wwr),e(wC,Uwr),e(be,Hwr),e(be,AC),e(AC,h0e),e(h0e,Jwr),e(AC,Ywr),e(AC,uee),e(uee,Zwr),e(AC,Kwr),e(be,eAr),e(be,LC),e(LC,u0e),e(u0e,oAr),e(LC,rAr),e(LC,pee),e(pee,tAr),e(LC,aAr),e(go,nAr),e(go,yC),e(yC,sAr),e(yC,p0e),e(p0e,lAr),e(yC,iAr),e(yC,_0e),e(_0e,dAr),e(go,mAr),M(xC,go,null),b(c,cao,_),b(c,Fm,_),e(Fm,$C),e($C,b0e),M(Zk,b0e,null),e(Fm,cAr),e(Fm,v0e),e(v0e,fAr),b(c,fao,_),b(c,Jo,_),M(Kk,Jo,null),e(Jo,gAr),e(Jo,Tm),e(Tm,hAr),e(Tm,_ee),e(_ee,uAr),e(Tm,pAr),e(Tm,bee),e(bee,_Ar),e(Tm,bAr),e(Jo,vAr),e(Jo,eS),e(eS,FAr),e(eS,F0e),e(F0e,TAr),e(eS,MAr),e(Jo,EAr),e(Jo,Nt),M(oS,Nt,null),e(Nt,CAr),e(Nt,T0e),e(T0e,wAr),e(Nt,AAr),e(Nt,Mm),e(Mm,LAr),e(Mm,M0e),e(M0e,yAr),e(Mm,xAr),e(Mm,vee),e(vee,$Ar),e(Mm,kAr),e(Nt,SAr),M(kC,Nt,null),e(Jo,RAr),e(Jo,ho),M(rS,ho,null),e(ho,PAr),e(ho,E0e),e(E0e,BAr),e(ho,IAr),e(ho,Fn),e(Fn,NAr),e(Fn,C0e),e(C0e,qAr),e(Fn,DAr),e(Fn,w0e),e(w0e,jAr),e(Fn,GAr),e(Fn,A0e),e(A0e,OAr),e(Fn,VAr),e(ho,XAr),e(ho,L0e),e(L0e,SC),e(SC,y0e),e(y0e,zAr),e(SC,QAr),e(SC,Fee),e(Fee,WAr),e(SC,UAr),e(ho,HAr),e(ho,RC),e(RC,JAr),e(RC,x0e),e(x0e,YAr),e(RC,ZAr),e(RC,$0e),e($0e,KAr),e(ho,e6r),M(PC,ho,null),b(c,gao,_),b(c,Em,_),e(Em,BC),e(BC,k0e),M(tS,k0e,null),e(Em,o6r),e(Em,S0e),e(S0e,r6r),b(c,hao,_),b(c,Yo,_),M(aS,Yo,null),e(Yo,t6r),e(Yo,Cm),e(Cm,a6r),e(Cm,Tee),e(Tee,n6r),e(Cm,s6r),e(Cm,Mee),e(Mee,l6r),e(Cm,i6r),e(Yo,d6r),e(Yo,nS),e(nS,m6r),e(nS,R0e),e(R0e,c6r),e(nS,f6r),e(Yo,g6r),e(Yo,qt),M(sS,qt,null),e(qt,h6r),e(qt,P0e),e(P0e,u6r),e(qt,p6r),e(qt,wm),e(wm,_6r),e(wm,B0e),e(B0e,b6r),e(wm,v6r),e(wm,Eee),e(Eee,F6r),e(wm,T6r),e(qt,M6r),M(IC,qt,null),e(Yo,E6r),e(Yo,uo),M(lS,uo,null),e(uo,C6r),e(uo,I0e),e(I0e,w6r),e(uo,A6r),e(uo,Tn),e(Tn,L6r),e(Tn,N0e),e(N0e,y6r),e(Tn,x6r),e(Tn,q0e),e(q0e,$6r),e(Tn,k6r),e(Tn,D0e),e(D0e,S6r),e(Tn,R6r),e(uo,P6r),e(uo,j0e),e(j0e,NC),e(NC,G0e),e(G0e,B6r),e(NC,I6r),e(NC,Cee),e(Cee,N6r),e(NC,q6r),e(uo,D6r),e(uo,qC),e(qC,j6r),e(qC,O0e),e(O0e,G6r),e(qC,O6r),e(qC,V0e),e(V0e,V6r),e(uo,X6r),M(DC,uo,null),b(c,uao,_),b(c,Am,_),e(Am,jC),e(jC,X0e),M(iS,X0e,null),e(Am,z6r),e(Am,z0e),e(z0e,Q6r),b(c,pao,_),b(c,Zo,_),M(dS,Zo,null),e(Zo,W6r),e(Zo,Lm),e(Lm,U6r),e(Lm,wee),e(wee,H6r),e(Lm,J6r),e(Lm,Aee),e(Aee,Y6r),e(Lm,Z6r),e(Zo,K6r),e(Zo,mS),e(mS,e7r),e(mS,Q0e),e(Q0e,o7r),e(mS,r7r),e(Zo,t7r),e(Zo,Dt),M(cS,Dt,null),e(Dt,a7r),e(Dt,W0e),e(W0e,n7r),e(Dt,s7r),e(Dt,ym),e(ym,l7r),e(ym,U0e),e(U0e,i7r),e(ym,d7r),e(ym,Lee),e(Lee,m7r),e(ym,c7r),e(Dt,f7r),M(GC,Dt,null),e(Zo,g7r),e(Zo,po),M(fS,po,null),e(po,h7r),e(po,H0e),e(H0e,u7r),e(po,p7r),e(po,Mn),e(Mn,_7r),e(Mn,J0e),e(J0e,b7r),e(Mn,v7r),e(Mn,Y0e),e(Y0e,F7r),e(Mn,T7r),e(Mn,Z0e),e(Z0e,M7r),e(Mn,E7r),e(po,C7r),e(po,K0e),e(K0e,OC),e(OC,ewe),e(ewe,w7r),e(OC,A7r),e(OC,yee),e(yee,L7r),e(OC,y7r),e(po,x7r),e(po,VC),e(VC,$7r),e(VC,owe),e(owe,k7r),e(VC,S7r),e(VC,rwe),e(rwe,R7r),e(po,P7r),M(XC,po,null),b(c,_ao,_),b(c,xm,_),e(xm,zC),e(zC,twe),M(gS,twe,null),e(xm,B7r),e(xm,awe),e(awe,I7r),b(c,bao,_),b(c,Ko,_),M(hS,Ko,null),e(Ko,N7r),e(Ko,$m),e($m,q7r),e($m,xee),e(xee,D7r),e($m,j7r),e($m,$ee),e($ee,G7r),e($m,O7r),e(Ko,V7r),e(Ko,uS),e(uS,X7r),e(uS,nwe),e(nwe,z7r),e(uS,Q7r),e(Ko,W7r),e(Ko,jt),M(pS,jt,null),e(jt,U7r),e(jt,swe),e(swe,H7r),e(jt,J7r),e(jt,km),e(km,Y7r),e(km,lwe),e(lwe,Z7r),e(km,K7r),e(km,kee),e(kee,e8r),e(km,o8r),e(jt,r8r),M(QC,jt,null),e(Ko,t8r),e(Ko,_o),M(_S,_o,null),e(_o,a8r),e(_o,iwe),e(iwe,n8r),e(_o,s8r),e(_o,En),e(En,l8r),e(En,dwe),e(dwe,i8r),e(En,d8r),e(En,mwe),e(mwe,m8r),e(En,c8r),e(En,cwe),e(cwe,f8r),e(En,g8r),e(_o,h8r),e(_o,Be),e(Be,WC),e(WC,fwe),e(fwe,u8r),e(WC,p8r),e(WC,See),e(See,_8r),e(WC,b8r),e(Be,v8r),e(Be,UC),e(UC,gwe),e(gwe,F8r),e(UC,T8r),e(UC,Ree),e(Ree,M8r),e(UC,E8r),e(Be,C8r),e(Be,HC),e(HC,hwe),e(hwe,w8r),e(HC,A8r),e(HC,Pee),e(Pee,L8r),e(HC,y8r),e(Be,x8r),e(Be,JC),e(JC,uwe),e(uwe,$8r),e(JC,k8r),e(JC,Bee),e(Bee,S8r),e(JC,R8r),e(Be,P8r),e(Be,YC),e(YC,pwe),e(pwe,B8r),e(YC,I8r),e(YC,Iee),e(Iee,N8r),e(YC,q8r),e(Be,D8r),e(Be,ZC),e(ZC,_we),e(_we,j8r),e(ZC,G8r),e(ZC,Nee),e(Nee,O8r),e(ZC,V8r),e(Be,X8r),e(Be,KC),e(KC,bwe),e(bwe,z8r),e(KC,Q8r),e(KC,qee),e(qee,W8r),e(KC,U8r),e(Be,H8r),e(Be,e3),e(e3,vwe),e(vwe,J8r),e(e3,Y8r),e(e3,Dee),e(Dee,Z8r),e(e3,K8r),e(Be,eLr),e(Be,o3),e(o3,Fwe),e(Fwe,oLr),e(o3,rLr),e(o3,jee),e(jee,tLr),e(o3,aLr),e(_o,nLr),e(_o,r3),e(r3,sLr),e(r3,Twe),e(Twe,lLr),e(r3,iLr),e(r3,Mwe),e(Mwe,dLr),e(_o,mLr),M(t3,_o,null),b(c,vao,_),b(c,Sm,_),e(Sm,a3),e(a3,Ewe),M(bS,Ewe,null),e(Sm,cLr),e(Sm,Cwe),e(Cwe,fLr),b(c,Fao,_),b(c,er,_),M(vS,er,null),e(er,gLr),e(er,Rm),e(Rm,hLr),e(Rm,Gee),e(Gee,uLr),e(Rm,pLr),e(Rm,Oee),e(Oee,_Lr),e(Rm,bLr),e(er,vLr),e(er,FS),e(FS,FLr),e(FS,wwe),e(wwe,TLr),e(FS,MLr),e(er,ELr),e(er,Gt),M(TS,Gt,null),e(Gt,CLr),e(Gt,Awe),e(Awe,wLr),e(Gt,ALr),e(Gt,Pm),e(Pm,LLr),e(Pm,Lwe),e(Lwe,yLr),e(Pm,xLr),e(Pm,Vee),e(Vee,$Lr),e(Pm,kLr),e(Gt,SLr),M(n3,Gt,null),e(er,RLr),e(er,bo),M(MS,bo,null),e(bo,PLr),e(bo,ywe),e(ywe,BLr),e(bo,ILr),e(bo,Cn),e(Cn,NLr),e(Cn,xwe),e(xwe,qLr),e(Cn,DLr),e(Cn,$we),e($we,jLr),e(Cn,GLr),e(Cn,kwe),e(kwe,OLr),e(Cn,VLr),e(bo,XLr),e(bo,ut),e(ut,s3),e(s3,Swe),e(Swe,zLr),e(s3,QLr),e(s3,Xee),e(Xee,WLr),e(s3,ULr),e(ut,HLr),e(ut,l3),e(l3,Rwe),e(Rwe,JLr),e(l3,YLr),e(l3,zee),e(zee,ZLr),e(l3,KLr),e(ut,eyr),e(ut,i3),e(i3,Pwe),e(Pwe,oyr),e(i3,ryr),e(i3,Qee),e(Qee,tyr),e(i3,ayr),e(ut,nyr),e(ut,d3),e(d3,Bwe),e(Bwe,syr),e(d3,lyr),e(d3,Wee),e(Wee,iyr),e(d3,dyr),e(ut,myr),e(ut,m3),e(m3,Iwe),e(Iwe,cyr),e(m3,fyr),e(m3,Uee),e(Uee,gyr),e(m3,hyr),e(bo,uyr),e(bo,c3),e(c3,pyr),e(c3,Nwe),e(Nwe,_yr),e(c3,byr),e(c3,qwe),e(qwe,vyr),e(bo,Fyr),M(f3,bo,null),b(c,Tao,_),b(c,Bm,_),e(Bm,g3),e(g3,Dwe),M(ES,Dwe,null),e(Bm,Tyr),e(Bm,jwe),e(jwe,Myr),b(c,Mao,_),b(c,or,_),M(CS,or,null),e(or,Eyr),e(or,Im),e(Im,Cyr),e(Im,Hee),e(Hee,wyr),e(Im,Ayr),e(Im,Jee),e(Jee,Lyr),e(Im,yyr),e(or,xyr),e(or,wS),e(wS,$yr),e(wS,Gwe),e(Gwe,kyr),e(wS,Syr),e(or,Ryr),e(or,Ot),M(AS,Ot,null),e(Ot,Pyr),e(Ot,Owe),e(Owe,Byr),e(Ot,Iyr),e(Ot,Nm),e(Nm,Nyr),e(Nm,Vwe),e(Vwe,qyr),e(Nm,Dyr),e(Nm,Yee),e(Yee,jyr),e(Nm,Gyr),e(Ot,Oyr),M(h3,Ot,null),e(or,Vyr),e(or,vo),M(LS,vo,null),e(vo,Xyr),e(vo,Xwe),e(Xwe,zyr),e(vo,Qyr),e(vo,wn),e(wn,Wyr),e(wn,zwe),e(zwe,Uyr),e(wn,Hyr),e(wn,Qwe),e(Qwe,Jyr),e(wn,Yyr),e(wn,Wwe),e(Wwe,Zyr),e(wn,Kyr),e(vo,e9r),e(vo,Le),e(Le,u3),e(u3,Uwe),e(Uwe,o9r),e(u3,r9r),e(u3,Zee),e(Zee,t9r),e(u3,a9r),e(Le,n9r),e(Le,p3),e(p3,Hwe),e(Hwe,s9r),e(p3,l9r),e(p3,Kee),e(Kee,i9r),e(p3,d9r),e(Le,m9r),e(Le,_3),e(_3,Jwe),e(Jwe,c9r),e(_3,f9r),e(_3,eoe),e(eoe,g9r),e(_3,h9r),e(Le,u9r),e(Le,b3),e(b3,Ywe),e(Ywe,p9r),e(b3,_9r),e(b3,ooe),e(ooe,b9r),e(b3,v9r),e(Le,F9r),e(Le,v3),e(v3,Zwe),e(Zwe,T9r),e(v3,M9r),e(v3,roe),e(roe,E9r),e(v3,C9r),e(Le,w9r),e(Le,F3),e(F3,Kwe),e(Kwe,A9r),e(F3,L9r),e(F3,toe),e(toe,y9r),e(F3,x9r),e(Le,$9r),e(Le,T3),e(T3,eAe),e(eAe,k9r),e(T3,S9r),e(T3,aoe),e(aoe,R9r),e(T3,P9r),e(Le,B9r),e(Le,M3),e(M3,oAe),e(oAe,I9r),e(M3,N9r),e(M3,noe),e(noe,q9r),e(M3,D9r),e(Le,j9r),e(Le,E3),e(E3,rAe),e(rAe,G9r),e(E3,O9r),e(E3,soe),e(soe,V9r),e(E3,X9r),e(Le,z9r),e(Le,C3),e(C3,tAe),e(tAe,Q9r),e(C3,W9r),e(C3,loe),e(loe,U9r),e(C3,H9r),e(vo,J9r),e(vo,w3),e(w3,Y9r),e(w3,aAe),e(aAe,Z9r),e(w3,K9r),e(w3,nAe),e(nAe,exr),e(vo,oxr),M(A3,vo,null),b(c,Eao,_),b(c,qm,_),e(qm,L3),e(L3,sAe),M(yS,sAe,null),e(qm,rxr),e(qm,lAe),e(lAe,txr),b(c,Cao,_),b(c,rr,_),M(xS,rr,null),e(rr,axr),e(rr,Dm),e(Dm,nxr),e(Dm,ioe),e(ioe,sxr),e(Dm,lxr),e(Dm,doe),e(doe,ixr),e(Dm,dxr),e(rr,mxr),e(rr,$S),e($S,cxr),e($S,iAe),e(iAe,fxr),e($S,gxr),e(rr,hxr),e(rr,Vt),M(kS,Vt,null),e(Vt,uxr),e(Vt,dAe),e(dAe,pxr),e(Vt,_xr),e(Vt,jm),e(jm,bxr),e(jm,mAe),e(mAe,vxr),e(jm,Fxr),e(jm,moe),e(moe,Txr),e(jm,Mxr),e(Vt,Exr),M(y3,Vt,null),e(rr,Cxr),e(rr,Fo),M(SS,Fo,null),e(Fo,wxr),e(Fo,cAe),e(cAe,Axr),e(Fo,Lxr),e(Fo,An),e(An,yxr),e(An,fAe),e(fAe,xxr),e(An,$xr),e(An,gAe),e(gAe,kxr),e(An,Sxr),e(An,hAe),e(hAe,Rxr),e(An,Pxr),e(Fo,Bxr),e(Fo,Gm),e(Gm,x3),e(x3,uAe),e(uAe,Ixr),e(x3,Nxr),e(x3,coe),e(coe,qxr),e(x3,Dxr),e(Gm,jxr),e(Gm,$3),e($3,pAe),e(pAe,Gxr),e($3,Oxr),e($3,foe),e(foe,Vxr),e($3,Xxr),e(Gm,zxr),e(Gm,k3),e(k3,_Ae),e(_Ae,Qxr),e(k3,Wxr),e(k3,goe),e(goe,Uxr),e(k3,Hxr),e(Fo,Jxr),e(Fo,S3),e(S3,Yxr),e(S3,bAe),e(bAe,Zxr),e(S3,Kxr),e(S3,vAe),e(vAe,e$r),e(Fo,o$r),M(R3,Fo,null),b(c,wao,_),b(c,Om,_),e(Om,P3),e(P3,FAe),M(RS,FAe,null),e(Om,r$r),e(Om,TAe),e(TAe,t$r),b(c,Aao,_),b(c,tr,_),M(PS,tr,null),e(tr,a$r),e(tr,Vm),e(Vm,n$r),e(Vm,hoe),e(hoe,s$r),e(Vm,l$r),e(Vm,uoe),e(uoe,i$r),e(Vm,d$r),e(tr,m$r),e(tr,BS),e(BS,c$r),e(BS,MAe),e(MAe,f$r),e(BS,g$r),e(tr,h$r),e(tr,Xt),M(IS,Xt,null),e(Xt,u$r),e(Xt,EAe),e(EAe,p$r),e(Xt,_$r),e(Xt,Xm),e(Xm,b$r),e(Xm,CAe),e(CAe,v$r),e(Xm,F$r),e(Xm,poe),e(poe,T$r),e(Xm,M$r),e(Xt,E$r),M(B3,Xt,null),e(tr,C$r),e(tr,To),M(NS,To,null),e(To,w$r),e(To,wAe),e(wAe,A$r),e(To,L$r),e(To,Ln),e(Ln,y$r),e(Ln,AAe),e(AAe,x$r),e(Ln,$$r),e(Ln,LAe),e(LAe,k$r),e(Ln,S$r),e(Ln,yAe),e(yAe,R$r),e(Ln,P$r),e(To,B$r),e(To,pt),e(pt,I3),e(I3,xAe),e(xAe,I$r),e(I3,N$r),e(I3,_oe),e(_oe,q$r),e(I3,D$r),e(pt,j$r),e(pt,N3),e(N3,$Ae),e($Ae,G$r),e(N3,O$r),e(N3,boe),e(boe,V$r),e(N3,X$r),e(pt,z$r),e(pt,q3),e(q3,kAe),e(kAe,Q$r),e(q3,W$r),e(q3,voe),e(voe,U$r),e(q3,H$r),e(pt,J$r),e(pt,D3),e(D3,SAe),e(SAe,Y$r),e(D3,Z$r),e(D3,Foe),e(Foe,K$r),e(D3,ekr),e(pt,okr),e(pt,j3),e(j3,RAe),e(RAe,rkr),e(j3,tkr),e(j3,Toe),e(Toe,akr),e(j3,nkr),e(To,skr),e(To,G3),e(G3,lkr),e(G3,PAe),e(PAe,ikr),e(G3,dkr),e(G3,BAe),e(BAe,mkr),e(To,ckr),M(O3,To,null),b(c,Lao,_),b(c,zm,_),e(zm,V3),e(V3,IAe),M(qS,IAe,null),e(zm,fkr),e(zm,NAe),e(NAe,gkr),b(c,yao,_),b(c,ar,_),M(DS,ar,null),e(ar,hkr),e(ar,Qm),e(Qm,ukr),e(Qm,Moe),e(Moe,pkr),e(Qm,_kr),e(Qm,Eoe),e(Eoe,bkr),e(Qm,vkr),e(ar,Fkr),e(ar,jS),e(jS,Tkr),e(jS,qAe),e(qAe,Mkr),e(jS,Ekr),e(ar,Ckr),e(ar,zt),M(GS,zt,null),e(zt,wkr),e(zt,DAe),e(DAe,Akr),e(zt,Lkr),e(zt,Wm),e(Wm,ykr),e(Wm,jAe),e(jAe,xkr),e(Wm,$kr),e(Wm,Coe),e(Coe,kkr),e(Wm,Skr),e(zt,Rkr),M(X3,zt,null),e(ar,Pkr),e(ar,Mo),M(OS,Mo,null),e(Mo,Bkr),e(Mo,GAe),e(GAe,Ikr),e(Mo,Nkr),e(Mo,yn),e(yn,qkr),e(yn,OAe),e(OAe,Dkr),e(yn,jkr),e(yn,VAe),e(VAe,Gkr),e(yn,Okr),e(yn,XAe),e(XAe,Vkr),e(yn,Xkr),e(Mo,zkr),e(Mo,xn),e(xn,z3),e(z3,zAe),e(zAe,Qkr),e(z3,Wkr),e(z3,woe),e(woe,Ukr),e(z3,Hkr),e(xn,Jkr),e(xn,Q3),e(Q3,QAe),e(QAe,Ykr),e(Q3,Zkr),e(Q3,Aoe),e(Aoe,Kkr),e(Q3,eSr),e(xn,oSr),e(xn,W3),e(W3,WAe),e(WAe,rSr),e(W3,tSr),e(W3,Loe),e(Loe,aSr),e(W3,nSr),e(xn,sSr),e(xn,U3),e(U3,UAe),e(UAe,lSr),e(U3,iSr),e(U3,yoe),e(yoe,dSr),e(U3,mSr),e(Mo,cSr),e(Mo,H3),e(H3,fSr),e(H3,HAe),e(HAe,gSr),e(H3,hSr),e(H3,JAe),e(JAe,uSr),e(Mo,pSr),M(J3,Mo,null),b(c,xao,_),b(c,Um,_),e(Um,Y3),e(Y3,YAe),M(VS,YAe,null),e(Um,_Sr),e(Um,ZAe),e(ZAe,bSr),b(c,$ao,_),b(c,nr,_),M(XS,nr,null),e(nr,vSr),e(nr,Hm),e(Hm,FSr),e(Hm,xoe),e(xoe,TSr),e(Hm,MSr),e(Hm,$oe),e($oe,ESr),e(Hm,CSr),e(nr,wSr),e(nr,zS),e(zS,ASr),e(zS,KAe),e(KAe,LSr),e(zS,ySr),e(nr,xSr),e(nr,Qt),M(QS,Qt,null),e(Qt,$Sr),e(Qt,e6e),e(e6e,kSr),e(Qt,SSr),e(Qt,Jm),e(Jm,RSr),e(Jm,o6e),e(o6e,PSr),e(Jm,BSr),e(Jm,koe),e(koe,ISr),e(Jm,NSr),e(Qt,qSr),M(Z3,Qt,null),e(nr,DSr),e(nr,Eo),M(WS,Eo,null),e(Eo,jSr),e(Eo,r6e),e(r6e,GSr),e(Eo,OSr),e(Eo,$n),e($n,VSr),e($n,t6e),e(t6e,XSr),e($n,zSr),e($n,a6e),e(a6e,QSr),e($n,WSr),e($n,n6e),e(n6e,USr),e($n,HSr),e(Eo,JSr),e(Eo,_t),e(_t,K3),e(K3,s6e),e(s6e,YSr),e(K3,ZSr),e(K3,Soe),e(Soe,KSr),e(K3,eRr),e(_t,oRr),e(_t,e5),e(e5,l6e),e(l6e,rRr),e(e5,tRr),e(e5,Roe),e(Roe,aRr),e(e5,nRr),e(_t,sRr),e(_t,o5),e(o5,i6e),e(i6e,lRr),e(o5,iRr),e(o5,Poe),e(Poe,dRr),e(o5,mRr),e(_t,cRr),e(_t,r5),e(r5,d6e),e(d6e,fRr),e(r5,gRr),e(r5,Boe),e(Boe,hRr),e(r5,uRr),e(_t,pRr),e(_t,t5),e(t5,m6e),e(m6e,_Rr),e(t5,bRr),e(t5,Ioe),e(Ioe,vRr),e(t5,FRr),e(Eo,TRr),e(Eo,a5),e(a5,MRr),e(a5,c6e),e(c6e,ERr),e(a5,CRr),e(a5,f6e),e(f6e,wRr),e(Eo,ARr),M(n5,Eo,null),b(c,kao,_),b(c,Ym,_),e(Ym,s5),e(s5,g6e),M(US,g6e,null),e(Ym,LRr),e(Ym,h6e),e(h6e,yRr),b(c,Sao,_),b(c,sr,_),M(HS,sr,null),e(sr,xRr),e(sr,Zm),e(Zm,$Rr),e(Zm,Noe),e(Noe,kRr),e(Zm,SRr),e(Zm,qoe),e(qoe,RRr),e(Zm,PRr),e(sr,BRr),e(sr,JS),e(JS,IRr),e(JS,u6e),e(u6e,NRr),e(JS,qRr),e(sr,DRr),e(sr,Wt),M(YS,Wt,null),e(Wt,jRr),e(Wt,p6e),e(p6e,GRr),e(Wt,ORr),e(Wt,Km),e(Km,VRr),e(Km,_6e),e(_6e,XRr),e(Km,zRr),e(Km,Doe),e(Doe,QRr),e(Km,WRr),e(Wt,URr),M(l5,Wt,null),e(sr,HRr),e(sr,Co),M(ZS,Co,null),e(Co,JRr),e(Co,b6e),e(b6e,YRr),e(Co,ZRr),e(Co,kn),e(kn,KRr),e(kn,v6e),e(v6e,ePr),e(kn,oPr),e(kn,F6e),e(F6e,rPr),e(kn,tPr),e(kn,T6e),e(T6e,aPr),e(kn,nPr),e(Co,sPr),e(Co,M6e),e(M6e,i5),e(i5,E6e),e(E6e,lPr),e(i5,iPr),e(i5,joe),e(joe,dPr),e(i5,mPr),e(Co,cPr),e(Co,d5),e(d5,fPr),e(d5,C6e),e(C6e,gPr),e(d5,hPr),e(d5,w6e),e(w6e,uPr),e(Co,pPr),M(m5,Co,null),b(c,Rao,_),b(c,ec,_),e(ec,c5),e(c5,A6e),M(KS,A6e,null),e(ec,_Pr),e(ec,L6e),e(L6e,bPr),b(c,Pao,_),b(c,lr,_),M(eR,lr,null),e(lr,vPr),e(lr,oc),e(oc,FPr),e(oc,Goe),e(Goe,TPr),e(oc,MPr),e(oc,Ooe),e(Ooe,EPr),e(oc,CPr),e(lr,wPr),e(lr,oR),e(oR,APr),e(oR,y6e),e(y6e,LPr),e(oR,yPr),e(lr,xPr),e(lr,Ut),M(rR,Ut,null),e(Ut,$Pr),e(Ut,x6e),e(x6e,kPr),e(Ut,SPr),e(Ut,rc),e(rc,RPr),e(rc,$6e),e($6e,PPr),e(rc,BPr),e(rc,Voe),e(Voe,IPr),e(rc,NPr),e(Ut,qPr),M(f5,Ut,null),e(lr,DPr),e(lr,wo),M(tR,wo,null),e(wo,jPr),e(wo,k6e),e(k6e,GPr),e(wo,OPr),e(wo,Sn),e(Sn,VPr),e(Sn,S6e),e(S6e,XPr),e(Sn,zPr),e(Sn,R6e),e(R6e,QPr),e(Sn,WPr),e(Sn,P6e),e(P6e,UPr),e(Sn,HPr),e(wo,JPr),e(wo,bt),e(bt,g5),e(g5,B6e),e(B6e,YPr),e(g5,ZPr),e(g5,Xoe),e(Xoe,KPr),e(g5,eBr),e(bt,oBr),e(bt,h5),e(h5,I6e),e(I6e,rBr),e(h5,tBr),e(h5,zoe),e(zoe,aBr),e(h5,nBr),e(bt,sBr),e(bt,u5),e(u5,N6e),e(N6e,lBr),e(u5,iBr),e(u5,Qoe),e(Qoe,dBr),e(u5,mBr),e(bt,cBr),e(bt,p5),e(p5,q6e),e(q6e,fBr),e(p5,gBr),e(p5,Woe),e(Woe,hBr),e(p5,uBr),e(bt,pBr),e(bt,_5),e(_5,D6e),e(D6e,_Br),e(_5,bBr),e(_5,Uoe),e(Uoe,vBr),e(_5,FBr),e(wo,TBr),e(wo,b5),e(b5,MBr),e(b5,j6e),e(j6e,EBr),e(b5,CBr),e(b5,G6e),e(G6e,wBr),e(wo,ABr),M(v5,wo,null),b(c,Bao,_),b(c,tc,_),e(tc,F5),e(F5,O6e),M(aR,O6e,null),e(tc,LBr),e(tc,V6e),e(V6e,yBr),b(c,Iao,_),b(c,ir,_),M(nR,ir,null),e(ir,xBr),e(ir,ac),e(ac,$Br),e(ac,Hoe),e(Hoe,kBr),e(ac,SBr),e(ac,Joe),e(Joe,RBr),e(ac,PBr),e(ir,BBr),e(ir,sR),e(sR,IBr),e(sR,X6e),e(X6e,NBr),e(sR,qBr),e(ir,DBr),e(ir,Ht),M(lR,Ht,null),e(Ht,jBr),e(Ht,z6e),e(z6e,GBr),e(Ht,OBr),e(Ht,nc),e(nc,VBr),e(nc,Q6e),e(Q6e,XBr),e(nc,zBr),e(nc,Yoe),e(Yoe,QBr),e(nc,WBr),e(Ht,UBr),M(T5,Ht,null),e(ir,HBr),e(ir,Ao),M(iR,Ao,null),e(Ao,JBr),e(Ao,W6e),e(W6e,YBr),e(Ao,ZBr),e(Ao,Rn),e(Rn,KBr),e(Rn,U6e),e(U6e,eIr),e(Rn,oIr),e(Rn,H6e),e(H6e,rIr),e(Rn,tIr),e(Rn,J6e),e(J6e,aIr),e(Rn,nIr),e(Ao,sIr),e(Ao,Y6e),e(Y6e,M5),e(M5,Z6e),e(Z6e,lIr),e(M5,iIr),e(M5,Zoe),e(Zoe,dIr),e(M5,mIr),e(Ao,cIr),e(Ao,E5),e(E5,fIr),e(E5,K6e),e(K6e,gIr),e(E5,hIr),e(E5,e7e),e(e7e,uIr),e(Ao,pIr),M(C5,Ao,null),b(c,Nao,_),b(c,sc,_),e(sc,w5),e(w5,o7e),M(dR,o7e,null),e(sc,_Ir),e(sc,r7e),e(r7e,bIr),b(c,qao,_),b(c,dr,_),M(mR,dr,null),e(dr,vIr),e(dr,lc),e(lc,FIr),e(lc,Koe),e(Koe,TIr),e(lc,MIr),e(lc,ere),e(ere,EIr),e(lc,CIr),e(dr,wIr),e(dr,cR),e(cR,AIr),e(cR,t7e),e(t7e,LIr),e(cR,yIr),e(dr,xIr),e(dr,Jt),M(fR,Jt,null),e(Jt,$Ir),e(Jt,a7e),e(a7e,kIr),e(Jt,SIr),e(Jt,ic),e(ic,RIr),e(ic,n7e),e(n7e,PIr),e(ic,BIr),e(ic,ore),e(ore,IIr),e(ic,NIr),e(Jt,qIr),M(A5,Jt,null),e(dr,DIr),e(dr,Lo),M(gR,Lo,null),e(Lo,jIr),e(Lo,s7e),e(s7e,GIr),e(Lo,OIr),e(Lo,Pn),e(Pn,VIr),e(Pn,l7e),e(l7e,XIr),e(Pn,zIr),e(Pn,i7e),e(i7e,QIr),e(Pn,WIr),e(Pn,d7e),e(d7e,UIr),e(Pn,HIr),e(Lo,JIr),e(Lo,m7e),e(m7e,L5),e(L5,c7e),e(c7e,YIr),e(L5,ZIr),e(L5,rre),e(rre,KIr),e(L5,eNr),e(Lo,oNr),e(Lo,y5),e(y5,rNr),e(y5,f7e),e(f7e,tNr),e(y5,aNr),e(y5,g7e),e(g7e,nNr),e(Lo,sNr),M(x5,Lo,null),b(c,Dao,_),b(c,dc,_),e(dc,$5),e($5,h7e),M(hR,h7e,null),e(dc,lNr),e(dc,u7e),e(u7e,iNr),b(c,jao,_),b(c,mr,_),M(uR,mr,null),e(mr,dNr),e(mr,mc),e(mc,mNr),e(mc,tre),e(tre,cNr),e(mc,fNr),e(mc,are),e(are,gNr),e(mc,hNr),e(mr,uNr),e(mr,pR),e(pR,pNr),e(pR,p7e),e(p7e,_Nr),e(pR,bNr),e(mr,vNr),e(mr,Yt),M(_R,Yt,null),e(Yt,FNr),e(Yt,_7e),e(_7e,TNr),e(Yt,MNr),e(Yt,cc),e(cc,ENr),e(cc,b7e),e(b7e,CNr),e(cc,wNr),e(cc,nre),e(nre,ANr),e(cc,LNr),e(Yt,yNr),M(k5,Yt,null),e(mr,xNr),e(mr,jr),M(bR,jr,null),e(jr,$Nr),e(jr,v7e),e(v7e,kNr),e(jr,SNr),e(jr,Bn),e(Bn,RNr),e(Bn,F7e),e(F7e,PNr),e(Bn,BNr),e(Bn,T7e),e(T7e,INr),e(Bn,NNr),e(Bn,M7e),e(M7e,qNr),e(Bn,DNr),e(jr,jNr),e(jr,P),e(P,S5),e(S5,E7e),e(E7e,GNr),e(S5,ONr),e(S5,sre),e(sre,VNr),e(S5,XNr),e(P,zNr),e(P,R5),e(R5,C7e),e(C7e,QNr),e(R5,WNr),e(R5,lre),e(lre,UNr),e(R5,HNr),e(P,JNr),e(P,P5),e(P5,w7e),e(w7e,YNr),e(P5,ZNr),e(P5,ire),e(ire,KNr),e(P5,eqr),e(P,oqr),e(P,B5),e(B5,A7e),e(A7e,rqr),e(B5,tqr),e(B5,dre),e(dre,aqr),e(B5,nqr),e(P,sqr),e(P,I5),e(I5,L7e),e(L7e,lqr),e(I5,iqr),e(I5,mre),e(mre,dqr),e(I5,mqr),e(P,cqr),e(P,N5),e(N5,y7e),e(y7e,fqr),e(N5,gqr),e(N5,cre),e(cre,hqr),e(N5,uqr),e(P,pqr),e(P,q5),e(q5,x7e),e(x7e,_qr),e(q5,bqr),e(q5,fre),e(fre,vqr),e(q5,Fqr),e(P,Tqr),e(P,D5),e(D5,$7e),e($7e,Mqr),e(D5,Eqr),e(D5,gre),e(gre,Cqr),e(D5,wqr),e(P,Aqr),e(P,j5),e(j5,k7e),e(k7e,Lqr),e(j5,yqr),e(j5,hre),e(hre,xqr),e(j5,$qr),e(P,kqr),e(P,G5),e(G5,S7e),e(S7e,Sqr),e(G5,Rqr),e(G5,ure),e(ure,Pqr),e(G5,Bqr),e(P,Iqr),e(P,O5),e(O5,R7e),e(R7e,Nqr),e(O5,qqr),e(O5,pre),e(pre,Dqr),e(O5,jqr),e(P,Gqr),e(P,V5),e(V5,P7e),e(P7e,Oqr),e(V5,Vqr),e(V5,_re),e(_re,Xqr),e(V5,zqr),e(P,Qqr),e(P,X5),e(X5,B7e),e(B7e,Wqr),e(X5,Uqr),e(X5,bre),e(bre,Hqr),e(X5,Jqr),e(P,Yqr),e(P,z5),e(z5,I7e),e(I7e,Zqr),e(z5,Kqr),e(z5,vre),e(vre,eDr),e(z5,oDr),e(P,rDr),e(P,Q5),e(Q5,N7e),e(N7e,tDr),e(Q5,aDr),e(Q5,Fre),e(Fre,nDr),e(Q5,sDr),e(P,lDr),e(P,W5),e(W5,q7e),e(q7e,iDr),e(W5,dDr),e(W5,Tre),e(Tre,mDr),e(W5,cDr),e(P,fDr),e(P,U5),e(U5,D7e),e(D7e,gDr),e(U5,hDr),e(U5,Mre),e(Mre,uDr),e(U5,pDr),e(P,_Dr),e(P,H5),e(H5,j7e),e(j7e,bDr),e(H5,vDr),e(H5,Ere),e(Ere,FDr),e(H5,TDr),e(P,MDr),e(P,J5),e(J5,G7e),e(G7e,EDr),e(J5,CDr),e(J5,Cre),e(Cre,wDr),e(J5,ADr),e(P,LDr),e(P,Y5),e(Y5,O7e),e(O7e,yDr),e(Y5,xDr),e(Y5,wre),e(wre,$Dr),e(Y5,kDr),e(P,SDr),e(P,kl),e(kl,V7e),e(V7e,RDr),e(kl,PDr),e(kl,Are),e(Are,BDr),e(kl,IDr),e(kl,Lre),e(Lre,NDr),e(kl,qDr),e(P,DDr),e(P,Z5),e(Z5,X7e),e(X7e,jDr),e(Z5,GDr),e(Z5,yre),e(yre,ODr),e(Z5,VDr),e(P,XDr),e(P,K5),e(K5,z7e),e(z7e,zDr),e(K5,QDr),e(K5,xre),e(xre,WDr),e(K5,UDr),e(P,HDr),e(P,e0),e(e0,Q7e),e(Q7e,JDr),e(e0,YDr),e(e0,$re),e($re,ZDr),e(e0,KDr),e(P,ejr),e(P,o0),e(o0,W7e),e(W7e,ojr),e(o0,rjr),e(o0,kre),e(kre,tjr),e(o0,ajr),e(P,njr),e(P,r0),e(r0,U7e),e(U7e,sjr),e(r0,ljr),e(r0,Sre),e(Sre,ijr),e(r0,djr),e(P,mjr),e(P,t0),e(t0,H7e),e(H7e,cjr),e(t0,fjr),e(t0,Rre),e(Rre,gjr),e(t0,hjr),e(P,ujr),e(P,a0),e(a0,J7e),e(J7e,pjr),e(a0,_jr),e(a0,Pre),e(Pre,bjr),e(a0,vjr),e(P,Fjr),e(P,n0),e(n0,Y7e),e(Y7e,Tjr),e(n0,Mjr),e(n0,Bre),e(Bre,Ejr),e(n0,Cjr),e(P,wjr),e(P,s0),e(s0,Z7e),e(Z7e,Ajr),e(s0,Ljr),e(s0,Ire),e(Ire,yjr),e(s0,xjr),e(P,$jr),e(P,l0),e(l0,K7e),e(K7e,kjr),e(l0,Sjr),e(l0,Nre),e(Nre,Rjr),e(l0,Pjr),e(P,Bjr),e(P,i0),e(i0,e8e),e(e8e,Ijr),e(i0,Njr),e(i0,qre),e(qre,qjr),e(i0,Djr),e(P,jjr),e(P,d0),e(d0,o8e),e(o8e,Gjr),e(d0,Ojr),e(d0,Dre),e(Dre,Vjr),e(d0,Xjr),e(P,zjr),e(P,m0),e(m0,r8e),e(r8e,Qjr),e(m0,Wjr),e(m0,jre),e(jre,Ujr),e(m0,Hjr),e(P,Jjr),e(P,c0),e(c0,t8e),e(t8e,Yjr),e(c0,Zjr),e(c0,Gre),e(Gre,Kjr),e(c0,eGr),e(P,oGr),e(P,f0),e(f0,a8e),e(a8e,rGr),e(f0,tGr),e(f0,Ore),e(Ore,aGr),e(f0,nGr),e(P,sGr),e(P,g0),e(g0,n8e),e(n8e,lGr),e(g0,iGr),e(g0,Vre),e(Vre,dGr),e(g0,mGr),e(P,cGr),e(P,h0),e(h0,s8e),e(s8e,fGr),e(h0,gGr),e(h0,Xre),e(Xre,hGr),e(h0,uGr),e(P,pGr),e(P,u0),e(u0,l8e),e(l8e,_Gr),e(u0,bGr),e(u0,zre),e(zre,vGr),e(u0,FGr),e(P,TGr),e(P,p0),e(p0,i8e),e(i8e,MGr),e(p0,EGr),e(p0,Qre),e(Qre,CGr),e(p0,wGr),e(P,AGr),e(P,_0),e(_0,d8e),e(d8e,LGr),e(_0,yGr),e(_0,Wre),e(Wre,xGr),e(_0,$Gr),e(P,kGr),e(P,b0),e(b0,m8e),e(m8e,SGr),e(b0,RGr),e(b0,Ure),e(Ure,PGr),e(b0,BGr),e(P,IGr),e(P,v0),e(v0,c8e),e(c8e,NGr),e(v0,qGr),e(v0,Hre),e(Hre,DGr),e(v0,jGr),e(P,GGr),e(P,F0),e(F0,f8e),e(f8e,OGr),e(F0,VGr),e(F0,Jre),e(Jre,XGr),e(F0,zGr),e(P,QGr),e(P,T0),e(T0,g8e),e(g8e,WGr),e(T0,UGr),e(T0,Yre),e(Yre,HGr),e(T0,JGr),e(P,YGr),e(P,M0),e(M0,h8e),e(h8e,ZGr),e(M0,KGr),e(M0,Zre),e(Zre,eOr),e(M0,oOr),e(P,rOr),e(P,E0),e(E0,u8e),e(u8e,tOr),e(E0,aOr),e(E0,Kre),e(Kre,nOr),e(E0,sOr),e(P,lOr),e(P,C0),e(C0,p8e),e(p8e,iOr),e(C0,dOr),e(C0,ete),e(ete,mOr),e(C0,cOr),e(P,fOr),e(P,w0),e(w0,_8e),e(_8e,gOr),e(w0,hOr),e(w0,ote),e(ote,uOr),e(w0,pOr),e(P,_Or),e(P,A0),e(A0,b8e),e(b8e,bOr),e(A0,vOr),e(A0,rte),e(rte,FOr),e(A0,TOr),e(P,MOr),e(P,L0),e(L0,v8e),e(v8e,EOr),e(L0,COr),e(L0,tte),e(tte,wOr),e(L0,AOr),e(P,LOr),e(P,y0),e(y0,F8e),e(F8e,yOr),e(y0,xOr),e(y0,ate),e(ate,$Or),e(y0,kOr),e(P,SOr),e(P,x0),e(x0,T8e),e(T8e,ROr),e(x0,POr),e(x0,nte),e(nte,BOr),e(x0,IOr),e(P,NOr),e(P,$0),e($0,M8e),e(M8e,qOr),e($0,DOr),e($0,ste),e(ste,jOr),e($0,GOr),e(P,OOr),e(P,k0),e(k0,E8e),e(E8e,VOr),e(k0,XOr),e(k0,lte),e(lte,zOr),e(k0,QOr),e(P,WOr),e(P,S0),e(S0,C8e),e(C8e,UOr),e(S0,HOr),e(S0,ite),e(ite,JOr),e(S0,YOr),e(P,ZOr),e(P,R0),e(R0,w8e),e(w8e,KOr),e(R0,eVr),e(R0,dte),e(dte,oVr),e(R0,rVr),e(P,tVr),e(P,P0),e(P0,A8e),e(A8e,aVr),e(P0,nVr),e(P0,mte),e(mte,sVr),e(P0,lVr),e(jr,iVr),M(B0,jr,null),b(c,Gao,_),b(c,fc,_),e(fc,I0),e(I0,L8e),M(vR,L8e,null),e(fc,dVr),e(fc,y8e),e(y8e,mVr),b(c,Oao,_),b(c,cr,_),M(FR,cr,null),e(cr,cVr),e(cr,gc),e(gc,fVr),e(gc,cte),e(cte,gVr),e(gc,hVr),e(gc,fte),e(fte,uVr),e(gc,pVr),e(cr,_Vr),e(cr,TR),e(TR,bVr),e(TR,x8e),e(x8e,vVr),e(TR,FVr),e(cr,TVr),e(cr,Zt),M(MR,Zt,null),e(Zt,MVr),e(Zt,$8e),e($8e,EVr),e(Zt,CVr),e(Zt,hc),e(hc,wVr),e(hc,k8e),e(k8e,AVr),e(hc,LVr),e(hc,gte),e(gte,yVr),e(hc,xVr),e(Zt,$Vr),M(N0,Zt,null),e(cr,kVr),e(cr,Gr),M(ER,Gr,null),e(Gr,SVr),e(Gr,S8e),e(S8e,RVr),e(Gr,PVr),e(Gr,In),e(In,BVr),e(In,R8e),e(R8e,IVr),e(In,NVr),e(In,P8e),e(P8e,qVr),e(In,DVr),e(In,B8e),e(B8e,jVr),e(In,GVr),e(Gr,OVr),e(Gr,le),e(le,q0),e(q0,I8e),e(I8e,VVr),e(q0,XVr),e(q0,hte),e(hte,zVr),e(q0,QVr),e(le,WVr),e(le,D0),e(D0,N8e),e(N8e,UVr),e(D0,HVr),e(D0,ute),e(ute,JVr),e(D0,YVr),e(le,ZVr),e(le,j0),e(j0,q8e),e(q8e,KVr),e(j0,eXr),e(j0,pte),e(pte,oXr),e(j0,rXr),e(le,tXr),e(le,G0),e(G0,D8e),e(D8e,aXr),e(G0,nXr),e(G0,_te),e(_te,sXr),e(G0,lXr),e(le,iXr),e(le,O0),e(O0,j8e),e(j8e,dXr),e(O0,mXr),e(O0,bte),e(bte,cXr),e(O0,fXr),e(le,gXr),e(le,V0),e(V0,G8e),e(G8e,hXr),e(V0,uXr),e(V0,vte),e(vte,pXr),e(V0,_Xr),e(le,bXr),e(le,X0),e(X0,O8e),e(O8e,vXr),e(X0,FXr),e(X0,Fte),e(Fte,TXr),e(X0,MXr),e(le,EXr),e(le,z0),e(z0,V8e),e(V8e,CXr),e(z0,wXr),e(z0,Tte),e(Tte,AXr),e(z0,LXr),e(le,yXr),e(le,Q0),e(Q0,X8e),e(X8e,xXr),e(Q0,$Xr),e(Q0,Mte),e(Mte,kXr),e(Q0,SXr),e(le,RXr),e(le,W0),e(W0,z8e),e(z8e,PXr),e(W0,BXr),e(W0,Ete),e(Ete,IXr),e(W0,NXr),e(le,qXr),e(le,U0),e(U0,Q8e),e(Q8e,DXr),e(U0,jXr),e(U0,Cte),e(Cte,GXr),e(U0,OXr),e(le,VXr),e(le,H0),e(H0,W8e),e(W8e,XXr),e(H0,zXr),e(H0,wte),e(wte,QXr),e(H0,WXr),e(le,UXr),e(le,J0),e(J0,U8e),e(U8e,HXr),e(J0,JXr),e(J0,Ate),e(Ate,YXr),e(J0,ZXr),e(le,KXr),e(le,Y0),e(Y0,H8e),e(H8e,ezr),e(Y0,ozr),e(Y0,Lte),e(Lte,rzr),e(Y0,tzr),e(le,azr),e(le,Z0),e(Z0,J8e),e(J8e,nzr),e(Z0,szr),e(Z0,yte),e(yte,lzr),e(Z0,izr),e(le,dzr),e(le,K0),e(K0,Y8e),e(Y8e,mzr),e(K0,czr),e(K0,xte),e(xte,fzr),e(K0,gzr),e(le,hzr),e(le,ew),e(ew,Z8e),e(Z8e,uzr),e(ew,pzr),e(ew,$te),e($te,_zr),e(ew,bzr),e(le,vzr),e(le,ow),e(ow,K8e),e(K8e,Fzr),e(ow,Tzr),e(ow,kte),e(kte,Mzr),e(ow,Ezr),e(le,Czr),e(le,rw),e(rw,eLe),e(eLe,wzr),e(rw,Azr),e(rw,Ste),e(Ste,Lzr),e(rw,yzr),e(le,xzr),e(le,tw),e(tw,oLe),e(oLe,$zr),e(tw,kzr),e(tw,Rte),e(Rte,Szr),e(tw,Rzr),e(le,Pzr),e(le,aw),e(aw,rLe),e(rLe,Bzr),e(aw,Izr),e(aw,Pte),e(Pte,Nzr),e(aw,qzr),e(le,Dzr),e(le,nw),e(nw,tLe),e(tLe,jzr),e(nw,Gzr),e(nw,Bte),e(Bte,Ozr),e(nw,Vzr),e(le,Xzr),e(le,sw),e(sw,aLe),e(aLe,zzr),e(sw,Qzr),e(sw,Ite),e(Ite,Wzr),e(sw,Uzr),e(Gr,Hzr),M(lw,Gr,null),b(c,Vao,_),b(c,uc,_),e(uc,iw),e(iw,nLe),M(CR,nLe,null),e(uc,Jzr),e(uc,sLe),e(sLe,Yzr),b(c,Xao,_),b(c,fr,_),M(wR,fr,null),e(fr,Zzr),e(fr,pc),e(pc,Kzr),e(pc,Nte),e(Nte,eQr),e(pc,oQr),e(pc,qte),e(qte,rQr),e(pc,tQr),e(fr,aQr),e(fr,AR),e(AR,nQr),e(AR,lLe),e(lLe,sQr),e(AR,lQr),e(fr,iQr),e(fr,Kt),M(LR,Kt,null),e(Kt,dQr),e(Kt,iLe),e(iLe,mQr),e(Kt,cQr),e(Kt,_c),e(_c,fQr),e(_c,dLe),e(dLe,gQr),e(_c,hQr),e(_c,Dte),e(Dte,uQr),e(_c,pQr),e(Kt,_Qr),M(dw,Kt,null),e(fr,bQr),e(fr,Or),M(yR,Or,null),e(Or,vQr),e(Or,mLe),e(mLe,FQr),e(Or,TQr),e(Or,Nn),e(Nn,MQr),e(Nn,cLe),e(cLe,EQr),e(Nn,CQr),e(Nn,fLe),e(fLe,wQr),e(Nn,AQr),e(Nn,gLe),e(gLe,LQr),e(Nn,yQr),e(Or,xQr),e(Or,Me),e(Me,mw),e(mw,hLe),e(hLe,$Qr),e(mw,kQr),e(mw,jte),e(jte,SQr),e(mw,RQr),e(Me,PQr),e(Me,cw),e(cw,uLe),e(uLe,BQr),e(cw,IQr),e(cw,Gte),e(Gte,NQr),e(cw,qQr),e(Me,DQr),e(Me,fw),e(fw,pLe),e(pLe,jQr),e(fw,GQr),e(fw,Ote),e(Ote,OQr),e(fw,VQr),e(Me,XQr),e(Me,gw),e(gw,_Le),e(_Le,zQr),e(gw,QQr),e(gw,Vte),e(Vte,WQr),e(gw,UQr),e(Me,HQr),e(Me,hw),e(hw,bLe),e(bLe,JQr),e(hw,YQr),e(hw,Xte),e(Xte,ZQr),e(hw,KQr),e(Me,eWr),e(Me,uw),e(uw,vLe),e(vLe,oWr),e(uw,rWr),e(uw,zte),e(zte,tWr),e(uw,aWr),e(Me,nWr),e(Me,pw),e(pw,FLe),e(FLe,sWr),e(pw,lWr),e(pw,Qte),e(Qte,iWr),e(pw,dWr),e(Me,mWr),e(Me,_w),e(_w,TLe),e(TLe,cWr),e(_w,fWr),e(_w,Wte),e(Wte,gWr),e(_w,hWr),e(Me,uWr),e(Me,bw),e(bw,MLe),e(MLe,pWr),e(bw,_Wr),e(bw,Ute),e(Ute,bWr),e(bw,vWr),e(Me,FWr),e(Me,vw),e(vw,ELe),e(ELe,TWr),e(vw,MWr),e(vw,Hte),e(Hte,EWr),e(vw,CWr),e(Me,wWr),e(Me,Fw),e(Fw,CLe),e(CLe,AWr),e(Fw,LWr),e(Fw,Jte),e(Jte,yWr),e(Fw,xWr),e(Me,$Wr),e(Me,Tw),e(Tw,wLe),e(wLe,kWr),e(Tw,SWr),e(Tw,Yte),e(Yte,RWr),e(Tw,PWr),e(Me,BWr),e(Me,Mw),e(Mw,ALe),e(ALe,IWr),e(Mw,NWr),e(Mw,Zte),e(Zte,qWr),e(Mw,DWr),e(Me,jWr),e(Me,Ew),e(Ew,LLe),e(LLe,GWr),e(Ew,OWr),e(Ew,Kte),e(Kte,VWr),e(Ew,XWr),e(Or,zWr),M(Cw,Or,null),b(c,zao,_),b(c,bc,_),e(bc,ww),e(ww,yLe),M(xR,yLe,null),e(bc,QWr),e(bc,xLe),e(xLe,WWr),b(c,Qao,_),b(c,gr,_),M($R,gr,null),e(gr,UWr),e(gr,vc),e(vc,HWr),e(vc,eae),e(eae,JWr),e(vc,YWr),e(vc,oae),e(oae,ZWr),e(vc,KWr),e(gr,eUr),e(gr,kR),e(kR,oUr),e(kR,$Le),e($Le,rUr),e(kR,tUr),e(gr,aUr),e(gr,ea),M(SR,ea,null),e(ea,nUr),e(ea,kLe),e(kLe,sUr),e(ea,lUr),e(ea,Fc),e(Fc,iUr),e(Fc,SLe),e(SLe,dUr),e(Fc,mUr),e(Fc,rae),e(rae,cUr),e(Fc,fUr),e(ea,gUr),M(Aw,ea,null),e(gr,hUr),e(gr,Vr),M(RR,Vr,null),e(Vr,uUr),e(Vr,RLe),e(RLe,pUr),e(Vr,_Ur),e(Vr,qn),e(qn,bUr),e(qn,PLe),e(PLe,vUr),e(qn,FUr),e(qn,BLe),e(BLe,TUr),e(qn,MUr),e(qn,ILe),e(ILe,EUr),e(qn,CUr),e(Vr,wUr),e(Vr,ye),e(ye,Lw),e(Lw,NLe),e(NLe,AUr),e(Lw,LUr),e(Lw,tae),e(tae,yUr),e(Lw,xUr),e(ye,$Ur),e(ye,yw),e(yw,qLe),e(qLe,kUr),e(yw,SUr),e(yw,aae),e(aae,RUr),e(yw,PUr),e(ye,BUr),e(ye,xw),e(xw,DLe),e(DLe,IUr),e(xw,NUr),e(xw,nae),e(nae,qUr),e(xw,DUr),e(ye,jUr),e(ye,Sl),e(Sl,jLe),e(jLe,GUr),e(Sl,OUr),e(Sl,sae),e(sae,VUr),e(Sl,XUr),e(Sl,lae),e(lae,zUr),e(Sl,QUr),e(ye,WUr),e(ye,$w),e($w,GLe),e(GLe,UUr),e($w,HUr),e($w,iae),e(iae,JUr),e($w,YUr),e(ye,ZUr),e(ye,kw),e(kw,OLe),e(OLe,KUr),e(kw,eHr),e(kw,dae),e(dae,oHr),e(kw,rHr),e(ye,tHr),e(ye,Sw),e(Sw,VLe),e(VLe,aHr),e(Sw,nHr),e(Sw,mae),e(mae,sHr),e(Sw,lHr),e(ye,iHr),e(ye,Rw),e(Rw,XLe),e(XLe,dHr),e(Rw,mHr),e(Rw,cae),e(cae,cHr),e(Rw,fHr),e(ye,gHr),e(ye,Pw),e(Pw,zLe),e(zLe,hHr),e(Pw,uHr),e(Pw,fae),e(fae,pHr),e(Pw,_Hr),e(ye,bHr),e(ye,Bw),e(Bw,QLe),e(QLe,vHr),e(Bw,FHr),e(Bw,gae),e(gae,THr),e(Bw,MHr),e(Vr,EHr),M(Iw,Vr,null),b(c,Wao,_),b(c,Tc,_),e(Tc,Nw),e(Nw,WLe),M(PR,WLe,null),e(Tc,CHr),e(Tc,ULe),e(ULe,wHr),b(c,Uao,_),b(c,hr,_),M(BR,hr,null),e(hr,AHr),e(hr,Mc),e(Mc,LHr),e(Mc,hae),e(hae,yHr),e(Mc,xHr),e(Mc,uae),e(uae,$Hr),e(Mc,kHr),e(hr,SHr),e(hr,IR),e(IR,RHr),e(IR,HLe),e(HLe,PHr),e(IR,BHr),e(hr,IHr),e(hr,oa),M(NR,oa,null),e(oa,NHr),e(oa,JLe),e(JLe,qHr),e(oa,DHr),e(oa,Ec),e(Ec,jHr),e(Ec,YLe),e(YLe,GHr),e(Ec,OHr),e(Ec,pae),e(pae,VHr),e(Ec,XHr),e(oa,zHr),M(qw,oa,null),e(hr,QHr),e(hr,Xr),M(qR,Xr,null),e(Xr,WHr),e(Xr,ZLe),e(ZLe,UHr),e(Xr,HHr),e(Xr,Dn),e(Dn,JHr),e(Dn,KLe),e(KLe,YHr),e(Dn,ZHr),e(Dn,eye),e(eye,KHr),e(Dn,eJr),e(Dn,oye),e(oye,oJr),e(Dn,rJr),e(Xr,tJr),e(Xr,Cc),e(Cc,Dw),e(Dw,rye),e(rye,aJr),e(Dw,nJr),e(Dw,_ae),e(_ae,sJr),e(Dw,lJr),e(Cc,iJr),e(Cc,jw),e(jw,tye),e(tye,dJr),e(jw,mJr),e(jw,bae),e(bae,cJr),e(jw,fJr),e(Cc,gJr),e(Cc,Gw),e(Gw,aye),e(aye,hJr),e(Gw,uJr),e(Gw,vae),e(vae,pJr),e(Gw,_Jr),e(Xr,bJr),M(Ow,Xr,null),b(c,Hao,_),b(c,wc,_),e(wc,Vw),e(Vw,nye),M(DR,nye,null),e(wc,vJr),e(wc,sye),e(sye,FJr),b(c,Jao,_),b(c,ur,_),M(jR,ur,null),e(ur,TJr),e(ur,Ac),e(Ac,MJr),e(Ac,Fae),e(Fae,EJr),e(Ac,CJr),e(Ac,Tae),e(Tae,wJr),e(Ac,AJr),e(ur,LJr),e(ur,GR),e(GR,yJr),e(GR,lye),e(lye,xJr),e(GR,$Jr),e(ur,kJr),e(ur,ra),M(OR,ra,null),e(ra,SJr),e(ra,iye),e(iye,RJr),e(ra,PJr),e(ra,Lc),e(Lc,BJr),e(Lc,dye),e(dye,IJr),e(Lc,NJr),e(Lc,Mae),e(Mae,qJr),e(Lc,DJr),e(ra,jJr),M(Xw,ra,null),e(ur,GJr),e(ur,zr),M(VR,zr,null),e(zr,OJr),e(zr,mye),e(mye,VJr),e(zr,XJr),e(zr,jn),e(jn,zJr),e(jn,cye),e(cye,QJr),e(jn,WJr),e(jn,fye),e(fye,UJr),e(jn,HJr),e(jn,gye),e(gye,JJr),e(jn,YJr),e(zr,ZJr),e(zr,ce),e(ce,zw),e(zw,hye),e(hye,KJr),e(zw,eYr),e(zw,Eae),e(Eae,oYr),e(zw,rYr),e(ce,tYr),e(ce,Qw),e(Qw,uye),e(uye,aYr),e(Qw,nYr),e(Qw,Cae),e(Cae,sYr),e(Qw,lYr),e(ce,iYr),e(ce,Ww),e(Ww,pye),e(pye,dYr),e(Ww,mYr),e(Ww,wae),e(wae,cYr),e(Ww,fYr),e(ce,gYr),e(ce,Uw),e(Uw,_ye),e(_ye,hYr),e(Uw,uYr),e(Uw,Aae),e(Aae,pYr),e(Uw,_Yr),e(ce,bYr),e(ce,Hw),e(Hw,bye),e(bye,vYr),e(Hw,FYr),e(Hw,Lae),e(Lae,TYr),e(Hw,MYr),e(ce,EYr),e(ce,Jw),e(Jw,vye),e(vye,CYr),e(Jw,wYr),e(Jw,yae),e(yae,AYr),e(Jw,LYr),e(ce,yYr),e(ce,Yw),e(Yw,Fye),e(Fye,xYr),e(Yw,$Yr),e(Yw,xae),e(xae,kYr),e(Yw,SYr),e(ce,RYr),e(ce,Zw),e(Zw,Tye),e(Tye,PYr),e(Zw,BYr),e(Zw,$ae),e($ae,IYr),e(Zw,NYr),e(ce,qYr),e(ce,Kw),e(Kw,Mye),e(Mye,DYr),e(Kw,jYr),e(Kw,kae),e(kae,GYr),e(Kw,OYr),e(ce,VYr),e(ce,eA),e(eA,Eye),e(Eye,XYr),e(eA,zYr),e(eA,Sae),e(Sae,QYr),e(eA,WYr),e(ce,UYr),e(ce,oA),e(oA,Cye),e(Cye,HYr),e(oA,JYr),e(oA,Rae),e(Rae,YYr),e(oA,ZYr),e(ce,KYr),e(ce,rA),e(rA,wye),e(wye,eZr),e(rA,oZr),e(rA,Pae),e(Pae,rZr),e(rA,tZr),e(ce,aZr),e(ce,tA),e(tA,Aye),e(Aye,nZr),e(tA,sZr),e(tA,Bae),e(Bae,lZr),e(tA,iZr),e(ce,dZr),e(ce,aA),e(aA,Lye),e(Lye,mZr),e(aA,cZr),e(aA,Iae),e(Iae,fZr),e(aA,gZr),e(ce,hZr),e(ce,nA),e(nA,yye),e(yye,uZr),e(nA,pZr),e(nA,Nae),e(Nae,_Zr),e(nA,bZr),e(ce,vZr),e(ce,sA),e(sA,xye),e(xye,FZr),e(sA,TZr),e(sA,qae),e(qae,MZr),e(sA,EZr),e(ce,CZr),e(ce,lA),e(lA,$ye),e($ye,wZr),e(lA,AZr),e(lA,Dae),e(Dae,LZr),e(lA,yZr),e(ce,xZr),e(ce,iA),e(iA,kye),e(kye,$Zr),e(iA,kZr),e(iA,jae),e(jae,SZr),e(iA,RZr),e(ce,PZr),e(ce,dA),e(dA,Sye),e(Sye,BZr),e(dA,IZr),e(dA,Gae),e(Gae,NZr),e(dA,qZr),e(ce,DZr),e(ce,mA),e(mA,Rye),e(Rye,jZr),e(mA,GZr),e(mA,Oae),e(Oae,OZr),e(mA,VZr),e(ce,XZr),e(ce,cA),e(cA,Pye),e(Pye,zZr),e(cA,QZr),e(cA,Vae),e(Vae,WZr),e(cA,UZr),e(zr,HZr),M(fA,zr,null),b(c,Yao,_),b(c,yc,_),e(yc,gA),e(gA,Bye),M(XR,Bye,null),e(yc,JZr),e(yc,Iye),e(Iye,YZr),b(c,Zao,_),b(c,pr,_),M(zR,pr,null),e(pr,ZZr),e(pr,xc),e(xc,KZr),e(xc,Xae),e(Xae,eKr),e(xc,oKr),e(xc,zae),e(zae,rKr),e(xc,tKr),e(pr,aKr),e(pr,QR),e(QR,nKr),e(QR,Nye),e(Nye,sKr),e(QR,lKr),e(pr,iKr),e(pr,ta),M(WR,ta,null),e(ta,dKr),e(ta,qye),e(qye,mKr),e(ta,cKr),e(ta,$c),e($c,fKr),e($c,Dye),e(Dye,gKr),e($c,hKr),e($c,Qae),e(Qae,uKr),e($c,pKr),e(ta,_Kr),M(hA,ta,null),e(pr,bKr),e(pr,Qr),M(UR,Qr,null),e(Qr,vKr),e(Qr,jye),e(jye,FKr),e(Qr,TKr),e(Qr,Gn),e(Gn,MKr),e(Gn,Gye),e(Gye,EKr),e(Gn,CKr),e(Gn,Oye),e(Oye,wKr),e(Gn,AKr),e(Gn,Vye),e(Vye,LKr),e(Gn,yKr),e(Qr,xKr),e(Qr,xe),e(xe,uA),e(uA,Xye),e(Xye,$Kr),e(uA,kKr),e(uA,Wae),e(Wae,SKr),e(uA,RKr),e(xe,PKr),e(xe,pA),e(pA,zye),e(zye,BKr),e(pA,IKr),e(pA,Uae),e(Uae,NKr),e(pA,qKr),e(xe,DKr),e(xe,_A),e(_A,Qye),e(Qye,jKr),e(_A,GKr),e(_A,Hae),e(Hae,OKr),e(_A,VKr),e(xe,XKr),e(xe,bA),e(bA,Wye),e(Wye,zKr),e(bA,QKr),e(bA,Jae),e(Jae,WKr),e(bA,UKr),e(xe,HKr),e(xe,vA),e(vA,Uye),e(Uye,JKr),e(vA,YKr),e(vA,Yae),e(Yae,ZKr),e(vA,KKr),e(xe,eet),e(xe,FA),e(FA,Hye),e(Hye,oet),e(FA,ret),e(FA,Zae),e(Zae,tet),e(FA,aet),e(xe,net),e(xe,TA),e(TA,Jye),e(Jye,set),e(TA,iet),e(TA,Kae),e(Kae,det),e(TA,met),e(xe,cet),e(xe,MA),e(MA,Yye),e(Yye,fet),e(MA,get),e(MA,ene),e(ene,het),e(MA,uet),e(xe,pet),e(xe,EA),e(EA,Zye),e(Zye,_et),e(EA,bet),e(EA,one),e(one,vet),e(EA,Fet),e(xe,Tet),e(xe,CA),e(CA,Kye),e(Kye,Met),e(CA,Eet),e(CA,rne),e(rne,Cet),e(CA,wet),e(Qr,Aet),M(wA,Qr,null),b(c,Kao,_),b(c,kc,_),e(kc,AA),e(AA,e9e),M(HR,e9e,null),e(kc,Let),e(kc,o9e),e(o9e,yet),b(c,eno,_),b(c,_r,_),M(JR,_r,null),e(_r,xet),e(_r,Sc),e(Sc,$et),e(Sc,tne),e(tne,ket),e(Sc,Set),e(Sc,ane),e(ane,Ret),e(Sc,Pet),e(_r,Bet),e(_r,YR),e(YR,Iet),e(YR,r9e),e(r9e,Net),e(YR,qet),e(_r,Det),e(_r,aa),M(ZR,aa,null),e(aa,jet),e(aa,t9e),e(t9e,Get),e(aa,Oet),e(aa,Rc),e(Rc,Vet),e(Rc,a9e),e(a9e,Xet),e(Rc,zet),e(Rc,nne),e(nne,Qet),e(Rc,Wet),e(aa,Uet),M(LA,aa,null),e(_r,Het),e(_r,Wr),M(KR,Wr,null),e(Wr,Jet),e(Wr,n9e),e(n9e,Yet),e(Wr,Zet),e(Wr,On),e(On,Ket),e(On,s9e),e(s9e,eot),e(On,oot),e(On,l9e),e(l9e,rot),e(On,tot),e(On,i9e),e(i9e,aot),e(On,not),e(Wr,sot),e(Wr,re),e(re,yA),e(yA,d9e),e(d9e,lot),e(yA,iot),e(yA,sne),e(sne,dot),e(yA,mot),e(re,cot),e(re,xA),e(xA,m9e),e(m9e,fot),e(xA,got),e(xA,lne),e(lne,hot),e(xA,uot),e(re,pot),e(re,$A),e($A,c9e),e(c9e,_ot),e($A,bot),e($A,ine),e(ine,vot),e($A,Fot),e(re,Tot),e(re,kA),e(kA,f9e),e(f9e,Mot),e(kA,Eot),e(kA,dne),e(dne,Cot),e(kA,wot),e(re,Aot),e(re,SA),e(SA,g9e),e(g9e,Lot),e(SA,yot),e(SA,mne),e(mne,xot),e(SA,$ot),e(re,kot),e(re,RA),e(RA,h9e),e(h9e,Sot),e(RA,Rot),e(RA,cne),e(cne,Pot),e(RA,Bot),e(re,Iot),e(re,PA),e(PA,u9e),e(u9e,Not),e(PA,qot),e(PA,fne),e(fne,Dot),e(PA,jot),e(re,Got),e(re,BA),e(BA,p9e),e(p9e,Oot),e(BA,Vot),e(BA,gne),e(gne,Xot),e(BA,zot),e(re,Qot),e(re,IA),e(IA,_9e),e(_9e,Wot),e(IA,Uot),e(IA,hne),e(hne,Hot),e(IA,Jot),e(re,Yot),e(re,NA),e(NA,b9e),e(b9e,Zot),e(NA,Kot),e(NA,une),e(une,ert),e(NA,ort),e(re,rrt),e(re,qA),e(qA,v9e),e(v9e,trt),e(qA,art),e(qA,pne),e(pne,nrt),e(qA,srt),e(re,lrt),e(re,DA),e(DA,F9e),e(F9e,irt),e(DA,drt),e(DA,_ne),e(_ne,mrt),e(DA,crt),e(re,frt),e(re,jA),e(jA,T9e),e(T9e,grt),e(jA,hrt),e(jA,bne),e(bne,urt),e(jA,prt),e(re,_rt),e(re,GA),e(GA,M9e),e(M9e,brt),e(GA,vrt),e(GA,vne),e(vne,Frt),e(GA,Trt),e(re,Mrt),e(re,OA),e(OA,E9e),e(E9e,Ert),e(OA,Crt),e(OA,Fne),e(Fne,wrt),e(OA,Art),e(re,Lrt),e(re,VA),e(VA,C9e),e(C9e,yrt),e(VA,xrt),e(VA,Tne),e(Tne,$rt),e(VA,krt),e(re,Srt),e(re,XA),e(XA,w9e),e(w9e,Rrt),e(XA,Prt),e(XA,Mne),e(Mne,Brt),e(XA,Irt),e(re,Nrt),e(re,zA),e(zA,A9e),e(A9e,qrt),e(zA,Drt),e(zA,Ene),e(Ene,jrt),e(zA,Grt),e(re,Ort),e(re,QA),e(QA,L9e),e(L9e,Vrt),e(QA,Xrt),e(QA,Cne),e(Cne,zrt),e(QA,Qrt),e(re,Wrt),e(re,WA),e(WA,y9e),e(y9e,Urt),e(WA,Hrt),e(WA,wne),e(wne,Jrt),e(WA,Yrt),e(re,Zrt),e(re,UA),e(UA,x9e),e(x9e,Krt),e(UA,ett),e(UA,Ane),e(Ane,ott),e(UA,rtt),e(re,ttt),e(re,HA),e(HA,$9e),e($9e,att),e(HA,ntt),e(HA,Lne),e(Lne,stt),e(HA,ltt),e(re,itt),e(re,JA),e(JA,k9e),e(k9e,dtt),e(JA,mtt),e(JA,yne),e(yne,ctt),e(JA,ftt),e(re,gtt),e(re,YA),e(YA,S9e),e(S9e,htt),e(YA,utt),e(YA,xne),e(xne,ptt),e(YA,_tt),e(re,btt),e(re,ZA),e(ZA,R9e),e(R9e,vtt),e(ZA,Ftt),e(ZA,$ne),e($ne,Ttt),e(ZA,Mtt),e(re,Ett),e(re,KA),e(KA,P9e),e(P9e,Ctt),e(KA,wtt),e(KA,kne),e(kne,Att),e(KA,Ltt),e(re,ytt),e(re,e6),e(e6,B9e),e(B9e,xtt),e(e6,$tt),e(e6,Sne),e(Sne,ktt),e(e6,Stt),e(re,Rtt),e(re,o6),e(o6,I9e),e(I9e,Ptt),e(o6,Btt),e(o6,Rne),e(Rne,Itt),e(o6,Ntt),e(Wr,qtt),M(r6,Wr,null),b(c,ono,_),b(c,Pc,_),e(Pc,t6),e(t6,N9e),M(eP,N9e,null),e(Pc,Dtt),e(Pc,q9e),e(q9e,jtt),b(c,rno,_),b(c,br,_),M(oP,br,null),e(br,Gtt),e(br,Bc),e(Bc,Ott),e(Bc,Pne),e(Pne,Vtt),e(Bc,Xtt),e(Bc,Bne),e(Bne,ztt),e(Bc,Qtt),e(br,Wtt),e(br,rP),e(rP,Utt),e(rP,D9e),e(D9e,Htt),e(rP,Jtt),e(br,Ytt),e(br,na),M(tP,na,null),e(na,Ztt),e(na,j9e),e(j9e,Ktt),e(na,eat),e(na,Ic),e(Ic,oat),e(Ic,G9e),e(G9e,rat),e(Ic,tat),e(Ic,Ine),e(Ine,aat),e(Ic,nat),e(na,sat),M(a6,na,null),e(br,lat),e(br,Ur),M(aP,Ur,null),e(Ur,iat),e(Ur,O9e),e(O9e,dat),e(Ur,mat),e(Ur,Vn),e(Vn,cat),e(Vn,V9e),e(V9e,fat),e(Vn,gat),e(Vn,X9e),e(X9e,hat),e(Vn,uat),e(Vn,z9e),e(z9e,pat),e(Vn,_at),e(Ur,bat),e(Ur,ve),e(ve,n6),e(n6,Q9e),e(Q9e,vat),e(n6,Fat),e(n6,Nne),e(Nne,Tat),e(n6,Mat),e(ve,Eat),e(ve,s6),e(s6,W9e),e(W9e,Cat),e(s6,wat),e(s6,qne),e(qne,Aat),e(s6,Lat),e(ve,yat),e(ve,l6),e(l6,U9e),e(U9e,xat),e(l6,$at),e(l6,Dne),e(Dne,kat),e(l6,Sat),e(ve,Rat),e(ve,i6),e(i6,H9e),e(H9e,Pat),e(i6,Bat),e(i6,jne),e(jne,Iat),e(i6,Nat),e(ve,qat),e(ve,d6),e(d6,J9e),e(J9e,Dat),e(d6,jat),e(d6,Gne),e(Gne,Gat),e(d6,Oat),e(ve,Vat),e(ve,m6),e(m6,Y9e),e(Y9e,Xat),e(m6,zat),e(m6,One),e(One,Qat),e(m6,Wat),e(ve,Uat),e(ve,c6),e(c6,Z9e),e(Z9e,Hat),e(c6,Jat),e(c6,Vne),e(Vne,Yat),e(c6,Zat),e(ve,Kat),e(ve,f6),e(f6,K9e),e(K9e,ent),e(f6,ont),e(f6,Xne),e(Xne,rnt),e(f6,tnt),e(ve,ant),e(ve,g6),e(g6,exe),e(exe,nnt),e(g6,snt),e(g6,zne),e(zne,lnt),e(g6,int),e(ve,dnt),e(ve,h6),e(h6,oxe),e(oxe,mnt),e(h6,cnt),e(h6,Qne),e(Qne,fnt),e(h6,gnt),e(ve,hnt),e(ve,u6),e(u6,rxe),e(rxe,unt),e(u6,pnt),e(u6,Wne),e(Wne,_nt),e(u6,bnt),e(ve,vnt),e(ve,p6),e(p6,txe),e(txe,Fnt),e(p6,Tnt),e(p6,Une),e(Une,Mnt),e(p6,Ent),e(ve,Cnt),e(ve,_6),e(_6,axe),e(axe,wnt),e(_6,Ant),e(_6,Hne),e(Hne,Lnt),e(_6,ynt),e(ve,xnt),e(ve,b6),e(b6,nxe),e(nxe,$nt),e(b6,knt),e(b6,Jne),e(Jne,Snt),e(b6,Rnt),e(ve,Pnt),e(ve,v6),e(v6,sxe),e(sxe,Bnt),e(v6,Int),e(v6,Yne),e(Yne,Nnt),e(v6,qnt),e(ve,Dnt),e(ve,F6),e(F6,lxe),e(lxe,jnt),e(F6,Gnt),e(F6,Zne),e(Zne,Ont),e(F6,Vnt),e(ve,Xnt),e(ve,T6),e(T6,ixe),e(ixe,znt),e(T6,Qnt),e(T6,Kne),e(Kne,Wnt),e(T6,Unt),e(Ur,Hnt),M(M6,Ur,null),b(c,tno,_),b(c,Nc,_),e(Nc,E6),e(E6,dxe),M(nP,dxe,null),e(Nc,Jnt),e(Nc,mxe),e(mxe,Ynt),b(c,ano,_),b(c,vr,_),M(sP,vr,null),e(vr,Znt),e(vr,qc),e(qc,Knt),e(qc,ese),e(ese,est),e(qc,ost),e(qc,ose),e(ose,rst),e(qc,tst),e(vr,ast),e(vr,lP),e(lP,nst),e(lP,cxe),e(cxe,sst),e(lP,lst),e(vr,ist),e(vr,sa),M(iP,sa,null),e(sa,dst),e(sa,fxe),e(fxe,mst),e(sa,cst),e(sa,Dc),e(Dc,fst),e(Dc,gxe),e(gxe,gst),e(Dc,hst),e(Dc,rse),e(rse,ust),e(Dc,pst),e(sa,_st),M(C6,sa,null),e(vr,bst),e(vr,Hr),M(dP,Hr,null),e(Hr,vst),e(Hr,hxe),e(hxe,Fst),e(Hr,Tst),e(Hr,Xn),e(Xn,Mst),e(Xn,uxe),e(uxe,Est),e(Xn,Cst),e(Xn,pxe),e(pxe,wst),e(Xn,Ast),e(Xn,_xe),e(_xe,Lst),e(Xn,yst),e(Hr,xst),e(Hr,mP),e(mP,w6),e(w6,bxe),e(bxe,$st),e(w6,kst),e(w6,tse),e(tse,Sst),e(w6,Rst),e(mP,Pst),e(mP,A6),e(A6,vxe),e(vxe,Bst),e(A6,Ist),e(A6,ase),e(ase,Nst),e(A6,qst),e(Hr,Dst),M(L6,Hr,null),b(c,nno,_),b(c,jc,_),e(jc,y6),e(y6,Fxe),M(cP,Fxe,null),e(jc,jst),e(jc,Txe),e(Txe,Gst),b(c,sno,_),b(c,Fr,_),M(fP,Fr,null),e(Fr,Ost),e(Fr,Gc),e(Gc,Vst),e(Gc,nse),e(nse,Xst),e(Gc,zst),e(Gc,sse),e(sse,Qst),e(Gc,Wst),e(Fr,Ust),e(Fr,gP),e(gP,Hst),e(gP,Mxe),e(Mxe,Jst),e(gP,Yst),e(Fr,Zst),e(Fr,la),M(hP,la,null),e(la,Kst),e(la,Exe),e(Exe,elt),e(la,olt),e(la,Oc),e(Oc,rlt),e(Oc,Cxe),e(Cxe,tlt),e(Oc,alt),e(Oc,lse),e(lse,nlt),e(Oc,slt),e(la,llt),M(x6,la,null),e(Fr,ilt),e(Fr,Jr),M(uP,Jr,null),e(Jr,dlt),e(Jr,wxe),e(wxe,mlt),e(Jr,clt),e(Jr,zn),e(zn,flt),e(zn,Axe),e(Axe,glt),e(zn,hlt),e(zn,Lxe),e(Lxe,ult),e(zn,plt),e(zn,yxe),e(yxe,_lt),e(zn,blt),e(Jr,vlt),e(Jr,xxe),e(xxe,$6),e($6,$xe),e($xe,Flt),e($6,Tlt),e($6,ise),e(ise,Mlt),e($6,Elt),e(Jr,Clt),M(k6,Jr,null),b(c,lno,_),b(c,Vc,_),e(Vc,S6),e(S6,kxe),M(pP,kxe,null),e(Vc,wlt),e(Vc,Sxe),e(Sxe,Alt),b(c,ino,_),b(c,Tr,_),M(_P,Tr,null),e(Tr,Llt),e(Tr,Xc),e(Xc,ylt),e(Xc,dse),e(dse,xlt),e(Xc,$lt),e(Xc,mse),e(mse,klt),e(Xc,Slt),e(Tr,Rlt),e(Tr,bP),e(bP,Plt),e(bP,Rxe),e(Rxe,Blt),e(bP,Ilt),e(Tr,Nlt),e(Tr,ia),M(vP,ia,null),e(ia,qlt),e(ia,Pxe),e(Pxe,Dlt),e(ia,jlt),e(ia,zc),e(zc,Glt),e(zc,Bxe),e(Bxe,Olt),e(zc,Vlt),e(zc,cse),e(cse,Xlt),e(zc,zlt),e(ia,Qlt),M(R6,ia,null),e(Tr,Wlt),e(Tr,Yr),M(FP,Yr,null),e(Yr,Ult),e(Yr,Ixe),e(Ixe,Hlt),e(Yr,Jlt),e(Yr,Qn),e(Qn,Ylt),e(Qn,Nxe),e(Nxe,Zlt),e(Qn,Klt),e(Qn,qxe),e(qxe,eit),e(Qn,oit),e(Qn,Dxe),e(Dxe,rit),e(Qn,tit),e(Yr,ait),e(Yr,jxe),e(jxe,P6),e(P6,Gxe),e(Gxe,nit),e(P6,sit),e(P6,fse),e(fse,lit),e(P6,iit),e(Yr,dit),M(B6,Yr,null),b(c,dno,_),b(c,Qc,_),e(Qc,I6),e(I6,Oxe),M(TP,Oxe,null),e(Qc,mit),e(Qc,Vxe),e(Vxe,cit),b(c,mno,_),b(c,Mr,_),M(MP,Mr,null),e(Mr,fit),e(Mr,Wc),e(Wc,git),e(Wc,gse),e(gse,hit),e(Wc,uit),e(Wc,hse),e(hse,pit),e(Wc,_it),e(Mr,bit),e(Mr,EP),e(EP,vit),e(EP,Xxe),e(Xxe,Fit),e(EP,Tit),e(Mr,Mit),e(Mr,da),M(CP,da,null),e(da,Eit),e(da,zxe),e(zxe,Cit),e(da,wit),e(da,Uc),e(Uc,Ait),e(Uc,Qxe),e(Qxe,Lit),e(Uc,yit),e(Uc,use),e(use,xit),e(Uc,$it),e(da,kit),M(N6,da,null),e(Mr,Sit),e(Mr,Zr),M(wP,Zr,null),e(Zr,Rit),e(Zr,Wxe),e(Wxe,Pit),e(Zr,Bit),e(Zr,Wn),e(Wn,Iit),e(Wn,Uxe),e(Uxe,Nit),e(Wn,qit),e(Wn,Hxe),e(Hxe,Dit),e(Wn,jit),e(Wn,Jxe),e(Jxe,Git),e(Wn,Oit),e(Zr,Vit),e(Zr,ie),e(ie,q6),e(q6,Yxe),e(Yxe,Xit),e(q6,zit),e(q6,pse),e(pse,Qit),e(q6,Wit),e(ie,Uit),e(ie,D6),e(D6,Zxe),e(Zxe,Hit),e(D6,Jit),e(D6,_se),e(_se,Yit),e(D6,Zit),e(ie,Kit),e(ie,j6),e(j6,Kxe),e(Kxe,edt),e(j6,odt),e(j6,bse),e(bse,rdt),e(j6,tdt),e(ie,adt),e(ie,G6),e(G6,e$e),e(e$e,ndt),e(G6,sdt),e(G6,vse),e(vse,ldt),e(G6,idt),e(ie,ddt),e(ie,O6),e(O6,o$e),e(o$e,mdt),e(O6,cdt),e(O6,Fse),e(Fse,fdt),e(O6,gdt),e(ie,hdt),e(ie,V6),e(V6,r$e),e(r$e,udt),e(V6,pdt),e(V6,Tse),e(Tse,_dt),e(V6,bdt),e(ie,vdt),e(ie,X6),e(X6,t$e),e(t$e,Fdt),e(X6,Tdt),e(X6,Mse),e(Mse,Mdt),e(X6,Edt),e(ie,Cdt),e(ie,z6),e(z6,a$e),e(a$e,wdt),e(z6,Adt),e(z6,Ese),e(Ese,Ldt),e(z6,ydt),e(ie,xdt),e(ie,Q6),e(Q6,n$e),e(n$e,$dt),e(Q6,kdt),e(Q6,Cse),e(Cse,Sdt),e(Q6,Rdt),e(ie,Pdt),e(ie,W6),e(W6,s$e),e(s$e,Bdt),e(W6,Idt),e(W6,wse),e(wse,Ndt),e(W6,qdt),e(ie,Ddt),e(ie,U6),e(U6,l$e),e(l$e,jdt),e(U6,Gdt),e(U6,Ase),e(Ase,Odt),e(U6,Vdt),e(ie,Xdt),e(ie,H6),e(H6,i$e),e(i$e,zdt),e(H6,Qdt),e(H6,Lse),e(Lse,Wdt),e(H6,Udt),e(ie,Hdt),e(ie,J6),e(J6,d$e),e(d$e,Jdt),e(J6,Ydt),e(J6,yse),e(yse,Zdt),e(J6,Kdt),e(ie,emt),e(ie,Y6),e(Y6,m$e),e(m$e,omt),e(Y6,rmt),e(Y6,xse),e(xse,tmt),e(Y6,amt),e(ie,nmt),e(ie,Z6),e(Z6,c$e),e(c$e,smt),e(Z6,lmt),e(Z6,$se),e($se,imt),e(Z6,dmt),e(ie,mmt),e(ie,K6),e(K6,f$e),e(f$e,cmt),e(K6,fmt),e(K6,kse),e(kse,gmt),e(K6,hmt),e(ie,umt),e(ie,e7),e(e7,g$e),e(g$e,pmt),e(e7,_mt),e(e7,Sse),e(Sse,bmt),e(e7,vmt),e(ie,Fmt),e(ie,o7),e(o7,h$e),e(h$e,Tmt),e(o7,Mmt),e(o7,Rse),e(Rse,Emt),e(o7,Cmt),e(ie,wmt),e(ie,r7),e(r7,u$e),e(u$e,Amt),e(r7,Lmt),e(r7,Pse),e(Pse,ymt),e(r7,xmt),e(ie,$mt),e(ie,t7),e(t7,p$e),e(p$e,kmt),e(t7,Smt),e(t7,Bse),e(Bse,Rmt),e(t7,Pmt),e(ie,Bmt),e(ie,a7),e(a7,_$e),e(_$e,Imt),e(a7,Nmt),e(a7,Ise),e(Ise,qmt),e(a7,Dmt),e(ie,jmt),e(ie,n7),e(n7,b$e),e(b$e,Gmt),e(n7,Omt),e(n7,Nse),e(Nse,Vmt),e(n7,Xmt),e(Zr,zmt),M(s7,Zr,null),b(c,cno,_),b(c,Hc,_),e(Hc,l7),e(l7,v$e),M(AP,v$e,null),e(Hc,Qmt),e(Hc,F$e),e(F$e,Wmt),b(c,fno,_),b(c,Er,_),M(LP,Er,null),e(Er,Umt),e(Er,Jc),e(Jc,Hmt),e(Jc,qse),e(qse,Jmt),e(Jc,Ymt),e(Jc,Dse),e(Dse,Zmt),e(Jc,Kmt),e(Er,ect),e(Er,yP),e(yP,oct),e(yP,T$e),e(T$e,rct),e(yP,tct),e(Er,act),e(Er,ma),M(xP,ma,null),e(ma,nct),e(ma,M$e),e(M$e,sct),e(ma,lct),e(ma,Yc),e(Yc,ict),e(Yc,E$e),e(E$e,dct),e(Yc,mct),e(Yc,jse),e(jse,cct),e(Yc,fct),e(ma,gct),M(i7,ma,null),e(Er,hct),e(Er,Kr),M($P,Kr,null),e(Kr,uct),e(Kr,C$e),e(C$e,pct),e(Kr,_ct),e(Kr,Un),e(Un,bct),e(Un,w$e),e(w$e,vct),e(Un,Fct),e(Un,A$e),e(A$e,Tct),e(Un,Mct),e(Un,L$e),e(L$e,Ect),e(Un,Cct),e(Kr,wct),e(Kr,fe),e(fe,d7),e(d7,y$e),e(y$e,Act),e(d7,Lct),e(d7,Gse),e(Gse,yct),e(d7,xct),e(fe,$ct),e(fe,m7),e(m7,x$e),e(x$e,kct),e(m7,Sct),e(m7,Ose),e(Ose,Rct),e(m7,Pct),e(fe,Bct),e(fe,c7),e(c7,$$e),e($$e,Ict),e(c7,Nct),e(c7,Vse),e(Vse,qct),e(c7,Dct),e(fe,jct),e(fe,f7),e(f7,k$e),e(k$e,Gct),e(f7,Oct),e(f7,Xse),e(Xse,Vct),e(f7,Xct),e(fe,zct),e(fe,g7),e(g7,S$e),e(S$e,Qct),e(g7,Wct),e(g7,zse),e(zse,Uct),e(g7,Hct),e(fe,Jct),e(fe,h7),e(h7,R$e),e(R$e,Yct),e(h7,Zct),e(h7,Qse),e(Qse,Kct),e(h7,eft),e(fe,oft),e(fe,u7),e(u7,P$e),e(P$e,rft),e(u7,tft),e(u7,Wse),e(Wse,aft),e(u7,nft),e(fe,sft),e(fe,p7),e(p7,B$e),e(B$e,lft),e(p7,ift),e(p7,Use),e(Use,dft),e(p7,mft),e(fe,cft),e(fe,_7),e(_7,I$e),e(I$e,fft),e(_7,gft),e(_7,Hse),e(Hse,hft),e(_7,uft),e(fe,pft),e(fe,b7),e(b7,N$e),e(N$e,_ft),e(b7,bft),e(b7,Jse),e(Jse,vft),e(b7,Fft),e(fe,Tft),e(fe,v7),e(v7,q$e),e(q$e,Mft),e(v7,Eft),e(v7,Yse),e(Yse,Cft),e(v7,wft),e(fe,Aft),e(fe,F7),e(F7,D$e),e(D$e,Lft),e(F7,yft),e(F7,Zse),e(Zse,xft),e(F7,$ft),e(fe,kft),e(fe,T7),e(T7,j$e),e(j$e,Sft),e(T7,Rft),e(T7,Kse),e(Kse,Pft),e(T7,Bft),e(fe,Ift),e(fe,M7),e(M7,G$e),e(G$e,Nft),e(M7,qft),e(M7,ele),e(ele,Dft),e(M7,jft),e(fe,Gft),e(fe,E7),e(E7,O$e),e(O$e,Oft),e(E7,Vft),e(E7,ole),e(ole,Xft),e(E7,zft),e(fe,Qft),e(fe,C7),e(C7,V$e),e(V$e,Wft),e(C7,Uft),e(C7,rle),e(rle,Hft),e(C7,Jft),e(fe,Yft),e(fe,w7),e(w7,X$e),e(X$e,Zft),e(w7,Kft),e(w7,tle),e(tle,egt),e(w7,ogt),e(fe,rgt),e(fe,A7),e(A7,z$e),e(z$e,tgt),e(A7,agt),e(A7,ale),e(ale,ngt),e(A7,sgt),e(fe,lgt),e(fe,L7),e(L7,Q$e),e(Q$e,igt),e(L7,dgt),e(L7,nle),e(nle,mgt),e(L7,cgt),e(fe,fgt),e(fe,y7),e(y7,W$e),e(W$e,ggt),e(y7,hgt),e(y7,sle),e(sle,ugt),e(y7,pgt),e(fe,_gt),e(fe,x7),e(x7,U$e),e(U$e,bgt),e(x7,vgt),e(x7,lle),e(lle,Fgt),e(x7,Tgt),e(Kr,Mgt),M($7,Kr,null),b(c,gno,_),b(c,Zc,_),e(Zc,k7),e(k7,H$e),M(kP,H$e,null),e(Zc,Egt),e(Zc,J$e),e(J$e,Cgt),b(c,hno,_),b(c,Cr,_),M(SP,Cr,null),e(Cr,wgt),e(Cr,Kc),e(Kc,Agt),e(Kc,ile),e(ile,Lgt),e(Kc,ygt),e(Kc,dle),e(dle,xgt),e(Kc,$gt),e(Cr,kgt),e(Cr,RP),e(RP,Sgt),e(RP,Y$e),e(Y$e,Rgt),e(RP,Pgt),e(Cr,Bgt),e(Cr,ca),M(PP,ca,null),e(ca,Igt),e(ca,Z$e),e(Z$e,Ngt),e(ca,qgt),e(ca,ef),e(ef,Dgt),e(ef,K$e),e(K$e,jgt),e(ef,Ggt),e(ef,mle),e(mle,Ogt),e(ef,Vgt),e(ca,Xgt),M(S7,ca,null),e(Cr,zgt),e(Cr,et),M(BP,et,null),e(et,Qgt),e(et,eke),e(eke,Wgt),e(et,Ugt),e(et,Hn),e(Hn,Hgt),e(Hn,oke),e(oke,Jgt),e(Hn,Ygt),e(Hn,rke),e(rke,Zgt),e(Hn,Kgt),e(Hn,tke),e(tke,eht),e(Hn,oht),e(et,rht),e(et,ake),e(ake,R7),e(R7,nke),e(nke,tht),e(R7,aht),e(R7,cle),e(cle,nht),e(R7,sht),e(et,lht),M(P7,et,null),b(c,uno,_),b(c,of,_),e(of,B7),e(B7,ske),M(IP,ske,null),e(of,iht),e(of,lke),e(lke,dht),b(c,pno,_),b(c,wr,_),M(NP,wr,null),e(wr,mht),e(wr,rf),e(rf,cht),e(rf,fle),e(fle,fht),e(rf,ght),e(rf,gle),e(gle,hht),e(rf,uht),e(wr,pht),e(wr,qP),e(qP,_ht),e(qP,ike),e(ike,bht),e(qP,vht),e(wr,Fht),e(wr,fa),M(DP,fa,null),e(fa,Tht),e(fa,dke),e(dke,Mht),e(fa,Eht),e(fa,tf),e(tf,Cht),e(tf,mke),e(mke,wht),e(tf,Aht),e(tf,hle),e(hle,Lht),e(tf,yht),e(fa,xht),M(I7,fa,null),e(wr,$ht),e(wr,ot),M(jP,ot,null),e(ot,kht),e(ot,cke),e(cke,Sht),e(ot,Rht),e(ot,Jn),e(Jn,Pht),e(Jn,fke),e(fke,Bht),e(Jn,Iht),e(Jn,gke),e(gke,Nht),e(Jn,qht),e(Jn,hke),e(hke,Dht),e(Jn,jht),e(ot,Ght),e(ot,GP),e(GP,N7),e(N7,uke),e(uke,Oht),e(N7,Vht),e(N7,ule),e(ule,Xht),e(N7,zht),e(GP,Qht),e(GP,q7),e(q7,pke),e(pke,Wht),e(q7,Uht),e(q7,ple),e(ple,Hht),e(q7,Jht),e(ot,Yht),M(D7,ot,null),b(c,_no,_),b(c,af,_),e(af,j7),e(j7,_ke),M(OP,_ke,null),e(af,Zht),e(af,bke),e(bke,Kht),b(c,bno,_),b(c,Ar,_),M(VP,Ar,null),e(Ar,eut),e(Ar,nf),e(nf,out),e(nf,_le),e(_le,rut),e(nf,tut),e(nf,ble),e(ble,aut),e(nf,nut),e(Ar,sut),e(Ar,XP),e(XP,lut),e(XP,vke),e(vke,iut),e(XP,dut),e(Ar,mut),e(Ar,ga),M(zP,ga,null),e(ga,cut),e(ga,Fke),e(Fke,fut),e(ga,gut),e(ga,sf),e(sf,hut),e(sf,Tke),e(Tke,uut),e(sf,put),e(sf,vle),e(vle,_ut),e(sf,but),e(ga,vut),M(G7,ga,null),e(Ar,Fut),e(Ar,rt),M(QP,rt,null),e(rt,Tut),e(rt,Mke),e(Mke,Mut),e(rt,Eut),e(rt,Yn),e(Yn,Cut),e(Yn,Eke),e(Eke,wut),e(Yn,Aut),e(Yn,Cke),e(Cke,Lut),e(Yn,yut),e(Yn,wke),e(wke,xut),e(Yn,$ut),e(rt,kut),e(rt,te),e(te,O7),e(O7,Ake),e(Ake,Sut),e(O7,Rut),e(O7,Fle),e(Fle,Put),e(O7,But),e(te,Iut),e(te,V7),e(V7,Lke),e(Lke,Nut),e(V7,qut),e(V7,Tle),e(Tle,Dut),e(V7,jut),e(te,Gut),e(te,X7),e(X7,yke),e(yke,Out),e(X7,Vut),e(X7,Mle),e(Mle,Xut),e(X7,zut),e(te,Qut),e(te,z7),e(z7,xke),e(xke,Wut),e(z7,Uut),e(z7,Ele),e(Ele,Hut),e(z7,Jut),e(te,Yut),e(te,Q7),e(Q7,$ke),e($ke,Zut),e(Q7,Kut),e(Q7,Cle),e(Cle,ept),e(Q7,opt),e(te,rpt),e(te,W7),e(W7,kke),e(kke,tpt),e(W7,apt),e(W7,wle),e(wle,npt),e(W7,spt),e(te,lpt),e(te,U7),e(U7,Ske),e(Ske,ipt),e(U7,dpt),e(U7,Ale),e(Ale,mpt),e(U7,cpt),e(te,fpt),e(te,H7),e(H7,Rke),e(Rke,gpt),e(H7,hpt),e(H7,Lle),e(Lle,upt),e(H7,ppt),e(te,_pt),e(te,J7),e(J7,Pke),e(Pke,bpt),e(J7,vpt),e(J7,yle),e(yle,Fpt),e(J7,Tpt),e(te,Mpt),e(te,Y7),e(Y7,Bke),e(Bke,Ept),e(Y7,Cpt),e(Y7,xle),e(xle,wpt),e(Y7,Apt),e(te,Lpt),e(te,Z7),e(Z7,Ike),e(Ike,ypt),e(Z7,xpt),e(Z7,$le),e($le,$pt),e(Z7,kpt),e(te,Spt),e(te,K7),e(K7,Nke),e(Nke,Rpt),e(K7,Ppt),e(K7,kle),e(kle,Bpt),e(K7,Ipt),e(te,Npt),e(te,e8),e(e8,qke),e(qke,qpt),e(e8,Dpt),e(e8,Sle),e(Sle,jpt),e(e8,Gpt),e(te,Opt),e(te,o8),e(o8,Dke),e(Dke,Vpt),e(o8,Xpt),e(o8,Rle),e(Rle,zpt),e(o8,Qpt),e(te,Wpt),e(te,r8),e(r8,jke),e(jke,Upt),e(r8,Hpt),e(r8,Ple),e(Ple,Jpt),e(r8,Ypt),e(te,Zpt),e(te,t8),e(t8,Gke),e(Gke,Kpt),e(t8,e_t),e(t8,Ble),e(Ble,o_t),e(t8,r_t),e(te,t_t),e(te,a8),e(a8,Oke),e(Oke,a_t),e(a8,n_t),e(a8,Ile),e(Ile,s_t),e(a8,l_t),e(te,i_t),e(te,n8),e(n8,Vke),e(Vke,d_t),e(n8,m_t),e(n8,Nle),e(Nle,c_t),e(n8,f_t),e(te,g_t),e(te,s8),e(s8,Xke),e(Xke,h_t),e(s8,u_t),e(s8,qle),e(qle,p_t),e(s8,__t),e(te,b_t),e(te,l8),e(l8,zke),e(zke,v_t),e(l8,F_t),e(l8,Dle),e(Dle,T_t),e(l8,M_t),e(te,E_t),e(te,i8),e(i8,Qke),e(Qke,C_t),e(i8,w_t),e(i8,jle),e(jle,A_t),e(i8,L_t),e(te,y_t),e(te,d8),e(d8,Wke),e(Wke,x_t),e(d8,$_t),e(d8,Gle),e(Gle,k_t),e(d8,S_t),e(te,R_t),e(te,m8),e(m8,Uke),e(Uke,P_t),e(m8,B_t),e(m8,Ole),e(Ole,I_t),e(m8,N_t),e(te,q_t),e(te,c8),e(c8,Hke),e(Hke,D_t),e(c8,j_t),e(c8,Vle),e(Vle,G_t),e(c8,O_t),e(te,V_t),e(te,f8),e(f8,Jke),e(Jke,X_t),e(f8,z_t),e(f8,Xle),e(Xle,Q_t),e(f8,W_t),e(te,U_t),e(te,g8),e(g8,Yke),e(Yke,H_t),e(g8,J_t),e(g8,zle),e(zle,Y_t),e(g8,Z_t),e(te,K_t),e(te,h8),e(h8,Zke),e(Zke,e1t),e(h8,o1t),e(h8,Qle),e(Qle,r1t),e(h8,t1t),e(rt,a1t),M(u8,rt,null),b(c,vno,_),b(c,lf,_),e(lf,p8),e(p8,Kke),M(WP,Kke,null),e(lf,n1t),e(lf,eSe),e(eSe,s1t),b(c,Fno,_),b(c,Lr,_),M(UP,Lr,null),e(Lr,l1t),e(Lr,df),e(df,i1t),e(df,Wle),e(Wle,d1t),e(df,m1t),e(df,Ule),e(Ule,c1t),e(df,f1t),e(Lr,g1t),e(Lr,HP),e(HP,h1t),e(HP,oSe),e(oSe,u1t),e(HP,p1t),e(Lr,_1t),e(Lr,ha),M(JP,ha,null),e(ha,b1t),e(ha,rSe),e(rSe,v1t),e(ha,F1t),e(ha,mf),e(mf,T1t),e(mf,tSe),e(tSe,M1t),e(mf,E1t),e(mf,Hle),e(Hle,C1t),e(mf,w1t),e(ha,A1t),M(_8,ha,null),e(Lr,L1t),e(Lr,tt),M(YP,tt,null),e(tt,y1t),e(tt,aSe),e(aSe,x1t),e(tt,$1t),e(tt,Zn),e(Zn,k1t),e(Zn,nSe),e(nSe,S1t),e(Zn,R1t),e(Zn,sSe),e(sSe,P1t),e(Zn,B1t),e(Zn,lSe),e(lSe,I1t),e(Zn,N1t),e(tt,q1t),e(tt,$e),e($e,b8),e(b8,iSe),e(iSe,D1t),e(b8,j1t),e(b8,Jle),e(Jle,G1t),e(b8,O1t),e($e,V1t),e($e,v8),e(v8,dSe),e(dSe,X1t),e(v8,z1t),e(v8,Yle),e(Yle,Q1t),e(v8,W1t),e($e,U1t),e($e,F8),e(F8,mSe),e(mSe,H1t),e(F8,J1t),e(F8,Zle),e(Zle,Y1t),e(F8,Z1t),e($e,K1t),e($e,T8),e(T8,cSe),e(cSe,e2t),e(T8,o2t),e(T8,Kle),e(Kle,r2t),e(T8,t2t),e($e,a2t),e($e,M8),e(M8,fSe),e(fSe,n2t),e(M8,s2t),e(M8,eie),e(eie,l2t),e(M8,i2t),e($e,d2t),e($e,E8),e(E8,gSe),e(gSe,m2t),e(E8,c2t),e(E8,oie),e(oie,f2t),e(E8,g2t),e($e,h2t),e($e,C8),e(C8,hSe),e(hSe,u2t),e(C8,p2t),e(C8,rie),e(rie,_2t),e(C8,b2t),e($e,v2t),e($e,w8),e(w8,uSe),e(uSe,F2t),e(w8,T2t),e(w8,tie),e(tie,M2t),e(w8,E2t),e($e,C2t),e($e,A8),e(A8,pSe),e(pSe,w2t),e(A8,A2t),e(A8,aie),e(aie,L2t),e(A8,y2t),e($e,x2t),e($e,L8),e(L8,_Se),e(_Se,$2t),e(L8,k2t),e(L8,nie),e(nie,S2t),e(L8,R2t),e(tt,P2t),M(y8,tt,null),b(c,Tno,_),b(c,cf,_),e(cf,x8),e(x8,bSe),M(ZP,bSe,null),e(cf,B2t),e(cf,vSe),e(vSe,I2t),b(c,Mno,_),b(c,yr,_),M(KP,yr,null),e(yr,N2t),e(yr,ff),e(ff,q2t),e(ff,sie),e(sie,D2t),e(ff,j2t),e(ff,lie),e(lie,G2t),e(ff,O2t),e(yr,V2t),e(yr,eB),e(eB,X2t),e(eB,FSe),e(FSe,z2t),e(eB,Q2t),e(yr,W2t),e(yr,ua),M(oB,ua,null),e(ua,U2t),e(ua,TSe),e(TSe,H2t),e(ua,J2t),e(ua,gf),e(gf,Y2t),e(gf,MSe),e(MSe,Z2t),e(gf,K2t),e(gf,iie),e(iie,ebt),e(gf,obt),e(ua,rbt),M($8,ua,null),e(yr,tbt),e(yr,at),M(rB,at,null),e(at,abt),e(at,ESe),e(ESe,nbt),e(at,sbt),e(at,Kn),e(Kn,lbt),e(Kn,CSe),e(CSe,ibt),e(Kn,dbt),e(Kn,wSe),e(wSe,mbt),e(Kn,cbt),e(Kn,ASe),e(ASe,fbt),e(Kn,gbt),e(at,hbt),e(at,Ee),e(Ee,k8),e(k8,LSe),e(LSe,ubt),e(k8,pbt),e(k8,die),e(die,_bt),e(k8,bbt),e(Ee,vbt),e(Ee,S8),e(S8,ySe),e(ySe,Fbt),e(S8,Tbt),e(S8,mie),e(mie,Mbt),e(S8,Ebt),e(Ee,Cbt),e(Ee,R8),e(R8,xSe),e(xSe,wbt),e(R8,Abt),e(R8,cie),e(cie,Lbt),e(R8,ybt),e(Ee,xbt),e(Ee,P8),e(P8,$Se),e($Se,$bt),e(P8,kbt),e(P8,fie),e(fie,Sbt),e(P8,Rbt),e(Ee,Pbt),e(Ee,B8),e(B8,kSe),e(kSe,Bbt),e(B8,Ibt),e(B8,gie),e(gie,Nbt),e(B8,qbt),e(Ee,Dbt),e(Ee,I8),e(I8,SSe),e(SSe,jbt),e(I8,Gbt),e(I8,hie),e(hie,Obt),e(I8,Vbt),e(Ee,Xbt),e(Ee,N8),e(N8,RSe),e(RSe,zbt),e(N8,Qbt),e(N8,uie),e(uie,Wbt),e(N8,Ubt),e(Ee,Hbt),e(Ee,q8),e(q8,PSe),e(PSe,Jbt),e(q8,Ybt),e(q8,pie),e(pie,Zbt),e(q8,Kbt),e(Ee,evt),e(Ee,D8),e(D8,BSe),e(BSe,ovt),e(D8,rvt),e(D8,_ie),e(_ie,tvt),e(D8,avt),e(Ee,nvt),e(Ee,j8),e(j8,ISe),e(ISe,svt),e(j8,lvt),e(j8,bie),e(bie,ivt),e(j8,dvt),e(Ee,mvt),e(Ee,G8),e(G8,NSe),e(NSe,cvt),e(G8,fvt),e(G8,vie),e(vie,gvt),e(G8,hvt),e(Ee,uvt),e(Ee,O8),e(O8,qSe),e(qSe,pvt),e(O8,_vt),e(O8,Fie),e(Fie,bvt),e(O8,vvt),e(Ee,Fvt),e(Ee,V8),e(V8,DSe),e(DSe,Tvt),e(V8,Mvt),e(V8,Tie),e(Tie,Evt),e(V8,Cvt),e(at,wvt),M(X8,at,null),b(c,Eno,_),b(c,hf,_),e(hf,z8),e(z8,jSe),M(tB,jSe,null),e(hf,Avt),e(hf,GSe),e(GSe,Lvt),b(c,Cno,_),b(c,xr,_),M(aB,xr,null),e(xr,yvt),e(xr,uf),e(uf,xvt),e(uf,Mie),e(Mie,$vt),e(uf,kvt),e(uf,Eie),e(Eie,Svt),e(uf,Rvt),e(xr,Pvt),e(xr,nB),e(nB,Bvt),e(nB,OSe),e(OSe,Ivt),e(nB,Nvt),e(xr,qvt),e(xr,pa),M(sB,pa,null),e(pa,Dvt),e(pa,VSe),e(VSe,jvt),e(pa,Gvt),e(pa,pf),e(pf,Ovt),e(pf,XSe),e(XSe,Vvt),e(pf,Xvt),e(pf,Cie),e(Cie,zvt),e(pf,Qvt),e(pa,Wvt),M(Q8,pa,null),e(xr,Uvt),e(xr,nt),M(lB,nt,null),e(nt,Hvt),e(nt,zSe),e(zSe,Jvt),e(nt,Yvt),e(nt,es),e(es,Zvt),e(es,QSe),e(QSe,Kvt),e(es,eFt),e(es,WSe),e(WSe,oFt),e(es,rFt),e(es,USe),e(USe,tFt),e(es,aFt),e(nt,nFt),e(nt,ke),e(ke,W8),e(W8,HSe),e(HSe,sFt),e(W8,lFt),e(W8,wie),e(wie,iFt),e(W8,dFt),e(ke,mFt),e(ke,U8),e(U8,JSe),e(JSe,cFt),e(U8,fFt),e(U8,Aie),e(Aie,gFt),e(U8,hFt),e(ke,uFt),e(ke,H8),e(H8,YSe),e(YSe,pFt),e(H8,_Ft),e(H8,Lie),e(Lie,bFt),e(H8,vFt),e(ke,FFt),e(ke,J8),e(J8,ZSe),e(ZSe,TFt),e(J8,MFt),e(J8,yie),e(yie,EFt),e(J8,CFt),e(ke,wFt),e(ke,Y8),e(Y8,KSe),e(KSe,AFt),e(Y8,LFt),e(Y8,xie),e(xie,yFt),e(Y8,xFt),e(ke,$Ft),e(ke,Z8),e(Z8,eRe),e(eRe,kFt),e(Z8,SFt),e(Z8,$ie),e($ie,RFt),e(Z8,PFt),e(ke,BFt),e(ke,K8),e(K8,oRe),e(oRe,IFt),e(K8,NFt),e(K8,kie),e(kie,qFt),e(K8,DFt),e(ke,jFt),e(ke,eL),e(eL,rRe),e(rRe,GFt),e(eL,OFt),e(eL,Sie),e(Sie,VFt),e(eL,XFt),e(ke,zFt),e(ke,oL),e(oL,tRe),e(tRe,QFt),e(oL,WFt),e(oL,Rie),e(Rie,UFt),e(oL,HFt),e(ke,JFt),e(ke,rL),e(rL,aRe),e(aRe,YFt),e(rL,ZFt),e(rL,Pie),e(Pie,KFt),e(rL,eTt),e(nt,oTt),M(tL,nt,null),b(c,wno,_),b(c,_f,_),e(_f,aL),e(aL,nRe),M(iB,nRe,null),e(_f,rTt),e(_f,sRe),e(sRe,tTt),b(c,Ano,_),b(c,$r,_),M(dB,$r,null),e($r,aTt),e($r,bf),e(bf,nTt),e(bf,Bie),e(Bie,sTt),e(bf,lTt),e(bf,Iie),e(Iie,iTt),e(bf,dTt),e($r,mTt),e($r,mB),e(mB,cTt),e(mB,lRe),e(lRe,fTt),e(mB,gTt),e($r,hTt),e($r,_a),M(cB,_a,null),e(_a,uTt),e(_a,iRe),e(iRe,pTt),e(_a,_Tt),e(_a,vf),e(vf,bTt),e(vf,dRe),e(dRe,vTt),e(vf,FTt),e(vf,Nie),e(Nie,TTt),e(vf,MTt),e(_a,ETt),M(nL,_a,null),e($r,CTt),e($r,st),M(fB,st,null),e(st,wTt),e(st,mRe),e(mRe,ATt),e(st,LTt),e(st,os),e(os,yTt),e(os,cRe),e(cRe,xTt),e(os,$Tt),e(os,fRe),e(fRe,kTt),e(os,STt),e(os,gRe),e(gRe,RTt),e(os,PTt),e(st,BTt),e(st,Se),e(Se,sL),e(sL,hRe),e(hRe,ITt),e(sL,NTt),e(sL,qie),e(qie,qTt),e(sL,DTt),e(Se,jTt),e(Se,lL),e(lL,uRe),e(uRe,GTt),e(lL,OTt),e(lL,Die),e(Die,VTt),e(lL,XTt),e(Se,zTt),e(Se,iL),e(iL,pRe),e(pRe,QTt),e(iL,WTt),e(iL,jie),e(jie,UTt),e(iL,HTt),e(Se,JTt),e(Se,dL),e(dL,_Re),e(_Re,YTt),e(dL,ZTt),e(dL,Gie),e(Gie,KTt),e(dL,eMt),e(Se,oMt),e(Se,mL),e(mL,bRe),e(bRe,rMt),e(mL,tMt),e(mL,Oie),e(Oie,aMt),e(mL,nMt),e(Se,sMt),e(Se,cL),e(cL,vRe),e(vRe,lMt),e(cL,iMt),e(cL,Vie),e(Vie,dMt),e(cL,mMt),e(Se,cMt),e(Se,fL),e(fL,FRe),e(FRe,fMt),e(fL,gMt),e(fL,Xie),e(Xie,hMt),e(fL,uMt),e(Se,pMt),e(Se,gL),e(gL,TRe),e(TRe,_Mt),e(gL,bMt),e(gL,zie),e(zie,vMt),e(gL,FMt),e(Se,TMt),e(Se,hL),e(hL,MRe),e(MRe,MMt),e(hL,EMt),e(hL,Qie),e(Qie,CMt),e(hL,wMt),e(Se,AMt),e(Se,uL),e(uL,ERe),e(ERe,LMt),e(uL,yMt),e(uL,Wie),e(Wie,xMt),e(uL,$Mt),e(st,kMt),M(pL,st,null),b(c,Lno,_),b(c,Ff,_),e(Ff,_L),e(_L,CRe),M(gB,CRe,null),e(Ff,SMt),e(Ff,wRe),e(wRe,RMt),b(c,yno,_),b(c,kr,_),M(hB,kr,null),e(kr,PMt),e(kr,Tf),e(Tf,BMt),e(Tf,Uie),e(Uie,IMt),e(Tf,NMt),e(Tf,Hie),e(Hie,qMt),e(Tf,DMt),e(kr,jMt),e(kr,uB),e(uB,GMt),e(uB,ARe),e(ARe,OMt),e(uB,VMt),e(kr,XMt),e(kr,ba),M(pB,ba,null),e(ba,zMt),e(ba,LRe),e(LRe,QMt),e(ba,WMt),e(ba,Mf),e(Mf,UMt),e(Mf,yRe),e(yRe,HMt),e(Mf,JMt),e(Mf,Jie),e(Jie,YMt),e(Mf,ZMt),e(ba,KMt),M(bL,ba,null),e(kr,eEt),e(kr,lt),M(_B,lt,null),e(lt,oEt),e(lt,xRe),e(xRe,rEt),e(lt,tEt),e(lt,rs),e(rs,aEt),e(rs,$Re),e($Re,nEt),e(rs,sEt),e(rs,kRe),e(kRe,lEt),e(rs,iEt),e(rs,SRe),e(SRe,dEt),e(rs,mEt),e(lt,cEt),e(lt,Re),e(Re,vL),e(vL,RRe),e(RRe,fEt),e(vL,gEt),e(vL,Yie),e(Yie,hEt),e(vL,uEt),e(Re,pEt),e(Re,FL),e(FL,PRe),e(PRe,_Et),e(FL,bEt),e(FL,Zie),e(Zie,vEt),e(FL,FEt),e(Re,TEt),e(Re,TL),e(TL,BRe),e(BRe,MEt),e(TL,EEt),e(TL,Kie),e(Kie,CEt),e(TL,wEt),e(Re,AEt),e(Re,ML),e(ML,IRe),e(IRe,LEt),e(ML,yEt),e(ML,ede),e(ede,xEt),e(ML,$Et),e(Re,kEt),e(Re,EL),e(EL,NRe),e(NRe,SEt),e(EL,REt),e(EL,ode),e(ode,PEt),e(EL,BEt),e(Re,IEt),e(Re,CL),e(CL,qRe),e(qRe,NEt),e(CL,qEt),e(CL,rde),e(rde,DEt),e(CL,jEt),e(Re,GEt),e(Re,wL),e(wL,DRe),e(DRe,OEt),e(wL,VEt),e(wL,tde),e(tde,XEt),e(wL,zEt),e(Re,QEt),e(Re,AL),e(AL,jRe),e(jRe,WEt),e(AL,UEt),e(AL,ade),e(ade,HEt),e(AL,JEt),e(Re,YEt),e(Re,LL),e(LL,GRe),e(GRe,ZEt),e(LL,KEt),e(LL,nde),e(nde,e4t),e(LL,o4t),e(Re,r4t),e(Re,yL),e(yL,ORe),e(ORe,t4t),e(yL,a4t),e(yL,sde),e(sde,n4t),e(yL,s4t),e(lt,l4t),M(xL,lt,null),b(c,xno,_),b(c,Ef,_),e(Ef,$L),e($L,VRe),M(bB,VRe,null),e(Ef,i4t),e(Ef,XRe),e(XRe,d4t),b(c,$no,_),b(c,Sr,_),M(vB,Sr,null),e(Sr,m4t),e(Sr,Cf),e(Cf,c4t),e(Cf,lde),e(lde,f4t),e(Cf,g4t),e(Cf,ide),e(ide,h4t),e(Cf,u4t),e(Sr,p4t),e(Sr,FB),e(FB,_4t),e(FB,zRe),e(zRe,b4t),e(FB,v4t),e(Sr,F4t),e(Sr,va),M(TB,va,null),e(va,T4t),e(va,QRe),e(QRe,M4t),e(va,E4t),e(va,wf),e(wf,C4t),e(wf,WRe),e(WRe,w4t),e(wf,A4t),e(wf,dde),e(dde,L4t),e(wf,y4t),e(va,x4t),M(kL,va,null),e(Sr,$4t),e(Sr,it),M(MB,it,null),e(it,k4t),e(it,URe),e(URe,S4t),e(it,R4t),e(it,ts),e(ts,P4t),e(ts,HRe),e(HRe,B4t),e(ts,I4t),e(ts,JRe),e(JRe,N4t),e(ts,q4t),e(ts,YRe),e(YRe,D4t),e(ts,j4t),e(it,G4t),e(it,Pe),e(Pe,SL),e(SL,ZRe),e(ZRe,O4t),e(SL,V4t),e(SL,mde),e(mde,X4t),e(SL,z4t),e(Pe,Q4t),e(Pe,RL),e(RL,KRe),e(KRe,W4t),e(RL,U4t),e(RL,cde),e(cde,H4t),e(RL,J4t),e(Pe,Y4t),e(Pe,PL),e(PL,ePe),e(ePe,Z4t),e(PL,K4t),e(PL,fde),e(fde,eCt),e(PL,oCt),e(Pe,rCt),e(Pe,BL),e(BL,oPe),e(oPe,tCt),e(BL,aCt),e(BL,gde),e(gde,nCt),e(BL,sCt),e(Pe,lCt),e(Pe,IL),e(IL,rPe),e(rPe,iCt),e(IL,dCt),e(IL,hde),e(hde,mCt),e(IL,cCt),e(Pe,fCt),e(Pe,NL),e(NL,tPe),e(tPe,gCt),e(NL,hCt),e(NL,ude),e(ude,uCt),e(NL,pCt),e(Pe,_Ct),e(Pe,qL),e(qL,aPe),e(aPe,bCt),e(qL,vCt),e(qL,pde),e(pde,FCt),e(qL,TCt),e(Pe,MCt),e(Pe,DL),e(DL,nPe),e(nPe,ECt),e(DL,CCt),e(DL,_de),e(_de,wCt),e(DL,ACt),e(Pe,LCt),e(Pe,jL),e(jL,sPe),e(sPe,yCt),e(jL,xCt),e(jL,bde),e(bde,$Ct),e(jL,kCt),e(Pe,SCt),e(Pe,GL),e(GL,lPe),e(lPe,RCt),e(GL,PCt),e(GL,vde),e(vde,BCt),e(GL,ICt),e(it,NCt),M(OL,it,null),b(c,kno,_),b(c,Af,_),e(Af,VL),e(VL,iPe),M(EB,iPe,null),e(Af,qCt),e(Af,dPe),e(dPe,DCt),b(c,Sno,_),b(c,Rr,_),M(CB,Rr,null),e(Rr,jCt),e(Rr,Lf),e(Lf,GCt),e(Lf,Fde),e(Fde,OCt),e(Lf,VCt),e(Lf,Tde),e(Tde,XCt),e(Lf,zCt),e(Rr,QCt),e(Rr,wB),e(wB,WCt),e(wB,mPe),e(mPe,UCt),e(wB,HCt),e(Rr,JCt),e(Rr,Fa),M(AB,Fa,null),e(Fa,YCt),e(Fa,cPe),e(cPe,ZCt),e(Fa,KCt),e(Fa,yf),e(yf,e3t),e(yf,fPe),e(fPe,o3t),e(yf,r3t),e(yf,Mde),e(Mde,t3t),e(yf,a3t),e(Fa,n3t),M(XL,Fa,null),e(Rr,s3t),e(Rr,dt),M(LB,dt,null),e(dt,l3t),e(dt,gPe),e(gPe,i3t),e(dt,d3t),e(dt,as),e(as,m3t),e(as,hPe),e(hPe,c3t),e(as,f3t),e(as,uPe),e(uPe,g3t),e(as,h3t),e(as,pPe),e(pPe,u3t),e(as,p3t),e(dt,_3t),e(dt,ze),e(ze,zL),e(zL,_Pe),e(_Pe,b3t),e(zL,v3t),e(zL,Ede),e(Ede,F3t),e(zL,T3t),e(ze,M3t),e(ze,QL),e(QL,bPe),e(bPe,E3t),e(QL,C3t),e(QL,Cde),e(Cde,w3t),e(QL,A3t),e(ze,L3t),e(ze,WL),e(WL,vPe),e(vPe,y3t),e(WL,x3t),e(WL,wde),e(wde,$3t),e(WL,k3t),e(ze,S3t),e(ze,UL),e(UL,FPe),e(FPe,R3t),e(UL,P3t),e(UL,Ade),e(Ade,B3t),e(UL,I3t),e(ze,N3t),e(ze,HL),e(HL,TPe),e(TPe,q3t),e(HL,D3t),e(HL,Lde),e(Lde,j3t),e(HL,G3t),e(ze,O3t),e(ze,JL),e(JL,MPe),e(MPe,V3t),e(JL,X3t),e(JL,yde),e(yde,z3t),e(JL,Q3t),e(ze,W3t),e(ze,YL),e(YL,EPe),e(EPe,U3t),e(YL,H3t),e(YL,xde),e(xde,J3t),e(YL,Y3t),e(ze,Z3t),e(ze,ZL),e(ZL,CPe),e(CPe,K3t),e(ZL,e5t),e(ZL,$de),e($de,o5t),e(ZL,r5t),e(dt,t5t),M(KL,dt,null),b(c,Rno,_),b(c,xf,_),e(xf,ey),e(ey,wPe),M(yB,wPe,null),e(xf,a5t),e(xf,APe),e(APe,n5t),b(c,Pno,_),b(c,Pr,_),M(xB,Pr,null),e(Pr,s5t),e(Pr,$f),e($f,l5t),e($f,kde),e(kde,i5t),e($f,d5t),e($f,Sde),e(Sde,m5t),e($f,c5t),e(Pr,f5t),e(Pr,$B),e($B,g5t),e($B,LPe),e(LPe,h5t),e($B,u5t),e(Pr,p5t),e(Pr,Ta),M(kB,Ta,null),e(Ta,_5t),e(Ta,yPe),e(yPe,b5t),e(Ta,v5t),e(Ta,kf),e(kf,F5t),e(kf,xPe),e(xPe,T5t),e(kf,M5t),e(kf,Rde),e(Rde,E5t),e(kf,C5t),e(Ta,w5t),M(oy,Ta,null),e(Pr,A5t),e(Pr,mt),M(SB,mt,null),e(mt,L5t),e(mt,$Pe),e($Pe,y5t),e(mt,x5t),e(mt,ns),e(ns,$5t),e(ns,kPe),e(kPe,k5t),e(ns,S5t),e(ns,SPe),e(SPe,R5t),e(ns,P5t),e(ns,RPe),e(RPe,B5t),e(ns,I5t),e(mt,N5t),e(mt,Qe),e(Qe,ry),e(ry,PPe),e(PPe,q5t),e(ry,D5t),e(ry,Pde),e(Pde,j5t),e(ry,G5t),e(Qe,O5t),e(Qe,ty),e(ty,BPe),e(BPe,V5t),e(ty,X5t),e(ty,Bde),e(Bde,z5t),e(ty,Q5t),e(Qe,W5t),e(Qe,ay),e(ay,IPe),e(IPe,U5t),e(ay,H5t),e(ay,Ide),e(Ide,J5t),e(ay,Y5t),e(Qe,Z5t),e(Qe,ny),e(ny,NPe),e(NPe,K5t),e(ny,e0t),e(ny,Nde),e(Nde,o0t),e(ny,r0t),e(Qe,t0t),e(Qe,sy),e(sy,qPe),e(qPe,a0t),e(sy,n0t),e(sy,qde),e(qde,s0t),e(sy,l0t),e(Qe,i0t),e(Qe,ly),e(ly,DPe),e(DPe,d0t),e(ly,m0t),e(ly,Dde),e(Dde,c0t),e(ly,f0t),e(Qe,g0t),e(Qe,iy),e(iy,jPe),e(jPe,h0t),e(iy,u0t),e(iy,jde),e(jde,p0t),e(iy,_0t),e(Qe,b0t),e(Qe,dy),e(dy,GPe),e(GPe,v0t),e(dy,F0t),e(dy,Gde),e(Gde,T0t),e(dy,M0t),e(mt,E0t),M(my,mt,null),b(c,Bno,_),b(c,Sf,_),e(Sf,cy),e(cy,OPe),M(RB,OPe,null),e(Sf,C0t),e(Sf,VPe),e(VPe,w0t),b(c,Ino,_),b(c,Br,_),M(PB,Br,null),e(Br,A0t),e(Br,Rf),e(Rf,L0t),e(Rf,Ode),e(Ode,y0t),e(Rf,x0t),e(Rf,Vde),e(Vde,$0t),e(Rf,k0t),e(Br,S0t),e(Br,BB),e(BB,R0t),e(BB,XPe),e(XPe,P0t),e(BB,B0t),e(Br,I0t),e(Br,Ma),M(IB,Ma,null),e(Ma,N0t),e(Ma,zPe),e(zPe,q0t),e(Ma,D0t),e(Ma,Pf),e(Pf,j0t),e(Pf,QPe),e(QPe,G0t),e(Pf,O0t),e(Pf,Xde),e(Xde,V0t),e(Pf,X0t),e(Ma,z0t),M(fy,Ma,null),e(Br,Q0t),e(Br,ct),M(NB,ct,null),e(ct,W0t),e(ct,WPe),e(WPe,U0t),e(ct,H0t),e(ct,ss),e(ss,J0t),e(ss,UPe),e(UPe,Y0t),e(ss,Z0t),e(ss,HPe),e(HPe,K0t),e(ss,ewt),e(ss,JPe),e(JPe,owt),e(ss,rwt),e(ct,twt),e(ct,YPe),e(YPe,gy),e(gy,ZPe),e(ZPe,awt),e(gy,nwt),e(gy,zde),e(zde,swt),e(gy,lwt),e(ct,iwt),M(hy,ct,null),b(c,Nno,_),b(c,Bf,_),e(Bf,uy),e(uy,KPe),M(qB,KPe,null),e(Bf,dwt),e(Bf,eBe),e(eBe,mwt),b(c,qno,_),b(c,Ir,_),M(DB,Ir,null),e(Ir,cwt),e(Ir,If),e(If,fwt),e(If,Qde),e(Qde,gwt),e(If,hwt),e(If,Wde),e(Wde,uwt),e(If,pwt),e(Ir,_wt),e(Ir,jB),e(jB,bwt),e(jB,oBe),e(oBe,vwt),e(jB,Fwt),e(Ir,Twt),e(Ir,Ea),M(GB,Ea,null),e(Ea,Mwt),e(Ea,rBe),e(rBe,Ewt),e(Ea,Cwt),e(Ea,Nf),e(Nf,wwt),e(Nf,tBe),e(tBe,Awt),e(Nf,Lwt),e(Nf,Ude),e(Ude,ywt),e(Nf,xwt),e(Ea,$wt),M(py,Ea,null),e(Ir,kwt),e(Ir,ft),M(OB,ft,null),e(ft,Swt),e(ft,aBe),e(aBe,Rwt),e(ft,Pwt),e(ft,ls),e(ls,Bwt),e(ls,nBe),e(nBe,Iwt),e(ls,Nwt),e(ls,sBe),e(sBe,qwt),e(ls,Dwt),e(ls,lBe),e(lBe,jwt),e(ls,Gwt),e(ft,Owt),e(ft,VB),e(VB,_y),e(_y,iBe),e(iBe,Vwt),e(_y,Xwt),e(_y,Hde),e(Hde,zwt),e(_y,Qwt),e(VB,Wwt),e(VB,by),e(by,dBe),e(dBe,Uwt),e(by,Hwt),e(by,Jde),e(Jde,Jwt),e(by,Ywt),e(ft,Zwt),M(vy,ft,null),b(c,Dno,_),b(c,qf,_),e(qf,Fy),e(Fy,mBe),M(XB,mBe,null),e(qf,Kwt),e(qf,cBe),e(cBe,eAt),b(c,jno,_),b(c,Nr,_),M(zB,Nr,null),e(Nr,oAt),e(Nr,Df),e(Df,rAt),e(Df,Yde),e(Yde,tAt),e(Df,aAt),e(Df,Zde),e(Zde,nAt),e(Df,sAt),e(Nr,lAt),e(Nr,QB),e(QB,iAt),e(QB,fBe),e(fBe,dAt),e(QB,mAt),e(Nr,cAt),e(Nr,Ca),M(WB,Ca,null),e(Ca,fAt),e(Ca,gBe),e(gBe,gAt),e(Ca,hAt),e(Ca,jf),e(jf,uAt),e(jf,hBe),e(hBe,pAt),e(jf,_At),e(jf,Kde),e(Kde,bAt),e(jf,vAt),e(Ca,FAt),M(Ty,Ca,null),e(Nr,TAt),e(Nr,gt),M(UB,gt,null),e(gt,MAt),e(gt,uBe),e(uBe,EAt),e(gt,CAt),e(gt,is),e(is,wAt),e(is,pBe),e(pBe,AAt),e(is,LAt),e(is,_Be),e(_Be,yAt),e(is,xAt),e(is,bBe),e(bBe,$At),e(is,kAt),e(gt,SAt),e(gt,vBe),e(vBe,My),e(My,FBe),e(FBe,RAt),e(My,PAt),e(My,eme),e(eme,BAt),e(My,IAt),e(gt,NAt),M(Ey,gt,null),Gno=!0},p(c,[_]){const HB={};_&2&&(HB.$$scope={dirty:_,ctx:c}),Hf.$set(HB);const TBe={};_&2&&(TBe.$$scope={dirty:_,ctx:c}),Cu.$set(TBe);const MBe={};_&2&&(MBe.$$scope={dirty:_,ctx:c}),dp.$set(MBe);const EBe={};_&2&&(EBe.$$scope={dirty:_,ctx:c}),r_.$set(EBe);const JB={};_&2&&(JB.$$scope={dirty:_,ctx:c}),t_.$set(JB);const CBe={};_&2&&(CBe.$$scope={dirty:_,ctx:c}),x_.$set(CBe);const ds={};_&2&&(ds.$$scope={dirty:_,ctx:c}),$_.$set(ds);const wBe={};_&2&&(wBe.$$scope={dirty:_,ctx:c}),R_.$set(wBe);const ABe={};_&2&&(ABe.$$scope={dirty:_,ctx:c}),ob.$set(ABe);const LBe={};_&2&&(LBe.$$scope={dirty:_,ctx:c}),tb.$set(LBe);const YB={};_&2&&(YB.$$scope={dirty:_,ctx:c}),Kb.$set(YB);const yBe={};_&2&&(yBe.$$scope={dirty:_,ctx:c}),ov.$set(yBe);const ZB={};_&2&&(ZB.$$scope={dirty:_,ctx:c}),zv.$set(ZB);const xBe={};_&2&&(xBe.$$scope={dirty:_,ctx:c}),Wv.$set(xBe);const KB={};_&2&&(KB.$$scope={dirty:_,ctx:c}),Yv.$set(KB);const $Be={};_&2&&($Be.$$scope={dirty:_,ctx:c}),Kv.$set($Be);const kBe={};_&2&&(kBe.$$scope={dirty:_,ctx:c}),jF.$set(kBe);const SBe={};_&2&&(SBe.$$scope={dirty:_,ctx:c}),OF.$set(SBe);const Gf={};_&2&&(Gf.$$scope={dirty:_,ctx:c}),mT.$set(Gf);const RBe={};_&2&&(RBe.$$scope={dirty:_,ctx:c}),fT.$set(RBe);const PBe={};_&2&&(PBe.$$scope={dirty:_,ctx:c}),pM.$set(PBe);const BBe={};_&2&&(BBe.$$scope={dirty:_,ctx:c}),bM.$set(BBe);const eI={};_&2&&(eI.$$scope={dirty:_,ctx:c}),ZM.$set(eI);const IBe={};_&2&&(IBe.$$scope={dirty:_,ctx:c}),eE.$set(IBe);const NBe={};_&2&&(NBe.$$scope={dirty:_,ctx:c}),dE.$set(NBe);const qBe={};_&2&&(qBe.$$scope={dirty:_,ctx:c}),cE.$set(qBe);const vt={};_&2&&(vt.$$scope={dirty:_,ctx:c}),e4.$set(vt);const oI={};_&2&&(oI.$$scope={dirty:_,ctx:c}),r4.$set(oI);const DBe={};_&2&&(DBe.$$scope={dirty:_,ctx:c}),Z4.$set(DBe);const rI={};_&2&&(rI.$$scope={dirty:_,ctx:c}),eC.$set(rI);const jBe={};_&2&&(jBe.$$scope={dirty:_,ctx:c}),tC.$set(jBe);const Ft={};_&2&&(Ft.$$scope={dirty:_,ctx:c}),nC.$set(Ft);const GBe={};_&2&&(GBe.$$scope={dirty:_,ctx:c}),mC.$set(GBe);const Of={};_&2&&(Of.$$scope={dirty:_,ctx:c}),fC.$set(Of);const OBe={};_&2&&(OBe.$$scope={dirty:_,ctx:c}),xC.$set(OBe);const VBe={};_&2&&(VBe.$$scope={dirty:_,ctx:c}),kC.$set(VBe);const L={};_&2&&(L.$$scope={dirty:_,ctx:c}),PC.$set(L);const Cy={};_&2&&(Cy.$$scope={dirty:_,ctx:c}),IC.$set(Cy);const XBe={};_&2&&(XBe.$$scope={dirty:_,ctx:c}),DC.$set(XBe);const zBe={};_&2&&(zBe.$$scope={dirty:_,ctx:c}),GC.$set(zBe);const wy={};_&2&&(wy.$$scope={dirty:_,ctx:c}),XC.$set(wy);const QBe={};_&2&&(QBe.$$scope={dirty:_,ctx:c}),QC.$set(QBe);const WBe={};_&2&&(WBe.$$scope={dirty:_,ctx:c}),t3.$set(WBe);const Ay={};_&2&&(Ay.$$scope={dirty:_,ctx:c}),n3.$set(Ay);const UBe={};_&2&&(UBe.$$scope={dirty:_,ctx:c}),f3.$set(UBe);const HBe={};_&2&&(HBe.$$scope={dirty:_,ctx:c}),h3.$set(HBe);const Ly={};_&2&&(Ly.$$scope={dirty:_,ctx:c}),A3.$set(Ly);const JBe={};_&2&&(JBe.$$scope={dirty:_,ctx:c}),y3.$set(JBe);const YBe={};_&2&&(YBe.$$scope={dirty:_,ctx:c}),R3.$set(YBe);const yy={};_&2&&(yy.$$scope={dirty:_,ctx:c}),B3.$set(yy);const ZBe={};_&2&&(ZBe.$$scope={dirty:_,ctx:c}),O3.$set(ZBe);const KBe={};_&2&&(KBe.$$scope={dirty:_,ctx:c}),X3.$set(KBe);const xy={};_&2&&(xy.$$scope={dirty:_,ctx:c}),J3.$set(xy);const eIe={};_&2&&(eIe.$$scope={dirty:_,ctx:c}),Z3.$set(eIe);const oIe={};_&2&&(oIe.$$scope={dirty:_,ctx:c}),n5.$set(oIe);const $y={};_&2&&($y.$$scope={dirty:_,ctx:c}),l5.$set($y);const rIe={};_&2&&(rIe.$$scope={dirty:_,ctx:c}),m5.$set(rIe);const tIe={};_&2&&(tIe.$$scope={dirty:_,ctx:c}),f5.$set(tIe);const ky={};_&2&&(ky.$$scope={dirty:_,ctx:c}),v5.$set(ky);const aIe={};_&2&&(aIe.$$scope={dirty:_,ctx:c}),T5.$set(aIe);const nIe={};_&2&&(nIe.$$scope={dirty:_,ctx:c}),C5.$set(nIe);const Sy={};_&2&&(Sy.$$scope={dirty:_,ctx:c}),A5.$set(Sy);const sIe={};_&2&&(sIe.$$scope={dirty:_,ctx:c}),x5.$set(sIe);const lIe={};_&2&&(lIe.$$scope={dirty:_,ctx:c}),k5.$set(lIe);const Ry={};_&2&&(Ry.$$scope={dirty:_,ctx:c}),B0.$set(Ry);const iIe={};_&2&&(iIe.$$scope={dirty:_,ctx:c}),N0.$set(iIe);const dIe={};_&2&&(dIe.$$scope={dirty:_,ctx:c}),lw.$set(dIe);const Py={};_&2&&(Py.$$scope={dirty:_,ctx:c}),dw.$set(Py);const mIe={};_&2&&(mIe.$$scope={dirty:_,ctx:c}),Cw.$set(mIe);const cIe={};_&2&&(cIe.$$scope={dirty:_,ctx:c}),Aw.$set(cIe);const By={};_&2&&(By.$$scope={dirty:_,ctx:c}),Iw.$set(By);const fIe={};_&2&&(fIe.$$scope={dirty:_,ctx:c}),qw.$set(fIe);const gIe={};_&2&&(gIe.$$scope={dirty:_,ctx:c}),Ow.$set(gIe);const Iy={};_&2&&(Iy.$$scope={dirty:_,ctx:c}),Xw.$set(Iy);const hIe={};_&2&&(hIe.$$scope={dirty:_,ctx:c}),fA.$set(hIe);const uIe={};_&2&&(uIe.$$scope={dirty:_,ctx:c}),hA.$set(uIe);const Ny={};_&2&&(Ny.$$scope={dirty:_,ctx:c}),wA.$set(Ny);const pIe={};_&2&&(pIe.$$scope={dirty:_,ctx:c}),LA.$set(pIe);const _Ie={};_&2&&(_Ie.$$scope={dirty:_,ctx:c}),r6.$set(_Ie);const qy={};_&2&&(qy.$$scope={dirty:_,ctx:c}),a6.$set(qy);const bIe={};_&2&&(bIe.$$scope={dirty:_,ctx:c}),M6.$set(bIe);const vIe={};_&2&&(vIe.$$scope={dirty:_,ctx:c}),C6.$set(vIe);const Dy={};_&2&&(Dy.$$scope={dirty:_,ctx:c}),L6.$set(Dy);const FIe={};_&2&&(FIe.$$scope={dirty:_,ctx:c}),x6.$set(FIe);const TIe={};_&2&&(TIe.$$scope={dirty:_,ctx:c}),k6.$set(TIe);const jy={};_&2&&(jy.$$scope={dirty:_,ctx:c}),R6.$set(jy);const MIe={};_&2&&(MIe.$$scope={dirty:_,ctx:c}),B6.$set(MIe);const EIe={};_&2&&(EIe.$$scope={dirty:_,ctx:c}),N6.$set(EIe);const Gy={};_&2&&(Gy.$$scope={dirty:_,ctx:c}),s7.$set(Gy);const CIe={};_&2&&(CIe.$$scope={dirty:_,ctx:c}),i7.$set(CIe);const wIe={};_&2&&(wIe.$$scope={dirty:_,ctx:c}),$7.$set(wIe);const Oy={};_&2&&(Oy.$$scope={dirty:_,ctx:c}),S7.$set(Oy);const AIe={};_&2&&(AIe.$$scope={dirty:_,ctx:c}),P7.$set(AIe);const LIe={};_&2&&(LIe.$$scope={dirty:_,ctx:c}),I7.$set(LIe);const Vy={};_&2&&(Vy.$$scope={dirty:_,ctx:c}),D7.$set(Vy);const yIe={};_&2&&(yIe.$$scope={dirty:_,ctx:c}),G7.$set(yIe);const xIe={};_&2&&(xIe.$$scope={dirty:_,ctx:c}),u8.$set(xIe);const Xy={};_&2&&(Xy.$$scope={dirty:_,ctx:c}),_8.$set(Xy);const $Ie={};_&2&&($Ie.$$scope={dirty:_,ctx:c}),y8.$set($Ie);const kIe={};_&2&&(kIe.$$scope={dirty:_,ctx:c}),$8.$set(kIe);const zy={};_&2&&(zy.$$scope={dirty:_,ctx:c}),X8.$set(zy);const SIe={};_&2&&(SIe.$$scope={dirty:_,ctx:c}),Q8.$set(SIe);const RIe={};_&2&&(RIe.$$scope={dirty:_,ctx:c}),tL.$set(RIe);const Qy={};_&2&&(Qy.$$scope={dirty:_,ctx:c}),nL.$set(Qy);const PIe={};_&2&&(PIe.$$scope={dirty:_,ctx:c}),pL.$set(PIe);const BIe={};_&2&&(BIe.$$scope={dirty:_,ctx:c}),bL.$set(BIe);const Wy={};_&2&&(Wy.$$scope={dirty:_,ctx:c}),xL.$set(Wy);const IIe={};_&2&&(IIe.$$scope={dirty:_,ctx:c}),kL.$set(IIe);const NIe={};_&2&&(NIe.$$scope={dirty:_,ctx:c}),OL.$set(NIe);const Uy={};_&2&&(Uy.$$scope={dirty:_,ctx:c}),XL.$set(Uy);const qIe={};_&2&&(qIe.$$scope={dirty:_,ctx:c}),KL.$set(qIe);const DIe={};_&2&&(DIe.$$scope={dirty:_,ctx:c}),oy.$set(DIe);const Hy={};_&2&&(Hy.$$scope={dirty:_,ctx:c}),my.$set(Hy);const jIe={};_&2&&(jIe.$$scope={dirty:_,ctx:c}),fy.$set(jIe);const GIe={};_&2&&(GIe.$$scope={dirty:_,ctx:c}),hy.$set(GIe);const Jy={};_&2&&(Jy.$$scope={dirty:_,ctx:c}),py.$set(Jy);const OIe={};_&2&&(OIe.$$scope={dirty:_,ctx:c}),vy.$set(OIe);const VIe={};_&2&&(VIe.$$scope={dirty:_,ctx:c}),Ty.$set(VIe);const Yy={};_&2&&(Yy.$$scope={dirty:_,ctx:c}),Ey.$set(Yy)},i(c){Gno||(E(d.$$.fragment,c),E(on.$$.fragment,c),E(d$.$$.fragment,c),E(m$.$$.fragment,c),E(Hf.$$.fragment,c),E(c$.$$.fragment,c),E(f$.$$.fragment,c),E(u$.$$.fragment,c),E(Cu.$$.fragment,c),E(p$.$$.fragment,c),E(_$.$$.fragment,c),E(b$.$$.fragment,c),E(T$.$$.fragment,c),E(dp.$$.fragment,c),E(M$.$$.fragment,c),E(E$.$$.fragment,c),E(C$.$$.fragment,c),E(L$.$$.fragment,c),E(r_.$$.fragment,c),E(t_.$$.fragment,c),E(y$.$$.fragment,c),E(x$.$$.fragment,c),E($$.$$.fragment,c),E(R$.$$.fragment,c),E(x_.$$.fragment,c),E($_.$$.fragment,c),E(P$.$$.fragment,c),E(B$.$$.fragment,c),E(I$.$$.fragment,c),E(q$.$$.fragment,c),E(R_.$$.fragment,c),E(D$.$$.fragment,c),E(ob.$$.fragment,c),E(j$.$$.fragment,c),E(G$.$$.fragment,c),E(V$.$$.fragment,c),E(tb.$$.fragment,c),E(X$.$$.fragment,c),E(Kb.$$.fragment,c),E(z$.$$.fragment,c),E(Q$.$$.fragment,c),E(U$.$$.fragment,c),E(ov.$$.fragment,c),E(H$.$$.fragment,c),E(zv.$$.fragment,c),E(J$.$$.fragment,c),E(Y$.$$.fragment,c),E(K$.$$.fragment,c),E(Wv.$$.fragment,c),E(ek.$$.fragment,c),E(Yv.$$.fragment,c),E(rk.$$.fragment,c),E(tk.$$.fragment,c),E(nk.$$.fragment,c),E(Kv.$$.fragment,c),E(sk.$$.fragment,c),E(jF.$$.fragment,c),E(lk.$$.fragment,c),E(ik.$$.fragment,c),E(mk.$$.fragment,c),E(OF.$$.fragment,c),E(ck.$$.fragment,c),E(mT.$$.fragment,c),E(fk.$$.fragment,c),E(gk.$$.fragment,c),E(uk.$$.fragment,c),E(fT.$$.fragment,c),E(pk.$$.fragment,c),E(pM.$$.fragment,c),E(_k.$$.fragment,c),E(bk.$$.fragment,c),E(Fk.$$.fragment,c),E(bM.$$.fragment,c),E(Tk.$$.fragment,c),E(ZM.$$.fragment,c),E(Mk.$$.fragment,c),E(Ek.$$.fragment,c),E(wk.$$.fragment,c),E(eE.$$.fragment,c),E(Ak.$$.fragment,c),E(dE.$$.fragment,c),E(Lk.$$.fragment,c),E(yk.$$.fragment,c),E($k.$$.fragment,c),E(cE.$$.fragment,c),E(kk.$$.fragment,c),E(e4.$$.fragment,c),E(Sk.$$.fragment,c),E(Rk.$$.fragment,c),E(Bk.$$.fragment,c),E(r4.$$.fragment,c),E(Ik.$$.fragment,c),E(Z4.$$.fragment,c),E(Nk.$$.fragment,c),E(qk.$$.fragment,c),E(jk.$$.fragment,c),E(eC.$$.fragment,c),E(Gk.$$.fragment,c),E(tC.$$.fragment,c),E(Ok.$$.fragment,c),E(Vk.$$.fragment,c),E(zk.$$.fragment,c),E(nC.$$.fragment,c),E(Qk.$$.fragment,c),E(mC.$$.fragment,c),E(Wk.$$.fragment,c),E(Uk.$$.fragment,c),E(Jk.$$.fragment,c),E(fC.$$.fragment,c),E(Yk.$$.fragment,c),E(xC.$$.fragment,c),E(Zk.$$.fragment,c),E(Kk.$$.fragment,c),E(oS.$$.fragment,c),E(kC.$$.fragment,c),E(rS.$$.fragment,c),E(PC.$$.fragment,c),E(tS.$$.fragment,c),E(aS.$$.fragment,c),E(sS.$$.fragment,c),E(IC.$$.fragment,c),E(lS.$$.fragment,c),E(DC.$$.fragment,c),E(iS.$$.fragment,c),E(dS.$$.fragment,c),E(cS.$$.fragment,c),E(GC.$$.fragment,c),E(fS.$$.fragment,c),E(XC.$$.fragment,c),E(gS.$$.fragment,c),E(hS.$$.fragment,c),E(pS.$$.fragment,c),E(QC.$$.fragment,c),E(_S.$$.fragment,c),E(t3.$$.fragment,c),E(bS.$$.fragment,c),E(vS.$$.fragment,c),E(TS.$$.fragment,c),E(n3.$$.fragment,c),E(MS.$$.fragment,c),E(f3.$$.fragment,c),E(ES.$$.fragment,c),E(CS.$$.fragment,c),E(AS.$$.fragment,c),E(h3.$$.fragment,c),E(LS.$$.fragment,c),E(A3.$$.fragment,c),E(yS.$$.fragment,c),E(xS.$$.fragment,c),E(kS.$$.fragment,c),E(y3.$$.fragment,c),E(SS.$$.fragment,c),E(R3.$$.fragment,c),E(RS.$$.fragment,c),E(PS.$$.fragment,c),E(IS.$$.fragment,c),E(B3.$$.fragment,c),E(NS.$$.fragment,c),E(O3.$$.fragment,c),E(qS.$$.fragment,c),E(DS.$$.fragment,c),E(GS.$$.fragment,c),E(X3.$$.fragment,c),E(OS.$$.fragment,c),E(J3.$$.fragment,c),E(VS.$$.fragment,c),E(XS.$$.fragment,c),E(QS.$$.fragment,c),E(Z3.$$.fragment,c),E(WS.$$.fragment,c),E(n5.$$.fragment,c),E(US.$$.fragment,c),E(HS.$$.fragment,c),E(YS.$$.fragment,c),E(l5.$$.fragment,c),E(ZS.$$.fragment,c),E(m5.$$.fragment,c),E(KS.$$.fragment,c),E(eR.$$.fragment,c),E(rR.$$.fragment,c),E(f5.$$.fragment,c),E(tR.$$.fragment,c),E(v5.$$.fragment,c),E(aR.$$.fragment,c),E(nR.$$.fragment,c),E(lR.$$.fragment,c),E(T5.$$.fragment,c),E(iR.$$.fragment,c),E(C5.$$.fragment,c),E(dR.$$.fragment,c),E(mR.$$.fragment,c),E(fR.$$.fragment,c),E(A5.$$.fragment,c),E(gR.$$.fragment,c),E(x5.$$.fragment,c),E(hR.$$.fragment,c),E(uR.$$.fragment,c),E(_R.$$.fragment,c),E(k5.$$.fragment,c),E(bR.$$.fragment,c),E(B0.$$.fragment,c),E(vR.$$.fragment,c),E(FR.$$.fragment,c),E(MR.$$.fragment,c),E(N0.$$.fragment,c),E(ER.$$.fragment,c),E(lw.$$.fragment,c),E(CR.$$.fragment,c),E(wR.$$.fragment,c),E(LR.$$.fragment,c),E(dw.$$.fragment,c),E(yR.$$.fragment,c),E(Cw.$$.fragment,c),E(xR.$$.fragment,c),E($R.$$.fragment,c),E(SR.$$.fragment,c),E(Aw.$$.fragment,c),E(RR.$$.fragment,c),E(Iw.$$.fragment,c),E(PR.$$.fragment,c),E(BR.$$.fragment,c),E(NR.$$.fragment,c),E(qw.$$.fragment,c),E(qR.$$.fragment,c),E(Ow.$$.fragment,c),E(DR.$$.fragment,c),E(jR.$$.fragment,c),E(OR.$$.fragment,c),E(Xw.$$.fragment,c),E(VR.$$.fragment,c),E(fA.$$.fragment,c),E(XR.$$.fragment,c),E(zR.$$.fragment,c),E(WR.$$.fragment,c),E(hA.$$.fragment,c),E(UR.$$.fragment,c),E(wA.$$.fragment,c),E(HR.$$.fragment,c),E(JR.$$.fragment,c),E(ZR.$$.fragment,c),E(LA.$$.fragment,c),E(KR.$$.fragment,c),E(r6.$$.fragment,c),E(eP.$$.fragment,c),E(oP.$$.fragment,c),E(tP.$$.fragment,c),E(a6.$$.fragment,c),E(aP.$$.fragment,c),E(M6.$$.fragment,c),E(nP.$$.fragment,c),E(sP.$$.fragment,c),E(iP.$$.fragment,c),E(C6.$$.fragment,c),E(dP.$$.fragment,c),E(L6.$$.fragment,c),E(cP.$$.fragment,c),E(fP.$$.fragment,c),E(hP.$$.fragment,c),E(x6.$$.fragment,c),E(uP.$$.fragment,c),E(k6.$$.fragment,c),E(pP.$$.fragment,c),E(_P.$$.fragment,c),E(vP.$$.fragment,c),E(R6.$$.fragment,c),E(FP.$$.fragment,c),E(B6.$$.fragment,c),E(TP.$$.fragment,c),E(MP.$$.fragment,c),E(CP.$$.fragment,c),E(N6.$$.fragment,c),E(wP.$$.fragment,c),E(s7.$$.fragment,c),E(AP.$$.fragment,c),E(LP.$$.fragment,c),E(xP.$$.fragment,c),E(i7.$$.fragment,c),E($P.$$.fragment,c),E($7.$$.fragment,c),E(kP.$$.fragment,c),E(SP.$$.fragment,c),E(PP.$$.fragment,c),E(S7.$$.fragment,c),E(BP.$$.fragment,c),E(P7.$$.fragment,c),E(IP.$$.fragment,c),E(NP.$$.fragment,c),E(DP.$$.fragment,c),E(I7.$$.fragment,c),E(jP.$$.fragment,c),E(D7.$$.fragment,c),E(OP.$$.fragment,c),E(VP.$$.fragment,c),E(zP.$$.fragment,c),E(G7.$$.fragment,c),E(QP.$$.fragment,c),E(u8.$$.fragment,c),E(WP.$$.fragment,c),E(UP.$$.fragment,c),E(JP.$$.fragment,c),E(_8.$$.fragment,c),E(YP.$$.fragment,c),E(y8.$$.fragment,c),E(ZP.$$.fragment,c),E(KP.$$.fragment,c),E(oB.$$.fragment,c),E($8.$$.fragment,c),E(rB.$$.fragment,c),E(X8.$$.fragment,c),E(tB.$$.fragment,c),E(aB.$$.fragment,c),E(sB.$$.fragment,c),E(Q8.$$.fragment,c),E(lB.$$.fragment,c),E(tL.$$.fragment,c),E(iB.$$.fragment,c),E(dB.$$.fragment,c),E(cB.$$.fragment,c),E(nL.$$.fragment,c),E(fB.$$.fragment,c),E(pL.$$.fragment,c),E(gB.$$.fragment,c),E(hB.$$.fragment,c),E(pB.$$.fragment,c),E(bL.$$.fragment,c),E(_B.$$.fragment,c),E(xL.$$.fragment,c),E(bB.$$.fragment,c),E(vB.$$.fragment,c),E(TB.$$.fragment,c),E(kL.$$.fragment,c),E(MB.$$.fragment,c),E(OL.$$.fragment,c),E(EB.$$.fragment,c),E(CB.$$.fragment,c),E(AB.$$.fragment,c),E(XL.$$.fragment,c),E(LB.$$.fragment,c),E(KL.$$.fragment,c),E(yB.$$.fragment,c),E(xB.$$.fragment,c),E(kB.$$.fragment,c),E(oy.$$.fragment,c),E(SB.$$.fragment,c),E(my.$$.fragment,c),E(RB.$$.fragment,c),E(PB.$$.fragment,c),E(IB.$$.fragment,c),E(fy.$$.fragment,c),E(NB.$$.fragment,c),E(hy.$$.fragment,c),E(qB.$$.fragment,c),E(DB.$$.fragment,c),E(GB.$$.fragment,c),E(py.$$.fragment,c),E(OB.$$.fragment,c),E(vy.$$.fragment,c),E(XB.$$.fragment,c),E(zB.$$.fragment,c),E(WB.$$.fragment,c),E(Ty.$$.fragment,c),E(UB.$$.fragment,c),E(Ey.$$.fragment,c),Gno=!0)},o(c){C(d.$$.fragment,c),C(on.$$.fragment,c),C(d$.$$.fragment,c),C(m$.$$.fragment,c),C(Hf.$$.fragment,c),C(c$.$$.fragment,c),C(f$.$$.fragment,c),C(u$.$$.fragment,c),C(Cu.$$.fragment,c),C(p$.$$.fragment,c),C(_$.$$.fragment,c),C(b$.$$.fragment,c),C(T$.$$.fragment,c),C(dp.$$.fragment,c),C(M$.$$.fragment,c),C(E$.$$.fragment,c),C(C$.$$.fragment,c),C(L$.$$.fragment,c),C(r_.$$.fragment,c),C(t_.$$.fragment,c),C(y$.$$.fragment,c),C(x$.$$.fragment,c),C($$.$$.fragment,c),C(R$.$$.fragment,c),C(x_.$$.fragment,c),C($_.$$.fragment,c),C(P$.$$.fragment,c),C(B$.$$.fragment,c),C(I$.$$.fragment,c),C(q$.$$.fragment,c),C(R_.$$.fragment,c),C(D$.$$.fragment,c),C(ob.$$.fragment,c),C(j$.$$.fragment,c),C(G$.$$.fragment,c),C(V$.$$.fragment,c),C(tb.$$.fragment,c),C(X$.$$.fragment,c),C(Kb.$$.fragment,c),C(z$.$$.fragment,c),C(Q$.$$.fragment,c),C(U$.$$.fragment,c),C(ov.$$.fragment,c),C(H$.$$.fragment,c),C(zv.$$.fragment,c),C(J$.$$.fragment,c),C(Y$.$$.fragment,c),C(K$.$$.fragment,c),C(Wv.$$.fragment,c),C(ek.$$.fragment,c),C(Yv.$$.fragment,c),C(rk.$$.fragment,c),C(tk.$$.fragment,c),C(nk.$$.fragment,c),C(Kv.$$.fragment,c),C(sk.$$.fragment,c),C(jF.$$.fragment,c),C(lk.$$.fragment,c),C(ik.$$.fragment,c),C(mk.$$.fragment,c),C(OF.$$.fragment,c),C(ck.$$.fragment,c),C(mT.$$.fragment,c),C(fk.$$.fragment,c),C(gk.$$.fragment,c),C(uk.$$.fragment,c),C(fT.$$.fragment,c),C(pk.$$.fragment,c),C(pM.$$.fragment,c),C(_k.$$.fragment,c),C(bk.$$.fragment,c),C(Fk.$$.fragment,c),C(bM.$$.fragment,c),C(Tk.$$.fragment,c),C(ZM.$$.fragment,c),C(Mk.$$.fragment,c),C(Ek.$$.fragment,c),C(wk.$$.fragment,c),C(eE.$$.fragment,c),C(Ak.$$.fragment,c),C(dE.$$.fragment,c),C(Lk.$$.fragment,c),C(yk.$$.fragment,c),C($k.$$.fragment,c),C(cE.$$.fragment,c),C(kk.$$.fragment,c),C(e4.$$.fragment,c),C(Sk.$$.fragment,c),C(Rk.$$.fragment,c),C(Bk.$$.fragment,c),C(r4.$$.fragment,c),C(Ik.$$.fragment,c),C(Z4.$$.fragment,c),C(Nk.$$.fragment,c),C(qk.$$.fragment,c),C(jk.$$.fragment,c),C(eC.$$.fragment,c),C(Gk.$$.fragment,c),C(tC.$$.fragment,c),C(Ok.$$.fragment,c),C(Vk.$$.fragment,c),C(zk.$$.fragment,c),C(nC.$$.fragment,c),C(Qk.$$.fragment,c),C(mC.$$.fragment,c),C(Wk.$$.fragment,c),C(Uk.$$.fragment,c),C(Jk.$$.fragment,c),C(fC.$$.fragment,c),C(Yk.$$.fragment,c),C(xC.$$.fragment,c),C(Zk.$$.fragment,c),C(Kk.$$.fragment,c),C(oS.$$.fragment,c),C(kC.$$.fragment,c),C(rS.$$.fragment,c),C(PC.$$.fragment,c),C(tS.$$.fragment,c),C(aS.$$.fragment,c),C(sS.$$.fragment,c),C(IC.$$.fragment,c),C(lS.$$.fragment,c),C(DC.$$.fragment,c),C(iS.$$.fragment,c),C(dS.$$.fragment,c),C(cS.$$.fragment,c),C(GC.$$.fragment,c),C(fS.$$.fragment,c),C(XC.$$.fragment,c),C(gS.$$.fragment,c),C(hS.$$.fragment,c),C(pS.$$.fragment,c),C(QC.$$.fragment,c),C(_S.$$.fragment,c),C(t3.$$.fragment,c),C(bS.$$.fragment,c),C(vS.$$.fragment,c),C(TS.$$.fragment,c),C(n3.$$.fragment,c),C(MS.$$.fragment,c),C(f3.$$.fragment,c),C(ES.$$.fragment,c),C(CS.$$.fragment,c),C(AS.$$.fragment,c),C(h3.$$.fragment,c),C(LS.$$.fragment,c),C(A3.$$.fragment,c),C(yS.$$.fragment,c),C(xS.$$.fragment,c),C(kS.$$.fragment,c),C(y3.$$.fragment,c),C(SS.$$.fragment,c),C(R3.$$.fragment,c),C(RS.$$.fragment,c),C(PS.$$.fragment,c),C(IS.$$.fragment,c),C(B3.$$.fragment,c),C(NS.$$.fragment,c),C(O3.$$.fragment,c),C(qS.$$.fragment,c),C(DS.$$.fragment,c),C(GS.$$.fragment,c),C(X3.$$.fragment,c),C(OS.$$.fragment,c),C(J3.$$.fragment,c),C(VS.$$.fragment,c),C(XS.$$.fragment,c),C(QS.$$.fragment,c),C(Z3.$$.fragment,c),C(WS.$$.fragment,c),C(n5.$$.fragment,c),C(US.$$.fragment,c),C(HS.$$.fragment,c),C(YS.$$.fragment,c),C(l5.$$.fragment,c),C(ZS.$$.fragment,c),C(m5.$$.fragment,c),C(KS.$$.fragment,c),C(eR.$$.fragment,c),C(rR.$$.fragment,c),C(f5.$$.fragment,c),C(tR.$$.fragment,c),C(v5.$$.fragment,c),C(aR.$$.fragment,c),C(nR.$$.fragment,c),C(lR.$$.fragment,c),C(T5.$$.fragment,c),C(iR.$$.fragment,c),C(C5.$$.fragment,c),C(dR.$$.fragment,c),C(mR.$$.fragment,c),C(fR.$$.fragment,c),C(A5.$$.fragment,c),C(gR.$$.fragment,c),C(x5.$$.fragment,c),C(hR.$$.fragment,c),C(uR.$$.fragment,c),C(_R.$$.fragment,c),C(k5.$$.fragment,c),C(bR.$$.fragment,c),C(B0.$$.fragment,c),C(vR.$$.fragment,c),C(FR.$$.fragment,c),C(MR.$$.fragment,c),C(N0.$$.fragment,c),C(ER.$$.fragment,c),C(lw.$$.fragment,c),C(CR.$$.fragment,c),C(wR.$$.fragment,c),C(LR.$$.fragment,c),C(dw.$$.fragment,c),C(yR.$$.fragment,c),C(Cw.$$.fragment,c),C(xR.$$.fragment,c),C($R.$$.fragment,c),C(SR.$$.fragment,c),C(Aw.$$.fragment,c),C(RR.$$.fragment,c),C(Iw.$$.fragment,c),C(PR.$$.fragment,c),C(BR.$$.fragment,c),C(NR.$$.fragment,c),C(qw.$$.fragment,c),C(qR.$$.fragment,c),C(Ow.$$.fragment,c),C(DR.$$.fragment,c),C(jR.$$.fragment,c),C(OR.$$.fragment,c),C(Xw.$$.fragment,c),C(VR.$$.fragment,c),C(fA.$$.fragment,c),C(XR.$$.fragment,c),C(zR.$$.fragment,c),C(WR.$$.fragment,c),C(hA.$$.fragment,c),C(UR.$$.fragment,c),C(wA.$$.fragment,c),C(HR.$$.fragment,c),C(JR.$$.fragment,c),C(ZR.$$.fragment,c),C(LA.$$.fragment,c),C(KR.$$.fragment,c),C(r6.$$.fragment,c),C(eP.$$.fragment,c),C(oP.$$.fragment,c),C(tP.$$.fragment,c),C(a6.$$.fragment,c),C(aP.$$.fragment,c),C(M6.$$.fragment,c),C(nP.$$.fragment,c),C(sP.$$.fragment,c),C(iP.$$.fragment,c),C(C6.$$.fragment,c),C(dP.$$.fragment,c),C(L6.$$.fragment,c),C(cP.$$.fragment,c),C(fP.$$.fragment,c),C(hP.$$.fragment,c),C(x6.$$.fragment,c),C(uP.$$.fragment,c),C(k6.$$.fragment,c),C(pP.$$.fragment,c),C(_P.$$.fragment,c),C(vP.$$.fragment,c),C(R6.$$.fragment,c),C(FP.$$.fragment,c),C(B6.$$.fragment,c),C(TP.$$.fragment,c),C(MP.$$.fragment,c),C(CP.$$.fragment,c),C(N6.$$.fragment,c),C(wP.$$.fragment,c),C(s7.$$.fragment,c),C(AP.$$.fragment,c),C(LP.$$.fragment,c),C(xP.$$.fragment,c),C(i7.$$.fragment,c),C($P.$$.fragment,c),C($7.$$.fragment,c),C(kP.$$.fragment,c),C(SP.$$.fragment,c),C(PP.$$.fragment,c),C(S7.$$.fragment,c),C(BP.$$.fragment,c),C(P7.$$.fragment,c),C(IP.$$.fragment,c),C(NP.$$.fragment,c),C(DP.$$.fragment,c),C(I7.$$.fragment,c),C(jP.$$.fragment,c),C(D7.$$.fragment,c),C(OP.$$.fragment,c),C(VP.$$.fragment,c),C(zP.$$.fragment,c),C(G7.$$.fragment,c),C(QP.$$.fragment,c),C(u8.$$.fragment,c),C(WP.$$.fragment,c),C(UP.$$.fragment,c),C(JP.$$.fragment,c),C(_8.$$.fragment,c),C(YP.$$.fragment,c),C(y8.$$.fragment,c),C(ZP.$$.fragment,c),C(KP.$$.fragment,c),C(oB.$$.fragment,c),C($8.$$.fragment,c),C(rB.$$.fragment,c),C(X8.$$.fragment,c),C(tB.$$.fragment,c),C(aB.$$.fragment,c),C(sB.$$.fragment,c),C(Q8.$$.fragment,c),C(lB.$$.fragment,c),C(tL.$$.fragment,c),C(iB.$$.fragment,c),C(dB.$$.fragment,c),C(cB.$$.fragment,c),C(nL.$$.fragment,c),C(fB.$$.fragment,c),C(pL.$$.fragment,c),C(gB.$$.fragment,c),C(hB.$$.fragment,c),C(pB.$$.fragment,c),C(bL.$$.fragment,c),C(_B.$$.fragment,c),C(xL.$$.fragment,c),C(bB.$$.fragment,c),C(vB.$$.fragment,c),C(TB.$$.fragment,c),C(kL.$$.fragment,c),C(MB.$$.fragment,c),C(OL.$$.fragment,c),C(EB.$$.fragment,c),C(CB.$$.fragment,c),C(AB.$$.fragment,c),C(XL.$$.fragment,c),C(LB.$$.fragment,c),C(KL.$$.fragment,c),C(yB.$$.fragment,c),C(xB.$$.fragment,c),C(kB.$$.fragment,c),C(oy.$$.fragment,c),C(SB.$$.fragment,c),C(my.$$.fragment,c),C(RB.$$.fragment,c),C(PB.$$.fragment,c),C(IB.$$.fragment,c),C(fy.$$.fragment,c),C(NB.$$.fragment,c),C(hy.$$.fragment,c),C(qB.$$.fragment,c),C(DB.$$.fragment,c),C(GB.$$.fragment,c),C(py.$$.fragment,c),C(OB.$$.fragment,c),C(vy.$$.fragment,c),C(XB.$$.fragment,c),C(zB.$$.fragment,c),C(WB.$$.fragment,c),C(Ty.$$.fragment,c),C(UB.$$.fragment,c),C(Ey.$$.fragment,c),Gno=!1},d(c){t(g),c&&t(v),c&&t(u),w(d),c&&t(Xf),c&&t(Tt),c&&t(Xe),c&&t(He),c&&t(Qf),w(on,c),c&&t(Je),c&&t(Ae),c&&t(ko),c&&t(rn),c&&t(Cto),c&&t(Cd),w(d$),c&&t(wto),c&&t(hs),c&&t(Ato),w(m$,c),c&&t(Lto),c&&t(AN),c&&t(yto),w(Hf,c),c&&t(xto),c&&t(wd),w(c$),c&&t($to),c&&t(So),w(f$),w(u$),w(Cu),w(p$),c&&t(kto),c&&t(Ld),w(_$),c&&t(Sto),c&&t(Ro),w(b$),w(T$),w(dp),w(M$),c&&t(Rto),c&&t(yd),w(E$),c&&t(Pto),c&&t(Po),w(C$),w(L$),w(r_),w(t_),w(y$),c&&t(Bto),c&&t(xd),w(x$),c&&t(Ito),c&&t(Bo),w($$),w(R$),w(x_),w($_),w(P$),c&&t(Nto),c&&t(kd),w(B$),c&&t(qto),c&&t(Io),w(I$),w(q$),w(R_),w(D$),w(ob),c&&t(Dto),c&&t(Pd),w(j$),c&&t(jto),c&&t(No),w(G$),w(V$),w(tb),w(X$),w(Kb),c&&t(Gto),c&&t(Nd),w(z$),c&&t(Oto),c&&t(qo),w(Q$),w(U$),w(ov),w(H$),w(zv),c&&t(Vto),c&&t(jd),w(J$),c&&t(Xto),c&&t(Do),w(Y$),w(K$),w(Wv),w(ek),w(Yv),c&&t(zto),c&&t(Vd),w(rk),c&&t(Qto),c&&t(jo),w(tk),w(nk),w(Kv),w(sk),w(jF),c&&t(Wto),c&&t(Qd),w(lk),c&&t(Uto),c&&t(Go),w(ik),w(mk),w(OF),w(ck),w(mT),c&&t(Hto),c&&t(Hd),w(fk),c&&t(Jto),c&&t(Oo),w(gk),w(uk),w(fT),w(pk),w(pM),c&&t(Yto),c&&t(Zd),w(_k),c&&t(Zto),c&&t(Vo),w(bk),w(Fk),w(bM),w(Tk),w(ZM),c&&t(Kto),c&&t(om),w(Mk),c&&t(eao),c&&t(Xo),w(Ek),w(wk),w(eE),w(Ak),w(dE),c&&t(oao),c&&t(am),w(Lk),c&&t(rao),c&&t(zo),w(yk),w($k),w(cE),w(kk),w(e4),c&&t(tao),c&&t(lm),w(Sk),c&&t(aao),c&&t(Qo),w(Rk),w(Bk),w(r4),w(Ik),w(Z4),c&&t(nao),c&&t(mm),w(Nk),c&&t(sao),c&&t(Wo),w(qk),w(jk),w(eC),w(Gk),w(tC),c&&t(lao),c&&t(gm),w(Ok),c&&t(iao),c&&t(Uo),w(Vk),w(zk),w(nC),w(Qk),w(mC),c&&t(dao),c&&t(_m),w(Wk),c&&t(mao),c&&t(Ho),w(Uk),w(Jk),w(fC),w(Yk),w(xC),c&&t(cao),c&&t(Fm),w(Zk),c&&t(fao),c&&t(Jo),w(Kk),w(oS),w(kC),w(rS),w(PC),c&&t(gao),c&&t(Em),w(tS),c&&t(hao),c&&t(Yo),w(aS),w(sS),w(IC),w(lS),w(DC),c&&t(uao),c&&t(Am),w(iS),c&&t(pao),c&&t(Zo),w(dS),w(cS),w(GC),w(fS),w(XC),c&&t(_ao),c&&t(xm),w(gS),c&&t(bao),c&&t(Ko),w(hS),w(pS),w(QC),w(_S),w(t3),c&&t(vao),c&&t(Sm),w(bS),c&&t(Fao),c&&t(er),w(vS),w(TS),w(n3),w(MS),w(f3),c&&t(Tao),c&&t(Bm),w(ES),c&&t(Mao),c&&t(or),w(CS),w(AS),w(h3),w(LS),w(A3),c&&t(Eao),c&&t(qm),w(yS),c&&t(Cao),c&&t(rr),w(xS),w(kS),w(y3),w(SS),w(R3),c&&t(wao),c&&t(Om),w(RS),c&&t(Aao),c&&t(tr),w(PS),w(IS),w(B3),w(NS),w(O3),c&&t(Lao),c&&t(zm),w(qS),c&&t(yao),c&&t(ar),w(DS),w(GS),w(X3),w(OS),w(J3),c&&t(xao),c&&t(Um),w(VS),c&&t($ao),c&&t(nr),w(XS),w(QS),w(Z3),w(WS),w(n5),c&&t(kao),c&&t(Ym),w(US),c&&t(Sao),c&&t(sr),w(HS),w(YS),w(l5),w(ZS),w(m5),c&&t(Rao),c&&t(ec),w(KS),c&&t(Pao),c&&t(lr),w(eR),w(rR),w(f5),w(tR),w(v5),c&&t(Bao),c&&t(tc),w(aR),c&&t(Iao),c&&t(ir),w(nR),w(lR),w(T5),w(iR),w(C5),c&&t(Nao),c&&t(sc),w(dR),c&&t(qao),c&&t(dr),w(mR),w(fR),w(A5),w(gR),w(x5),c&&t(Dao),c&&t(dc),w(hR),c&&t(jao),c&&t(mr),w(uR),w(_R),w(k5),w(bR),w(B0),c&&t(Gao),c&&t(fc),w(vR),c&&t(Oao),c&&t(cr),w(FR),w(MR),w(N0),w(ER),w(lw),c&&t(Vao),c&&t(uc),w(CR),c&&t(Xao),c&&t(fr),w(wR),w(LR),w(dw),w(yR),w(Cw),c&&t(zao),c&&t(bc),w(xR),c&&t(Qao),c&&t(gr),w($R),w(SR),w(Aw),w(RR),w(Iw),c&&t(Wao),c&&t(Tc),w(PR),c&&t(Uao),c&&t(hr),w(BR),w(NR),w(qw),w(qR),w(Ow),c&&t(Hao),c&&t(wc),w(DR),c&&t(Jao),c&&t(ur),w(jR),w(OR),w(Xw),w(VR),w(fA),c&&t(Yao),c&&t(yc),w(XR),c&&t(Zao),c&&t(pr),w(zR),w(WR),w(hA),w(UR),w(wA),c&&t(Kao),c&&t(kc),w(HR),c&&t(eno),c&&t(_r),w(JR),w(ZR),w(LA),w(KR),w(r6),c&&t(ono),c&&t(Pc),w(eP),c&&t(rno),c&&t(br),w(oP),w(tP),w(a6),w(aP),w(M6),c&&t(tno),c&&t(Nc),w(nP),c&&t(ano),c&&t(vr),w(sP),w(iP),w(C6),w(dP),w(L6),c&&t(nno),c&&t(jc),w(cP),c&&t(sno),c&&t(Fr),w(fP),w(hP),w(x6),w(uP),w(k6),c&&t(lno),c&&t(Vc),w(pP),c&&t(ino),c&&t(Tr),w(_P),w(vP),w(R6),w(FP),w(B6),c&&t(dno),c&&t(Qc),w(TP),c&&t(mno),c&&t(Mr),w(MP),w(CP),w(N6),w(wP),w(s7),c&&t(cno),c&&t(Hc),w(AP),c&&t(fno),c&&t(Er),w(LP),w(xP),w(i7),w($P),w($7),c&&t(gno),c&&t(Zc),w(kP),c&&t(hno),c&&t(Cr),w(SP),w(PP),w(S7),w(BP),w(P7),c&&t(uno),c&&t(of),w(IP),c&&t(pno),c&&t(wr),w(NP),w(DP),w(I7),w(jP),w(D7),c&&t(_no),c&&t(af),w(OP),c&&t(bno),c&&t(Ar),w(VP),w(zP),w(G7),w(QP),w(u8),c&&t(vno),c&&t(lf),w(WP),c&&t(Fno),c&&t(Lr),w(UP),w(JP),w(_8),w(YP),w(y8),c&&t(Tno),c&&t(cf),w(ZP),c&&t(Mno),c&&t(yr),w(KP),w(oB),w($8),w(rB),w(X8),c&&t(Eno),c&&t(hf),w(tB),c&&t(Cno),c&&t(xr),w(aB),w(sB),w(Q8),w(lB),w(tL),c&&t(wno),c&&t(_f),w(iB),c&&t(Ano),c&&t($r),w(dB),w(cB),w(nL),w(fB),w(pL),c&&t(Lno),c&&t(Ff),w(gB),c&&t(yno),c&&t(kr),w(hB),w(pB),w(bL),w(_B),w(xL),c&&t(xno),c&&t(Ef),w(bB),c&&t($no),c&&t(Sr),w(vB),w(TB),w(kL),w(MB),w(OL),c&&t(kno),c&&t(Af),w(EB),c&&t(Sno),c&&t(Rr),w(CB),w(AB),w(XL),w(LB),w(KL),c&&t(Rno),c&&t(xf),w(yB),c&&t(Pno),c&&t(Pr),w(xB),w(kB),w(oy),w(SB),w(my),c&&t(Bno),c&&t(Sf),w(RB),c&&t(Ino),c&&t(Br),w(PB),w(IB),w(fy),w(NB),w(hy),c&&t(Nno),c&&t(Bf),w(qB),c&&t(qno),c&&t(Ir),w(DB),w(GB),w(py),w(OB),w(vy),c&&t(Dno),c&&t(qf),w(XB),c&&t(jno),c&&t(Nr),w(zB),w(WB),w(Ty),w(UB),w(Ey)}}}const I0a={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForDepthEstimation",title:"AutoModelForDepthEstimation"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForDocumentQuestionAnswering",title:"AutoModelForDocumentQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVideoClassification",title:"AutoModelForVideoClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.AutoModelForZeroShotObjectDetection",title:"AutoModelForZeroShotObjectDetection"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForSemanticSegmentation",title:"TFAutoModelForSemanticSegmentation"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForDocumentQuestionAnswering",title:"TFAutoModelForDocumentQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function N0a($){return E3a(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class X0a extends v3a{constructor(g){super();F3a(this,g,N0a,B0a,T3a,{})}}export{X0a as default,I0a as metadata};
