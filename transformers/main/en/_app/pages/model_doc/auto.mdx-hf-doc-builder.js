import{S as G9a,i as O9a,s as V9a,e as a,k as l,w as F,t as o,M as X9a,c as n,d as t,m as i,a as s,x as T,h as r,b as d,G as e,g as b,y as M,q as E,o as C,B as w,v as z9a,L as q}from"../../chunks/vendor-hf-doc-builder.js";import{T as lfo}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as B}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as oe}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as N}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function Q9a($){let g,v,u,f,p,m,h,He,Ad,eg,wt,Ld,yd,ik,og,Qe,Ze,xd,ps,dk,_s,bs,mk,$d,vs,ck,kd,rg,sn;return{c(){g=a("p"),v=o("If your "),u=a("code"),f=o("NewModelConfig"),p=o(" is a subclass of "),m=a("code"),h=o("~transformer.PretrainedConfig"),He=o(`, make sure its
`),Ad=a("code"),eg=o("model_type"),wt=o(" attribute is set to the same key you use when registering the config (here "),Ld=a("code"),yd=o('"new-model"'),ik=o(")."),og=l(),Qe=a("p"),Ze=o("Likewise, if your "),xd=a("code"),ps=o("NewModel"),dk=o(" is a subclass of "),_s=a("a"),bs=o("PreTrainedModel"),mk=o(`, make sure its
`),$d=a("code"),vs=o("config_class"),ck=o(` attribute is set to the same class you use when registering the model (here
`),kd=a("code"),rg=o("NewModelConfig"),sn=o(")."),this.h()},l(Ke){g=n(Ke,"P",{});var ye=s(g);v=r(ye,"If your "),u=n(ye,"CODE",{});var Sq=s(u);f=r(Sq,"NewModelConfig"),Sq.forEach(t),p=r(ye," is a subclass of "),m=n(ye,"CODE",{});var Sd=s(m);h=r(Sd,"~transformer.PretrainedConfig"),Sd.forEach(t),He=r(ye,`, make sure its
`),Ad=n(ye,"CODE",{});var Rq=s(Ad);eg=r(Rq,"model_type"),Rq.forEach(t),wt=r(ye," attribute is set to the same key you use when registering the config (here "),Ld=n(ye,"CODE",{});var Pq=s(Ld);yd=r(Pq,'"new-model"'),Pq.forEach(t),ik=r(ye,")."),ye.forEach(t),og=i(Ke),Qe=n(Ke,"P",{});var Po=s(Qe);Ze=r(Po,"Likewise, if your "),xd=n(Po,"CODE",{});var ln=s(xd);ps=r(ln,"NewModel"),ln.forEach(t),dk=r(Po," is a subclass of "),_s=n(Po,"A",{href:!0});var Bq=s(_s);bs=r(Bq,"PreTrainedModel"),Bq.forEach(t),mk=r(Po,`, make sure its
`),$d=n(Po,"CODE",{});var tg=s($d);vs=r(tg,"config_class"),tg.forEach(t),ck=r(Po,` attribute is set to the same class you use when registering the model (here
`),kd=n(Po,"CODE",{});var Iq=s(kd);rg=r(Iq,"NewModelConfig"),Iq.forEach(t),sn=r(Po,")."),Po.forEach(t),this.h()},h(){d(_s,"href","/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel")},m(Ke,ye){b(Ke,g,ye),e(g,v),e(g,u),e(u,f),e(g,p),e(g,m),e(m,h),e(g,He),e(g,Ad),e(Ad,eg),e(g,wt),e(g,Ld),e(Ld,yd),e(g,ik),b(Ke,og,ye),b(Ke,Qe,ye),e(Qe,Ze),e(Qe,xd),e(xd,ps),e(Qe,dk),e(Qe,_s),e(_s,bs),e(Qe,mk),e(Qe,$d),e($d,vs),e(Qe,ck),e(Qe,kd),e(kd,rg),e(Qe,sn)},d(Ke){Ke&&t(g),Ke&&t(og),Ke&&t(Qe)}}}function W9a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function U9a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function H9a($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var He=s(u);f=r(He,"use_auth_token=True"),He.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(m,h){b(m,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(m){m&&t(g)}}}function J9a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Y9a($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var He=s(u);f=r(He,"use_auth_token=True"),He.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(m,h){b(m,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(m){m&&t(g)}}}function Z9a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoImageProcessor

# Download image processor from huggingface.co and cache.
image_processor = AutoImageProcessor.from_pretrained("google/vit-base-patch16-224-in21k")

# If image processor files are in a directory (e.g. image processor was saved using *save_pretrained('./test/saved_model/')*)
image_processor = AutoImageProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoImageProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download image processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>image_processor = AutoImageProcessor.from_pretrained(<span class="hljs-string">&quot;google/vit-base-patch16-224-in21k&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If image processor files are in a directory (e.g. image processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>image_processor = AutoImageProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function K9a($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var He=s(u);f=r(He,"use_auth_token=True"),He.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(m,h){b(m,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(m){m&&t(g)}}}function exa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function oxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function rxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function txa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function axa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function nxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function sxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function lxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDepthEstimation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForDepthEstimation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDepthEstimation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function ixa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDepthEstimation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForDepthEstimation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForDepthEstimation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForDepthEstimation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDepthEstimation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function dxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function mxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function cxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function fxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function gxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function hxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function uxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function pxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function _xa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function bxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function vxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Fxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Txa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Mxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Exa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Cxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function wxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = AutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Axa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/layoutlm_tf_model_config.json")
model = AutoModelForDocumentQuestionAnswering.from_pretrained(
    "./tf_model/layoutlm_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/layoutlm_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/layoutlm_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Lxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function yxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function xxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVideoClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function $xa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVideoClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function kxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Sxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Rxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Pxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Bxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Ixa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Nxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function qxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Dxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function jxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Gxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Oxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Vxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Xxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function zxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Qxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Wxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Uxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Hxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Jxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Yxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Zxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Kxa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function e$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function o$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForZeroShotObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForZeroShotObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForZeroShotObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function r$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForZeroShotObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForZeroShotObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForZeroShotObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForZeroShotObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForZeroShotObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function t$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function a$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function n$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function s$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function l$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function i$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function d$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function m$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function c$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function f$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSemanticSegmentation.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function g$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function h$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function u$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function p$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function _$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function b$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function v$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function F$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function T$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function M$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function E$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function C$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function w$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function A$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/layoutlm_pt_model_config.json")
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
    "./pt_model/layoutlm_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/layoutlm_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/layoutlm_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function L$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function y$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function x$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function $$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function k$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function S$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function R$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function P$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function B$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function I$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function N$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function q$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function D$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function j$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function G$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function O$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function V$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function X$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function z$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Q$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function W$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function U$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function H$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function J$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Y$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Z$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function K$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function eka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function oka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function rka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function tka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function aka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function nka($){let g,v,u,f,p,m,h,He,Ad,eg,wt,Ld,yd,ik,og,Qe,Ze,xd,ps,dk,_s,bs,mk,$d,vs,ck,kd,rg,sn,Ke,ye,Sq,Sd,Rq,Pq,Po,ln,Bq,tg,Iq,ifo,plo,Rd,ag,ghe,fk,dfo,hhe,mfo,_lo,Fs,cfo,uhe,ffo,gfo,phe,hfo,ufo,blo,gk,vlo,Nq,pfo,Flo,ng,Tlo,Pd,sg,_he,hk,_fo,bhe,bfo,Mlo,Bo,uk,vfo,pk,Ffo,qq,Tfo,Mfo,Efo,_k,Cfo,vhe,wfo,Afo,Lfo,Or,bk,yfo,Fhe,xfo,$fo,Bd,kfo,The,Sfo,Rfo,Mhe,Pfo,Bfo,Ifo,A,lg,Ehe,Nfo,qfo,Dq,Dfo,jfo,Gfo,ig,Che,Ofo,Vfo,jq,Xfo,zfo,Qfo,dg,whe,Wfo,Ufo,Gq,Hfo,Jfo,Yfo,mg,Ahe,Zfo,Kfo,Oq,ego,ogo,rgo,cg,Lhe,tgo,ago,Vq,ngo,sgo,lgo,fg,yhe,igo,dgo,Xq,mgo,cgo,fgo,gg,xhe,ggo,hgo,zq,ugo,pgo,_go,hg,$he,bgo,vgo,Qq,Fgo,Tgo,Mgo,ug,khe,Ego,Cgo,Wq,wgo,Ago,Lgo,pg,She,ygo,xgo,Uq,$go,kgo,Sgo,_g,Rhe,Rgo,Pgo,Hq,Bgo,Igo,Ngo,bg,Phe,qgo,Dgo,Jq,jgo,Ggo,Ogo,vg,Bhe,Vgo,Xgo,Yq,zgo,Qgo,Wgo,Fg,Ihe,Ugo,Hgo,Zq,Jgo,Ygo,Zgo,Tg,Nhe,Kgo,eho,Kq,oho,rho,tho,Mg,qhe,aho,nho,eD,sho,lho,iho,Eg,Dhe,dho,mho,oD,cho,fho,gho,Cg,jhe,hho,uho,rD,pho,_ho,bho,wg,Ghe,vho,Fho,tD,Tho,Mho,Eho,Ag,Ohe,Cho,who,aD,Aho,Lho,yho,Lg,Vhe,xho,$ho,nD,kho,Sho,Rho,yg,Xhe,Pho,Bho,sD,Iho,Nho,qho,xg,zhe,Dho,jho,lD,Gho,Oho,Vho,$g,Qhe,Xho,zho,iD,Qho,Who,Uho,kg,Whe,Hho,Jho,dD,Yho,Zho,Kho,Sg,Uhe,euo,ouo,mD,ruo,tuo,auo,Rg,Hhe,nuo,suo,cD,luo,iuo,duo,Pg,Jhe,muo,cuo,fD,fuo,guo,huo,Bg,Yhe,uuo,puo,gD,_uo,buo,vuo,Ig,Zhe,Fuo,Tuo,hD,Muo,Euo,Cuo,Ng,Khe,wuo,Auo,uD,Luo,yuo,xuo,qg,eue,$uo,kuo,pD,Suo,Ruo,Puo,Dg,oue,Buo,Iuo,_D,Nuo,quo,Duo,jg,rue,juo,Guo,bD,Ouo,Vuo,Xuo,Gg,tue,zuo,Quo,vD,Wuo,Uuo,Huo,Og,aue,Juo,Yuo,FD,Zuo,Kuo,epo,Vg,nue,opo,rpo,TD,tpo,apo,npo,Xg,sue,spo,lpo,MD,ipo,dpo,mpo,zg,lue,cpo,fpo,ED,gpo,hpo,upo,Qg,iue,ppo,_po,CD,bpo,vpo,Fpo,Wg,due,Tpo,Mpo,wD,Epo,Cpo,wpo,Ug,mue,Apo,Lpo,AD,ypo,xpo,$po,Hg,cue,kpo,Spo,LD,Rpo,Ppo,Bpo,Jg,fue,Ipo,Npo,yD,qpo,Dpo,jpo,Yg,gue,Gpo,Opo,xD,Vpo,Xpo,zpo,Zg,hue,Qpo,Wpo,$D,Upo,Hpo,Jpo,Kg,uue,Ypo,Zpo,kD,Kpo,e_o,o_o,eh,pue,r_o,t_o,SD,a_o,n_o,s_o,oh,_ue,l_o,i_o,RD,d_o,m_o,c_o,rh,bue,f_o,g_o,PD,h_o,u_o,p_o,th,vue,__o,b_o,BD,v_o,F_o,T_o,ah,Fue,M_o,E_o,ID,C_o,w_o,A_o,nh,Tue,L_o,y_o,ND,x_o,$_o,k_o,sh,Mue,S_o,R_o,qD,P_o,B_o,I_o,lh,Eue,N_o,q_o,DD,D_o,j_o,G_o,ih,Cue,O_o,V_o,jD,X_o,z_o,Q_o,dh,wue,W_o,U_o,GD,H_o,J_o,Y_o,mh,Aue,Z_o,K_o,OD,e1o,o1o,r1o,ch,Lue,t1o,a1o,VD,n1o,s1o,l1o,fh,yue,i1o,d1o,XD,m1o,c1o,f1o,gh,xue,g1o,h1o,zD,u1o,p1o,_1o,hh,$ue,b1o,v1o,QD,F1o,T1o,M1o,uh,kue,E1o,C1o,WD,w1o,A1o,L1o,ph,Sue,y1o,x1o,UD,$1o,k1o,S1o,_h,Rue,R1o,P1o,HD,B1o,I1o,N1o,bh,Pue,q1o,D1o,JD,j1o,G1o,O1o,vh,Bue,V1o,X1o,YD,z1o,Q1o,W1o,Fh,Iue,U1o,H1o,ZD,J1o,Y1o,Z1o,Th,Nue,K1o,e2o,KD,o2o,r2o,t2o,Mh,que,a2o,n2o,ej,s2o,l2o,i2o,Eh,Due,d2o,m2o,oj,c2o,f2o,g2o,Ch,jue,h2o,u2o,rj,p2o,_2o,b2o,wh,Gue,v2o,F2o,tj,T2o,M2o,E2o,Ah,Oue,C2o,w2o,aj,A2o,L2o,y2o,Lh,Vue,x2o,$2o,nj,k2o,S2o,R2o,yh,Xue,P2o,B2o,sj,I2o,N2o,q2o,xh,zue,D2o,j2o,lj,G2o,O2o,V2o,$h,Que,X2o,z2o,ij,Q2o,W2o,U2o,kh,Wue,H2o,J2o,dj,Y2o,Z2o,K2o,Sh,Uue,ebo,obo,mj,rbo,tbo,abo,Rh,Hue,nbo,sbo,cj,lbo,ibo,dbo,Ph,Jue,mbo,cbo,fj,fbo,gbo,hbo,Bh,Yue,ubo,pbo,gj,_bo,bbo,vbo,Ih,Zue,Fbo,Tbo,hj,Mbo,Ebo,Cbo,Nh,Kue,wbo,Abo,uj,Lbo,ybo,xbo,qh,epe,$bo,kbo,pj,Sbo,Rbo,Pbo,Dh,ope,Bbo,Ibo,_j,Nbo,qbo,Dbo,jh,rpe,jbo,Gbo,bj,Obo,Vbo,Xbo,Gh,tpe,zbo,Qbo,vj,Wbo,Ubo,Hbo,Oh,ape,Jbo,Ybo,Fj,Zbo,Kbo,evo,Vh,npe,ovo,rvo,Tj,tvo,avo,nvo,Xh,spe,svo,lvo,Mj,ivo,dvo,mvo,zh,lpe,cvo,fvo,Ej,gvo,hvo,uvo,Qh,ipe,pvo,_vo,Cj,bvo,vvo,Fvo,Wh,dpe,Tvo,Mvo,wj,Evo,Cvo,wvo,Uh,mpe,Avo,Lvo,Aj,yvo,xvo,$vo,Hh,cpe,kvo,Svo,Lj,Rvo,Pvo,Bvo,Jh,fpe,Ivo,Nvo,yj,qvo,Dvo,jvo,Yh,gpe,Gvo,Ovo,xj,Vvo,Xvo,zvo,Zh,hpe,Qvo,Wvo,$j,Uvo,Hvo,Jvo,Kh,upe,Yvo,Zvo,kj,Kvo,eFo,oFo,eu,ppe,rFo,tFo,Sj,aFo,nFo,sFo,ou,_pe,lFo,iFo,Rj,dFo,mFo,cFo,ru,bpe,fFo,gFo,Pj,hFo,uFo,pFo,tu,vpe,_Fo,bFo,Bj,vFo,FFo,TFo,au,Fpe,MFo,EFo,Ij,CFo,wFo,AFo,nu,Tpe,LFo,yFo,Nj,xFo,$Fo,kFo,su,Mpe,SFo,RFo,qj,PFo,BFo,IFo,lu,Epe,NFo,qFo,Dj,DFo,jFo,GFo,iu,Cpe,OFo,VFo,jj,XFo,zFo,QFo,du,wpe,WFo,UFo,Gj,HFo,JFo,YFo,mu,Ape,ZFo,KFo,Oj,eTo,oTo,rTo,cu,Lpe,tTo,aTo,Vj,nTo,sTo,lTo,fu,ype,iTo,dTo,Xj,mTo,cTo,fTo,gu,xpe,gTo,hTo,zj,uTo,pTo,_To,hu,$pe,bTo,vTo,Qj,FTo,TTo,MTo,uu,kpe,ETo,CTo,Wj,wTo,ATo,LTo,pu,Spe,yTo,xTo,Uj,$To,kTo,STo,_u,Rpe,RTo,PTo,Hj,BTo,ITo,NTo,bu,Ppe,qTo,DTo,Jj,jTo,GTo,OTo,vu,Bpe,VTo,XTo,Yj,zTo,QTo,WTo,Fu,Ipe,UTo,HTo,Zj,JTo,YTo,ZTo,Tu,Npe,KTo,eMo,Kj,oMo,rMo,tMo,Mu,qpe,aMo,nMo,eG,sMo,lMo,iMo,Eu,Dpe,dMo,mMo,oG,cMo,fMo,gMo,Cu,jpe,hMo,uMo,rG,pMo,_Mo,bMo,wu,Gpe,vMo,FMo,tG,TMo,MMo,EMo,Au,Ope,CMo,wMo,aG,AMo,LMo,yMo,Lu,Vpe,xMo,$Mo,nG,kMo,SMo,RMo,yu,Xpe,PMo,BMo,sG,IMo,NMo,qMo,xu,zpe,DMo,jMo,lG,GMo,OMo,VMo,$u,Qpe,XMo,zMo,iG,QMo,WMo,UMo,ku,Wpe,HMo,JMo,dG,YMo,ZMo,KMo,Su,Upe,eEo,oEo,mG,rEo,tEo,aEo,Ru,Hpe,nEo,sEo,cG,lEo,iEo,dEo,Pu,Jpe,mEo,cEo,fG,fEo,gEo,hEo,Bu,Ype,uEo,pEo,gG,_Eo,bEo,vEo,Iu,FEo,Nu,vk,TEo,Zpe,MEo,Elo,Id,qu,Kpe,Fk,EEo,e_e,CEo,Clo,Io,Tk,wEo,Mk,AEo,hG,LEo,yEo,xEo,Ek,$Eo,o_e,kEo,SEo,REo,Vr,Ck,PEo,r_e,BEo,IEo,dn,NEo,t_e,qEo,DEo,a_e,jEo,GEo,n_e,OEo,VEo,XEo,k,Ts,s_e,zEo,QEo,uG,WEo,UEo,pG,HEo,JEo,YEo,Ms,l_e,ZEo,KEo,_G,e4o,o4o,bG,r4o,t4o,a4o,Es,i_e,n4o,s4o,vG,l4o,i4o,FG,d4o,m4o,c4o,Du,d_e,f4o,g4o,TG,h4o,u4o,p4o,Cs,m_e,_4o,b4o,MG,v4o,F4o,EG,T4o,M4o,E4o,ju,c_e,C4o,w4o,CG,A4o,L4o,y4o,Gu,f_e,x4o,$4o,wG,k4o,S4o,R4o,Ou,g_e,P4o,B4o,AG,I4o,N4o,q4o,ws,h_e,D4o,j4o,LG,G4o,O4o,yG,V4o,X4o,z4o,As,u_e,Q4o,W4o,xG,U4o,H4o,$G,J4o,Y4o,Z4o,Ls,p_e,K4o,eCo,kG,oCo,rCo,SG,tCo,aCo,nCo,Vu,__e,sCo,lCo,RG,iCo,dCo,mCo,Xu,b_e,cCo,fCo,PG,gCo,hCo,uCo,zu,v_e,pCo,_Co,BG,bCo,vCo,FCo,ys,F_e,TCo,MCo,IG,ECo,CCo,NG,wCo,ACo,LCo,Qu,T_e,yCo,xCo,qG,$Co,kCo,SCo,xs,M_e,RCo,PCo,DG,BCo,ICo,jG,NCo,qCo,DCo,$s,E_e,jCo,GCo,GG,OCo,VCo,OG,XCo,zCo,QCo,ks,C_e,WCo,UCo,VG,HCo,JCo,XG,YCo,ZCo,KCo,Ss,w_e,e3o,o3o,zG,r3o,t3o,QG,a3o,n3o,s3o,Rs,A_e,l3o,i3o,WG,d3o,m3o,UG,c3o,f3o,g3o,Wu,L_e,h3o,u3o,HG,p3o,_3o,b3o,Ps,y_e,v3o,F3o,JG,T3o,M3o,YG,E3o,C3o,w3o,Bs,x_e,A3o,L3o,ZG,y3o,x3o,KG,$3o,k3o,S3o,Is,$_e,R3o,P3o,eO,B3o,I3o,oO,N3o,q3o,D3o,Ns,k_e,j3o,G3o,rO,O3o,V3o,tO,X3o,z3o,Q3o,qs,S_e,W3o,U3o,aO,H3o,J3o,nO,Y3o,Z3o,K3o,Ds,R_e,e5o,o5o,sO,r5o,t5o,lO,a5o,n5o,s5o,js,P_e,l5o,i5o,iO,d5o,m5o,dO,c5o,f5o,g5o,Uu,B_e,h5o,u5o,mO,p5o,_5o,b5o,Hu,I_e,v5o,F5o,cO,T5o,M5o,E5o,Gs,N_e,C5o,w5o,fO,A5o,L5o,gO,y5o,x5o,$5o,Ju,q_e,k5o,S5o,hO,R5o,P5o,B5o,Os,D_e,I5o,N5o,uO,q5o,D5o,pO,j5o,G5o,O5o,Vs,j_e,V5o,X5o,_O,z5o,Q5o,bO,W5o,U5o,H5o,Xs,G_e,J5o,Y5o,vO,Z5o,K5o,FO,e0o,o0o,r0o,Yu,O_e,t0o,a0o,TO,n0o,s0o,l0o,Zu,V_e,i0o,d0o,MO,m0o,c0o,f0o,zs,X_e,g0o,h0o,EO,u0o,p0o,CO,_0o,b0o,v0o,Qs,z_e,F0o,T0o,wO,M0o,E0o,AO,C0o,w0o,A0o,Ws,Q_e,L0o,y0o,LO,x0o,$0o,yO,k0o,S0o,R0o,Ku,W_e,P0o,B0o,xO,I0o,N0o,q0o,Us,U_e,D0o,j0o,$O,G0o,O0o,kO,V0o,X0o,z0o,Hs,H_e,Q0o,W0o,SO,U0o,H0o,RO,J0o,Y0o,Z0o,Js,J_e,K0o,ewo,PO,owo,rwo,BO,two,awo,nwo,Ys,Y_e,swo,lwo,IO,iwo,dwo,NO,mwo,cwo,fwo,Zs,Z_e,gwo,hwo,qO,uwo,pwo,DO,_wo,bwo,vwo,Ks,K_e,Fwo,Two,jO,Mwo,Ewo,GO,Cwo,wwo,Awo,el,e1e,Lwo,ywo,OO,xwo,$wo,VO,kwo,Swo,Rwo,ol,o1e,Pwo,Bwo,XO,Iwo,Nwo,zO,qwo,Dwo,jwo,rl,r1e,Gwo,Owo,QO,Vwo,Xwo,WO,zwo,Qwo,Wwo,ep,t1e,Uwo,Hwo,UO,Jwo,Ywo,Zwo,tl,a1e,Kwo,eAo,HO,oAo,rAo,JO,tAo,aAo,nAo,op,n1e,sAo,lAo,YO,iAo,dAo,mAo,rp,s1e,cAo,fAo,ZO,gAo,hAo,uAo,al,l1e,pAo,_Ao,KO,bAo,vAo,eV,FAo,TAo,MAo,nl,i1e,EAo,CAo,oV,wAo,AAo,rV,LAo,yAo,xAo,sl,d1e,$Ao,kAo,tV,SAo,RAo,aV,PAo,BAo,IAo,tp,m1e,NAo,qAo,nV,DAo,jAo,GAo,ll,c1e,OAo,VAo,sV,XAo,zAo,lV,QAo,WAo,UAo,il,f1e,HAo,JAo,iV,YAo,ZAo,dV,KAo,e6o,o6o,dl,g1e,r6o,t6o,mV,a6o,n6o,cV,s6o,l6o,i6o,ml,h1e,d6o,m6o,fV,c6o,f6o,gV,g6o,h6o,u6o,cl,u1e,p6o,_6o,hV,b6o,v6o,uV,F6o,T6o,M6o,fl,p1e,E6o,C6o,pV,w6o,A6o,_V,L6o,y6o,x6o,gl,_1e,$6o,k6o,bV,S6o,R6o,vV,P6o,B6o,I6o,hl,b1e,N6o,q6o,FV,D6o,j6o,TV,G6o,O6o,V6o,ap,v1e,X6o,z6o,MV,Q6o,W6o,U6o,ul,F1e,H6o,J6o,EV,Y6o,Z6o,CV,K6o,e7o,o7o,pl,T1e,r7o,t7o,wV,a7o,n7o,AV,s7o,l7o,i7o,_l,M1e,d7o,m7o,LV,c7o,f7o,yV,g7o,h7o,u7o,np,E1e,p7o,_7o,xV,b7o,v7o,F7o,sp,C1e,T7o,M7o,$V,E7o,C7o,w7o,lp,w1e,A7o,L7o,kV,y7o,x7o,$7o,ip,A1e,k7o,S7o,SV,R7o,P7o,B7o,bl,L1e,I7o,N7o,RV,q7o,D7o,PV,j7o,G7o,O7o,dp,y1e,V7o,X7o,BV,z7o,Q7o,W7o,vl,x1e,U7o,H7o,IV,J7o,Y7o,NV,Z7o,K7o,e8o,Fl,$1e,o8o,r8o,qV,t8o,a8o,DV,n8o,s8o,l8o,Tl,k1e,i8o,d8o,jV,m8o,c8o,GV,f8o,g8o,h8o,Ml,S1e,u8o,p8o,OV,_8o,b8o,VV,v8o,F8o,T8o,El,R1e,M8o,E8o,XV,C8o,w8o,zV,A8o,L8o,y8o,mp,P1e,x8o,$8o,QV,k8o,S8o,R8o,Cl,B1e,P8o,B8o,WV,I8o,N8o,UV,q8o,D8o,j8o,cp,I1e,G8o,O8o,HV,V8o,X8o,z8o,fp,N1e,Q8o,W8o,JV,U8o,H8o,J8o,wl,q1e,Y8o,Z8o,YV,K8o,eLo,ZV,oLo,rLo,tLo,Al,D1e,aLo,nLo,KV,sLo,lLo,eX,iLo,dLo,mLo,Ll,j1e,cLo,fLo,oX,gLo,hLo,rX,uLo,pLo,_Lo,gp,G1e,bLo,vLo,tX,FLo,TLo,MLo,hp,O1e,ELo,CLo,aX,wLo,ALo,LLo,up,V1e,yLo,xLo,nX,$Lo,kLo,SLo,yl,X1e,RLo,PLo,sX,BLo,ILo,lX,NLo,qLo,DLo,xl,z1e,jLo,GLo,iX,OLo,VLo,dX,XLo,zLo,QLo,pp,Q1e,WLo,ULo,mX,HLo,JLo,YLo,_p,W1e,ZLo,KLo,cX,eyo,oyo,ryo,bp,U1e,tyo,ayo,fX,nyo,syo,lyo,vp,H1e,iyo,dyo,gX,myo,cyo,fyo,$l,J1e,gyo,hyo,hX,uyo,pyo,uX,_yo,byo,vyo,kl,Y1e,Fyo,Tyo,pX,Myo,Eyo,_X,Cyo,wyo,Ayo,Fp,Z1e,Lyo,yyo,bX,xyo,$yo,kyo,Tp,K1e,Syo,Ryo,vX,Pyo,Byo,Iyo,Sl,e2e,Nyo,qyo,FX,Dyo,jyo,TX,Gyo,Oyo,Vyo,Rl,o2e,Xyo,zyo,MX,Qyo,Wyo,EX,Uyo,Hyo,Jyo,Pl,r2e,Yyo,Zyo,CX,Kyo,e9o,wX,o9o,r9o,t9o,Bl,t2e,a9o,n9o,AX,s9o,l9o,LX,i9o,d9o,m9o,Mp,c9o,Ep,wk,f9o,a2e,g9o,wlo,Nd,Cp,n2e,Ak,h9o,s2e,u9o,Alo,No,Lk,p9o,yk,_9o,yX,b9o,v9o,F9o,xk,T9o,l2e,M9o,E9o,C9o,eo,$k,w9o,i2e,A9o,L9o,mn,y9o,d2e,x9o,$9o,m2e,k9o,S9o,c2e,R9o,P9o,B9o,z,wp,f2e,I9o,N9o,xX,q9o,D9o,j9o,Ap,g2e,G9o,O9o,$X,V9o,X9o,z9o,Lp,h2e,Q9o,W9o,kX,U9o,H9o,J9o,yp,u2e,Y9o,Z9o,SX,K9o,exo,oxo,xp,p2e,rxo,txo,RX,axo,nxo,sxo,$p,_2e,lxo,ixo,PX,dxo,mxo,cxo,kp,b2e,fxo,gxo,BX,hxo,uxo,pxo,Sp,v2e,_xo,bxo,IX,vxo,Fxo,Txo,Rp,F2e,Mxo,Exo,NX,Cxo,wxo,Axo,Pp,T2e,Lxo,yxo,qX,xxo,$xo,kxo,Bp,M2e,Sxo,Rxo,DX,Pxo,Bxo,Ixo,Ip,E2e,Nxo,qxo,jX,Dxo,jxo,Gxo,Np,C2e,Oxo,Vxo,GX,Xxo,zxo,Qxo,qp,w2e,Wxo,Uxo,OX,Hxo,Jxo,Yxo,Dp,A2e,Zxo,Kxo,VX,e$o,o$o,r$o,jp,L2e,t$o,a$o,XX,n$o,s$o,l$o,Gp,y2e,i$o,d$o,zX,m$o,c$o,f$o,Op,x2e,g$o,h$o,QX,u$o,p$o,_$o,Vp,$2e,b$o,v$o,WX,F$o,T$o,M$o,Xp,k2e,E$o,C$o,UX,w$o,A$o,L$o,zp,S2e,y$o,x$o,HX,$$o,k$o,S$o,Qp,R2e,R$o,P$o,JX,B$o,I$o,N$o,Wp,P2e,q$o,D$o,YX,j$o,G$o,O$o,Up,B2e,V$o,X$o,ZX,z$o,Q$o,W$o,Hp,I2e,U$o,H$o,KX,J$o,Y$o,Z$o,Jp,N2e,K$o,eko,ez,oko,rko,tko,Yp,q2e,ako,nko,oz,sko,lko,iko,Zp,D2e,dko,mko,rz,cko,fko,gko,Kp,j2e,hko,uko,tz,pko,_ko,bko,e_,G2e,vko,Fko,az,Tko,Mko,Eko,o_,O2e,Cko,wko,nz,Ako,Lko,yko,r_,V2e,xko,$ko,sz,kko,Sko,Rko,t_,X2e,Pko,Bko,lz,Iko,Nko,qko,a_,z2e,Dko,jko,iz,Gko,Oko,Vko,n_,Q2e,Xko,zko,dz,Qko,Wko,Uko,s_,W2e,Hko,Jko,mz,Yko,Zko,Kko,l_,U2e,eSo,oSo,cz,rSo,tSo,aSo,i_,H2e,nSo,sSo,fz,lSo,iSo,dSo,d_,J2e,mSo,cSo,gz,fSo,gSo,hSo,m_,Y2e,uSo,pSo,hz,_So,bSo,vSo,c_,Z2e,FSo,TSo,uz,MSo,ESo,CSo,f_,K2e,wSo,ASo,pz,LSo,ySo,xSo,g_,ebe,$So,kSo,_z,SSo,RSo,PSo,h_,obe,BSo,ISo,bz,NSo,qSo,DSo,u_,rbe,jSo,GSo,vz,OSo,VSo,XSo,p_,zSo,__,QSo,b_,kk,WSo,tbe,USo,Llo,qd,v_,abe,Sk,HSo,nbe,JSo,ylo,qo,Rk,YSo,Pk,ZSo,Fz,KSo,eRo,oRo,Bk,rRo,sbe,tRo,aRo,nRo,oo,Ik,sRo,lbe,lRo,iRo,cn,dRo,ibe,mRo,cRo,dbe,fRo,gRo,mbe,hRo,uRo,pRo,re,F_,cbe,_Ro,bRo,Tz,vRo,FRo,TRo,T_,fbe,MRo,ERo,Mz,CRo,wRo,ARo,M_,gbe,LRo,yRo,Ez,xRo,$Ro,kRo,E_,hbe,SRo,RRo,Cz,PRo,BRo,IRo,C_,ube,NRo,qRo,wz,DRo,jRo,GRo,w_,pbe,ORo,VRo,Az,XRo,zRo,QRo,A_,_be,WRo,URo,Lz,HRo,JRo,YRo,L_,bbe,ZRo,KRo,yz,ePo,oPo,rPo,y_,vbe,tPo,aPo,xz,nPo,sPo,lPo,x_,Fbe,iPo,dPo,$z,mPo,cPo,fPo,$_,Tbe,gPo,hPo,kz,uPo,pPo,_Po,k_,Mbe,bPo,vPo,Sz,FPo,TPo,MPo,S_,Ebe,EPo,CPo,Rz,wPo,APo,LPo,R_,Cbe,yPo,xPo,Pz,$Po,kPo,SPo,P_,wbe,RPo,PPo,Bz,BPo,IPo,NPo,B_,Abe,qPo,DPo,Iz,jPo,GPo,OPo,I_,Lbe,VPo,XPo,Nz,zPo,QPo,WPo,N_,ybe,UPo,HPo,qz,JPo,YPo,ZPo,q_,xbe,KPo,eBo,Dz,oBo,rBo,tBo,D_,$be,aBo,nBo,jz,sBo,lBo,iBo,j_,kbe,dBo,mBo,Gz,cBo,fBo,gBo,G_,Sbe,hBo,uBo,Oz,pBo,_Bo,bBo,O_,Rbe,vBo,FBo,Vz,TBo,MBo,EBo,V_,Pbe,CBo,wBo,Xz,ABo,LBo,yBo,X_,Bbe,xBo,$Bo,zz,kBo,SBo,RBo,z_,Ibe,PBo,BBo,Qz,IBo,NBo,qBo,Q_,Nbe,DBo,jBo,Wz,GBo,OBo,VBo,W_,qbe,XBo,zBo,Uz,QBo,WBo,UBo,U_,Dbe,HBo,JBo,Hz,YBo,ZBo,KBo,H_,eIo,J_,oIo,Y_,Nk,rIo,jbe,tIo,xlo,Dd,Z_,Gbe,qk,aIo,Obe,nIo,$lo,Do,Dk,sIo,jk,lIo,Jz,iIo,dIo,mIo,Gk,cIo,Vbe,fIo,gIo,hIo,ro,Ok,uIo,Xbe,pIo,_Io,jd,bIo,zbe,vIo,FIo,Qbe,TIo,MIo,EIo,ie,K_,Wbe,CIo,wIo,Yz,AIo,LIo,yIo,e1,Ube,xIo,$Io,Zz,kIo,SIo,RIo,o1,Hbe,PIo,BIo,Kz,IIo,NIo,qIo,r1,Jbe,DIo,jIo,eQ,GIo,OIo,VIo,t1,Ybe,XIo,zIo,oQ,QIo,WIo,UIo,a1,Zbe,HIo,JIo,rQ,YIo,ZIo,KIo,n1,Kbe,eNo,oNo,tQ,rNo,tNo,aNo,s1,eve,nNo,sNo,aQ,lNo,iNo,dNo,l1,ove,mNo,cNo,nQ,fNo,gNo,hNo,i1,rve,uNo,pNo,sQ,_No,bNo,vNo,d1,tve,FNo,TNo,lQ,MNo,ENo,CNo,m1,ave,wNo,ANo,iQ,LNo,yNo,xNo,c1,nve,$No,kNo,dQ,SNo,RNo,PNo,f1,sve,BNo,INo,mQ,NNo,qNo,DNo,g1,lve,jNo,GNo,cQ,ONo,VNo,XNo,h1,ive,zNo,QNo,fQ,WNo,UNo,HNo,u1,dve,JNo,YNo,gQ,ZNo,KNo,eqo,p1,mve,oqo,rqo,hQ,tqo,aqo,nqo,_1,cve,sqo,lqo,uQ,iqo,dqo,mqo,b1,fve,cqo,fqo,pQ,gqo,hqo,uqo,v1,gve,pqo,_qo,_Q,bqo,vqo,Fqo,F1,hve,Tqo,Mqo,bQ,Eqo,Cqo,wqo,T1,uve,Aqo,Lqo,vQ,yqo,xqo,$qo,M1,kqo,E1,Sqo,C1,Vk,Rqo,pve,Pqo,klo,Gd,w1,_ve,Xk,Bqo,bve,Iqo,Slo,jo,zk,Nqo,Od,qqo,FQ,Dqo,jqo,TQ,Gqo,Oqo,Vqo,Qk,Xqo,vve,zqo,Qqo,Wqo,At,Wk,Uqo,Fve,Hqo,Jqo,Vd,Yqo,Tve,Zqo,Kqo,MQ,eDo,oDo,rDo,A1,tDo,to,Uk,aDo,Mve,nDo,sDo,fn,lDo,Eve,iDo,dDo,Cve,mDo,cDo,wve,fDo,gDo,hDo,y,L1,Ave,uDo,pDo,EQ,_Do,bDo,vDo,y1,Lve,FDo,TDo,CQ,MDo,EDo,CDo,x1,yve,wDo,ADo,wQ,LDo,yDo,xDo,$1,xve,$Do,kDo,AQ,SDo,RDo,PDo,k1,$ve,BDo,IDo,LQ,NDo,qDo,DDo,S1,kve,jDo,GDo,yQ,ODo,VDo,XDo,R1,Sve,zDo,QDo,xQ,WDo,UDo,HDo,P1,Rve,JDo,YDo,$Q,ZDo,KDo,ejo,B1,Pve,ojo,rjo,kQ,tjo,ajo,njo,I1,Bve,sjo,ljo,SQ,ijo,djo,mjo,N1,Ive,cjo,fjo,RQ,gjo,hjo,ujo,q1,Nve,pjo,_jo,PQ,bjo,vjo,Fjo,D1,qve,Tjo,Mjo,BQ,Ejo,Cjo,wjo,j1,Dve,Ajo,Ljo,IQ,yjo,xjo,$jo,G1,jve,kjo,Sjo,NQ,Rjo,Pjo,Bjo,O1,Gve,Ijo,Njo,qQ,qjo,Djo,jjo,V1,Ove,Gjo,Ojo,DQ,Vjo,Xjo,zjo,X1,Vve,Qjo,Wjo,jQ,Ujo,Hjo,Jjo,z1,Xve,Yjo,Zjo,GQ,Kjo,eGo,oGo,Q1,zve,rGo,tGo,OQ,aGo,nGo,sGo,W1,Qve,lGo,iGo,VQ,dGo,mGo,cGo,U1,Wve,fGo,gGo,XQ,hGo,uGo,pGo,H1,Uve,_Go,bGo,zQ,vGo,FGo,TGo,J1,Hve,MGo,EGo,QQ,CGo,wGo,AGo,Y1,Jve,LGo,yGo,WQ,xGo,$Go,kGo,Z1,Yve,SGo,RGo,UQ,PGo,BGo,IGo,K1,Zve,NGo,qGo,HQ,DGo,jGo,GGo,e2,Kve,OGo,VGo,JQ,XGo,zGo,QGo,o2,eFe,WGo,UGo,YQ,HGo,JGo,YGo,r2,oFe,ZGo,KGo,ZQ,eOo,oOo,rOo,t2,rFe,tOo,aOo,KQ,nOo,sOo,lOo,a2,tFe,iOo,dOo,eW,mOo,cOo,fOo,n2,aFe,gOo,hOo,oW,uOo,pOo,_Oo,s2,nFe,bOo,vOo,rW,FOo,TOo,MOo,l2,sFe,EOo,COo,tW,wOo,AOo,LOo,i2,lFe,yOo,xOo,aW,$Oo,kOo,SOo,d2,iFe,ROo,POo,nW,BOo,IOo,NOo,m2,dFe,qOo,DOo,sW,jOo,GOo,OOo,c2,mFe,VOo,XOo,lW,zOo,QOo,WOo,f2,cFe,UOo,HOo,iW,JOo,YOo,ZOo,Il,fFe,KOo,eVo,dW,oVo,rVo,mW,tVo,aVo,nVo,g2,gFe,sVo,lVo,cW,iVo,dVo,mVo,h2,hFe,cVo,fVo,fW,gVo,hVo,uVo,u2,uFe,pVo,_Vo,gW,bVo,vVo,FVo,p2,pFe,TVo,MVo,hW,EVo,CVo,wVo,_2,_Fe,AVo,LVo,uW,yVo,xVo,$Vo,b2,bFe,kVo,SVo,pW,RVo,PVo,BVo,v2,vFe,IVo,NVo,_W,qVo,DVo,jVo,F2,FFe,GVo,OVo,bW,VVo,XVo,zVo,T2,TFe,QVo,WVo,vW,UVo,HVo,JVo,M2,MFe,YVo,ZVo,FW,KVo,eXo,oXo,E2,EFe,rXo,tXo,TW,aXo,nXo,sXo,C2,CFe,lXo,iXo,MW,dXo,mXo,cXo,w2,wFe,fXo,gXo,EW,hXo,uXo,pXo,A2,AFe,_Xo,bXo,CW,vXo,FXo,TXo,L2,LFe,MXo,EXo,wW,CXo,wXo,AXo,y2,yFe,LXo,yXo,AW,xXo,$Xo,kXo,x2,xFe,SXo,RXo,LW,PXo,BXo,IXo,$2,$Fe,NXo,qXo,yW,DXo,jXo,GXo,k2,kFe,OXo,VXo,xW,XXo,zXo,QXo,S2,SFe,WXo,UXo,$W,HXo,JXo,YXo,R2,RFe,ZXo,KXo,kW,ezo,ozo,rzo,P2,PFe,tzo,azo,SW,nzo,szo,lzo,B2,BFe,izo,dzo,RW,mzo,czo,fzo,I2,IFe,gzo,hzo,PW,uzo,pzo,_zo,N2,NFe,bzo,vzo,BW,Fzo,Tzo,Mzo,q2,qFe,Ezo,Czo,IW,wzo,Azo,Lzo,D2,DFe,yzo,xzo,NW,$zo,kzo,Szo,j2,jFe,Rzo,Pzo,qW,Bzo,Izo,Nzo,G2,GFe,qzo,Dzo,DW,jzo,Gzo,Ozo,O2,OFe,Vzo,Xzo,jW,zzo,Qzo,Wzo,V2,VFe,Uzo,Hzo,GW,Jzo,Yzo,Zzo,X2,XFe,Kzo,eQo,OW,oQo,rQo,tQo,z2,zFe,aQo,nQo,VW,sQo,lQo,iQo,Q2,QFe,dQo,mQo,XW,cQo,fQo,gQo,W2,WFe,hQo,uQo,zW,pQo,_Qo,bQo,U2,UFe,vQo,FQo,QW,TQo,MQo,EQo,H2,HFe,CQo,wQo,WW,AQo,LQo,yQo,J2,JFe,xQo,$Qo,UW,kQo,SQo,RQo,Y2,YFe,PQo,BQo,HW,IQo,NQo,qQo,Z2,ZFe,DQo,jQo,JW,GQo,OQo,VQo,K2,KFe,XQo,zQo,YW,QQo,WQo,UQo,eb,eTe,HQo,JQo,ZW,YQo,ZQo,KQo,ob,oTe,eWo,oWo,KW,rWo,tWo,aWo,rb,rTe,nWo,sWo,eU,lWo,iWo,dWo,tb,tTe,mWo,cWo,oU,fWo,gWo,hWo,ab,aTe,uWo,pWo,rU,_Wo,bWo,vWo,nb,nTe,FWo,TWo,tU,MWo,EWo,CWo,sb,sTe,wWo,AWo,aU,LWo,yWo,xWo,lb,lTe,$Wo,kWo,nU,SWo,RWo,PWo,ib,iTe,BWo,IWo,sU,NWo,qWo,DWo,db,dTe,jWo,GWo,lU,OWo,VWo,XWo,mb,mTe,zWo,QWo,iU,WWo,UWo,HWo,cb,cTe,JWo,YWo,dU,ZWo,KWo,eUo,fb,fTe,oUo,rUo,mU,tUo,aUo,nUo,gb,gTe,sUo,lUo,cU,iUo,dUo,mUo,hb,hTe,cUo,fUo,fU,gUo,hUo,uUo,ub,uTe,pUo,_Uo,gU,bUo,vUo,FUo,pb,pTe,TUo,MUo,hU,EUo,CUo,wUo,_b,_Te,AUo,LUo,uU,yUo,xUo,$Uo,bb,bTe,kUo,SUo,pU,RUo,PUo,BUo,vb,vTe,IUo,NUo,_U,qUo,DUo,jUo,Fb,FTe,GUo,OUo,bU,VUo,XUo,zUo,Tb,TTe,QUo,WUo,vU,UUo,HUo,JUo,Mb,MTe,YUo,ZUo,FU,KUo,eHo,oHo,Eb,ETe,rHo,tHo,TU,aHo,nHo,sHo,Cb,CTe,lHo,iHo,MU,dHo,mHo,cHo,wb,wTe,fHo,gHo,EU,hHo,uHo,pHo,Ab,ATe,_Ho,bHo,CU,vHo,FHo,THo,Lb,LTe,MHo,EHo,wU,CHo,wHo,AHo,yb,yTe,LHo,yHo,AU,xHo,$Ho,kHo,xb,xTe,SHo,RHo,LU,PHo,BHo,IHo,$b,$Te,NHo,qHo,yU,DHo,jHo,GHo,kb,kTe,OHo,VHo,xU,XHo,zHo,QHo,Sb,STe,WHo,UHo,$U,HHo,JHo,YHo,Rb,RTe,ZHo,KHo,kU,eJo,oJo,rJo,Pb,PTe,tJo,aJo,SU,nJo,sJo,lJo,Bb,BTe,iJo,dJo,RU,mJo,cJo,fJo,Ib,ITe,gJo,hJo,PU,uJo,pJo,_Jo,Nb,NTe,bJo,vJo,BU,FJo,TJo,MJo,qb,qTe,EJo,CJo,IU,wJo,AJo,LJo,Db,DTe,yJo,xJo,NU,$Jo,kJo,SJo,jb,jTe,RJo,PJo,qU,BJo,IJo,NJo,Gb,GTe,qJo,DJo,DU,jJo,GJo,OJo,Ob,OTe,VJo,XJo,jU,zJo,QJo,WJo,Vb,VTe,UJo,HJo,GU,JJo,YJo,ZJo,Xb,XTe,KJo,eYo,OU,oYo,rYo,tYo,zb,zTe,aYo,nYo,VU,sYo,lYo,iYo,Qb,QTe,dYo,mYo,XU,cYo,fYo,gYo,Wb,WTe,hYo,uYo,zU,pYo,_Yo,bYo,Ub,UTe,vYo,FYo,QU,TYo,MYo,EYo,Hb,CYo,HTe,wYo,AYo,JTe,LYo,yYo,Jb,Rlo,Xd,Yb,YTe,Hk,xYo,ZTe,$Yo,Plo,Go,Jk,kYo,zd,SYo,WU,RYo,PYo,UU,BYo,IYo,NYo,Yk,qYo,KTe,DYo,jYo,GYo,Lt,Zk,OYo,eMe,VYo,XYo,Qd,zYo,oMe,QYo,WYo,HU,UYo,HYo,JYo,Zb,YYo,ao,Kk,ZYo,rMe,KYo,eZo,gn,oZo,tMe,rZo,tZo,aMe,aZo,nZo,nMe,sZo,lZo,iZo,G,Kb,sMe,dZo,mZo,JU,cZo,fZo,gZo,ev,lMe,hZo,uZo,YU,pZo,_Zo,bZo,ov,iMe,vZo,FZo,ZU,TZo,MZo,EZo,rv,dMe,CZo,wZo,KU,AZo,LZo,yZo,tv,mMe,xZo,$Zo,eH,kZo,SZo,RZo,av,cMe,PZo,BZo,oH,IZo,NZo,qZo,nv,fMe,DZo,jZo,rH,GZo,OZo,VZo,sv,gMe,XZo,zZo,tH,QZo,WZo,UZo,lv,hMe,HZo,JZo,aH,YZo,ZZo,KZo,iv,uMe,eKo,oKo,nH,rKo,tKo,aKo,dv,pMe,nKo,sKo,sH,lKo,iKo,dKo,mv,_Me,mKo,cKo,lH,fKo,gKo,hKo,cv,bMe,uKo,pKo,iH,_Ko,bKo,vKo,fv,vMe,FKo,TKo,dH,MKo,EKo,CKo,gv,FMe,wKo,AKo,mH,LKo,yKo,xKo,hv,TMe,$Ko,kKo,cH,SKo,RKo,PKo,uv,MMe,BKo,IKo,fH,NKo,qKo,DKo,pv,EMe,jKo,GKo,gH,OKo,VKo,XKo,_v,CMe,zKo,QKo,hH,WKo,UKo,HKo,bv,wMe,JKo,YKo,uH,ZKo,KKo,eer,vv,AMe,oer,rer,pH,ter,aer,ner,Fv,LMe,ser,ler,_H,ier,der,mer,Tv,yMe,cer,fer,bH,ger,her,uer,Mv,xMe,per,_er,vH,ber,ver,Fer,Ev,$Me,Ter,Mer,FH,Eer,Cer,wer,Cv,kMe,Aer,Ler,TH,yer,xer,$er,wv,SMe,ker,Ser,MH,Rer,Per,Ber,Av,RMe,Ier,Ner,EH,qer,Der,jer,Lv,PMe,Ger,Oer,CH,Ver,Xer,zer,yv,BMe,Qer,Wer,wH,Uer,Her,Jer,xv,IMe,Yer,Zer,AH,Ker,eor,oor,$v,NMe,ror,tor,LH,aor,nor,sor,kv,qMe,lor,ior,yH,dor,mor,cor,Sv,DMe,gor,hor,xH,uor,por,_or,Rv,jMe,bor,vor,$H,For,Tor,Mor,Pv,GMe,Eor,Cor,kH,wor,Aor,Lor,Bv,OMe,yor,xor,SH,$or,kor,Sor,Iv,VMe,Ror,Por,RH,Bor,Ior,Nor,Nv,XMe,qor,Dor,PH,jor,Gor,Oor,qv,zMe,Vor,Xor,BH,zor,Qor,Wor,Dv,QMe,Uor,Hor,IH,Jor,Yor,Zor,jv,WMe,Kor,err,NH,orr,rrr,trr,Gv,UMe,arr,nrr,qH,srr,lrr,irr,Ov,HMe,drr,mrr,DH,crr,frr,grr,Vv,JMe,hrr,urr,jH,prr,_rr,brr,Xv,YMe,vrr,Frr,GH,Trr,Mrr,Err,zv,ZMe,Crr,wrr,OH,Arr,Lrr,yrr,Qv,KMe,xrr,$rr,VH,krr,Srr,Rrr,Wv,eEe,Prr,Brr,XH,Irr,Nrr,qrr,Uv,Drr,oEe,jrr,Grr,rEe,Orr,Vrr,Hv,Blo,Wd,Jv,tEe,eS,Xrr,aEe,zrr,Ilo,Oo,oS,Qrr,Ud,Wrr,zH,Urr,Hrr,QH,Jrr,Yrr,Zrr,rS,Krr,nEe,etr,otr,rtr,yt,tS,ttr,sEe,atr,ntr,Hd,str,lEe,ltr,itr,WH,dtr,mtr,ctr,Yv,ftr,no,aS,gtr,iEe,htr,utr,hn,ptr,dEe,_tr,btr,mEe,vtr,Ftr,cEe,Ttr,Mtr,Etr,W,Zv,fEe,Ctr,wtr,UH,Atr,Ltr,ytr,Kv,gEe,xtr,$tr,HH,ktr,Str,Rtr,eF,hEe,Ptr,Btr,JH,Itr,Ntr,qtr,oF,uEe,Dtr,jtr,YH,Gtr,Otr,Vtr,rF,pEe,Xtr,ztr,ZH,Qtr,Wtr,Utr,tF,_Ee,Htr,Jtr,KH,Ytr,Ztr,Ktr,aF,bEe,ear,oar,eJ,rar,tar,aar,nF,vEe,nar,sar,oJ,lar,iar,dar,sF,FEe,mar,car,rJ,far,gar,har,lF,TEe,uar,par,tJ,_ar,bar,Far,iF,MEe,Tar,Mar,aJ,Ear,Car,war,dF,EEe,Aar,Lar,nJ,yar,xar,$ar,mF,CEe,kar,Sar,sJ,Rar,Par,Bar,cF,wEe,Iar,Nar,lJ,qar,Dar,jar,fF,AEe,Gar,Oar,iJ,Var,Xar,zar,gF,LEe,Qar,War,dJ,Uar,Har,Jar,hF,yEe,Yar,Zar,mJ,Kar,enr,onr,uF,xEe,rnr,tnr,cJ,anr,nnr,snr,pF,$Ee,lnr,inr,fJ,dnr,mnr,cnr,_F,kEe,fnr,gnr,gJ,hnr,unr,pnr,bF,SEe,_nr,bnr,hJ,vnr,Fnr,Tnr,vF,REe,Mnr,Enr,uJ,Cnr,wnr,Anr,FF,PEe,Lnr,ynr,pJ,xnr,$nr,knr,TF,BEe,Snr,Rnr,_J,Pnr,Bnr,Inr,MF,IEe,Nnr,qnr,bJ,Dnr,jnr,Gnr,EF,NEe,Onr,Vnr,vJ,Xnr,znr,Qnr,CF,qEe,Wnr,Unr,FJ,Hnr,Jnr,Ynr,wF,DEe,Znr,Knr,TJ,esr,osr,rsr,AF,jEe,tsr,asr,MJ,nsr,ssr,lsr,LF,GEe,isr,dsr,EJ,msr,csr,fsr,yF,OEe,gsr,hsr,CJ,usr,psr,_sr,xF,VEe,bsr,vsr,wJ,Fsr,Tsr,Msr,$F,XEe,Esr,Csr,AJ,wsr,Asr,Lsr,kF,zEe,ysr,xsr,LJ,$sr,ksr,Ssr,SF,QEe,Rsr,Psr,yJ,Bsr,Isr,Nsr,RF,WEe,qsr,Dsr,xJ,jsr,Gsr,Osr,PF,UEe,Vsr,Xsr,$J,zsr,Qsr,Wsr,BF,HEe,Usr,Hsr,kJ,Jsr,Ysr,Zsr,IF,JEe,Ksr,elr,SJ,olr,rlr,tlr,NF,YEe,alr,nlr,RJ,slr,llr,ilr,qF,ZEe,dlr,mlr,PJ,clr,flr,glr,DF,KEe,hlr,ulr,BJ,plr,_lr,blr,jF,e4e,vlr,Flr,IJ,Tlr,Mlr,Elr,GF,Clr,o4e,wlr,Alr,r4e,Llr,ylr,OF,Nlo,Jd,VF,t4e,nS,xlr,a4e,$lr,qlo,Vo,sS,klr,Yd,Slr,NJ,Rlr,Plr,qJ,Blr,Ilr,Nlr,lS,qlr,n4e,Dlr,jlr,Glr,xt,iS,Olr,s4e,Vlr,Xlr,Zd,zlr,l4e,Qlr,Wlr,DJ,Ulr,Hlr,Jlr,XF,Ylr,so,dS,Zlr,i4e,Klr,eir,un,oir,d4e,rir,tir,m4e,air,nir,c4e,sir,lir,iir,mS,zF,f4e,dir,mir,jJ,cir,fir,gir,QF,g4e,hir,uir,GJ,pir,_ir,bir,WF,vir,h4e,Fir,Tir,u4e,Mir,Eir,UF,Dlo,Kd,HF,p4e,cS,Cir,_4e,wir,jlo,Xo,fS,Air,em,Lir,OJ,yir,xir,VJ,$ir,kir,Sir,gS,Rir,b4e,Pir,Bir,Iir,$t,hS,Nir,v4e,qir,Dir,om,jir,F4e,Gir,Oir,XJ,Vir,Xir,zir,JF,Qir,lo,uS,Wir,T4e,Uir,Hir,pn,Jir,M4e,Yir,Zir,E4e,Kir,edr,C4e,odr,rdr,tdr,Y,YF,w4e,adr,ndr,zJ,sdr,ldr,idr,ZF,A4e,ddr,mdr,QJ,cdr,fdr,gdr,KF,L4e,hdr,udr,WJ,pdr,_dr,bdr,eT,y4e,vdr,Fdr,UJ,Tdr,Mdr,Edr,oT,x4e,Cdr,wdr,HJ,Adr,Ldr,ydr,rT,$4e,xdr,$dr,JJ,kdr,Sdr,Rdr,tT,k4e,Pdr,Bdr,YJ,Idr,Ndr,qdr,aT,S4e,Ddr,jdr,ZJ,Gdr,Odr,Vdr,nT,R4e,Xdr,zdr,KJ,Qdr,Wdr,Udr,sT,P4e,Hdr,Jdr,eY,Ydr,Zdr,Kdr,lT,B4e,emr,omr,oY,rmr,tmr,amr,iT,I4e,nmr,smr,rY,lmr,imr,dmr,dT,N4e,mmr,cmr,tY,fmr,gmr,hmr,mT,q4e,umr,pmr,aY,_mr,bmr,vmr,cT,D4e,Fmr,Tmr,nY,Mmr,Emr,Cmr,fT,j4e,wmr,Amr,sY,Lmr,ymr,xmr,gT,G4e,$mr,kmr,lY,Smr,Rmr,Pmr,hT,O4e,Bmr,Imr,iY,Nmr,qmr,Dmr,uT,V4e,jmr,Gmr,dY,Omr,Vmr,Xmr,pT,X4e,zmr,Qmr,mY,Wmr,Umr,Hmr,_T,z4e,Jmr,Ymr,cY,Zmr,Kmr,ecr,bT,Q4e,ocr,rcr,fY,tcr,acr,ncr,vT,W4e,scr,lcr,gY,icr,dcr,mcr,FT,U4e,ccr,fcr,hY,gcr,hcr,ucr,TT,H4e,pcr,_cr,uY,bcr,vcr,Fcr,MT,J4e,Tcr,Mcr,pY,Ecr,Ccr,wcr,ET,Y4e,Acr,Lcr,_Y,ycr,xcr,$cr,CT,Z4e,kcr,Scr,bY,Rcr,Pcr,Bcr,wT,K4e,Icr,Ncr,vY,qcr,Dcr,jcr,AT,eCe,Gcr,Ocr,FY,Vcr,Xcr,zcr,LT,oCe,Qcr,Wcr,TY,Ucr,Hcr,Jcr,yT,rCe,Ycr,Zcr,MY,Kcr,efr,ofr,xT,tCe,rfr,tfr,EY,afr,nfr,sfr,$T,aCe,lfr,ifr,CY,dfr,mfr,cfr,kT,nCe,ffr,gfr,wY,hfr,ufr,pfr,ST,sCe,_fr,bfr,lCe,vfr,Ffr,Tfr,RT,iCe,Mfr,Efr,AY,Cfr,wfr,Afr,PT,dCe,Lfr,yfr,LY,xfr,$fr,kfr,BT,mCe,Sfr,Rfr,yY,Pfr,Bfr,Ifr,IT,cCe,Nfr,qfr,xY,Dfr,jfr,Gfr,NT,Ofr,fCe,Vfr,Xfr,gCe,zfr,Qfr,qT,Glo,rm,DT,hCe,pS,Wfr,uCe,Ufr,Olo,zo,_S,Hfr,tm,Jfr,$Y,Yfr,Zfr,kY,Kfr,egr,ogr,bS,rgr,pCe,tgr,agr,ngr,kt,vS,sgr,_Ce,lgr,igr,am,dgr,bCe,mgr,cgr,SY,fgr,ggr,hgr,jT,ugr,io,FS,pgr,vCe,_gr,bgr,_n,vgr,FCe,Fgr,Tgr,TCe,Mgr,Egr,MCe,Cgr,wgr,Agr,pe,GT,ECe,Lgr,ygr,RY,xgr,$gr,kgr,OT,CCe,Sgr,Rgr,PY,Pgr,Bgr,Igr,VT,wCe,Ngr,qgr,BY,Dgr,jgr,Ggr,XT,ACe,Ogr,Vgr,IY,Xgr,zgr,Qgr,zT,LCe,Wgr,Ugr,NY,Hgr,Jgr,Ygr,QT,yCe,Zgr,Kgr,qY,ehr,ohr,rhr,WT,xCe,thr,ahr,DY,nhr,shr,lhr,UT,$Ce,ihr,dhr,jY,mhr,chr,fhr,HT,kCe,ghr,hhr,GY,uhr,phr,_hr,JT,SCe,bhr,vhr,OY,Fhr,Thr,Mhr,YT,RCe,Ehr,Chr,VY,whr,Ahr,Lhr,ZT,PCe,yhr,xhr,XY,$hr,khr,Shr,KT,BCe,Rhr,Phr,zY,Bhr,Ihr,Nhr,eM,ICe,qhr,Dhr,QY,jhr,Ghr,Ohr,oM,NCe,Vhr,Xhr,WY,zhr,Qhr,Whr,rM,qCe,Uhr,Hhr,UY,Jhr,Yhr,Zhr,tM,DCe,Khr,eur,HY,our,rur,tur,aM,jCe,aur,nur,JY,sur,lur,iur,nM,GCe,dur,mur,YY,cur,fur,gur,sM,OCe,hur,uur,ZY,pur,_ur,bur,lM,vur,VCe,Fur,Tur,XCe,Mur,Eur,iM,Vlo,nm,dM,zCe,TS,Cur,QCe,wur,Xlo,Qo,MS,Aur,sm,Lur,KY,yur,xur,eZ,$ur,kur,Sur,ES,Rur,WCe,Pur,Bur,Iur,St,CS,Nur,UCe,qur,Dur,lm,jur,HCe,Gur,Our,oZ,Vur,Xur,zur,mM,Qur,mo,wS,Wur,JCe,Uur,Hur,bn,Jur,YCe,Yur,Zur,ZCe,Kur,epr,KCe,opr,rpr,tpr,I,cM,e3e,apr,npr,rZ,spr,lpr,ipr,fM,o3e,dpr,mpr,tZ,cpr,fpr,gpr,gM,r3e,hpr,upr,aZ,ppr,_pr,bpr,hM,t3e,vpr,Fpr,nZ,Tpr,Mpr,Epr,uM,a3e,Cpr,wpr,sZ,Apr,Lpr,ypr,pM,n3e,xpr,$pr,lZ,kpr,Spr,Rpr,_M,s3e,Ppr,Bpr,iZ,Ipr,Npr,qpr,bM,l3e,Dpr,jpr,dZ,Gpr,Opr,Vpr,vM,i3e,Xpr,zpr,mZ,Qpr,Wpr,Upr,FM,d3e,Hpr,Jpr,cZ,Ypr,Zpr,Kpr,TM,m3e,e_r,o_r,fZ,r_r,t_r,a_r,MM,c3e,n_r,s_r,gZ,l_r,i_r,d_r,EM,f3e,m_r,c_r,hZ,f_r,g_r,h_r,CM,g3e,u_r,p_r,uZ,__r,b_r,v_r,wM,h3e,F_r,T_r,pZ,M_r,E_r,C_r,AM,u3e,w_r,A_r,_Z,L_r,y_r,x_r,LM,p3e,$_r,k_r,bZ,S_r,R_r,P_r,yM,_3e,B_r,I_r,vZ,N_r,q_r,D_r,xM,b3e,j_r,G_r,FZ,O_r,V_r,X_r,$M,v3e,z_r,Q_r,TZ,W_r,U_r,H_r,kM,F3e,J_r,Y_r,MZ,Z_r,K_r,e1r,SM,T3e,o1r,r1r,EZ,t1r,a1r,n1r,RM,M3e,s1r,l1r,CZ,i1r,d1r,m1r,PM,E3e,c1r,f1r,wZ,g1r,h1r,u1r,BM,C3e,p1r,_1r,AZ,b1r,v1r,F1r,IM,w3e,T1r,M1r,LZ,E1r,C1r,w1r,NM,A3e,A1r,L1r,yZ,y1r,x1r,$1r,qM,L3e,k1r,S1r,xZ,R1r,P1r,B1r,DM,y3e,I1r,N1r,$Z,q1r,D1r,j1r,jM,x3e,G1r,O1r,kZ,V1r,X1r,z1r,GM,$3e,Q1r,W1r,SZ,U1r,H1r,J1r,OM,k3e,Y1r,Z1r,RZ,K1r,e2r,o2r,VM,S3e,r2r,t2r,PZ,a2r,n2r,s2r,XM,R3e,l2r,i2r,BZ,d2r,m2r,c2r,zM,P3e,f2r,g2r,IZ,h2r,u2r,p2r,QM,B3e,_2r,b2r,NZ,v2r,F2r,T2r,WM,I3e,M2r,E2r,qZ,C2r,w2r,A2r,UM,N3e,L2r,y2r,DZ,x2r,$2r,k2r,HM,q3e,S2r,R2r,jZ,P2r,B2r,I2r,JM,D3e,N2r,q2r,GZ,D2r,j2r,G2r,YM,j3e,O2r,V2r,OZ,X2r,z2r,Q2r,ZM,G3e,W2r,U2r,VZ,H2r,J2r,Y2r,KM,O3e,Z2r,K2r,XZ,ebr,obr,rbr,eE,V3e,tbr,abr,zZ,nbr,sbr,lbr,oE,X3e,ibr,dbr,QZ,mbr,cbr,fbr,rE,z3e,gbr,hbr,WZ,ubr,pbr,_br,tE,Q3e,bbr,vbr,UZ,Fbr,Tbr,Mbr,aE,W3e,Ebr,Cbr,HZ,wbr,Abr,Lbr,nE,U3e,ybr,xbr,JZ,$br,kbr,Sbr,sE,H3e,Rbr,Pbr,YZ,Bbr,Ibr,Nbr,lE,J3e,qbr,Dbr,ZZ,jbr,Gbr,Obr,iE,Y3e,Vbr,Xbr,KZ,zbr,Qbr,Wbr,dE,Z3e,Ubr,Hbr,eK,Jbr,Ybr,Zbr,mE,K3e,Kbr,evr,oK,ovr,rvr,tvr,cE,e5e,avr,nvr,rK,svr,lvr,ivr,fE,o5e,dvr,mvr,tK,cvr,fvr,gvr,gE,r5e,hvr,uvr,aK,pvr,_vr,bvr,hE,vvr,t5e,Fvr,Tvr,a5e,Mvr,Evr,uE,zlo,im,pE,n5e,AS,Cvr,s5e,wvr,Qlo,Wo,LS,Avr,dm,Lvr,nK,yvr,xvr,sK,$vr,kvr,Svr,yS,Rvr,l5e,Pvr,Bvr,Ivr,Rt,xS,Nvr,i5e,qvr,Dvr,mm,jvr,d5e,Gvr,Ovr,lK,Vvr,Xvr,zvr,_E,Qvr,co,$S,Wvr,m5e,Uvr,Hvr,vn,Jvr,c5e,Yvr,Zvr,f5e,Kvr,eFr,g5e,oFr,rFr,tFr,K,bE,h5e,aFr,nFr,iK,sFr,lFr,iFr,vE,u5e,dFr,mFr,dK,cFr,fFr,gFr,FE,p5e,hFr,uFr,mK,pFr,_Fr,bFr,TE,_5e,vFr,FFr,cK,TFr,MFr,EFr,ME,b5e,CFr,wFr,fK,AFr,LFr,yFr,EE,v5e,xFr,$Fr,gK,kFr,SFr,RFr,CE,F5e,PFr,BFr,hK,IFr,NFr,qFr,wE,T5e,DFr,jFr,uK,GFr,OFr,VFr,AE,M5e,XFr,zFr,pK,QFr,WFr,UFr,LE,E5e,HFr,JFr,_K,YFr,ZFr,KFr,yE,C5e,eTr,oTr,bK,rTr,tTr,aTr,xE,w5e,nTr,sTr,vK,lTr,iTr,dTr,$E,A5e,mTr,cTr,FK,fTr,gTr,hTr,kE,L5e,uTr,pTr,TK,_Tr,bTr,vTr,SE,y5e,FTr,TTr,MK,MTr,ETr,CTr,RE,x5e,wTr,ATr,EK,LTr,yTr,xTr,PE,$5e,$Tr,kTr,CK,STr,RTr,PTr,BE,k5e,BTr,ITr,wK,NTr,qTr,DTr,IE,S5e,jTr,GTr,AK,OTr,VTr,XTr,NE,R5e,zTr,QTr,LK,WTr,UTr,HTr,qE,P5e,JTr,YTr,yK,ZTr,KTr,eMr,DE,B5e,oMr,rMr,xK,tMr,aMr,nMr,jE,I5e,sMr,lMr,$K,iMr,dMr,mMr,GE,N5e,cMr,fMr,kK,gMr,hMr,uMr,OE,q5e,pMr,_Mr,SK,bMr,vMr,FMr,VE,D5e,TMr,MMr,RK,EMr,CMr,wMr,XE,j5e,AMr,LMr,PK,yMr,xMr,$Mr,zE,G5e,kMr,SMr,BK,RMr,PMr,BMr,QE,O5e,IMr,NMr,IK,qMr,DMr,jMr,WE,V5e,GMr,OMr,NK,VMr,XMr,zMr,UE,X5e,QMr,WMr,qK,UMr,HMr,JMr,HE,z5e,YMr,ZMr,DK,KMr,eEr,oEr,JE,Q5e,rEr,tEr,jK,aEr,nEr,sEr,YE,lEr,W5e,iEr,dEr,U5e,mEr,cEr,ZE,Wlo,cm,KE,H5e,kS,fEr,J5e,gEr,Ulo,Uo,SS,hEr,fm,uEr,GK,pEr,_Er,OK,bEr,vEr,FEr,RS,TEr,Y5e,MEr,EEr,CEr,Pt,PS,wEr,Z5e,AEr,LEr,gm,yEr,K5e,xEr,$Er,VK,kEr,SEr,REr,e4,PEr,fo,BS,BEr,e0e,IEr,NEr,Fn,qEr,o0e,DEr,jEr,r0e,GEr,OEr,t0e,VEr,XEr,zEr,Ye,o4,a0e,QEr,WEr,XK,UEr,HEr,JEr,r4,n0e,YEr,ZEr,zK,KEr,e4r,o4r,t4,s0e,r4r,t4r,QK,a4r,n4r,s4r,a4,l0e,l4r,i4r,WK,d4r,m4r,c4r,n4,i0e,f4r,g4r,UK,h4r,u4r,p4r,s4,d0e,_4r,b4r,HK,v4r,F4r,T4r,l4,m0e,M4r,E4r,JK,C4r,w4r,A4r,i4,L4r,c0e,y4r,x4r,f0e,$4r,k4r,d4,Hlo,hm,m4,g0e,IS,S4r,h0e,R4r,Jlo,Ho,NS,P4r,um,B4r,YK,I4r,N4r,ZK,q4r,D4r,j4r,qS,G4r,u0e,O4r,V4r,X4r,Bt,DS,z4r,p0e,Q4r,W4r,pm,U4r,_0e,H4r,J4r,KK,Y4r,Z4r,K4r,c4,eCr,go,jS,oCr,b0e,rCr,tCr,Tn,aCr,v0e,nCr,sCr,F0e,lCr,iCr,T0e,dCr,mCr,cCr,U,f4,M0e,fCr,gCr,eee,hCr,uCr,pCr,g4,E0e,_Cr,bCr,oee,vCr,FCr,TCr,h4,C0e,MCr,ECr,ree,CCr,wCr,ACr,u4,w0e,LCr,yCr,tee,xCr,$Cr,kCr,p4,A0e,SCr,RCr,aee,PCr,BCr,ICr,_4,L0e,NCr,qCr,nee,DCr,jCr,GCr,b4,y0e,OCr,VCr,see,XCr,zCr,QCr,v4,x0e,WCr,UCr,lee,HCr,JCr,YCr,F4,$0e,ZCr,KCr,iee,e3r,o3r,r3r,T4,k0e,t3r,a3r,dee,n3r,s3r,l3r,M4,S0e,i3r,d3r,mee,m3r,c3r,f3r,E4,R0e,g3r,h3r,cee,u3r,p3r,_3r,C4,P0e,b3r,v3r,fee,F3r,T3r,M3r,w4,B0e,E3r,C3r,gee,w3r,A3r,L3r,A4,I0e,y3r,x3r,hee,$3r,k3r,S3r,L4,N0e,R3r,P3r,uee,B3r,I3r,N3r,y4,q0e,q3r,D3r,pee,j3r,G3r,O3r,x4,D0e,V3r,X3r,_ee,z3r,Q3r,W3r,$4,j0e,U3r,H3r,bee,J3r,Y3r,Z3r,k4,G0e,K3r,e5r,vee,o5r,r5r,t5r,S4,O0e,a5r,n5r,Fee,s5r,l5r,i5r,R4,V0e,d5r,m5r,Tee,c5r,f5r,g5r,P4,X0e,h5r,u5r,Mee,p5r,_5r,b5r,B4,z0e,v5r,F5r,Eee,T5r,M5r,E5r,I4,Q0e,C5r,w5r,Cee,A5r,L5r,y5r,N4,W0e,x5r,$5r,wee,k5r,S5r,R5r,q4,U0e,P5r,B5r,Aee,I5r,N5r,q5r,D4,H0e,D5r,j5r,Lee,G5r,O5r,V5r,j4,J0e,X5r,z5r,yee,Q5r,W5r,U5r,G4,Y0e,H5r,J5r,xee,Y5r,Z5r,K5r,O4,Z0e,e0r,o0r,$ee,r0r,t0r,a0r,V4,K0e,n0r,s0r,kee,l0r,i0r,d0r,X4,ewe,m0r,c0r,See,f0r,g0r,h0r,z4,owe,u0r,p0r,Ree,_0r,b0r,v0r,Q4,rwe,F0r,T0r,Pee,M0r,E0r,C0r,W4,twe,w0r,A0r,Bee,L0r,y0r,x0r,U4,awe,$0r,k0r,Iee,S0r,R0r,P0r,H4,nwe,B0r,I0r,Nee,N0r,q0r,D0r,J4,swe,j0r,G0r,qee,O0r,V0r,X0r,Y4,lwe,z0r,Q0r,Dee,W0r,U0r,H0r,Z4,iwe,J0r,Y0r,jee,Z0r,K0r,ewr,K4,dwe,owr,rwr,Gee,twr,awr,nwr,eC,swr,mwe,lwr,iwr,cwe,dwr,mwr,oC,Ylo,_m,rC,fwe,GS,cwr,gwe,fwr,Zlo,Jo,OS,gwr,bm,hwr,Oee,uwr,pwr,Vee,_wr,bwr,vwr,VS,Fwr,hwe,Twr,Mwr,Ewr,It,XS,Cwr,uwe,wwr,Awr,vm,Lwr,pwe,ywr,xwr,Xee,$wr,kwr,Swr,tC,Rwr,ho,zS,Pwr,_we,Bwr,Iwr,Mn,Nwr,bwe,qwr,Dwr,vwe,jwr,Gwr,Fwe,Owr,Vwr,Xwr,O,aC,Twe,zwr,Qwr,zee,Wwr,Uwr,Hwr,nC,Mwe,Jwr,Ywr,Qee,Zwr,Kwr,eAr,sC,Ewe,oAr,rAr,Wee,tAr,aAr,nAr,lC,Cwe,sAr,lAr,Uee,iAr,dAr,mAr,iC,wwe,cAr,fAr,Hee,gAr,hAr,uAr,dC,Awe,pAr,_Ar,Jee,bAr,vAr,FAr,mC,Lwe,TAr,MAr,Yee,EAr,CAr,wAr,cC,ywe,AAr,LAr,Zee,yAr,xAr,$Ar,fC,xwe,kAr,SAr,Kee,RAr,PAr,BAr,gC,$we,IAr,NAr,eoe,qAr,DAr,jAr,hC,kwe,GAr,OAr,ooe,VAr,XAr,zAr,uC,Swe,QAr,WAr,roe,UAr,HAr,JAr,pC,Rwe,YAr,ZAr,toe,KAr,e6r,o6r,_C,Pwe,r6r,t6r,aoe,a6r,n6r,s6r,bC,Bwe,l6r,i6r,noe,d6r,m6r,c6r,vC,Iwe,f6r,g6r,soe,h6r,u6r,p6r,FC,Nwe,_6r,b6r,loe,v6r,F6r,T6r,TC,qwe,M6r,E6r,ioe,C6r,w6r,A6r,MC,Dwe,L6r,y6r,doe,x6r,$6r,k6r,EC,jwe,S6r,R6r,moe,P6r,B6r,I6r,CC,Gwe,N6r,q6r,coe,D6r,j6r,G6r,wC,Owe,O6r,V6r,foe,X6r,z6r,Q6r,AC,Vwe,W6r,U6r,goe,H6r,J6r,Y6r,LC,Xwe,Z6r,K6r,hoe,e7r,o7r,r7r,yC,zwe,t7r,a7r,uoe,n7r,s7r,l7r,xC,Qwe,i7r,d7r,poe,m7r,c7r,f7r,$C,Wwe,g7r,h7r,_oe,u7r,p7r,_7r,kC,Uwe,b7r,v7r,boe,F7r,T7r,M7r,SC,Hwe,E7r,C7r,voe,w7r,A7r,L7r,RC,Jwe,y7r,x7r,Foe,$7r,k7r,S7r,PC,Ywe,R7r,P7r,Toe,B7r,I7r,N7r,BC,Zwe,q7r,D7r,Moe,j7r,G7r,O7r,IC,Kwe,V7r,X7r,Eoe,z7r,Q7r,W7r,NC,eAe,U7r,H7r,Coe,J7r,Y7r,Z7r,qC,oAe,K7r,e8r,woe,o8r,r8r,t8r,DC,rAe,a8r,n8r,Aoe,s8r,l8r,i8r,jC,tAe,d8r,m8r,Loe,c8r,f8r,g8r,GC,aAe,h8r,u8r,yoe,p8r,_8r,b8r,OC,nAe,v8r,F8r,xoe,T8r,M8r,E8r,VC,sAe,C8r,w8r,$oe,A8r,L8r,y8r,XC,lAe,x8r,$8r,koe,k8r,S8r,R8r,zC,iAe,P8r,B8r,Soe,I8r,N8r,q8r,QC,dAe,D8r,j8r,Roe,G8r,O8r,V8r,WC,mAe,X8r,z8r,Poe,Q8r,W8r,U8r,UC,cAe,H8r,J8r,Boe,Y8r,Z8r,K8r,HC,fAe,eLr,oLr,Ioe,rLr,tLr,aLr,JC,gAe,nLr,sLr,Noe,lLr,iLr,dLr,YC,hAe,mLr,cLr,qoe,fLr,gLr,hLr,ZC,uAe,uLr,pLr,Doe,_Lr,bLr,vLr,KC,FLr,pAe,TLr,MLr,_Ae,ELr,CLr,e3,Klo,Fm,o3,bAe,QS,wLr,vAe,ALr,eio,Yo,WS,LLr,Tm,yLr,joe,xLr,$Lr,Goe,kLr,SLr,RLr,US,PLr,FAe,BLr,ILr,NLr,Nt,HS,qLr,TAe,DLr,jLr,Mm,GLr,MAe,OLr,VLr,Ooe,XLr,zLr,QLr,r3,WLr,uo,JS,ULr,EAe,HLr,JLr,En,YLr,CAe,ZLr,KLr,wAe,eyr,oyr,AAe,ryr,tyr,ayr,LAe,t3,yAe,nyr,syr,Voe,lyr,iyr,dyr,a3,myr,xAe,cyr,fyr,$Ae,gyr,hyr,n3,oio,Em,s3,kAe,YS,uyr,SAe,pyr,rio,Zo,ZS,_yr,Cm,byr,Xoe,vyr,Fyr,zoe,Tyr,Myr,Eyr,KS,Cyr,RAe,wyr,Ayr,Lyr,qt,eR,yyr,PAe,xyr,$yr,wm,kyr,BAe,Syr,Ryr,Qoe,Pyr,Byr,Iyr,l3,Nyr,po,oR,qyr,IAe,Dyr,jyr,Cn,Gyr,NAe,Oyr,Vyr,qAe,Xyr,zyr,DAe,Qyr,Wyr,Uyr,Am,i3,jAe,Hyr,Jyr,Woe,Yyr,Zyr,Kyr,d3,GAe,e9r,o9r,Uoe,r9r,t9r,a9r,m3,OAe,n9r,s9r,Hoe,l9r,i9r,d9r,c3,m9r,VAe,c9r,f9r,XAe,g9r,h9r,f3,tio,Lm,g3,zAe,rR,u9r,QAe,p9r,aio,Ko,tR,_9r,ym,b9r,Joe,v9r,F9r,Yoe,T9r,M9r,E9r,aR,C9r,WAe,w9r,A9r,L9r,Dt,nR,y9r,UAe,x9r,$9r,xm,k9r,HAe,S9r,R9r,Zoe,P9r,B9r,I9r,h3,N9r,_o,sR,q9r,JAe,D9r,j9r,wn,G9r,YAe,O9r,V9r,ZAe,X9r,z9r,KAe,Q9r,W9r,U9r,Fe,u3,e6e,H9r,J9r,Koe,Y9r,Z9r,K9r,p3,o6e,exr,oxr,ere,rxr,txr,axr,_3,r6e,nxr,sxr,ore,lxr,ixr,dxr,b3,t6e,mxr,cxr,rre,fxr,gxr,hxr,Nl,a6e,uxr,pxr,tre,_xr,bxr,are,vxr,Fxr,Txr,v3,n6e,Mxr,Exr,nre,Cxr,wxr,Axr,ql,s6e,Lxr,yxr,sre,xxr,$xr,lre,kxr,Sxr,Rxr,F3,l6e,Pxr,Bxr,ire,Ixr,Nxr,qxr,jt,i6e,Dxr,jxr,dre,Gxr,Oxr,mre,Vxr,Xxr,cre,zxr,Qxr,Wxr,T3,d6e,Uxr,Hxr,fre,Jxr,Yxr,Zxr,M3,m6e,Kxr,e$r,gre,o$r,r$r,t$r,E3,c6e,a$r,n$r,hre,s$r,l$r,i$r,C3,f6e,d$r,m$r,ure,c$r,f$r,g$r,w3,g6e,h$r,u$r,pre,p$r,_$r,b$r,A3,h6e,v$r,F$r,_re,T$r,M$r,E$r,L3,u6e,C$r,w$r,bre,A$r,L$r,y$r,y3,p6e,x$r,$$r,vre,k$r,S$r,R$r,x3,_6e,P$r,B$r,Fre,I$r,N$r,q$r,$3,D$r,b6e,j$r,G$r,v6e,O$r,V$r,k3,nio,$m,S3,F6e,lR,X$r,T6e,z$r,sio,er,iR,Q$r,km,W$r,Tre,U$r,H$r,Mre,J$r,Y$r,Z$r,dR,K$r,M6e,ekr,okr,rkr,Gt,mR,tkr,E6e,akr,nkr,Sm,skr,C6e,lkr,ikr,Ere,dkr,mkr,ckr,R3,fkr,bo,cR,gkr,w6e,hkr,ukr,An,pkr,A6e,_kr,bkr,L6e,vkr,Fkr,y6e,Tkr,Mkr,Ekr,x6e,P3,$6e,Ckr,wkr,Cre,Akr,Lkr,ykr,B3,xkr,k6e,$kr,kkr,S6e,Skr,Rkr,I3,lio,Rm,N3,R6e,fR,Pkr,P6e,Bkr,iio,or,gR,Ikr,Pm,Nkr,wre,qkr,Dkr,Are,jkr,Gkr,Okr,hR,Vkr,B6e,Xkr,zkr,Qkr,Ot,uR,Wkr,I6e,Ukr,Hkr,Bm,Jkr,N6e,Ykr,Zkr,Lre,Kkr,eSr,oSr,q3,rSr,vo,pR,tSr,q6e,aSr,nSr,Ln,sSr,D6e,lSr,iSr,j6e,dSr,mSr,G6e,cSr,fSr,gSr,O6e,D3,V6e,hSr,uSr,yre,pSr,_Sr,bSr,j3,vSr,X6e,FSr,TSr,z6e,MSr,ESr,G3,dio,Im,O3,Q6e,_R,CSr,W6e,wSr,mio,rr,bR,ASr,Nm,LSr,xre,ySr,xSr,$re,$Sr,kSr,SSr,vR,RSr,U6e,PSr,BSr,ISr,Vt,FR,NSr,H6e,qSr,DSr,qm,jSr,J6e,GSr,OSr,kre,VSr,XSr,zSr,V3,QSr,Fo,TR,WSr,Y6e,USr,HSr,yn,JSr,Z6e,YSr,ZSr,K6e,KSr,eRr,e7e,oRr,rRr,tRr,o7e,X3,r7e,aRr,nRr,Sre,sRr,lRr,iRr,z3,dRr,t7e,mRr,cRr,a7e,fRr,gRr,Q3,cio,Dm,W3,n7e,MR,hRr,s7e,uRr,fio,tr,ER,pRr,jm,_Rr,Rre,bRr,vRr,Pre,FRr,TRr,MRr,CR,ERr,l7e,CRr,wRr,ARr,Xt,wR,LRr,i7e,yRr,xRr,Gm,$Rr,d7e,kRr,SRr,Bre,RRr,PRr,BRr,U3,IRr,To,AR,NRr,m7e,qRr,DRr,xn,jRr,c7e,GRr,ORr,f7e,VRr,XRr,g7e,zRr,QRr,WRr,Ne,H3,h7e,URr,HRr,Ire,JRr,YRr,ZRr,J3,u7e,KRr,ePr,Nre,oPr,rPr,tPr,Y3,p7e,aPr,nPr,qre,sPr,lPr,iPr,Z3,_7e,dPr,mPr,Dre,cPr,fPr,gPr,K3,b7e,hPr,uPr,jre,pPr,_Pr,bPr,e5,v7e,vPr,FPr,Gre,TPr,MPr,EPr,o5,F7e,CPr,wPr,Ore,APr,LPr,yPr,r5,T7e,xPr,$Pr,Vre,kPr,SPr,RPr,t5,M7e,PPr,BPr,Xre,IPr,NPr,qPr,a5,DPr,E7e,jPr,GPr,C7e,OPr,VPr,n5,gio,Om,s5,w7e,LR,XPr,A7e,zPr,hio,ar,yR,QPr,Vm,WPr,zre,UPr,HPr,Qre,JPr,YPr,ZPr,xR,KPr,L7e,eBr,oBr,rBr,zt,$R,tBr,y7e,aBr,nBr,Xm,sBr,x7e,lBr,iBr,Wre,dBr,mBr,cBr,l5,fBr,Mo,kR,gBr,$7e,hBr,uBr,$n,pBr,k7e,_Br,bBr,S7e,vBr,FBr,R7e,TBr,MBr,EBr,vt,i5,P7e,CBr,wBr,Ure,ABr,LBr,yBr,d5,B7e,xBr,$Br,Hre,kBr,SBr,RBr,m5,I7e,PBr,BBr,Jre,IBr,NBr,qBr,c5,N7e,DBr,jBr,Yre,GBr,OBr,VBr,f5,q7e,XBr,zBr,Zre,QBr,WBr,UBr,g5,HBr,D7e,JBr,YBr,j7e,ZBr,KBr,h5,uio,zm,u5,G7e,SR,eIr,O7e,oIr,pio,nr,RR,rIr,Qm,tIr,Kre,aIr,nIr,ete,sIr,lIr,iIr,PR,dIr,V7e,mIr,cIr,fIr,Qt,BR,gIr,X7e,hIr,uIr,Wm,pIr,z7e,_Ir,bIr,ote,vIr,FIr,TIr,p5,MIr,Eo,IR,EIr,Q7e,CIr,wIr,kn,AIr,W7e,LIr,yIr,U7e,xIr,$Ir,H7e,kIr,SIr,RIr,xe,_5,J7e,PIr,BIr,rte,IIr,NIr,qIr,b5,Y7e,DIr,jIr,tte,GIr,OIr,VIr,v5,Z7e,XIr,zIr,ate,QIr,WIr,UIr,F5,K7e,HIr,JIr,nte,YIr,ZIr,KIr,T5,e8e,eNr,oNr,ste,rNr,tNr,aNr,M5,o8e,nNr,sNr,lte,lNr,iNr,dNr,E5,r8e,mNr,cNr,ite,fNr,gNr,hNr,C5,t8e,uNr,pNr,dte,_Nr,bNr,vNr,w5,a8e,FNr,TNr,mte,MNr,ENr,CNr,A5,n8e,wNr,ANr,cte,LNr,yNr,xNr,L5,$Nr,s8e,kNr,SNr,l8e,RNr,PNr,y5,_io,Um,x5,i8e,NR,BNr,d8e,INr,bio,sr,qR,NNr,Hm,qNr,fte,DNr,jNr,gte,GNr,ONr,VNr,DR,XNr,m8e,zNr,QNr,WNr,Wt,jR,UNr,c8e,HNr,JNr,Jm,YNr,f8e,ZNr,KNr,hte,eqr,oqr,rqr,$5,tqr,Co,GR,aqr,g8e,nqr,sqr,Sn,lqr,h8e,iqr,dqr,u8e,mqr,cqr,p8e,fqr,gqr,hqr,Ym,k5,_8e,uqr,pqr,ute,_qr,bqr,vqr,S5,b8e,Fqr,Tqr,pte,Mqr,Eqr,Cqr,R5,v8e,wqr,Aqr,_te,Lqr,yqr,xqr,P5,$qr,F8e,kqr,Sqr,T8e,Rqr,Pqr,B5,vio,Zm,I5,M8e,OR,Bqr,E8e,Iqr,Fio,lr,VR,Nqr,Km,qqr,bte,Dqr,jqr,vte,Gqr,Oqr,Vqr,XR,Xqr,C8e,zqr,Qqr,Wqr,Ut,zR,Uqr,w8e,Hqr,Jqr,ec,Yqr,A8e,Zqr,Kqr,Fte,eDr,oDr,rDr,N5,tDr,wo,QR,aDr,L8e,nDr,sDr,Rn,lDr,y8e,iDr,dDr,x8e,mDr,cDr,$8e,fDr,gDr,hDr,Ft,q5,k8e,uDr,pDr,Tte,_Dr,bDr,vDr,D5,S8e,FDr,TDr,Mte,MDr,EDr,CDr,j5,R8e,wDr,ADr,Ete,LDr,yDr,xDr,G5,P8e,$Dr,kDr,Cte,SDr,RDr,PDr,O5,B8e,BDr,IDr,wte,NDr,qDr,DDr,V5,jDr,I8e,GDr,ODr,N8e,VDr,XDr,X5,Tio,oc,z5,q8e,WR,zDr,D8e,QDr,Mio,ir,UR,WDr,rc,UDr,Ate,HDr,JDr,Lte,YDr,ZDr,KDr,HR,ejr,j8e,ojr,rjr,tjr,Ht,JR,ajr,G8e,njr,sjr,tc,ljr,O8e,ijr,djr,yte,mjr,cjr,fjr,Q5,gjr,Ao,YR,hjr,V8e,ujr,pjr,Pn,_jr,X8e,bjr,vjr,z8e,Fjr,Tjr,Q8e,Mjr,Ejr,Cjr,Bn,W5,W8e,wjr,Ajr,xte,Ljr,yjr,xjr,U5,U8e,$jr,kjr,$te,Sjr,Rjr,Pjr,H5,H8e,Bjr,Ijr,kte,Njr,qjr,Djr,J5,J8e,jjr,Gjr,Ste,Ojr,Vjr,Xjr,Y5,zjr,Y8e,Qjr,Wjr,Z8e,Ujr,Hjr,Z5,Eio,ac,K5,K8e,ZR,Jjr,eLe,Yjr,Cio,dr,KR,Zjr,nc,Kjr,Rte,eGr,oGr,Pte,rGr,tGr,aGr,eP,nGr,oLe,sGr,lGr,iGr,Jt,oP,dGr,rLe,mGr,cGr,sc,fGr,tLe,gGr,hGr,Bte,uGr,pGr,_Gr,e0,bGr,Lo,rP,vGr,aLe,FGr,TGr,In,MGr,nLe,EGr,CGr,sLe,wGr,AGr,lLe,LGr,yGr,xGr,Tt,o0,iLe,$Gr,kGr,Ite,SGr,RGr,PGr,r0,dLe,BGr,IGr,Nte,NGr,qGr,DGr,t0,mLe,jGr,GGr,qte,OGr,VGr,XGr,a0,cLe,zGr,QGr,Dte,WGr,UGr,HGr,n0,fLe,JGr,YGr,jte,ZGr,KGr,eOr,s0,oOr,gLe,rOr,tOr,hLe,aOr,nOr,l0,wio,lc,i0,uLe,tP,sOr,pLe,lOr,Aio,mr,aP,iOr,ic,dOr,Gte,mOr,cOr,Ote,fOr,gOr,hOr,nP,uOr,_Le,pOr,_Or,bOr,Yt,sP,vOr,bLe,FOr,TOr,dc,MOr,vLe,EOr,COr,Vte,wOr,AOr,LOr,d0,yOr,yo,lP,xOr,FLe,$Or,kOr,Nn,SOr,TLe,ROr,POr,MLe,BOr,IOr,ELe,NOr,qOr,DOr,CLe,m0,wLe,jOr,GOr,Xte,OOr,VOr,XOr,c0,zOr,ALe,QOr,WOr,LLe,UOr,HOr,f0,Lio,mc,g0,yLe,iP,JOr,xLe,YOr,yio,cr,dP,ZOr,cc,KOr,zte,eVr,oVr,Qte,rVr,tVr,aVr,mP,nVr,$Le,sVr,lVr,iVr,Zt,cP,dVr,kLe,mVr,cVr,fc,fVr,SLe,gVr,hVr,Wte,uVr,pVr,_Vr,h0,bVr,xo,fP,vVr,RLe,FVr,TVr,qn,MVr,PLe,EVr,CVr,BLe,wVr,AVr,ILe,LVr,yVr,xVr,Mt,u0,NLe,$Vr,kVr,Ute,SVr,RVr,PVr,p0,qLe,BVr,IVr,Hte,NVr,qVr,DVr,_0,DLe,jVr,GVr,Jte,OVr,VVr,XVr,b0,jLe,zVr,QVr,Yte,WVr,UVr,HVr,v0,GLe,JVr,YVr,Zte,ZVr,KVr,eXr,F0,oXr,OLe,rXr,tXr,VLe,aXr,nXr,T0,xio,gc,M0,XLe,gP,sXr,zLe,lXr,$io,fr,hP,iXr,hc,dXr,Kte,mXr,cXr,eae,fXr,gXr,hXr,uP,uXr,QLe,pXr,_Xr,bXr,Kt,pP,vXr,WLe,FXr,TXr,uc,MXr,ULe,EXr,CXr,oae,wXr,AXr,LXr,E0,yXr,$o,_P,xXr,HLe,$Xr,kXr,Dn,SXr,JLe,RXr,PXr,YLe,BXr,IXr,ZLe,NXr,qXr,DXr,KLe,C0,eye,jXr,GXr,rae,OXr,VXr,XXr,w0,zXr,oye,QXr,WXr,rye,UXr,HXr,A0,kio,pc,L0,tye,bP,JXr,aye,YXr,Sio,gr,vP,ZXr,_c,KXr,tae,ezr,ozr,aae,rzr,tzr,azr,FP,nzr,nye,szr,lzr,izr,ea,TP,dzr,sye,mzr,czr,bc,fzr,lye,gzr,hzr,nae,uzr,pzr,_zr,y0,bzr,ko,MP,vzr,iye,Fzr,Tzr,jn,Mzr,dye,Ezr,Czr,mye,wzr,Azr,cye,Lzr,yzr,xzr,fye,x0,gye,$zr,kzr,sae,Szr,Rzr,Pzr,$0,Bzr,hye,Izr,Nzr,uye,qzr,Dzr,k0,Rio,vc,S0,pye,EP,jzr,_ye,Gzr,Pio,hr,CP,Ozr,Fc,Vzr,lae,Xzr,zzr,iae,Qzr,Wzr,Uzr,wP,Hzr,bye,Jzr,Yzr,Zzr,oa,AP,Kzr,vye,eQr,oQr,Tc,rQr,Fye,tQr,aQr,dae,nQr,sQr,lQr,R0,iQr,Xr,LP,dQr,Tye,mQr,cQr,Gn,fQr,Mye,gQr,hQr,Eye,uQr,pQr,Cye,_Qr,bQr,vQr,P,P0,wye,FQr,TQr,mae,MQr,EQr,CQr,B0,Aye,wQr,AQr,cae,LQr,yQr,xQr,I0,Lye,$Qr,kQr,fae,SQr,RQr,PQr,N0,yye,BQr,IQr,gae,NQr,qQr,DQr,q0,xye,jQr,GQr,hae,OQr,VQr,XQr,D0,$ye,zQr,QQr,uae,WQr,UQr,HQr,j0,kye,JQr,YQr,pae,ZQr,KQr,eWr,G0,Sye,oWr,rWr,_ae,tWr,aWr,nWr,O0,Rye,sWr,lWr,bae,iWr,dWr,mWr,V0,Pye,cWr,fWr,vae,gWr,hWr,uWr,X0,Bye,pWr,_Wr,Fae,bWr,vWr,FWr,z0,Iye,TWr,MWr,Tae,EWr,CWr,wWr,Q0,Nye,AWr,LWr,Mae,yWr,xWr,$Wr,W0,qye,kWr,SWr,Eae,RWr,PWr,BWr,U0,Dye,IWr,NWr,Cae,qWr,DWr,jWr,H0,jye,GWr,OWr,wae,VWr,XWr,zWr,J0,Gye,QWr,WWr,Aae,UWr,HWr,JWr,Y0,Oye,YWr,ZWr,Lae,KWr,eUr,oUr,Z0,Vye,rUr,tUr,yae,aUr,nUr,sUr,K0,Xye,lUr,iUr,xae,dUr,mUr,cUr,Dl,zye,fUr,gUr,$ae,hUr,uUr,kae,pUr,_Ur,bUr,ew,Qye,vUr,FUr,Sae,TUr,MUr,EUr,ow,Wye,CUr,wUr,Rae,AUr,LUr,yUr,rw,Uye,xUr,$Ur,Pae,kUr,SUr,RUr,tw,Hye,PUr,BUr,Bae,IUr,NUr,qUr,aw,Jye,DUr,jUr,Iae,GUr,OUr,VUr,nw,Yye,XUr,zUr,Nae,QUr,WUr,UUr,sw,Zye,HUr,JUr,qae,YUr,ZUr,KUr,lw,Kye,eHr,oHr,Dae,rHr,tHr,aHr,iw,e9e,nHr,sHr,jae,lHr,iHr,dHr,dw,o9e,mHr,cHr,Gae,fHr,gHr,hHr,mw,r9e,uHr,pHr,Oae,_Hr,bHr,vHr,cw,t9e,FHr,THr,Vae,MHr,EHr,CHr,fw,a9e,wHr,AHr,Xae,LHr,yHr,xHr,gw,n9e,$Hr,kHr,zae,SHr,RHr,PHr,hw,s9e,BHr,IHr,Qae,NHr,qHr,DHr,uw,l9e,jHr,GHr,Wae,OHr,VHr,XHr,pw,i9e,zHr,QHr,Uae,WHr,UHr,HHr,_w,d9e,JHr,YHr,Hae,ZHr,KHr,eJr,bw,m9e,oJr,rJr,Jae,tJr,aJr,nJr,vw,c9e,sJr,lJr,Yae,iJr,dJr,mJr,Fw,f9e,cJr,fJr,Zae,gJr,hJr,uJr,Tw,g9e,pJr,_Jr,Kae,bJr,vJr,FJr,Mw,h9e,TJr,MJr,ene,EJr,CJr,wJr,Ew,u9e,AJr,LJr,one,yJr,xJr,$Jr,Cw,p9e,kJr,SJr,rne,RJr,PJr,BJr,ww,_9e,IJr,NJr,tne,qJr,DJr,jJr,Aw,b9e,GJr,OJr,ane,VJr,XJr,zJr,Lw,v9e,QJr,WJr,nne,UJr,HJr,JJr,yw,F9e,YJr,ZJr,sne,KJr,eYr,oYr,xw,T9e,rYr,tYr,lne,aYr,nYr,sYr,$w,M9e,lYr,iYr,ine,dYr,mYr,cYr,kw,E9e,fYr,gYr,dne,hYr,uYr,pYr,Sw,C9e,_Yr,bYr,mne,vYr,FYr,TYr,Rw,w9e,MYr,EYr,cne,CYr,wYr,AYr,Pw,A9e,LYr,yYr,fne,xYr,$Yr,kYr,Bw,L9e,SYr,RYr,gne,PYr,BYr,IYr,Iw,y9e,NYr,qYr,hne,DYr,jYr,GYr,Nw,Bio,Mc,qw,x9e,yP,OYr,$9e,VYr,Iio,ur,xP,XYr,Ec,zYr,une,QYr,WYr,pne,UYr,HYr,JYr,$P,YYr,k9e,ZYr,KYr,eZr,ra,kP,oZr,S9e,rZr,tZr,Cc,aZr,R9e,nZr,sZr,_ne,lZr,iZr,dZr,Dw,mZr,zr,SP,cZr,P9e,fZr,gZr,On,hZr,B9e,uZr,pZr,I9e,_Zr,bZr,N9e,vZr,FZr,TZr,de,jw,q9e,MZr,EZr,bne,CZr,wZr,AZr,Gw,D9e,LZr,yZr,vne,xZr,$Zr,kZr,Ow,j9e,SZr,RZr,Fne,PZr,BZr,IZr,Vw,G9e,NZr,qZr,Tne,DZr,jZr,GZr,Xw,O9e,OZr,VZr,Mne,XZr,zZr,QZr,zw,V9e,WZr,UZr,Ene,HZr,JZr,YZr,Qw,X9e,ZZr,KZr,Cne,eKr,oKr,rKr,Ww,z9e,tKr,aKr,wne,nKr,sKr,lKr,Uw,Q9e,iKr,dKr,Ane,mKr,cKr,fKr,Hw,W9e,gKr,hKr,Lne,uKr,pKr,_Kr,Jw,U9e,bKr,vKr,yne,FKr,TKr,MKr,Yw,H9e,EKr,CKr,xne,wKr,AKr,LKr,Zw,J9e,yKr,xKr,$ne,$Kr,kKr,SKr,Kw,Y9e,RKr,PKr,kne,BKr,IKr,NKr,eA,Z9e,qKr,DKr,Sne,jKr,GKr,OKr,oA,K9e,VKr,XKr,Rne,zKr,QKr,WKr,rA,exe,UKr,HKr,Pne,JKr,YKr,ZKr,tA,oxe,KKr,eet,Bne,oet,ret,tet,aA,rxe,aet,net,Ine,set,iet,det,nA,txe,met,cet,Nne,fet,get,het,sA,axe,uet,pet,qne,_et,bet,vet,lA,nxe,Fet,Tet,Dne,Met,Eet,Cet,iA,sxe,wet,Aet,jne,Let,yet,xet,dA,Nio,wc,mA,lxe,RP,$et,ixe,ket,qio,pr,PP,Set,Ac,Ret,Gne,Pet,Bet,One,Iet,Net,qet,BP,Det,dxe,jet,Get,Oet,ta,IP,Vet,mxe,Xet,zet,Lc,Qet,cxe,Wet,Uet,Vne,Het,Jet,Yet,cA,Zet,Qr,NP,Ket,fxe,eot,oot,Vn,rot,gxe,tot,aot,hxe,not,sot,uxe,lot,iot,dot,Ce,fA,pxe,mot,cot,Xne,fot,got,hot,gA,_xe,uot,pot,zne,_ot,bot,vot,hA,bxe,Fot,Tot,Qne,Mot,Eot,Cot,uA,vxe,wot,Aot,Wne,Lot,yot,xot,pA,Fxe,$ot,kot,Une,Sot,Rot,Pot,_A,Txe,Bot,Iot,Hne,Not,qot,Dot,bA,Mxe,jot,Got,Jne,Oot,Vot,Xot,vA,Exe,zot,Qot,Yne,Wot,Uot,Hot,FA,Cxe,Jot,Yot,Zne,Zot,Kot,ert,TA,wxe,ort,rrt,Kne,trt,art,nrt,MA,Axe,srt,lrt,ese,irt,drt,mrt,EA,Lxe,crt,frt,ose,grt,hrt,urt,CA,yxe,prt,_rt,rse,brt,vrt,Frt,wA,xxe,Trt,Mrt,tse,Ert,Crt,wrt,AA,Dio,yc,LA,$xe,qP,Art,kxe,Lrt,jio,_r,DP,yrt,xc,xrt,ase,$rt,krt,nse,Srt,Rrt,Prt,jP,Brt,Sxe,Irt,Nrt,qrt,aa,GP,Drt,Rxe,jrt,Grt,$c,Ort,Pxe,Vrt,Xrt,sse,zrt,Qrt,Wrt,yA,Urt,Wr,OP,Hrt,Bxe,Jrt,Yrt,Xn,Zrt,Ixe,Krt,ett,Nxe,ott,rtt,qxe,ttt,att,ntt,$e,xA,Dxe,stt,ltt,lse,itt,dtt,mtt,$A,jxe,ctt,ftt,ise,gtt,htt,utt,kA,Gxe,ptt,_tt,dse,btt,vtt,Ftt,jl,Oxe,Ttt,Mtt,mse,Ett,Ctt,cse,wtt,Att,Ltt,SA,Vxe,ytt,xtt,fse,$tt,ktt,Stt,RA,Xxe,Rtt,Ptt,gse,Btt,Itt,Ntt,PA,zxe,qtt,Dtt,hse,jtt,Gtt,Ott,BA,Qxe,Vtt,Xtt,use,ztt,Qtt,Wtt,IA,Wxe,Utt,Htt,pse,Jtt,Ytt,Ztt,NA,Uxe,Ktt,eat,_se,oat,rat,tat,qA,Gio,kc,DA,Hxe,VP,aat,Jxe,nat,Oio,br,XP,sat,Sc,lat,bse,iat,dat,vse,mat,cat,fat,zP,gat,Yxe,hat,uat,pat,na,QP,_at,Zxe,bat,vat,Rc,Fat,Kxe,Tat,Mat,Fse,Eat,Cat,wat,jA,Aat,Ur,WP,Lat,e$e,yat,xat,zn,$at,o$e,kat,Sat,r$e,Rat,Pat,t$e,Bat,Iat,Nat,Pc,GA,a$e,qat,Dat,Tse,jat,Gat,Oat,OA,n$e,Vat,Xat,Mse,zat,Qat,Wat,VA,s$e,Uat,Hat,Ese,Jat,Yat,Zat,XA,Vio,Bc,zA,l$e,UP,Kat,i$e,ent,Xio,vr,HP,ont,Ic,rnt,Cse,tnt,ant,wse,nnt,snt,lnt,JP,int,d$e,dnt,mnt,cnt,sa,YP,fnt,m$e,gnt,hnt,Nc,unt,c$e,pnt,_nt,Ase,bnt,vnt,Fnt,QA,Tnt,Hr,ZP,Mnt,f$e,Ent,Cnt,Qn,wnt,g$e,Ant,Lnt,h$e,ynt,xnt,u$e,$nt,knt,Snt,ge,WA,p$e,Rnt,Pnt,Lse,Bnt,Int,Nnt,UA,_$e,qnt,Dnt,yse,jnt,Gnt,Ont,HA,b$e,Vnt,Xnt,xse,znt,Qnt,Wnt,JA,v$e,Unt,Hnt,$se,Jnt,Ynt,Znt,YA,F$e,Knt,est,kse,ost,rst,tst,ZA,T$e,ast,nst,Sse,sst,lst,ist,KA,M$e,dst,mst,Rse,cst,fst,gst,e6,E$e,hst,ust,Pse,pst,_st,bst,o6,C$e,vst,Fst,Bse,Tst,Mst,Est,r6,w$e,Cst,wst,Ise,Ast,Lst,yst,t6,A$e,xst,$st,Nse,kst,Sst,Rst,a6,L$e,Pst,Bst,qse,Ist,Nst,qst,n6,y$e,Dst,jst,Dse,Gst,Ost,Vst,s6,x$e,Xst,zst,jse,Qst,Wst,Ust,l6,$$e,Hst,Jst,Gse,Yst,Zst,Kst,i6,k$e,elt,olt,Ose,rlt,tlt,alt,d6,S$e,nlt,slt,Vse,llt,ilt,dlt,m6,R$e,mlt,clt,Xse,flt,glt,hlt,c6,P$e,ult,plt,zse,_lt,blt,vlt,f6,B$e,Flt,Tlt,Qse,Mlt,Elt,Clt,g6,I$e,wlt,Alt,Wse,Llt,ylt,xlt,h6,zio,qc,u6,N$e,KP,$lt,q$e,klt,Qio,Fr,eB,Slt,Dc,Rlt,Use,Plt,Blt,Hse,Ilt,Nlt,qlt,oB,Dlt,D$e,jlt,Glt,Olt,la,rB,Vlt,j$e,Xlt,zlt,jc,Qlt,G$e,Wlt,Ult,Jse,Hlt,Jlt,Ylt,p6,Zlt,Jr,tB,Klt,O$e,eit,oit,Wn,rit,V$e,tit,ait,X$e,nit,sit,z$e,lit,iit,dit,ke,_6,Q$e,mit,cit,Yse,fit,git,hit,b6,W$e,uit,pit,Zse,_it,bit,vit,v6,U$e,Fit,Tit,Kse,Mit,Eit,Cit,F6,H$e,wit,Ait,ele,Lit,yit,xit,T6,J$e,$it,kit,ole,Sit,Rit,Pit,M6,Y$e,Bit,Iit,rle,Nit,qit,Dit,E6,Z$e,jit,Git,tle,Oit,Vit,Xit,C6,K$e,zit,Qit,ale,Wit,Uit,Hit,w6,eke,Jit,Yit,nle,Zit,Kit,edt,A6,oke,odt,rdt,sle,tdt,adt,ndt,L6,Wio,Gc,y6,rke,aB,sdt,tke,ldt,Uio,Tr,nB,idt,Oc,ddt,lle,mdt,cdt,ile,fdt,gdt,hdt,sB,udt,ake,pdt,_dt,bdt,ia,lB,vdt,nke,Fdt,Tdt,Vc,Mdt,ske,Edt,Cdt,dle,wdt,Adt,Ldt,x6,ydt,Yr,iB,xdt,lke,$dt,kdt,Un,Sdt,ike,Rdt,Pdt,dke,Bdt,Idt,mke,Ndt,qdt,Ddt,te,$6,cke,jdt,Gdt,mle,Odt,Vdt,Xdt,k6,fke,zdt,Qdt,cle,Wdt,Udt,Hdt,S6,gke,Jdt,Ydt,fle,Zdt,Kdt,emt,R6,hke,omt,rmt,gle,tmt,amt,nmt,P6,uke,smt,lmt,hle,imt,dmt,mmt,B6,pke,cmt,fmt,ule,gmt,hmt,umt,I6,_ke,pmt,_mt,ple,bmt,vmt,Fmt,N6,bke,Tmt,Mmt,_le,Emt,Cmt,wmt,q6,vke,Amt,Lmt,ble,ymt,xmt,$mt,D6,Fke,kmt,Smt,vle,Rmt,Pmt,Bmt,j6,Tke,Imt,Nmt,Fle,qmt,Dmt,jmt,G6,Mke,Gmt,Omt,Tle,Vmt,Xmt,zmt,O6,Eke,Qmt,Wmt,Mle,Umt,Hmt,Jmt,V6,Cke,Ymt,Zmt,Ele,Kmt,ect,oct,X6,wke,rct,tct,Cle,act,nct,sct,z6,Ake,lct,ict,wle,dct,mct,cct,Q6,Lke,fct,gct,Ale,hct,uct,pct,W6,yke,_ct,bct,Lle,vct,Fct,Tct,U6,xke,Mct,Ect,yle,Cct,wct,Act,H6,$ke,Lct,yct,xle,xct,$ct,kct,J6,kke,Sct,Rct,$le,Pct,Bct,Ict,Y6,Ske,Nct,qct,kle,Dct,jct,Gct,Z6,Rke,Oct,Vct,Sle,Xct,zct,Qct,K6,Pke,Wct,Uct,Rle,Hct,Jct,Yct,e7,Bke,Zct,Kct,Ple,eft,oft,rft,o7,Ike,tft,aft,Ble,nft,sft,lft,r7,Nke,ift,dft,Ile,mft,cft,fft,t7,qke,gft,hft,Nle,uft,pft,_ft,a7,Hio,Xc,n7,Dke,dB,bft,jke,vft,Jio,Mr,mB,Fft,zc,Tft,qle,Mft,Eft,Dle,Cft,wft,Aft,cB,Lft,Gke,yft,xft,$ft,da,fB,kft,Oke,Sft,Rft,Qc,Pft,Vke,Bft,Ift,jle,Nft,qft,Dft,s7,jft,Zr,gB,Gft,Xke,Oft,Vft,Hn,Xft,zke,zft,Qft,Qke,Wft,Uft,Wke,Hft,Jft,Yft,Te,l7,Uke,Zft,Kft,Gle,egt,ogt,rgt,i7,Hke,tgt,agt,Ole,ngt,sgt,lgt,d7,Jke,igt,dgt,Vle,mgt,cgt,fgt,m7,Yke,ggt,hgt,Xle,ugt,pgt,_gt,c7,Zke,bgt,vgt,zle,Fgt,Tgt,Mgt,f7,Kke,Egt,Cgt,Qle,wgt,Agt,Lgt,g7,eSe,ygt,xgt,Wle,$gt,kgt,Sgt,h7,oSe,Rgt,Pgt,Ule,Bgt,Igt,Ngt,u7,rSe,qgt,Dgt,Hle,jgt,Ggt,Ogt,p7,tSe,Vgt,Xgt,Jle,zgt,Qgt,Wgt,_7,aSe,Ugt,Hgt,Yle,Jgt,Ygt,Zgt,b7,nSe,Kgt,eht,Zle,oht,rht,tht,v7,sSe,aht,nht,Kle,sht,lht,iht,F7,lSe,dht,mht,eie,cht,fht,ght,T7,iSe,hht,uht,oie,pht,_ht,bht,M7,dSe,vht,Fht,rie,Tht,Mht,Eht,E7,mSe,Cht,wht,tie,Aht,Lht,yht,C7,Yio,Wc,w7,cSe,hB,xht,fSe,$ht,Zio,Er,uB,kht,Uc,Sht,aie,Rht,Pht,nie,Bht,Iht,Nht,pB,qht,gSe,Dht,jht,Ght,ma,_B,Oht,hSe,Vht,Xht,Hc,zht,uSe,Qht,Wht,sie,Uht,Hht,Jht,A7,Yht,Kr,bB,Zht,pSe,Kht,eut,Jn,out,_Se,rut,tut,bSe,aut,nut,vSe,sut,lut,iut,vB,L7,FSe,dut,mut,lie,cut,fut,gut,y7,TSe,hut,uut,iie,put,_ut,but,x7,Kio,Jc,$7,MSe,FB,vut,ESe,Fut,edo,Cr,TB,Tut,Yc,Mut,die,Eut,Cut,mie,wut,Aut,Lut,MB,yut,CSe,xut,$ut,kut,ca,EB,Sut,wSe,Rut,Put,Zc,But,ASe,Iut,Nut,cie,qut,Dut,jut,k7,Gut,et,CB,Out,LSe,Vut,Xut,Yn,zut,ySe,Qut,Wut,xSe,Uut,Hut,$Se,Jut,Yut,Zut,kSe,S7,SSe,Kut,ept,fie,opt,rpt,tpt,R7,odo,Kc,P7,RSe,wB,apt,PSe,npt,rdo,wr,AB,spt,ef,lpt,gie,ipt,dpt,hie,mpt,cpt,fpt,LB,gpt,BSe,hpt,upt,ppt,fa,yB,_pt,ISe,bpt,vpt,of,Fpt,NSe,Tpt,Mpt,uie,Ept,Cpt,wpt,B7,Apt,ot,xB,Lpt,qSe,ypt,xpt,Zn,$pt,DSe,kpt,Spt,jSe,Rpt,Ppt,GSe,Bpt,Ipt,Npt,OSe,I7,VSe,qpt,Dpt,pie,jpt,Gpt,Opt,N7,tdo,rf,q7,XSe,$B,Vpt,zSe,Xpt,ado,Ar,kB,zpt,tf,Qpt,_ie,Wpt,Upt,bie,Hpt,Jpt,Ypt,SB,Zpt,QSe,Kpt,e_t,o_t,ga,RB,r_t,WSe,t_t,a_t,af,n_t,USe,s_t,l_t,vie,i_t,d_t,m_t,D7,c_t,rt,PB,f_t,HSe,g_t,h_t,Kn,u_t,JSe,p_t,__t,YSe,b_t,v_t,ZSe,F_t,T_t,M_t,me,j7,KSe,E_t,C_t,Fie,w_t,A_t,L_t,G7,eRe,y_t,x_t,Tie,$_t,k_t,S_t,O7,oRe,R_t,P_t,Mie,B_t,I_t,N_t,V7,rRe,q_t,D_t,Eie,j_t,G_t,O_t,X7,tRe,V_t,X_t,Cie,z_t,Q_t,W_t,z7,aRe,U_t,H_t,wie,J_t,Y_t,Z_t,Q7,nRe,K_t,e1t,Aie,o1t,r1t,t1t,W7,sRe,a1t,n1t,Lie,s1t,l1t,i1t,U7,lRe,d1t,m1t,yie,c1t,f1t,g1t,H7,iRe,h1t,u1t,xie,p1t,_1t,b1t,J7,dRe,v1t,F1t,$ie,T1t,M1t,E1t,Y7,mRe,C1t,w1t,kie,A1t,L1t,y1t,Z7,cRe,x1t,$1t,Sie,k1t,S1t,R1t,K7,fRe,P1t,B1t,Rie,I1t,N1t,q1t,e8,gRe,D1t,j1t,Pie,G1t,O1t,V1t,o8,hRe,X1t,z1t,Bie,Q1t,W1t,U1t,r8,uRe,H1t,J1t,Iie,Y1t,Z1t,K1t,t8,pRe,e2t,o2t,Nie,r2t,t2t,a2t,a8,_Re,n2t,s2t,qie,l2t,i2t,d2t,n8,bRe,m2t,c2t,Die,f2t,g2t,h2t,s8,vRe,u2t,p2t,jie,_2t,b2t,v2t,l8,FRe,F2t,T2t,Gie,M2t,E2t,C2t,i8,ndo,nf,d8,TRe,BB,w2t,MRe,A2t,sdo,Lr,IB,L2t,sf,y2t,Oie,x2t,$2t,Vie,k2t,S2t,R2t,NB,P2t,ERe,B2t,I2t,N2t,ha,qB,q2t,CRe,D2t,j2t,lf,G2t,wRe,O2t,V2t,Xie,X2t,z2t,Q2t,m8,W2t,tt,DB,U2t,ARe,H2t,J2t,es,Y2t,LRe,Z2t,K2t,yRe,ebt,obt,xRe,rbt,tbt,abt,he,c8,$Re,nbt,sbt,zie,lbt,ibt,dbt,f8,kRe,mbt,cbt,Qie,fbt,gbt,hbt,g8,SRe,ubt,pbt,Wie,_bt,bbt,vbt,h8,RRe,Fbt,Tbt,Uie,Mbt,Ebt,Cbt,u8,PRe,wbt,Abt,Hie,Lbt,ybt,xbt,p8,BRe,$bt,kbt,Jie,Sbt,Rbt,Pbt,_8,IRe,Bbt,Ibt,Yie,Nbt,qbt,Dbt,b8,NRe,jbt,Gbt,Zie,Obt,Vbt,Xbt,v8,qRe,zbt,Qbt,Kie,Wbt,Ubt,Hbt,F8,DRe,Jbt,Ybt,ede,Zbt,Kbt,evt,T8,jRe,ovt,rvt,ode,tvt,avt,nvt,M8,GRe,svt,lvt,rde,ivt,dvt,mvt,E8,ORe,cvt,fvt,tde,gvt,hvt,uvt,C8,VRe,pvt,_vt,ade,bvt,vvt,Fvt,w8,XRe,Tvt,Mvt,nde,Evt,Cvt,wvt,A8,zRe,Avt,Lvt,sde,yvt,xvt,$vt,L8,QRe,kvt,Svt,lde,Rvt,Pvt,Bvt,y8,WRe,Ivt,Nvt,ide,qvt,Dvt,jvt,x8,URe,Gvt,Ovt,dde,Vvt,Xvt,zvt,$8,HRe,Qvt,Wvt,mde,Uvt,Hvt,Jvt,k8,JRe,Yvt,Zvt,cde,Kvt,eFt,oFt,S8,ldo,df,R8,YRe,jB,rFt,ZRe,tFt,ido,yr,GB,aFt,mf,nFt,fde,sFt,lFt,gde,iFt,dFt,mFt,OB,cFt,KRe,fFt,gFt,hFt,ua,VB,uFt,ePe,pFt,_Ft,cf,bFt,oPe,vFt,FFt,hde,TFt,MFt,EFt,P8,CFt,at,XB,wFt,rPe,AFt,LFt,os,yFt,tPe,xFt,$Ft,aPe,kFt,SFt,nPe,RFt,PFt,BFt,sPe,B8,lPe,IFt,NFt,ude,qFt,DFt,jFt,I8,ddo,ff,N8,iPe,zB,GFt,dPe,OFt,mdo,xr,QB,VFt,gf,XFt,pde,zFt,QFt,_de,WFt,UFt,HFt,WB,JFt,mPe,YFt,ZFt,KFt,pa,UB,eTt,cPe,oTt,rTt,hf,tTt,fPe,aTt,nTt,bde,sTt,lTt,iTt,q8,dTt,nt,HB,mTt,gPe,cTt,fTt,rs,gTt,hPe,hTt,uTt,uPe,pTt,_Tt,pPe,bTt,vTt,FTt,JB,D8,_Pe,TTt,MTt,vde,ETt,CTt,wTt,j8,bPe,ATt,LTt,Fde,yTt,xTt,$Tt,G8,cdo,uf,O8,vPe,YB,kTt,FPe,STt,fdo,$r,ZB,RTt,pf,PTt,Tde,BTt,ITt,Mde,NTt,qTt,DTt,KB,jTt,TPe,GTt,OTt,VTt,_a,eI,XTt,MPe,zTt,QTt,_f,WTt,EPe,UTt,HTt,Ede,JTt,YTt,ZTt,V8,KTt,st,oI,eMt,CPe,oMt,rMt,ts,tMt,wPe,aMt,nMt,APe,sMt,lMt,LPe,iMt,dMt,mMt,ne,X8,yPe,cMt,fMt,Cde,gMt,hMt,uMt,z8,xPe,pMt,_Mt,wde,bMt,vMt,FMt,Q8,$Pe,TMt,MMt,Ade,EMt,CMt,wMt,W8,kPe,AMt,LMt,Lde,yMt,xMt,$Mt,U8,SPe,kMt,SMt,yde,RMt,PMt,BMt,H8,RPe,IMt,NMt,xde,qMt,DMt,jMt,J8,PPe,GMt,OMt,$de,VMt,XMt,zMt,Y8,BPe,QMt,WMt,kde,UMt,HMt,JMt,Z8,IPe,YMt,ZMt,Sde,KMt,eEt,oEt,K8,NPe,rEt,tEt,Rde,aEt,nEt,sEt,eL,qPe,lEt,iEt,Pde,dEt,mEt,cEt,oL,DPe,fEt,gEt,Bde,hEt,uEt,pEt,rL,jPe,_Et,bEt,Ide,vEt,FEt,TEt,tL,GPe,MEt,EEt,Nde,CEt,wEt,AEt,aL,OPe,LEt,yEt,qde,xEt,$Et,kEt,nL,VPe,SEt,REt,Dde,PEt,BEt,IEt,sL,XPe,NEt,qEt,jde,DEt,jEt,GEt,lL,zPe,OEt,VEt,Gde,XEt,zEt,QEt,iL,QPe,WEt,UEt,Ode,HEt,JEt,YEt,dL,WPe,ZEt,KEt,Vde,e4t,o4t,r4t,mL,UPe,t4t,a4t,Xde,n4t,s4t,l4t,cL,HPe,i4t,d4t,zde,m4t,c4t,f4t,fL,JPe,g4t,h4t,Qde,u4t,p4t,_4t,gL,YPe,b4t,v4t,Wde,F4t,T4t,M4t,hL,ZPe,E4t,C4t,Ude,w4t,A4t,L4t,uL,KPe,y4t,x4t,Hde,$4t,k4t,S4t,pL,eBe,R4t,P4t,Jde,B4t,I4t,N4t,_L,gdo,bf,bL,oBe,rI,q4t,rBe,D4t,hdo,kr,tI,j4t,vf,G4t,Yde,O4t,V4t,Zde,X4t,z4t,Q4t,aI,W4t,tBe,U4t,H4t,J4t,ba,nI,Y4t,aBe,Z4t,K4t,Ff,eCt,nBe,oCt,rCt,Kde,tCt,aCt,nCt,vL,sCt,lt,sI,lCt,sBe,iCt,dCt,as,mCt,lBe,cCt,fCt,iBe,gCt,hCt,dBe,uCt,pCt,_Ct,Se,FL,mBe,bCt,vCt,eme,FCt,TCt,MCt,TL,cBe,ECt,CCt,ome,wCt,ACt,LCt,ML,fBe,yCt,xCt,rme,$Ct,kCt,SCt,EL,gBe,RCt,PCt,tme,BCt,ICt,NCt,CL,hBe,qCt,DCt,ame,jCt,GCt,OCt,wL,uBe,VCt,XCt,nme,zCt,QCt,WCt,AL,pBe,UCt,HCt,sme,JCt,YCt,ZCt,LL,_Be,KCt,e3t,lme,o3t,r3t,t3t,yL,bBe,a3t,n3t,ime,s3t,l3t,i3t,xL,vBe,d3t,m3t,dme,c3t,f3t,g3t,$L,udo,Tf,kL,FBe,lI,h3t,TBe,u3t,pdo,Sr,iI,p3t,Mf,_3t,mme,b3t,v3t,cme,F3t,T3t,M3t,dI,E3t,MBe,C3t,w3t,A3t,va,mI,L3t,EBe,y3t,x3t,Ef,$3t,CBe,k3t,S3t,fme,R3t,P3t,B3t,SL,I3t,it,cI,N3t,wBe,q3t,D3t,ns,j3t,ABe,G3t,O3t,LBe,V3t,X3t,yBe,z3t,Q3t,W3t,we,RL,xBe,U3t,H3t,gme,J3t,Y3t,Z3t,PL,$Be,K3t,e5t,hme,o5t,r5t,t5t,BL,kBe,a5t,n5t,ume,s5t,l5t,i5t,IL,SBe,d5t,m5t,pme,c5t,f5t,g5t,NL,RBe,h5t,u5t,_me,p5t,_5t,b5t,qL,PBe,v5t,F5t,bme,T5t,M5t,E5t,DL,BBe,C5t,w5t,vme,A5t,L5t,y5t,jL,IBe,x5t,$5t,Fme,k5t,S5t,R5t,GL,NBe,P5t,B5t,Tme,I5t,N5t,q5t,OL,qBe,D5t,j5t,Mme,G5t,O5t,V5t,VL,DBe,X5t,z5t,Eme,Q5t,W5t,U5t,XL,jBe,H5t,J5t,Cme,Y5t,Z5t,K5t,zL,GBe,e0t,o0t,wme,r0t,t0t,a0t,QL,_do,Cf,WL,OBe,fI,n0t,VBe,s0t,bdo,Rr,gI,l0t,wf,i0t,Ame,d0t,m0t,Lme,c0t,f0t,g0t,hI,h0t,XBe,u0t,p0t,_0t,Fa,uI,b0t,zBe,v0t,F0t,Af,T0t,QBe,M0t,E0t,yme,C0t,w0t,A0t,UL,L0t,dt,pI,y0t,WBe,x0t,$0t,ss,k0t,UBe,S0t,R0t,HBe,P0t,B0t,JBe,I0t,N0t,q0t,Re,HL,YBe,D0t,j0t,xme,G0t,O0t,V0t,JL,ZBe,X0t,z0t,$me,Q0t,W0t,U0t,YL,KBe,H0t,J0t,kme,Y0t,Z0t,K0t,ZL,eIe,ewt,owt,Sme,rwt,twt,awt,KL,oIe,nwt,swt,Rme,lwt,iwt,dwt,ey,rIe,mwt,cwt,Pme,fwt,gwt,hwt,oy,tIe,uwt,pwt,Bme,_wt,bwt,vwt,ry,aIe,Fwt,Twt,Ime,Mwt,Ewt,Cwt,ty,nIe,wwt,Awt,Nme,Lwt,ywt,xwt,ay,sIe,$wt,kwt,qme,Swt,Rwt,Pwt,ny,vdo,Lf,sy,lIe,_I,Bwt,iIe,Iwt,Fdo,Pr,bI,Nwt,yf,qwt,Dme,Dwt,jwt,jme,Gwt,Owt,Vwt,vI,Xwt,dIe,zwt,Qwt,Wwt,Ta,FI,Uwt,mIe,Hwt,Jwt,xf,Ywt,cIe,Zwt,Kwt,Gme,eAt,oAt,rAt,ly,tAt,mt,TI,aAt,fIe,nAt,sAt,ls,lAt,gIe,iAt,dAt,hIe,mAt,cAt,uIe,fAt,gAt,hAt,Pe,iy,pIe,uAt,pAt,Ome,_At,bAt,vAt,dy,_Ie,FAt,TAt,Vme,MAt,EAt,CAt,my,bIe,wAt,AAt,Xme,LAt,yAt,xAt,cy,vIe,$At,kAt,zme,SAt,RAt,PAt,fy,FIe,BAt,IAt,Qme,NAt,qAt,DAt,gy,TIe,jAt,GAt,Wme,OAt,VAt,XAt,hy,MIe,zAt,QAt,Ume,WAt,UAt,HAt,uy,EIe,JAt,YAt,Hme,ZAt,KAt,e6t,py,CIe,o6t,r6t,Jme,t6t,a6t,n6t,_y,wIe,s6t,l6t,Yme,i6t,d6t,m6t,by,Tdo,$f,vy,AIe,MI,c6t,LIe,f6t,Mdo,Br,EI,g6t,kf,h6t,Zme,u6t,p6t,Kme,_6t,b6t,v6t,CI,F6t,yIe,T6t,M6t,E6t,Ma,wI,C6t,xIe,w6t,A6t,Sf,L6t,$Ie,y6t,x6t,ece,$6t,k6t,S6t,Fy,R6t,ct,AI,P6t,kIe,B6t,I6t,is,N6t,SIe,q6t,D6t,RIe,j6t,G6t,PIe,O6t,V6t,X6t,Be,Ty,BIe,z6t,Q6t,oce,W6t,U6t,H6t,My,IIe,J6t,Y6t,rce,Z6t,K6t,e7t,Ey,NIe,o7t,r7t,tce,t7t,a7t,n7t,Cy,qIe,s7t,l7t,ace,i7t,d7t,m7t,wy,DIe,c7t,f7t,nce,g7t,h7t,u7t,Ay,jIe,p7t,_7t,sce,b7t,v7t,F7t,Ly,GIe,T7t,M7t,lce,E7t,C7t,w7t,yy,OIe,A7t,L7t,ice,y7t,x7t,$7t,xy,VIe,k7t,S7t,dce,R7t,P7t,B7t,$y,XIe,I7t,N7t,mce,q7t,D7t,j7t,ky,Edo,Rf,Sy,zIe,LI,G7t,QIe,O7t,Cdo,Ir,yI,V7t,Pf,X7t,cce,z7t,Q7t,fce,W7t,U7t,H7t,xI,J7t,WIe,Y7t,Z7t,K7t,Ea,$I,e8t,UIe,o8t,r8t,Bf,t8t,HIe,a8t,n8t,gce,s8t,l8t,i8t,Ry,d8t,ft,kI,m8t,JIe,c8t,f8t,ds,g8t,YIe,h8t,u8t,ZIe,p8t,_8t,KIe,b8t,v8t,F8t,Ie,Py,eNe,T8t,M8t,hce,E8t,C8t,w8t,By,oNe,A8t,L8t,uce,y8t,x8t,$8t,Iy,rNe,k8t,S8t,pce,R8t,P8t,B8t,Ny,tNe,I8t,N8t,_ce,q8t,D8t,j8t,qy,aNe,G8t,O8t,bce,V8t,X8t,z8t,Dy,nNe,Q8t,W8t,vce,U8t,H8t,J8t,jy,sNe,Y8t,Z8t,Fce,K8t,eLt,oLt,Gy,lNe,rLt,tLt,Tce,aLt,nLt,sLt,Oy,iNe,lLt,iLt,Mce,dLt,mLt,cLt,Vy,dNe,fLt,gLt,Ece,hLt,uLt,pLt,Xy,wdo,If,zy,mNe,SI,_Lt,cNe,bLt,Ado,Nr,RI,vLt,Nf,FLt,Cce,TLt,MLt,wce,ELt,CLt,wLt,PI,ALt,fNe,LLt,yLt,xLt,Ca,BI,$Lt,gNe,kLt,SLt,qf,RLt,hNe,PLt,BLt,Ace,ILt,NLt,qLt,Qy,DLt,gt,II,jLt,uNe,GLt,OLt,ms,VLt,pNe,XLt,zLt,_Ne,QLt,WLt,bNe,ULt,HLt,JLt,We,Wy,vNe,YLt,ZLt,Lce,KLt,eyt,oyt,Uy,FNe,ryt,tyt,yce,ayt,nyt,syt,Hy,TNe,lyt,iyt,xce,dyt,myt,cyt,Jy,MNe,fyt,gyt,$ce,hyt,uyt,pyt,Yy,ENe,_yt,byt,kce,vyt,Fyt,Tyt,Zy,CNe,Myt,Eyt,Sce,Cyt,wyt,Ayt,Ky,wNe,Lyt,yyt,Rce,xyt,$yt,kyt,e9,ANe,Syt,Ryt,Pce,Pyt,Byt,Iyt,o9,Ldo,Df,r9,LNe,NI,Nyt,yNe,qyt,ydo,qr,qI,Dyt,jf,jyt,Bce,Gyt,Oyt,Ice,Vyt,Xyt,zyt,DI,Qyt,xNe,Wyt,Uyt,Hyt,wa,jI,Jyt,$Ne,Yyt,Zyt,Gf,Kyt,kNe,e9t,o9t,Nce,r9t,t9t,a9t,t9,n9t,ht,GI,s9t,SNe,l9t,i9t,cs,d9t,RNe,m9t,c9t,PNe,f9t,g9t,BNe,h9t,u9t,p9t,Ue,a9,INe,_9t,b9t,qce,v9t,F9t,T9t,n9,NNe,M9t,E9t,Dce,C9t,w9t,A9t,s9,qNe,L9t,y9t,jce,x9t,$9t,k9t,l9,DNe,S9t,R9t,Gce,P9t,B9t,I9t,i9,jNe,N9t,q9t,Oce,D9t,j9t,G9t,d9,GNe,O9t,V9t,Vce,X9t,z9t,Q9t,m9,ONe,W9t,U9t,Xce,H9t,J9t,Y9t,c9,VNe,Z9t,K9t,zce,ext,oxt,rxt,f9,xdo,Of,g9,XNe,OI,txt,zNe,axt,$do,Dr,VI,nxt,Vf,sxt,Qce,lxt,ixt,Wce,dxt,mxt,cxt,XI,fxt,QNe,gxt,hxt,uxt,Aa,zI,pxt,WNe,_xt,bxt,Xf,vxt,UNe,Fxt,Txt,Uce,Mxt,Ext,Cxt,h9,wxt,ut,QI,Axt,HNe,Lxt,yxt,fs,xxt,JNe,$xt,kxt,YNe,Sxt,Rxt,ZNe,Pxt,Bxt,Ixt,KNe,u9,eqe,Nxt,qxt,Hce,Dxt,jxt,Gxt,p9,kdo,zf,_9,oqe,WI,Oxt,rqe,Vxt,Sdo,jr,UI,Xxt,Qf,zxt,Jce,Qxt,Wxt,Yce,Uxt,Hxt,Jxt,HI,Yxt,tqe,Zxt,Kxt,e$t,La,JI,o$t,aqe,r$t,t$t,Wf,a$t,nqe,n$t,s$t,Zce,l$t,i$t,d$t,b9,m$t,pt,YI,c$t,sqe,f$t,g$t,gs,h$t,lqe,u$t,p$t,iqe,_$t,b$t,dqe,v$t,F$t,T$t,ZI,v9,mqe,M$t,E$t,Kce,C$t,w$t,A$t,F9,cqe,L$t,y$t,efe,x$t,$$t,k$t,T9,Rdo,Uf,M9,fqe,KI,S$t,gqe,R$t,Pdo,Gr,eN,P$t,Hf,B$t,ofe,I$t,N$t,rfe,q$t,D$t,j$t,oN,G$t,hqe,O$t,V$t,X$t,ya,rN,z$t,uqe,Q$t,W$t,Jf,U$t,pqe,H$t,J$t,tfe,Y$t,Z$t,K$t,E9,ekt,_t,tN,okt,_qe,rkt,tkt,hs,akt,bqe,nkt,skt,vqe,lkt,ikt,Fqe,dkt,mkt,ckt,Tqe,C9,Mqe,fkt,gkt,afe,hkt,ukt,pkt,w9,Bdo;return m=new oe({}),sn=new B({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),fk=new oe({}),gk=new B({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),ng=new lfo({props:{warning:!0,$$slots:{default:[Q9a]},$$scope:{ctx:$}}}),hk=new oe({}),uk=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L671"}}),bk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L694"}}),Iu=new N({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[W9a]},$$scope:{ctx:$}}}),vk=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L817"}}),Fk=new oe({}),Tk=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L450"}}),Ck=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/main/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L464"}}),Mp=new N({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[U9a]},$$scope:{ctx:$}}}),wk=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L665"}}),Ak=new oe({}),Lk=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L205"}}),$k=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/main/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L219"}}),p_=new lfo({props:{$$slots:{default:[H9a]},$$scope:{ctx:$}}}),__=new N({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[J9a]},$$scope:{ctx:$}}}),kk=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L346"}}),Sk=new oe({}),Rk=new R({props:{name:"class transformers.AutoImageProcessor",anchor:"transformers.AutoImageProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/image_processing_auto.py#L189"}}),Ik=new R({props:{name:"from_pretrained",anchor:"transformers.AutoImageProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoImageProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained image_processor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a image processor file saved using the
<a href="/docs/transformers/main/en/internal/image_processing_utils#transformers.ImageProcessingMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved image processor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoImageProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model image processor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoImageProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the image processor files and override the cached versions if
they exist.`,name:"force_download"},{anchor:"transformers.AutoImageProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoImageProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoImageProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoImageProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoImageProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final image processor object. If <code>True</code>, then this
functions returns a <code>Tuple(image_processor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not image processor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>image_processor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoImageProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoImageProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are image processor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> image processor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/image_processing_auto.py#L203"}}),H_=new lfo({props:{$$slots:{default:[Y9a]},$$scope:{ctx:$}}}),J_=new N({props:{anchor:"transformers.AutoImageProcessor.from_pretrained.example",$$slots:{default:[Z9a]},$$scope:{ctx:$}}}),Nk=new R({props:{name:"register",anchor:"transformers.AutoImageProcessor.register",parameters:[{name:"config_class",val:""},{name:"image_processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoImageProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoImageProcessor.register.image_processor_class",description:'<strong>image_processor_class</strong> (<a href="/docs/transformers/main/en/internal/image_processing_utils#transformers.ImageProcessingMixin">ImageProcessingMixin</a>) &#x2014; The image processor to register.',name:"image_processor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/image_processing_auto.py#L348"}}),qk=new oe({}),Dk=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L98"}}),Ok=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L112"}}),M1=new lfo({props:{$$slots:{default:[K9a]},$$scope:{ctx:$}}}),E1=new N({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[exa]},$$scope:{ctx:$}}}),Vk=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L293"}}),Xk=new oe({}),zk=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L898"}}),Wk=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clipseg#transformers.CLIPSegConfig">CLIPSegConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clipseg#transformers.CLIPSegModel">CLIPSegModel</a> (CLIPSeg model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel">CodeGenModel</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig">ConditionalDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrModel">ConditionalDetrModel</a> (Conditional DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrModel">DeformableDetrModel</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig">DonutSwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel">DonutSwinModel</a> (DonutSwin model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel">ErnieModel</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmModel">EsmModel</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig">GPTNeoXJapaneseConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel">GPTNeoXJapaneseModel</a> (GPT NeoX Japanese model)</li>
<li><a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel">GroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltModel">LiltModel</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMModel">MarkupLMModel</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel">MobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel">MvpModel</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel">NezhaModel</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel">OwlViTModel</a> (OWL-ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel">PegasusXModel</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertModel">RoCBertModel</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model">Swinv2Model</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerConfig">TableTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerModel">TableTransformerModel</a> (Table Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig">TimeSeriesTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel">TimeSeriesTransformerModel</a> (Time Series Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig">ViTMSNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNModel">ViTMSNModel</a> (ViTMSN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel">VideoMAEModel</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperModel">WhisperModel</a> (Whisper model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig">XCLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel">XCLIPModel</a> (X-CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),A1=new N({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[oxa]},$$scope:{ctx:$}}}),Uk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Jb=new N({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[rxa]},$$scope:{ctx:$}}}),Hk=new oe({}),Jk=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L905"}}),Zk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining">ErnieForPreTraining</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining">NezhaForPreTraining</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForPreTraining">RoCBertForPreTraining</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining">VideoMAEForPreTraining</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Zb=new N({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[txa]},$$scope:{ctx:$}}}),Kk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Hv=new N({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[axa]},$$scope:{ctx:$}}}),eS=new oe({}),oS=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L920"}}),tS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM">CodeGenForCausalLM</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM">ErnieForCausalLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig">GPTNeoXJapaneseConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM">GPTNeoXJapaneseForCausalLM</a> (GPT NeoX Japanese model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM">MvpForCausalLM</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForCausalLM">RoCBertForCausalLM</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Yv=new N({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[nxa]},$$scope:{ctx:$}}}),aS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),OF=new N({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[sxa]},$$scope:{ctx:$}}}),nS=new oe({}),sS=new R({props:{name:"class transformers.AutoModelForDepthEstimation",anchor:"transformers.AutoModelForDepthEstimation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1063"}}),iS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForDepthEstimation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDepthEstimation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTForDepthEstimation">DPTForDepthEstimation</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNForDepthEstimation">GLPNForDepthEstimation</a> (GLPN model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),XF=new N({props:{anchor:"transformers.AutoModelForDepthEstimation.from_config.example",$$slots:{default:[lxa]},$$scope:{ctx:$}}}),dS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForDepthEstimation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),UF=new N({props:{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.example",$$slots:{default:[ixa]},$$scope:{ctx:$}}}),cS=new oe({}),fS=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L927"}}),hS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM">ErnieForMaskedLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM">NezhaForMaskedLM</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForMaskedLM">RoCBertForMaskedLM</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),JF=new N({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[dxa]},$$scope:{ctx:$}}}),uS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),qT=new N({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[mxa]},$$scope:{ctx:$}}}),pS=new oe({}),_S=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L934"}}),vS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration">PegasusXForConditionalGeneration</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),jT=new N({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[cxa]},$$scope:{ctx:$}}}),FS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),iM=new N({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[fxa]},$$scope:{ctx:$}}}),TS=new oe({}),MS=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L943"}}),CS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification">ErnieForSequenceClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmForSequenceClassification">EsmForSequenceClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltForSequenceClassification">LiltForSequenceClassification</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification">LukeForSequenceClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification">MarkupLMForSequenceClassification</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification">MvpForSequenceClassification</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification">NezhaForSequenceClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification">OPTForSequenceClassification</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForSequenceClassification">RoCBertForSequenceClassification</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),mM=new N({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[gxa]},$$scope:{ctx:$}}}),wS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),uE=new N({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[hxa]},$$scope:{ctx:$}}}),AS=new oe({}),LS=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L999"}}),xS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice">ErnieForMultipleChoice</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice">LukeForMultipleChoice</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice">NezhaForMultipleChoice</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForMultipleChoice">RoCBertForMultipleChoice</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),_E=new N({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[uxa]},$$scope:{ctx:$}}}),$S=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),ZE=new N({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[pxa]},$$scope:{ctx:$}}}),kS=new oe({}),SS=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1006"}}),PS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction">ErnieForNextSentencePrediction</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction">NezhaForNextSentencePrediction</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),e4=new N({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[_xa]},$$scope:{ctx:$}}}),BS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),d4=new N({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[bxa]},$$scope:{ctx:$}}}),IS=new oe({}),NS=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L992"}}),DS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification">ErnieForTokenClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmForTokenClassification">EsmForTokenClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltForTokenClassification">LiltForTokenClassification</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification">LukeForTokenClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification">MarkupLMForTokenClassification</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification">NezhaForTokenClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForTokenClassification">RoCBertForTokenClassification</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),c4=new N({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[vxa]},$$scope:{ctx:$}}}),jS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),oC=new N({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[Fxa]},$$scope:{ctx:$}}}),GS=new oe({}),OS=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L952"}}),XS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForQuestionAnswering">BloomForQuestionAnswering</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering">ErnieForQuestionAnswering</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltForQuestionAnswering">LiltForQuestionAnswering</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering">LukeForQuestionAnswering</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering">MarkupLMForQuestionAnswering</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering">MvpForQuestionAnswering</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering">NezhaForQuestionAnswering</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForQuestionAnswering">OPTForQuestionAnswering</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForQuestionAnswering">RoCBertForQuestionAnswering</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),tC=new N({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[Txa]},$$scope:{ctx:$}}}),zS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),e3=new N({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[Mxa]},$$scope:{ctx:$}}}),QS=new oe({}),WS=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L959"}}),HS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),r3=new N({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[Exa]},$$scope:{ctx:$}}}),JS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),n3=new N({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[Cxa]},$$scope:{ctx:$}}}),YS=new oe({}),ZS=new R({props:{name:"class transformers.AutoModelForDocumentQuestionAnswering",anchor:"transformers.AutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L981"}}),eR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering">LayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),l3=new N({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[wxa]},$$scope:{ctx:$}}}),oR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),f3=new N({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[Axa]},$$scope:{ctx:$}}}),rR=new oe({}),tR=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1015"}}),nR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification">MobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification">Swinv2ForImageClassification</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig">ViTMSNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification">ViTMSNForImageClassification</a> (ViTMSN model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),h3=new N({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[Lxa]},$$scope:{ctx:$}}}),sR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),k3=new N({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[yxa]},$$scope:{ctx:$}}}),lR=new oe({}),iR=new R({props:{name:"class transformers.AutoModelForVideoClassification",anchor:"transformers.AutoModelForVideoClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1070"}}),mR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVideoClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification">VideoMAEForVideoClassification</a> (VideoMAE model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),R3=new N({props:{anchor:"transformers.AutoModelForVideoClassification.from_config.example",$$slots:{default:[xxa]},$$scope:{ctx:$}}}),cR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVideoClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),I3=new N({props:{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.example",$$slots:{default:[$xa]},$$scope:{ctx:$}}}),fR=new oe({}),gR=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1077"}}),uR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),q3=new N({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[kxa]},$$scope:{ctx:$}}}),pR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),G3=new N({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[Sxa]},$$scope:{ctx:$}}}),_R=new oe({}),bR=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L970"}}),FR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),V3=new N({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[Rxa]},$$scope:{ctx:$}}}),TR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Q3=new N({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[Pxa]},$$scope:{ctx:$}}}),MR=new oe({}),ER=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1084"}}),wR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),U3=new N({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[Bxa]},$$scope:{ctx:$}}}),AR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),n5=new N({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[Ixa]},$$scope:{ctx:$}}}),LR=new oe({}),yR=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1107"}}),$R=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),l5=new N({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[Nxa]},$$scope:{ctx:$}}}),kR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),h5=new N({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[qxa]},$$scope:{ctx:$}}}),SR=new oe({}),RR=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1091"}}),BR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),p5=new N({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[Dxa]},$$scope:{ctx:$}}}),IR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),y5=new N({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[jxa]},$$scope:{ctx:$}}}),NR=new oe({}),qR=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1098"}}),jR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperForConditionalGeneration">WhisperForConditionalGeneration</a> (Whisper model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),$5=new N({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[Gxa]},$$scope:{ctx:$}}}),GR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),B5=new N({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[Oxa]},$$scope:{ctx:$}}}),OR=new oe({}),VR=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1116"}}),zR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),N5=new N({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[Vxa]},$$scope:{ctx:$}}}),QR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),X5=new N({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[Xxa]},$$scope:{ctx:$}}}),WR=new oe({}),UR=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1123"}}),JR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling">Swinv2ForMaskedImageModeling</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Q5=new N({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[zxa]},$$scope:{ctx:$}}}),YR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Z5=new N({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[Qxa]},$$scope:{ctx:$}}}),ZR=new oe({}),KR=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1047"}}),oP=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig">ConditionalDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection">ConditionalDetrForObjectDetection</a> (Conditional DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection">DeformableDetrForObjectDetection</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerConfig">TableTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerForObjectDetection">TableTransformerForObjectDetection</a> (Table Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),e0=new N({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[Wxa]},$$scope:{ctx:$}}}),rP=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),l0=new N({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[Uxa]},$$scope:{ctx:$}}}),tP=new oe({}),aP=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1022"}}),sP=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),d0=new N({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[Hxa]},$$scope:{ctx:$}}}),lP=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),f0=new N({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[Jxa]},$$scope:{ctx:$}}}),iP=new oe({}),dP=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1029"}}),cP=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation">MobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),h0=new N({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[Yxa]},$$scope:{ctx:$}}}),fP=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),T0=new N({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[Zxa]},$$scope:{ctx:$}}}),gP=new oe({}),hP=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1038"}}),pP=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),E0=new N({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[Kxa]},$$scope:{ctx:$}}}),_P=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),A0=new N({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[e$a]},$$scope:{ctx:$}}}),bP=new oe({}),vP=new R({props:{name:"class transformers.AutoModelForZeroShotObjectDetection",anchor:"transformers.AutoModelForZeroShotObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1054"}}),TP=new R({props:{name:"from_config",anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTForObjectDetection">OwlViTForObjectDetection</a> (OWL-ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),y0=new N({props:{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config.example",$$slots:{default:[o$a]},$$scope:{ctx:$}}}),MP=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),k0=new N({props:{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.example",$$slots:{default:[r$a]},$$scope:{ctx:$}}}),EP=new oe({}),CP=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L444"}}),AP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtModel">TFCvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel">TFDeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmModel">TFEsmModel</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/groupvit#transformers.TFGroupViTModel">TFGroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model">TFLayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel">TFMobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel">TFRegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel">TFResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel">TFSegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperModel">TFWhisperModel</a> (Whisper model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel">TFXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),R0=new N({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[t$a]},$$scope:{ctx:$}}}),LP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Nw=new N({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[a$a]},$$scope:{ctx:$}}}),yP=new oe({}),xP=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L451"}}),kP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Dw=new N({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[n$a]},$$scope:{ctx:$}}}),SP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),dA=new N({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[s$a]},$$scope:{ctx:$}}}),RP=new oe({}),PP=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L466"}}),IP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM">TFXGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),cA=new N({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[l$a]},$$scope:{ctx:$}}}),NP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),AA=new N({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[i$a]},$$scope:{ctx:$}}}),qP=new oe({}),DP=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L482"}}),GP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtForImageClassification">TFCvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification">TFDeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher">TFDeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification">TFMobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification">TFRegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification">TFResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification">TFSegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),yA=new N({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[d$a]},$$scope:{ctx:$}}}),OP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),qA=new N({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[m$a]},$$scope:{ctx:$}}}),VP=new oe({}),XP=new R({props:{name:"class transformers.TFAutoModelForSemanticSegmentation",anchor:"transformers.TFAutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L491"}}),QP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation">TFData2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation">TFMobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation">TFSegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),jA=new N({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[c$a]},$$scope:{ctx:$}}}),WP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),XA=new N({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[f$a]},$$scope:{ctx:$}}}),UP=new oe({}),HP=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L507"}}),YP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForMaskedLM">TFEsmForMaskedLM</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),QA=new N({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[g$a]},$$scope:{ctx:$}}}),ZP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),h6=new N({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[h$a]},$$scope:{ctx:$}}}),KP=new oe({}),eB=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L514"}}),rB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),p6=new N({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[u$a]},$$scope:{ctx:$}}}),tB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),L6=new N({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[p$a]},$$scope:{ctx:$}}}),aB=new oe({}),nB=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L523"}}),lB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForSequenceClassification">TFEsmForSequenceClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification">TFLayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),x6=new N({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[_$a]},$$scope:{ctx:$}}}),iB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),a7=new N({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[b$a]},$$scope:{ctx:$}}}),dB=new oe({}),mB=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L570"}}),fB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),s7=new N({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[v$a]},$$scope:{ctx:$}}}),gB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),C7=new N({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[F$a]},$$scope:{ctx:$}}}),hB=new oe({}),uB=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L577"}}),_B=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),A7=new N({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[T$a]},$$scope:{ctx:$}}}),bB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),x7=new N({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[M$a]},$$scope:{ctx:$}}}),FB=new oe({}),TB=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L550"}}),EB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),k7=new N({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[E$a]},$$scope:{ctx:$}}}),CB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),R7=new N({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[C$a]},$$scope:{ctx:$}}}),wB=new oe({}),AB=new R({props:{name:"class transformers.TFAutoModelForDocumentQuestionAnswering",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L539"}}),yB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering">TFLayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),B7=new N({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[w$a]},$$scope:{ctx:$}}}),xB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),N7=new N({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[A$a]},$$scope:{ctx:$}}}),$B=new oe({}),kB=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L561"}}),RB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForTokenClassification">TFEsmForTokenClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification">TFLayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),D7=new N({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[L$a]},$$scope:{ctx:$}}}),PB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),i8=new N({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[y$a]},$$scope:{ctx:$}}}),BB=new oe({}),IB=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L532"}}),qB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering">TFLayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),m8=new N({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[x$a]},$$scope:{ctx:$}}}),DB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),S8=new N({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[$$a]},$$scope:{ctx:$}}}),jB=new oe({}),GB=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L500"}}),VB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),P8=new N({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[k$a]},$$scope:{ctx:$}}}),XB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),I8=new N({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[S$a]},$$scope:{ctx:$}}}),zB=new oe({}),QB=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L586"}}),UB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration">TFWhisperForConditionalGeneration</a> (Whisper model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),q8=new N({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[R$a]},$$scope:{ctx:$}}}),HB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),G8=new N({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[P$a]},$$scope:{ctx:$}}}),YB=new oe({}),ZB=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),eI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),V8=new N({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[B$a]},$$scope:{ctx:$}}}),oI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),_L=new N({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[I$a]},$$scope:{ctx:$}}}),rI=new oe({}),tI=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L260"}}),nI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),vL=new N({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[N$a]},$$scope:{ctx:$}}}),sI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),$L=new N({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[q$a]},$$scope:{ctx:$}}}),lI=new oe({}),iI=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L253"}}),mI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),SL=new N({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[D$a]},$$scope:{ctx:$}}}),cI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),QL=new N({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[j$a]},$$scope:{ctx:$}}}),fI=new oe({}),gI=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L267"}}),uI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),UL=new N({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[G$a]},$$scope:{ctx:$}}}),pI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),ny=new N({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[O$a]},$$scope:{ctx:$}}}),_I=new oe({}),bI=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),FI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),ly=new N({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[V$a]},$$scope:{ctx:$}}}),TI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),by=new N({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[X$a]},$$scope:{ctx:$}}}),MI=new oe({}),EI=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),wI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Fy=new N({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[z$a]},$$scope:{ctx:$}}}),AI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),ky=new N({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[Q$a]},$$scope:{ctx:$}}}),LI=new oe({}),yI=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),$I=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Ry=new N({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[W$a]},$$scope:{ctx:$}}}),kI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Xy=new N({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[U$a]},$$scope:{ctx:$}}}),SI=new oe({}),RI=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),BI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Qy=new N({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[H$a]},$$scope:{ctx:$}}}),II=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),o9=new N({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[J$a]},$$scope:{ctx:$}}}),NI=new oe({}),qI=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L308"}}),jI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),t9=new N({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[Y$a]},$$scope:{ctx:$}}}),GI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),f9=new N({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[Z$a]},$$scope:{ctx:$}}}),OI=new oe({}),VI=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),zI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),h9=new N({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[K$a]},$$scope:{ctx:$}}}),QI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),p9=new N({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[eka]},$$scope:{ctx:$}}}),WI=new oe({}),UI=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),JI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),b9=new N({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[oka]},$$scope:{ctx:$}}}),YI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),T9=new N({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[rka]},$$scope:{ctx:$}}}),KI=new oe({}),eN=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),rN=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),E9=new N({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[tka]},$$scope:{ctx:$}}}),tN=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),w9=new N({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[aka]},$$scope:{ctx:$}}}),{c(){g=a("meta"),v=l(),u=a("h1"),f=a("a"),p=a("span"),F(m.$$.fragment),h=l(),He=a("span"),Ad=o("Auto Classes"),eg=l(),wt=a("p"),Ld=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),yd=a("code"),ik=o("from_pretrained()"),og=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Qe=l(),Ze=a("p"),xd=o("Instantiating one of "),ps=a("a"),dk=o("AutoConfig"),_s=o(", "),bs=a("a"),mk=o("AutoModel"),$d=o(`, and
`),vs=a("a"),ck=o("AutoTokenizer"),kd=o(" will directly create a class of the relevant architecture. For instance"),rg=l(),F(sn.$$.fragment),Ke=l(),ye=a("p"),Sq=o("will create a model that is an instance of "),Sd=a("a"),Rq=o("BertModel"),Pq=o("."),Po=l(),ln=a("p"),Bq=o("There is one class of "),tg=a("code"),Iq=o("AutoModel"),ifo=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),plo=l(),Rd=a("h2"),ag=a("a"),ghe=a("span"),F(fk.$$.fragment),dfo=l(),hhe=a("span"),mfo=o("Extending the Auto Classes"),_lo=l(),Fs=a("p"),cfo=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),uhe=a("code"),ffo=o("NewModel"),gfo=o(", make sure you have a "),phe=a("code"),hfo=o("NewModelConfig"),ufo=o(` then you can add those to the auto
classes like this:`),blo=l(),F(gk.$$.fragment),vlo=l(),Nq=a("p"),pfo=o("You will then be able to use the auto classes like you would usually do!"),Flo=l(),F(ng.$$.fragment),Tlo=l(),Pd=a("h2"),sg=a("a"),_he=a("span"),F(hk.$$.fragment),_fo=l(),bhe=a("span"),bfo=o("AutoConfig"),Mlo=l(),Bo=a("div"),F(uk.$$.fragment),vfo=l(),pk=a("p"),Ffo=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),qq=a("a"),Tfo=o("from_pretrained()"),Mfo=o(" class method."),Efo=l(),_k=a("p"),Cfo=o("This class cannot be instantiated directly using "),vhe=a("code"),wfo=o("__init__()"),Afo=o(" (throws an error)."),Lfo=l(),Or=a("div"),F(bk.$$.fragment),yfo=l(),Fhe=a("p"),xfo=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),$fo=l(),Bd=a("p"),kfo=o("The configuration class to instantiate is selected based on the "),The=a("code"),Sfo=o("model_type"),Rfo=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Mhe=a("code"),Pfo=o("pretrained_model_name_or_path"),Bfo=o(":"),Ifo=l(),A=a("ul"),lg=a("li"),Ehe=a("strong"),Nfo=o("albert"),qfo=o(" \u2014 "),Dq=a("a"),Dfo=o("AlbertConfig"),jfo=o(" (ALBERT model)"),Gfo=l(),ig=a("li"),Che=a("strong"),Ofo=o("bart"),Vfo=o(" \u2014 "),jq=a("a"),Xfo=o("BartConfig"),zfo=o(" (BART model)"),Qfo=l(),dg=a("li"),whe=a("strong"),Wfo=o("beit"),Ufo=o(" \u2014 "),Gq=a("a"),Hfo=o("BeitConfig"),Jfo=o(" (BEiT model)"),Yfo=l(),mg=a("li"),Ahe=a("strong"),Zfo=o("bert"),Kfo=o(" \u2014 "),Oq=a("a"),ego=o("BertConfig"),ogo=o(" (BERT model)"),rgo=l(),cg=a("li"),Lhe=a("strong"),tgo=o("bert-generation"),ago=o(" \u2014 "),Vq=a("a"),ngo=o("BertGenerationConfig"),sgo=o(" (Bert Generation model)"),lgo=l(),fg=a("li"),yhe=a("strong"),igo=o("big_bird"),dgo=o(" \u2014 "),Xq=a("a"),mgo=o("BigBirdConfig"),cgo=o(" (BigBird model)"),fgo=l(),gg=a("li"),xhe=a("strong"),ggo=o("bigbird_pegasus"),hgo=o(" \u2014 "),zq=a("a"),ugo=o("BigBirdPegasusConfig"),pgo=o(" (BigBird-Pegasus model)"),_go=l(),hg=a("li"),$he=a("strong"),bgo=o("blenderbot"),vgo=o(" \u2014 "),Qq=a("a"),Fgo=o("BlenderbotConfig"),Tgo=o(" (Blenderbot model)"),Mgo=l(),ug=a("li"),khe=a("strong"),Ego=o("blenderbot-small"),Cgo=o(" \u2014 "),Wq=a("a"),wgo=o("BlenderbotSmallConfig"),Ago=o(" (BlenderbotSmall model)"),Lgo=l(),pg=a("li"),She=a("strong"),ygo=o("bloom"),xgo=o(" \u2014 "),Uq=a("a"),$go=o("BloomConfig"),kgo=o(" (BLOOM model)"),Sgo=l(),_g=a("li"),Rhe=a("strong"),Rgo=o("camembert"),Pgo=o(" \u2014 "),Hq=a("a"),Bgo=o("CamembertConfig"),Igo=o(" (CamemBERT model)"),Ngo=l(),bg=a("li"),Phe=a("strong"),qgo=o("canine"),Dgo=o(" \u2014 "),Jq=a("a"),jgo=o("CanineConfig"),Ggo=o(" (CANINE model)"),Ogo=l(),vg=a("li"),Bhe=a("strong"),Vgo=o("clip"),Xgo=o(" \u2014 "),Yq=a("a"),zgo=o("CLIPConfig"),Qgo=o(" (CLIP model)"),Wgo=l(),Fg=a("li"),Ihe=a("strong"),Ugo=o("clipseg"),Hgo=o(" \u2014 "),Zq=a("a"),Jgo=o("CLIPSegConfig"),Ygo=o(" (CLIPSeg model)"),Zgo=l(),Tg=a("li"),Nhe=a("strong"),Kgo=o("codegen"),eho=o(" \u2014 "),Kq=a("a"),oho=o("CodeGenConfig"),rho=o(" (CodeGen model)"),tho=l(),Mg=a("li"),qhe=a("strong"),aho=o("conditional_detr"),nho=o(" \u2014 "),eD=a("a"),sho=o("ConditionalDetrConfig"),lho=o(" (Conditional DETR model)"),iho=l(),Eg=a("li"),Dhe=a("strong"),dho=o("convbert"),mho=o(" \u2014 "),oD=a("a"),cho=o("ConvBertConfig"),fho=o(" (ConvBERT model)"),gho=l(),Cg=a("li"),jhe=a("strong"),hho=o("convnext"),uho=o(" \u2014 "),rD=a("a"),pho=o("ConvNextConfig"),_ho=o(" (ConvNeXT model)"),bho=l(),wg=a("li"),Ghe=a("strong"),vho=o("ctrl"),Fho=o(" \u2014 "),tD=a("a"),Tho=o("CTRLConfig"),Mho=o(" (CTRL model)"),Eho=l(),Ag=a("li"),Ohe=a("strong"),Cho=o("cvt"),who=o(" \u2014 "),aD=a("a"),Aho=o("CvtConfig"),Lho=o(" (CvT model)"),yho=l(),Lg=a("li"),Vhe=a("strong"),xho=o("data2vec-audio"),$ho=o(" \u2014 "),nD=a("a"),kho=o("Data2VecAudioConfig"),Sho=o(" (Data2VecAudio model)"),Rho=l(),yg=a("li"),Xhe=a("strong"),Pho=o("data2vec-text"),Bho=o(" \u2014 "),sD=a("a"),Iho=o("Data2VecTextConfig"),Nho=o(" (Data2VecText model)"),qho=l(),xg=a("li"),zhe=a("strong"),Dho=o("data2vec-vision"),jho=o(" \u2014 "),lD=a("a"),Gho=o("Data2VecVisionConfig"),Oho=o(" (Data2VecVision model)"),Vho=l(),$g=a("li"),Qhe=a("strong"),Xho=o("deberta"),zho=o(" \u2014 "),iD=a("a"),Qho=o("DebertaConfig"),Who=o(" (DeBERTa model)"),Uho=l(),kg=a("li"),Whe=a("strong"),Hho=o("deberta-v2"),Jho=o(" \u2014 "),dD=a("a"),Yho=o("DebertaV2Config"),Zho=o(" (DeBERTa-v2 model)"),Kho=l(),Sg=a("li"),Uhe=a("strong"),euo=o("decision_transformer"),ouo=o(" \u2014 "),mD=a("a"),ruo=o("DecisionTransformerConfig"),tuo=o(" (Decision Transformer model)"),auo=l(),Rg=a("li"),Hhe=a("strong"),nuo=o("deformable_detr"),suo=o(" \u2014 "),cD=a("a"),luo=o("DeformableDetrConfig"),iuo=o(" (Deformable DETR model)"),duo=l(),Pg=a("li"),Jhe=a("strong"),muo=o("deit"),cuo=o(" \u2014 "),fD=a("a"),fuo=o("DeiTConfig"),guo=o(" (DeiT model)"),huo=l(),Bg=a("li"),Yhe=a("strong"),uuo=o("detr"),puo=o(" \u2014 "),gD=a("a"),_uo=o("DetrConfig"),buo=o(" (DETR model)"),vuo=l(),Ig=a("li"),Zhe=a("strong"),Fuo=o("distilbert"),Tuo=o(" \u2014 "),hD=a("a"),Muo=o("DistilBertConfig"),Euo=o(" (DistilBERT model)"),Cuo=l(),Ng=a("li"),Khe=a("strong"),wuo=o("donut-swin"),Auo=o(" \u2014 "),uD=a("a"),Luo=o("DonutSwinConfig"),yuo=o(" (DonutSwin model)"),xuo=l(),qg=a("li"),eue=a("strong"),$uo=o("dpr"),kuo=o(" \u2014 "),pD=a("a"),Suo=o("DPRConfig"),Ruo=o(" (DPR model)"),Puo=l(),Dg=a("li"),oue=a("strong"),Buo=o("dpt"),Iuo=o(" \u2014 "),_D=a("a"),Nuo=o("DPTConfig"),quo=o(" (DPT model)"),Duo=l(),jg=a("li"),rue=a("strong"),juo=o("electra"),Guo=o(" \u2014 "),bD=a("a"),Ouo=o("ElectraConfig"),Vuo=o(" (ELECTRA model)"),Xuo=l(),Gg=a("li"),tue=a("strong"),zuo=o("encoder-decoder"),Quo=o(" \u2014 "),vD=a("a"),Wuo=o("EncoderDecoderConfig"),Uuo=o(" (Encoder decoder model)"),Huo=l(),Og=a("li"),aue=a("strong"),Juo=o("ernie"),Yuo=o(" \u2014 "),FD=a("a"),Zuo=o("ErnieConfig"),Kuo=o(" (ERNIE model)"),epo=l(),Vg=a("li"),nue=a("strong"),opo=o("esm"),rpo=o(" \u2014 "),TD=a("a"),tpo=o("EsmConfig"),apo=o(" (ESM model)"),npo=l(),Xg=a("li"),sue=a("strong"),spo=o("flaubert"),lpo=o(" \u2014 "),MD=a("a"),ipo=o("FlaubertConfig"),dpo=o(" (FlauBERT model)"),mpo=l(),zg=a("li"),lue=a("strong"),cpo=o("flava"),fpo=o(" \u2014 "),ED=a("a"),gpo=o("FlavaConfig"),hpo=o(" (FLAVA model)"),upo=l(),Qg=a("li"),iue=a("strong"),ppo=o("fnet"),_po=o(" \u2014 "),CD=a("a"),bpo=o("FNetConfig"),vpo=o(" (FNet model)"),Fpo=l(),Wg=a("li"),due=a("strong"),Tpo=o("fsmt"),Mpo=o(" \u2014 "),wD=a("a"),Epo=o("FSMTConfig"),Cpo=o(" (FairSeq Machine-Translation model)"),wpo=l(),Ug=a("li"),mue=a("strong"),Apo=o("funnel"),Lpo=o(" \u2014 "),AD=a("a"),ypo=o("FunnelConfig"),xpo=o(" (Funnel Transformer model)"),$po=l(),Hg=a("li"),cue=a("strong"),kpo=o("glpn"),Spo=o(" \u2014 "),LD=a("a"),Rpo=o("GLPNConfig"),Ppo=o(" (GLPN model)"),Bpo=l(),Jg=a("li"),fue=a("strong"),Ipo=o("gpt2"),Npo=o(" \u2014 "),yD=a("a"),qpo=o("GPT2Config"),Dpo=o(" (OpenAI GPT-2 model)"),jpo=l(),Yg=a("li"),gue=a("strong"),Gpo=o("gpt_neo"),Opo=o(" \u2014 "),xD=a("a"),Vpo=o("GPTNeoConfig"),Xpo=o(" (GPT Neo model)"),zpo=l(),Zg=a("li"),hue=a("strong"),Qpo=o("gpt_neox"),Wpo=o(" \u2014 "),$D=a("a"),Upo=o("GPTNeoXConfig"),Hpo=o(" (GPT NeoX model)"),Jpo=l(),Kg=a("li"),uue=a("strong"),Ypo=o("gpt_neox_japanese"),Zpo=o(" \u2014 "),kD=a("a"),Kpo=o("GPTNeoXJapaneseConfig"),e_o=o(" (GPT NeoX Japanese model)"),o_o=l(),eh=a("li"),pue=a("strong"),r_o=o("gptj"),t_o=o(" \u2014 "),SD=a("a"),a_o=o("GPTJConfig"),n_o=o(" (GPT-J model)"),s_o=l(),oh=a("li"),_ue=a("strong"),l_o=o("groupvit"),i_o=o(" \u2014 "),RD=a("a"),d_o=o("GroupViTConfig"),m_o=o(" (GroupViT model)"),c_o=l(),rh=a("li"),bue=a("strong"),f_o=o("hubert"),g_o=o(" \u2014 "),PD=a("a"),h_o=o("HubertConfig"),u_o=o(" (Hubert model)"),p_o=l(),th=a("li"),vue=a("strong"),__o=o("ibert"),b_o=o(" \u2014 "),BD=a("a"),v_o=o("IBertConfig"),F_o=o(" (I-BERT model)"),T_o=l(),ah=a("li"),Fue=a("strong"),M_o=o("imagegpt"),E_o=o(" \u2014 "),ID=a("a"),C_o=o("ImageGPTConfig"),w_o=o(" (ImageGPT model)"),A_o=l(),nh=a("li"),Tue=a("strong"),L_o=o("layoutlm"),y_o=o(" \u2014 "),ND=a("a"),x_o=o("LayoutLMConfig"),$_o=o(" (LayoutLM model)"),k_o=l(),sh=a("li"),Mue=a("strong"),S_o=o("layoutlmv2"),R_o=o(" \u2014 "),qD=a("a"),P_o=o("LayoutLMv2Config"),B_o=o(" (LayoutLMv2 model)"),I_o=l(),lh=a("li"),Eue=a("strong"),N_o=o("layoutlmv3"),q_o=o(" \u2014 "),DD=a("a"),D_o=o("LayoutLMv3Config"),j_o=o(" (LayoutLMv3 model)"),G_o=l(),ih=a("li"),Cue=a("strong"),O_o=o("led"),V_o=o(" \u2014 "),jD=a("a"),X_o=o("LEDConfig"),z_o=o(" (LED model)"),Q_o=l(),dh=a("li"),wue=a("strong"),W_o=o("levit"),U_o=o(" \u2014 "),GD=a("a"),H_o=o("LevitConfig"),J_o=o(" (LeViT model)"),Y_o=l(),mh=a("li"),Aue=a("strong"),Z_o=o("lilt"),K_o=o(" \u2014 "),OD=a("a"),e1o=o("LiltConfig"),o1o=o(" (LiLT model)"),r1o=l(),ch=a("li"),Lue=a("strong"),t1o=o("longformer"),a1o=o(" \u2014 "),VD=a("a"),n1o=o("LongformerConfig"),s1o=o(" (Longformer model)"),l1o=l(),fh=a("li"),yue=a("strong"),i1o=o("longt5"),d1o=o(" \u2014 "),XD=a("a"),m1o=o("LongT5Config"),c1o=o(" (LongT5 model)"),f1o=l(),gh=a("li"),xue=a("strong"),g1o=o("luke"),h1o=o(" \u2014 "),zD=a("a"),u1o=o("LukeConfig"),p1o=o(" (LUKE model)"),_1o=l(),hh=a("li"),$ue=a("strong"),b1o=o("lxmert"),v1o=o(" \u2014 "),QD=a("a"),F1o=o("LxmertConfig"),T1o=o(" (LXMERT model)"),M1o=l(),uh=a("li"),kue=a("strong"),E1o=o("m2m_100"),C1o=o(" \u2014 "),WD=a("a"),w1o=o("M2M100Config"),A1o=o(" (M2M100 model)"),L1o=l(),ph=a("li"),Sue=a("strong"),y1o=o("marian"),x1o=o(" \u2014 "),UD=a("a"),$1o=o("MarianConfig"),k1o=o(" (Marian model)"),S1o=l(),_h=a("li"),Rue=a("strong"),R1o=o("markuplm"),P1o=o(" \u2014 "),HD=a("a"),B1o=o("MarkupLMConfig"),I1o=o(" (MarkupLM model)"),N1o=l(),bh=a("li"),Pue=a("strong"),q1o=o("maskformer"),D1o=o(" \u2014 "),JD=a("a"),j1o=o("MaskFormerConfig"),G1o=o(" (MaskFormer model)"),O1o=l(),vh=a("li"),Bue=a("strong"),V1o=o("mbart"),X1o=o(" \u2014 "),YD=a("a"),z1o=o("MBartConfig"),Q1o=o(" (mBART model)"),W1o=l(),Fh=a("li"),Iue=a("strong"),U1o=o("mctct"),H1o=o(" \u2014 "),ZD=a("a"),J1o=o("MCTCTConfig"),Y1o=o(" (M-CTC-T model)"),Z1o=l(),Th=a("li"),Nue=a("strong"),K1o=o("megatron-bert"),e2o=o(" \u2014 "),KD=a("a"),o2o=o("MegatronBertConfig"),r2o=o(" (Megatron-BERT model)"),t2o=l(),Mh=a("li"),que=a("strong"),a2o=o("mobilebert"),n2o=o(" \u2014 "),ej=a("a"),s2o=o("MobileBertConfig"),l2o=o(" (MobileBERT model)"),i2o=l(),Eh=a("li"),Due=a("strong"),d2o=o("mobilevit"),m2o=o(" \u2014 "),oj=a("a"),c2o=o("MobileViTConfig"),f2o=o(" (MobileViT model)"),g2o=l(),Ch=a("li"),jue=a("strong"),h2o=o("mpnet"),u2o=o(" \u2014 "),rj=a("a"),p2o=o("MPNetConfig"),_2o=o(" (MPNet model)"),b2o=l(),wh=a("li"),Gue=a("strong"),v2o=o("mt5"),F2o=o(" \u2014 "),tj=a("a"),T2o=o("MT5Config"),M2o=o(" (MT5 model)"),E2o=l(),Ah=a("li"),Oue=a("strong"),C2o=o("mvp"),w2o=o(" \u2014 "),aj=a("a"),A2o=o("MvpConfig"),L2o=o(" (MVP model)"),y2o=l(),Lh=a("li"),Vue=a("strong"),x2o=o("nezha"),$2o=o(" \u2014 "),nj=a("a"),k2o=o("NezhaConfig"),S2o=o(" (Nezha model)"),R2o=l(),yh=a("li"),Xue=a("strong"),P2o=o("nystromformer"),B2o=o(" \u2014 "),sj=a("a"),I2o=o("NystromformerConfig"),N2o=o(" (Nystr\xF6mformer model)"),q2o=l(),xh=a("li"),zue=a("strong"),D2o=o("openai-gpt"),j2o=o(" \u2014 "),lj=a("a"),G2o=o("OpenAIGPTConfig"),O2o=o(" (OpenAI GPT model)"),V2o=l(),$h=a("li"),Que=a("strong"),X2o=o("opt"),z2o=o(" \u2014 "),ij=a("a"),Q2o=o("OPTConfig"),W2o=o(" (OPT model)"),U2o=l(),kh=a("li"),Wue=a("strong"),H2o=o("owlvit"),J2o=o(" \u2014 "),dj=a("a"),Y2o=o("OwlViTConfig"),Z2o=o(" (OWL-ViT model)"),K2o=l(),Sh=a("li"),Uue=a("strong"),ebo=o("pegasus"),obo=o(" \u2014 "),mj=a("a"),rbo=o("PegasusConfig"),tbo=o(" (Pegasus model)"),abo=l(),Rh=a("li"),Hue=a("strong"),nbo=o("pegasus_x"),sbo=o(" \u2014 "),cj=a("a"),lbo=o("PegasusXConfig"),ibo=o(" (PEGASUS-X model)"),dbo=l(),Ph=a("li"),Jue=a("strong"),mbo=o("perceiver"),cbo=o(" \u2014 "),fj=a("a"),fbo=o("PerceiverConfig"),gbo=o(" (Perceiver model)"),hbo=l(),Bh=a("li"),Yue=a("strong"),ubo=o("plbart"),pbo=o(" \u2014 "),gj=a("a"),_bo=o("PLBartConfig"),bbo=o(" (PLBart model)"),vbo=l(),Ih=a("li"),Zue=a("strong"),Fbo=o("poolformer"),Tbo=o(" \u2014 "),hj=a("a"),Mbo=o("PoolFormerConfig"),Ebo=o(" (PoolFormer model)"),Cbo=l(),Nh=a("li"),Kue=a("strong"),wbo=o("prophetnet"),Abo=o(" \u2014 "),uj=a("a"),Lbo=o("ProphetNetConfig"),ybo=o(" (ProphetNet model)"),xbo=l(),qh=a("li"),epe=a("strong"),$bo=o("qdqbert"),kbo=o(" \u2014 "),pj=a("a"),Sbo=o("QDQBertConfig"),Rbo=o(" (QDQBert model)"),Pbo=l(),Dh=a("li"),ope=a("strong"),Bbo=o("rag"),Ibo=o(" \u2014 "),_j=a("a"),Nbo=o("RagConfig"),qbo=o(" (RAG model)"),Dbo=l(),jh=a("li"),rpe=a("strong"),jbo=o("realm"),Gbo=o(" \u2014 "),bj=a("a"),Obo=o("RealmConfig"),Vbo=o(" (REALM model)"),Xbo=l(),Gh=a("li"),tpe=a("strong"),zbo=o("reformer"),Qbo=o(" \u2014 "),vj=a("a"),Wbo=o("ReformerConfig"),Ubo=o(" (Reformer model)"),Hbo=l(),Oh=a("li"),ape=a("strong"),Jbo=o("regnet"),Ybo=o(" \u2014 "),Fj=a("a"),Zbo=o("RegNetConfig"),Kbo=o(" (RegNet model)"),evo=l(),Vh=a("li"),npe=a("strong"),ovo=o("rembert"),rvo=o(" \u2014 "),Tj=a("a"),tvo=o("RemBertConfig"),avo=o(" (RemBERT model)"),nvo=l(),Xh=a("li"),spe=a("strong"),svo=o("resnet"),lvo=o(" \u2014 "),Mj=a("a"),ivo=o("ResNetConfig"),dvo=o(" (ResNet model)"),mvo=l(),zh=a("li"),lpe=a("strong"),cvo=o("retribert"),fvo=o(" \u2014 "),Ej=a("a"),gvo=o("RetriBertConfig"),hvo=o(" (RetriBERT model)"),uvo=l(),Qh=a("li"),ipe=a("strong"),pvo=o("roberta"),_vo=o(" \u2014 "),Cj=a("a"),bvo=o("RobertaConfig"),vvo=o(" (RoBERTa model)"),Fvo=l(),Wh=a("li"),dpe=a("strong"),Tvo=o("roc_bert"),Mvo=o(" \u2014 "),wj=a("a"),Evo=o("RoCBertConfig"),Cvo=o(" (RoCBert model)"),wvo=l(),Uh=a("li"),mpe=a("strong"),Avo=o("roformer"),Lvo=o(" \u2014 "),Aj=a("a"),yvo=o("RoFormerConfig"),xvo=o(" (RoFormer model)"),$vo=l(),Hh=a("li"),cpe=a("strong"),kvo=o("segformer"),Svo=o(" \u2014 "),Lj=a("a"),Rvo=o("SegformerConfig"),Pvo=o(" (SegFormer model)"),Bvo=l(),Jh=a("li"),fpe=a("strong"),Ivo=o("sew"),Nvo=o(" \u2014 "),yj=a("a"),qvo=o("SEWConfig"),Dvo=o(" (SEW model)"),jvo=l(),Yh=a("li"),gpe=a("strong"),Gvo=o("sew-d"),Ovo=o(" \u2014 "),xj=a("a"),Vvo=o("SEWDConfig"),Xvo=o(" (SEW-D model)"),zvo=l(),Zh=a("li"),hpe=a("strong"),Qvo=o("speech-encoder-decoder"),Wvo=o(" \u2014 "),$j=a("a"),Uvo=o("SpeechEncoderDecoderConfig"),Hvo=o(" (Speech Encoder decoder model)"),Jvo=l(),Kh=a("li"),upe=a("strong"),Yvo=o("speech_to_text"),Zvo=o(" \u2014 "),kj=a("a"),Kvo=o("Speech2TextConfig"),eFo=o(" (Speech2Text model)"),oFo=l(),eu=a("li"),ppe=a("strong"),rFo=o("speech_to_text_2"),tFo=o(" \u2014 "),Sj=a("a"),aFo=o("Speech2Text2Config"),nFo=o(" (Speech2Text2 model)"),sFo=l(),ou=a("li"),_pe=a("strong"),lFo=o("splinter"),iFo=o(" \u2014 "),Rj=a("a"),dFo=o("SplinterConfig"),mFo=o(" (Splinter model)"),cFo=l(),ru=a("li"),bpe=a("strong"),fFo=o("squeezebert"),gFo=o(" \u2014 "),Pj=a("a"),hFo=o("SqueezeBertConfig"),uFo=o(" (SqueezeBERT model)"),pFo=l(),tu=a("li"),vpe=a("strong"),_Fo=o("swin"),bFo=o(" \u2014 "),Bj=a("a"),vFo=o("SwinConfig"),FFo=o(" (Swin Transformer model)"),TFo=l(),au=a("li"),Fpe=a("strong"),MFo=o("swinv2"),EFo=o(" \u2014 "),Ij=a("a"),CFo=o("Swinv2Config"),wFo=o(" (Swin Transformer V2 model)"),AFo=l(),nu=a("li"),Tpe=a("strong"),LFo=o("t5"),yFo=o(" \u2014 "),Nj=a("a"),xFo=o("T5Config"),$Fo=o(" (T5 model)"),kFo=l(),su=a("li"),Mpe=a("strong"),SFo=o("table-transformer"),RFo=o(" \u2014 "),qj=a("a"),PFo=o("TableTransformerConfig"),BFo=o(" (Table Transformer model)"),IFo=l(),lu=a("li"),Epe=a("strong"),NFo=o("tapas"),qFo=o(" \u2014 "),Dj=a("a"),DFo=o("TapasConfig"),jFo=o(" (TAPAS model)"),GFo=l(),iu=a("li"),Cpe=a("strong"),OFo=o("time_series_transformer"),VFo=o(" \u2014 "),jj=a("a"),XFo=o("TimeSeriesTransformerConfig"),zFo=o(" (Time Series Transformer model)"),QFo=l(),du=a("li"),wpe=a("strong"),WFo=o("trajectory_transformer"),UFo=o(" \u2014 "),Gj=a("a"),HFo=o("TrajectoryTransformerConfig"),JFo=o(" (Trajectory Transformer model)"),YFo=l(),mu=a("li"),Ape=a("strong"),ZFo=o("transfo-xl"),KFo=o(" \u2014 "),Oj=a("a"),eTo=o("TransfoXLConfig"),oTo=o(" (Transformer-XL model)"),rTo=l(),cu=a("li"),Lpe=a("strong"),tTo=o("trocr"),aTo=o(" \u2014 "),Vj=a("a"),nTo=o("TrOCRConfig"),sTo=o(" (TrOCR model)"),lTo=l(),fu=a("li"),ype=a("strong"),iTo=o("unispeech"),dTo=o(" \u2014 "),Xj=a("a"),mTo=o("UniSpeechConfig"),cTo=o(" (UniSpeech model)"),fTo=l(),gu=a("li"),xpe=a("strong"),gTo=o("unispeech-sat"),hTo=o(" \u2014 "),zj=a("a"),uTo=o("UniSpeechSatConfig"),pTo=o(" (UniSpeechSat model)"),_To=l(),hu=a("li"),$pe=a("strong"),bTo=o("van"),vTo=o(" \u2014 "),Qj=a("a"),FTo=o("VanConfig"),TTo=o(" (VAN model)"),MTo=l(),uu=a("li"),kpe=a("strong"),ETo=o("videomae"),CTo=o(" \u2014 "),Wj=a("a"),wTo=o("VideoMAEConfig"),ATo=o(" (VideoMAE model)"),LTo=l(),pu=a("li"),Spe=a("strong"),yTo=o("vilt"),xTo=o(" \u2014 "),Uj=a("a"),$To=o("ViltConfig"),kTo=o(" (ViLT model)"),STo=l(),_u=a("li"),Rpe=a("strong"),RTo=o("vision-encoder-decoder"),PTo=o(" \u2014 "),Hj=a("a"),BTo=o("VisionEncoderDecoderConfig"),ITo=o(" (Vision Encoder decoder model)"),NTo=l(),bu=a("li"),Ppe=a("strong"),qTo=o("vision-text-dual-encoder"),DTo=o(" \u2014 "),Jj=a("a"),jTo=o("VisionTextDualEncoderConfig"),GTo=o(" (VisionTextDualEncoder model)"),OTo=l(),vu=a("li"),Bpe=a("strong"),VTo=o("visual_bert"),XTo=o(" \u2014 "),Yj=a("a"),zTo=o("VisualBertConfig"),QTo=o(" (VisualBERT model)"),WTo=l(),Fu=a("li"),Ipe=a("strong"),UTo=o("vit"),HTo=o(" \u2014 "),Zj=a("a"),JTo=o("ViTConfig"),YTo=o(" (ViT model)"),ZTo=l(),Tu=a("li"),Npe=a("strong"),KTo=o("vit_mae"),eMo=o(" \u2014 "),Kj=a("a"),oMo=o("ViTMAEConfig"),rMo=o(" (ViTMAE model)"),tMo=l(),Mu=a("li"),qpe=a("strong"),aMo=o("vit_msn"),nMo=o(" \u2014 "),eG=a("a"),sMo=o("ViTMSNConfig"),lMo=o(" (ViTMSN model)"),iMo=l(),Eu=a("li"),Dpe=a("strong"),dMo=o("wav2vec2"),mMo=o(" \u2014 "),oG=a("a"),cMo=o("Wav2Vec2Config"),fMo=o(" (Wav2Vec2 model)"),gMo=l(),Cu=a("li"),jpe=a("strong"),hMo=o("wav2vec2-conformer"),uMo=o(" \u2014 "),rG=a("a"),pMo=o("Wav2Vec2ConformerConfig"),_Mo=o(" (Wav2Vec2-Conformer model)"),bMo=l(),wu=a("li"),Gpe=a("strong"),vMo=o("wavlm"),FMo=o(" \u2014 "),tG=a("a"),TMo=o("WavLMConfig"),MMo=o(" (WavLM model)"),EMo=l(),Au=a("li"),Ope=a("strong"),CMo=o("whisper"),wMo=o(" \u2014 "),aG=a("a"),AMo=o("WhisperConfig"),LMo=o(" (Whisper model)"),yMo=l(),Lu=a("li"),Vpe=a("strong"),xMo=o("xclip"),$Mo=o(" \u2014 "),nG=a("a"),kMo=o("XCLIPConfig"),SMo=o(" (X-CLIP model)"),RMo=l(),yu=a("li"),Xpe=a("strong"),PMo=o("xglm"),BMo=o(" \u2014 "),sG=a("a"),IMo=o("XGLMConfig"),NMo=o(" (XGLM model)"),qMo=l(),xu=a("li"),zpe=a("strong"),DMo=o("xlm"),jMo=o(" \u2014 "),lG=a("a"),GMo=o("XLMConfig"),OMo=o(" (XLM model)"),VMo=l(),$u=a("li"),Qpe=a("strong"),XMo=o("xlm-prophetnet"),zMo=o(" \u2014 "),iG=a("a"),QMo=o("XLMProphetNetConfig"),WMo=o(" (XLM-ProphetNet model)"),UMo=l(),ku=a("li"),Wpe=a("strong"),HMo=o("xlm-roberta"),JMo=o(" \u2014 "),dG=a("a"),YMo=o("XLMRobertaConfig"),ZMo=o(" (XLM-RoBERTa model)"),KMo=l(),Su=a("li"),Upe=a("strong"),eEo=o("xlm-roberta-xl"),oEo=o(" \u2014 "),mG=a("a"),rEo=o("XLMRobertaXLConfig"),tEo=o(" (XLM-RoBERTa-XL model)"),aEo=l(),Ru=a("li"),Hpe=a("strong"),nEo=o("xlnet"),sEo=o(" \u2014 "),cG=a("a"),lEo=o("XLNetConfig"),iEo=o(" (XLNet model)"),dEo=l(),Pu=a("li"),Jpe=a("strong"),mEo=o("yolos"),cEo=o(" \u2014 "),fG=a("a"),fEo=o("YolosConfig"),gEo=o(" (YOLOS model)"),hEo=l(),Bu=a("li"),Ype=a("strong"),uEo=o("yoso"),pEo=o(" \u2014 "),gG=a("a"),_Eo=o("YosoConfig"),bEo=o(" (YOSO model)"),vEo=l(),F(Iu.$$.fragment),FEo=l(),Nu=a("div"),F(vk.$$.fragment),TEo=l(),Zpe=a("p"),MEo=o("Register a new configuration for this class."),Elo=l(),Id=a("h2"),qu=a("a"),Kpe=a("span"),F(Fk.$$.fragment),EEo=l(),e_e=a("span"),CEo=o("AutoTokenizer"),Clo=l(),Io=a("div"),F(Tk.$$.fragment),wEo=l(),Mk=a("p"),AEo=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),hG=a("a"),LEo=o("AutoTokenizer.from_pretrained()"),yEo=o(" class method."),xEo=l(),Ek=a("p"),$Eo=o("This class cannot be instantiated directly using "),o_e=a("code"),kEo=o("__init__()"),SEo=o(" (throws an error)."),REo=l(),Vr=a("div"),F(Ck.$$.fragment),PEo=l(),r_e=a("p"),BEo=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),IEo=l(),dn=a("p"),NEo=o("The tokenizer class to instantiate is selected based on the "),t_e=a("code"),qEo=o("model_type"),DEo=o(` property of the config object (either
passed as an argument or loaded from `),a_e=a("code"),jEo=o("pretrained_model_name_or_path"),GEo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n_e=a("code"),OEo=o("pretrained_model_name_or_path"),VEo=o(":"),XEo=l(),k=a("ul"),Ts=a("li"),s_e=a("strong"),zEo=o("albert"),QEo=o(" \u2014 "),uG=a("a"),WEo=o("AlbertTokenizer"),UEo=o(" or "),pG=a("a"),HEo=o("AlbertTokenizerFast"),JEo=o(" (ALBERT model)"),YEo=l(),Ms=a("li"),l_e=a("strong"),ZEo=o("bart"),KEo=o(" \u2014 "),_G=a("a"),e4o=o("BartTokenizer"),o4o=o(" or "),bG=a("a"),r4o=o("BartTokenizerFast"),t4o=o(" (BART model)"),a4o=l(),Es=a("li"),i_e=a("strong"),n4o=o("barthez"),s4o=o(" \u2014 "),vG=a("a"),l4o=o("BarthezTokenizer"),i4o=o(" or "),FG=a("a"),d4o=o("BarthezTokenizerFast"),m4o=o(" (BARThez model)"),c4o=l(),Du=a("li"),d_e=a("strong"),f4o=o("bartpho"),g4o=o(" \u2014 "),TG=a("a"),h4o=o("BartphoTokenizer"),u4o=o(" (BARTpho model)"),p4o=l(),Cs=a("li"),m_e=a("strong"),_4o=o("bert"),b4o=o(" \u2014 "),MG=a("a"),v4o=o("BertTokenizer"),F4o=o(" or "),EG=a("a"),T4o=o("BertTokenizerFast"),M4o=o(" (BERT model)"),E4o=l(),ju=a("li"),c_e=a("strong"),C4o=o("bert-generation"),w4o=o(" \u2014 "),CG=a("a"),A4o=o("BertGenerationTokenizer"),L4o=o(" (Bert Generation model)"),y4o=l(),Gu=a("li"),f_e=a("strong"),x4o=o("bert-japanese"),$4o=o(" \u2014 "),wG=a("a"),k4o=o("BertJapaneseTokenizer"),S4o=o(" (BertJapanese model)"),R4o=l(),Ou=a("li"),g_e=a("strong"),P4o=o("bertweet"),B4o=o(" \u2014 "),AG=a("a"),I4o=o("BertweetTokenizer"),N4o=o(" (BERTweet model)"),q4o=l(),ws=a("li"),h_e=a("strong"),D4o=o("big_bird"),j4o=o(" \u2014 "),LG=a("a"),G4o=o("BigBirdTokenizer"),O4o=o(" or "),yG=a("a"),V4o=o("BigBirdTokenizerFast"),X4o=o(" (BigBird model)"),z4o=l(),As=a("li"),u_e=a("strong"),Q4o=o("bigbird_pegasus"),W4o=o(" \u2014 "),xG=a("a"),U4o=o("PegasusTokenizer"),H4o=o(" or "),$G=a("a"),J4o=o("PegasusTokenizerFast"),Y4o=o(" (BigBird-Pegasus model)"),Z4o=l(),Ls=a("li"),p_e=a("strong"),K4o=o("blenderbot"),eCo=o(" \u2014 "),kG=a("a"),oCo=o("BlenderbotTokenizer"),rCo=o(" or "),SG=a("a"),tCo=o("BlenderbotTokenizerFast"),aCo=o(" (Blenderbot model)"),nCo=l(),Vu=a("li"),__e=a("strong"),sCo=o("blenderbot-small"),lCo=o(" \u2014 "),RG=a("a"),iCo=o("BlenderbotSmallTokenizer"),dCo=o(" (BlenderbotSmall model)"),mCo=l(),Xu=a("li"),b_e=a("strong"),cCo=o("bloom"),fCo=o(" \u2014 "),PG=a("a"),gCo=o("BloomTokenizerFast"),hCo=o(" (BLOOM model)"),uCo=l(),zu=a("li"),v_e=a("strong"),pCo=o("byt5"),_Co=o(" \u2014 "),BG=a("a"),bCo=o("ByT5Tokenizer"),vCo=o(" (ByT5 model)"),FCo=l(),ys=a("li"),F_e=a("strong"),TCo=o("camembert"),MCo=o(" \u2014 "),IG=a("a"),ECo=o("CamembertTokenizer"),CCo=o(" or "),NG=a("a"),wCo=o("CamembertTokenizerFast"),ACo=o(" (CamemBERT model)"),LCo=l(),Qu=a("li"),T_e=a("strong"),yCo=o("canine"),xCo=o(" \u2014 "),qG=a("a"),$Co=o("CanineTokenizer"),kCo=o(" (CANINE model)"),SCo=l(),xs=a("li"),M_e=a("strong"),RCo=o("clip"),PCo=o(" \u2014 "),DG=a("a"),BCo=o("CLIPTokenizer"),ICo=o(" or "),jG=a("a"),NCo=o("CLIPTokenizerFast"),qCo=o(" (CLIP model)"),DCo=l(),$s=a("li"),E_e=a("strong"),jCo=o("clipseg"),GCo=o(" \u2014 "),GG=a("a"),OCo=o("CLIPTokenizer"),VCo=o(" or "),OG=a("a"),XCo=o("CLIPTokenizerFast"),zCo=o(" (CLIPSeg model)"),QCo=l(),ks=a("li"),C_e=a("strong"),WCo=o("codegen"),UCo=o(" \u2014 "),VG=a("a"),HCo=o("CodeGenTokenizer"),JCo=o(" or "),XG=a("a"),YCo=o("CodeGenTokenizerFast"),ZCo=o(" (CodeGen model)"),KCo=l(),Ss=a("li"),w_e=a("strong"),e3o=o("convbert"),o3o=o(" \u2014 "),zG=a("a"),r3o=o("ConvBertTokenizer"),t3o=o(" or "),QG=a("a"),a3o=o("ConvBertTokenizerFast"),n3o=o(" (ConvBERT model)"),s3o=l(),Rs=a("li"),A_e=a("strong"),l3o=o("cpm"),i3o=o(" \u2014 "),WG=a("a"),d3o=o("CpmTokenizer"),m3o=o(" or "),UG=a("a"),c3o=o("CpmTokenizerFast"),f3o=o(" (CPM model)"),g3o=l(),Wu=a("li"),L_e=a("strong"),h3o=o("ctrl"),u3o=o(" \u2014 "),HG=a("a"),p3o=o("CTRLTokenizer"),_3o=o(" (CTRL model)"),b3o=l(),Ps=a("li"),y_e=a("strong"),v3o=o("data2vec-text"),F3o=o(" \u2014 "),JG=a("a"),T3o=o("RobertaTokenizer"),M3o=o(" or "),YG=a("a"),E3o=o("RobertaTokenizerFast"),C3o=o(" (Data2VecText model)"),w3o=l(),Bs=a("li"),x_e=a("strong"),A3o=o("deberta"),L3o=o(" \u2014 "),ZG=a("a"),y3o=o("DebertaTokenizer"),x3o=o(" or "),KG=a("a"),$3o=o("DebertaTokenizerFast"),k3o=o(" (DeBERTa model)"),S3o=l(),Is=a("li"),$_e=a("strong"),R3o=o("deberta-v2"),P3o=o(" \u2014 "),eO=a("a"),B3o=o("DebertaV2Tokenizer"),I3o=o(" or "),oO=a("a"),N3o=o("DebertaV2TokenizerFast"),q3o=o(" (DeBERTa-v2 model)"),D3o=l(),Ns=a("li"),k_e=a("strong"),j3o=o("distilbert"),G3o=o(" \u2014 "),rO=a("a"),O3o=o("DistilBertTokenizer"),V3o=o(" or "),tO=a("a"),X3o=o("DistilBertTokenizerFast"),z3o=o(" (DistilBERT model)"),Q3o=l(),qs=a("li"),S_e=a("strong"),W3o=o("dpr"),U3o=o(" \u2014 "),aO=a("a"),H3o=o("DPRQuestionEncoderTokenizer"),J3o=o(" or "),nO=a("a"),Y3o=o("DPRQuestionEncoderTokenizerFast"),Z3o=o(" (DPR model)"),K3o=l(),Ds=a("li"),R_e=a("strong"),e5o=o("electra"),o5o=o(" \u2014 "),sO=a("a"),r5o=o("ElectraTokenizer"),t5o=o(" or "),lO=a("a"),a5o=o("ElectraTokenizerFast"),n5o=o(" (ELECTRA model)"),s5o=l(),js=a("li"),P_e=a("strong"),l5o=o("ernie"),i5o=o(" \u2014 "),iO=a("a"),d5o=o("BertTokenizer"),m5o=o(" or "),dO=a("a"),c5o=o("BertTokenizerFast"),f5o=o(" (ERNIE model)"),g5o=l(),Uu=a("li"),B_e=a("strong"),h5o=o("esm"),u5o=o(" \u2014 "),mO=a("a"),p5o=o("EsmTokenizer"),_5o=o(" (ESM model)"),b5o=l(),Hu=a("li"),I_e=a("strong"),v5o=o("flaubert"),F5o=o(" \u2014 "),cO=a("a"),T5o=o("FlaubertTokenizer"),M5o=o(" (FlauBERT model)"),E5o=l(),Gs=a("li"),N_e=a("strong"),C5o=o("fnet"),w5o=o(" \u2014 "),fO=a("a"),A5o=o("FNetTokenizer"),L5o=o(" or "),gO=a("a"),y5o=o("FNetTokenizerFast"),x5o=o(" (FNet model)"),$5o=l(),Ju=a("li"),q_e=a("strong"),k5o=o("fsmt"),S5o=o(" \u2014 "),hO=a("a"),R5o=o("FSMTTokenizer"),P5o=o(" (FairSeq Machine-Translation model)"),B5o=l(),Os=a("li"),D_e=a("strong"),I5o=o("funnel"),N5o=o(" \u2014 "),uO=a("a"),q5o=o("FunnelTokenizer"),D5o=o(" or "),pO=a("a"),j5o=o("FunnelTokenizerFast"),G5o=o(" (Funnel Transformer model)"),O5o=l(),Vs=a("li"),j_e=a("strong"),V5o=o("gpt2"),X5o=o(" \u2014 "),_O=a("a"),z5o=o("GPT2Tokenizer"),Q5o=o(" or "),bO=a("a"),W5o=o("GPT2TokenizerFast"),U5o=o(" (OpenAI GPT-2 model)"),H5o=l(),Xs=a("li"),G_e=a("strong"),J5o=o("gpt_neo"),Y5o=o(" \u2014 "),vO=a("a"),Z5o=o("GPT2Tokenizer"),K5o=o(" or "),FO=a("a"),e0o=o("GPT2TokenizerFast"),o0o=o(" (GPT Neo model)"),r0o=l(),Yu=a("li"),O_e=a("strong"),t0o=o("gpt_neox"),a0o=o(" \u2014 "),TO=a("a"),n0o=o("GPTNeoXTokenizerFast"),s0o=o(" (GPT NeoX model)"),l0o=l(),Zu=a("li"),V_e=a("strong"),i0o=o("gpt_neox_japanese"),d0o=o(" \u2014 "),MO=a("a"),m0o=o("GPTNeoXJapaneseTokenizer"),c0o=o(" (GPT NeoX Japanese model)"),f0o=l(),zs=a("li"),X_e=a("strong"),g0o=o("gptj"),h0o=o(" \u2014 "),EO=a("a"),u0o=o("GPT2Tokenizer"),p0o=o(" or "),CO=a("a"),_0o=o("GPT2TokenizerFast"),b0o=o(" (GPT-J model)"),v0o=l(),Qs=a("li"),z_e=a("strong"),F0o=o("groupvit"),T0o=o(" \u2014 "),wO=a("a"),M0o=o("CLIPTokenizer"),E0o=o(" or "),AO=a("a"),C0o=o("CLIPTokenizerFast"),w0o=o(" (GroupViT model)"),A0o=l(),Ws=a("li"),Q_e=a("strong"),L0o=o("herbert"),y0o=o(" \u2014 "),LO=a("a"),x0o=o("HerbertTokenizer"),$0o=o(" or "),yO=a("a"),k0o=o("HerbertTokenizerFast"),S0o=o(" (HerBERT model)"),R0o=l(),Ku=a("li"),W_e=a("strong"),P0o=o("hubert"),B0o=o(" \u2014 "),xO=a("a"),I0o=o("Wav2Vec2CTCTokenizer"),N0o=o(" (Hubert model)"),q0o=l(),Us=a("li"),U_e=a("strong"),D0o=o("ibert"),j0o=o(" \u2014 "),$O=a("a"),G0o=o("RobertaTokenizer"),O0o=o(" or "),kO=a("a"),V0o=o("RobertaTokenizerFast"),X0o=o(" (I-BERT model)"),z0o=l(),Hs=a("li"),H_e=a("strong"),Q0o=o("layoutlm"),W0o=o(" \u2014 "),SO=a("a"),U0o=o("LayoutLMTokenizer"),H0o=o(" or "),RO=a("a"),J0o=o("LayoutLMTokenizerFast"),Y0o=o(" (LayoutLM model)"),Z0o=l(),Js=a("li"),J_e=a("strong"),K0o=o("layoutlmv2"),ewo=o(" \u2014 "),PO=a("a"),owo=o("LayoutLMv2Tokenizer"),rwo=o(" or "),BO=a("a"),two=o("LayoutLMv2TokenizerFast"),awo=o(" (LayoutLMv2 model)"),nwo=l(),Ys=a("li"),Y_e=a("strong"),swo=o("layoutlmv3"),lwo=o(" \u2014 "),IO=a("a"),iwo=o("LayoutLMv3Tokenizer"),dwo=o(" or "),NO=a("a"),mwo=o("LayoutLMv3TokenizerFast"),cwo=o(" (LayoutLMv3 model)"),fwo=l(),Zs=a("li"),Z_e=a("strong"),gwo=o("layoutxlm"),hwo=o(" \u2014 "),qO=a("a"),uwo=o("LayoutXLMTokenizer"),pwo=o(" or "),DO=a("a"),_wo=o("LayoutXLMTokenizerFast"),bwo=o(" (LayoutXLM model)"),vwo=l(),Ks=a("li"),K_e=a("strong"),Fwo=o("led"),Two=o(" \u2014 "),jO=a("a"),Mwo=o("LEDTokenizer"),Ewo=o(" or "),GO=a("a"),Cwo=o("LEDTokenizerFast"),wwo=o(" (LED model)"),Awo=l(),el=a("li"),e1e=a("strong"),Lwo=o("lilt"),ywo=o(" \u2014 "),OO=a("a"),xwo=o("LayoutLMv3Tokenizer"),$wo=o(" or "),VO=a("a"),kwo=o("LayoutLMv3TokenizerFast"),Swo=o(" (LiLT model)"),Rwo=l(),ol=a("li"),o1e=a("strong"),Pwo=o("longformer"),Bwo=o(" \u2014 "),XO=a("a"),Iwo=o("LongformerTokenizer"),Nwo=o(" or "),zO=a("a"),qwo=o("LongformerTokenizerFast"),Dwo=o(" (Longformer model)"),jwo=l(),rl=a("li"),r1e=a("strong"),Gwo=o("longt5"),Owo=o(" \u2014 "),QO=a("a"),Vwo=o("T5Tokenizer"),Xwo=o(" or "),WO=a("a"),zwo=o("T5TokenizerFast"),Qwo=o(" (LongT5 model)"),Wwo=l(),ep=a("li"),t1e=a("strong"),Uwo=o("luke"),Hwo=o(" \u2014 "),UO=a("a"),Jwo=o("LukeTokenizer"),Ywo=o(" (LUKE model)"),Zwo=l(),tl=a("li"),a1e=a("strong"),Kwo=o("lxmert"),eAo=o(" \u2014 "),HO=a("a"),oAo=o("LxmertTokenizer"),rAo=o(" or "),JO=a("a"),tAo=o("LxmertTokenizerFast"),aAo=o(" (LXMERT model)"),nAo=l(),op=a("li"),n1e=a("strong"),sAo=o("m2m_100"),lAo=o(" \u2014 "),YO=a("a"),iAo=o("M2M100Tokenizer"),dAo=o(" (M2M100 model)"),mAo=l(),rp=a("li"),s1e=a("strong"),cAo=o("marian"),fAo=o(" \u2014 "),ZO=a("a"),gAo=o("MarianTokenizer"),hAo=o(" (Marian model)"),uAo=l(),al=a("li"),l1e=a("strong"),pAo=o("mbart"),_Ao=o(" \u2014 "),KO=a("a"),bAo=o("MBartTokenizer"),vAo=o(" or "),eV=a("a"),FAo=o("MBartTokenizerFast"),TAo=o(" (mBART model)"),MAo=l(),nl=a("li"),i1e=a("strong"),EAo=o("mbart50"),CAo=o(" \u2014 "),oV=a("a"),wAo=o("MBart50Tokenizer"),AAo=o(" or "),rV=a("a"),LAo=o("MBart50TokenizerFast"),yAo=o(" (mBART-50 model)"),xAo=l(),sl=a("li"),d1e=a("strong"),$Ao=o("megatron-bert"),kAo=o(" \u2014 "),tV=a("a"),SAo=o("BertTokenizer"),RAo=o(" or "),aV=a("a"),PAo=o("BertTokenizerFast"),BAo=o(" (Megatron-BERT model)"),IAo=l(),tp=a("li"),m1e=a("strong"),NAo=o("mluke"),qAo=o(" \u2014 "),nV=a("a"),DAo=o("MLukeTokenizer"),jAo=o(" (mLUKE model)"),GAo=l(),ll=a("li"),c1e=a("strong"),OAo=o("mobilebert"),VAo=o(" \u2014 "),sV=a("a"),XAo=o("MobileBertTokenizer"),zAo=o(" or "),lV=a("a"),QAo=o("MobileBertTokenizerFast"),WAo=o(" (MobileBERT model)"),UAo=l(),il=a("li"),f1e=a("strong"),HAo=o("mpnet"),JAo=o(" \u2014 "),iV=a("a"),YAo=o("MPNetTokenizer"),ZAo=o(" or "),dV=a("a"),KAo=o("MPNetTokenizerFast"),e6o=o(" (MPNet model)"),o6o=l(),dl=a("li"),g1e=a("strong"),r6o=o("mt5"),t6o=o(" \u2014 "),mV=a("a"),a6o=o("MT5Tokenizer"),n6o=o(" or "),cV=a("a"),s6o=o("MT5TokenizerFast"),l6o=o(" (MT5 model)"),i6o=l(),ml=a("li"),h1e=a("strong"),d6o=o("mvp"),m6o=o(" \u2014 "),fV=a("a"),c6o=o("MvpTokenizer"),f6o=o(" or "),gV=a("a"),g6o=o("MvpTokenizerFast"),h6o=o(" (MVP model)"),u6o=l(),cl=a("li"),u1e=a("strong"),p6o=o("nezha"),_6o=o(" \u2014 "),hV=a("a"),b6o=o("BertTokenizer"),v6o=o(" or "),uV=a("a"),F6o=o("BertTokenizerFast"),T6o=o(" (Nezha model)"),M6o=l(),fl=a("li"),p1e=a("strong"),E6o=o("nllb"),C6o=o(" \u2014 "),pV=a("a"),w6o=o("NllbTokenizer"),A6o=o(" or "),_V=a("a"),L6o=o("NllbTokenizerFast"),y6o=o(" (NLLB model)"),x6o=l(),gl=a("li"),_1e=a("strong"),$6o=o("nystromformer"),k6o=o(" \u2014 "),bV=a("a"),S6o=o("AlbertTokenizer"),R6o=o(" or "),vV=a("a"),P6o=o("AlbertTokenizerFast"),B6o=o(" (Nystr\xF6mformer model)"),I6o=l(),hl=a("li"),b1e=a("strong"),N6o=o("openai-gpt"),q6o=o(" \u2014 "),FV=a("a"),D6o=o("OpenAIGPTTokenizer"),j6o=o(" or "),TV=a("a"),G6o=o("OpenAIGPTTokenizerFast"),O6o=o(" (OpenAI GPT model)"),V6o=l(),ap=a("li"),v1e=a("strong"),X6o=o("opt"),z6o=o(" \u2014 "),MV=a("a"),Q6o=o("GPT2Tokenizer"),W6o=o(" (OPT model)"),U6o=l(),ul=a("li"),F1e=a("strong"),H6o=o("owlvit"),J6o=o(" \u2014 "),EV=a("a"),Y6o=o("CLIPTokenizer"),Z6o=o(" or "),CV=a("a"),K6o=o("CLIPTokenizerFast"),e7o=o(" (OWL-ViT model)"),o7o=l(),pl=a("li"),T1e=a("strong"),r7o=o("pegasus"),t7o=o(" \u2014 "),wV=a("a"),a7o=o("PegasusTokenizer"),n7o=o(" or "),AV=a("a"),s7o=o("PegasusTokenizerFast"),l7o=o(" (Pegasus model)"),i7o=l(),_l=a("li"),M1e=a("strong"),d7o=o("pegasus_x"),m7o=o(" \u2014 "),LV=a("a"),c7o=o("PegasusTokenizer"),f7o=o(" or "),yV=a("a"),g7o=o("PegasusTokenizerFast"),h7o=o(" (PEGASUS-X model)"),u7o=l(),np=a("li"),E1e=a("strong"),p7o=o("perceiver"),_7o=o(" \u2014 "),xV=a("a"),b7o=o("PerceiverTokenizer"),v7o=o(" (Perceiver model)"),F7o=l(),sp=a("li"),C1e=a("strong"),T7o=o("phobert"),M7o=o(" \u2014 "),$V=a("a"),E7o=o("PhobertTokenizer"),C7o=o(" (PhoBERT model)"),w7o=l(),lp=a("li"),w1e=a("strong"),A7o=o("plbart"),L7o=o(" \u2014 "),kV=a("a"),y7o=o("PLBartTokenizer"),x7o=o(" (PLBart model)"),$7o=l(),ip=a("li"),A1e=a("strong"),k7o=o("prophetnet"),S7o=o(" \u2014 "),SV=a("a"),R7o=o("ProphetNetTokenizer"),P7o=o(" (ProphetNet model)"),B7o=l(),bl=a("li"),L1e=a("strong"),I7o=o("qdqbert"),N7o=o(" \u2014 "),RV=a("a"),q7o=o("BertTokenizer"),D7o=o(" or "),PV=a("a"),j7o=o("BertTokenizerFast"),G7o=o(" (QDQBert model)"),O7o=l(),dp=a("li"),y1e=a("strong"),V7o=o("rag"),X7o=o(" \u2014 "),BV=a("a"),z7o=o("RagTokenizer"),Q7o=o(" (RAG model)"),W7o=l(),vl=a("li"),x1e=a("strong"),U7o=o("realm"),H7o=o(" \u2014 "),IV=a("a"),J7o=o("RealmTokenizer"),Y7o=o(" or "),NV=a("a"),Z7o=o("RealmTokenizerFast"),K7o=o(" (REALM model)"),e8o=l(),Fl=a("li"),$1e=a("strong"),o8o=o("reformer"),r8o=o(" \u2014 "),qV=a("a"),t8o=o("ReformerTokenizer"),a8o=o(" or "),DV=a("a"),n8o=o("ReformerTokenizerFast"),s8o=o(" (Reformer model)"),l8o=l(),Tl=a("li"),k1e=a("strong"),i8o=o("rembert"),d8o=o(" \u2014 "),jV=a("a"),m8o=o("RemBertTokenizer"),c8o=o(" or "),GV=a("a"),f8o=o("RemBertTokenizerFast"),g8o=o(" (RemBERT model)"),h8o=l(),Ml=a("li"),S1e=a("strong"),u8o=o("retribert"),p8o=o(" \u2014 "),OV=a("a"),_8o=o("RetriBertTokenizer"),b8o=o(" or "),VV=a("a"),v8o=o("RetriBertTokenizerFast"),F8o=o(" (RetriBERT model)"),T8o=l(),El=a("li"),R1e=a("strong"),M8o=o("roberta"),E8o=o(" \u2014 "),XV=a("a"),C8o=o("RobertaTokenizer"),w8o=o(" or "),zV=a("a"),A8o=o("RobertaTokenizerFast"),L8o=o(" (RoBERTa model)"),y8o=l(),mp=a("li"),P1e=a("strong"),x8o=o("roc_bert"),$8o=o(" \u2014 "),QV=a("a"),k8o=o("RoCBertTokenizer"),S8o=o(" (RoCBert model)"),R8o=l(),Cl=a("li"),B1e=a("strong"),P8o=o("roformer"),B8o=o(" \u2014 "),WV=a("a"),I8o=o("RoFormerTokenizer"),N8o=o(" or "),UV=a("a"),q8o=o("RoFormerTokenizerFast"),D8o=o(" (RoFormer model)"),j8o=l(),cp=a("li"),I1e=a("strong"),G8o=o("speech_to_text"),O8o=o(" \u2014 "),HV=a("a"),V8o=o("Speech2TextTokenizer"),X8o=o(" (Speech2Text model)"),z8o=l(),fp=a("li"),N1e=a("strong"),Q8o=o("speech_to_text_2"),W8o=o(" \u2014 "),JV=a("a"),U8o=o("Speech2Text2Tokenizer"),H8o=o(" (Speech2Text2 model)"),J8o=l(),wl=a("li"),q1e=a("strong"),Y8o=o("splinter"),Z8o=o(" \u2014 "),YV=a("a"),K8o=o("SplinterTokenizer"),eLo=o(" or "),ZV=a("a"),oLo=o("SplinterTokenizerFast"),rLo=o(" (Splinter model)"),tLo=l(),Al=a("li"),D1e=a("strong"),aLo=o("squeezebert"),nLo=o(" \u2014 "),KV=a("a"),sLo=o("SqueezeBertTokenizer"),lLo=o(" or "),eX=a("a"),iLo=o("SqueezeBertTokenizerFast"),dLo=o(" (SqueezeBERT model)"),mLo=l(),Ll=a("li"),j1e=a("strong"),cLo=o("t5"),fLo=o(" \u2014 "),oX=a("a"),gLo=o("T5Tokenizer"),hLo=o(" or "),rX=a("a"),uLo=o("T5TokenizerFast"),pLo=o(" (T5 model)"),_Lo=l(),gp=a("li"),G1e=a("strong"),bLo=o("tapas"),vLo=o(" \u2014 "),tX=a("a"),FLo=o("TapasTokenizer"),TLo=o(" (TAPAS model)"),MLo=l(),hp=a("li"),O1e=a("strong"),ELo=o("tapex"),CLo=o(" \u2014 "),aX=a("a"),wLo=o("TapexTokenizer"),ALo=o(" (TAPEX model)"),LLo=l(),up=a("li"),V1e=a("strong"),yLo=o("transfo-xl"),xLo=o(" \u2014 "),nX=a("a"),$Lo=o("TransfoXLTokenizer"),kLo=o(" (Transformer-XL model)"),SLo=l(),yl=a("li"),X1e=a("strong"),RLo=o("vilt"),PLo=o(" \u2014 "),sX=a("a"),BLo=o("BertTokenizer"),ILo=o(" or "),lX=a("a"),NLo=o("BertTokenizerFast"),qLo=o(" (ViLT model)"),DLo=l(),xl=a("li"),z1e=a("strong"),jLo=o("visual_bert"),GLo=o(" \u2014 "),iX=a("a"),OLo=o("BertTokenizer"),VLo=o(" or "),dX=a("a"),XLo=o("BertTokenizerFast"),zLo=o(" (VisualBERT model)"),QLo=l(),pp=a("li"),Q1e=a("strong"),WLo=o("wav2vec2"),ULo=o(" \u2014 "),mX=a("a"),HLo=o("Wav2Vec2CTCTokenizer"),JLo=o(" (Wav2Vec2 model)"),YLo=l(),_p=a("li"),W1e=a("strong"),ZLo=o("wav2vec2-conformer"),KLo=o(" \u2014 "),cX=a("a"),eyo=o("Wav2Vec2CTCTokenizer"),oyo=o(" (Wav2Vec2-Conformer model)"),ryo=l(),bp=a("li"),U1e=a("strong"),tyo=o("wav2vec2_phoneme"),ayo=o(" \u2014 "),fX=a("a"),nyo=o("Wav2Vec2PhonemeCTCTokenizer"),syo=o(" (Wav2Vec2Phoneme model)"),lyo=l(),vp=a("li"),H1e=a("strong"),iyo=o("whisper"),dyo=o(" \u2014 "),gX=a("a"),myo=o("WhisperTokenizer"),cyo=o(" (Whisper model)"),fyo=l(),$l=a("li"),J1e=a("strong"),gyo=o("xclip"),hyo=o(" \u2014 "),hX=a("a"),uyo=o("CLIPTokenizer"),pyo=o(" or "),uX=a("a"),_yo=o("CLIPTokenizerFast"),byo=o(" (X-CLIP model)"),vyo=l(),kl=a("li"),Y1e=a("strong"),Fyo=o("xglm"),Tyo=o(" \u2014 "),pX=a("a"),Myo=o("XGLMTokenizer"),Eyo=o(" or "),_X=a("a"),Cyo=o("XGLMTokenizerFast"),wyo=o(" (XGLM model)"),Ayo=l(),Fp=a("li"),Z1e=a("strong"),Lyo=o("xlm"),yyo=o(" \u2014 "),bX=a("a"),xyo=o("XLMTokenizer"),$yo=o(" (XLM model)"),kyo=l(),Tp=a("li"),K1e=a("strong"),Syo=o("xlm-prophetnet"),Ryo=o(" \u2014 "),vX=a("a"),Pyo=o("XLMProphetNetTokenizer"),Byo=o(" (XLM-ProphetNet model)"),Iyo=l(),Sl=a("li"),e2e=a("strong"),Nyo=o("xlm-roberta"),qyo=o(" \u2014 "),FX=a("a"),Dyo=o("XLMRobertaTokenizer"),jyo=o(" or "),TX=a("a"),Gyo=o("XLMRobertaTokenizerFast"),Oyo=o(" (XLM-RoBERTa model)"),Vyo=l(),Rl=a("li"),o2e=a("strong"),Xyo=o("xlm-roberta-xl"),zyo=o(" \u2014 "),MX=a("a"),Qyo=o("XLMRobertaTokenizer"),Wyo=o(" or "),EX=a("a"),Uyo=o("XLMRobertaTokenizerFast"),Hyo=o(" (XLM-RoBERTa-XL model)"),Jyo=l(),Pl=a("li"),r2e=a("strong"),Yyo=o("xlnet"),Zyo=o(" \u2014 "),CX=a("a"),Kyo=o("XLNetTokenizer"),e9o=o(" or "),wX=a("a"),o9o=o("XLNetTokenizerFast"),r9o=o(" (XLNet model)"),t9o=l(),Bl=a("li"),t2e=a("strong"),a9o=o("yoso"),n9o=o(" \u2014 "),AX=a("a"),s9o=o("AlbertTokenizer"),l9o=o(" or "),LX=a("a"),i9o=o("AlbertTokenizerFast"),d9o=o(" (YOSO model)"),m9o=l(),F(Mp.$$.fragment),c9o=l(),Ep=a("div"),F(wk.$$.fragment),f9o=l(),a2e=a("p"),g9o=o("Register a new tokenizer in this mapping."),wlo=l(),Nd=a("h2"),Cp=a("a"),n2e=a("span"),F(Ak.$$.fragment),h9o=l(),s2e=a("span"),u9o=o("AutoFeatureExtractor"),Alo=l(),No=a("div"),F(Lk.$$.fragment),p9o=l(),yk=a("p"),_9o=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),yX=a("a"),b9o=o("AutoFeatureExtractor.from_pretrained()"),v9o=o(" class method."),F9o=l(),xk=a("p"),T9o=o("This class cannot be instantiated directly using "),l2e=a("code"),M9o=o("__init__()"),E9o=o(" (throws an error)."),C9o=l(),eo=a("div"),F($k.$$.fragment),w9o=l(),i2e=a("p"),A9o=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),L9o=l(),mn=a("p"),y9o=o("The feature extractor class to instantiate is selected based on the "),d2e=a("code"),x9o=o("model_type"),$9o=o(` property of the config object
(either passed as an argument or loaded from `),m2e=a("code"),k9o=o("pretrained_model_name_or_path"),S9o=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),c2e=a("code"),R9o=o("pretrained_model_name_or_path"),P9o=o(":"),B9o=l(),z=a("ul"),wp=a("li"),f2e=a("strong"),I9o=o("beit"),N9o=o(" \u2014 "),xX=a("a"),q9o=o("BeitFeatureExtractor"),D9o=o(" (BEiT model)"),j9o=l(),Ap=a("li"),g2e=a("strong"),G9o=o("clip"),O9o=o(" \u2014 "),$X=a("a"),V9o=o("CLIPFeatureExtractor"),X9o=o(" (CLIP model)"),z9o=l(),Lp=a("li"),h2e=a("strong"),Q9o=o("clipseg"),W9o=o(" \u2014 "),kX=a("a"),U9o=o("ViTFeatureExtractor"),H9o=o(" (CLIPSeg model)"),J9o=l(),yp=a("li"),u2e=a("strong"),Y9o=o("conditional_detr"),Z9o=o(" \u2014 "),SX=a("a"),K9o=o("ConditionalDetrFeatureExtractor"),exo=o(" (Conditional DETR model)"),oxo=l(),xp=a("li"),p2e=a("strong"),rxo=o("convnext"),txo=o(" \u2014 "),RX=a("a"),axo=o("ConvNextFeatureExtractor"),nxo=o(" (ConvNeXT model)"),sxo=l(),$p=a("li"),_2e=a("strong"),lxo=o("cvt"),ixo=o(" \u2014 "),PX=a("a"),dxo=o("ConvNextFeatureExtractor"),mxo=o(" (CvT model)"),cxo=l(),kp=a("li"),b2e=a("strong"),fxo=o("data2vec-audio"),gxo=o(" \u2014 "),BX=a("a"),hxo=o("Wav2Vec2FeatureExtractor"),uxo=o(" (Data2VecAudio model)"),pxo=l(),Sp=a("li"),v2e=a("strong"),_xo=o("data2vec-vision"),bxo=o(" \u2014 "),IX=a("a"),vxo=o("BeitFeatureExtractor"),Fxo=o(" (Data2VecVision model)"),Txo=l(),Rp=a("li"),F2e=a("strong"),Mxo=o("deformable_detr"),Exo=o(" \u2014 "),NX=a("a"),Cxo=o("DeformableDetrFeatureExtractor"),wxo=o(" (Deformable DETR model)"),Axo=l(),Pp=a("li"),T2e=a("strong"),Lxo=o("deit"),yxo=o(" \u2014 "),qX=a("a"),xxo=o("DeiTFeatureExtractor"),$xo=o(" (DeiT model)"),kxo=l(),Bp=a("li"),M2e=a("strong"),Sxo=o("detr"),Rxo=o(" \u2014 "),DX=a("a"),Pxo=o("DetrFeatureExtractor"),Bxo=o(" (DETR model)"),Ixo=l(),Ip=a("li"),E2e=a("strong"),Nxo=o("donut-swin"),qxo=o(" \u2014 "),jX=a("a"),Dxo=o("DonutFeatureExtractor"),jxo=o(" (DonutSwin model)"),Gxo=l(),Np=a("li"),C2e=a("strong"),Oxo=o("dpt"),Vxo=o(" \u2014 "),GX=a("a"),Xxo=o("DPTFeatureExtractor"),zxo=o(" (DPT model)"),Qxo=l(),qp=a("li"),w2e=a("strong"),Wxo=o("flava"),Uxo=o(" \u2014 "),OX=a("a"),Hxo=o("FlavaFeatureExtractor"),Jxo=o(" (FLAVA model)"),Yxo=l(),Dp=a("li"),A2e=a("strong"),Zxo=o("glpn"),Kxo=o(" \u2014 "),VX=a("a"),e$o=o("GLPNFeatureExtractor"),o$o=o(" (GLPN model)"),r$o=l(),jp=a("li"),L2e=a("strong"),t$o=o("groupvit"),a$o=o(" \u2014 "),XX=a("a"),n$o=o("CLIPFeatureExtractor"),s$o=o(" (GroupViT model)"),l$o=l(),Gp=a("li"),y2e=a("strong"),i$o=o("hubert"),d$o=o(" \u2014 "),zX=a("a"),m$o=o("Wav2Vec2FeatureExtractor"),c$o=o(" (Hubert model)"),f$o=l(),Op=a("li"),x2e=a("strong"),g$o=o("imagegpt"),h$o=o(" \u2014 "),QX=a("a"),u$o=o("ImageGPTFeatureExtractor"),p$o=o(" (ImageGPT model)"),_$o=l(),Vp=a("li"),$2e=a("strong"),b$o=o("layoutlmv2"),v$o=o(" \u2014 "),WX=a("a"),F$o=o("LayoutLMv2FeatureExtractor"),T$o=o(" (LayoutLMv2 model)"),M$o=l(),Xp=a("li"),k2e=a("strong"),E$o=o("layoutlmv3"),C$o=o(" \u2014 "),UX=a("a"),w$o=o("LayoutLMv3FeatureExtractor"),A$o=o(" (LayoutLMv3 model)"),L$o=l(),zp=a("li"),S2e=a("strong"),y$o=o("levit"),x$o=o(" \u2014 "),HX=a("a"),$$o=o("LevitFeatureExtractor"),k$o=o(" (LeViT model)"),S$o=l(),Qp=a("li"),R2e=a("strong"),R$o=o("maskformer"),P$o=o(" \u2014 "),JX=a("a"),B$o=o("MaskFormerFeatureExtractor"),I$o=o(" (MaskFormer model)"),N$o=l(),Wp=a("li"),P2e=a("strong"),q$o=o("mctct"),D$o=o(" \u2014 "),YX=a("a"),j$o=o("MCTCTFeatureExtractor"),G$o=o(" (M-CTC-T model)"),O$o=l(),Up=a("li"),B2e=a("strong"),V$o=o("mobilevit"),X$o=o(" \u2014 "),ZX=a("a"),z$o=o("MobileViTFeatureExtractor"),Q$o=o(" (MobileViT model)"),W$o=l(),Hp=a("li"),I2e=a("strong"),U$o=o("owlvit"),H$o=o(" \u2014 "),KX=a("a"),J$o=o("OwlViTFeatureExtractor"),Y$o=o(" (OWL-ViT model)"),Z$o=l(),Jp=a("li"),N2e=a("strong"),K$o=o("perceiver"),eko=o(" \u2014 "),ez=a("a"),oko=o("PerceiverFeatureExtractor"),rko=o(" (Perceiver model)"),tko=l(),Yp=a("li"),q2e=a("strong"),ako=o("poolformer"),nko=o(" \u2014 "),oz=a("a"),sko=o("PoolFormerFeatureExtractor"),lko=o(" (PoolFormer model)"),iko=l(),Zp=a("li"),D2e=a("strong"),dko=o("regnet"),mko=o(" \u2014 "),rz=a("a"),cko=o("ConvNextFeatureExtractor"),fko=o(" (RegNet model)"),gko=l(),Kp=a("li"),j2e=a("strong"),hko=o("resnet"),uko=o(" \u2014 "),tz=a("a"),pko=o("ConvNextFeatureExtractor"),_ko=o(" (ResNet model)"),bko=l(),e_=a("li"),G2e=a("strong"),vko=o("segformer"),Fko=o(" \u2014 "),az=a("a"),Tko=o("SegformerFeatureExtractor"),Mko=o(" (SegFormer model)"),Eko=l(),o_=a("li"),O2e=a("strong"),Cko=o("speech_to_text"),wko=o(" \u2014 "),nz=a("a"),Ako=o("Speech2TextFeatureExtractor"),Lko=o(" (Speech2Text model)"),yko=l(),r_=a("li"),V2e=a("strong"),xko=o("swin"),$ko=o(" \u2014 "),sz=a("a"),kko=o("ViTFeatureExtractor"),Sko=o(" (Swin Transformer model)"),Rko=l(),t_=a("li"),X2e=a("strong"),Pko=o("swinv2"),Bko=o(" \u2014 "),lz=a("a"),Iko=o("ViTFeatureExtractor"),Nko=o(" (Swin Transformer V2 model)"),qko=l(),a_=a("li"),z2e=a("strong"),Dko=o("table-transformer"),jko=o(" \u2014 "),iz=a("a"),Gko=o("DetrFeatureExtractor"),Oko=o(" (Table Transformer model)"),Vko=l(),n_=a("li"),Q2e=a("strong"),Xko=o("van"),zko=o(" \u2014 "),dz=a("a"),Qko=o("ConvNextFeatureExtractor"),Wko=o(" (VAN model)"),Uko=l(),s_=a("li"),W2e=a("strong"),Hko=o("videomae"),Jko=o(" \u2014 "),mz=a("a"),Yko=o("VideoMAEFeatureExtractor"),Zko=o(" (VideoMAE model)"),Kko=l(),l_=a("li"),U2e=a("strong"),eSo=o("vilt"),oSo=o(" \u2014 "),cz=a("a"),rSo=o("ViltFeatureExtractor"),tSo=o(" (ViLT model)"),aSo=l(),i_=a("li"),H2e=a("strong"),nSo=o("vit"),sSo=o(" \u2014 "),fz=a("a"),lSo=o("ViTFeatureExtractor"),iSo=o(" (ViT model)"),dSo=l(),d_=a("li"),J2e=a("strong"),mSo=o("vit_mae"),cSo=o(" \u2014 "),gz=a("a"),fSo=o("ViTFeatureExtractor"),gSo=o(" (ViTMAE model)"),hSo=l(),m_=a("li"),Y2e=a("strong"),uSo=o("vit_msn"),pSo=o(" \u2014 "),hz=a("a"),_So=o("ViTFeatureExtractor"),bSo=o(" (ViTMSN model)"),vSo=l(),c_=a("li"),Z2e=a("strong"),FSo=o("wav2vec2"),TSo=o(" \u2014 "),uz=a("a"),MSo=o("Wav2Vec2FeatureExtractor"),ESo=o(" (Wav2Vec2 model)"),CSo=l(),f_=a("li"),K2e=a("strong"),wSo=o("wav2vec2-conformer"),ASo=o(" \u2014 "),pz=a("a"),LSo=o("Wav2Vec2FeatureExtractor"),ySo=o(" (Wav2Vec2-Conformer model)"),xSo=l(),g_=a("li"),ebe=a("strong"),$So=o("whisper"),kSo=o(" \u2014 "),_z=a("a"),SSo=o("WhisperFeatureExtractor"),RSo=o(" (Whisper model)"),PSo=l(),h_=a("li"),obe=a("strong"),BSo=o("xclip"),ISo=o(" \u2014 "),bz=a("a"),NSo=o("CLIPFeatureExtractor"),qSo=o(" (X-CLIP model)"),DSo=l(),u_=a("li"),rbe=a("strong"),jSo=o("yolos"),GSo=o(" \u2014 "),vz=a("a"),OSo=o("YolosFeatureExtractor"),VSo=o(" (YOLOS model)"),XSo=l(),F(p_.$$.fragment),zSo=l(),F(__.$$.fragment),QSo=l(),b_=a("div"),F(kk.$$.fragment),WSo=l(),tbe=a("p"),USo=o("Register a new feature extractor for this class."),Llo=l(),qd=a("h2"),v_=a("a"),abe=a("span"),F(Sk.$$.fragment),HSo=l(),nbe=a("span"),JSo=o("AutoImageProcessor"),ylo=l(),qo=a("div"),F(Rk.$$.fragment),YSo=l(),Pk=a("p"),ZSo=o(`This is a generic image processor class that will be instantiated as one of the image processor classes of the
library when created with the `),Fz=a("a"),KSo=o("AutoImageProcessor.from_pretrained()"),eRo=o(" class method."),oRo=l(),Bk=a("p"),rRo=o("This class cannot be instantiated directly using "),sbe=a("code"),tRo=o("__init__()"),aRo=o(" (throws an error)."),nRo=l(),oo=a("div"),F(Ik.$$.fragment),sRo=l(),lbe=a("p"),lRo=o("Instantiate one of the image processor classes of the library from a pretrained model vocabulary."),iRo=l(),cn=a("p"),dRo=o("The image processor class to instantiate is selected based on the "),ibe=a("code"),mRo=o("model_type"),cRo=o(` property of the config object
(either passed as an argument or loaded from `),dbe=a("code"),fRo=o("pretrained_model_name_or_path"),gRo=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),mbe=a("code"),hRo=o("pretrained_model_name_or_path"),uRo=o(":"),pRo=l(),re=a("ul"),F_=a("li"),cbe=a("strong"),_Ro=o("beit"),bRo=o(" \u2014 "),Tz=a("a"),vRo=o("BeitImageProcessor"),FRo=o(" (BEiT model)"),TRo=l(),T_=a("li"),fbe=a("strong"),MRo=o("clip"),ERo=o(" \u2014 "),Mz=a("a"),CRo=o("CLIPImageProcessor"),wRo=o(" (CLIP model)"),ARo=l(),M_=a("li"),gbe=a("strong"),LRo=o("convnext"),yRo=o(" \u2014 "),Ez=a("a"),xRo=o("ConvNextImageProcessor"),$Ro=o(" (ConvNeXT model)"),kRo=l(),E_=a("li"),hbe=a("strong"),SRo=o("cvt"),RRo=o(" \u2014 "),Cz=a("a"),PRo=o("ConvNextImageProcessor"),BRo=o(" (CvT model)"),IRo=l(),C_=a("li"),ube=a("strong"),NRo=o("data2vec-vision"),qRo=o(" \u2014 "),wz=a("a"),DRo=o("BeitImageProcessor"),jRo=o(" (Data2VecVision model)"),GRo=l(),w_=a("li"),pbe=a("strong"),ORo=o("deit"),VRo=o(" \u2014 "),Az=a("a"),XRo=o("DeiTImageProcessor"),zRo=o(" (DeiT model)"),QRo=l(),A_=a("li"),_be=a("strong"),WRo=o("dpt"),URo=o(" \u2014 "),Lz=a("a"),HRo=o("DPTImageProcessor"),JRo=o(" (DPT model)"),YRo=l(),L_=a("li"),bbe=a("strong"),ZRo=o("flava"),KRo=o(" \u2014 "),yz=a("a"),ePo=o("FlavaImageProcessor"),oPo=o(" (FLAVA model)"),rPo=l(),y_=a("li"),vbe=a("strong"),tPo=o("glpn"),aPo=o(" \u2014 "),xz=a("a"),nPo=o("GLPNImageProcessor"),sPo=o(" (GLPN model)"),lPo=l(),x_=a("li"),Fbe=a("strong"),iPo=o("groupvit"),dPo=o(" \u2014 "),$z=a("a"),mPo=o("CLIPImageProcessor"),cPo=o(" (GroupViT model)"),fPo=l(),$_=a("li"),Tbe=a("strong"),gPo=o("imagegpt"),hPo=o(" \u2014 "),kz=a("a"),uPo=o("ImageGPTImageProcessor"),pPo=o(" (ImageGPT model)"),_Po=l(),k_=a("li"),Mbe=a("strong"),bPo=o("layoutlmv2"),vPo=o(" \u2014 "),Sz=a("a"),FPo=o("LayoutLMv2ImageProcessor"),TPo=o(" (LayoutLMv2 model)"),MPo=l(),S_=a("li"),Ebe=a("strong"),EPo=o("layoutlmv3"),CPo=o(" \u2014 "),Rz=a("a"),wPo=o("LayoutLMv3ImageProcessor"),APo=o(" (LayoutLMv3 model)"),LPo=l(),R_=a("li"),Cbe=a("strong"),yPo=o("levit"),xPo=o(" \u2014 "),Pz=a("a"),$Po=o("LevitImageProcessor"),kPo=o(" (LeViT model)"),SPo=l(),P_=a("li"),wbe=a("strong"),RPo=o("mobilevit"),PPo=o(" \u2014 "),Bz=a("a"),BPo=o("MobileViTImageProcessor"),IPo=o(" (MobileViT model)"),NPo=l(),B_=a("li"),Abe=a("strong"),qPo=o("perceiver"),DPo=o(" \u2014 "),Iz=a("a"),jPo=o("PerceiverImageProcessor"),GPo=o(" (Perceiver model)"),OPo=l(),I_=a("li"),Lbe=a("strong"),VPo=o("poolformer"),XPo=o(" \u2014 "),Nz=a("a"),zPo=o("PoolFormerImageProcessor"),QPo=o(" (PoolFormer model)"),WPo=l(),N_=a("li"),ybe=a("strong"),UPo=o("regnet"),HPo=o(" \u2014 "),qz=a("a"),JPo=o("ConvNextImageProcessor"),YPo=o(" (RegNet model)"),ZPo=l(),q_=a("li"),xbe=a("strong"),KPo=o("resnet"),eBo=o(" \u2014 "),Dz=a("a"),oBo=o("ConvNextImageProcessor"),rBo=o(" (ResNet model)"),tBo=l(),D_=a("li"),$be=a("strong"),aBo=o("segformer"),nBo=o(" \u2014 "),jz=a("a"),sBo=o("SegformerImageProcessor"),lBo=o(" (SegFormer model)"),iBo=l(),j_=a("li"),kbe=a("strong"),dBo=o("swin"),mBo=o(" \u2014 "),Gz=a("a"),cBo=o("ViTImageProcessor"),fBo=o(" (Swin Transformer model)"),gBo=l(),G_=a("li"),Sbe=a("strong"),hBo=o("swinv2"),uBo=o(" \u2014 "),Oz=a("a"),pBo=o("ViTImageProcessor"),_Bo=o(" (Swin Transformer V2 model)"),bBo=l(),O_=a("li"),Rbe=a("strong"),vBo=o("van"),FBo=o(" \u2014 "),Vz=a("a"),TBo=o("ConvNextImageProcessor"),MBo=o(" (VAN model)"),EBo=l(),V_=a("li"),Pbe=a("strong"),CBo=o("videomae"),wBo=o(" \u2014 "),Xz=a("a"),ABo=o("VideoMAEImageProcessor"),LBo=o(" (VideoMAE model)"),yBo=l(),X_=a("li"),Bbe=a("strong"),xBo=o("vilt"),$Bo=o(" \u2014 "),zz=a("a"),kBo=o("ViltImageProcessor"),SBo=o(" (ViLT model)"),RBo=l(),z_=a("li"),Ibe=a("strong"),PBo=o("vit"),BBo=o(" \u2014 "),Qz=a("a"),IBo=o("ViTImageProcessor"),NBo=o(" (ViT model)"),qBo=l(),Q_=a("li"),Nbe=a("strong"),DBo=o("vit_mae"),jBo=o(" \u2014 "),Wz=a("a"),GBo=o("ViTImageProcessor"),OBo=o(" (ViTMAE model)"),VBo=l(),W_=a("li"),qbe=a("strong"),XBo=o("vit_msn"),zBo=o(" \u2014 "),Uz=a("a"),QBo=o("ViTImageProcessor"),WBo=o(" (ViTMSN model)"),UBo=l(),U_=a("li"),Dbe=a("strong"),HBo=o("xclip"),JBo=o(" \u2014 "),Hz=a("a"),YBo=o("CLIPImageProcessor"),ZBo=o(" (X-CLIP model)"),KBo=l(),F(H_.$$.fragment),eIo=l(),F(J_.$$.fragment),oIo=l(),Y_=a("div"),F(Nk.$$.fragment),rIo=l(),jbe=a("p"),tIo=o("Register a new image processor for this class."),xlo=l(),Dd=a("h2"),Z_=a("a"),Gbe=a("span"),F(qk.$$.fragment),aIo=l(),Obe=a("span"),nIo=o("AutoProcessor"),$lo=l(),Do=a("div"),F(Dk.$$.fragment),sIo=l(),jk=a("p"),lIo=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),Jz=a("a"),iIo=o("AutoProcessor.from_pretrained()"),dIo=o(" class method."),mIo=l(),Gk=a("p"),cIo=o("This class cannot be instantiated directly using "),Vbe=a("code"),fIo=o("__init__()"),gIo=o(" (throws an error)."),hIo=l(),ro=a("div"),F(Ok.$$.fragment),uIo=l(),Xbe=a("p"),pIo=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),_Io=l(),jd=a("p"),bIo=o("The processor class to instantiate is selected based on the "),zbe=a("code"),vIo=o("model_type"),FIo=o(` property of the config object (either
passed as an argument or loaded from `),Qbe=a("code"),TIo=o("pretrained_model_name_or_path"),MIo=o(" if possible):"),EIo=l(),ie=a("ul"),K_=a("li"),Wbe=a("strong"),CIo=o("clip"),wIo=o(" \u2014 "),Yz=a("a"),AIo=o("CLIPProcessor"),LIo=o(" (CLIP model)"),yIo=l(),e1=a("li"),Ube=a("strong"),xIo=o("clipseg"),$Io=o(" \u2014 "),Zz=a("a"),kIo=o("CLIPSegProcessor"),SIo=o(" (CLIPSeg model)"),RIo=l(),o1=a("li"),Hbe=a("strong"),PIo=o("flava"),BIo=o(" \u2014 "),Kz=a("a"),IIo=o("FlavaProcessor"),NIo=o(" (FLAVA model)"),qIo=l(),r1=a("li"),Jbe=a("strong"),DIo=o("groupvit"),jIo=o(" \u2014 "),eQ=a("a"),GIo=o("CLIPProcessor"),OIo=o(" (GroupViT model)"),VIo=l(),t1=a("li"),Ybe=a("strong"),XIo=o("layoutlmv2"),zIo=o(" \u2014 "),oQ=a("a"),QIo=o("LayoutLMv2Processor"),WIo=o(" (LayoutLMv2 model)"),UIo=l(),a1=a("li"),Zbe=a("strong"),HIo=o("layoutlmv3"),JIo=o(" \u2014 "),rQ=a("a"),YIo=o("LayoutLMv3Processor"),ZIo=o(" (LayoutLMv3 model)"),KIo=l(),n1=a("li"),Kbe=a("strong"),eNo=o("layoutxlm"),oNo=o(" \u2014 "),tQ=a("a"),rNo=o("LayoutXLMProcessor"),tNo=o(" (LayoutXLM model)"),aNo=l(),s1=a("li"),eve=a("strong"),nNo=o("markuplm"),sNo=o(" \u2014 "),aQ=a("a"),lNo=o("MarkupLMProcessor"),iNo=o(" (MarkupLM model)"),dNo=l(),l1=a("li"),ove=a("strong"),mNo=o("owlvit"),cNo=o(" \u2014 "),nQ=a("a"),fNo=o("OwlViTProcessor"),gNo=o(" (OWL-ViT model)"),hNo=l(),i1=a("li"),rve=a("strong"),uNo=o("sew"),pNo=o(" \u2014 "),sQ=a("a"),_No=o("Wav2Vec2Processor"),bNo=o(" (SEW model)"),vNo=l(),d1=a("li"),tve=a("strong"),FNo=o("sew-d"),TNo=o(" \u2014 "),lQ=a("a"),MNo=o("Wav2Vec2Processor"),ENo=o(" (SEW-D model)"),CNo=l(),m1=a("li"),ave=a("strong"),wNo=o("speech_to_text"),ANo=o(" \u2014 "),iQ=a("a"),LNo=o("Speech2TextProcessor"),yNo=o(" (Speech2Text model)"),xNo=l(),c1=a("li"),nve=a("strong"),$No=o("speech_to_text_2"),kNo=o(" \u2014 "),dQ=a("a"),SNo=o("Speech2Text2Processor"),RNo=o(" (Speech2Text2 model)"),PNo=l(),f1=a("li"),sve=a("strong"),BNo=o("trocr"),INo=o(" \u2014 "),mQ=a("a"),NNo=o("TrOCRProcessor"),qNo=o(" (TrOCR model)"),DNo=l(),g1=a("li"),lve=a("strong"),jNo=o("unispeech"),GNo=o(" \u2014 "),cQ=a("a"),ONo=o("Wav2Vec2Processor"),VNo=o(" (UniSpeech model)"),XNo=l(),h1=a("li"),ive=a("strong"),zNo=o("unispeech-sat"),QNo=o(" \u2014 "),fQ=a("a"),WNo=o("Wav2Vec2Processor"),UNo=o(" (UniSpeechSat model)"),HNo=l(),u1=a("li"),dve=a("strong"),JNo=o("vilt"),YNo=o(" \u2014 "),gQ=a("a"),ZNo=o("ViltProcessor"),KNo=o(" (ViLT model)"),eqo=l(),p1=a("li"),mve=a("strong"),oqo=o("vision-text-dual-encoder"),rqo=o(" \u2014 "),hQ=a("a"),tqo=o("VisionTextDualEncoderProcessor"),aqo=o(" (VisionTextDualEncoder model)"),nqo=l(),_1=a("li"),cve=a("strong"),sqo=o("wav2vec2"),lqo=o(" \u2014 "),uQ=a("a"),iqo=o("Wav2Vec2Processor"),dqo=o(" (Wav2Vec2 model)"),mqo=l(),b1=a("li"),fve=a("strong"),cqo=o("wav2vec2-conformer"),fqo=o(" \u2014 "),pQ=a("a"),gqo=o("Wav2Vec2Processor"),hqo=o(" (Wav2Vec2-Conformer model)"),uqo=l(),v1=a("li"),gve=a("strong"),pqo=o("wavlm"),_qo=o(" \u2014 "),_Q=a("a"),bqo=o("Wav2Vec2Processor"),vqo=o(" (WavLM model)"),Fqo=l(),F1=a("li"),hve=a("strong"),Tqo=o("whisper"),Mqo=o(" \u2014 "),bQ=a("a"),Eqo=o("WhisperProcessor"),Cqo=o(" (Whisper model)"),wqo=l(),T1=a("li"),uve=a("strong"),Aqo=o("xclip"),Lqo=o(" \u2014 "),vQ=a("a"),yqo=o("XCLIPProcessor"),xqo=o(" (X-CLIP model)"),$qo=l(),F(M1.$$.fragment),kqo=l(),F(E1.$$.fragment),Sqo=l(),C1=a("div"),F(Vk.$$.fragment),Rqo=l(),pve=a("p"),Pqo=o("Register a new processor for this class."),klo=l(),Gd=a("h2"),w1=a("a"),_ve=a("span"),F(Xk.$$.fragment),Bqo=l(),bve=a("span"),Iqo=o("AutoModel"),Slo=l(),jo=a("div"),F(zk.$$.fragment),Nqo=l(),Od=a("p"),qqo=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),FQ=a("a"),Dqo=o("from_pretrained()"),jqo=o(" class method or the "),TQ=a("a"),Gqo=o("from_config()"),Oqo=o(` class
method.`),Vqo=l(),Qk=a("p"),Xqo=o("This class cannot be instantiated directly using "),vve=a("code"),zqo=o("__init__()"),Qqo=o(" (throws an error)."),Wqo=l(),At=a("div"),F(Wk.$$.fragment),Uqo=l(),Fve=a("p"),Hqo=o("Instantiates one of the base model classes of the library from a configuration."),Jqo=l(),Vd=a("p"),Yqo=o(`Note:
Loading a model from its configuration file does `),Tve=a("strong"),Zqo=o("not"),Kqo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),MQ=a("a"),eDo=o("from_pretrained()"),oDo=o(" to load the model weights."),rDo=l(),F(A1.$$.fragment),tDo=l(),to=a("div"),F(Uk.$$.fragment),aDo=l(),Mve=a("p"),nDo=o("Instantiate one of the base model classes of the library from a pretrained model."),sDo=l(),fn=a("p"),lDo=o("The model class to instantiate is selected based on the "),Eve=a("code"),iDo=o("model_type"),dDo=o(` property of the config object (either
passed as an argument or loaded from `),Cve=a("code"),mDo=o("pretrained_model_name_or_path"),cDo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wve=a("code"),fDo=o("pretrained_model_name_or_path"),gDo=o(":"),hDo=l(),y=a("ul"),L1=a("li"),Ave=a("strong"),uDo=o("albert"),pDo=o(" \u2014 "),EQ=a("a"),_Do=o("AlbertModel"),bDo=o(" (ALBERT model)"),vDo=l(),y1=a("li"),Lve=a("strong"),FDo=o("bart"),TDo=o(" \u2014 "),CQ=a("a"),MDo=o("BartModel"),EDo=o(" (BART model)"),CDo=l(),x1=a("li"),yve=a("strong"),wDo=o("beit"),ADo=o(" \u2014 "),wQ=a("a"),LDo=o("BeitModel"),yDo=o(" (BEiT model)"),xDo=l(),$1=a("li"),xve=a("strong"),$Do=o("bert"),kDo=o(" \u2014 "),AQ=a("a"),SDo=o("BertModel"),RDo=o(" (BERT model)"),PDo=l(),k1=a("li"),$ve=a("strong"),BDo=o("bert-generation"),IDo=o(" \u2014 "),LQ=a("a"),NDo=o("BertGenerationEncoder"),qDo=o(" (Bert Generation model)"),DDo=l(),S1=a("li"),kve=a("strong"),jDo=o("big_bird"),GDo=o(" \u2014 "),yQ=a("a"),ODo=o("BigBirdModel"),VDo=o(" (BigBird model)"),XDo=l(),R1=a("li"),Sve=a("strong"),zDo=o("bigbird_pegasus"),QDo=o(" \u2014 "),xQ=a("a"),WDo=o("BigBirdPegasusModel"),UDo=o(" (BigBird-Pegasus model)"),HDo=l(),P1=a("li"),Rve=a("strong"),JDo=o("blenderbot"),YDo=o(" \u2014 "),$Q=a("a"),ZDo=o("BlenderbotModel"),KDo=o(" (Blenderbot model)"),ejo=l(),B1=a("li"),Pve=a("strong"),ojo=o("blenderbot-small"),rjo=o(" \u2014 "),kQ=a("a"),tjo=o("BlenderbotSmallModel"),ajo=o(" (BlenderbotSmall model)"),njo=l(),I1=a("li"),Bve=a("strong"),sjo=o("bloom"),ljo=o(" \u2014 "),SQ=a("a"),ijo=o("BloomModel"),djo=o(" (BLOOM model)"),mjo=l(),N1=a("li"),Ive=a("strong"),cjo=o("camembert"),fjo=o(" \u2014 "),RQ=a("a"),gjo=o("CamembertModel"),hjo=o(" (CamemBERT model)"),ujo=l(),q1=a("li"),Nve=a("strong"),pjo=o("canine"),_jo=o(" \u2014 "),PQ=a("a"),bjo=o("CanineModel"),vjo=o(" (CANINE model)"),Fjo=l(),D1=a("li"),qve=a("strong"),Tjo=o("clip"),Mjo=o(" \u2014 "),BQ=a("a"),Ejo=o("CLIPModel"),Cjo=o(" (CLIP model)"),wjo=l(),j1=a("li"),Dve=a("strong"),Ajo=o("clipseg"),Ljo=o(" \u2014 "),IQ=a("a"),yjo=o("CLIPSegModel"),xjo=o(" (CLIPSeg model)"),$jo=l(),G1=a("li"),jve=a("strong"),kjo=o("codegen"),Sjo=o(" \u2014 "),NQ=a("a"),Rjo=o("CodeGenModel"),Pjo=o(" (CodeGen model)"),Bjo=l(),O1=a("li"),Gve=a("strong"),Ijo=o("conditional_detr"),Njo=o(" \u2014 "),qQ=a("a"),qjo=o("ConditionalDetrModel"),Djo=o(" (Conditional DETR model)"),jjo=l(),V1=a("li"),Ove=a("strong"),Gjo=o("convbert"),Ojo=o(" \u2014 "),DQ=a("a"),Vjo=o("ConvBertModel"),Xjo=o(" (ConvBERT model)"),zjo=l(),X1=a("li"),Vve=a("strong"),Qjo=o("convnext"),Wjo=o(" \u2014 "),jQ=a("a"),Ujo=o("ConvNextModel"),Hjo=o(" (ConvNeXT model)"),Jjo=l(),z1=a("li"),Xve=a("strong"),Yjo=o("ctrl"),Zjo=o(" \u2014 "),GQ=a("a"),Kjo=o("CTRLModel"),eGo=o(" (CTRL model)"),oGo=l(),Q1=a("li"),zve=a("strong"),rGo=o("cvt"),tGo=o(" \u2014 "),OQ=a("a"),aGo=o("CvtModel"),nGo=o(" (CvT model)"),sGo=l(),W1=a("li"),Qve=a("strong"),lGo=o("data2vec-audio"),iGo=o(" \u2014 "),VQ=a("a"),dGo=o("Data2VecAudioModel"),mGo=o(" (Data2VecAudio model)"),cGo=l(),U1=a("li"),Wve=a("strong"),fGo=o("data2vec-text"),gGo=o(" \u2014 "),XQ=a("a"),hGo=o("Data2VecTextModel"),uGo=o(" (Data2VecText model)"),pGo=l(),H1=a("li"),Uve=a("strong"),_Go=o("data2vec-vision"),bGo=o(" \u2014 "),zQ=a("a"),vGo=o("Data2VecVisionModel"),FGo=o(" (Data2VecVision model)"),TGo=l(),J1=a("li"),Hve=a("strong"),MGo=o("deberta"),EGo=o(" \u2014 "),QQ=a("a"),CGo=o("DebertaModel"),wGo=o(" (DeBERTa model)"),AGo=l(),Y1=a("li"),Jve=a("strong"),LGo=o("deberta-v2"),yGo=o(" \u2014 "),WQ=a("a"),xGo=o("DebertaV2Model"),$Go=o(" (DeBERTa-v2 model)"),kGo=l(),Z1=a("li"),Yve=a("strong"),SGo=o("decision_transformer"),RGo=o(" \u2014 "),UQ=a("a"),PGo=o("DecisionTransformerModel"),BGo=o(" (Decision Transformer model)"),IGo=l(),K1=a("li"),Zve=a("strong"),NGo=o("deformable_detr"),qGo=o(" \u2014 "),HQ=a("a"),DGo=o("DeformableDetrModel"),jGo=o(" (Deformable DETR model)"),GGo=l(),e2=a("li"),Kve=a("strong"),OGo=o("deit"),VGo=o(" \u2014 "),JQ=a("a"),XGo=o("DeiTModel"),zGo=o(" (DeiT model)"),QGo=l(),o2=a("li"),eFe=a("strong"),WGo=o("detr"),UGo=o(" \u2014 "),YQ=a("a"),HGo=o("DetrModel"),JGo=o(" (DETR model)"),YGo=l(),r2=a("li"),oFe=a("strong"),ZGo=o("distilbert"),KGo=o(" \u2014 "),ZQ=a("a"),eOo=o("DistilBertModel"),oOo=o(" (DistilBERT model)"),rOo=l(),t2=a("li"),rFe=a("strong"),tOo=o("donut-swin"),aOo=o(" \u2014 "),KQ=a("a"),nOo=o("DonutSwinModel"),sOo=o(" (DonutSwin model)"),lOo=l(),a2=a("li"),tFe=a("strong"),iOo=o("dpr"),dOo=o(" \u2014 "),eW=a("a"),mOo=o("DPRQuestionEncoder"),cOo=o(" (DPR model)"),fOo=l(),n2=a("li"),aFe=a("strong"),gOo=o("dpt"),hOo=o(" \u2014 "),oW=a("a"),uOo=o("DPTModel"),pOo=o(" (DPT model)"),_Oo=l(),s2=a("li"),nFe=a("strong"),bOo=o("electra"),vOo=o(" \u2014 "),rW=a("a"),FOo=o("ElectraModel"),TOo=o(" (ELECTRA model)"),MOo=l(),l2=a("li"),sFe=a("strong"),EOo=o("ernie"),COo=o(" \u2014 "),tW=a("a"),wOo=o("ErnieModel"),AOo=o(" (ERNIE model)"),LOo=l(),i2=a("li"),lFe=a("strong"),yOo=o("esm"),xOo=o(" \u2014 "),aW=a("a"),$Oo=o("EsmModel"),kOo=o(" (ESM model)"),SOo=l(),d2=a("li"),iFe=a("strong"),ROo=o("flaubert"),POo=o(" \u2014 "),nW=a("a"),BOo=o("FlaubertModel"),IOo=o(" (FlauBERT model)"),NOo=l(),m2=a("li"),dFe=a("strong"),qOo=o("flava"),DOo=o(" \u2014 "),sW=a("a"),jOo=o("FlavaModel"),GOo=o(" (FLAVA model)"),OOo=l(),c2=a("li"),mFe=a("strong"),VOo=o("fnet"),XOo=o(" \u2014 "),lW=a("a"),zOo=o("FNetModel"),QOo=o(" (FNet model)"),WOo=l(),f2=a("li"),cFe=a("strong"),UOo=o("fsmt"),HOo=o(" \u2014 "),iW=a("a"),JOo=o("FSMTModel"),YOo=o(" (FairSeq Machine-Translation model)"),ZOo=l(),Il=a("li"),fFe=a("strong"),KOo=o("funnel"),eVo=o(" \u2014 "),dW=a("a"),oVo=o("FunnelModel"),rVo=o(" or "),mW=a("a"),tVo=o("FunnelBaseModel"),aVo=o(" (Funnel Transformer model)"),nVo=l(),g2=a("li"),gFe=a("strong"),sVo=o("glpn"),lVo=o(" \u2014 "),cW=a("a"),iVo=o("GLPNModel"),dVo=o(" (GLPN model)"),mVo=l(),h2=a("li"),hFe=a("strong"),cVo=o("gpt2"),fVo=o(" \u2014 "),fW=a("a"),gVo=o("GPT2Model"),hVo=o(" (OpenAI GPT-2 model)"),uVo=l(),u2=a("li"),uFe=a("strong"),pVo=o("gpt_neo"),_Vo=o(" \u2014 "),gW=a("a"),bVo=o("GPTNeoModel"),vVo=o(" (GPT Neo model)"),FVo=l(),p2=a("li"),pFe=a("strong"),TVo=o("gpt_neox"),MVo=o(" \u2014 "),hW=a("a"),EVo=o("GPTNeoXModel"),CVo=o(" (GPT NeoX model)"),wVo=l(),_2=a("li"),_Fe=a("strong"),AVo=o("gpt_neox_japanese"),LVo=o(" \u2014 "),uW=a("a"),yVo=o("GPTNeoXJapaneseModel"),xVo=o(" (GPT NeoX Japanese model)"),$Vo=l(),b2=a("li"),bFe=a("strong"),kVo=o("gptj"),SVo=o(" \u2014 "),pW=a("a"),RVo=o("GPTJModel"),PVo=o(" (GPT-J model)"),BVo=l(),v2=a("li"),vFe=a("strong"),IVo=o("groupvit"),NVo=o(" \u2014 "),_W=a("a"),qVo=o("GroupViTModel"),DVo=o(" (GroupViT model)"),jVo=l(),F2=a("li"),FFe=a("strong"),GVo=o("hubert"),OVo=o(" \u2014 "),bW=a("a"),VVo=o("HubertModel"),XVo=o(" (Hubert model)"),zVo=l(),T2=a("li"),TFe=a("strong"),QVo=o("ibert"),WVo=o(" \u2014 "),vW=a("a"),UVo=o("IBertModel"),HVo=o(" (I-BERT model)"),JVo=l(),M2=a("li"),MFe=a("strong"),YVo=o("imagegpt"),ZVo=o(" \u2014 "),FW=a("a"),KVo=o("ImageGPTModel"),eXo=o(" (ImageGPT model)"),oXo=l(),E2=a("li"),EFe=a("strong"),rXo=o("layoutlm"),tXo=o(" \u2014 "),TW=a("a"),aXo=o("LayoutLMModel"),nXo=o(" (LayoutLM model)"),sXo=l(),C2=a("li"),CFe=a("strong"),lXo=o("layoutlmv2"),iXo=o(" \u2014 "),MW=a("a"),dXo=o("LayoutLMv2Model"),mXo=o(" (LayoutLMv2 model)"),cXo=l(),w2=a("li"),wFe=a("strong"),fXo=o("layoutlmv3"),gXo=o(" \u2014 "),EW=a("a"),hXo=o("LayoutLMv3Model"),uXo=o(" (LayoutLMv3 model)"),pXo=l(),A2=a("li"),AFe=a("strong"),_Xo=o("led"),bXo=o(" \u2014 "),CW=a("a"),vXo=o("LEDModel"),FXo=o(" (LED model)"),TXo=l(),L2=a("li"),LFe=a("strong"),MXo=o("levit"),EXo=o(" \u2014 "),wW=a("a"),CXo=o("LevitModel"),wXo=o(" (LeViT model)"),AXo=l(),y2=a("li"),yFe=a("strong"),LXo=o("lilt"),yXo=o(" \u2014 "),AW=a("a"),xXo=o("LiltModel"),$Xo=o(" (LiLT model)"),kXo=l(),x2=a("li"),xFe=a("strong"),SXo=o("longformer"),RXo=o(" \u2014 "),LW=a("a"),PXo=o("LongformerModel"),BXo=o(" (Longformer model)"),IXo=l(),$2=a("li"),$Fe=a("strong"),NXo=o("longt5"),qXo=o(" \u2014 "),yW=a("a"),DXo=o("LongT5Model"),jXo=o(" (LongT5 model)"),GXo=l(),k2=a("li"),kFe=a("strong"),OXo=o("luke"),VXo=o(" \u2014 "),xW=a("a"),XXo=o("LukeModel"),zXo=o(" (LUKE model)"),QXo=l(),S2=a("li"),SFe=a("strong"),WXo=o("lxmert"),UXo=o(" \u2014 "),$W=a("a"),HXo=o("LxmertModel"),JXo=o(" (LXMERT model)"),YXo=l(),R2=a("li"),RFe=a("strong"),ZXo=o("m2m_100"),KXo=o(" \u2014 "),kW=a("a"),ezo=o("M2M100Model"),ozo=o(" (M2M100 model)"),rzo=l(),P2=a("li"),PFe=a("strong"),tzo=o("marian"),azo=o(" \u2014 "),SW=a("a"),nzo=o("MarianModel"),szo=o(" (Marian model)"),lzo=l(),B2=a("li"),BFe=a("strong"),izo=o("markuplm"),dzo=o(" \u2014 "),RW=a("a"),mzo=o("MarkupLMModel"),czo=o(" (MarkupLM model)"),fzo=l(),I2=a("li"),IFe=a("strong"),gzo=o("maskformer"),hzo=o(" \u2014 "),PW=a("a"),uzo=o("MaskFormerModel"),pzo=o(" (MaskFormer model)"),_zo=l(),N2=a("li"),NFe=a("strong"),bzo=o("mbart"),vzo=o(" \u2014 "),BW=a("a"),Fzo=o("MBartModel"),Tzo=o(" (mBART model)"),Mzo=l(),q2=a("li"),qFe=a("strong"),Ezo=o("mctct"),Czo=o(" \u2014 "),IW=a("a"),wzo=o("MCTCTModel"),Azo=o(" (M-CTC-T model)"),Lzo=l(),D2=a("li"),DFe=a("strong"),yzo=o("megatron-bert"),xzo=o(" \u2014 "),NW=a("a"),$zo=o("MegatronBertModel"),kzo=o(" (Megatron-BERT model)"),Szo=l(),j2=a("li"),jFe=a("strong"),Rzo=o("mobilebert"),Pzo=o(" \u2014 "),qW=a("a"),Bzo=o("MobileBertModel"),Izo=o(" (MobileBERT model)"),Nzo=l(),G2=a("li"),GFe=a("strong"),qzo=o("mobilevit"),Dzo=o(" \u2014 "),DW=a("a"),jzo=o("MobileViTModel"),Gzo=o(" (MobileViT model)"),Ozo=l(),O2=a("li"),OFe=a("strong"),Vzo=o("mpnet"),Xzo=o(" \u2014 "),jW=a("a"),zzo=o("MPNetModel"),Qzo=o(" (MPNet model)"),Wzo=l(),V2=a("li"),VFe=a("strong"),Uzo=o("mt5"),Hzo=o(" \u2014 "),GW=a("a"),Jzo=o("MT5Model"),Yzo=o(" (MT5 model)"),Zzo=l(),X2=a("li"),XFe=a("strong"),Kzo=o("mvp"),eQo=o(" \u2014 "),OW=a("a"),oQo=o("MvpModel"),rQo=o(" (MVP model)"),tQo=l(),z2=a("li"),zFe=a("strong"),aQo=o("nezha"),nQo=o(" \u2014 "),VW=a("a"),sQo=o("NezhaModel"),lQo=o(" (Nezha model)"),iQo=l(),Q2=a("li"),QFe=a("strong"),dQo=o("nllb"),mQo=o(" \u2014 "),XW=a("a"),cQo=o("M2M100Model"),fQo=o(" (NLLB model)"),gQo=l(),W2=a("li"),WFe=a("strong"),hQo=o("nystromformer"),uQo=o(" \u2014 "),zW=a("a"),pQo=o("NystromformerModel"),_Qo=o(" (Nystr\xF6mformer model)"),bQo=l(),U2=a("li"),UFe=a("strong"),vQo=o("openai-gpt"),FQo=o(" \u2014 "),QW=a("a"),TQo=o("OpenAIGPTModel"),MQo=o(" (OpenAI GPT model)"),EQo=l(),H2=a("li"),HFe=a("strong"),CQo=o("opt"),wQo=o(" \u2014 "),WW=a("a"),AQo=o("OPTModel"),LQo=o(" (OPT model)"),yQo=l(),J2=a("li"),JFe=a("strong"),xQo=o("owlvit"),$Qo=o(" \u2014 "),UW=a("a"),kQo=o("OwlViTModel"),SQo=o(" (OWL-ViT model)"),RQo=l(),Y2=a("li"),YFe=a("strong"),PQo=o("pegasus"),BQo=o(" \u2014 "),HW=a("a"),IQo=o("PegasusModel"),NQo=o(" (Pegasus model)"),qQo=l(),Z2=a("li"),ZFe=a("strong"),DQo=o("pegasus_x"),jQo=o(" \u2014 "),JW=a("a"),GQo=o("PegasusXModel"),OQo=o(" (PEGASUS-X model)"),VQo=l(),K2=a("li"),KFe=a("strong"),XQo=o("perceiver"),zQo=o(" \u2014 "),YW=a("a"),QQo=o("PerceiverModel"),WQo=o(" (Perceiver model)"),UQo=l(),eb=a("li"),eTe=a("strong"),HQo=o("plbart"),JQo=o(" \u2014 "),ZW=a("a"),YQo=o("PLBartModel"),ZQo=o(" (PLBart model)"),KQo=l(),ob=a("li"),oTe=a("strong"),eWo=o("poolformer"),oWo=o(" \u2014 "),KW=a("a"),rWo=o("PoolFormerModel"),tWo=o(" (PoolFormer model)"),aWo=l(),rb=a("li"),rTe=a("strong"),nWo=o("prophetnet"),sWo=o(" \u2014 "),eU=a("a"),lWo=o("ProphetNetModel"),iWo=o(" (ProphetNet model)"),dWo=l(),tb=a("li"),tTe=a("strong"),mWo=o("qdqbert"),cWo=o(" \u2014 "),oU=a("a"),fWo=o("QDQBertModel"),gWo=o(" (QDQBert model)"),hWo=l(),ab=a("li"),aTe=a("strong"),uWo=o("reformer"),pWo=o(" \u2014 "),rU=a("a"),_Wo=o("ReformerModel"),bWo=o(" (Reformer model)"),vWo=l(),nb=a("li"),nTe=a("strong"),FWo=o("regnet"),TWo=o(" \u2014 "),tU=a("a"),MWo=o("RegNetModel"),EWo=o(" (RegNet model)"),CWo=l(),sb=a("li"),sTe=a("strong"),wWo=o("rembert"),AWo=o(" \u2014 "),aU=a("a"),LWo=o("RemBertModel"),yWo=o(" (RemBERT model)"),xWo=l(),lb=a("li"),lTe=a("strong"),$Wo=o("resnet"),kWo=o(" \u2014 "),nU=a("a"),SWo=o("ResNetModel"),RWo=o(" (ResNet model)"),PWo=l(),ib=a("li"),iTe=a("strong"),BWo=o("retribert"),IWo=o(" \u2014 "),sU=a("a"),NWo=o("RetriBertModel"),qWo=o(" (RetriBERT model)"),DWo=l(),db=a("li"),dTe=a("strong"),jWo=o("roberta"),GWo=o(" \u2014 "),lU=a("a"),OWo=o("RobertaModel"),VWo=o(" (RoBERTa model)"),XWo=l(),mb=a("li"),mTe=a("strong"),zWo=o("roc_bert"),QWo=o(" \u2014 "),iU=a("a"),WWo=o("RoCBertModel"),UWo=o(" (RoCBert model)"),HWo=l(),cb=a("li"),cTe=a("strong"),JWo=o("roformer"),YWo=o(" \u2014 "),dU=a("a"),ZWo=o("RoFormerModel"),KWo=o(" (RoFormer model)"),eUo=l(),fb=a("li"),fTe=a("strong"),oUo=o("segformer"),rUo=o(" \u2014 "),mU=a("a"),tUo=o("SegformerModel"),aUo=o(" (SegFormer model)"),nUo=l(),gb=a("li"),gTe=a("strong"),sUo=o("sew"),lUo=o(" \u2014 "),cU=a("a"),iUo=o("SEWModel"),dUo=o(" (SEW model)"),mUo=l(),hb=a("li"),hTe=a("strong"),cUo=o("sew-d"),fUo=o(" \u2014 "),fU=a("a"),gUo=o("SEWDModel"),hUo=o(" (SEW-D model)"),uUo=l(),ub=a("li"),uTe=a("strong"),pUo=o("speech_to_text"),_Uo=o(" \u2014 "),gU=a("a"),bUo=o("Speech2TextModel"),vUo=o(" (Speech2Text model)"),FUo=l(),pb=a("li"),pTe=a("strong"),TUo=o("splinter"),MUo=o(" \u2014 "),hU=a("a"),EUo=o("SplinterModel"),CUo=o(" (Splinter model)"),wUo=l(),_b=a("li"),_Te=a("strong"),AUo=o("squeezebert"),LUo=o(" \u2014 "),uU=a("a"),yUo=o("SqueezeBertModel"),xUo=o(" (SqueezeBERT model)"),$Uo=l(),bb=a("li"),bTe=a("strong"),kUo=o("swin"),SUo=o(" \u2014 "),pU=a("a"),RUo=o("SwinModel"),PUo=o(" (Swin Transformer model)"),BUo=l(),vb=a("li"),vTe=a("strong"),IUo=o("swinv2"),NUo=o(" \u2014 "),_U=a("a"),qUo=o("Swinv2Model"),DUo=o(" (Swin Transformer V2 model)"),jUo=l(),Fb=a("li"),FTe=a("strong"),GUo=o("t5"),OUo=o(" \u2014 "),bU=a("a"),VUo=o("T5Model"),XUo=o(" (T5 model)"),zUo=l(),Tb=a("li"),TTe=a("strong"),QUo=o("table-transformer"),WUo=o(" \u2014 "),vU=a("a"),UUo=o("TableTransformerModel"),HUo=o(" (Table Transformer model)"),JUo=l(),Mb=a("li"),MTe=a("strong"),YUo=o("tapas"),ZUo=o(" \u2014 "),FU=a("a"),KUo=o("TapasModel"),eHo=o(" (TAPAS model)"),oHo=l(),Eb=a("li"),ETe=a("strong"),rHo=o("time_series_transformer"),tHo=o(" \u2014 "),TU=a("a"),aHo=o("TimeSeriesTransformerModel"),nHo=o(" (Time Series Transformer model)"),sHo=l(),Cb=a("li"),CTe=a("strong"),lHo=o("trajectory_transformer"),iHo=o(" \u2014 "),MU=a("a"),dHo=o("TrajectoryTransformerModel"),mHo=o(" (Trajectory Transformer model)"),cHo=l(),wb=a("li"),wTe=a("strong"),fHo=o("transfo-xl"),gHo=o(" \u2014 "),EU=a("a"),hHo=o("TransfoXLModel"),uHo=o(" (Transformer-XL model)"),pHo=l(),Ab=a("li"),ATe=a("strong"),_Ho=o("unispeech"),bHo=o(" \u2014 "),CU=a("a"),vHo=o("UniSpeechModel"),FHo=o(" (UniSpeech model)"),THo=l(),Lb=a("li"),LTe=a("strong"),MHo=o("unispeech-sat"),EHo=o(" \u2014 "),wU=a("a"),CHo=o("UniSpeechSatModel"),wHo=o(" (UniSpeechSat model)"),AHo=l(),yb=a("li"),yTe=a("strong"),LHo=o("van"),yHo=o(" \u2014 "),AU=a("a"),xHo=o("VanModel"),$Ho=o(" (VAN model)"),kHo=l(),xb=a("li"),xTe=a("strong"),SHo=o("videomae"),RHo=o(" \u2014 "),LU=a("a"),PHo=o("VideoMAEModel"),BHo=o(" (VideoMAE model)"),IHo=l(),$b=a("li"),$Te=a("strong"),NHo=o("vilt"),qHo=o(" \u2014 "),yU=a("a"),DHo=o("ViltModel"),jHo=o(" (ViLT model)"),GHo=l(),kb=a("li"),kTe=a("strong"),OHo=o("vision-text-dual-encoder"),VHo=o(" \u2014 "),xU=a("a"),XHo=o("VisionTextDualEncoderModel"),zHo=o(" (VisionTextDualEncoder model)"),QHo=l(),Sb=a("li"),STe=a("strong"),WHo=o("visual_bert"),UHo=o(" \u2014 "),$U=a("a"),HHo=o("VisualBertModel"),JHo=o(" (VisualBERT model)"),YHo=l(),Rb=a("li"),RTe=a("strong"),ZHo=o("vit"),KHo=o(" \u2014 "),kU=a("a"),eJo=o("ViTModel"),oJo=o(" (ViT model)"),rJo=l(),Pb=a("li"),PTe=a("strong"),tJo=o("vit_mae"),aJo=o(" \u2014 "),SU=a("a"),nJo=o("ViTMAEModel"),sJo=o(" (ViTMAE model)"),lJo=l(),Bb=a("li"),BTe=a("strong"),iJo=o("vit_msn"),dJo=o(" \u2014 "),RU=a("a"),mJo=o("ViTMSNModel"),cJo=o(" (ViTMSN model)"),fJo=l(),Ib=a("li"),ITe=a("strong"),gJo=o("wav2vec2"),hJo=o(" \u2014 "),PU=a("a"),uJo=o("Wav2Vec2Model"),pJo=o(" (Wav2Vec2 model)"),_Jo=l(),Nb=a("li"),NTe=a("strong"),bJo=o("wav2vec2-conformer"),vJo=o(" \u2014 "),BU=a("a"),FJo=o("Wav2Vec2ConformerModel"),TJo=o(" (Wav2Vec2-Conformer model)"),MJo=l(),qb=a("li"),qTe=a("strong"),EJo=o("wavlm"),CJo=o(" \u2014 "),IU=a("a"),wJo=o("WavLMModel"),AJo=o(" (WavLM model)"),LJo=l(),Db=a("li"),DTe=a("strong"),yJo=o("whisper"),xJo=o(" \u2014 "),NU=a("a"),$Jo=o("WhisperModel"),kJo=o(" (Whisper model)"),SJo=l(),jb=a("li"),jTe=a("strong"),RJo=o("xclip"),PJo=o(" \u2014 "),qU=a("a"),BJo=o("XCLIPModel"),IJo=o(" (X-CLIP model)"),NJo=l(),Gb=a("li"),GTe=a("strong"),qJo=o("xglm"),DJo=o(" \u2014 "),DU=a("a"),jJo=o("XGLMModel"),GJo=o(" (XGLM model)"),OJo=l(),Ob=a("li"),OTe=a("strong"),VJo=o("xlm"),XJo=o(" \u2014 "),jU=a("a"),zJo=o("XLMModel"),QJo=o(" (XLM model)"),WJo=l(),Vb=a("li"),VTe=a("strong"),UJo=o("xlm-prophetnet"),HJo=o(" \u2014 "),GU=a("a"),JJo=o("XLMProphetNetModel"),YJo=o(" (XLM-ProphetNet model)"),ZJo=l(),Xb=a("li"),XTe=a("strong"),KJo=o("xlm-roberta"),eYo=o(" \u2014 "),OU=a("a"),oYo=o("XLMRobertaModel"),rYo=o(" (XLM-RoBERTa model)"),tYo=l(),zb=a("li"),zTe=a("strong"),aYo=o("xlm-roberta-xl"),nYo=o(" \u2014 "),VU=a("a"),sYo=o("XLMRobertaXLModel"),lYo=o(" (XLM-RoBERTa-XL model)"),iYo=l(),Qb=a("li"),QTe=a("strong"),dYo=o("xlnet"),mYo=o(" \u2014 "),XU=a("a"),cYo=o("XLNetModel"),fYo=o(" (XLNet model)"),gYo=l(),Wb=a("li"),WTe=a("strong"),hYo=o("yolos"),uYo=o(" \u2014 "),zU=a("a"),pYo=o("YolosModel"),_Yo=o(" (YOLOS model)"),bYo=l(),Ub=a("li"),UTe=a("strong"),vYo=o("yoso"),FYo=o(" \u2014 "),QU=a("a"),TYo=o("YosoModel"),MYo=o(" (YOSO model)"),EYo=l(),Hb=a("p"),CYo=o("The model is set in evaluation mode by default using "),HTe=a("code"),wYo=o("model.eval()"),AYo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),JTe=a("code"),LYo=o("model.train()"),yYo=l(),F(Jb.$$.fragment),Rlo=l(),Xd=a("h2"),Yb=a("a"),YTe=a("span"),F(Hk.$$.fragment),xYo=l(),ZTe=a("span"),$Yo=o("AutoModelForPreTraining"),Plo=l(),Go=a("div"),F(Jk.$$.fragment),kYo=l(),zd=a("p"),SYo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),WU=a("a"),RYo=o("from_pretrained()"),PYo=o(" class method or the "),UU=a("a"),BYo=o("from_config()"),IYo=o(` class
method.`),NYo=l(),Yk=a("p"),qYo=o("This class cannot be instantiated directly using "),KTe=a("code"),DYo=o("__init__()"),jYo=o(" (throws an error)."),GYo=l(),Lt=a("div"),F(Zk.$$.fragment),OYo=l(),eMe=a("p"),VYo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),XYo=l(),Qd=a("p"),zYo=o(`Note:
Loading a model from its configuration file does `),oMe=a("strong"),QYo=o("not"),WYo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),HU=a("a"),UYo=o("from_pretrained()"),HYo=o(" to load the model weights."),JYo=l(),F(Zb.$$.fragment),YYo=l(),ao=a("div"),F(Kk.$$.fragment),ZYo=l(),rMe=a("p"),KYo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),eZo=l(),gn=a("p"),oZo=o("The model class to instantiate is selected based on the "),tMe=a("code"),rZo=o("model_type"),tZo=o(` property of the config object (either
passed as an argument or loaded from `),aMe=a("code"),aZo=o("pretrained_model_name_or_path"),nZo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nMe=a("code"),sZo=o("pretrained_model_name_or_path"),lZo=o(":"),iZo=l(),G=a("ul"),Kb=a("li"),sMe=a("strong"),dZo=o("albert"),mZo=o(" \u2014 "),JU=a("a"),cZo=o("AlbertForPreTraining"),fZo=o(" (ALBERT model)"),gZo=l(),ev=a("li"),lMe=a("strong"),hZo=o("bart"),uZo=o(" \u2014 "),YU=a("a"),pZo=o("BartForConditionalGeneration"),_Zo=o(" (BART model)"),bZo=l(),ov=a("li"),iMe=a("strong"),vZo=o("bert"),FZo=o(" \u2014 "),ZU=a("a"),TZo=o("BertForPreTraining"),MZo=o(" (BERT model)"),EZo=l(),rv=a("li"),dMe=a("strong"),CZo=o("big_bird"),wZo=o(" \u2014 "),KU=a("a"),AZo=o("BigBirdForPreTraining"),LZo=o(" (BigBird model)"),yZo=l(),tv=a("li"),mMe=a("strong"),xZo=o("bloom"),$Zo=o(" \u2014 "),eH=a("a"),kZo=o("BloomForCausalLM"),SZo=o(" (BLOOM model)"),RZo=l(),av=a("li"),cMe=a("strong"),PZo=o("camembert"),BZo=o(" \u2014 "),oH=a("a"),IZo=o("CamembertForMaskedLM"),NZo=o(" (CamemBERT model)"),qZo=l(),nv=a("li"),fMe=a("strong"),DZo=o("ctrl"),jZo=o(" \u2014 "),rH=a("a"),GZo=o("CTRLLMHeadModel"),OZo=o(" (CTRL model)"),VZo=l(),sv=a("li"),gMe=a("strong"),XZo=o("data2vec-text"),zZo=o(" \u2014 "),tH=a("a"),QZo=o("Data2VecTextForMaskedLM"),WZo=o(" (Data2VecText model)"),UZo=l(),lv=a("li"),hMe=a("strong"),HZo=o("deberta"),JZo=o(" \u2014 "),aH=a("a"),YZo=o("DebertaForMaskedLM"),ZZo=o(" (DeBERTa model)"),KZo=l(),iv=a("li"),uMe=a("strong"),eKo=o("deberta-v2"),oKo=o(" \u2014 "),nH=a("a"),rKo=o("DebertaV2ForMaskedLM"),tKo=o(" (DeBERTa-v2 model)"),aKo=l(),dv=a("li"),pMe=a("strong"),nKo=o("distilbert"),sKo=o(" \u2014 "),sH=a("a"),lKo=o("DistilBertForMaskedLM"),iKo=o(" (DistilBERT model)"),dKo=l(),mv=a("li"),_Me=a("strong"),mKo=o("electra"),cKo=o(" \u2014 "),lH=a("a"),fKo=o("ElectraForPreTraining"),gKo=o(" (ELECTRA model)"),hKo=l(),cv=a("li"),bMe=a("strong"),uKo=o("ernie"),pKo=o(" \u2014 "),iH=a("a"),_Ko=o("ErnieForPreTraining"),bKo=o(" (ERNIE model)"),vKo=l(),fv=a("li"),vMe=a("strong"),FKo=o("flaubert"),TKo=o(" \u2014 "),dH=a("a"),MKo=o("FlaubertWithLMHeadModel"),EKo=o(" (FlauBERT model)"),CKo=l(),gv=a("li"),FMe=a("strong"),wKo=o("flava"),AKo=o(" \u2014 "),mH=a("a"),LKo=o("FlavaForPreTraining"),yKo=o(" (FLAVA model)"),xKo=l(),hv=a("li"),TMe=a("strong"),$Ko=o("fnet"),kKo=o(" \u2014 "),cH=a("a"),SKo=o("FNetForPreTraining"),RKo=o(" (FNet model)"),PKo=l(),uv=a("li"),MMe=a("strong"),BKo=o("fsmt"),IKo=o(" \u2014 "),fH=a("a"),NKo=o("FSMTForConditionalGeneration"),qKo=o(" (FairSeq Machine-Translation model)"),DKo=l(),pv=a("li"),EMe=a("strong"),jKo=o("funnel"),GKo=o(" \u2014 "),gH=a("a"),OKo=o("FunnelForPreTraining"),VKo=o(" (Funnel Transformer model)"),XKo=l(),_v=a("li"),CMe=a("strong"),zKo=o("gpt2"),QKo=o(" \u2014 "),hH=a("a"),WKo=o("GPT2LMHeadModel"),UKo=o(" (OpenAI GPT-2 model)"),HKo=l(),bv=a("li"),wMe=a("strong"),JKo=o("ibert"),YKo=o(" \u2014 "),uH=a("a"),ZKo=o("IBertForMaskedLM"),KKo=o(" (I-BERT model)"),eer=l(),vv=a("li"),AMe=a("strong"),oer=o("layoutlm"),rer=o(" \u2014 "),pH=a("a"),ter=o("LayoutLMForMaskedLM"),aer=o(" (LayoutLM model)"),ner=l(),Fv=a("li"),LMe=a("strong"),ser=o("longformer"),ler=o(" \u2014 "),_H=a("a"),ier=o("LongformerForMaskedLM"),der=o(" (Longformer model)"),mer=l(),Tv=a("li"),yMe=a("strong"),cer=o("luke"),fer=o(" \u2014 "),bH=a("a"),ger=o("LukeForMaskedLM"),her=o(" (LUKE model)"),uer=l(),Mv=a("li"),xMe=a("strong"),per=o("lxmert"),_er=o(" \u2014 "),vH=a("a"),ber=o("LxmertForPreTraining"),ver=o(" (LXMERT model)"),Fer=l(),Ev=a("li"),$Me=a("strong"),Ter=o("megatron-bert"),Mer=o(" \u2014 "),FH=a("a"),Eer=o("MegatronBertForPreTraining"),Cer=o(" (Megatron-BERT model)"),wer=l(),Cv=a("li"),kMe=a("strong"),Aer=o("mobilebert"),Ler=o(" \u2014 "),TH=a("a"),yer=o("MobileBertForPreTraining"),xer=o(" (MobileBERT model)"),$er=l(),wv=a("li"),SMe=a("strong"),ker=o("mpnet"),Ser=o(" \u2014 "),MH=a("a"),Rer=o("MPNetForMaskedLM"),Per=o(" (MPNet model)"),Ber=l(),Av=a("li"),RMe=a("strong"),Ier=o("mvp"),Ner=o(" \u2014 "),EH=a("a"),qer=o("MvpForConditionalGeneration"),Der=o(" (MVP model)"),jer=l(),Lv=a("li"),PMe=a("strong"),Ger=o("nezha"),Oer=o(" \u2014 "),CH=a("a"),Ver=o("NezhaForPreTraining"),Xer=o(" (Nezha model)"),zer=l(),yv=a("li"),BMe=a("strong"),Qer=o("openai-gpt"),Wer=o(" \u2014 "),wH=a("a"),Uer=o("OpenAIGPTLMHeadModel"),Her=o(" (OpenAI GPT model)"),Jer=l(),xv=a("li"),IMe=a("strong"),Yer=o("retribert"),Zer=o(" \u2014 "),AH=a("a"),Ker=o("RetriBertModel"),eor=o(" (RetriBERT model)"),oor=l(),$v=a("li"),NMe=a("strong"),ror=o("roberta"),tor=o(" \u2014 "),LH=a("a"),aor=o("RobertaForMaskedLM"),nor=o(" (RoBERTa model)"),sor=l(),kv=a("li"),qMe=a("strong"),lor=o("roc_bert"),ior=o(" \u2014 "),yH=a("a"),dor=o("RoCBertForPreTraining"),mor=o(" (RoCBert model)"),cor=l(),Sv=a("li"),DMe=a("strong"),gor=o("splinter"),hor=o(" \u2014 "),xH=a("a"),uor=o("SplinterForPreTraining"),por=o(" (Splinter model)"),_or=l(),Rv=a("li"),jMe=a("strong"),bor=o("squeezebert"),vor=o(" \u2014 "),$H=a("a"),For=o("SqueezeBertForMaskedLM"),Tor=o(" (SqueezeBERT model)"),Mor=l(),Pv=a("li"),GMe=a("strong"),Eor=o("t5"),Cor=o(" \u2014 "),kH=a("a"),wor=o("T5ForConditionalGeneration"),Aor=o(" (T5 model)"),Lor=l(),Bv=a("li"),OMe=a("strong"),yor=o("tapas"),xor=o(" \u2014 "),SH=a("a"),$or=o("TapasForMaskedLM"),kor=o(" (TAPAS model)"),Sor=l(),Iv=a("li"),VMe=a("strong"),Ror=o("transfo-xl"),Por=o(" \u2014 "),RH=a("a"),Bor=o("TransfoXLLMHeadModel"),Ior=o(" (Transformer-XL model)"),Nor=l(),Nv=a("li"),XMe=a("strong"),qor=o("unispeech"),Dor=o(" \u2014 "),PH=a("a"),jor=o("UniSpeechForPreTraining"),Gor=o(" (UniSpeech model)"),Oor=l(),qv=a("li"),zMe=a("strong"),Vor=o("unispeech-sat"),Xor=o(" \u2014 "),BH=a("a"),zor=o("UniSpeechSatForPreTraining"),Qor=o(" (UniSpeechSat model)"),Wor=l(),Dv=a("li"),QMe=a("strong"),Uor=o("videomae"),Hor=o(" \u2014 "),IH=a("a"),Jor=o("VideoMAEForPreTraining"),Yor=o(" (VideoMAE model)"),Zor=l(),jv=a("li"),WMe=a("strong"),Kor=o("visual_bert"),err=o(" \u2014 "),NH=a("a"),orr=o("VisualBertForPreTraining"),rrr=o(" (VisualBERT model)"),trr=l(),Gv=a("li"),UMe=a("strong"),arr=o("vit_mae"),nrr=o(" \u2014 "),qH=a("a"),srr=o("ViTMAEForPreTraining"),lrr=o(" (ViTMAE model)"),irr=l(),Ov=a("li"),HMe=a("strong"),drr=o("wav2vec2"),mrr=o(" \u2014 "),DH=a("a"),crr=o("Wav2Vec2ForPreTraining"),frr=o(" (Wav2Vec2 model)"),grr=l(),Vv=a("li"),JMe=a("strong"),hrr=o("wav2vec2-conformer"),urr=o(" \u2014 "),jH=a("a"),prr=o("Wav2Vec2ConformerForPreTraining"),_rr=o(" (Wav2Vec2-Conformer model)"),brr=l(),Xv=a("li"),YMe=a("strong"),vrr=o("xlm"),Frr=o(" \u2014 "),GH=a("a"),Trr=o("XLMWithLMHeadModel"),Mrr=o(" (XLM model)"),Err=l(),zv=a("li"),ZMe=a("strong"),Crr=o("xlm-roberta"),wrr=o(" \u2014 "),OH=a("a"),Arr=o("XLMRobertaForMaskedLM"),Lrr=o(" (XLM-RoBERTa model)"),yrr=l(),Qv=a("li"),KMe=a("strong"),xrr=o("xlm-roberta-xl"),$rr=o(" \u2014 "),VH=a("a"),krr=o("XLMRobertaXLForMaskedLM"),Srr=o(" (XLM-RoBERTa-XL model)"),Rrr=l(),Wv=a("li"),eEe=a("strong"),Prr=o("xlnet"),Brr=o(" \u2014 "),XH=a("a"),Irr=o("XLNetLMHeadModel"),Nrr=o(" (XLNet model)"),qrr=l(),Uv=a("p"),Drr=o("The model is set in evaluation mode by default using "),oEe=a("code"),jrr=o("model.eval()"),Grr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),rEe=a("code"),Orr=o("model.train()"),Vrr=l(),F(Hv.$$.fragment),Blo=l(),Wd=a("h2"),Jv=a("a"),tEe=a("span"),F(eS.$$.fragment),Xrr=l(),aEe=a("span"),zrr=o("AutoModelForCausalLM"),Ilo=l(),Oo=a("div"),F(oS.$$.fragment),Qrr=l(),Ud=a("p"),Wrr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),zH=a("a"),Urr=o("from_pretrained()"),Hrr=o(" class method or the "),QH=a("a"),Jrr=o("from_config()"),Yrr=o(` class
method.`),Zrr=l(),rS=a("p"),Krr=o("This class cannot be instantiated directly using "),nEe=a("code"),etr=o("__init__()"),otr=o(" (throws an error)."),rtr=l(),yt=a("div"),F(tS.$$.fragment),ttr=l(),sEe=a("p"),atr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),ntr=l(),Hd=a("p"),str=o(`Note:
Loading a model from its configuration file does `),lEe=a("strong"),ltr=o("not"),itr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WH=a("a"),dtr=o("from_pretrained()"),mtr=o(" to load the model weights."),ctr=l(),F(Yv.$$.fragment),ftr=l(),no=a("div"),F(aS.$$.fragment),gtr=l(),iEe=a("p"),htr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),utr=l(),hn=a("p"),ptr=o("The model class to instantiate is selected based on the "),dEe=a("code"),_tr=o("model_type"),btr=o(` property of the config object (either
passed as an argument or loaded from `),mEe=a("code"),vtr=o("pretrained_model_name_or_path"),Ftr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cEe=a("code"),Ttr=o("pretrained_model_name_or_path"),Mtr=o(":"),Etr=l(),W=a("ul"),Zv=a("li"),fEe=a("strong"),Ctr=o("bart"),wtr=o(" \u2014 "),UH=a("a"),Atr=o("BartForCausalLM"),Ltr=o(" (BART model)"),ytr=l(),Kv=a("li"),gEe=a("strong"),xtr=o("bert"),$tr=o(" \u2014 "),HH=a("a"),ktr=o("BertLMHeadModel"),Str=o(" (BERT model)"),Rtr=l(),eF=a("li"),hEe=a("strong"),Ptr=o("bert-generation"),Btr=o(" \u2014 "),JH=a("a"),Itr=o("BertGenerationDecoder"),Ntr=o(" (Bert Generation model)"),qtr=l(),oF=a("li"),uEe=a("strong"),Dtr=o("big_bird"),jtr=o(" \u2014 "),YH=a("a"),Gtr=o("BigBirdForCausalLM"),Otr=o(" (BigBird model)"),Vtr=l(),rF=a("li"),pEe=a("strong"),Xtr=o("bigbird_pegasus"),ztr=o(" \u2014 "),ZH=a("a"),Qtr=o("BigBirdPegasusForCausalLM"),Wtr=o(" (BigBird-Pegasus model)"),Utr=l(),tF=a("li"),_Ee=a("strong"),Htr=o("blenderbot"),Jtr=o(" \u2014 "),KH=a("a"),Ytr=o("BlenderbotForCausalLM"),Ztr=o(" (Blenderbot model)"),Ktr=l(),aF=a("li"),bEe=a("strong"),ear=o("blenderbot-small"),oar=o(" \u2014 "),eJ=a("a"),rar=o("BlenderbotSmallForCausalLM"),tar=o(" (BlenderbotSmall model)"),aar=l(),nF=a("li"),vEe=a("strong"),nar=o("bloom"),sar=o(" \u2014 "),oJ=a("a"),lar=o("BloomForCausalLM"),iar=o(" (BLOOM model)"),dar=l(),sF=a("li"),FEe=a("strong"),mar=o("camembert"),car=o(" \u2014 "),rJ=a("a"),far=o("CamembertForCausalLM"),gar=o(" (CamemBERT model)"),har=l(),lF=a("li"),TEe=a("strong"),uar=o("codegen"),par=o(" \u2014 "),tJ=a("a"),_ar=o("CodeGenForCausalLM"),bar=o(" (CodeGen model)"),Far=l(),iF=a("li"),MEe=a("strong"),Tar=o("ctrl"),Mar=o(" \u2014 "),aJ=a("a"),Ear=o("CTRLLMHeadModel"),Car=o(" (CTRL model)"),war=l(),dF=a("li"),EEe=a("strong"),Aar=o("data2vec-text"),Lar=o(" \u2014 "),nJ=a("a"),yar=o("Data2VecTextForCausalLM"),xar=o(" (Data2VecText model)"),$ar=l(),mF=a("li"),CEe=a("strong"),kar=o("electra"),Sar=o(" \u2014 "),sJ=a("a"),Rar=o("ElectraForCausalLM"),Par=o(" (ELECTRA model)"),Bar=l(),cF=a("li"),wEe=a("strong"),Iar=o("ernie"),Nar=o(" \u2014 "),lJ=a("a"),qar=o("ErnieForCausalLM"),Dar=o(" (ERNIE model)"),jar=l(),fF=a("li"),AEe=a("strong"),Gar=o("gpt2"),Oar=o(" \u2014 "),iJ=a("a"),Var=o("GPT2LMHeadModel"),Xar=o(" (OpenAI GPT-2 model)"),zar=l(),gF=a("li"),LEe=a("strong"),Qar=o("gpt_neo"),War=o(" \u2014 "),dJ=a("a"),Uar=o("GPTNeoForCausalLM"),Har=o(" (GPT Neo model)"),Jar=l(),hF=a("li"),yEe=a("strong"),Yar=o("gpt_neox"),Zar=o(" \u2014 "),mJ=a("a"),Kar=o("GPTNeoXForCausalLM"),enr=o(" (GPT NeoX model)"),onr=l(),uF=a("li"),xEe=a("strong"),rnr=o("gpt_neox_japanese"),tnr=o(" \u2014 "),cJ=a("a"),anr=o("GPTNeoXJapaneseForCausalLM"),nnr=o(" (GPT NeoX Japanese model)"),snr=l(),pF=a("li"),$Ee=a("strong"),lnr=o("gptj"),inr=o(" \u2014 "),fJ=a("a"),dnr=o("GPTJForCausalLM"),mnr=o(" (GPT-J model)"),cnr=l(),_F=a("li"),kEe=a("strong"),fnr=o("marian"),gnr=o(" \u2014 "),gJ=a("a"),hnr=o("MarianForCausalLM"),unr=o(" (Marian model)"),pnr=l(),bF=a("li"),SEe=a("strong"),_nr=o("mbart"),bnr=o(" \u2014 "),hJ=a("a"),vnr=o("MBartForCausalLM"),Fnr=o(" (mBART model)"),Tnr=l(),vF=a("li"),REe=a("strong"),Mnr=o("megatron-bert"),Enr=o(" \u2014 "),uJ=a("a"),Cnr=o("MegatronBertForCausalLM"),wnr=o(" (Megatron-BERT model)"),Anr=l(),FF=a("li"),PEe=a("strong"),Lnr=o("mvp"),ynr=o(" \u2014 "),pJ=a("a"),xnr=o("MvpForCausalLM"),$nr=o(" (MVP model)"),knr=l(),TF=a("li"),BEe=a("strong"),Snr=o("openai-gpt"),Rnr=o(" \u2014 "),_J=a("a"),Pnr=o("OpenAIGPTLMHeadModel"),Bnr=o(" (OpenAI GPT model)"),Inr=l(),MF=a("li"),IEe=a("strong"),Nnr=o("opt"),qnr=o(" \u2014 "),bJ=a("a"),Dnr=o("OPTForCausalLM"),jnr=o(" (OPT model)"),Gnr=l(),EF=a("li"),NEe=a("strong"),Onr=o("pegasus"),Vnr=o(" \u2014 "),vJ=a("a"),Xnr=o("PegasusForCausalLM"),znr=o(" (Pegasus model)"),Qnr=l(),CF=a("li"),qEe=a("strong"),Wnr=o("plbart"),Unr=o(" \u2014 "),FJ=a("a"),Hnr=o("PLBartForCausalLM"),Jnr=o(" (PLBart model)"),Ynr=l(),wF=a("li"),DEe=a("strong"),Znr=o("prophetnet"),Knr=o(" \u2014 "),TJ=a("a"),esr=o("ProphetNetForCausalLM"),osr=o(" (ProphetNet model)"),rsr=l(),AF=a("li"),jEe=a("strong"),tsr=o("qdqbert"),asr=o(" \u2014 "),MJ=a("a"),nsr=o("QDQBertLMHeadModel"),ssr=o(" (QDQBert model)"),lsr=l(),LF=a("li"),GEe=a("strong"),isr=o("reformer"),dsr=o(" \u2014 "),EJ=a("a"),msr=o("ReformerModelWithLMHead"),csr=o(" (Reformer model)"),fsr=l(),yF=a("li"),OEe=a("strong"),gsr=o("rembert"),hsr=o(" \u2014 "),CJ=a("a"),usr=o("RemBertForCausalLM"),psr=o(" (RemBERT model)"),_sr=l(),xF=a("li"),VEe=a("strong"),bsr=o("roberta"),vsr=o(" \u2014 "),wJ=a("a"),Fsr=o("RobertaForCausalLM"),Tsr=o(" (RoBERTa model)"),Msr=l(),$F=a("li"),XEe=a("strong"),Esr=o("roc_bert"),Csr=o(" \u2014 "),AJ=a("a"),wsr=o("RoCBertForCausalLM"),Asr=o(" (RoCBert model)"),Lsr=l(),kF=a("li"),zEe=a("strong"),ysr=o("roformer"),xsr=o(" \u2014 "),LJ=a("a"),$sr=o("RoFormerForCausalLM"),ksr=o(" (RoFormer model)"),Ssr=l(),SF=a("li"),QEe=a("strong"),Rsr=o("speech_to_text_2"),Psr=o(" \u2014 "),yJ=a("a"),Bsr=o("Speech2Text2ForCausalLM"),Isr=o(" (Speech2Text2 model)"),Nsr=l(),RF=a("li"),WEe=a("strong"),qsr=o("transfo-xl"),Dsr=o(" \u2014 "),xJ=a("a"),jsr=o("TransfoXLLMHeadModel"),Gsr=o(" (Transformer-XL model)"),Osr=l(),PF=a("li"),UEe=a("strong"),Vsr=o("trocr"),Xsr=o(" \u2014 "),$J=a("a"),zsr=o("TrOCRForCausalLM"),Qsr=o(" (TrOCR model)"),Wsr=l(),BF=a("li"),HEe=a("strong"),Usr=o("xglm"),Hsr=o(" \u2014 "),kJ=a("a"),Jsr=o("XGLMForCausalLM"),Ysr=o(" (XGLM model)"),Zsr=l(),IF=a("li"),JEe=a("strong"),Ksr=o("xlm"),elr=o(" \u2014 "),SJ=a("a"),olr=o("XLMWithLMHeadModel"),rlr=o(" (XLM model)"),tlr=l(),NF=a("li"),YEe=a("strong"),alr=o("xlm-prophetnet"),nlr=o(" \u2014 "),RJ=a("a"),slr=o("XLMProphetNetForCausalLM"),llr=o(" (XLM-ProphetNet model)"),ilr=l(),qF=a("li"),ZEe=a("strong"),dlr=o("xlm-roberta"),mlr=o(" \u2014 "),PJ=a("a"),clr=o("XLMRobertaForCausalLM"),flr=o(" (XLM-RoBERTa model)"),glr=l(),DF=a("li"),KEe=a("strong"),hlr=o("xlm-roberta-xl"),ulr=o(" \u2014 "),BJ=a("a"),plr=o("XLMRobertaXLForCausalLM"),_lr=o(" (XLM-RoBERTa-XL model)"),blr=l(),jF=a("li"),e4e=a("strong"),vlr=o("xlnet"),Flr=o(" \u2014 "),IJ=a("a"),Tlr=o("XLNetLMHeadModel"),Mlr=o(" (XLNet model)"),Elr=l(),GF=a("p"),Clr=o("The model is set in evaluation mode by default using "),o4e=a("code"),wlr=o("model.eval()"),Alr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),r4e=a("code"),Llr=o("model.train()"),ylr=l(),F(OF.$$.fragment),Nlo=l(),Jd=a("h2"),VF=a("a"),t4e=a("span"),F(nS.$$.fragment),xlr=l(),a4e=a("span"),$lr=o("AutoModelForDepthEstimation"),qlo=l(),Vo=a("div"),F(sS.$$.fragment),klr=l(),Yd=a("p"),Slr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a depth estimation head) when created
with the `),NJ=a("a"),Rlr=o("from_pretrained()"),Plr=o(" class method or the "),qJ=a("a"),Blr=o("from_config()"),Ilr=o(` class
method.`),Nlr=l(),lS=a("p"),qlr=o("This class cannot be instantiated directly using "),n4e=a("code"),Dlr=o("__init__()"),jlr=o(" (throws an error)."),Glr=l(),xt=a("div"),F(iS.$$.fragment),Olr=l(),s4e=a("p"),Vlr=o("Instantiates one of the model classes of the library (with a depth estimation head) from a configuration."),Xlr=l(),Zd=a("p"),zlr=o(`Note:
Loading a model from its configuration file does `),l4e=a("strong"),Qlr=o("not"),Wlr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),DJ=a("a"),Ulr=o("from_pretrained()"),Hlr=o(" to load the model weights."),Jlr=l(),F(XF.$$.fragment),Ylr=l(),so=a("div"),F(dS.$$.fragment),Zlr=l(),i4e=a("p"),Klr=o("Instantiate one of the model classes of the library (with a depth estimation head) from a pretrained model."),eir=l(),un=a("p"),oir=o("The model class to instantiate is selected based on the "),d4e=a("code"),rir=o("model_type"),tir=o(` property of the config object (either
passed as an argument or loaded from `),m4e=a("code"),air=o("pretrained_model_name_or_path"),nir=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c4e=a("code"),sir=o("pretrained_model_name_or_path"),lir=o(":"),iir=l(),mS=a("ul"),zF=a("li"),f4e=a("strong"),dir=o("dpt"),mir=o(" \u2014 "),jJ=a("a"),cir=o("DPTForDepthEstimation"),fir=o(" (DPT model)"),gir=l(),QF=a("li"),g4e=a("strong"),hir=o("glpn"),uir=o(" \u2014 "),GJ=a("a"),pir=o("GLPNForDepthEstimation"),_ir=o(" (GLPN model)"),bir=l(),WF=a("p"),vir=o("The model is set in evaluation mode by default using "),h4e=a("code"),Fir=o("model.eval()"),Tir=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),u4e=a("code"),Mir=o("model.train()"),Eir=l(),F(UF.$$.fragment),Dlo=l(),Kd=a("h2"),HF=a("a"),p4e=a("span"),F(cS.$$.fragment),Cir=l(),_4e=a("span"),wir=o("AutoModelForMaskedLM"),jlo=l(),Xo=a("div"),F(fS.$$.fragment),Air=l(),em=a("p"),Lir=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),OJ=a("a"),yir=o("from_pretrained()"),xir=o(" class method or the "),VJ=a("a"),$ir=o("from_config()"),kir=o(` class
method.`),Sir=l(),gS=a("p"),Rir=o("This class cannot be instantiated directly using "),b4e=a("code"),Pir=o("__init__()"),Bir=o(" (throws an error)."),Iir=l(),$t=a("div"),F(hS.$$.fragment),Nir=l(),v4e=a("p"),qir=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Dir=l(),om=a("p"),jir=o(`Note:
Loading a model from its configuration file does `),F4e=a("strong"),Gir=o("not"),Oir=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),XJ=a("a"),Vir=o("from_pretrained()"),Xir=o(" to load the model weights."),zir=l(),F(JF.$$.fragment),Qir=l(),lo=a("div"),F(uS.$$.fragment),Wir=l(),T4e=a("p"),Uir=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Hir=l(),pn=a("p"),Jir=o("The model class to instantiate is selected based on the "),M4e=a("code"),Yir=o("model_type"),Zir=o(` property of the config object (either
passed as an argument or loaded from `),E4e=a("code"),Kir=o("pretrained_model_name_or_path"),edr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C4e=a("code"),odr=o("pretrained_model_name_or_path"),rdr=o(":"),tdr=l(),Y=a("ul"),YF=a("li"),w4e=a("strong"),adr=o("albert"),ndr=o(" \u2014 "),zJ=a("a"),sdr=o("AlbertForMaskedLM"),ldr=o(" (ALBERT model)"),idr=l(),ZF=a("li"),A4e=a("strong"),ddr=o("bart"),mdr=o(" \u2014 "),QJ=a("a"),cdr=o("BartForConditionalGeneration"),fdr=o(" (BART model)"),gdr=l(),KF=a("li"),L4e=a("strong"),hdr=o("bert"),udr=o(" \u2014 "),WJ=a("a"),pdr=o("BertForMaskedLM"),_dr=o(" (BERT model)"),bdr=l(),eT=a("li"),y4e=a("strong"),vdr=o("big_bird"),Fdr=o(" \u2014 "),UJ=a("a"),Tdr=o("BigBirdForMaskedLM"),Mdr=o(" (BigBird model)"),Edr=l(),oT=a("li"),x4e=a("strong"),Cdr=o("camembert"),wdr=o(" \u2014 "),HJ=a("a"),Adr=o("CamembertForMaskedLM"),Ldr=o(" (CamemBERT model)"),ydr=l(),rT=a("li"),$4e=a("strong"),xdr=o("convbert"),$dr=o(" \u2014 "),JJ=a("a"),kdr=o("ConvBertForMaskedLM"),Sdr=o(" (ConvBERT model)"),Rdr=l(),tT=a("li"),k4e=a("strong"),Pdr=o("data2vec-text"),Bdr=o(" \u2014 "),YJ=a("a"),Idr=o("Data2VecTextForMaskedLM"),Ndr=o(" (Data2VecText model)"),qdr=l(),aT=a("li"),S4e=a("strong"),Ddr=o("deberta"),jdr=o(" \u2014 "),ZJ=a("a"),Gdr=o("DebertaForMaskedLM"),Odr=o(" (DeBERTa model)"),Vdr=l(),nT=a("li"),R4e=a("strong"),Xdr=o("deberta-v2"),zdr=o(" \u2014 "),KJ=a("a"),Qdr=o("DebertaV2ForMaskedLM"),Wdr=o(" (DeBERTa-v2 model)"),Udr=l(),sT=a("li"),P4e=a("strong"),Hdr=o("distilbert"),Jdr=o(" \u2014 "),eY=a("a"),Ydr=o("DistilBertForMaskedLM"),Zdr=o(" (DistilBERT model)"),Kdr=l(),lT=a("li"),B4e=a("strong"),emr=o("electra"),omr=o(" \u2014 "),oY=a("a"),rmr=o("ElectraForMaskedLM"),tmr=o(" (ELECTRA model)"),amr=l(),iT=a("li"),I4e=a("strong"),nmr=o("ernie"),smr=o(" \u2014 "),rY=a("a"),lmr=o("ErnieForMaskedLM"),imr=o(" (ERNIE model)"),dmr=l(),dT=a("li"),N4e=a("strong"),mmr=o("flaubert"),cmr=o(" \u2014 "),tY=a("a"),fmr=o("FlaubertWithLMHeadModel"),gmr=o(" (FlauBERT model)"),hmr=l(),mT=a("li"),q4e=a("strong"),umr=o("fnet"),pmr=o(" \u2014 "),aY=a("a"),_mr=o("FNetForMaskedLM"),bmr=o(" (FNet model)"),vmr=l(),cT=a("li"),D4e=a("strong"),Fmr=o("funnel"),Tmr=o(" \u2014 "),nY=a("a"),Mmr=o("FunnelForMaskedLM"),Emr=o(" (Funnel Transformer model)"),Cmr=l(),fT=a("li"),j4e=a("strong"),wmr=o("ibert"),Amr=o(" \u2014 "),sY=a("a"),Lmr=o("IBertForMaskedLM"),ymr=o(" (I-BERT model)"),xmr=l(),gT=a("li"),G4e=a("strong"),$mr=o("layoutlm"),kmr=o(" \u2014 "),lY=a("a"),Smr=o("LayoutLMForMaskedLM"),Rmr=o(" (LayoutLM model)"),Pmr=l(),hT=a("li"),O4e=a("strong"),Bmr=o("longformer"),Imr=o(" \u2014 "),iY=a("a"),Nmr=o("LongformerForMaskedLM"),qmr=o(" (Longformer model)"),Dmr=l(),uT=a("li"),V4e=a("strong"),jmr=o("luke"),Gmr=o(" \u2014 "),dY=a("a"),Omr=o("LukeForMaskedLM"),Vmr=o(" (LUKE model)"),Xmr=l(),pT=a("li"),X4e=a("strong"),zmr=o("mbart"),Qmr=o(" \u2014 "),mY=a("a"),Wmr=o("MBartForConditionalGeneration"),Umr=o(" (mBART model)"),Hmr=l(),_T=a("li"),z4e=a("strong"),Jmr=o("megatron-bert"),Ymr=o(" \u2014 "),cY=a("a"),Zmr=o("MegatronBertForMaskedLM"),Kmr=o(" (Megatron-BERT model)"),ecr=l(),bT=a("li"),Q4e=a("strong"),ocr=o("mobilebert"),rcr=o(" \u2014 "),fY=a("a"),tcr=o("MobileBertForMaskedLM"),acr=o(" (MobileBERT model)"),ncr=l(),vT=a("li"),W4e=a("strong"),scr=o("mpnet"),lcr=o(" \u2014 "),gY=a("a"),icr=o("MPNetForMaskedLM"),dcr=o(" (MPNet model)"),mcr=l(),FT=a("li"),U4e=a("strong"),ccr=o("mvp"),fcr=o(" \u2014 "),hY=a("a"),gcr=o("MvpForConditionalGeneration"),hcr=o(" (MVP model)"),ucr=l(),TT=a("li"),H4e=a("strong"),pcr=o("nezha"),_cr=o(" \u2014 "),uY=a("a"),bcr=o("NezhaForMaskedLM"),vcr=o(" (Nezha model)"),Fcr=l(),MT=a("li"),J4e=a("strong"),Tcr=o("nystromformer"),Mcr=o(" \u2014 "),pY=a("a"),Ecr=o("NystromformerForMaskedLM"),Ccr=o(" (Nystr\xF6mformer model)"),wcr=l(),ET=a("li"),Y4e=a("strong"),Acr=o("perceiver"),Lcr=o(" \u2014 "),_Y=a("a"),ycr=o("PerceiverForMaskedLM"),xcr=o(" (Perceiver model)"),$cr=l(),CT=a("li"),Z4e=a("strong"),kcr=o("qdqbert"),Scr=o(" \u2014 "),bY=a("a"),Rcr=o("QDQBertForMaskedLM"),Pcr=o(" (QDQBert model)"),Bcr=l(),wT=a("li"),K4e=a("strong"),Icr=o("reformer"),Ncr=o(" \u2014 "),vY=a("a"),qcr=o("ReformerForMaskedLM"),Dcr=o(" (Reformer model)"),jcr=l(),AT=a("li"),eCe=a("strong"),Gcr=o("rembert"),Ocr=o(" \u2014 "),FY=a("a"),Vcr=o("RemBertForMaskedLM"),Xcr=o(" (RemBERT model)"),zcr=l(),LT=a("li"),oCe=a("strong"),Qcr=o("roberta"),Wcr=o(" \u2014 "),TY=a("a"),Ucr=o("RobertaForMaskedLM"),Hcr=o(" (RoBERTa model)"),Jcr=l(),yT=a("li"),rCe=a("strong"),Ycr=o("roc_bert"),Zcr=o(" \u2014 "),MY=a("a"),Kcr=o("RoCBertForMaskedLM"),efr=o(" (RoCBert model)"),ofr=l(),xT=a("li"),tCe=a("strong"),rfr=o("roformer"),tfr=o(" \u2014 "),EY=a("a"),afr=o("RoFormerForMaskedLM"),nfr=o(" (RoFormer model)"),sfr=l(),$T=a("li"),aCe=a("strong"),lfr=o("squeezebert"),ifr=o(" \u2014 "),CY=a("a"),dfr=o("SqueezeBertForMaskedLM"),mfr=o(" (SqueezeBERT model)"),cfr=l(),kT=a("li"),nCe=a("strong"),ffr=o("tapas"),gfr=o(" \u2014 "),wY=a("a"),hfr=o("TapasForMaskedLM"),ufr=o(" (TAPAS model)"),pfr=l(),ST=a("li"),sCe=a("strong"),_fr=o("wav2vec2"),bfr=o(" \u2014 "),lCe=a("code"),vfr=o("Wav2Vec2ForMaskedLM"),Ffr=o(" (Wav2Vec2 model)"),Tfr=l(),RT=a("li"),iCe=a("strong"),Mfr=o("xlm"),Efr=o(" \u2014 "),AY=a("a"),Cfr=o("XLMWithLMHeadModel"),wfr=o(" (XLM model)"),Afr=l(),PT=a("li"),dCe=a("strong"),Lfr=o("xlm-roberta"),yfr=o(" \u2014 "),LY=a("a"),xfr=o("XLMRobertaForMaskedLM"),$fr=o(" (XLM-RoBERTa model)"),kfr=l(),BT=a("li"),mCe=a("strong"),Sfr=o("xlm-roberta-xl"),Rfr=o(" \u2014 "),yY=a("a"),Pfr=o("XLMRobertaXLForMaskedLM"),Bfr=o(" (XLM-RoBERTa-XL model)"),Ifr=l(),IT=a("li"),cCe=a("strong"),Nfr=o("yoso"),qfr=o(" \u2014 "),xY=a("a"),Dfr=o("YosoForMaskedLM"),jfr=o(" (YOSO model)"),Gfr=l(),NT=a("p"),Ofr=o("The model is set in evaluation mode by default using "),fCe=a("code"),Vfr=o("model.eval()"),Xfr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gCe=a("code"),zfr=o("model.train()"),Qfr=l(),F(qT.$$.fragment),Glo=l(),rm=a("h2"),DT=a("a"),hCe=a("span"),F(pS.$$.fragment),Wfr=l(),uCe=a("span"),Ufr=o("AutoModelForSeq2SeqLM"),Olo=l(),zo=a("div"),F(_S.$$.fragment),Hfr=l(),tm=a("p"),Jfr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),$Y=a("a"),Yfr=o("from_pretrained()"),Zfr=o(" class method or the "),kY=a("a"),Kfr=o("from_config()"),egr=o(` class
method.`),ogr=l(),bS=a("p"),rgr=o("This class cannot be instantiated directly using "),pCe=a("code"),tgr=o("__init__()"),agr=o(" (throws an error)."),ngr=l(),kt=a("div"),F(vS.$$.fragment),sgr=l(),_Ce=a("p"),lgr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),igr=l(),am=a("p"),dgr=o(`Note:
Loading a model from its configuration file does `),bCe=a("strong"),mgr=o("not"),cgr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SY=a("a"),fgr=o("from_pretrained()"),ggr=o(" to load the model weights."),hgr=l(),F(jT.$$.fragment),ugr=l(),io=a("div"),F(FS.$$.fragment),pgr=l(),vCe=a("p"),_gr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),bgr=l(),_n=a("p"),vgr=o("The model class to instantiate is selected based on the "),FCe=a("code"),Fgr=o("model_type"),Tgr=o(` property of the config object (either
passed as an argument or loaded from `),TCe=a("code"),Mgr=o("pretrained_model_name_or_path"),Egr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MCe=a("code"),Cgr=o("pretrained_model_name_or_path"),wgr=o(":"),Agr=l(),pe=a("ul"),GT=a("li"),ECe=a("strong"),Lgr=o("bart"),ygr=o(" \u2014 "),RY=a("a"),xgr=o("BartForConditionalGeneration"),$gr=o(" (BART model)"),kgr=l(),OT=a("li"),CCe=a("strong"),Sgr=o("bigbird_pegasus"),Rgr=o(" \u2014 "),PY=a("a"),Pgr=o("BigBirdPegasusForConditionalGeneration"),Bgr=o(" (BigBird-Pegasus model)"),Igr=l(),VT=a("li"),wCe=a("strong"),Ngr=o("blenderbot"),qgr=o(" \u2014 "),BY=a("a"),Dgr=o("BlenderbotForConditionalGeneration"),jgr=o(" (Blenderbot model)"),Ggr=l(),XT=a("li"),ACe=a("strong"),Ogr=o("blenderbot-small"),Vgr=o(" \u2014 "),IY=a("a"),Xgr=o("BlenderbotSmallForConditionalGeneration"),zgr=o(" (BlenderbotSmall model)"),Qgr=l(),zT=a("li"),LCe=a("strong"),Wgr=o("encoder-decoder"),Ugr=o(" \u2014 "),NY=a("a"),Hgr=o("EncoderDecoderModel"),Jgr=o(" (Encoder decoder model)"),Ygr=l(),QT=a("li"),yCe=a("strong"),Zgr=o("fsmt"),Kgr=o(" \u2014 "),qY=a("a"),ehr=o("FSMTForConditionalGeneration"),ohr=o(" (FairSeq Machine-Translation model)"),rhr=l(),WT=a("li"),xCe=a("strong"),thr=o("led"),ahr=o(" \u2014 "),DY=a("a"),nhr=o("LEDForConditionalGeneration"),shr=o(" (LED model)"),lhr=l(),UT=a("li"),$Ce=a("strong"),ihr=o("longt5"),dhr=o(" \u2014 "),jY=a("a"),mhr=o("LongT5ForConditionalGeneration"),chr=o(" (LongT5 model)"),fhr=l(),HT=a("li"),kCe=a("strong"),ghr=o("m2m_100"),hhr=o(" \u2014 "),GY=a("a"),uhr=o("M2M100ForConditionalGeneration"),phr=o(" (M2M100 model)"),_hr=l(),JT=a("li"),SCe=a("strong"),bhr=o("marian"),vhr=o(" \u2014 "),OY=a("a"),Fhr=o("MarianMTModel"),Thr=o(" (Marian model)"),Mhr=l(),YT=a("li"),RCe=a("strong"),Ehr=o("mbart"),Chr=o(" \u2014 "),VY=a("a"),whr=o("MBartForConditionalGeneration"),Ahr=o(" (mBART model)"),Lhr=l(),ZT=a("li"),PCe=a("strong"),yhr=o("mt5"),xhr=o(" \u2014 "),XY=a("a"),$hr=o("MT5ForConditionalGeneration"),khr=o(" (MT5 model)"),Shr=l(),KT=a("li"),BCe=a("strong"),Rhr=o("mvp"),Phr=o(" \u2014 "),zY=a("a"),Bhr=o("MvpForConditionalGeneration"),Ihr=o(" (MVP model)"),Nhr=l(),eM=a("li"),ICe=a("strong"),qhr=o("nllb"),Dhr=o(" \u2014 "),QY=a("a"),jhr=o("M2M100ForConditionalGeneration"),Ghr=o(" (NLLB model)"),Ohr=l(),oM=a("li"),NCe=a("strong"),Vhr=o("pegasus"),Xhr=o(" \u2014 "),WY=a("a"),zhr=o("PegasusForConditionalGeneration"),Qhr=o(" (Pegasus model)"),Whr=l(),rM=a("li"),qCe=a("strong"),Uhr=o("pegasus_x"),Hhr=o(" \u2014 "),UY=a("a"),Jhr=o("PegasusXForConditionalGeneration"),Yhr=o(" (PEGASUS-X model)"),Zhr=l(),tM=a("li"),DCe=a("strong"),Khr=o("plbart"),eur=o(" \u2014 "),HY=a("a"),our=o("PLBartForConditionalGeneration"),rur=o(" (PLBart model)"),tur=l(),aM=a("li"),jCe=a("strong"),aur=o("prophetnet"),nur=o(" \u2014 "),JY=a("a"),sur=o("ProphetNetForConditionalGeneration"),lur=o(" (ProphetNet model)"),iur=l(),nM=a("li"),GCe=a("strong"),dur=o("t5"),mur=o(" \u2014 "),YY=a("a"),cur=o("T5ForConditionalGeneration"),fur=o(" (T5 model)"),gur=l(),sM=a("li"),OCe=a("strong"),hur=o("xlm-prophetnet"),uur=o(" \u2014 "),ZY=a("a"),pur=o("XLMProphetNetForConditionalGeneration"),_ur=o(" (XLM-ProphetNet model)"),bur=l(),lM=a("p"),vur=o("The model is set in evaluation mode by default using "),VCe=a("code"),Fur=o("model.eval()"),Tur=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),XCe=a("code"),Mur=o("model.train()"),Eur=l(),F(iM.$$.fragment),Vlo=l(),nm=a("h2"),dM=a("a"),zCe=a("span"),F(TS.$$.fragment),Cur=l(),QCe=a("span"),wur=o("AutoModelForSequenceClassification"),Xlo=l(),Qo=a("div"),F(MS.$$.fragment),Aur=l(),sm=a("p"),Lur=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),KY=a("a"),yur=o("from_pretrained()"),xur=o(" class method or the "),eZ=a("a"),$ur=o("from_config()"),kur=o(` class
method.`),Sur=l(),ES=a("p"),Rur=o("This class cannot be instantiated directly using "),WCe=a("code"),Pur=o("__init__()"),Bur=o(" (throws an error)."),Iur=l(),St=a("div"),F(CS.$$.fragment),Nur=l(),UCe=a("p"),qur=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Dur=l(),lm=a("p"),jur=o(`Note:
Loading a model from its configuration file does `),HCe=a("strong"),Gur=o("not"),Our=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oZ=a("a"),Vur=o("from_pretrained()"),Xur=o(" to load the model weights."),zur=l(),F(mM.$$.fragment),Qur=l(),mo=a("div"),F(wS.$$.fragment),Wur=l(),JCe=a("p"),Uur=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Hur=l(),bn=a("p"),Jur=o("The model class to instantiate is selected based on the "),YCe=a("code"),Yur=o("model_type"),Zur=o(` property of the config object (either
passed as an argument or loaded from `),ZCe=a("code"),Kur=o("pretrained_model_name_or_path"),epr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KCe=a("code"),opr=o("pretrained_model_name_or_path"),rpr=o(":"),tpr=l(),I=a("ul"),cM=a("li"),e3e=a("strong"),apr=o("albert"),npr=o(" \u2014 "),rZ=a("a"),spr=o("AlbertForSequenceClassification"),lpr=o(" (ALBERT model)"),ipr=l(),fM=a("li"),o3e=a("strong"),dpr=o("bart"),mpr=o(" \u2014 "),tZ=a("a"),cpr=o("BartForSequenceClassification"),fpr=o(" (BART model)"),gpr=l(),gM=a("li"),r3e=a("strong"),hpr=o("bert"),upr=o(" \u2014 "),aZ=a("a"),ppr=o("BertForSequenceClassification"),_pr=o(" (BERT model)"),bpr=l(),hM=a("li"),t3e=a("strong"),vpr=o("big_bird"),Fpr=o(" \u2014 "),nZ=a("a"),Tpr=o("BigBirdForSequenceClassification"),Mpr=o(" (BigBird model)"),Epr=l(),uM=a("li"),a3e=a("strong"),Cpr=o("bigbird_pegasus"),wpr=o(" \u2014 "),sZ=a("a"),Apr=o("BigBirdPegasusForSequenceClassification"),Lpr=o(" (BigBird-Pegasus model)"),ypr=l(),pM=a("li"),n3e=a("strong"),xpr=o("bloom"),$pr=o(" \u2014 "),lZ=a("a"),kpr=o("BloomForSequenceClassification"),Spr=o(" (BLOOM model)"),Rpr=l(),_M=a("li"),s3e=a("strong"),Ppr=o("camembert"),Bpr=o(" \u2014 "),iZ=a("a"),Ipr=o("CamembertForSequenceClassification"),Npr=o(" (CamemBERT model)"),qpr=l(),bM=a("li"),l3e=a("strong"),Dpr=o("canine"),jpr=o(" \u2014 "),dZ=a("a"),Gpr=o("CanineForSequenceClassification"),Opr=o(" (CANINE model)"),Vpr=l(),vM=a("li"),i3e=a("strong"),Xpr=o("convbert"),zpr=o(" \u2014 "),mZ=a("a"),Qpr=o("ConvBertForSequenceClassification"),Wpr=o(" (ConvBERT model)"),Upr=l(),FM=a("li"),d3e=a("strong"),Hpr=o("ctrl"),Jpr=o(" \u2014 "),cZ=a("a"),Ypr=o("CTRLForSequenceClassification"),Zpr=o(" (CTRL model)"),Kpr=l(),TM=a("li"),m3e=a("strong"),e_r=o("data2vec-text"),o_r=o(" \u2014 "),fZ=a("a"),r_r=o("Data2VecTextForSequenceClassification"),t_r=o(" (Data2VecText model)"),a_r=l(),MM=a("li"),c3e=a("strong"),n_r=o("deberta"),s_r=o(" \u2014 "),gZ=a("a"),l_r=o("DebertaForSequenceClassification"),i_r=o(" (DeBERTa model)"),d_r=l(),EM=a("li"),f3e=a("strong"),m_r=o("deberta-v2"),c_r=o(" \u2014 "),hZ=a("a"),f_r=o("DebertaV2ForSequenceClassification"),g_r=o(" (DeBERTa-v2 model)"),h_r=l(),CM=a("li"),g3e=a("strong"),u_r=o("distilbert"),p_r=o(" \u2014 "),uZ=a("a"),__r=o("DistilBertForSequenceClassification"),b_r=o(" (DistilBERT model)"),v_r=l(),wM=a("li"),h3e=a("strong"),F_r=o("electra"),T_r=o(" \u2014 "),pZ=a("a"),M_r=o("ElectraForSequenceClassification"),E_r=o(" (ELECTRA model)"),C_r=l(),AM=a("li"),u3e=a("strong"),w_r=o("ernie"),A_r=o(" \u2014 "),_Z=a("a"),L_r=o("ErnieForSequenceClassification"),y_r=o(" (ERNIE model)"),x_r=l(),LM=a("li"),p3e=a("strong"),$_r=o("esm"),k_r=o(" \u2014 "),bZ=a("a"),S_r=o("EsmForSequenceClassification"),R_r=o(" (ESM model)"),P_r=l(),yM=a("li"),_3e=a("strong"),B_r=o("flaubert"),I_r=o(" \u2014 "),vZ=a("a"),N_r=o("FlaubertForSequenceClassification"),q_r=o(" (FlauBERT model)"),D_r=l(),xM=a("li"),b3e=a("strong"),j_r=o("fnet"),G_r=o(" \u2014 "),FZ=a("a"),O_r=o("FNetForSequenceClassification"),V_r=o(" (FNet model)"),X_r=l(),$M=a("li"),v3e=a("strong"),z_r=o("funnel"),Q_r=o(" \u2014 "),TZ=a("a"),W_r=o("FunnelForSequenceClassification"),U_r=o(" (Funnel Transformer model)"),H_r=l(),kM=a("li"),F3e=a("strong"),J_r=o("gpt2"),Y_r=o(" \u2014 "),MZ=a("a"),Z_r=o("GPT2ForSequenceClassification"),K_r=o(" (OpenAI GPT-2 model)"),e1r=l(),SM=a("li"),T3e=a("strong"),o1r=o("gpt_neo"),r1r=o(" \u2014 "),EZ=a("a"),t1r=o("GPTNeoForSequenceClassification"),a1r=o(" (GPT Neo model)"),n1r=l(),RM=a("li"),M3e=a("strong"),s1r=o("gptj"),l1r=o(" \u2014 "),CZ=a("a"),i1r=o("GPTJForSequenceClassification"),d1r=o(" (GPT-J model)"),m1r=l(),PM=a("li"),E3e=a("strong"),c1r=o("ibert"),f1r=o(" \u2014 "),wZ=a("a"),g1r=o("IBertForSequenceClassification"),h1r=o(" (I-BERT model)"),u1r=l(),BM=a("li"),C3e=a("strong"),p1r=o("layoutlm"),_1r=o(" \u2014 "),AZ=a("a"),b1r=o("LayoutLMForSequenceClassification"),v1r=o(" (LayoutLM model)"),F1r=l(),IM=a("li"),w3e=a("strong"),T1r=o("layoutlmv2"),M1r=o(" \u2014 "),LZ=a("a"),E1r=o("LayoutLMv2ForSequenceClassification"),C1r=o(" (LayoutLMv2 model)"),w1r=l(),NM=a("li"),A3e=a("strong"),A1r=o("layoutlmv3"),L1r=o(" \u2014 "),yZ=a("a"),y1r=o("LayoutLMv3ForSequenceClassification"),x1r=o(" (LayoutLMv3 model)"),$1r=l(),qM=a("li"),L3e=a("strong"),k1r=o("led"),S1r=o(" \u2014 "),xZ=a("a"),R1r=o("LEDForSequenceClassification"),P1r=o(" (LED model)"),B1r=l(),DM=a("li"),y3e=a("strong"),I1r=o("lilt"),N1r=o(" \u2014 "),$Z=a("a"),q1r=o("LiltForSequenceClassification"),D1r=o(" (LiLT model)"),j1r=l(),jM=a("li"),x3e=a("strong"),G1r=o("longformer"),O1r=o(" \u2014 "),kZ=a("a"),V1r=o("LongformerForSequenceClassification"),X1r=o(" (Longformer model)"),z1r=l(),GM=a("li"),$3e=a("strong"),Q1r=o("luke"),W1r=o(" \u2014 "),SZ=a("a"),U1r=o("LukeForSequenceClassification"),H1r=o(" (LUKE model)"),J1r=l(),OM=a("li"),k3e=a("strong"),Y1r=o("markuplm"),Z1r=o(" \u2014 "),RZ=a("a"),K1r=o("MarkupLMForSequenceClassification"),e2r=o(" (MarkupLM model)"),o2r=l(),VM=a("li"),S3e=a("strong"),r2r=o("mbart"),t2r=o(" \u2014 "),PZ=a("a"),a2r=o("MBartForSequenceClassification"),n2r=o(" (mBART model)"),s2r=l(),XM=a("li"),R3e=a("strong"),l2r=o("megatron-bert"),i2r=o(" \u2014 "),BZ=a("a"),d2r=o("MegatronBertForSequenceClassification"),m2r=o(" (Megatron-BERT model)"),c2r=l(),zM=a("li"),P3e=a("strong"),f2r=o("mobilebert"),g2r=o(" \u2014 "),IZ=a("a"),h2r=o("MobileBertForSequenceClassification"),u2r=o(" (MobileBERT model)"),p2r=l(),QM=a("li"),B3e=a("strong"),_2r=o("mpnet"),b2r=o(" \u2014 "),NZ=a("a"),v2r=o("MPNetForSequenceClassification"),F2r=o(" (MPNet model)"),T2r=l(),WM=a("li"),I3e=a("strong"),M2r=o("mvp"),E2r=o(" \u2014 "),qZ=a("a"),C2r=o("MvpForSequenceClassification"),w2r=o(" (MVP model)"),A2r=l(),UM=a("li"),N3e=a("strong"),L2r=o("nezha"),y2r=o(" \u2014 "),DZ=a("a"),x2r=o("NezhaForSequenceClassification"),$2r=o(" (Nezha model)"),k2r=l(),HM=a("li"),q3e=a("strong"),S2r=o("nystromformer"),R2r=o(" \u2014 "),jZ=a("a"),P2r=o("NystromformerForSequenceClassification"),B2r=o(" (Nystr\xF6mformer model)"),I2r=l(),JM=a("li"),D3e=a("strong"),N2r=o("openai-gpt"),q2r=o(" \u2014 "),GZ=a("a"),D2r=o("OpenAIGPTForSequenceClassification"),j2r=o(" (OpenAI GPT model)"),G2r=l(),YM=a("li"),j3e=a("strong"),O2r=o("opt"),V2r=o(" \u2014 "),OZ=a("a"),X2r=o("OPTForSequenceClassification"),z2r=o(" (OPT model)"),Q2r=l(),ZM=a("li"),G3e=a("strong"),W2r=o("perceiver"),U2r=o(" \u2014 "),VZ=a("a"),H2r=o("PerceiverForSequenceClassification"),J2r=o(" (Perceiver model)"),Y2r=l(),KM=a("li"),O3e=a("strong"),Z2r=o("plbart"),K2r=o(" \u2014 "),XZ=a("a"),ebr=o("PLBartForSequenceClassification"),obr=o(" (PLBart model)"),rbr=l(),eE=a("li"),V3e=a("strong"),tbr=o("qdqbert"),abr=o(" \u2014 "),zZ=a("a"),nbr=o("QDQBertForSequenceClassification"),sbr=o(" (QDQBert model)"),lbr=l(),oE=a("li"),X3e=a("strong"),ibr=o("reformer"),dbr=o(" \u2014 "),QZ=a("a"),mbr=o("ReformerForSequenceClassification"),cbr=o(" (Reformer model)"),fbr=l(),rE=a("li"),z3e=a("strong"),gbr=o("rembert"),hbr=o(" \u2014 "),WZ=a("a"),ubr=o("RemBertForSequenceClassification"),pbr=o(" (RemBERT model)"),_br=l(),tE=a("li"),Q3e=a("strong"),bbr=o("roberta"),vbr=o(" \u2014 "),UZ=a("a"),Fbr=o("RobertaForSequenceClassification"),Tbr=o(" (RoBERTa model)"),Mbr=l(),aE=a("li"),W3e=a("strong"),Ebr=o("roc_bert"),Cbr=o(" \u2014 "),HZ=a("a"),wbr=o("RoCBertForSequenceClassification"),Abr=o(" (RoCBert model)"),Lbr=l(),nE=a("li"),U3e=a("strong"),ybr=o("roformer"),xbr=o(" \u2014 "),JZ=a("a"),$br=o("RoFormerForSequenceClassification"),kbr=o(" (RoFormer model)"),Sbr=l(),sE=a("li"),H3e=a("strong"),Rbr=o("squeezebert"),Pbr=o(" \u2014 "),YZ=a("a"),Bbr=o("SqueezeBertForSequenceClassification"),Ibr=o(" (SqueezeBERT model)"),Nbr=l(),lE=a("li"),J3e=a("strong"),qbr=o("tapas"),Dbr=o(" \u2014 "),ZZ=a("a"),jbr=o("TapasForSequenceClassification"),Gbr=o(" (TAPAS model)"),Obr=l(),iE=a("li"),Y3e=a("strong"),Vbr=o("transfo-xl"),Xbr=o(" \u2014 "),KZ=a("a"),zbr=o("TransfoXLForSequenceClassification"),Qbr=o(" (Transformer-XL model)"),Wbr=l(),dE=a("li"),Z3e=a("strong"),Ubr=o("xlm"),Hbr=o(" \u2014 "),eK=a("a"),Jbr=o("XLMForSequenceClassification"),Ybr=o(" (XLM model)"),Zbr=l(),mE=a("li"),K3e=a("strong"),Kbr=o("xlm-roberta"),evr=o(" \u2014 "),oK=a("a"),ovr=o("XLMRobertaForSequenceClassification"),rvr=o(" (XLM-RoBERTa model)"),tvr=l(),cE=a("li"),e5e=a("strong"),avr=o("xlm-roberta-xl"),nvr=o(" \u2014 "),rK=a("a"),svr=o("XLMRobertaXLForSequenceClassification"),lvr=o(" (XLM-RoBERTa-XL model)"),ivr=l(),fE=a("li"),o5e=a("strong"),dvr=o("xlnet"),mvr=o(" \u2014 "),tK=a("a"),cvr=o("XLNetForSequenceClassification"),fvr=o(" (XLNet model)"),gvr=l(),gE=a("li"),r5e=a("strong"),hvr=o("yoso"),uvr=o(" \u2014 "),aK=a("a"),pvr=o("YosoForSequenceClassification"),_vr=o(" (YOSO model)"),bvr=l(),hE=a("p"),vvr=o("The model is set in evaluation mode by default using "),t5e=a("code"),Fvr=o("model.eval()"),Tvr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),a5e=a("code"),Mvr=o("model.train()"),Evr=l(),F(uE.$$.fragment),zlo=l(),im=a("h2"),pE=a("a"),n5e=a("span"),F(AS.$$.fragment),Cvr=l(),s5e=a("span"),wvr=o("AutoModelForMultipleChoice"),Qlo=l(),Wo=a("div"),F(LS.$$.fragment),Avr=l(),dm=a("p"),Lvr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),nK=a("a"),yvr=o("from_pretrained()"),xvr=o(" class method or the "),sK=a("a"),$vr=o("from_config()"),kvr=o(` class
method.`),Svr=l(),yS=a("p"),Rvr=o("This class cannot be instantiated directly using "),l5e=a("code"),Pvr=o("__init__()"),Bvr=o(" (throws an error)."),Ivr=l(),Rt=a("div"),F(xS.$$.fragment),Nvr=l(),i5e=a("p"),qvr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Dvr=l(),mm=a("p"),jvr=o(`Note:
Loading a model from its configuration file does `),d5e=a("strong"),Gvr=o("not"),Ovr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lK=a("a"),Vvr=o("from_pretrained()"),Xvr=o(" to load the model weights."),zvr=l(),F(_E.$$.fragment),Qvr=l(),co=a("div"),F($S.$$.fragment),Wvr=l(),m5e=a("p"),Uvr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Hvr=l(),vn=a("p"),Jvr=o("The model class to instantiate is selected based on the "),c5e=a("code"),Yvr=o("model_type"),Zvr=o(` property of the config object (either
passed as an argument or loaded from `),f5e=a("code"),Kvr=o("pretrained_model_name_or_path"),eFr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),g5e=a("code"),oFr=o("pretrained_model_name_or_path"),rFr=o(":"),tFr=l(),K=a("ul"),bE=a("li"),h5e=a("strong"),aFr=o("albert"),nFr=o(" \u2014 "),iK=a("a"),sFr=o("AlbertForMultipleChoice"),lFr=o(" (ALBERT model)"),iFr=l(),vE=a("li"),u5e=a("strong"),dFr=o("bert"),mFr=o(" \u2014 "),dK=a("a"),cFr=o("BertForMultipleChoice"),fFr=o(" (BERT model)"),gFr=l(),FE=a("li"),p5e=a("strong"),hFr=o("big_bird"),uFr=o(" \u2014 "),mK=a("a"),pFr=o("BigBirdForMultipleChoice"),_Fr=o(" (BigBird model)"),bFr=l(),TE=a("li"),_5e=a("strong"),vFr=o("camembert"),FFr=o(" \u2014 "),cK=a("a"),TFr=o("CamembertForMultipleChoice"),MFr=o(" (CamemBERT model)"),EFr=l(),ME=a("li"),b5e=a("strong"),CFr=o("canine"),wFr=o(" \u2014 "),fK=a("a"),AFr=o("CanineForMultipleChoice"),LFr=o(" (CANINE model)"),yFr=l(),EE=a("li"),v5e=a("strong"),xFr=o("convbert"),$Fr=o(" \u2014 "),gK=a("a"),kFr=o("ConvBertForMultipleChoice"),SFr=o(" (ConvBERT model)"),RFr=l(),CE=a("li"),F5e=a("strong"),PFr=o("data2vec-text"),BFr=o(" \u2014 "),hK=a("a"),IFr=o("Data2VecTextForMultipleChoice"),NFr=o(" (Data2VecText model)"),qFr=l(),wE=a("li"),T5e=a("strong"),DFr=o("deberta-v2"),jFr=o(" \u2014 "),uK=a("a"),GFr=o("DebertaV2ForMultipleChoice"),OFr=o(" (DeBERTa-v2 model)"),VFr=l(),AE=a("li"),M5e=a("strong"),XFr=o("distilbert"),zFr=o(" \u2014 "),pK=a("a"),QFr=o("DistilBertForMultipleChoice"),WFr=o(" (DistilBERT model)"),UFr=l(),LE=a("li"),E5e=a("strong"),HFr=o("electra"),JFr=o(" \u2014 "),_K=a("a"),YFr=o("ElectraForMultipleChoice"),ZFr=o(" (ELECTRA model)"),KFr=l(),yE=a("li"),C5e=a("strong"),eTr=o("ernie"),oTr=o(" \u2014 "),bK=a("a"),rTr=o("ErnieForMultipleChoice"),tTr=o(" (ERNIE model)"),aTr=l(),xE=a("li"),w5e=a("strong"),nTr=o("flaubert"),sTr=o(" \u2014 "),vK=a("a"),lTr=o("FlaubertForMultipleChoice"),iTr=o(" (FlauBERT model)"),dTr=l(),$E=a("li"),A5e=a("strong"),mTr=o("fnet"),cTr=o(" \u2014 "),FK=a("a"),fTr=o("FNetForMultipleChoice"),gTr=o(" (FNet model)"),hTr=l(),kE=a("li"),L5e=a("strong"),uTr=o("funnel"),pTr=o(" \u2014 "),TK=a("a"),_Tr=o("FunnelForMultipleChoice"),bTr=o(" (Funnel Transformer model)"),vTr=l(),SE=a("li"),y5e=a("strong"),FTr=o("ibert"),TTr=o(" \u2014 "),MK=a("a"),MTr=o("IBertForMultipleChoice"),ETr=o(" (I-BERT model)"),CTr=l(),RE=a("li"),x5e=a("strong"),wTr=o("longformer"),ATr=o(" \u2014 "),EK=a("a"),LTr=o("LongformerForMultipleChoice"),yTr=o(" (Longformer model)"),xTr=l(),PE=a("li"),$5e=a("strong"),$Tr=o("luke"),kTr=o(" \u2014 "),CK=a("a"),STr=o("LukeForMultipleChoice"),RTr=o(" (LUKE model)"),PTr=l(),BE=a("li"),k5e=a("strong"),BTr=o("megatron-bert"),ITr=o(" \u2014 "),wK=a("a"),NTr=o("MegatronBertForMultipleChoice"),qTr=o(" (Megatron-BERT model)"),DTr=l(),IE=a("li"),S5e=a("strong"),jTr=o("mobilebert"),GTr=o(" \u2014 "),AK=a("a"),OTr=o("MobileBertForMultipleChoice"),VTr=o(" (MobileBERT model)"),XTr=l(),NE=a("li"),R5e=a("strong"),zTr=o("mpnet"),QTr=o(" \u2014 "),LK=a("a"),WTr=o("MPNetForMultipleChoice"),UTr=o(" (MPNet model)"),HTr=l(),qE=a("li"),P5e=a("strong"),JTr=o("nezha"),YTr=o(" \u2014 "),yK=a("a"),ZTr=o("NezhaForMultipleChoice"),KTr=o(" (Nezha model)"),eMr=l(),DE=a("li"),B5e=a("strong"),oMr=o("nystromformer"),rMr=o(" \u2014 "),xK=a("a"),tMr=o("NystromformerForMultipleChoice"),aMr=o(" (Nystr\xF6mformer model)"),nMr=l(),jE=a("li"),I5e=a("strong"),sMr=o("qdqbert"),lMr=o(" \u2014 "),$K=a("a"),iMr=o("QDQBertForMultipleChoice"),dMr=o(" (QDQBert model)"),mMr=l(),GE=a("li"),N5e=a("strong"),cMr=o("rembert"),fMr=o(" \u2014 "),kK=a("a"),gMr=o("RemBertForMultipleChoice"),hMr=o(" (RemBERT model)"),uMr=l(),OE=a("li"),q5e=a("strong"),pMr=o("roberta"),_Mr=o(" \u2014 "),SK=a("a"),bMr=o("RobertaForMultipleChoice"),vMr=o(" (RoBERTa model)"),FMr=l(),VE=a("li"),D5e=a("strong"),TMr=o("roc_bert"),MMr=o(" \u2014 "),RK=a("a"),EMr=o("RoCBertForMultipleChoice"),CMr=o(" (RoCBert model)"),wMr=l(),XE=a("li"),j5e=a("strong"),AMr=o("roformer"),LMr=o(" \u2014 "),PK=a("a"),yMr=o("RoFormerForMultipleChoice"),xMr=o(" (RoFormer model)"),$Mr=l(),zE=a("li"),G5e=a("strong"),kMr=o("squeezebert"),SMr=o(" \u2014 "),BK=a("a"),RMr=o("SqueezeBertForMultipleChoice"),PMr=o(" (SqueezeBERT model)"),BMr=l(),QE=a("li"),O5e=a("strong"),IMr=o("xlm"),NMr=o(" \u2014 "),IK=a("a"),qMr=o("XLMForMultipleChoice"),DMr=o(" (XLM model)"),jMr=l(),WE=a("li"),V5e=a("strong"),GMr=o("xlm-roberta"),OMr=o(" \u2014 "),NK=a("a"),VMr=o("XLMRobertaForMultipleChoice"),XMr=o(" (XLM-RoBERTa model)"),zMr=l(),UE=a("li"),X5e=a("strong"),QMr=o("xlm-roberta-xl"),WMr=o(" \u2014 "),qK=a("a"),UMr=o("XLMRobertaXLForMultipleChoice"),HMr=o(" (XLM-RoBERTa-XL model)"),JMr=l(),HE=a("li"),z5e=a("strong"),YMr=o("xlnet"),ZMr=o(" \u2014 "),DK=a("a"),KMr=o("XLNetForMultipleChoice"),eEr=o(" (XLNet model)"),oEr=l(),JE=a("li"),Q5e=a("strong"),rEr=o("yoso"),tEr=o(" \u2014 "),jK=a("a"),aEr=o("YosoForMultipleChoice"),nEr=o(" (YOSO model)"),sEr=l(),YE=a("p"),lEr=o("The model is set in evaluation mode by default using "),W5e=a("code"),iEr=o("model.eval()"),dEr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),U5e=a("code"),mEr=o("model.train()"),cEr=l(),F(ZE.$$.fragment),Wlo=l(),cm=a("h2"),KE=a("a"),H5e=a("span"),F(kS.$$.fragment),fEr=l(),J5e=a("span"),gEr=o("AutoModelForNextSentencePrediction"),Ulo=l(),Uo=a("div"),F(SS.$$.fragment),hEr=l(),fm=a("p"),uEr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),GK=a("a"),pEr=o("from_pretrained()"),_Er=o(" class method or the "),OK=a("a"),bEr=o("from_config()"),vEr=o(` class
method.`),FEr=l(),RS=a("p"),TEr=o("This class cannot be instantiated directly using "),Y5e=a("code"),MEr=o("__init__()"),EEr=o(" (throws an error)."),CEr=l(),Pt=a("div"),F(PS.$$.fragment),wEr=l(),Z5e=a("p"),AEr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),LEr=l(),gm=a("p"),yEr=o(`Note:
Loading a model from its configuration file does `),K5e=a("strong"),xEr=o("not"),$Er=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VK=a("a"),kEr=o("from_pretrained()"),SEr=o(" to load the model weights."),REr=l(),F(e4.$$.fragment),PEr=l(),fo=a("div"),F(BS.$$.fragment),BEr=l(),e0e=a("p"),IEr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),NEr=l(),Fn=a("p"),qEr=o("The model class to instantiate is selected based on the "),o0e=a("code"),DEr=o("model_type"),jEr=o(` property of the config object (either
passed as an argument or loaded from `),r0e=a("code"),GEr=o("pretrained_model_name_or_path"),OEr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),t0e=a("code"),VEr=o("pretrained_model_name_or_path"),XEr=o(":"),zEr=l(),Ye=a("ul"),o4=a("li"),a0e=a("strong"),QEr=o("bert"),WEr=o(" \u2014 "),XK=a("a"),UEr=o("BertForNextSentencePrediction"),HEr=o(" (BERT model)"),JEr=l(),r4=a("li"),n0e=a("strong"),YEr=o("ernie"),ZEr=o(" \u2014 "),zK=a("a"),KEr=o("ErnieForNextSentencePrediction"),e4r=o(" (ERNIE model)"),o4r=l(),t4=a("li"),s0e=a("strong"),r4r=o("fnet"),t4r=o(" \u2014 "),QK=a("a"),a4r=o("FNetForNextSentencePrediction"),n4r=o(" (FNet model)"),s4r=l(),a4=a("li"),l0e=a("strong"),l4r=o("megatron-bert"),i4r=o(" \u2014 "),WK=a("a"),d4r=o("MegatronBertForNextSentencePrediction"),m4r=o(" (Megatron-BERT model)"),c4r=l(),n4=a("li"),i0e=a("strong"),f4r=o("mobilebert"),g4r=o(" \u2014 "),UK=a("a"),h4r=o("MobileBertForNextSentencePrediction"),u4r=o(" (MobileBERT model)"),p4r=l(),s4=a("li"),d0e=a("strong"),_4r=o("nezha"),b4r=o(" \u2014 "),HK=a("a"),v4r=o("NezhaForNextSentencePrediction"),F4r=o(" (Nezha model)"),T4r=l(),l4=a("li"),m0e=a("strong"),M4r=o("qdqbert"),E4r=o(" \u2014 "),JK=a("a"),C4r=o("QDQBertForNextSentencePrediction"),w4r=o(" (QDQBert model)"),A4r=l(),i4=a("p"),L4r=o("The model is set in evaluation mode by default using "),c0e=a("code"),y4r=o("model.eval()"),x4r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),f0e=a("code"),$4r=o("model.train()"),k4r=l(),F(d4.$$.fragment),Hlo=l(),hm=a("h2"),m4=a("a"),g0e=a("span"),F(IS.$$.fragment),S4r=l(),h0e=a("span"),R4r=o("AutoModelForTokenClassification"),Jlo=l(),Ho=a("div"),F(NS.$$.fragment),P4r=l(),um=a("p"),B4r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),YK=a("a"),I4r=o("from_pretrained()"),N4r=o(" class method or the "),ZK=a("a"),q4r=o("from_config()"),D4r=o(` class
method.`),j4r=l(),qS=a("p"),G4r=o("This class cannot be instantiated directly using "),u0e=a("code"),O4r=o("__init__()"),V4r=o(" (throws an error)."),X4r=l(),Bt=a("div"),F(DS.$$.fragment),z4r=l(),p0e=a("p"),Q4r=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),W4r=l(),pm=a("p"),U4r=o(`Note:
Loading a model from its configuration file does `),_0e=a("strong"),H4r=o("not"),J4r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),KK=a("a"),Y4r=o("from_pretrained()"),Z4r=o(" to load the model weights."),K4r=l(),F(c4.$$.fragment),eCr=l(),go=a("div"),F(jS.$$.fragment),oCr=l(),b0e=a("p"),rCr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),tCr=l(),Tn=a("p"),aCr=o("The model class to instantiate is selected based on the "),v0e=a("code"),nCr=o("model_type"),sCr=o(` property of the config object (either
passed as an argument or loaded from `),F0e=a("code"),lCr=o("pretrained_model_name_or_path"),iCr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T0e=a("code"),dCr=o("pretrained_model_name_or_path"),mCr=o(":"),cCr=l(),U=a("ul"),f4=a("li"),M0e=a("strong"),fCr=o("albert"),gCr=o(" \u2014 "),eee=a("a"),hCr=o("AlbertForTokenClassification"),uCr=o(" (ALBERT model)"),pCr=l(),g4=a("li"),E0e=a("strong"),_Cr=o("bert"),bCr=o(" \u2014 "),oee=a("a"),vCr=o("BertForTokenClassification"),FCr=o(" (BERT model)"),TCr=l(),h4=a("li"),C0e=a("strong"),MCr=o("big_bird"),ECr=o(" \u2014 "),ree=a("a"),CCr=o("BigBirdForTokenClassification"),wCr=o(" (BigBird model)"),ACr=l(),u4=a("li"),w0e=a("strong"),LCr=o("bloom"),yCr=o(" \u2014 "),tee=a("a"),xCr=o("BloomForTokenClassification"),$Cr=o(" (BLOOM model)"),kCr=l(),p4=a("li"),A0e=a("strong"),SCr=o("camembert"),RCr=o(" \u2014 "),aee=a("a"),PCr=o("CamembertForTokenClassification"),BCr=o(" (CamemBERT model)"),ICr=l(),_4=a("li"),L0e=a("strong"),NCr=o("canine"),qCr=o(" \u2014 "),nee=a("a"),DCr=o("CanineForTokenClassification"),jCr=o(" (CANINE model)"),GCr=l(),b4=a("li"),y0e=a("strong"),OCr=o("convbert"),VCr=o(" \u2014 "),see=a("a"),XCr=o("ConvBertForTokenClassification"),zCr=o(" (ConvBERT model)"),QCr=l(),v4=a("li"),x0e=a("strong"),WCr=o("data2vec-text"),UCr=o(" \u2014 "),lee=a("a"),HCr=o("Data2VecTextForTokenClassification"),JCr=o(" (Data2VecText model)"),YCr=l(),F4=a("li"),$0e=a("strong"),ZCr=o("deberta"),KCr=o(" \u2014 "),iee=a("a"),e3r=o("DebertaForTokenClassification"),o3r=o(" (DeBERTa model)"),r3r=l(),T4=a("li"),k0e=a("strong"),t3r=o("deberta-v2"),a3r=o(" \u2014 "),dee=a("a"),n3r=o("DebertaV2ForTokenClassification"),s3r=o(" (DeBERTa-v2 model)"),l3r=l(),M4=a("li"),S0e=a("strong"),i3r=o("distilbert"),d3r=o(" \u2014 "),mee=a("a"),m3r=o("DistilBertForTokenClassification"),c3r=o(" (DistilBERT model)"),f3r=l(),E4=a("li"),R0e=a("strong"),g3r=o("electra"),h3r=o(" \u2014 "),cee=a("a"),u3r=o("ElectraForTokenClassification"),p3r=o(" (ELECTRA model)"),_3r=l(),C4=a("li"),P0e=a("strong"),b3r=o("ernie"),v3r=o(" \u2014 "),fee=a("a"),F3r=o("ErnieForTokenClassification"),T3r=o(" (ERNIE model)"),M3r=l(),w4=a("li"),B0e=a("strong"),E3r=o("esm"),C3r=o(" \u2014 "),gee=a("a"),w3r=o("EsmForTokenClassification"),A3r=o(" (ESM model)"),L3r=l(),A4=a("li"),I0e=a("strong"),y3r=o("flaubert"),x3r=o(" \u2014 "),hee=a("a"),$3r=o("FlaubertForTokenClassification"),k3r=o(" (FlauBERT model)"),S3r=l(),L4=a("li"),N0e=a("strong"),R3r=o("fnet"),P3r=o(" \u2014 "),uee=a("a"),B3r=o("FNetForTokenClassification"),I3r=o(" (FNet model)"),N3r=l(),y4=a("li"),q0e=a("strong"),q3r=o("funnel"),D3r=o(" \u2014 "),pee=a("a"),j3r=o("FunnelForTokenClassification"),G3r=o(" (Funnel Transformer model)"),O3r=l(),x4=a("li"),D0e=a("strong"),V3r=o("gpt2"),X3r=o(" \u2014 "),_ee=a("a"),z3r=o("GPT2ForTokenClassification"),Q3r=o(" (OpenAI GPT-2 model)"),W3r=l(),$4=a("li"),j0e=a("strong"),U3r=o("ibert"),H3r=o(" \u2014 "),bee=a("a"),J3r=o("IBertForTokenClassification"),Y3r=o(" (I-BERT model)"),Z3r=l(),k4=a("li"),G0e=a("strong"),K3r=o("layoutlm"),e5r=o(" \u2014 "),vee=a("a"),o5r=o("LayoutLMForTokenClassification"),r5r=o(" (LayoutLM model)"),t5r=l(),S4=a("li"),O0e=a("strong"),a5r=o("layoutlmv2"),n5r=o(" \u2014 "),Fee=a("a"),s5r=o("LayoutLMv2ForTokenClassification"),l5r=o(" (LayoutLMv2 model)"),i5r=l(),R4=a("li"),V0e=a("strong"),d5r=o("layoutlmv3"),m5r=o(" \u2014 "),Tee=a("a"),c5r=o("LayoutLMv3ForTokenClassification"),f5r=o(" (LayoutLMv3 model)"),g5r=l(),P4=a("li"),X0e=a("strong"),h5r=o("lilt"),u5r=o(" \u2014 "),Mee=a("a"),p5r=o("LiltForTokenClassification"),_5r=o(" (LiLT model)"),b5r=l(),B4=a("li"),z0e=a("strong"),v5r=o("longformer"),F5r=o(" \u2014 "),Eee=a("a"),T5r=o("LongformerForTokenClassification"),M5r=o(" (Longformer model)"),E5r=l(),I4=a("li"),Q0e=a("strong"),C5r=o("luke"),w5r=o(" \u2014 "),Cee=a("a"),A5r=o("LukeForTokenClassification"),L5r=o(" (LUKE model)"),y5r=l(),N4=a("li"),W0e=a("strong"),x5r=o("markuplm"),$5r=o(" \u2014 "),wee=a("a"),k5r=o("MarkupLMForTokenClassification"),S5r=o(" (MarkupLM model)"),R5r=l(),q4=a("li"),U0e=a("strong"),P5r=o("megatron-bert"),B5r=o(" \u2014 "),Aee=a("a"),I5r=o("MegatronBertForTokenClassification"),N5r=o(" (Megatron-BERT model)"),q5r=l(),D4=a("li"),H0e=a("strong"),D5r=o("mobilebert"),j5r=o(" \u2014 "),Lee=a("a"),G5r=o("MobileBertForTokenClassification"),O5r=o(" (MobileBERT model)"),V5r=l(),j4=a("li"),J0e=a("strong"),X5r=o("mpnet"),z5r=o(" \u2014 "),yee=a("a"),Q5r=o("MPNetForTokenClassification"),W5r=o(" (MPNet model)"),U5r=l(),G4=a("li"),Y0e=a("strong"),H5r=o("nezha"),J5r=o(" \u2014 "),xee=a("a"),Y5r=o("NezhaForTokenClassification"),Z5r=o(" (Nezha model)"),K5r=l(),O4=a("li"),Z0e=a("strong"),e0r=o("nystromformer"),o0r=o(" \u2014 "),$ee=a("a"),r0r=o("NystromformerForTokenClassification"),t0r=o(" (Nystr\xF6mformer model)"),a0r=l(),V4=a("li"),K0e=a("strong"),n0r=o("qdqbert"),s0r=o(" \u2014 "),kee=a("a"),l0r=o("QDQBertForTokenClassification"),i0r=o(" (QDQBert model)"),d0r=l(),X4=a("li"),ewe=a("strong"),m0r=o("rembert"),c0r=o(" \u2014 "),See=a("a"),f0r=o("RemBertForTokenClassification"),g0r=o(" (RemBERT model)"),h0r=l(),z4=a("li"),owe=a("strong"),u0r=o("roberta"),p0r=o(" \u2014 "),Ree=a("a"),_0r=o("RobertaForTokenClassification"),b0r=o(" (RoBERTa model)"),v0r=l(),Q4=a("li"),rwe=a("strong"),F0r=o("roc_bert"),T0r=o(" \u2014 "),Pee=a("a"),M0r=o("RoCBertForTokenClassification"),E0r=o(" (RoCBert model)"),C0r=l(),W4=a("li"),twe=a("strong"),w0r=o("roformer"),A0r=o(" \u2014 "),Bee=a("a"),L0r=o("RoFormerForTokenClassification"),y0r=o(" (RoFormer model)"),x0r=l(),U4=a("li"),awe=a("strong"),$0r=o("squeezebert"),k0r=o(" \u2014 "),Iee=a("a"),S0r=o("SqueezeBertForTokenClassification"),R0r=o(" (SqueezeBERT model)"),P0r=l(),H4=a("li"),nwe=a("strong"),B0r=o("xlm"),I0r=o(" \u2014 "),Nee=a("a"),N0r=o("XLMForTokenClassification"),q0r=o(" (XLM model)"),D0r=l(),J4=a("li"),swe=a("strong"),j0r=o("xlm-roberta"),G0r=o(" \u2014 "),qee=a("a"),O0r=o("XLMRobertaForTokenClassification"),V0r=o(" (XLM-RoBERTa model)"),X0r=l(),Y4=a("li"),lwe=a("strong"),z0r=o("xlm-roberta-xl"),Q0r=o(" \u2014 "),Dee=a("a"),W0r=o("XLMRobertaXLForTokenClassification"),U0r=o(" (XLM-RoBERTa-XL model)"),H0r=l(),Z4=a("li"),iwe=a("strong"),J0r=o("xlnet"),Y0r=o(" \u2014 "),jee=a("a"),Z0r=o("XLNetForTokenClassification"),K0r=o(" (XLNet model)"),ewr=l(),K4=a("li"),dwe=a("strong"),owr=o("yoso"),rwr=o(" \u2014 "),Gee=a("a"),twr=o("YosoForTokenClassification"),awr=o(" (YOSO model)"),nwr=l(),eC=a("p"),swr=o("The model is set in evaluation mode by default using "),mwe=a("code"),lwr=o("model.eval()"),iwr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cwe=a("code"),dwr=o("model.train()"),mwr=l(),F(oC.$$.fragment),Ylo=l(),_m=a("h2"),rC=a("a"),fwe=a("span"),F(GS.$$.fragment),cwr=l(),gwe=a("span"),fwr=o("AutoModelForQuestionAnswering"),Zlo=l(),Jo=a("div"),F(OS.$$.fragment),gwr=l(),bm=a("p"),hwr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Oee=a("a"),uwr=o("from_pretrained()"),pwr=o(" class method or the "),Vee=a("a"),_wr=o("from_config()"),bwr=o(` class
method.`),vwr=l(),VS=a("p"),Fwr=o("This class cannot be instantiated directly using "),hwe=a("code"),Twr=o("__init__()"),Mwr=o(" (throws an error)."),Ewr=l(),It=a("div"),F(XS.$$.fragment),Cwr=l(),uwe=a("p"),wwr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Awr=l(),vm=a("p"),Lwr=o(`Note:
Loading a model from its configuration file does `),pwe=a("strong"),ywr=o("not"),xwr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Xee=a("a"),$wr=o("from_pretrained()"),kwr=o(" to load the model weights."),Swr=l(),F(tC.$$.fragment),Rwr=l(),ho=a("div"),F(zS.$$.fragment),Pwr=l(),_we=a("p"),Bwr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Iwr=l(),Mn=a("p"),Nwr=o("The model class to instantiate is selected based on the "),bwe=a("code"),qwr=o("model_type"),Dwr=o(` property of the config object (either
passed as an argument or loaded from `),vwe=a("code"),jwr=o("pretrained_model_name_or_path"),Gwr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Fwe=a("code"),Owr=o("pretrained_model_name_or_path"),Vwr=o(":"),Xwr=l(),O=a("ul"),aC=a("li"),Twe=a("strong"),zwr=o("albert"),Qwr=o(" \u2014 "),zee=a("a"),Wwr=o("AlbertForQuestionAnswering"),Uwr=o(" (ALBERT model)"),Hwr=l(),nC=a("li"),Mwe=a("strong"),Jwr=o("bart"),Ywr=o(" \u2014 "),Qee=a("a"),Zwr=o("BartForQuestionAnswering"),Kwr=o(" (BART model)"),eAr=l(),sC=a("li"),Ewe=a("strong"),oAr=o("bert"),rAr=o(" \u2014 "),Wee=a("a"),tAr=o("BertForQuestionAnswering"),aAr=o(" (BERT model)"),nAr=l(),lC=a("li"),Cwe=a("strong"),sAr=o("big_bird"),lAr=o(" \u2014 "),Uee=a("a"),iAr=o("BigBirdForQuestionAnswering"),dAr=o(" (BigBird model)"),mAr=l(),iC=a("li"),wwe=a("strong"),cAr=o("bigbird_pegasus"),fAr=o(" \u2014 "),Hee=a("a"),gAr=o("BigBirdPegasusForQuestionAnswering"),hAr=o(" (BigBird-Pegasus model)"),uAr=l(),dC=a("li"),Awe=a("strong"),pAr=o("bloom"),_Ar=o(" \u2014 "),Jee=a("a"),bAr=o("BloomForQuestionAnswering"),vAr=o(" (BLOOM model)"),FAr=l(),mC=a("li"),Lwe=a("strong"),TAr=o("camembert"),MAr=o(" \u2014 "),Yee=a("a"),EAr=o("CamembertForQuestionAnswering"),CAr=o(" (CamemBERT model)"),wAr=l(),cC=a("li"),ywe=a("strong"),AAr=o("canine"),LAr=o(" \u2014 "),Zee=a("a"),yAr=o("CanineForQuestionAnswering"),xAr=o(" (CANINE model)"),$Ar=l(),fC=a("li"),xwe=a("strong"),kAr=o("convbert"),SAr=o(" \u2014 "),Kee=a("a"),RAr=o("ConvBertForQuestionAnswering"),PAr=o(" (ConvBERT model)"),BAr=l(),gC=a("li"),$we=a("strong"),IAr=o("data2vec-text"),NAr=o(" \u2014 "),eoe=a("a"),qAr=o("Data2VecTextForQuestionAnswering"),DAr=o(" (Data2VecText model)"),jAr=l(),hC=a("li"),kwe=a("strong"),GAr=o("deberta"),OAr=o(" \u2014 "),ooe=a("a"),VAr=o("DebertaForQuestionAnswering"),XAr=o(" (DeBERTa model)"),zAr=l(),uC=a("li"),Swe=a("strong"),QAr=o("deberta-v2"),WAr=o(" \u2014 "),roe=a("a"),UAr=o("DebertaV2ForQuestionAnswering"),HAr=o(" (DeBERTa-v2 model)"),JAr=l(),pC=a("li"),Rwe=a("strong"),YAr=o("distilbert"),ZAr=o(" \u2014 "),toe=a("a"),KAr=o("DistilBertForQuestionAnswering"),e6r=o(" (DistilBERT model)"),o6r=l(),_C=a("li"),Pwe=a("strong"),r6r=o("electra"),t6r=o(" \u2014 "),aoe=a("a"),a6r=o("ElectraForQuestionAnswering"),n6r=o(" (ELECTRA model)"),s6r=l(),bC=a("li"),Bwe=a("strong"),l6r=o("ernie"),i6r=o(" \u2014 "),noe=a("a"),d6r=o("ErnieForQuestionAnswering"),m6r=o(" (ERNIE model)"),c6r=l(),vC=a("li"),Iwe=a("strong"),f6r=o("flaubert"),g6r=o(" \u2014 "),soe=a("a"),h6r=o("FlaubertForQuestionAnsweringSimple"),u6r=o(" (FlauBERT model)"),p6r=l(),FC=a("li"),Nwe=a("strong"),_6r=o("fnet"),b6r=o(" \u2014 "),loe=a("a"),v6r=o("FNetForQuestionAnswering"),F6r=o(" (FNet model)"),T6r=l(),TC=a("li"),qwe=a("strong"),M6r=o("funnel"),E6r=o(" \u2014 "),ioe=a("a"),C6r=o("FunnelForQuestionAnswering"),w6r=o(" (Funnel Transformer model)"),A6r=l(),MC=a("li"),Dwe=a("strong"),L6r=o("gptj"),y6r=o(" \u2014 "),doe=a("a"),x6r=o("GPTJForQuestionAnswering"),$6r=o(" (GPT-J model)"),k6r=l(),EC=a("li"),jwe=a("strong"),S6r=o("ibert"),R6r=o(" \u2014 "),moe=a("a"),P6r=o("IBertForQuestionAnswering"),B6r=o(" (I-BERT model)"),I6r=l(),CC=a("li"),Gwe=a("strong"),N6r=o("layoutlmv2"),q6r=o(" \u2014 "),coe=a("a"),D6r=o("LayoutLMv2ForQuestionAnswering"),j6r=o(" (LayoutLMv2 model)"),G6r=l(),wC=a("li"),Owe=a("strong"),O6r=o("layoutlmv3"),V6r=o(" \u2014 "),foe=a("a"),X6r=o("LayoutLMv3ForQuestionAnswering"),z6r=o(" (LayoutLMv3 model)"),Q6r=l(),AC=a("li"),Vwe=a("strong"),W6r=o("led"),U6r=o(" \u2014 "),goe=a("a"),H6r=o("LEDForQuestionAnswering"),J6r=o(" (LED model)"),Y6r=l(),LC=a("li"),Xwe=a("strong"),Z6r=o("lilt"),K6r=o(" \u2014 "),hoe=a("a"),e7r=o("LiltForQuestionAnswering"),o7r=o(" (LiLT model)"),r7r=l(),yC=a("li"),zwe=a("strong"),t7r=o("longformer"),a7r=o(" \u2014 "),uoe=a("a"),n7r=o("LongformerForQuestionAnswering"),s7r=o(" (Longformer model)"),l7r=l(),xC=a("li"),Qwe=a("strong"),i7r=o("luke"),d7r=o(" \u2014 "),poe=a("a"),m7r=o("LukeForQuestionAnswering"),c7r=o(" (LUKE model)"),f7r=l(),$C=a("li"),Wwe=a("strong"),g7r=o("lxmert"),h7r=o(" \u2014 "),_oe=a("a"),u7r=o("LxmertForQuestionAnswering"),p7r=o(" (LXMERT model)"),_7r=l(),kC=a("li"),Uwe=a("strong"),b7r=o("markuplm"),v7r=o(" \u2014 "),boe=a("a"),F7r=o("MarkupLMForQuestionAnswering"),T7r=o(" (MarkupLM model)"),M7r=l(),SC=a("li"),Hwe=a("strong"),E7r=o("mbart"),C7r=o(" \u2014 "),voe=a("a"),w7r=o("MBartForQuestionAnswering"),A7r=o(" (mBART model)"),L7r=l(),RC=a("li"),Jwe=a("strong"),y7r=o("megatron-bert"),x7r=o(" \u2014 "),Foe=a("a"),$7r=o("MegatronBertForQuestionAnswering"),k7r=o(" (Megatron-BERT model)"),S7r=l(),PC=a("li"),Ywe=a("strong"),R7r=o("mobilebert"),P7r=o(" \u2014 "),Toe=a("a"),B7r=o("MobileBertForQuestionAnswering"),I7r=o(" (MobileBERT model)"),N7r=l(),BC=a("li"),Zwe=a("strong"),q7r=o("mpnet"),D7r=o(" \u2014 "),Moe=a("a"),j7r=o("MPNetForQuestionAnswering"),G7r=o(" (MPNet model)"),O7r=l(),IC=a("li"),Kwe=a("strong"),V7r=o("mvp"),X7r=o(" \u2014 "),Eoe=a("a"),z7r=o("MvpForQuestionAnswering"),Q7r=o(" (MVP model)"),W7r=l(),NC=a("li"),eAe=a("strong"),U7r=o("nezha"),H7r=o(" \u2014 "),Coe=a("a"),J7r=o("NezhaForQuestionAnswering"),Y7r=o(" (Nezha model)"),Z7r=l(),qC=a("li"),oAe=a("strong"),K7r=o("nystromformer"),e8r=o(" \u2014 "),woe=a("a"),o8r=o("NystromformerForQuestionAnswering"),r8r=o(" (Nystr\xF6mformer model)"),t8r=l(),DC=a("li"),rAe=a("strong"),a8r=o("opt"),n8r=o(" \u2014 "),Aoe=a("a"),s8r=o("OPTForQuestionAnswering"),l8r=o(" (OPT model)"),i8r=l(),jC=a("li"),tAe=a("strong"),d8r=o("qdqbert"),m8r=o(" \u2014 "),Loe=a("a"),c8r=o("QDQBertForQuestionAnswering"),f8r=o(" (QDQBert model)"),g8r=l(),GC=a("li"),aAe=a("strong"),h8r=o("reformer"),u8r=o(" \u2014 "),yoe=a("a"),p8r=o("ReformerForQuestionAnswering"),_8r=o(" (Reformer model)"),b8r=l(),OC=a("li"),nAe=a("strong"),v8r=o("rembert"),F8r=o(" \u2014 "),xoe=a("a"),T8r=o("RemBertForQuestionAnswering"),M8r=o(" (RemBERT model)"),E8r=l(),VC=a("li"),sAe=a("strong"),C8r=o("roberta"),w8r=o(" \u2014 "),$oe=a("a"),A8r=o("RobertaForQuestionAnswering"),L8r=o(" (RoBERTa model)"),y8r=l(),XC=a("li"),lAe=a("strong"),x8r=o("roc_bert"),$8r=o(" \u2014 "),koe=a("a"),k8r=o("RoCBertForQuestionAnswering"),S8r=o(" (RoCBert model)"),R8r=l(),zC=a("li"),iAe=a("strong"),P8r=o("roformer"),B8r=o(" \u2014 "),Soe=a("a"),I8r=o("RoFormerForQuestionAnswering"),N8r=o(" (RoFormer model)"),q8r=l(),QC=a("li"),dAe=a("strong"),D8r=o("splinter"),j8r=o(" \u2014 "),Roe=a("a"),G8r=o("SplinterForQuestionAnswering"),O8r=o(" (Splinter model)"),V8r=l(),WC=a("li"),mAe=a("strong"),X8r=o("squeezebert"),z8r=o(" \u2014 "),Poe=a("a"),Q8r=o("SqueezeBertForQuestionAnswering"),W8r=o(" (SqueezeBERT model)"),U8r=l(),UC=a("li"),cAe=a("strong"),H8r=o("xlm"),J8r=o(" \u2014 "),Boe=a("a"),Y8r=o("XLMForQuestionAnsweringSimple"),Z8r=o(" (XLM model)"),K8r=l(),HC=a("li"),fAe=a("strong"),eLr=o("xlm-roberta"),oLr=o(" \u2014 "),Ioe=a("a"),rLr=o("XLMRobertaForQuestionAnswering"),tLr=o(" (XLM-RoBERTa model)"),aLr=l(),JC=a("li"),gAe=a("strong"),nLr=o("xlm-roberta-xl"),sLr=o(" \u2014 "),Noe=a("a"),lLr=o("XLMRobertaXLForQuestionAnswering"),iLr=o(" (XLM-RoBERTa-XL model)"),dLr=l(),YC=a("li"),hAe=a("strong"),mLr=o("xlnet"),cLr=o(" \u2014 "),qoe=a("a"),fLr=o("XLNetForQuestionAnsweringSimple"),gLr=o(" (XLNet model)"),hLr=l(),ZC=a("li"),uAe=a("strong"),uLr=o("yoso"),pLr=o(" \u2014 "),Doe=a("a"),_Lr=o("YosoForQuestionAnswering"),bLr=o(" (YOSO model)"),vLr=l(),KC=a("p"),FLr=o("The model is set in evaluation mode by default using "),pAe=a("code"),TLr=o("model.eval()"),MLr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_Ae=a("code"),ELr=o("model.train()"),CLr=l(),F(e3.$$.fragment),Klo=l(),Fm=a("h2"),o3=a("a"),bAe=a("span"),F(QS.$$.fragment),wLr=l(),vAe=a("span"),ALr=o("AutoModelForTableQuestionAnswering"),eio=l(),Yo=a("div"),F(WS.$$.fragment),LLr=l(),Tm=a("p"),yLr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),joe=a("a"),xLr=o("from_pretrained()"),$Lr=o(" class method or the "),Goe=a("a"),kLr=o("from_config()"),SLr=o(` class
method.`),RLr=l(),US=a("p"),PLr=o("This class cannot be instantiated directly using "),FAe=a("code"),BLr=o("__init__()"),ILr=o(" (throws an error)."),NLr=l(),Nt=a("div"),F(HS.$$.fragment),qLr=l(),TAe=a("p"),DLr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),jLr=l(),Mm=a("p"),GLr=o(`Note:
Loading a model from its configuration file does `),MAe=a("strong"),OLr=o("not"),VLr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ooe=a("a"),XLr=o("from_pretrained()"),zLr=o(" to load the model weights."),QLr=l(),F(r3.$$.fragment),WLr=l(),uo=a("div"),F(JS.$$.fragment),ULr=l(),EAe=a("p"),HLr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),JLr=l(),En=a("p"),YLr=o("The model class to instantiate is selected based on the "),CAe=a("code"),ZLr=o("model_type"),KLr=o(` property of the config object (either
passed as an argument or loaded from `),wAe=a("code"),eyr=o("pretrained_model_name_or_path"),oyr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),AAe=a("code"),ryr=o("pretrained_model_name_or_path"),tyr=o(":"),ayr=l(),LAe=a("ul"),t3=a("li"),yAe=a("strong"),nyr=o("tapas"),syr=o(" \u2014 "),Voe=a("a"),lyr=o("TapasForQuestionAnswering"),iyr=o(" (TAPAS model)"),dyr=l(),a3=a("p"),myr=o("The model is set in evaluation mode by default using "),xAe=a("code"),cyr=o("model.eval()"),fyr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$Ae=a("code"),gyr=o("model.train()"),hyr=l(),F(n3.$$.fragment),oio=l(),Em=a("h2"),s3=a("a"),kAe=a("span"),F(YS.$$.fragment),uyr=l(),SAe=a("span"),pyr=o("AutoModelForDocumentQuestionAnswering"),rio=l(),Zo=a("div"),F(ZS.$$.fragment),_yr=l(),Cm=a("p"),byr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),Xoe=a("a"),vyr=o("from_pretrained()"),Fyr=o(" class method or the "),zoe=a("a"),Tyr=o("from_config()"),Myr=o(` class
method.`),Eyr=l(),KS=a("p"),Cyr=o("This class cannot be instantiated directly using "),RAe=a("code"),wyr=o("__init__()"),Ayr=o(" (throws an error)."),Lyr=l(),qt=a("div"),F(eR.$$.fragment),yyr=l(),PAe=a("p"),xyr=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),$yr=l(),wm=a("p"),kyr=o(`Note:
Loading a model from its configuration file does `),BAe=a("strong"),Syr=o("not"),Ryr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Qoe=a("a"),Pyr=o("from_pretrained()"),Byr=o(" to load the model weights."),Iyr=l(),F(l3.$$.fragment),Nyr=l(),po=a("div"),F(oR.$$.fragment),qyr=l(),IAe=a("p"),Dyr=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),jyr=l(),Cn=a("p"),Gyr=o("The model class to instantiate is selected based on the "),NAe=a("code"),Oyr=o("model_type"),Vyr=o(` property of the config object (either
passed as an argument or loaded from `),qAe=a("code"),Xyr=o("pretrained_model_name_or_path"),zyr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),DAe=a("code"),Qyr=o("pretrained_model_name_or_path"),Wyr=o(":"),Uyr=l(),Am=a("ul"),i3=a("li"),jAe=a("strong"),Hyr=o("layoutlm"),Jyr=o(" \u2014 "),Woe=a("a"),Yyr=o("LayoutLMForQuestionAnswering"),Zyr=o(" (LayoutLM model)"),Kyr=l(),d3=a("li"),GAe=a("strong"),e9r=o("layoutlmv2"),o9r=o(" \u2014 "),Uoe=a("a"),r9r=o("LayoutLMv2ForQuestionAnswering"),t9r=o(" (LayoutLMv2 model)"),a9r=l(),m3=a("li"),OAe=a("strong"),n9r=o("layoutlmv3"),s9r=o(" \u2014 "),Hoe=a("a"),l9r=o("LayoutLMv3ForQuestionAnswering"),i9r=o(" (LayoutLMv3 model)"),d9r=l(),c3=a("p"),m9r=o("The model is set in evaluation mode by default using "),VAe=a("code"),c9r=o("model.eval()"),f9r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),XAe=a("code"),g9r=o("model.train()"),h9r=l(),F(f3.$$.fragment),tio=l(),Lm=a("h2"),g3=a("a"),zAe=a("span"),F(rR.$$.fragment),u9r=l(),QAe=a("span"),p9r=o("AutoModelForImageClassification"),aio=l(),Ko=a("div"),F(tR.$$.fragment),_9r=l(),ym=a("p"),b9r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Joe=a("a"),v9r=o("from_pretrained()"),F9r=o(" class method or the "),Yoe=a("a"),T9r=o("from_config()"),M9r=o(` class
method.`),E9r=l(),aR=a("p"),C9r=o("This class cannot be instantiated directly using "),WAe=a("code"),w9r=o("__init__()"),A9r=o(" (throws an error)."),L9r=l(),Dt=a("div"),F(nR.$$.fragment),y9r=l(),UAe=a("p"),x9r=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),$9r=l(),xm=a("p"),k9r=o(`Note:
Loading a model from its configuration file does `),HAe=a("strong"),S9r=o("not"),R9r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Zoe=a("a"),P9r=o("from_pretrained()"),B9r=o(" to load the model weights."),I9r=l(),F(h3.$$.fragment),N9r=l(),_o=a("div"),F(sR.$$.fragment),q9r=l(),JAe=a("p"),D9r=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),j9r=l(),wn=a("p"),G9r=o("The model class to instantiate is selected based on the "),YAe=a("code"),O9r=o("model_type"),V9r=o(` property of the config object (either
passed as an argument or loaded from `),ZAe=a("code"),X9r=o("pretrained_model_name_or_path"),z9r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KAe=a("code"),Q9r=o("pretrained_model_name_or_path"),W9r=o(":"),U9r=l(),Fe=a("ul"),u3=a("li"),e6e=a("strong"),H9r=o("beit"),J9r=o(" \u2014 "),Koe=a("a"),Y9r=o("BeitForImageClassification"),Z9r=o(" (BEiT model)"),K9r=l(),p3=a("li"),o6e=a("strong"),exr=o("convnext"),oxr=o(" \u2014 "),ere=a("a"),rxr=o("ConvNextForImageClassification"),txr=o(" (ConvNeXT model)"),axr=l(),_3=a("li"),r6e=a("strong"),nxr=o("cvt"),sxr=o(" \u2014 "),ore=a("a"),lxr=o("CvtForImageClassification"),ixr=o(" (CvT model)"),dxr=l(),b3=a("li"),t6e=a("strong"),mxr=o("data2vec-vision"),cxr=o(" \u2014 "),rre=a("a"),fxr=o("Data2VecVisionForImageClassification"),gxr=o(" (Data2VecVision model)"),hxr=l(),Nl=a("li"),a6e=a("strong"),uxr=o("deit"),pxr=o(" \u2014 "),tre=a("a"),_xr=o("DeiTForImageClassification"),bxr=o(" or "),are=a("a"),vxr=o("DeiTForImageClassificationWithTeacher"),Fxr=o(" (DeiT model)"),Txr=l(),v3=a("li"),n6e=a("strong"),Mxr=o("imagegpt"),Exr=o(" \u2014 "),nre=a("a"),Cxr=o("ImageGPTForImageClassification"),wxr=o(" (ImageGPT model)"),Axr=l(),ql=a("li"),s6e=a("strong"),Lxr=o("levit"),yxr=o(" \u2014 "),sre=a("a"),xxr=o("LevitForImageClassification"),$xr=o(" or "),lre=a("a"),kxr=o("LevitForImageClassificationWithTeacher"),Sxr=o(" (LeViT model)"),Rxr=l(),F3=a("li"),l6e=a("strong"),Pxr=o("mobilevit"),Bxr=o(" \u2014 "),ire=a("a"),Ixr=o("MobileViTForImageClassification"),Nxr=o(" (MobileViT model)"),qxr=l(),jt=a("li"),i6e=a("strong"),Dxr=o("perceiver"),jxr=o(" \u2014 "),dre=a("a"),Gxr=o("PerceiverForImageClassificationLearned"),Oxr=o(" or "),mre=a("a"),Vxr=o("PerceiverForImageClassificationFourier"),Xxr=o(" or "),cre=a("a"),zxr=o("PerceiverForImageClassificationConvProcessing"),Qxr=o(" (Perceiver model)"),Wxr=l(),T3=a("li"),d6e=a("strong"),Uxr=o("poolformer"),Hxr=o(" \u2014 "),fre=a("a"),Jxr=o("PoolFormerForImageClassification"),Yxr=o(" (PoolFormer model)"),Zxr=l(),M3=a("li"),m6e=a("strong"),Kxr=o("regnet"),e$r=o(" \u2014 "),gre=a("a"),o$r=o("RegNetForImageClassification"),r$r=o(" (RegNet model)"),t$r=l(),E3=a("li"),c6e=a("strong"),a$r=o("resnet"),n$r=o(" \u2014 "),hre=a("a"),s$r=o("ResNetForImageClassification"),l$r=o(" (ResNet model)"),i$r=l(),C3=a("li"),f6e=a("strong"),d$r=o("segformer"),m$r=o(" \u2014 "),ure=a("a"),c$r=o("SegformerForImageClassification"),f$r=o(" (SegFormer model)"),g$r=l(),w3=a("li"),g6e=a("strong"),h$r=o("swin"),u$r=o(" \u2014 "),pre=a("a"),p$r=o("SwinForImageClassification"),_$r=o(" (Swin Transformer model)"),b$r=l(),A3=a("li"),h6e=a("strong"),v$r=o("swinv2"),F$r=o(" \u2014 "),_re=a("a"),T$r=o("Swinv2ForImageClassification"),M$r=o(" (Swin Transformer V2 model)"),E$r=l(),L3=a("li"),u6e=a("strong"),C$r=o("van"),w$r=o(" \u2014 "),bre=a("a"),A$r=o("VanForImageClassification"),L$r=o(" (VAN model)"),y$r=l(),y3=a("li"),p6e=a("strong"),x$r=o("vit"),$$r=o(" \u2014 "),vre=a("a"),k$r=o("ViTForImageClassification"),S$r=o(" (ViT model)"),R$r=l(),x3=a("li"),_6e=a("strong"),P$r=o("vit_msn"),B$r=o(" \u2014 "),Fre=a("a"),I$r=o("ViTMSNForImageClassification"),N$r=o(" (ViTMSN model)"),q$r=l(),$3=a("p"),D$r=o("The model is set in evaluation mode by default using "),b6e=a("code"),j$r=o("model.eval()"),G$r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),v6e=a("code"),O$r=o("model.train()"),V$r=l(),F(k3.$$.fragment),nio=l(),$m=a("h2"),S3=a("a"),F6e=a("span"),F(lR.$$.fragment),X$r=l(),T6e=a("span"),z$r=o("AutoModelForVideoClassification"),sio=l(),er=a("div"),F(iR.$$.fragment),Q$r=l(),km=a("p"),W$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),Tre=a("a"),U$r=o("from_pretrained()"),H$r=o(" class method or the "),Mre=a("a"),J$r=o("from_config()"),Y$r=o(` class
method.`),Z$r=l(),dR=a("p"),K$r=o("This class cannot be instantiated directly using "),M6e=a("code"),ekr=o("__init__()"),okr=o(" (throws an error)."),rkr=l(),Gt=a("div"),F(mR.$$.fragment),tkr=l(),E6e=a("p"),akr=o("Instantiates one of the model classes of the library (with a video classification head) from a configuration."),nkr=l(),Sm=a("p"),skr=o(`Note:
Loading a model from its configuration file does `),C6e=a("strong"),lkr=o("not"),ikr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ere=a("a"),dkr=o("from_pretrained()"),mkr=o(" to load the model weights."),ckr=l(),F(R3.$$.fragment),fkr=l(),bo=a("div"),F(cR.$$.fragment),gkr=l(),w6e=a("p"),hkr=o("Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),ukr=l(),An=a("p"),pkr=o("The model class to instantiate is selected based on the "),A6e=a("code"),_kr=o("model_type"),bkr=o(` property of the config object (either
passed as an argument or loaded from `),L6e=a("code"),vkr=o("pretrained_model_name_or_path"),Fkr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),y6e=a("code"),Tkr=o("pretrained_model_name_or_path"),Mkr=o(":"),Ekr=l(),x6e=a("ul"),P3=a("li"),$6e=a("strong"),Ckr=o("videomae"),wkr=o(" \u2014 "),Cre=a("a"),Akr=o("VideoMAEForVideoClassification"),Lkr=o(" (VideoMAE model)"),ykr=l(),B3=a("p"),xkr=o("The model is set in evaluation mode by default using "),k6e=a("code"),$kr=o("model.eval()"),kkr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),S6e=a("code"),Skr=o("model.train()"),Rkr=l(),F(I3.$$.fragment),lio=l(),Rm=a("h2"),N3=a("a"),R6e=a("span"),F(fR.$$.fragment),Pkr=l(),P6e=a("span"),Bkr=o("AutoModelForVision2Seq"),iio=l(),or=a("div"),F(gR.$$.fragment),Ikr=l(),Pm=a("p"),Nkr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),wre=a("a"),qkr=o("from_pretrained()"),Dkr=o(" class method or the "),Are=a("a"),jkr=o("from_config()"),Gkr=o(` class
method.`),Okr=l(),hR=a("p"),Vkr=o("This class cannot be instantiated directly using "),B6e=a("code"),Xkr=o("__init__()"),zkr=o(" (throws an error)."),Qkr=l(),Ot=a("div"),F(uR.$$.fragment),Wkr=l(),I6e=a("p"),Ukr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Hkr=l(),Bm=a("p"),Jkr=o(`Note:
Loading a model from its configuration file does `),N6e=a("strong"),Ykr=o("not"),Zkr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Lre=a("a"),Kkr=o("from_pretrained()"),eSr=o(" to load the model weights."),oSr=l(),F(q3.$$.fragment),rSr=l(),vo=a("div"),F(pR.$$.fragment),tSr=l(),q6e=a("p"),aSr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),nSr=l(),Ln=a("p"),sSr=o("The model class to instantiate is selected based on the "),D6e=a("code"),lSr=o("model_type"),iSr=o(` property of the config object (either
passed as an argument or loaded from `),j6e=a("code"),dSr=o("pretrained_model_name_or_path"),mSr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G6e=a("code"),cSr=o("pretrained_model_name_or_path"),fSr=o(":"),gSr=l(),O6e=a("ul"),D3=a("li"),V6e=a("strong"),hSr=o("vision-encoder-decoder"),uSr=o(" \u2014 "),yre=a("a"),pSr=o("VisionEncoderDecoderModel"),_Sr=o(" (Vision Encoder decoder model)"),bSr=l(),j3=a("p"),vSr=o("The model is set in evaluation mode by default using "),X6e=a("code"),FSr=o("model.eval()"),TSr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),z6e=a("code"),MSr=o("model.train()"),ESr=l(),F(G3.$$.fragment),dio=l(),Im=a("h2"),O3=a("a"),Q6e=a("span"),F(_R.$$.fragment),CSr=l(),W6e=a("span"),wSr=o("AutoModelForVisualQuestionAnswering"),mio=l(),rr=a("div"),F(bR.$$.fragment),ASr=l(),Nm=a("p"),LSr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),xre=a("a"),ySr=o("from_pretrained()"),xSr=o(" class method or the "),$re=a("a"),$Sr=o("from_config()"),kSr=o(` class
method.`),SSr=l(),vR=a("p"),RSr=o("This class cannot be instantiated directly using "),U6e=a("code"),PSr=o("__init__()"),BSr=o(" (throws an error)."),ISr=l(),Vt=a("div"),F(FR.$$.fragment),NSr=l(),H6e=a("p"),qSr=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),DSr=l(),qm=a("p"),jSr=o(`Note:
Loading a model from its configuration file does `),J6e=a("strong"),GSr=o("not"),OSr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kre=a("a"),VSr=o("from_pretrained()"),XSr=o(" to load the model weights."),zSr=l(),F(V3.$$.fragment),QSr=l(),Fo=a("div"),F(TR.$$.fragment),WSr=l(),Y6e=a("p"),USr=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),HSr=l(),yn=a("p"),JSr=o("The model class to instantiate is selected based on the "),Z6e=a("code"),YSr=o("model_type"),ZSr=o(` property of the config object (either
passed as an argument or loaded from `),K6e=a("code"),KSr=o("pretrained_model_name_or_path"),eRr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e7e=a("code"),oRr=o("pretrained_model_name_or_path"),rRr=o(":"),tRr=l(),o7e=a("ul"),X3=a("li"),r7e=a("strong"),aRr=o("vilt"),nRr=o(" \u2014 "),Sre=a("a"),sRr=o("ViltForQuestionAnswering"),lRr=o(" (ViLT model)"),iRr=l(),z3=a("p"),dRr=o("The model is set in evaluation mode by default using "),t7e=a("code"),mRr=o("model.eval()"),cRr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),a7e=a("code"),fRr=o("model.train()"),gRr=l(),F(Q3.$$.fragment),cio=l(),Dm=a("h2"),W3=a("a"),n7e=a("span"),F(MR.$$.fragment),hRr=l(),s7e=a("span"),uRr=o("AutoModelForAudioClassification"),fio=l(),tr=a("div"),F(ER.$$.fragment),pRr=l(),jm=a("p"),_Rr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),Rre=a("a"),bRr=o("from_pretrained()"),vRr=o(" class method or the "),Pre=a("a"),FRr=o("from_config()"),TRr=o(` class
method.`),MRr=l(),CR=a("p"),ERr=o("This class cannot be instantiated directly using "),l7e=a("code"),CRr=o("__init__()"),wRr=o(" (throws an error)."),ARr=l(),Xt=a("div"),F(wR.$$.fragment),LRr=l(),i7e=a("p"),yRr=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),xRr=l(),Gm=a("p"),$Rr=o(`Note:
Loading a model from its configuration file does `),d7e=a("strong"),kRr=o("not"),SRr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Bre=a("a"),RRr=o("from_pretrained()"),PRr=o(" to load the model weights."),BRr=l(),F(U3.$$.fragment),IRr=l(),To=a("div"),F(AR.$$.fragment),NRr=l(),m7e=a("p"),qRr=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),DRr=l(),xn=a("p"),jRr=o("The model class to instantiate is selected based on the "),c7e=a("code"),GRr=o("model_type"),ORr=o(` property of the config object (either
passed as an argument or loaded from `),f7e=a("code"),VRr=o("pretrained_model_name_or_path"),XRr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),g7e=a("code"),zRr=o("pretrained_model_name_or_path"),QRr=o(":"),WRr=l(),Ne=a("ul"),H3=a("li"),h7e=a("strong"),URr=o("data2vec-audio"),HRr=o(" \u2014 "),Ire=a("a"),JRr=o("Data2VecAudioForSequenceClassification"),YRr=o(" (Data2VecAudio model)"),ZRr=l(),J3=a("li"),u7e=a("strong"),KRr=o("hubert"),ePr=o(" \u2014 "),Nre=a("a"),oPr=o("HubertForSequenceClassification"),rPr=o(" (Hubert model)"),tPr=l(),Y3=a("li"),p7e=a("strong"),aPr=o("sew"),nPr=o(" \u2014 "),qre=a("a"),sPr=o("SEWForSequenceClassification"),lPr=o(" (SEW model)"),iPr=l(),Z3=a("li"),_7e=a("strong"),dPr=o("sew-d"),mPr=o(" \u2014 "),Dre=a("a"),cPr=o("SEWDForSequenceClassification"),fPr=o(" (SEW-D model)"),gPr=l(),K3=a("li"),b7e=a("strong"),hPr=o("unispeech"),uPr=o(" \u2014 "),jre=a("a"),pPr=o("UniSpeechForSequenceClassification"),_Pr=o(" (UniSpeech model)"),bPr=l(),e5=a("li"),v7e=a("strong"),vPr=o("unispeech-sat"),FPr=o(" \u2014 "),Gre=a("a"),TPr=o("UniSpeechSatForSequenceClassification"),MPr=o(" (UniSpeechSat model)"),EPr=l(),o5=a("li"),F7e=a("strong"),CPr=o("wav2vec2"),wPr=o(" \u2014 "),Ore=a("a"),APr=o("Wav2Vec2ForSequenceClassification"),LPr=o(" (Wav2Vec2 model)"),yPr=l(),r5=a("li"),T7e=a("strong"),xPr=o("wav2vec2-conformer"),$Pr=o(" \u2014 "),Vre=a("a"),kPr=o("Wav2Vec2ConformerForSequenceClassification"),SPr=o(" (Wav2Vec2-Conformer model)"),RPr=l(),t5=a("li"),M7e=a("strong"),PPr=o("wavlm"),BPr=o(" \u2014 "),Xre=a("a"),IPr=o("WavLMForSequenceClassification"),NPr=o(" (WavLM model)"),qPr=l(),a5=a("p"),DPr=o("The model is set in evaluation mode by default using "),E7e=a("code"),jPr=o("model.eval()"),GPr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),C7e=a("code"),OPr=o("model.train()"),VPr=l(),F(n5.$$.fragment),gio=l(),Om=a("h2"),s5=a("a"),w7e=a("span"),F(LR.$$.fragment),XPr=l(),A7e=a("span"),zPr=o("AutoModelForAudioFrameClassification"),hio=l(),ar=a("div"),F(yR.$$.fragment),QPr=l(),Vm=a("p"),WPr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),zre=a("a"),UPr=o("from_pretrained()"),HPr=o(" class method or the "),Qre=a("a"),JPr=o("from_config()"),YPr=o(` class
method.`),ZPr=l(),xR=a("p"),KPr=o("This class cannot be instantiated directly using "),L7e=a("code"),eBr=o("__init__()"),oBr=o(" (throws an error)."),rBr=l(),zt=a("div"),F($R.$$.fragment),tBr=l(),y7e=a("p"),aBr=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),nBr=l(),Xm=a("p"),sBr=o(`Note:
Loading a model from its configuration file does `),x7e=a("strong"),lBr=o("not"),iBr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Wre=a("a"),dBr=o("from_pretrained()"),mBr=o(" to load the model weights."),cBr=l(),F(l5.$$.fragment),fBr=l(),Mo=a("div"),F(kR.$$.fragment),gBr=l(),$7e=a("p"),hBr=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),uBr=l(),$n=a("p"),pBr=o("The model class to instantiate is selected based on the "),k7e=a("code"),_Br=o("model_type"),bBr=o(` property of the config object (either
passed as an argument or loaded from `),S7e=a("code"),vBr=o("pretrained_model_name_or_path"),FBr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R7e=a("code"),TBr=o("pretrained_model_name_or_path"),MBr=o(":"),EBr=l(),vt=a("ul"),i5=a("li"),P7e=a("strong"),CBr=o("data2vec-audio"),wBr=o(" \u2014 "),Ure=a("a"),ABr=o("Data2VecAudioForAudioFrameClassification"),LBr=o(" (Data2VecAudio model)"),yBr=l(),d5=a("li"),B7e=a("strong"),xBr=o("unispeech-sat"),$Br=o(" \u2014 "),Hre=a("a"),kBr=o("UniSpeechSatForAudioFrameClassification"),SBr=o(" (UniSpeechSat model)"),RBr=l(),m5=a("li"),I7e=a("strong"),PBr=o("wav2vec2"),BBr=o(" \u2014 "),Jre=a("a"),IBr=o("Wav2Vec2ForAudioFrameClassification"),NBr=o(" (Wav2Vec2 model)"),qBr=l(),c5=a("li"),N7e=a("strong"),DBr=o("wav2vec2-conformer"),jBr=o(" \u2014 "),Yre=a("a"),GBr=o("Wav2Vec2ConformerForAudioFrameClassification"),OBr=o(" (Wav2Vec2-Conformer model)"),VBr=l(),f5=a("li"),q7e=a("strong"),XBr=o("wavlm"),zBr=o(" \u2014 "),Zre=a("a"),QBr=o("WavLMForAudioFrameClassification"),WBr=o(" (WavLM model)"),UBr=l(),g5=a("p"),HBr=o("The model is set in evaluation mode by default using "),D7e=a("code"),JBr=o("model.eval()"),YBr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),j7e=a("code"),ZBr=o("model.train()"),KBr=l(),F(h5.$$.fragment),uio=l(),zm=a("h2"),u5=a("a"),G7e=a("span"),F(SR.$$.fragment),eIr=l(),O7e=a("span"),oIr=o("AutoModelForCTC"),pio=l(),nr=a("div"),F(RR.$$.fragment),rIr=l(),Qm=a("p"),tIr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),Kre=a("a"),aIr=o("from_pretrained()"),nIr=o(" class method or the "),ete=a("a"),sIr=o("from_config()"),lIr=o(` class
method.`),iIr=l(),PR=a("p"),dIr=o("This class cannot be instantiated directly using "),V7e=a("code"),mIr=o("__init__()"),cIr=o(" (throws an error)."),fIr=l(),Qt=a("div"),F(BR.$$.fragment),gIr=l(),X7e=a("p"),hIr=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),uIr=l(),Wm=a("p"),pIr=o(`Note:
Loading a model from its configuration file does `),z7e=a("strong"),_Ir=o("not"),bIr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ote=a("a"),vIr=o("from_pretrained()"),FIr=o(" to load the model weights."),TIr=l(),F(p5.$$.fragment),MIr=l(),Eo=a("div"),F(IR.$$.fragment),EIr=l(),Q7e=a("p"),CIr=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),wIr=l(),kn=a("p"),AIr=o("The model class to instantiate is selected based on the "),W7e=a("code"),LIr=o("model_type"),yIr=o(` property of the config object (either
passed as an argument or loaded from `),U7e=a("code"),xIr=o("pretrained_model_name_or_path"),$Ir=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),H7e=a("code"),kIr=o("pretrained_model_name_or_path"),SIr=o(":"),RIr=l(),xe=a("ul"),_5=a("li"),J7e=a("strong"),PIr=o("data2vec-audio"),BIr=o(" \u2014 "),rte=a("a"),IIr=o("Data2VecAudioForCTC"),NIr=o(" (Data2VecAudio model)"),qIr=l(),b5=a("li"),Y7e=a("strong"),DIr=o("hubert"),jIr=o(" \u2014 "),tte=a("a"),GIr=o("HubertForCTC"),OIr=o(" (Hubert model)"),VIr=l(),v5=a("li"),Z7e=a("strong"),XIr=o("mctct"),zIr=o(" \u2014 "),ate=a("a"),QIr=o("MCTCTForCTC"),WIr=o(" (M-CTC-T model)"),UIr=l(),F5=a("li"),K7e=a("strong"),HIr=o("sew"),JIr=o(" \u2014 "),nte=a("a"),YIr=o("SEWForCTC"),ZIr=o(" (SEW model)"),KIr=l(),T5=a("li"),e8e=a("strong"),eNr=o("sew-d"),oNr=o(" \u2014 "),ste=a("a"),rNr=o("SEWDForCTC"),tNr=o(" (SEW-D model)"),aNr=l(),M5=a("li"),o8e=a("strong"),nNr=o("unispeech"),sNr=o(" \u2014 "),lte=a("a"),lNr=o("UniSpeechForCTC"),iNr=o(" (UniSpeech model)"),dNr=l(),E5=a("li"),r8e=a("strong"),mNr=o("unispeech-sat"),cNr=o(" \u2014 "),ite=a("a"),fNr=o("UniSpeechSatForCTC"),gNr=o(" (UniSpeechSat model)"),hNr=l(),C5=a("li"),t8e=a("strong"),uNr=o("wav2vec2"),pNr=o(" \u2014 "),dte=a("a"),_Nr=o("Wav2Vec2ForCTC"),bNr=o(" (Wav2Vec2 model)"),vNr=l(),w5=a("li"),a8e=a("strong"),FNr=o("wav2vec2-conformer"),TNr=o(" \u2014 "),mte=a("a"),MNr=o("Wav2Vec2ConformerForCTC"),ENr=o(" (Wav2Vec2-Conformer model)"),CNr=l(),A5=a("li"),n8e=a("strong"),wNr=o("wavlm"),ANr=o(" \u2014 "),cte=a("a"),LNr=o("WavLMForCTC"),yNr=o(" (WavLM model)"),xNr=l(),L5=a("p"),$Nr=o("The model is set in evaluation mode by default using "),s8e=a("code"),kNr=o("model.eval()"),SNr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),l8e=a("code"),RNr=o("model.train()"),PNr=l(),F(y5.$$.fragment),_io=l(),Um=a("h2"),x5=a("a"),i8e=a("span"),F(NR.$$.fragment),BNr=l(),d8e=a("span"),INr=o("AutoModelForSpeechSeq2Seq"),bio=l(),sr=a("div"),F(qR.$$.fragment),NNr=l(),Hm=a("p"),qNr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),fte=a("a"),DNr=o("from_pretrained()"),jNr=o(" class method or the "),gte=a("a"),GNr=o("from_config()"),ONr=o(` class
method.`),VNr=l(),DR=a("p"),XNr=o("This class cannot be instantiated directly using "),m8e=a("code"),zNr=o("__init__()"),QNr=o(" (throws an error)."),WNr=l(),Wt=a("div"),F(jR.$$.fragment),UNr=l(),c8e=a("p"),HNr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),JNr=l(),Jm=a("p"),YNr=o(`Note:
Loading a model from its configuration file does `),f8e=a("strong"),ZNr=o("not"),KNr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hte=a("a"),eqr=o("from_pretrained()"),oqr=o(" to load the model weights."),rqr=l(),F($5.$$.fragment),tqr=l(),Co=a("div"),F(GR.$$.fragment),aqr=l(),g8e=a("p"),nqr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),sqr=l(),Sn=a("p"),lqr=o("The model class to instantiate is selected based on the "),h8e=a("code"),iqr=o("model_type"),dqr=o(` property of the config object (either
passed as an argument or loaded from `),u8e=a("code"),mqr=o("pretrained_model_name_or_path"),cqr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p8e=a("code"),fqr=o("pretrained_model_name_or_path"),gqr=o(":"),hqr=l(),Ym=a("ul"),k5=a("li"),_8e=a("strong"),uqr=o("speech-encoder-decoder"),pqr=o(" \u2014 "),ute=a("a"),_qr=o("SpeechEncoderDecoderModel"),bqr=o(" (Speech Encoder decoder model)"),vqr=l(),S5=a("li"),b8e=a("strong"),Fqr=o("speech_to_text"),Tqr=o(" \u2014 "),pte=a("a"),Mqr=o("Speech2TextForConditionalGeneration"),Eqr=o(" (Speech2Text model)"),Cqr=l(),R5=a("li"),v8e=a("strong"),wqr=o("whisper"),Aqr=o(" \u2014 "),_te=a("a"),Lqr=o("WhisperForConditionalGeneration"),yqr=o(" (Whisper model)"),xqr=l(),P5=a("p"),$qr=o("The model is set in evaluation mode by default using "),F8e=a("code"),kqr=o("model.eval()"),Sqr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),T8e=a("code"),Rqr=o("model.train()"),Pqr=l(),F(B5.$$.fragment),vio=l(),Zm=a("h2"),I5=a("a"),M8e=a("span"),F(OR.$$.fragment),Bqr=l(),E8e=a("span"),Iqr=o("AutoModelForAudioXVector"),Fio=l(),lr=a("div"),F(VR.$$.fragment),Nqr=l(),Km=a("p"),qqr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),bte=a("a"),Dqr=o("from_pretrained()"),jqr=o(" class method or the "),vte=a("a"),Gqr=o("from_config()"),Oqr=o(` class
method.`),Vqr=l(),XR=a("p"),Xqr=o("This class cannot be instantiated directly using "),C8e=a("code"),zqr=o("__init__()"),Qqr=o(" (throws an error)."),Wqr=l(),Ut=a("div"),F(zR.$$.fragment),Uqr=l(),w8e=a("p"),Hqr=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),Jqr=l(),ec=a("p"),Yqr=o(`Note:
Loading a model from its configuration file does `),A8e=a("strong"),Zqr=o("not"),Kqr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Fte=a("a"),eDr=o("from_pretrained()"),oDr=o(" to load the model weights."),rDr=l(),F(N5.$$.fragment),tDr=l(),wo=a("div"),F(QR.$$.fragment),aDr=l(),L8e=a("p"),nDr=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),sDr=l(),Rn=a("p"),lDr=o("The model class to instantiate is selected based on the "),y8e=a("code"),iDr=o("model_type"),dDr=o(` property of the config object (either
passed as an argument or loaded from `),x8e=a("code"),mDr=o("pretrained_model_name_or_path"),cDr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$8e=a("code"),fDr=o("pretrained_model_name_or_path"),gDr=o(":"),hDr=l(),Ft=a("ul"),q5=a("li"),k8e=a("strong"),uDr=o("data2vec-audio"),pDr=o(" \u2014 "),Tte=a("a"),_Dr=o("Data2VecAudioForXVector"),bDr=o(" (Data2VecAudio model)"),vDr=l(),D5=a("li"),S8e=a("strong"),FDr=o("unispeech-sat"),TDr=o(" \u2014 "),Mte=a("a"),MDr=o("UniSpeechSatForXVector"),EDr=o(" (UniSpeechSat model)"),CDr=l(),j5=a("li"),R8e=a("strong"),wDr=o("wav2vec2"),ADr=o(" \u2014 "),Ete=a("a"),LDr=o("Wav2Vec2ForXVector"),yDr=o(" (Wav2Vec2 model)"),xDr=l(),G5=a("li"),P8e=a("strong"),$Dr=o("wav2vec2-conformer"),kDr=o(" \u2014 "),Cte=a("a"),SDr=o("Wav2Vec2ConformerForXVector"),RDr=o(" (Wav2Vec2-Conformer model)"),PDr=l(),O5=a("li"),B8e=a("strong"),BDr=o("wavlm"),IDr=o(" \u2014 "),wte=a("a"),NDr=o("WavLMForXVector"),qDr=o(" (WavLM model)"),DDr=l(),V5=a("p"),jDr=o("The model is set in evaluation mode by default using "),I8e=a("code"),GDr=o("model.eval()"),ODr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),N8e=a("code"),VDr=o("model.train()"),XDr=l(),F(X5.$$.fragment),Tio=l(),oc=a("h2"),z5=a("a"),q8e=a("span"),F(WR.$$.fragment),zDr=l(),D8e=a("span"),QDr=o("AutoModelForMaskedImageModeling"),Mio=l(),ir=a("div"),F(UR.$$.fragment),WDr=l(),rc=a("p"),UDr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),Ate=a("a"),HDr=o("from_pretrained()"),JDr=o(" class method or the "),Lte=a("a"),YDr=o("from_config()"),ZDr=o(` class
method.`),KDr=l(),HR=a("p"),ejr=o("This class cannot be instantiated directly using "),j8e=a("code"),ojr=o("__init__()"),rjr=o(" (throws an error)."),tjr=l(),Ht=a("div"),F(JR.$$.fragment),ajr=l(),G8e=a("p"),njr=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),sjr=l(),tc=a("p"),ljr=o(`Note:
Loading a model from its configuration file does `),O8e=a("strong"),ijr=o("not"),djr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yte=a("a"),mjr=o("from_pretrained()"),cjr=o(" to load the model weights."),fjr=l(),F(Q5.$$.fragment),gjr=l(),Ao=a("div"),F(YR.$$.fragment),hjr=l(),V8e=a("p"),ujr=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),pjr=l(),Pn=a("p"),_jr=o("The model class to instantiate is selected based on the "),X8e=a("code"),bjr=o("model_type"),vjr=o(` property of the config object (either
passed as an argument or loaded from `),z8e=a("code"),Fjr=o("pretrained_model_name_or_path"),Tjr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q8e=a("code"),Mjr=o("pretrained_model_name_or_path"),Ejr=o(":"),Cjr=l(),Bn=a("ul"),W5=a("li"),W8e=a("strong"),wjr=o("deit"),Ajr=o(" \u2014 "),xte=a("a"),Ljr=o("DeiTForMaskedImageModeling"),yjr=o(" (DeiT model)"),xjr=l(),U5=a("li"),U8e=a("strong"),$jr=o("swin"),kjr=o(" \u2014 "),$te=a("a"),Sjr=o("SwinForMaskedImageModeling"),Rjr=o(" (Swin Transformer model)"),Pjr=l(),H5=a("li"),H8e=a("strong"),Bjr=o("swinv2"),Ijr=o(" \u2014 "),kte=a("a"),Njr=o("Swinv2ForMaskedImageModeling"),qjr=o(" (Swin Transformer V2 model)"),Djr=l(),J5=a("li"),J8e=a("strong"),jjr=o("vit"),Gjr=o(" \u2014 "),Ste=a("a"),Ojr=o("ViTForMaskedImageModeling"),Vjr=o(" (ViT model)"),Xjr=l(),Y5=a("p"),zjr=o("The model is set in evaluation mode by default using "),Y8e=a("code"),Qjr=o("model.eval()"),Wjr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Z8e=a("code"),Ujr=o("model.train()"),Hjr=l(),F(Z5.$$.fragment),Eio=l(),ac=a("h2"),K5=a("a"),K8e=a("span"),F(ZR.$$.fragment),Jjr=l(),eLe=a("span"),Yjr=o("AutoModelForObjectDetection"),Cio=l(),dr=a("div"),F(KR.$$.fragment),Zjr=l(),nc=a("p"),Kjr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),Rte=a("a"),eGr=o("from_pretrained()"),oGr=o(" class method or the "),Pte=a("a"),rGr=o("from_config()"),tGr=o(` class
method.`),aGr=l(),eP=a("p"),nGr=o("This class cannot be instantiated directly using "),oLe=a("code"),sGr=o("__init__()"),lGr=o(" (throws an error)."),iGr=l(),Jt=a("div"),F(oP.$$.fragment),dGr=l(),rLe=a("p"),mGr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),cGr=l(),sc=a("p"),fGr=o(`Note:
Loading a model from its configuration file does `),tLe=a("strong"),gGr=o("not"),hGr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Bte=a("a"),uGr=o("from_pretrained()"),pGr=o(" to load the model weights."),_Gr=l(),F(e0.$$.fragment),bGr=l(),Lo=a("div"),F(rP.$$.fragment),vGr=l(),aLe=a("p"),FGr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),TGr=l(),In=a("p"),MGr=o("The model class to instantiate is selected based on the "),nLe=a("code"),EGr=o("model_type"),CGr=o(` property of the config object (either
passed as an argument or loaded from `),sLe=a("code"),wGr=o("pretrained_model_name_or_path"),AGr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lLe=a("code"),LGr=o("pretrained_model_name_or_path"),yGr=o(":"),xGr=l(),Tt=a("ul"),o0=a("li"),iLe=a("strong"),$Gr=o("conditional_detr"),kGr=o(" \u2014 "),Ite=a("a"),SGr=o("ConditionalDetrForObjectDetection"),RGr=o(" (Conditional DETR model)"),PGr=l(),r0=a("li"),dLe=a("strong"),BGr=o("deformable_detr"),IGr=o(" \u2014 "),Nte=a("a"),NGr=o("DeformableDetrForObjectDetection"),qGr=o(" (Deformable DETR model)"),DGr=l(),t0=a("li"),mLe=a("strong"),jGr=o("detr"),GGr=o(" \u2014 "),qte=a("a"),OGr=o("DetrForObjectDetection"),VGr=o(" (DETR model)"),XGr=l(),a0=a("li"),cLe=a("strong"),zGr=o("table-transformer"),QGr=o(" \u2014 "),Dte=a("a"),WGr=o("TableTransformerForObjectDetection"),UGr=o(" (Table Transformer model)"),HGr=l(),n0=a("li"),fLe=a("strong"),JGr=o("yolos"),YGr=o(" \u2014 "),jte=a("a"),ZGr=o("YolosForObjectDetection"),KGr=o(" (YOLOS model)"),eOr=l(),s0=a("p"),oOr=o("The model is set in evaluation mode by default using "),gLe=a("code"),rOr=o("model.eval()"),tOr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),hLe=a("code"),aOr=o("model.train()"),nOr=l(),F(l0.$$.fragment),wio=l(),lc=a("h2"),i0=a("a"),uLe=a("span"),F(tP.$$.fragment),sOr=l(),pLe=a("span"),lOr=o("AutoModelForImageSegmentation"),Aio=l(),mr=a("div"),F(aP.$$.fragment),iOr=l(),ic=a("p"),dOr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),Gte=a("a"),mOr=o("from_pretrained()"),cOr=o(" class method or the "),Ote=a("a"),fOr=o("from_config()"),gOr=o(` class
method.`),hOr=l(),nP=a("p"),uOr=o("This class cannot be instantiated directly using "),_Le=a("code"),pOr=o("__init__()"),_Or=o(" (throws an error)."),bOr=l(),Yt=a("div"),F(sP.$$.fragment),vOr=l(),bLe=a("p"),FOr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),TOr=l(),dc=a("p"),MOr=o(`Note:
Loading a model from its configuration file does `),vLe=a("strong"),EOr=o("not"),COr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Vte=a("a"),wOr=o("from_pretrained()"),AOr=o(" to load the model weights."),LOr=l(),F(d0.$$.fragment),yOr=l(),yo=a("div"),F(lP.$$.fragment),xOr=l(),FLe=a("p"),$Or=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),kOr=l(),Nn=a("p"),SOr=o("The model class to instantiate is selected based on the "),TLe=a("code"),ROr=o("model_type"),POr=o(` property of the config object (either
passed as an argument or loaded from `),MLe=a("code"),BOr=o("pretrained_model_name_or_path"),IOr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ELe=a("code"),NOr=o("pretrained_model_name_or_path"),qOr=o(":"),DOr=l(),CLe=a("ul"),m0=a("li"),wLe=a("strong"),jOr=o("detr"),GOr=o(" \u2014 "),Xte=a("a"),OOr=o("DetrForSegmentation"),VOr=o(" (DETR model)"),XOr=l(),c0=a("p"),zOr=o("The model is set in evaluation mode by default using "),ALe=a("code"),QOr=o("model.eval()"),WOr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),LLe=a("code"),UOr=o("model.train()"),HOr=l(),F(f0.$$.fragment),Lio=l(),mc=a("h2"),g0=a("a"),yLe=a("span"),F(iP.$$.fragment),JOr=l(),xLe=a("span"),YOr=o("AutoModelForSemanticSegmentation"),yio=l(),cr=a("div"),F(dP.$$.fragment),ZOr=l(),cc=a("p"),KOr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),zte=a("a"),eVr=o("from_pretrained()"),oVr=o(" class method or the "),Qte=a("a"),rVr=o("from_config()"),tVr=o(` class
method.`),aVr=l(),mP=a("p"),nVr=o("This class cannot be instantiated directly using "),$Le=a("code"),sVr=o("__init__()"),lVr=o(" (throws an error)."),iVr=l(),Zt=a("div"),F(cP.$$.fragment),dVr=l(),kLe=a("p"),mVr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),cVr=l(),fc=a("p"),fVr=o(`Note:
Loading a model from its configuration file does `),SLe=a("strong"),gVr=o("not"),hVr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Wte=a("a"),uVr=o("from_pretrained()"),pVr=o(" to load the model weights."),_Vr=l(),F(h0.$$.fragment),bVr=l(),xo=a("div"),F(fP.$$.fragment),vVr=l(),RLe=a("p"),FVr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),TVr=l(),qn=a("p"),MVr=o("The model class to instantiate is selected based on the "),PLe=a("code"),EVr=o("model_type"),CVr=o(` property of the config object (either
passed as an argument or loaded from `),BLe=a("code"),wVr=o("pretrained_model_name_or_path"),AVr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ILe=a("code"),LVr=o("pretrained_model_name_or_path"),yVr=o(":"),xVr=l(),Mt=a("ul"),u0=a("li"),NLe=a("strong"),$Vr=o("beit"),kVr=o(" \u2014 "),Ute=a("a"),SVr=o("BeitForSemanticSegmentation"),RVr=o(" (BEiT model)"),PVr=l(),p0=a("li"),qLe=a("strong"),BVr=o("data2vec-vision"),IVr=o(" \u2014 "),Hte=a("a"),NVr=o("Data2VecVisionForSemanticSegmentation"),qVr=o(" (Data2VecVision model)"),DVr=l(),_0=a("li"),DLe=a("strong"),jVr=o("dpt"),GVr=o(" \u2014 "),Jte=a("a"),OVr=o("DPTForSemanticSegmentation"),VVr=o(" (DPT model)"),XVr=l(),b0=a("li"),jLe=a("strong"),zVr=o("mobilevit"),QVr=o(" \u2014 "),Yte=a("a"),WVr=o("MobileViTForSemanticSegmentation"),UVr=o(" (MobileViT model)"),HVr=l(),v0=a("li"),GLe=a("strong"),JVr=o("segformer"),YVr=o(" \u2014 "),Zte=a("a"),ZVr=o("SegformerForSemanticSegmentation"),KVr=o(" (SegFormer model)"),eXr=l(),F0=a("p"),oXr=o("The model is set in evaluation mode by default using "),OLe=a("code"),rXr=o("model.eval()"),tXr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),VLe=a("code"),aXr=o("model.train()"),nXr=l(),F(T0.$$.fragment),xio=l(),gc=a("h2"),M0=a("a"),XLe=a("span"),F(gP.$$.fragment),sXr=l(),zLe=a("span"),lXr=o("AutoModelForInstanceSegmentation"),$io=l(),fr=a("div"),F(hP.$$.fragment),iXr=l(),hc=a("p"),dXr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),Kte=a("a"),mXr=o("from_pretrained()"),cXr=o(" class method or the "),eae=a("a"),fXr=o("from_config()"),gXr=o(` class
method.`),hXr=l(),uP=a("p"),uXr=o("This class cannot be instantiated directly using "),QLe=a("code"),pXr=o("__init__()"),_Xr=o(" (throws an error)."),bXr=l(),Kt=a("div"),F(pP.$$.fragment),vXr=l(),WLe=a("p"),FXr=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),TXr=l(),uc=a("p"),MXr=o(`Note:
Loading a model from its configuration file does `),ULe=a("strong"),EXr=o("not"),CXr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oae=a("a"),wXr=o("from_pretrained()"),AXr=o(" to load the model weights."),LXr=l(),F(E0.$$.fragment),yXr=l(),$o=a("div"),F(_P.$$.fragment),xXr=l(),HLe=a("p"),$Xr=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),kXr=l(),Dn=a("p"),SXr=o("The model class to instantiate is selected based on the "),JLe=a("code"),RXr=o("model_type"),PXr=o(` property of the config object (either
passed as an argument or loaded from `),YLe=a("code"),BXr=o("pretrained_model_name_or_path"),IXr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ZLe=a("code"),NXr=o("pretrained_model_name_or_path"),qXr=o(":"),DXr=l(),KLe=a("ul"),C0=a("li"),eye=a("strong"),jXr=o("maskformer"),GXr=o(" \u2014 "),rae=a("a"),OXr=o("MaskFormerForInstanceSegmentation"),VXr=o(" (MaskFormer model)"),XXr=l(),w0=a("p"),zXr=o("The model is set in evaluation mode by default using "),oye=a("code"),QXr=o("model.eval()"),WXr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),rye=a("code"),UXr=o("model.train()"),HXr=l(),F(A0.$$.fragment),kio=l(),pc=a("h2"),L0=a("a"),tye=a("span"),F(bP.$$.fragment),JXr=l(),aye=a("span"),YXr=o("AutoModelForZeroShotObjectDetection"),Sio=l(),gr=a("div"),F(vP.$$.fragment),ZXr=l(),_c=a("p"),KXr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a zero-shot object detection head) when created
with the `),tae=a("a"),ezr=o("from_pretrained()"),ozr=o(" class method or the "),aae=a("a"),rzr=o("from_config()"),tzr=o(` class
method.`),azr=l(),FP=a("p"),nzr=o("This class cannot be instantiated directly using "),nye=a("code"),szr=o("__init__()"),lzr=o(" (throws an error)."),izr=l(),ea=a("div"),F(TP.$$.fragment),dzr=l(),sye=a("p"),mzr=o("Instantiates one of the model classes of the library (with a zero-shot object detection head) from a configuration."),czr=l(),bc=a("p"),fzr=o(`Note:
Loading a model from its configuration file does `),lye=a("strong"),gzr=o("not"),hzr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nae=a("a"),uzr=o("from_pretrained()"),pzr=o(" to load the model weights."),_zr=l(),F(y0.$$.fragment),bzr=l(),ko=a("div"),F(MP.$$.fragment),vzr=l(),iye=a("p"),Fzr=o("Instantiate one of the model classes of the library (with a zero-shot object detection head) from a pretrained model."),Tzr=l(),jn=a("p"),Mzr=o("The model class to instantiate is selected based on the "),dye=a("code"),Ezr=o("model_type"),Czr=o(` property of the config object (either
passed as an argument or loaded from `),mye=a("code"),wzr=o("pretrained_model_name_or_path"),Azr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cye=a("code"),Lzr=o("pretrained_model_name_or_path"),yzr=o(":"),xzr=l(),fye=a("ul"),x0=a("li"),gye=a("strong"),$zr=o("owlvit"),kzr=o(" \u2014 "),sae=a("a"),Szr=o("OwlViTForObjectDetection"),Rzr=o(" (OWL-ViT model)"),Pzr=l(),$0=a("p"),Bzr=o("The model is set in evaluation mode by default using "),hye=a("code"),Izr=o("model.eval()"),Nzr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),uye=a("code"),qzr=o("model.train()"),Dzr=l(),F(k0.$$.fragment),Rio=l(),vc=a("h2"),S0=a("a"),pye=a("span"),F(EP.$$.fragment),jzr=l(),_ye=a("span"),Gzr=o("TFAutoModel"),Pio=l(),hr=a("div"),F(CP.$$.fragment),Ozr=l(),Fc=a("p"),Vzr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),lae=a("a"),Xzr=o("from_pretrained()"),zzr=o(" class method or the "),iae=a("a"),Qzr=o("from_config()"),Wzr=o(` class
method.`),Uzr=l(),wP=a("p"),Hzr=o("This class cannot be instantiated directly using "),bye=a("code"),Jzr=o("__init__()"),Yzr=o(" (throws an error)."),Zzr=l(),oa=a("div"),F(AP.$$.fragment),Kzr=l(),vye=a("p"),eQr=o("Instantiates one of the base model classes of the library from a configuration."),oQr=l(),Tc=a("p"),rQr=o(`Note:
Loading a model from its configuration file does `),Fye=a("strong"),tQr=o("not"),aQr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dae=a("a"),nQr=o("from_pretrained()"),sQr=o(" to load the model weights."),lQr=l(),F(R0.$$.fragment),iQr=l(),Xr=a("div"),F(LP.$$.fragment),dQr=l(),Tye=a("p"),mQr=o("Instantiate one of the base model classes of the library from a pretrained model."),cQr=l(),Gn=a("p"),fQr=o("The model class to instantiate is selected based on the "),Mye=a("code"),gQr=o("model_type"),hQr=o(` property of the config object (either
passed as an argument or loaded from `),Eye=a("code"),uQr=o("pretrained_model_name_or_path"),pQr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Cye=a("code"),_Qr=o("pretrained_model_name_or_path"),bQr=o(":"),vQr=l(),P=a("ul"),P0=a("li"),wye=a("strong"),FQr=o("albert"),TQr=o(" \u2014 "),mae=a("a"),MQr=o("TFAlbertModel"),EQr=o(" (ALBERT model)"),CQr=l(),B0=a("li"),Aye=a("strong"),wQr=o("bart"),AQr=o(" \u2014 "),cae=a("a"),LQr=o("TFBartModel"),yQr=o(" (BART model)"),xQr=l(),I0=a("li"),Lye=a("strong"),$Qr=o("bert"),kQr=o(" \u2014 "),fae=a("a"),SQr=o("TFBertModel"),RQr=o(" (BERT model)"),PQr=l(),N0=a("li"),yye=a("strong"),BQr=o("blenderbot"),IQr=o(" \u2014 "),gae=a("a"),NQr=o("TFBlenderbotModel"),qQr=o(" (Blenderbot model)"),DQr=l(),q0=a("li"),xye=a("strong"),jQr=o("blenderbot-small"),GQr=o(" \u2014 "),hae=a("a"),OQr=o("TFBlenderbotSmallModel"),VQr=o(" (BlenderbotSmall model)"),XQr=l(),D0=a("li"),$ye=a("strong"),zQr=o("camembert"),QQr=o(" \u2014 "),uae=a("a"),WQr=o("TFCamembertModel"),UQr=o(" (CamemBERT model)"),HQr=l(),j0=a("li"),kye=a("strong"),JQr=o("clip"),YQr=o(" \u2014 "),pae=a("a"),ZQr=o("TFCLIPModel"),KQr=o(" (CLIP model)"),eWr=l(),G0=a("li"),Sye=a("strong"),oWr=o("convbert"),rWr=o(" \u2014 "),_ae=a("a"),tWr=o("TFConvBertModel"),aWr=o(" (ConvBERT model)"),nWr=l(),O0=a("li"),Rye=a("strong"),sWr=o("convnext"),lWr=o(" \u2014 "),bae=a("a"),iWr=o("TFConvNextModel"),dWr=o(" (ConvNeXT model)"),mWr=l(),V0=a("li"),Pye=a("strong"),cWr=o("ctrl"),fWr=o(" \u2014 "),vae=a("a"),gWr=o("TFCTRLModel"),hWr=o(" (CTRL model)"),uWr=l(),X0=a("li"),Bye=a("strong"),pWr=o("cvt"),_Wr=o(" \u2014 "),Fae=a("a"),bWr=o("TFCvtModel"),vWr=o(" (CvT model)"),FWr=l(),z0=a("li"),Iye=a("strong"),TWr=o("data2vec-vision"),MWr=o(" \u2014 "),Tae=a("a"),EWr=o("TFData2VecVisionModel"),CWr=o(" (Data2VecVision model)"),wWr=l(),Q0=a("li"),Nye=a("strong"),AWr=o("deberta"),LWr=o(" \u2014 "),Mae=a("a"),yWr=o("TFDebertaModel"),xWr=o(" (DeBERTa model)"),$Wr=l(),W0=a("li"),qye=a("strong"),kWr=o("deberta-v2"),SWr=o(" \u2014 "),Eae=a("a"),RWr=o("TFDebertaV2Model"),PWr=o(" (DeBERTa-v2 model)"),BWr=l(),U0=a("li"),Dye=a("strong"),IWr=o("deit"),NWr=o(" \u2014 "),Cae=a("a"),qWr=o("TFDeiTModel"),DWr=o(" (DeiT model)"),jWr=l(),H0=a("li"),jye=a("strong"),GWr=o("distilbert"),OWr=o(" \u2014 "),wae=a("a"),VWr=o("TFDistilBertModel"),XWr=o(" (DistilBERT model)"),zWr=l(),J0=a("li"),Gye=a("strong"),QWr=o("dpr"),WWr=o(" \u2014 "),Aae=a("a"),UWr=o("TFDPRQuestionEncoder"),HWr=o(" (DPR model)"),JWr=l(),Y0=a("li"),Oye=a("strong"),YWr=o("electra"),ZWr=o(" \u2014 "),Lae=a("a"),KWr=o("TFElectraModel"),eUr=o(" (ELECTRA model)"),oUr=l(),Z0=a("li"),Vye=a("strong"),rUr=o("esm"),tUr=o(" \u2014 "),yae=a("a"),aUr=o("TFEsmModel"),nUr=o(" (ESM model)"),sUr=l(),K0=a("li"),Xye=a("strong"),lUr=o("flaubert"),iUr=o(" \u2014 "),xae=a("a"),dUr=o("TFFlaubertModel"),mUr=o(" (FlauBERT model)"),cUr=l(),Dl=a("li"),zye=a("strong"),fUr=o("funnel"),gUr=o(" \u2014 "),$ae=a("a"),hUr=o("TFFunnelModel"),uUr=o(" or "),kae=a("a"),pUr=o("TFFunnelBaseModel"),_Ur=o(" (Funnel Transformer model)"),bUr=l(),ew=a("li"),Qye=a("strong"),vUr=o("gpt2"),FUr=o(" \u2014 "),Sae=a("a"),TUr=o("TFGPT2Model"),MUr=o(" (OpenAI GPT-2 model)"),EUr=l(),ow=a("li"),Wye=a("strong"),CUr=o("gptj"),wUr=o(" \u2014 "),Rae=a("a"),AUr=o("TFGPTJModel"),LUr=o(" (GPT-J model)"),yUr=l(),rw=a("li"),Uye=a("strong"),xUr=o("groupvit"),$Ur=o(" \u2014 "),Pae=a("a"),kUr=o("TFGroupViTModel"),SUr=o(" (GroupViT model)"),RUr=l(),tw=a("li"),Hye=a("strong"),PUr=o("hubert"),BUr=o(" \u2014 "),Bae=a("a"),IUr=o("TFHubertModel"),NUr=o(" (Hubert model)"),qUr=l(),aw=a("li"),Jye=a("strong"),DUr=o("layoutlm"),jUr=o(" \u2014 "),Iae=a("a"),GUr=o("TFLayoutLMModel"),OUr=o(" (LayoutLM model)"),VUr=l(),nw=a("li"),Yye=a("strong"),XUr=o("layoutlmv3"),zUr=o(" \u2014 "),Nae=a("a"),QUr=o("TFLayoutLMv3Model"),WUr=o(" (LayoutLMv3 model)"),UUr=l(),sw=a("li"),Zye=a("strong"),HUr=o("led"),JUr=o(" \u2014 "),qae=a("a"),YUr=o("TFLEDModel"),ZUr=o(" (LED model)"),KUr=l(),lw=a("li"),Kye=a("strong"),eHr=o("longformer"),oHr=o(" \u2014 "),Dae=a("a"),rHr=o("TFLongformerModel"),tHr=o(" (Longformer model)"),aHr=l(),iw=a("li"),e9e=a("strong"),nHr=o("lxmert"),sHr=o(" \u2014 "),jae=a("a"),lHr=o("TFLxmertModel"),iHr=o(" (LXMERT model)"),dHr=l(),dw=a("li"),o9e=a("strong"),mHr=o("marian"),cHr=o(" \u2014 "),Gae=a("a"),fHr=o("TFMarianModel"),gHr=o(" (Marian model)"),hHr=l(),mw=a("li"),r9e=a("strong"),uHr=o("mbart"),pHr=o(" \u2014 "),Oae=a("a"),_Hr=o("TFMBartModel"),bHr=o(" (mBART model)"),vHr=l(),cw=a("li"),t9e=a("strong"),FHr=o("mobilebert"),THr=o(" \u2014 "),Vae=a("a"),MHr=o("TFMobileBertModel"),EHr=o(" (MobileBERT model)"),CHr=l(),fw=a("li"),a9e=a("strong"),wHr=o("mobilevit"),AHr=o(" \u2014 "),Xae=a("a"),LHr=o("TFMobileViTModel"),yHr=o(" (MobileViT model)"),xHr=l(),gw=a("li"),n9e=a("strong"),$Hr=o("mpnet"),kHr=o(" \u2014 "),zae=a("a"),SHr=o("TFMPNetModel"),RHr=o(" (MPNet model)"),PHr=l(),hw=a("li"),s9e=a("strong"),BHr=o("mt5"),IHr=o(" \u2014 "),Qae=a("a"),NHr=o("TFMT5Model"),qHr=o(" (MT5 model)"),DHr=l(),uw=a("li"),l9e=a("strong"),jHr=o("openai-gpt"),GHr=o(" \u2014 "),Wae=a("a"),OHr=o("TFOpenAIGPTModel"),VHr=o(" (OpenAI GPT model)"),XHr=l(),pw=a("li"),i9e=a("strong"),zHr=o("opt"),QHr=o(" \u2014 "),Uae=a("a"),WHr=o("TFOPTModel"),UHr=o(" (OPT model)"),HHr=l(),_w=a("li"),d9e=a("strong"),JHr=o("pegasus"),YHr=o(" \u2014 "),Hae=a("a"),ZHr=o("TFPegasusModel"),KHr=o(" (Pegasus model)"),eJr=l(),bw=a("li"),m9e=a("strong"),oJr=o("regnet"),rJr=o(" \u2014 "),Jae=a("a"),tJr=o("TFRegNetModel"),aJr=o(" (RegNet model)"),nJr=l(),vw=a("li"),c9e=a("strong"),sJr=o("rembert"),lJr=o(" \u2014 "),Yae=a("a"),iJr=o("TFRemBertModel"),dJr=o(" (RemBERT model)"),mJr=l(),Fw=a("li"),f9e=a("strong"),cJr=o("resnet"),fJr=o(" \u2014 "),Zae=a("a"),gJr=o("TFResNetModel"),hJr=o(" (ResNet model)"),uJr=l(),Tw=a("li"),g9e=a("strong"),pJr=o("roberta"),_Jr=o(" \u2014 "),Kae=a("a"),bJr=o("TFRobertaModel"),vJr=o(" (RoBERTa model)"),FJr=l(),Mw=a("li"),h9e=a("strong"),TJr=o("roformer"),MJr=o(" \u2014 "),ene=a("a"),EJr=o("TFRoFormerModel"),CJr=o(" (RoFormer model)"),wJr=l(),Ew=a("li"),u9e=a("strong"),AJr=o("segformer"),LJr=o(" \u2014 "),one=a("a"),yJr=o("TFSegformerModel"),xJr=o(" (SegFormer model)"),$Jr=l(),Cw=a("li"),p9e=a("strong"),kJr=o("speech_to_text"),SJr=o(" \u2014 "),rne=a("a"),RJr=o("TFSpeech2TextModel"),PJr=o(" (Speech2Text model)"),BJr=l(),ww=a("li"),_9e=a("strong"),IJr=o("swin"),NJr=o(" \u2014 "),tne=a("a"),qJr=o("TFSwinModel"),DJr=o(" (Swin Transformer model)"),jJr=l(),Aw=a("li"),b9e=a("strong"),GJr=o("t5"),OJr=o(" \u2014 "),ane=a("a"),VJr=o("TFT5Model"),XJr=o(" (T5 model)"),zJr=l(),Lw=a("li"),v9e=a("strong"),QJr=o("tapas"),WJr=o(" \u2014 "),nne=a("a"),UJr=o("TFTapasModel"),HJr=o(" (TAPAS model)"),JJr=l(),yw=a("li"),F9e=a("strong"),YJr=o("transfo-xl"),ZJr=o(" \u2014 "),sne=a("a"),KJr=o("TFTransfoXLModel"),eYr=o(" (Transformer-XL model)"),oYr=l(),xw=a("li"),T9e=a("strong"),rYr=o("vit"),tYr=o(" \u2014 "),lne=a("a"),aYr=o("TFViTModel"),nYr=o(" (ViT model)"),sYr=l(),$w=a("li"),M9e=a("strong"),lYr=o("vit_mae"),iYr=o(" \u2014 "),ine=a("a"),dYr=o("TFViTMAEModel"),mYr=o(" (ViTMAE model)"),cYr=l(),kw=a("li"),E9e=a("strong"),fYr=o("wav2vec2"),gYr=o(" \u2014 "),dne=a("a"),hYr=o("TFWav2Vec2Model"),uYr=o(" (Wav2Vec2 model)"),pYr=l(),Sw=a("li"),C9e=a("strong"),_Yr=o("whisper"),bYr=o(" \u2014 "),mne=a("a"),vYr=o("TFWhisperModel"),FYr=o(" (Whisper model)"),TYr=l(),Rw=a("li"),w9e=a("strong"),MYr=o("xglm"),EYr=o(" \u2014 "),cne=a("a"),CYr=o("TFXGLMModel"),wYr=o(" (XGLM model)"),AYr=l(),Pw=a("li"),A9e=a("strong"),LYr=o("xlm"),yYr=o(" \u2014 "),fne=a("a"),xYr=o("TFXLMModel"),$Yr=o(" (XLM model)"),kYr=l(),Bw=a("li"),L9e=a("strong"),SYr=o("xlm-roberta"),RYr=o(" \u2014 "),gne=a("a"),PYr=o("TFXLMRobertaModel"),BYr=o(" (XLM-RoBERTa model)"),IYr=l(),Iw=a("li"),y9e=a("strong"),NYr=o("xlnet"),qYr=o(" \u2014 "),hne=a("a"),DYr=o("TFXLNetModel"),jYr=o(" (XLNet model)"),GYr=l(),F(Nw.$$.fragment),Bio=l(),Mc=a("h2"),qw=a("a"),x9e=a("span"),F(yP.$$.fragment),OYr=l(),$9e=a("span"),VYr=o("TFAutoModelForPreTraining"),Iio=l(),ur=a("div"),F(xP.$$.fragment),XYr=l(),Ec=a("p"),zYr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),une=a("a"),QYr=o("from_pretrained()"),WYr=o(" class method or the "),pne=a("a"),UYr=o("from_config()"),HYr=o(` class
method.`),JYr=l(),$P=a("p"),YYr=o("This class cannot be instantiated directly using "),k9e=a("code"),ZYr=o("__init__()"),KYr=o(" (throws an error)."),eZr=l(),ra=a("div"),F(kP.$$.fragment),oZr=l(),S9e=a("p"),rZr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),tZr=l(),Cc=a("p"),aZr=o(`Note:
Loading a model from its configuration file does `),R9e=a("strong"),nZr=o("not"),sZr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_ne=a("a"),lZr=o("from_pretrained()"),iZr=o(" to load the model weights."),dZr=l(),F(Dw.$$.fragment),mZr=l(),zr=a("div"),F(SP.$$.fragment),cZr=l(),P9e=a("p"),fZr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),gZr=l(),On=a("p"),hZr=o("The model class to instantiate is selected based on the "),B9e=a("code"),uZr=o("model_type"),pZr=o(` property of the config object (either
passed as an argument or loaded from `),I9e=a("code"),_Zr=o("pretrained_model_name_or_path"),bZr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N9e=a("code"),vZr=o("pretrained_model_name_or_path"),FZr=o(":"),TZr=l(),de=a("ul"),jw=a("li"),q9e=a("strong"),MZr=o("albert"),EZr=o(" \u2014 "),bne=a("a"),CZr=o("TFAlbertForPreTraining"),wZr=o(" (ALBERT model)"),AZr=l(),Gw=a("li"),D9e=a("strong"),LZr=o("bart"),yZr=o(" \u2014 "),vne=a("a"),xZr=o("TFBartForConditionalGeneration"),$Zr=o(" (BART model)"),kZr=l(),Ow=a("li"),j9e=a("strong"),SZr=o("bert"),RZr=o(" \u2014 "),Fne=a("a"),PZr=o("TFBertForPreTraining"),BZr=o(" (BERT model)"),IZr=l(),Vw=a("li"),G9e=a("strong"),NZr=o("camembert"),qZr=o(" \u2014 "),Tne=a("a"),DZr=o("TFCamembertForMaskedLM"),jZr=o(" (CamemBERT model)"),GZr=l(),Xw=a("li"),O9e=a("strong"),OZr=o("ctrl"),VZr=o(" \u2014 "),Mne=a("a"),XZr=o("TFCTRLLMHeadModel"),zZr=o(" (CTRL model)"),QZr=l(),zw=a("li"),V9e=a("strong"),WZr=o("distilbert"),UZr=o(" \u2014 "),Ene=a("a"),HZr=o("TFDistilBertForMaskedLM"),JZr=o(" (DistilBERT model)"),YZr=l(),Qw=a("li"),X9e=a("strong"),ZZr=o("electra"),KZr=o(" \u2014 "),Cne=a("a"),eKr=o("TFElectraForPreTraining"),oKr=o(" (ELECTRA model)"),rKr=l(),Ww=a("li"),z9e=a("strong"),tKr=o("flaubert"),aKr=o(" \u2014 "),wne=a("a"),nKr=o("TFFlaubertWithLMHeadModel"),sKr=o(" (FlauBERT model)"),lKr=l(),Uw=a("li"),Q9e=a("strong"),iKr=o("funnel"),dKr=o(" \u2014 "),Ane=a("a"),mKr=o("TFFunnelForPreTraining"),cKr=o(" (Funnel Transformer model)"),fKr=l(),Hw=a("li"),W9e=a("strong"),gKr=o("gpt2"),hKr=o(" \u2014 "),Lne=a("a"),uKr=o("TFGPT2LMHeadModel"),pKr=o(" (OpenAI GPT-2 model)"),_Kr=l(),Jw=a("li"),U9e=a("strong"),bKr=o("layoutlm"),vKr=o(" \u2014 "),yne=a("a"),FKr=o("TFLayoutLMForMaskedLM"),TKr=o(" (LayoutLM model)"),MKr=l(),Yw=a("li"),H9e=a("strong"),EKr=o("lxmert"),CKr=o(" \u2014 "),xne=a("a"),wKr=o("TFLxmertForPreTraining"),AKr=o(" (LXMERT model)"),LKr=l(),Zw=a("li"),J9e=a("strong"),yKr=o("mobilebert"),xKr=o(" \u2014 "),$ne=a("a"),$Kr=o("TFMobileBertForPreTraining"),kKr=o(" (MobileBERT model)"),SKr=l(),Kw=a("li"),Y9e=a("strong"),RKr=o("mpnet"),PKr=o(" \u2014 "),kne=a("a"),BKr=o("TFMPNetForMaskedLM"),IKr=o(" (MPNet model)"),NKr=l(),eA=a("li"),Z9e=a("strong"),qKr=o("openai-gpt"),DKr=o(" \u2014 "),Sne=a("a"),jKr=o("TFOpenAIGPTLMHeadModel"),GKr=o(" (OpenAI GPT model)"),OKr=l(),oA=a("li"),K9e=a("strong"),VKr=o("roberta"),XKr=o(" \u2014 "),Rne=a("a"),zKr=o("TFRobertaForMaskedLM"),QKr=o(" (RoBERTa model)"),WKr=l(),rA=a("li"),exe=a("strong"),UKr=o("t5"),HKr=o(" \u2014 "),Pne=a("a"),JKr=o("TFT5ForConditionalGeneration"),YKr=o(" (T5 model)"),ZKr=l(),tA=a("li"),oxe=a("strong"),KKr=o("tapas"),eet=o(" \u2014 "),Bne=a("a"),oet=o("TFTapasForMaskedLM"),ret=o(" (TAPAS model)"),tet=l(),aA=a("li"),rxe=a("strong"),aet=o("transfo-xl"),net=o(" \u2014 "),Ine=a("a"),set=o("TFTransfoXLLMHeadModel"),iet=o(" (Transformer-XL model)"),det=l(),nA=a("li"),txe=a("strong"),met=o("vit_mae"),cet=o(" \u2014 "),Nne=a("a"),fet=o("TFViTMAEForPreTraining"),get=o(" (ViTMAE model)"),het=l(),sA=a("li"),axe=a("strong"),uet=o("xlm"),pet=o(" \u2014 "),qne=a("a"),_et=o("TFXLMWithLMHeadModel"),bet=o(" (XLM model)"),vet=l(),lA=a("li"),nxe=a("strong"),Fet=o("xlm-roberta"),Tet=o(" \u2014 "),Dne=a("a"),Met=o("TFXLMRobertaForMaskedLM"),Eet=o(" (XLM-RoBERTa model)"),Cet=l(),iA=a("li"),sxe=a("strong"),wet=o("xlnet"),Aet=o(" \u2014 "),jne=a("a"),Let=o("TFXLNetLMHeadModel"),yet=o(" (XLNet model)"),xet=l(),F(dA.$$.fragment),Nio=l(),wc=a("h2"),mA=a("a"),lxe=a("span"),F(RP.$$.fragment),$et=l(),ixe=a("span"),ket=o("TFAutoModelForCausalLM"),qio=l(),pr=a("div"),F(PP.$$.fragment),Set=l(),Ac=a("p"),Ret=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Gne=a("a"),Pet=o("from_pretrained()"),Bet=o(" class method or the "),One=a("a"),Iet=o("from_config()"),Net=o(` class
method.`),qet=l(),BP=a("p"),Det=o("This class cannot be instantiated directly using "),dxe=a("code"),jet=o("__init__()"),Get=o(" (throws an error)."),Oet=l(),ta=a("div"),F(IP.$$.fragment),Vet=l(),mxe=a("p"),Xet=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),zet=l(),Lc=a("p"),Qet=o(`Note:
Loading a model from its configuration file does `),cxe=a("strong"),Wet=o("not"),Uet=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Vne=a("a"),Het=o("from_pretrained()"),Jet=o(" to load the model weights."),Yet=l(),F(cA.$$.fragment),Zet=l(),Qr=a("div"),F(NP.$$.fragment),Ket=l(),fxe=a("p"),eot=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),oot=l(),Vn=a("p"),rot=o("The model class to instantiate is selected based on the "),gxe=a("code"),tot=o("model_type"),aot=o(` property of the config object (either
passed as an argument or loaded from `),hxe=a("code"),not=o("pretrained_model_name_or_path"),sot=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uxe=a("code"),lot=o("pretrained_model_name_or_path"),iot=o(":"),dot=l(),Ce=a("ul"),fA=a("li"),pxe=a("strong"),mot=o("bert"),cot=o(" \u2014 "),Xne=a("a"),fot=o("TFBertLMHeadModel"),got=o(" (BERT model)"),hot=l(),gA=a("li"),_xe=a("strong"),uot=o("camembert"),pot=o(" \u2014 "),zne=a("a"),_ot=o("TFCamembertForCausalLM"),bot=o(" (CamemBERT model)"),vot=l(),hA=a("li"),bxe=a("strong"),Fot=o("ctrl"),Tot=o(" \u2014 "),Qne=a("a"),Mot=o("TFCTRLLMHeadModel"),Eot=o(" (CTRL model)"),Cot=l(),uA=a("li"),vxe=a("strong"),wot=o("gpt2"),Aot=o(" \u2014 "),Wne=a("a"),Lot=o("TFGPT2LMHeadModel"),yot=o(" (OpenAI GPT-2 model)"),xot=l(),pA=a("li"),Fxe=a("strong"),$ot=o("gptj"),kot=o(" \u2014 "),Une=a("a"),Sot=o("TFGPTJForCausalLM"),Rot=o(" (GPT-J model)"),Pot=l(),_A=a("li"),Txe=a("strong"),Bot=o("openai-gpt"),Iot=o(" \u2014 "),Hne=a("a"),Not=o("TFOpenAIGPTLMHeadModel"),qot=o(" (OpenAI GPT model)"),Dot=l(),bA=a("li"),Mxe=a("strong"),jot=o("opt"),Got=o(" \u2014 "),Jne=a("a"),Oot=o("TFOPTForCausalLM"),Vot=o(" (OPT model)"),Xot=l(),vA=a("li"),Exe=a("strong"),zot=o("rembert"),Qot=o(" \u2014 "),Yne=a("a"),Wot=o("TFRemBertForCausalLM"),Uot=o(" (RemBERT model)"),Hot=l(),FA=a("li"),Cxe=a("strong"),Jot=o("roberta"),Yot=o(" \u2014 "),Zne=a("a"),Zot=o("TFRobertaForCausalLM"),Kot=o(" (RoBERTa model)"),ert=l(),TA=a("li"),wxe=a("strong"),ort=o("roformer"),rrt=o(" \u2014 "),Kne=a("a"),trt=o("TFRoFormerForCausalLM"),art=o(" (RoFormer model)"),nrt=l(),MA=a("li"),Axe=a("strong"),srt=o("transfo-xl"),lrt=o(" \u2014 "),ese=a("a"),irt=o("TFTransfoXLLMHeadModel"),drt=o(" (Transformer-XL model)"),mrt=l(),EA=a("li"),Lxe=a("strong"),crt=o("xglm"),frt=o(" \u2014 "),ose=a("a"),grt=o("TFXGLMForCausalLM"),hrt=o(" (XGLM model)"),urt=l(),CA=a("li"),yxe=a("strong"),prt=o("xlm"),_rt=o(" \u2014 "),rse=a("a"),brt=o("TFXLMWithLMHeadModel"),vrt=o(" (XLM model)"),Frt=l(),wA=a("li"),xxe=a("strong"),Trt=o("xlnet"),Mrt=o(" \u2014 "),tse=a("a"),Ert=o("TFXLNetLMHeadModel"),Crt=o(" (XLNet model)"),wrt=l(),F(AA.$$.fragment),Dio=l(),yc=a("h2"),LA=a("a"),$xe=a("span"),F(qP.$$.fragment),Art=l(),kxe=a("span"),Lrt=o("TFAutoModelForImageClassification"),jio=l(),_r=a("div"),F(DP.$$.fragment),yrt=l(),xc=a("p"),xrt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),ase=a("a"),$rt=o("from_pretrained()"),krt=o(" class method or the "),nse=a("a"),Srt=o("from_config()"),Rrt=o(` class
method.`),Prt=l(),jP=a("p"),Brt=o("This class cannot be instantiated directly using "),Sxe=a("code"),Irt=o("__init__()"),Nrt=o(" (throws an error)."),qrt=l(),aa=a("div"),F(GP.$$.fragment),Drt=l(),Rxe=a("p"),jrt=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Grt=l(),$c=a("p"),Ort=o(`Note:
Loading a model from its configuration file does `),Pxe=a("strong"),Vrt=o("not"),Xrt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sse=a("a"),zrt=o("from_pretrained()"),Qrt=o(" to load the model weights."),Wrt=l(),F(yA.$$.fragment),Urt=l(),Wr=a("div"),F(OP.$$.fragment),Hrt=l(),Bxe=a("p"),Jrt=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Yrt=l(),Xn=a("p"),Zrt=o("The model class to instantiate is selected based on the "),Ixe=a("code"),Krt=o("model_type"),ett=o(` property of the config object (either
passed as an argument or loaded from `),Nxe=a("code"),ott=o("pretrained_model_name_or_path"),rtt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qxe=a("code"),ttt=o("pretrained_model_name_or_path"),att=o(":"),ntt=l(),$e=a("ul"),xA=a("li"),Dxe=a("strong"),stt=o("convnext"),ltt=o(" \u2014 "),lse=a("a"),itt=o("TFConvNextForImageClassification"),dtt=o(" (ConvNeXT model)"),mtt=l(),$A=a("li"),jxe=a("strong"),ctt=o("cvt"),ftt=o(" \u2014 "),ise=a("a"),gtt=o("TFCvtForImageClassification"),htt=o(" (CvT model)"),utt=l(),kA=a("li"),Gxe=a("strong"),ptt=o("data2vec-vision"),_tt=o(" \u2014 "),dse=a("a"),btt=o("TFData2VecVisionForImageClassification"),vtt=o(" (Data2VecVision model)"),Ftt=l(),jl=a("li"),Oxe=a("strong"),Ttt=o("deit"),Mtt=o(" \u2014 "),mse=a("a"),Ett=o("TFDeiTForImageClassification"),Ctt=o(" or "),cse=a("a"),wtt=o("TFDeiTForImageClassificationWithTeacher"),Att=o(" (DeiT model)"),Ltt=l(),SA=a("li"),Vxe=a("strong"),ytt=o("mobilevit"),xtt=o(" \u2014 "),fse=a("a"),$tt=o("TFMobileViTForImageClassification"),ktt=o(" (MobileViT model)"),Stt=l(),RA=a("li"),Xxe=a("strong"),Rtt=o("regnet"),Ptt=o(" \u2014 "),gse=a("a"),Btt=o("TFRegNetForImageClassification"),Itt=o(" (RegNet model)"),Ntt=l(),PA=a("li"),zxe=a("strong"),qtt=o("resnet"),Dtt=o(" \u2014 "),hse=a("a"),jtt=o("TFResNetForImageClassification"),Gtt=o(" (ResNet model)"),Ott=l(),BA=a("li"),Qxe=a("strong"),Vtt=o("segformer"),Xtt=o(" \u2014 "),use=a("a"),ztt=o("TFSegformerForImageClassification"),Qtt=o(" (SegFormer model)"),Wtt=l(),IA=a("li"),Wxe=a("strong"),Utt=o("swin"),Htt=o(" \u2014 "),pse=a("a"),Jtt=o("TFSwinForImageClassification"),Ytt=o(" (Swin Transformer model)"),Ztt=l(),NA=a("li"),Uxe=a("strong"),Ktt=o("vit"),eat=o(" \u2014 "),_se=a("a"),oat=o("TFViTForImageClassification"),rat=o(" (ViT model)"),tat=l(),F(qA.$$.fragment),Gio=l(),kc=a("h2"),DA=a("a"),Hxe=a("span"),F(VP.$$.fragment),aat=l(),Jxe=a("span"),nat=o("TFAutoModelForSemanticSegmentation"),Oio=l(),br=a("div"),F(XP.$$.fragment),sat=l(),Sc=a("p"),lat=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),bse=a("a"),iat=o("from_pretrained()"),dat=o(" class method or the "),vse=a("a"),mat=o("from_config()"),cat=o(` class
method.`),fat=l(),zP=a("p"),gat=o("This class cannot be instantiated directly using "),Yxe=a("code"),hat=o("__init__()"),uat=o(" (throws an error)."),pat=l(),na=a("div"),F(QP.$$.fragment),_at=l(),Zxe=a("p"),bat=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),vat=l(),Rc=a("p"),Fat=o(`Note:
Loading a model from its configuration file does `),Kxe=a("strong"),Tat=o("not"),Mat=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Fse=a("a"),Eat=o("from_pretrained()"),Cat=o(" to load the model weights."),wat=l(),F(jA.$$.fragment),Aat=l(),Ur=a("div"),F(WP.$$.fragment),Lat=l(),e$e=a("p"),yat=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),xat=l(),zn=a("p"),$at=o("The model class to instantiate is selected based on the "),o$e=a("code"),kat=o("model_type"),Sat=o(` property of the config object (either
passed as an argument or loaded from `),r$e=a("code"),Rat=o("pretrained_model_name_or_path"),Pat=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),t$e=a("code"),Bat=o("pretrained_model_name_or_path"),Iat=o(":"),Nat=l(),Pc=a("ul"),GA=a("li"),a$e=a("strong"),qat=o("data2vec-vision"),Dat=o(" \u2014 "),Tse=a("a"),jat=o("TFData2VecVisionForSemanticSegmentation"),Gat=o(" (Data2VecVision model)"),Oat=l(),OA=a("li"),n$e=a("strong"),Vat=o("mobilevit"),Xat=o(" \u2014 "),Mse=a("a"),zat=o("TFMobileViTForSemanticSegmentation"),Qat=o(" (MobileViT model)"),Wat=l(),VA=a("li"),s$e=a("strong"),Uat=o("segformer"),Hat=o(" \u2014 "),Ese=a("a"),Jat=o("TFSegformerForSemanticSegmentation"),Yat=o(" (SegFormer model)"),Zat=l(),F(XA.$$.fragment),Vio=l(),Bc=a("h2"),zA=a("a"),l$e=a("span"),F(UP.$$.fragment),Kat=l(),i$e=a("span"),ent=o("TFAutoModelForMaskedLM"),Xio=l(),vr=a("div"),F(HP.$$.fragment),ont=l(),Ic=a("p"),rnt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Cse=a("a"),tnt=o("from_pretrained()"),ant=o(" class method or the "),wse=a("a"),nnt=o("from_config()"),snt=o(` class
method.`),lnt=l(),JP=a("p"),int=o("This class cannot be instantiated directly using "),d$e=a("code"),dnt=o("__init__()"),mnt=o(" (throws an error)."),cnt=l(),sa=a("div"),F(YP.$$.fragment),fnt=l(),m$e=a("p"),gnt=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),hnt=l(),Nc=a("p"),unt=o(`Note:
Loading a model from its configuration file does `),c$e=a("strong"),pnt=o("not"),_nt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ase=a("a"),bnt=o("from_pretrained()"),vnt=o(" to load the model weights."),Fnt=l(),F(QA.$$.fragment),Tnt=l(),Hr=a("div"),F(ZP.$$.fragment),Mnt=l(),f$e=a("p"),Ent=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Cnt=l(),Qn=a("p"),wnt=o("The model class to instantiate is selected based on the "),g$e=a("code"),Ant=o("model_type"),Lnt=o(` property of the config object (either
passed as an argument or loaded from `),h$e=a("code"),ynt=o("pretrained_model_name_or_path"),xnt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u$e=a("code"),$nt=o("pretrained_model_name_or_path"),knt=o(":"),Snt=l(),ge=a("ul"),WA=a("li"),p$e=a("strong"),Rnt=o("albert"),Pnt=o(" \u2014 "),Lse=a("a"),Bnt=o("TFAlbertForMaskedLM"),Int=o(" (ALBERT model)"),Nnt=l(),UA=a("li"),_$e=a("strong"),qnt=o("bert"),Dnt=o(" \u2014 "),yse=a("a"),jnt=o("TFBertForMaskedLM"),Gnt=o(" (BERT model)"),Ont=l(),HA=a("li"),b$e=a("strong"),Vnt=o("camembert"),Xnt=o(" \u2014 "),xse=a("a"),znt=o("TFCamembertForMaskedLM"),Qnt=o(" (CamemBERT model)"),Wnt=l(),JA=a("li"),v$e=a("strong"),Unt=o("convbert"),Hnt=o(" \u2014 "),$se=a("a"),Jnt=o("TFConvBertForMaskedLM"),Ynt=o(" (ConvBERT model)"),Znt=l(),YA=a("li"),F$e=a("strong"),Knt=o("deberta"),est=o(" \u2014 "),kse=a("a"),ost=o("TFDebertaForMaskedLM"),rst=o(" (DeBERTa model)"),tst=l(),ZA=a("li"),T$e=a("strong"),ast=o("deberta-v2"),nst=o(" \u2014 "),Sse=a("a"),sst=o("TFDebertaV2ForMaskedLM"),lst=o(" (DeBERTa-v2 model)"),ist=l(),KA=a("li"),M$e=a("strong"),dst=o("distilbert"),mst=o(" \u2014 "),Rse=a("a"),cst=o("TFDistilBertForMaskedLM"),fst=o(" (DistilBERT model)"),gst=l(),e6=a("li"),E$e=a("strong"),hst=o("electra"),ust=o(" \u2014 "),Pse=a("a"),pst=o("TFElectraForMaskedLM"),_st=o(" (ELECTRA model)"),bst=l(),o6=a("li"),C$e=a("strong"),vst=o("esm"),Fst=o(" \u2014 "),Bse=a("a"),Tst=o("TFEsmForMaskedLM"),Mst=o(" (ESM model)"),Est=l(),r6=a("li"),w$e=a("strong"),Cst=o("flaubert"),wst=o(" \u2014 "),Ise=a("a"),Ast=o("TFFlaubertWithLMHeadModel"),Lst=o(" (FlauBERT model)"),yst=l(),t6=a("li"),A$e=a("strong"),xst=o("funnel"),$st=o(" \u2014 "),Nse=a("a"),kst=o("TFFunnelForMaskedLM"),Sst=o(" (Funnel Transformer model)"),Rst=l(),a6=a("li"),L$e=a("strong"),Pst=o("layoutlm"),Bst=o(" \u2014 "),qse=a("a"),Ist=o("TFLayoutLMForMaskedLM"),Nst=o(" (LayoutLM model)"),qst=l(),n6=a("li"),y$e=a("strong"),Dst=o("longformer"),jst=o(" \u2014 "),Dse=a("a"),Gst=o("TFLongformerForMaskedLM"),Ost=o(" (Longformer model)"),Vst=l(),s6=a("li"),x$e=a("strong"),Xst=o("mobilebert"),zst=o(" \u2014 "),jse=a("a"),Qst=o("TFMobileBertForMaskedLM"),Wst=o(" (MobileBERT model)"),Ust=l(),l6=a("li"),$$e=a("strong"),Hst=o("mpnet"),Jst=o(" \u2014 "),Gse=a("a"),Yst=o("TFMPNetForMaskedLM"),Zst=o(" (MPNet model)"),Kst=l(),i6=a("li"),k$e=a("strong"),elt=o("rembert"),olt=o(" \u2014 "),Ose=a("a"),rlt=o("TFRemBertForMaskedLM"),tlt=o(" (RemBERT model)"),alt=l(),d6=a("li"),S$e=a("strong"),nlt=o("roberta"),slt=o(" \u2014 "),Vse=a("a"),llt=o("TFRobertaForMaskedLM"),ilt=o(" (RoBERTa model)"),dlt=l(),m6=a("li"),R$e=a("strong"),mlt=o("roformer"),clt=o(" \u2014 "),Xse=a("a"),flt=o("TFRoFormerForMaskedLM"),glt=o(" (RoFormer model)"),hlt=l(),c6=a("li"),P$e=a("strong"),ult=o("tapas"),plt=o(" \u2014 "),zse=a("a"),_lt=o("TFTapasForMaskedLM"),blt=o(" (TAPAS model)"),vlt=l(),f6=a("li"),B$e=a("strong"),Flt=o("xlm"),Tlt=o(" \u2014 "),Qse=a("a"),Mlt=o("TFXLMWithLMHeadModel"),Elt=o(" (XLM model)"),Clt=l(),g6=a("li"),I$e=a("strong"),wlt=o("xlm-roberta"),Alt=o(" \u2014 "),Wse=a("a"),Llt=o("TFXLMRobertaForMaskedLM"),ylt=o(" (XLM-RoBERTa model)"),xlt=l(),F(h6.$$.fragment),zio=l(),qc=a("h2"),u6=a("a"),N$e=a("span"),F(KP.$$.fragment),$lt=l(),q$e=a("span"),klt=o("TFAutoModelForSeq2SeqLM"),Qio=l(),Fr=a("div"),F(eB.$$.fragment),Slt=l(),Dc=a("p"),Rlt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Use=a("a"),Plt=o("from_pretrained()"),Blt=o(" class method or the "),Hse=a("a"),Ilt=o("from_config()"),Nlt=o(` class
method.`),qlt=l(),oB=a("p"),Dlt=o("This class cannot be instantiated directly using "),D$e=a("code"),jlt=o("__init__()"),Glt=o(" (throws an error)."),Olt=l(),la=a("div"),F(rB.$$.fragment),Vlt=l(),j$e=a("p"),Xlt=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),zlt=l(),jc=a("p"),Qlt=o(`Note:
Loading a model from its configuration file does `),G$e=a("strong"),Wlt=o("not"),Ult=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Jse=a("a"),Hlt=o("from_pretrained()"),Jlt=o(" to load the model weights."),Ylt=l(),F(p6.$$.fragment),Zlt=l(),Jr=a("div"),F(tB.$$.fragment),Klt=l(),O$e=a("p"),eit=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),oit=l(),Wn=a("p"),rit=o("The model class to instantiate is selected based on the "),V$e=a("code"),tit=o("model_type"),ait=o(` property of the config object (either
passed as an argument or loaded from `),X$e=a("code"),nit=o("pretrained_model_name_or_path"),sit=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z$e=a("code"),lit=o("pretrained_model_name_or_path"),iit=o(":"),dit=l(),ke=a("ul"),_6=a("li"),Q$e=a("strong"),mit=o("bart"),cit=o(" \u2014 "),Yse=a("a"),fit=o("TFBartForConditionalGeneration"),git=o(" (BART model)"),hit=l(),b6=a("li"),W$e=a("strong"),uit=o("blenderbot"),pit=o(" \u2014 "),Zse=a("a"),_it=o("TFBlenderbotForConditionalGeneration"),bit=o(" (Blenderbot model)"),vit=l(),v6=a("li"),U$e=a("strong"),Fit=o("blenderbot-small"),Tit=o(" \u2014 "),Kse=a("a"),Mit=o("TFBlenderbotSmallForConditionalGeneration"),Eit=o(" (BlenderbotSmall model)"),Cit=l(),F6=a("li"),H$e=a("strong"),wit=o("encoder-decoder"),Ait=o(" \u2014 "),ele=a("a"),Lit=o("TFEncoderDecoderModel"),yit=o(" (Encoder decoder model)"),xit=l(),T6=a("li"),J$e=a("strong"),$it=o("led"),kit=o(" \u2014 "),ole=a("a"),Sit=o("TFLEDForConditionalGeneration"),Rit=o(" (LED model)"),Pit=l(),M6=a("li"),Y$e=a("strong"),Bit=o("marian"),Iit=o(" \u2014 "),rle=a("a"),Nit=o("TFMarianMTModel"),qit=o(" (Marian model)"),Dit=l(),E6=a("li"),Z$e=a("strong"),jit=o("mbart"),Git=o(" \u2014 "),tle=a("a"),Oit=o("TFMBartForConditionalGeneration"),Vit=o(" (mBART model)"),Xit=l(),C6=a("li"),K$e=a("strong"),zit=o("mt5"),Qit=o(" \u2014 "),ale=a("a"),Wit=o("TFMT5ForConditionalGeneration"),Uit=o(" (MT5 model)"),Hit=l(),w6=a("li"),eke=a("strong"),Jit=o("pegasus"),Yit=o(" \u2014 "),nle=a("a"),Zit=o("TFPegasusForConditionalGeneration"),Kit=o(" (Pegasus model)"),edt=l(),A6=a("li"),oke=a("strong"),odt=o("t5"),rdt=o(" \u2014 "),sle=a("a"),tdt=o("TFT5ForConditionalGeneration"),adt=o(" (T5 model)"),ndt=l(),F(L6.$$.fragment),Wio=l(),Gc=a("h2"),y6=a("a"),rke=a("span"),F(aB.$$.fragment),sdt=l(),tke=a("span"),ldt=o("TFAutoModelForSequenceClassification"),Uio=l(),Tr=a("div"),F(nB.$$.fragment),idt=l(),Oc=a("p"),ddt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),lle=a("a"),mdt=o("from_pretrained()"),cdt=o(" class method or the "),ile=a("a"),fdt=o("from_config()"),gdt=o(` class
method.`),hdt=l(),sB=a("p"),udt=o("This class cannot be instantiated directly using "),ake=a("code"),pdt=o("__init__()"),_dt=o(" (throws an error)."),bdt=l(),ia=a("div"),F(lB.$$.fragment),vdt=l(),nke=a("p"),Fdt=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Tdt=l(),Vc=a("p"),Mdt=o(`Note:
Loading a model from its configuration file does `),ske=a("strong"),Edt=o("not"),Cdt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dle=a("a"),wdt=o("from_pretrained()"),Adt=o(" to load the model weights."),Ldt=l(),F(x6.$$.fragment),ydt=l(),Yr=a("div"),F(iB.$$.fragment),xdt=l(),lke=a("p"),$dt=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),kdt=l(),Un=a("p"),Sdt=o("The model class to instantiate is selected based on the "),ike=a("code"),Rdt=o("model_type"),Pdt=o(` property of the config object (either
passed as an argument or loaded from `),dke=a("code"),Bdt=o("pretrained_model_name_or_path"),Idt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mke=a("code"),Ndt=o("pretrained_model_name_or_path"),qdt=o(":"),Ddt=l(),te=a("ul"),$6=a("li"),cke=a("strong"),jdt=o("albert"),Gdt=o(" \u2014 "),mle=a("a"),Odt=o("TFAlbertForSequenceClassification"),Vdt=o(" (ALBERT model)"),Xdt=l(),k6=a("li"),fke=a("strong"),zdt=o("bert"),Qdt=o(" \u2014 "),cle=a("a"),Wdt=o("TFBertForSequenceClassification"),Udt=o(" (BERT model)"),Hdt=l(),S6=a("li"),gke=a("strong"),Jdt=o("camembert"),Ydt=o(" \u2014 "),fle=a("a"),Zdt=o("TFCamembertForSequenceClassification"),Kdt=o(" (CamemBERT model)"),emt=l(),R6=a("li"),hke=a("strong"),omt=o("convbert"),rmt=o(" \u2014 "),gle=a("a"),tmt=o("TFConvBertForSequenceClassification"),amt=o(" (ConvBERT model)"),nmt=l(),P6=a("li"),uke=a("strong"),smt=o("ctrl"),lmt=o(" \u2014 "),hle=a("a"),imt=o("TFCTRLForSequenceClassification"),dmt=o(" (CTRL model)"),mmt=l(),B6=a("li"),pke=a("strong"),cmt=o("deberta"),fmt=o(" \u2014 "),ule=a("a"),gmt=o("TFDebertaForSequenceClassification"),hmt=o(" (DeBERTa model)"),umt=l(),I6=a("li"),_ke=a("strong"),pmt=o("deberta-v2"),_mt=o(" \u2014 "),ple=a("a"),bmt=o("TFDebertaV2ForSequenceClassification"),vmt=o(" (DeBERTa-v2 model)"),Fmt=l(),N6=a("li"),bke=a("strong"),Tmt=o("distilbert"),Mmt=o(" \u2014 "),_le=a("a"),Emt=o("TFDistilBertForSequenceClassification"),Cmt=o(" (DistilBERT model)"),wmt=l(),q6=a("li"),vke=a("strong"),Amt=o("electra"),Lmt=o(" \u2014 "),ble=a("a"),ymt=o("TFElectraForSequenceClassification"),xmt=o(" (ELECTRA model)"),$mt=l(),D6=a("li"),Fke=a("strong"),kmt=o("esm"),Smt=o(" \u2014 "),vle=a("a"),Rmt=o("TFEsmForSequenceClassification"),Pmt=o(" (ESM model)"),Bmt=l(),j6=a("li"),Tke=a("strong"),Imt=o("flaubert"),Nmt=o(" \u2014 "),Fle=a("a"),qmt=o("TFFlaubertForSequenceClassification"),Dmt=o(" (FlauBERT model)"),jmt=l(),G6=a("li"),Mke=a("strong"),Gmt=o("funnel"),Omt=o(" \u2014 "),Tle=a("a"),Vmt=o("TFFunnelForSequenceClassification"),Xmt=o(" (Funnel Transformer model)"),zmt=l(),O6=a("li"),Eke=a("strong"),Qmt=o("gpt2"),Wmt=o(" \u2014 "),Mle=a("a"),Umt=o("TFGPT2ForSequenceClassification"),Hmt=o(" (OpenAI GPT-2 model)"),Jmt=l(),V6=a("li"),Cke=a("strong"),Ymt=o("gptj"),Zmt=o(" \u2014 "),Ele=a("a"),Kmt=o("TFGPTJForSequenceClassification"),ect=o(" (GPT-J model)"),oct=l(),X6=a("li"),wke=a("strong"),rct=o("layoutlm"),tct=o(" \u2014 "),Cle=a("a"),act=o("TFLayoutLMForSequenceClassification"),nct=o(" (LayoutLM model)"),sct=l(),z6=a("li"),Ake=a("strong"),lct=o("layoutlmv3"),ict=o(" \u2014 "),wle=a("a"),dct=o("TFLayoutLMv3ForSequenceClassification"),mct=o(" (LayoutLMv3 model)"),cct=l(),Q6=a("li"),Lke=a("strong"),fct=o("longformer"),gct=o(" \u2014 "),Ale=a("a"),hct=o("TFLongformerForSequenceClassification"),uct=o(" (Longformer model)"),pct=l(),W6=a("li"),yke=a("strong"),_ct=o("mobilebert"),bct=o(" \u2014 "),Lle=a("a"),vct=o("TFMobileBertForSequenceClassification"),Fct=o(" (MobileBERT model)"),Tct=l(),U6=a("li"),xke=a("strong"),Mct=o("mpnet"),Ect=o(" \u2014 "),yle=a("a"),Cct=o("TFMPNetForSequenceClassification"),wct=o(" (MPNet model)"),Act=l(),H6=a("li"),$ke=a("strong"),Lct=o("openai-gpt"),yct=o(" \u2014 "),xle=a("a"),xct=o("TFOpenAIGPTForSequenceClassification"),$ct=o(" (OpenAI GPT model)"),kct=l(),J6=a("li"),kke=a("strong"),Sct=o("rembert"),Rct=o(" \u2014 "),$le=a("a"),Pct=o("TFRemBertForSequenceClassification"),Bct=o(" (RemBERT model)"),Ict=l(),Y6=a("li"),Ske=a("strong"),Nct=o("roberta"),qct=o(" \u2014 "),kle=a("a"),Dct=o("TFRobertaForSequenceClassification"),jct=o(" (RoBERTa model)"),Gct=l(),Z6=a("li"),Rke=a("strong"),Oct=o("roformer"),Vct=o(" \u2014 "),Sle=a("a"),Xct=o("TFRoFormerForSequenceClassification"),zct=o(" (RoFormer model)"),Qct=l(),K6=a("li"),Pke=a("strong"),Wct=o("tapas"),Uct=o(" \u2014 "),Rle=a("a"),Hct=o("TFTapasForSequenceClassification"),Jct=o(" (TAPAS model)"),Yct=l(),e7=a("li"),Bke=a("strong"),Zct=o("transfo-xl"),Kct=o(" \u2014 "),Ple=a("a"),eft=o("TFTransfoXLForSequenceClassification"),oft=o(" (Transformer-XL model)"),rft=l(),o7=a("li"),Ike=a("strong"),tft=o("xlm"),aft=o(" \u2014 "),Ble=a("a"),nft=o("TFXLMForSequenceClassification"),sft=o(" (XLM model)"),lft=l(),r7=a("li"),Nke=a("strong"),ift=o("xlm-roberta"),dft=o(" \u2014 "),Ile=a("a"),mft=o("TFXLMRobertaForSequenceClassification"),cft=o(" (XLM-RoBERTa model)"),fft=l(),t7=a("li"),qke=a("strong"),gft=o("xlnet"),hft=o(" \u2014 "),Nle=a("a"),uft=o("TFXLNetForSequenceClassification"),pft=o(" (XLNet model)"),_ft=l(),F(a7.$$.fragment),Hio=l(),Xc=a("h2"),n7=a("a"),Dke=a("span"),F(dB.$$.fragment),bft=l(),jke=a("span"),vft=o("TFAutoModelForMultipleChoice"),Jio=l(),Mr=a("div"),F(mB.$$.fragment),Fft=l(),zc=a("p"),Tft=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),qle=a("a"),Mft=o("from_pretrained()"),Eft=o(" class method or the "),Dle=a("a"),Cft=o("from_config()"),wft=o(` class
method.`),Aft=l(),cB=a("p"),Lft=o("This class cannot be instantiated directly using "),Gke=a("code"),yft=o("__init__()"),xft=o(" (throws an error)."),$ft=l(),da=a("div"),F(fB.$$.fragment),kft=l(),Oke=a("p"),Sft=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Rft=l(),Qc=a("p"),Pft=o(`Note:
Loading a model from its configuration file does `),Vke=a("strong"),Bft=o("not"),Ift=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jle=a("a"),Nft=o("from_pretrained()"),qft=o(" to load the model weights."),Dft=l(),F(s7.$$.fragment),jft=l(),Zr=a("div"),F(gB.$$.fragment),Gft=l(),Xke=a("p"),Oft=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Vft=l(),Hn=a("p"),Xft=o("The model class to instantiate is selected based on the "),zke=a("code"),zft=o("model_type"),Qft=o(` property of the config object (either
passed as an argument or loaded from `),Qke=a("code"),Wft=o("pretrained_model_name_or_path"),Uft=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wke=a("code"),Hft=o("pretrained_model_name_or_path"),Jft=o(":"),Yft=l(),Te=a("ul"),l7=a("li"),Uke=a("strong"),Zft=o("albert"),Kft=o(" \u2014 "),Gle=a("a"),egt=o("TFAlbertForMultipleChoice"),ogt=o(" (ALBERT model)"),rgt=l(),i7=a("li"),Hke=a("strong"),tgt=o("bert"),agt=o(" \u2014 "),Ole=a("a"),ngt=o("TFBertForMultipleChoice"),sgt=o(" (BERT model)"),lgt=l(),d7=a("li"),Jke=a("strong"),igt=o("camembert"),dgt=o(" \u2014 "),Vle=a("a"),mgt=o("TFCamembertForMultipleChoice"),cgt=o(" (CamemBERT model)"),fgt=l(),m7=a("li"),Yke=a("strong"),ggt=o("convbert"),hgt=o(" \u2014 "),Xle=a("a"),ugt=o("TFConvBertForMultipleChoice"),pgt=o(" (ConvBERT model)"),_gt=l(),c7=a("li"),Zke=a("strong"),bgt=o("distilbert"),vgt=o(" \u2014 "),zle=a("a"),Fgt=o("TFDistilBertForMultipleChoice"),Tgt=o(" (DistilBERT model)"),Mgt=l(),f7=a("li"),Kke=a("strong"),Egt=o("electra"),Cgt=o(" \u2014 "),Qle=a("a"),wgt=o("TFElectraForMultipleChoice"),Agt=o(" (ELECTRA model)"),Lgt=l(),g7=a("li"),eSe=a("strong"),ygt=o("flaubert"),xgt=o(" \u2014 "),Wle=a("a"),$gt=o("TFFlaubertForMultipleChoice"),kgt=o(" (FlauBERT model)"),Sgt=l(),h7=a("li"),oSe=a("strong"),Rgt=o("funnel"),Pgt=o(" \u2014 "),Ule=a("a"),Bgt=o("TFFunnelForMultipleChoice"),Igt=o(" (Funnel Transformer model)"),Ngt=l(),u7=a("li"),rSe=a("strong"),qgt=o("longformer"),Dgt=o(" \u2014 "),Hle=a("a"),jgt=o("TFLongformerForMultipleChoice"),Ggt=o(" (Longformer model)"),Ogt=l(),p7=a("li"),tSe=a("strong"),Vgt=o("mobilebert"),Xgt=o(" \u2014 "),Jle=a("a"),zgt=o("TFMobileBertForMultipleChoice"),Qgt=o(" (MobileBERT model)"),Wgt=l(),_7=a("li"),aSe=a("strong"),Ugt=o("mpnet"),Hgt=o(" \u2014 "),Yle=a("a"),Jgt=o("TFMPNetForMultipleChoice"),Ygt=o(" (MPNet model)"),Zgt=l(),b7=a("li"),nSe=a("strong"),Kgt=o("rembert"),eht=o(" \u2014 "),Zle=a("a"),oht=o("TFRemBertForMultipleChoice"),rht=o(" (RemBERT model)"),tht=l(),v7=a("li"),sSe=a("strong"),aht=o("roberta"),nht=o(" \u2014 "),Kle=a("a"),sht=o("TFRobertaForMultipleChoice"),lht=o(" (RoBERTa model)"),iht=l(),F7=a("li"),lSe=a("strong"),dht=o("roformer"),mht=o(" \u2014 "),eie=a("a"),cht=o("TFRoFormerForMultipleChoice"),fht=o(" (RoFormer model)"),ght=l(),T7=a("li"),iSe=a("strong"),hht=o("xlm"),uht=o(" \u2014 "),oie=a("a"),pht=o("TFXLMForMultipleChoice"),_ht=o(" (XLM model)"),bht=l(),M7=a("li"),dSe=a("strong"),vht=o("xlm-roberta"),Fht=o(" \u2014 "),rie=a("a"),Tht=o("TFXLMRobertaForMultipleChoice"),Mht=o(" (XLM-RoBERTa model)"),Eht=l(),E7=a("li"),mSe=a("strong"),Cht=o("xlnet"),wht=o(" \u2014 "),tie=a("a"),Aht=o("TFXLNetForMultipleChoice"),Lht=o(" (XLNet model)"),yht=l(),F(C7.$$.fragment),Yio=l(),Wc=a("h2"),w7=a("a"),cSe=a("span"),F(hB.$$.fragment),xht=l(),fSe=a("span"),$ht=o("TFAutoModelForNextSentencePrediction"),Zio=l(),Er=a("div"),F(uB.$$.fragment),kht=l(),Uc=a("p"),Sht=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),aie=a("a"),Rht=o("from_pretrained()"),Pht=o(" class method or the "),nie=a("a"),Bht=o("from_config()"),Iht=o(` class
method.`),Nht=l(),pB=a("p"),qht=o("This class cannot be instantiated directly using "),gSe=a("code"),Dht=o("__init__()"),jht=o(" (throws an error)."),Ght=l(),ma=a("div"),F(_B.$$.fragment),Oht=l(),hSe=a("p"),Vht=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Xht=l(),Hc=a("p"),zht=o(`Note:
Loading a model from its configuration file does `),uSe=a("strong"),Qht=o("not"),Wht=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sie=a("a"),Uht=o("from_pretrained()"),Hht=o(" to load the model weights."),Jht=l(),F(A7.$$.fragment),Yht=l(),Kr=a("div"),F(bB.$$.fragment),Zht=l(),pSe=a("p"),Kht=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),eut=l(),Jn=a("p"),out=o("The model class to instantiate is selected based on the "),_Se=a("code"),rut=o("model_type"),tut=o(` property of the config object (either
passed as an argument or loaded from `),bSe=a("code"),aut=o("pretrained_model_name_or_path"),nut=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vSe=a("code"),sut=o("pretrained_model_name_or_path"),lut=o(":"),iut=l(),vB=a("ul"),L7=a("li"),FSe=a("strong"),dut=o("bert"),mut=o(" \u2014 "),lie=a("a"),cut=o("TFBertForNextSentencePrediction"),fut=o(" (BERT model)"),gut=l(),y7=a("li"),TSe=a("strong"),hut=o("mobilebert"),uut=o(" \u2014 "),iie=a("a"),put=o("TFMobileBertForNextSentencePrediction"),_ut=o(" (MobileBERT model)"),but=l(),F(x7.$$.fragment),Kio=l(),Jc=a("h2"),$7=a("a"),MSe=a("span"),F(FB.$$.fragment),vut=l(),ESe=a("span"),Fut=o("TFAutoModelForTableQuestionAnswering"),edo=l(),Cr=a("div"),F(TB.$$.fragment),Tut=l(),Yc=a("p"),Mut=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),die=a("a"),Eut=o("from_pretrained()"),Cut=o(" class method or the "),mie=a("a"),wut=o("from_config()"),Aut=o(` class
method.`),Lut=l(),MB=a("p"),yut=o("This class cannot be instantiated directly using "),CSe=a("code"),xut=o("__init__()"),$ut=o(" (throws an error)."),kut=l(),ca=a("div"),F(EB.$$.fragment),Sut=l(),wSe=a("p"),Rut=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Put=l(),Zc=a("p"),But=o(`Note:
Loading a model from its configuration file does `),ASe=a("strong"),Iut=o("not"),Nut=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cie=a("a"),qut=o("from_pretrained()"),Dut=o(" to load the model weights."),jut=l(),F(k7.$$.fragment),Gut=l(),et=a("div"),F(CB.$$.fragment),Out=l(),LSe=a("p"),Vut=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Xut=l(),Yn=a("p"),zut=o("The model class to instantiate is selected based on the "),ySe=a("code"),Qut=o("model_type"),Wut=o(` property of the config object (either
passed as an argument or loaded from `),xSe=a("code"),Uut=o("pretrained_model_name_or_path"),Hut=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$Se=a("code"),Jut=o("pretrained_model_name_or_path"),Yut=o(":"),Zut=l(),kSe=a("ul"),S7=a("li"),SSe=a("strong"),Kut=o("tapas"),ept=o(" \u2014 "),fie=a("a"),opt=o("TFTapasForQuestionAnswering"),rpt=o(" (TAPAS model)"),tpt=l(),F(R7.$$.fragment),odo=l(),Kc=a("h2"),P7=a("a"),RSe=a("span"),F(wB.$$.fragment),apt=l(),PSe=a("span"),npt=o("TFAutoModelForDocumentQuestionAnswering"),rdo=l(),wr=a("div"),F(AB.$$.fragment),spt=l(),ef=a("p"),lpt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),gie=a("a"),ipt=o("from_pretrained()"),dpt=o(" class method or the "),hie=a("a"),mpt=o("from_config()"),cpt=o(` class
method.`),fpt=l(),LB=a("p"),gpt=o("This class cannot be instantiated directly using "),BSe=a("code"),hpt=o("__init__()"),upt=o(" (throws an error)."),ppt=l(),fa=a("div"),F(yB.$$.fragment),_pt=l(),ISe=a("p"),bpt=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),vpt=l(),of=a("p"),Fpt=o(`Note:
Loading a model from its configuration file does `),NSe=a("strong"),Tpt=o("not"),Mpt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),uie=a("a"),Ept=o("from_pretrained()"),Cpt=o(" to load the model weights."),wpt=l(),F(B7.$$.fragment),Apt=l(),ot=a("div"),F(xB.$$.fragment),Lpt=l(),qSe=a("p"),ypt=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),xpt=l(),Zn=a("p"),$pt=o("The model class to instantiate is selected based on the "),DSe=a("code"),kpt=o("model_type"),Spt=o(` property of the config object (either
passed as an argument or loaded from `),jSe=a("code"),Rpt=o("pretrained_model_name_or_path"),Ppt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),GSe=a("code"),Bpt=o("pretrained_model_name_or_path"),Ipt=o(":"),Npt=l(),OSe=a("ul"),I7=a("li"),VSe=a("strong"),qpt=o("layoutlm"),Dpt=o(" \u2014 "),pie=a("a"),jpt=o("TFLayoutLMForQuestionAnswering"),Gpt=o(" (LayoutLM model)"),Opt=l(),F(N7.$$.fragment),tdo=l(),rf=a("h2"),q7=a("a"),XSe=a("span"),F($B.$$.fragment),Vpt=l(),zSe=a("span"),Xpt=o("TFAutoModelForTokenClassification"),ado=l(),Ar=a("div"),F(kB.$$.fragment),zpt=l(),tf=a("p"),Qpt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),_ie=a("a"),Wpt=o("from_pretrained()"),Upt=o(" class method or the "),bie=a("a"),Hpt=o("from_config()"),Jpt=o(` class
method.`),Ypt=l(),SB=a("p"),Zpt=o("This class cannot be instantiated directly using "),QSe=a("code"),Kpt=o("__init__()"),e_t=o(" (throws an error)."),o_t=l(),ga=a("div"),F(RB.$$.fragment),r_t=l(),WSe=a("p"),t_t=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),a_t=l(),af=a("p"),n_t=o(`Note:
Loading a model from its configuration file does `),USe=a("strong"),s_t=o("not"),l_t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vie=a("a"),i_t=o("from_pretrained()"),d_t=o(" to load the model weights."),m_t=l(),F(D7.$$.fragment),c_t=l(),rt=a("div"),F(PB.$$.fragment),f_t=l(),HSe=a("p"),g_t=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),h_t=l(),Kn=a("p"),u_t=o("The model class to instantiate is selected based on the "),JSe=a("code"),p_t=o("model_type"),__t=o(` property of the config object (either
passed as an argument or loaded from `),YSe=a("code"),b_t=o("pretrained_model_name_or_path"),v_t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ZSe=a("code"),F_t=o("pretrained_model_name_or_path"),T_t=o(":"),M_t=l(),me=a("ul"),j7=a("li"),KSe=a("strong"),E_t=o("albert"),C_t=o(" \u2014 "),Fie=a("a"),w_t=o("TFAlbertForTokenClassification"),A_t=o(" (ALBERT model)"),L_t=l(),G7=a("li"),eRe=a("strong"),y_t=o("bert"),x_t=o(" \u2014 "),Tie=a("a"),$_t=o("TFBertForTokenClassification"),k_t=o(" (BERT model)"),S_t=l(),O7=a("li"),oRe=a("strong"),R_t=o("camembert"),P_t=o(" \u2014 "),Mie=a("a"),B_t=o("TFCamembertForTokenClassification"),I_t=o(" (CamemBERT model)"),N_t=l(),V7=a("li"),rRe=a("strong"),q_t=o("convbert"),D_t=o(" \u2014 "),Eie=a("a"),j_t=o("TFConvBertForTokenClassification"),G_t=o(" (ConvBERT model)"),O_t=l(),X7=a("li"),tRe=a("strong"),V_t=o("deberta"),X_t=o(" \u2014 "),Cie=a("a"),z_t=o("TFDebertaForTokenClassification"),Q_t=o(" (DeBERTa model)"),W_t=l(),z7=a("li"),aRe=a("strong"),U_t=o("deberta-v2"),H_t=o(" \u2014 "),wie=a("a"),J_t=o("TFDebertaV2ForTokenClassification"),Y_t=o(" (DeBERTa-v2 model)"),Z_t=l(),Q7=a("li"),nRe=a("strong"),K_t=o("distilbert"),e1t=o(" \u2014 "),Aie=a("a"),o1t=o("TFDistilBertForTokenClassification"),r1t=o(" (DistilBERT model)"),t1t=l(),W7=a("li"),sRe=a("strong"),a1t=o("electra"),n1t=o(" \u2014 "),Lie=a("a"),s1t=o("TFElectraForTokenClassification"),l1t=o(" (ELECTRA model)"),i1t=l(),U7=a("li"),lRe=a("strong"),d1t=o("esm"),m1t=o(" \u2014 "),yie=a("a"),c1t=o("TFEsmForTokenClassification"),f1t=o(" (ESM model)"),g1t=l(),H7=a("li"),iRe=a("strong"),h1t=o("flaubert"),u1t=o(" \u2014 "),xie=a("a"),p1t=o("TFFlaubertForTokenClassification"),_1t=o(" (FlauBERT model)"),b1t=l(),J7=a("li"),dRe=a("strong"),v1t=o("funnel"),F1t=o(" \u2014 "),$ie=a("a"),T1t=o("TFFunnelForTokenClassification"),M1t=o(" (Funnel Transformer model)"),E1t=l(),Y7=a("li"),mRe=a("strong"),C1t=o("layoutlm"),w1t=o(" \u2014 "),kie=a("a"),A1t=o("TFLayoutLMForTokenClassification"),L1t=o(" (LayoutLM model)"),y1t=l(),Z7=a("li"),cRe=a("strong"),x1t=o("layoutlmv3"),$1t=o(" \u2014 "),Sie=a("a"),k1t=o("TFLayoutLMv3ForTokenClassification"),S1t=o(" (LayoutLMv3 model)"),R1t=l(),K7=a("li"),fRe=a("strong"),P1t=o("longformer"),B1t=o(" \u2014 "),Rie=a("a"),I1t=o("TFLongformerForTokenClassification"),N1t=o(" (Longformer model)"),q1t=l(),e8=a("li"),gRe=a("strong"),D1t=o("mobilebert"),j1t=o(" \u2014 "),Pie=a("a"),G1t=o("TFMobileBertForTokenClassification"),O1t=o(" (MobileBERT model)"),V1t=l(),o8=a("li"),hRe=a("strong"),X1t=o("mpnet"),z1t=o(" \u2014 "),Bie=a("a"),Q1t=o("TFMPNetForTokenClassification"),W1t=o(" (MPNet model)"),U1t=l(),r8=a("li"),uRe=a("strong"),H1t=o("rembert"),J1t=o(" \u2014 "),Iie=a("a"),Y1t=o("TFRemBertForTokenClassification"),Z1t=o(" (RemBERT model)"),K1t=l(),t8=a("li"),pRe=a("strong"),e2t=o("roberta"),o2t=o(" \u2014 "),Nie=a("a"),r2t=o("TFRobertaForTokenClassification"),t2t=o(" (RoBERTa model)"),a2t=l(),a8=a("li"),_Re=a("strong"),n2t=o("roformer"),s2t=o(" \u2014 "),qie=a("a"),l2t=o("TFRoFormerForTokenClassification"),i2t=o(" (RoFormer model)"),d2t=l(),n8=a("li"),bRe=a("strong"),m2t=o("xlm"),c2t=o(" \u2014 "),Die=a("a"),f2t=o("TFXLMForTokenClassification"),g2t=o(" (XLM model)"),h2t=l(),s8=a("li"),vRe=a("strong"),u2t=o("xlm-roberta"),p2t=o(" \u2014 "),jie=a("a"),_2t=o("TFXLMRobertaForTokenClassification"),b2t=o(" (XLM-RoBERTa model)"),v2t=l(),l8=a("li"),FRe=a("strong"),F2t=o("xlnet"),T2t=o(" \u2014 "),Gie=a("a"),M2t=o("TFXLNetForTokenClassification"),E2t=o(" (XLNet model)"),C2t=l(),F(i8.$$.fragment),ndo=l(),nf=a("h2"),d8=a("a"),TRe=a("span"),F(BB.$$.fragment),w2t=l(),MRe=a("span"),A2t=o("TFAutoModelForQuestionAnswering"),sdo=l(),Lr=a("div"),F(IB.$$.fragment),L2t=l(),sf=a("p"),y2t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Oie=a("a"),x2t=o("from_pretrained()"),$2t=o(" class method or the "),Vie=a("a"),k2t=o("from_config()"),S2t=o(` class
method.`),R2t=l(),NB=a("p"),P2t=o("This class cannot be instantiated directly using "),ERe=a("code"),B2t=o("__init__()"),I2t=o(" (throws an error)."),N2t=l(),ha=a("div"),F(qB.$$.fragment),q2t=l(),CRe=a("p"),D2t=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),j2t=l(),lf=a("p"),G2t=o(`Note:
Loading a model from its configuration file does `),wRe=a("strong"),O2t=o("not"),V2t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Xie=a("a"),X2t=o("from_pretrained()"),z2t=o(" to load the model weights."),Q2t=l(),F(m8.$$.fragment),W2t=l(),tt=a("div"),F(DB.$$.fragment),U2t=l(),ARe=a("p"),H2t=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),J2t=l(),es=a("p"),Y2t=o("The model class to instantiate is selected based on the "),LRe=a("code"),Z2t=o("model_type"),K2t=o(` property of the config object (either
passed as an argument or loaded from `),yRe=a("code"),ebt=o("pretrained_model_name_or_path"),obt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xRe=a("code"),rbt=o("pretrained_model_name_or_path"),tbt=o(":"),abt=l(),he=a("ul"),c8=a("li"),$Re=a("strong"),nbt=o("albert"),sbt=o(" \u2014 "),zie=a("a"),lbt=o("TFAlbertForQuestionAnswering"),ibt=o(" (ALBERT model)"),dbt=l(),f8=a("li"),kRe=a("strong"),mbt=o("bert"),cbt=o(" \u2014 "),Qie=a("a"),fbt=o("TFBertForQuestionAnswering"),gbt=o(" (BERT model)"),hbt=l(),g8=a("li"),SRe=a("strong"),ubt=o("camembert"),pbt=o(" \u2014 "),Wie=a("a"),_bt=o("TFCamembertForQuestionAnswering"),bbt=o(" (CamemBERT model)"),vbt=l(),h8=a("li"),RRe=a("strong"),Fbt=o("convbert"),Tbt=o(" \u2014 "),Uie=a("a"),Mbt=o("TFConvBertForQuestionAnswering"),Ebt=o(" (ConvBERT model)"),Cbt=l(),u8=a("li"),PRe=a("strong"),wbt=o("deberta"),Abt=o(" \u2014 "),Hie=a("a"),Lbt=o("TFDebertaForQuestionAnswering"),ybt=o(" (DeBERTa model)"),xbt=l(),p8=a("li"),BRe=a("strong"),$bt=o("deberta-v2"),kbt=o(" \u2014 "),Jie=a("a"),Sbt=o("TFDebertaV2ForQuestionAnswering"),Rbt=o(" (DeBERTa-v2 model)"),Pbt=l(),_8=a("li"),IRe=a("strong"),Bbt=o("distilbert"),Ibt=o(" \u2014 "),Yie=a("a"),Nbt=o("TFDistilBertForQuestionAnswering"),qbt=o(" (DistilBERT model)"),Dbt=l(),b8=a("li"),NRe=a("strong"),jbt=o("electra"),Gbt=o(" \u2014 "),Zie=a("a"),Obt=o("TFElectraForQuestionAnswering"),Vbt=o(" (ELECTRA model)"),Xbt=l(),v8=a("li"),qRe=a("strong"),zbt=o("flaubert"),Qbt=o(" \u2014 "),Kie=a("a"),Wbt=o("TFFlaubertForQuestionAnsweringSimple"),Ubt=o(" (FlauBERT model)"),Hbt=l(),F8=a("li"),DRe=a("strong"),Jbt=o("funnel"),Ybt=o(" \u2014 "),ede=a("a"),Zbt=o("TFFunnelForQuestionAnswering"),Kbt=o(" (Funnel Transformer model)"),evt=l(),T8=a("li"),jRe=a("strong"),ovt=o("gptj"),rvt=o(" \u2014 "),ode=a("a"),tvt=o("TFGPTJForQuestionAnswering"),avt=o(" (GPT-J model)"),nvt=l(),M8=a("li"),GRe=a("strong"),svt=o("layoutlmv3"),lvt=o(" \u2014 "),rde=a("a"),ivt=o("TFLayoutLMv3ForQuestionAnswering"),dvt=o(" (LayoutLMv3 model)"),mvt=l(),E8=a("li"),ORe=a("strong"),cvt=o("longformer"),fvt=o(" \u2014 "),tde=a("a"),gvt=o("TFLongformerForQuestionAnswering"),hvt=o(" (Longformer model)"),uvt=l(),C8=a("li"),VRe=a("strong"),pvt=o("mobilebert"),_vt=o(" \u2014 "),ade=a("a"),bvt=o("TFMobileBertForQuestionAnswering"),vvt=o(" (MobileBERT model)"),Fvt=l(),w8=a("li"),XRe=a("strong"),Tvt=o("mpnet"),Mvt=o(" \u2014 "),nde=a("a"),Evt=o("TFMPNetForQuestionAnswering"),Cvt=o(" (MPNet model)"),wvt=l(),A8=a("li"),zRe=a("strong"),Avt=o("rembert"),Lvt=o(" \u2014 "),sde=a("a"),yvt=o("TFRemBertForQuestionAnswering"),xvt=o(" (RemBERT model)"),$vt=l(),L8=a("li"),QRe=a("strong"),kvt=o("roberta"),Svt=o(" \u2014 "),lde=a("a"),Rvt=o("TFRobertaForQuestionAnswering"),Pvt=o(" (RoBERTa model)"),Bvt=l(),y8=a("li"),WRe=a("strong"),Ivt=o("roformer"),Nvt=o(" \u2014 "),ide=a("a"),qvt=o("TFRoFormerForQuestionAnswering"),Dvt=o(" (RoFormer model)"),jvt=l(),x8=a("li"),URe=a("strong"),Gvt=o("xlm"),Ovt=o(" \u2014 "),dde=a("a"),Vvt=o("TFXLMForQuestionAnsweringSimple"),Xvt=o(" (XLM model)"),zvt=l(),$8=a("li"),HRe=a("strong"),Qvt=o("xlm-roberta"),Wvt=o(" \u2014 "),mde=a("a"),Uvt=o("TFXLMRobertaForQuestionAnswering"),Hvt=o(" (XLM-RoBERTa model)"),Jvt=l(),k8=a("li"),JRe=a("strong"),Yvt=o("xlnet"),Zvt=o(" \u2014 "),cde=a("a"),Kvt=o("TFXLNetForQuestionAnsweringSimple"),eFt=o(" (XLNet model)"),oFt=l(),F(S8.$$.fragment),ldo=l(),df=a("h2"),R8=a("a"),YRe=a("span"),F(jB.$$.fragment),rFt=l(),ZRe=a("span"),tFt=o("TFAutoModelForVision2Seq"),ido=l(),yr=a("div"),F(GB.$$.fragment),aFt=l(),mf=a("p"),nFt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),fde=a("a"),sFt=o("from_pretrained()"),lFt=o(" class method or the "),gde=a("a"),iFt=o("from_config()"),dFt=o(` class
method.`),mFt=l(),OB=a("p"),cFt=o("This class cannot be instantiated directly using "),KRe=a("code"),fFt=o("__init__()"),gFt=o(" (throws an error)."),hFt=l(),ua=a("div"),F(VB.$$.fragment),uFt=l(),ePe=a("p"),pFt=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),_Ft=l(),cf=a("p"),bFt=o(`Note:
Loading a model from its configuration file does `),oPe=a("strong"),vFt=o("not"),FFt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hde=a("a"),TFt=o("from_pretrained()"),MFt=o(" to load the model weights."),EFt=l(),F(P8.$$.fragment),CFt=l(),at=a("div"),F(XB.$$.fragment),wFt=l(),rPe=a("p"),AFt=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),LFt=l(),os=a("p"),yFt=o("The model class to instantiate is selected based on the "),tPe=a("code"),xFt=o("model_type"),$Ft=o(` property of the config object (either
passed as an argument or loaded from `),aPe=a("code"),kFt=o("pretrained_model_name_or_path"),SFt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nPe=a("code"),RFt=o("pretrained_model_name_or_path"),PFt=o(":"),BFt=l(),sPe=a("ul"),B8=a("li"),lPe=a("strong"),IFt=o("vision-encoder-decoder"),NFt=o(" \u2014 "),ude=a("a"),qFt=o("TFVisionEncoderDecoderModel"),DFt=o(" (Vision Encoder decoder model)"),jFt=l(),F(I8.$$.fragment),ddo=l(),ff=a("h2"),N8=a("a"),iPe=a("span"),F(zB.$$.fragment),GFt=l(),dPe=a("span"),OFt=o("TFAutoModelForSpeechSeq2Seq"),mdo=l(),xr=a("div"),F(QB.$$.fragment),VFt=l(),gf=a("p"),XFt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),pde=a("a"),zFt=o("from_pretrained()"),QFt=o(" class method or the "),_de=a("a"),WFt=o("from_config()"),UFt=o(` class
method.`),HFt=l(),WB=a("p"),JFt=o("This class cannot be instantiated directly using "),mPe=a("code"),YFt=o("__init__()"),ZFt=o(" (throws an error)."),KFt=l(),pa=a("div"),F(UB.$$.fragment),eTt=l(),cPe=a("p"),oTt=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),rTt=l(),hf=a("p"),tTt=o(`Note:
Loading a model from its configuration file does `),fPe=a("strong"),aTt=o("not"),nTt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bde=a("a"),sTt=o("from_pretrained()"),lTt=o(" to load the model weights."),iTt=l(),F(q8.$$.fragment),dTt=l(),nt=a("div"),F(HB.$$.fragment),mTt=l(),gPe=a("p"),cTt=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),fTt=l(),rs=a("p"),gTt=o("The model class to instantiate is selected based on the "),hPe=a("code"),hTt=o("model_type"),uTt=o(` property of the config object (either
passed as an argument or loaded from `),uPe=a("code"),pTt=o("pretrained_model_name_or_path"),_Tt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pPe=a("code"),bTt=o("pretrained_model_name_or_path"),vTt=o(":"),FTt=l(),JB=a("ul"),D8=a("li"),_Pe=a("strong"),TTt=o("speech_to_text"),MTt=o(" \u2014 "),vde=a("a"),ETt=o("TFSpeech2TextForConditionalGeneration"),CTt=o(" (Speech2Text model)"),wTt=l(),j8=a("li"),bPe=a("strong"),ATt=o("whisper"),LTt=o(" \u2014 "),Fde=a("a"),yTt=o("TFWhisperForConditionalGeneration"),xTt=o(" (Whisper model)"),$Tt=l(),F(G8.$$.fragment),cdo=l(),uf=a("h2"),O8=a("a"),vPe=a("span"),F(YB.$$.fragment),kTt=l(),FPe=a("span"),STt=o("FlaxAutoModel"),fdo=l(),$r=a("div"),F(ZB.$$.fragment),RTt=l(),pf=a("p"),PTt=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Tde=a("a"),BTt=o("from_pretrained()"),ITt=o(" class method or the "),Mde=a("a"),NTt=o("from_config()"),qTt=o(` class
method.`),DTt=l(),KB=a("p"),jTt=o("This class cannot be instantiated directly using "),TPe=a("code"),GTt=o("__init__()"),OTt=o(" (throws an error)."),VTt=l(),_a=a("div"),F(eI.$$.fragment),XTt=l(),MPe=a("p"),zTt=o("Instantiates one of the base model classes of the library from a configuration."),QTt=l(),_f=a("p"),WTt=o(`Note:
Loading a model from its configuration file does `),EPe=a("strong"),UTt=o("not"),HTt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ede=a("a"),JTt=o("from_pretrained()"),YTt=o(" to load the model weights."),ZTt=l(),F(V8.$$.fragment),KTt=l(),st=a("div"),F(oI.$$.fragment),eMt=l(),CPe=a("p"),oMt=o("Instantiate one of the base model classes of the library from a pretrained model."),rMt=l(),ts=a("p"),tMt=o("The model class to instantiate is selected based on the "),wPe=a("code"),aMt=o("model_type"),nMt=o(` property of the config object (either
passed as an argument or loaded from `),APe=a("code"),sMt=o("pretrained_model_name_or_path"),lMt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),LPe=a("code"),iMt=o("pretrained_model_name_or_path"),dMt=o(":"),mMt=l(),ne=a("ul"),X8=a("li"),yPe=a("strong"),cMt=o("albert"),fMt=o(" \u2014 "),Cde=a("a"),gMt=o("FlaxAlbertModel"),hMt=o(" (ALBERT model)"),uMt=l(),z8=a("li"),xPe=a("strong"),pMt=o("bart"),_Mt=o(" \u2014 "),wde=a("a"),bMt=o("FlaxBartModel"),vMt=o(" (BART model)"),FMt=l(),Q8=a("li"),$Pe=a("strong"),TMt=o("beit"),MMt=o(" \u2014 "),Ade=a("a"),EMt=o("FlaxBeitModel"),CMt=o(" (BEiT model)"),wMt=l(),W8=a("li"),kPe=a("strong"),AMt=o("bert"),LMt=o(" \u2014 "),Lde=a("a"),yMt=o("FlaxBertModel"),xMt=o(" (BERT model)"),$Mt=l(),U8=a("li"),SPe=a("strong"),kMt=o("big_bird"),SMt=o(" \u2014 "),yde=a("a"),RMt=o("FlaxBigBirdModel"),PMt=o(" (BigBird model)"),BMt=l(),H8=a("li"),RPe=a("strong"),IMt=o("blenderbot"),NMt=o(" \u2014 "),xde=a("a"),qMt=o("FlaxBlenderbotModel"),DMt=o(" (Blenderbot model)"),jMt=l(),J8=a("li"),PPe=a("strong"),GMt=o("blenderbot-small"),OMt=o(" \u2014 "),$de=a("a"),VMt=o("FlaxBlenderbotSmallModel"),XMt=o(" (BlenderbotSmall model)"),zMt=l(),Y8=a("li"),BPe=a("strong"),QMt=o("clip"),WMt=o(" \u2014 "),kde=a("a"),UMt=o("FlaxCLIPModel"),HMt=o(" (CLIP model)"),JMt=l(),Z8=a("li"),IPe=a("strong"),YMt=o("distilbert"),ZMt=o(" \u2014 "),Sde=a("a"),KMt=o("FlaxDistilBertModel"),eEt=o(" (DistilBERT model)"),oEt=l(),K8=a("li"),NPe=a("strong"),rEt=o("electra"),tEt=o(" \u2014 "),Rde=a("a"),aEt=o("FlaxElectraModel"),nEt=o(" (ELECTRA model)"),sEt=l(),eL=a("li"),qPe=a("strong"),lEt=o("gpt2"),iEt=o(" \u2014 "),Pde=a("a"),dEt=o("FlaxGPT2Model"),mEt=o(" (OpenAI GPT-2 model)"),cEt=l(),oL=a("li"),DPe=a("strong"),fEt=o("gpt_neo"),gEt=o(" \u2014 "),Bde=a("a"),hEt=o("FlaxGPTNeoModel"),uEt=o(" (GPT Neo model)"),pEt=l(),rL=a("li"),jPe=a("strong"),_Et=o("gptj"),bEt=o(" \u2014 "),Ide=a("a"),vEt=o("FlaxGPTJModel"),FEt=o(" (GPT-J model)"),TEt=l(),tL=a("li"),GPe=a("strong"),MEt=o("longt5"),EEt=o(" \u2014 "),Nde=a("a"),CEt=o("FlaxLongT5Model"),wEt=o(" (LongT5 model)"),AEt=l(),aL=a("li"),OPe=a("strong"),LEt=o("marian"),yEt=o(" \u2014 "),qde=a("a"),xEt=o("FlaxMarianModel"),$Et=o(" (Marian model)"),kEt=l(),nL=a("li"),VPe=a("strong"),SEt=o("mbart"),REt=o(" \u2014 "),Dde=a("a"),PEt=o("FlaxMBartModel"),BEt=o(" (mBART model)"),IEt=l(),sL=a("li"),XPe=a("strong"),NEt=o("mt5"),qEt=o(" \u2014 "),jde=a("a"),DEt=o("FlaxMT5Model"),jEt=o(" (MT5 model)"),GEt=l(),lL=a("li"),zPe=a("strong"),OEt=o("opt"),VEt=o(" \u2014 "),Gde=a("a"),XEt=o("FlaxOPTModel"),zEt=o(" (OPT model)"),QEt=l(),iL=a("li"),QPe=a("strong"),WEt=o("pegasus"),UEt=o(" \u2014 "),Ode=a("a"),HEt=o("FlaxPegasusModel"),JEt=o(" (Pegasus model)"),YEt=l(),dL=a("li"),WPe=a("strong"),ZEt=o("roberta"),KEt=o(" \u2014 "),Vde=a("a"),e4t=o("FlaxRobertaModel"),o4t=o(" (RoBERTa model)"),r4t=l(),mL=a("li"),UPe=a("strong"),t4t=o("roformer"),a4t=o(" \u2014 "),Xde=a("a"),n4t=o("FlaxRoFormerModel"),s4t=o(" (RoFormer model)"),l4t=l(),cL=a("li"),HPe=a("strong"),i4t=o("t5"),d4t=o(" \u2014 "),zde=a("a"),m4t=o("FlaxT5Model"),c4t=o(" (T5 model)"),f4t=l(),fL=a("li"),JPe=a("strong"),g4t=o("vision-text-dual-encoder"),h4t=o(" \u2014 "),Qde=a("a"),u4t=o("FlaxVisionTextDualEncoderModel"),p4t=o(" (VisionTextDualEncoder model)"),_4t=l(),gL=a("li"),YPe=a("strong"),b4t=o("vit"),v4t=o(" \u2014 "),Wde=a("a"),F4t=o("FlaxViTModel"),T4t=o(" (ViT model)"),M4t=l(),hL=a("li"),ZPe=a("strong"),E4t=o("wav2vec2"),C4t=o(" \u2014 "),Ude=a("a"),w4t=o("FlaxWav2Vec2Model"),A4t=o(" (Wav2Vec2 model)"),L4t=l(),uL=a("li"),KPe=a("strong"),y4t=o("xglm"),x4t=o(" \u2014 "),Hde=a("a"),$4t=o("FlaxXGLMModel"),k4t=o(" (XGLM model)"),S4t=l(),pL=a("li"),eBe=a("strong"),R4t=o("xlm-roberta"),P4t=o(" \u2014 "),Jde=a("a"),B4t=o("FlaxXLMRobertaModel"),I4t=o(" (XLM-RoBERTa model)"),N4t=l(),F(_L.$$.fragment),gdo=l(),bf=a("h2"),bL=a("a"),oBe=a("span"),F(rI.$$.fragment),q4t=l(),rBe=a("span"),D4t=o("FlaxAutoModelForCausalLM"),hdo=l(),kr=a("div"),F(tI.$$.fragment),j4t=l(),vf=a("p"),G4t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Yde=a("a"),O4t=o("from_pretrained()"),V4t=o(" class method or the "),Zde=a("a"),X4t=o("from_config()"),z4t=o(` class
method.`),Q4t=l(),aI=a("p"),W4t=o("This class cannot be instantiated directly using "),tBe=a("code"),U4t=o("__init__()"),H4t=o(" (throws an error)."),J4t=l(),ba=a("div"),F(nI.$$.fragment),Y4t=l(),aBe=a("p"),Z4t=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),K4t=l(),Ff=a("p"),eCt=o(`Note:
Loading a model from its configuration file does `),nBe=a("strong"),oCt=o("not"),rCt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Kde=a("a"),tCt=o("from_pretrained()"),aCt=o(" to load the model weights."),nCt=l(),F(vL.$$.fragment),sCt=l(),lt=a("div"),F(sI.$$.fragment),lCt=l(),sBe=a("p"),iCt=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),dCt=l(),as=a("p"),mCt=o("The model class to instantiate is selected based on the "),lBe=a("code"),cCt=o("model_type"),fCt=o(` property of the config object (either
passed as an argument or loaded from `),iBe=a("code"),gCt=o("pretrained_model_name_or_path"),hCt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dBe=a("code"),uCt=o("pretrained_model_name_or_path"),pCt=o(":"),_Ct=l(),Se=a("ul"),FL=a("li"),mBe=a("strong"),bCt=o("bart"),vCt=o(" \u2014 "),eme=a("a"),FCt=o("FlaxBartForCausalLM"),TCt=o(" (BART model)"),MCt=l(),TL=a("li"),cBe=a("strong"),ECt=o("bert"),CCt=o(" \u2014 "),ome=a("a"),wCt=o("FlaxBertForCausalLM"),ACt=o(" (BERT model)"),LCt=l(),ML=a("li"),fBe=a("strong"),yCt=o("big_bird"),xCt=o(" \u2014 "),rme=a("a"),$Ct=o("FlaxBigBirdForCausalLM"),kCt=o(" (BigBird model)"),SCt=l(),EL=a("li"),gBe=a("strong"),RCt=o("electra"),PCt=o(" \u2014 "),tme=a("a"),BCt=o("FlaxElectraForCausalLM"),ICt=o(" (ELECTRA model)"),NCt=l(),CL=a("li"),hBe=a("strong"),qCt=o("gpt2"),DCt=o(" \u2014 "),ame=a("a"),jCt=o("FlaxGPT2LMHeadModel"),GCt=o(" (OpenAI GPT-2 model)"),OCt=l(),wL=a("li"),uBe=a("strong"),VCt=o("gpt_neo"),XCt=o(" \u2014 "),nme=a("a"),zCt=o("FlaxGPTNeoForCausalLM"),QCt=o(" (GPT Neo model)"),WCt=l(),AL=a("li"),pBe=a("strong"),UCt=o("gptj"),HCt=o(" \u2014 "),sme=a("a"),JCt=o("FlaxGPTJForCausalLM"),YCt=o(" (GPT-J model)"),ZCt=l(),LL=a("li"),_Be=a("strong"),KCt=o("opt"),e3t=o(" \u2014 "),lme=a("a"),o3t=o("FlaxOPTForCausalLM"),r3t=o(" (OPT model)"),t3t=l(),yL=a("li"),bBe=a("strong"),a3t=o("roberta"),n3t=o(" \u2014 "),ime=a("a"),s3t=o("FlaxRobertaForCausalLM"),l3t=o(" (RoBERTa model)"),i3t=l(),xL=a("li"),vBe=a("strong"),d3t=o("xglm"),m3t=o(" \u2014 "),dme=a("a"),c3t=o("FlaxXGLMForCausalLM"),f3t=o(" (XGLM model)"),g3t=l(),F($L.$$.fragment),udo=l(),Tf=a("h2"),kL=a("a"),FBe=a("span"),F(lI.$$.fragment),h3t=l(),TBe=a("span"),u3t=o("FlaxAutoModelForPreTraining"),pdo=l(),Sr=a("div"),F(iI.$$.fragment),p3t=l(),Mf=a("p"),_3t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),mme=a("a"),b3t=o("from_pretrained()"),v3t=o(" class method or the "),cme=a("a"),F3t=o("from_config()"),T3t=o(` class
method.`),M3t=l(),dI=a("p"),E3t=o("This class cannot be instantiated directly using "),MBe=a("code"),C3t=o("__init__()"),w3t=o(" (throws an error)."),A3t=l(),va=a("div"),F(mI.$$.fragment),L3t=l(),EBe=a("p"),y3t=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),x3t=l(),Ef=a("p"),$3t=o(`Note:
Loading a model from its configuration file does `),CBe=a("strong"),k3t=o("not"),S3t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),fme=a("a"),R3t=o("from_pretrained()"),P3t=o(" to load the model weights."),B3t=l(),F(SL.$$.fragment),I3t=l(),it=a("div"),F(cI.$$.fragment),N3t=l(),wBe=a("p"),q3t=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),D3t=l(),ns=a("p"),j3t=o("The model class to instantiate is selected based on the "),ABe=a("code"),G3t=o("model_type"),O3t=o(` property of the config object (either
passed as an argument or loaded from `),LBe=a("code"),V3t=o("pretrained_model_name_or_path"),X3t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yBe=a("code"),z3t=o("pretrained_model_name_or_path"),Q3t=o(":"),W3t=l(),we=a("ul"),RL=a("li"),xBe=a("strong"),U3t=o("albert"),H3t=o(" \u2014 "),gme=a("a"),J3t=o("FlaxAlbertForPreTraining"),Y3t=o(" (ALBERT model)"),Z3t=l(),PL=a("li"),$Be=a("strong"),K3t=o("bart"),e5t=o(" \u2014 "),hme=a("a"),o5t=o("FlaxBartForConditionalGeneration"),r5t=o(" (BART model)"),t5t=l(),BL=a("li"),kBe=a("strong"),a5t=o("bert"),n5t=o(" \u2014 "),ume=a("a"),s5t=o("FlaxBertForPreTraining"),l5t=o(" (BERT model)"),i5t=l(),IL=a("li"),SBe=a("strong"),d5t=o("big_bird"),m5t=o(" \u2014 "),pme=a("a"),c5t=o("FlaxBigBirdForPreTraining"),f5t=o(" (BigBird model)"),g5t=l(),NL=a("li"),RBe=a("strong"),h5t=o("electra"),u5t=o(" \u2014 "),_me=a("a"),p5t=o("FlaxElectraForPreTraining"),_5t=o(" (ELECTRA model)"),b5t=l(),qL=a("li"),PBe=a("strong"),v5t=o("longt5"),F5t=o(" \u2014 "),bme=a("a"),T5t=o("FlaxLongT5ForConditionalGeneration"),M5t=o(" (LongT5 model)"),E5t=l(),DL=a("li"),BBe=a("strong"),C5t=o("mbart"),w5t=o(" \u2014 "),vme=a("a"),A5t=o("FlaxMBartForConditionalGeneration"),L5t=o(" (mBART model)"),y5t=l(),jL=a("li"),IBe=a("strong"),x5t=o("mt5"),$5t=o(" \u2014 "),Fme=a("a"),k5t=o("FlaxMT5ForConditionalGeneration"),S5t=o(" (MT5 model)"),R5t=l(),GL=a("li"),NBe=a("strong"),P5t=o("roberta"),B5t=o(" \u2014 "),Tme=a("a"),I5t=o("FlaxRobertaForMaskedLM"),N5t=o(" (RoBERTa model)"),q5t=l(),OL=a("li"),qBe=a("strong"),D5t=o("roformer"),j5t=o(" \u2014 "),Mme=a("a"),G5t=o("FlaxRoFormerForMaskedLM"),O5t=o(" (RoFormer model)"),V5t=l(),VL=a("li"),DBe=a("strong"),X5t=o("t5"),z5t=o(" \u2014 "),Eme=a("a"),Q5t=o("FlaxT5ForConditionalGeneration"),W5t=o(" (T5 model)"),U5t=l(),XL=a("li"),jBe=a("strong"),H5t=o("wav2vec2"),J5t=o(" \u2014 "),Cme=a("a"),Y5t=o("FlaxWav2Vec2ForPreTraining"),Z5t=o(" (Wav2Vec2 model)"),K5t=l(),zL=a("li"),GBe=a("strong"),e0t=o("xlm-roberta"),o0t=o(" \u2014 "),wme=a("a"),r0t=o("FlaxXLMRobertaForMaskedLM"),t0t=o(" (XLM-RoBERTa model)"),a0t=l(),F(QL.$$.fragment),_do=l(),Cf=a("h2"),WL=a("a"),OBe=a("span"),F(fI.$$.fragment),n0t=l(),VBe=a("span"),s0t=o("FlaxAutoModelForMaskedLM"),bdo=l(),Rr=a("div"),F(gI.$$.fragment),l0t=l(),wf=a("p"),i0t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Ame=a("a"),d0t=o("from_pretrained()"),m0t=o(" class method or the "),Lme=a("a"),c0t=o("from_config()"),f0t=o(` class
method.`),g0t=l(),hI=a("p"),h0t=o("This class cannot be instantiated directly using "),XBe=a("code"),u0t=o("__init__()"),p0t=o(" (throws an error)."),_0t=l(),Fa=a("div"),F(uI.$$.fragment),b0t=l(),zBe=a("p"),v0t=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),F0t=l(),Af=a("p"),T0t=o(`Note:
Loading a model from its configuration file does `),QBe=a("strong"),M0t=o("not"),E0t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yme=a("a"),C0t=o("from_pretrained()"),w0t=o(" to load the model weights."),A0t=l(),F(UL.$$.fragment),L0t=l(),dt=a("div"),F(pI.$$.fragment),y0t=l(),WBe=a("p"),x0t=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),$0t=l(),ss=a("p"),k0t=o("The model class to instantiate is selected based on the "),UBe=a("code"),S0t=o("model_type"),R0t=o(` property of the config object (either
passed as an argument or loaded from `),HBe=a("code"),P0t=o("pretrained_model_name_or_path"),B0t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JBe=a("code"),I0t=o("pretrained_model_name_or_path"),N0t=o(":"),q0t=l(),Re=a("ul"),HL=a("li"),YBe=a("strong"),D0t=o("albert"),j0t=o(" \u2014 "),xme=a("a"),G0t=o("FlaxAlbertForMaskedLM"),O0t=o(" (ALBERT model)"),V0t=l(),JL=a("li"),ZBe=a("strong"),X0t=o("bart"),z0t=o(" \u2014 "),$me=a("a"),Q0t=o("FlaxBartForConditionalGeneration"),W0t=o(" (BART model)"),U0t=l(),YL=a("li"),KBe=a("strong"),H0t=o("bert"),J0t=o(" \u2014 "),kme=a("a"),Y0t=o("FlaxBertForMaskedLM"),Z0t=o(" (BERT model)"),K0t=l(),ZL=a("li"),eIe=a("strong"),ewt=o("big_bird"),owt=o(" \u2014 "),Sme=a("a"),rwt=o("FlaxBigBirdForMaskedLM"),twt=o(" (BigBird model)"),awt=l(),KL=a("li"),oIe=a("strong"),nwt=o("distilbert"),swt=o(" \u2014 "),Rme=a("a"),lwt=o("FlaxDistilBertForMaskedLM"),iwt=o(" (DistilBERT model)"),dwt=l(),ey=a("li"),rIe=a("strong"),mwt=o("electra"),cwt=o(" \u2014 "),Pme=a("a"),fwt=o("FlaxElectraForMaskedLM"),gwt=o(" (ELECTRA model)"),hwt=l(),oy=a("li"),tIe=a("strong"),uwt=o("mbart"),pwt=o(" \u2014 "),Bme=a("a"),_wt=o("FlaxMBartForConditionalGeneration"),bwt=o(" (mBART model)"),vwt=l(),ry=a("li"),aIe=a("strong"),Fwt=o("roberta"),Twt=o(" \u2014 "),Ime=a("a"),Mwt=o("FlaxRobertaForMaskedLM"),Ewt=o(" (RoBERTa model)"),Cwt=l(),ty=a("li"),nIe=a("strong"),wwt=o("roformer"),Awt=o(" \u2014 "),Nme=a("a"),Lwt=o("FlaxRoFormerForMaskedLM"),ywt=o(" (RoFormer model)"),xwt=l(),ay=a("li"),sIe=a("strong"),$wt=o("xlm-roberta"),kwt=o(" \u2014 "),qme=a("a"),Swt=o("FlaxXLMRobertaForMaskedLM"),Rwt=o(" (XLM-RoBERTa model)"),Pwt=l(),F(ny.$$.fragment),vdo=l(),Lf=a("h2"),sy=a("a"),lIe=a("span"),F(_I.$$.fragment),Bwt=l(),iIe=a("span"),Iwt=o("FlaxAutoModelForSeq2SeqLM"),Fdo=l(),Pr=a("div"),F(bI.$$.fragment),Nwt=l(),yf=a("p"),qwt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Dme=a("a"),Dwt=o("from_pretrained()"),jwt=o(" class method or the "),jme=a("a"),Gwt=o("from_config()"),Owt=o(` class
method.`),Vwt=l(),vI=a("p"),Xwt=o("This class cannot be instantiated directly using "),dIe=a("code"),zwt=o("__init__()"),Qwt=o(" (throws an error)."),Wwt=l(),Ta=a("div"),F(FI.$$.fragment),Uwt=l(),mIe=a("p"),Hwt=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Jwt=l(),xf=a("p"),Ywt=o(`Note:
Loading a model from its configuration file does `),cIe=a("strong"),Zwt=o("not"),Kwt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Gme=a("a"),eAt=o("from_pretrained()"),oAt=o(" to load the model weights."),rAt=l(),F(ly.$$.fragment),tAt=l(),mt=a("div"),F(TI.$$.fragment),aAt=l(),fIe=a("p"),nAt=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),sAt=l(),ls=a("p"),lAt=o("The model class to instantiate is selected based on the "),gIe=a("code"),iAt=o("model_type"),dAt=o(` property of the config object (either
passed as an argument or loaded from `),hIe=a("code"),mAt=o("pretrained_model_name_or_path"),cAt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uIe=a("code"),fAt=o("pretrained_model_name_or_path"),gAt=o(":"),hAt=l(),Pe=a("ul"),iy=a("li"),pIe=a("strong"),uAt=o("bart"),pAt=o(" \u2014 "),Ome=a("a"),_At=o("FlaxBartForConditionalGeneration"),bAt=o(" (BART model)"),vAt=l(),dy=a("li"),_Ie=a("strong"),FAt=o("blenderbot"),TAt=o(" \u2014 "),Vme=a("a"),MAt=o("FlaxBlenderbotForConditionalGeneration"),EAt=o(" (Blenderbot model)"),CAt=l(),my=a("li"),bIe=a("strong"),wAt=o("blenderbot-small"),AAt=o(" \u2014 "),Xme=a("a"),LAt=o("FlaxBlenderbotSmallForConditionalGeneration"),yAt=o(" (BlenderbotSmall model)"),xAt=l(),cy=a("li"),vIe=a("strong"),$At=o("encoder-decoder"),kAt=o(" \u2014 "),zme=a("a"),SAt=o("FlaxEncoderDecoderModel"),RAt=o(" (Encoder decoder model)"),PAt=l(),fy=a("li"),FIe=a("strong"),BAt=o("longt5"),IAt=o(" \u2014 "),Qme=a("a"),NAt=o("FlaxLongT5ForConditionalGeneration"),qAt=o(" (LongT5 model)"),DAt=l(),gy=a("li"),TIe=a("strong"),jAt=o("marian"),GAt=o(" \u2014 "),Wme=a("a"),OAt=o("FlaxMarianMTModel"),VAt=o(" (Marian model)"),XAt=l(),hy=a("li"),MIe=a("strong"),zAt=o("mbart"),QAt=o(" \u2014 "),Ume=a("a"),WAt=o("FlaxMBartForConditionalGeneration"),UAt=o(" (mBART model)"),HAt=l(),uy=a("li"),EIe=a("strong"),JAt=o("mt5"),YAt=o(" \u2014 "),Hme=a("a"),ZAt=o("FlaxMT5ForConditionalGeneration"),KAt=o(" (MT5 model)"),e6t=l(),py=a("li"),CIe=a("strong"),o6t=o("pegasus"),r6t=o(" \u2014 "),Jme=a("a"),t6t=o("FlaxPegasusForConditionalGeneration"),a6t=o(" (Pegasus model)"),n6t=l(),_y=a("li"),wIe=a("strong"),s6t=o("t5"),l6t=o(" \u2014 "),Yme=a("a"),i6t=o("FlaxT5ForConditionalGeneration"),d6t=o(" (T5 model)"),m6t=l(),F(by.$$.fragment),Tdo=l(),$f=a("h2"),vy=a("a"),AIe=a("span"),F(MI.$$.fragment),c6t=l(),LIe=a("span"),f6t=o("FlaxAutoModelForSequenceClassification"),Mdo=l(),Br=a("div"),F(EI.$$.fragment),g6t=l(),kf=a("p"),h6t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Zme=a("a"),u6t=o("from_pretrained()"),p6t=o(" class method or the "),Kme=a("a"),_6t=o("from_config()"),b6t=o(` class
method.`),v6t=l(),CI=a("p"),F6t=o("This class cannot be instantiated directly using "),yIe=a("code"),T6t=o("__init__()"),M6t=o(" (throws an error)."),E6t=l(),Ma=a("div"),F(wI.$$.fragment),C6t=l(),xIe=a("p"),w6t=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),A6t=l(),Sf=a("p"),L6t=o(`Note:
Loading a model from its configuration file does `),$Ie=a("strong"),y6t=o("not"),x6t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ece=a("a"),$6t=o("from_pretrained()"),k6t=o(" to load the model weights."),S6t=l(),F(Fy.$$.fragment),R6t=l(),ct=a("div"),F(AI.$$.fragment),P6t=l(),kIe=a("p"),B6t=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),I6t=l(),is=a("p"),N6t=o("The model class to instantiate is selected based on the "),SIe=a("code"),q6t=o("model_type"),D6t=o(` property of the config object (either
passed as an argument or loaded from `),RIe=a("code"),j6t=o("pretrained_model_name_or_path"),G6t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),PIe=a("code"),O6t=o("pretrained_model_name_or_path"),V6t=o(":"),X6t=l(),Be=a("ul"),Ty=a("li"),BIe=a("strong"),z6t=o("albert"),Q6t=o(" \u2014 "),oce=a("a"),W6t=o("FlaxAlbertForSequenceClassification"),U6t=o(" (ALBERT model)"),H6t=l(),My=a("li"),IIe=a("strong"),J6t=o("bart"),Y6t=o(" \u2014 "),rce=a("a"),Z6t=o("FlaxBartForSequenceClassification"),K6t=o(" (BART model)"),e7t=l(),Ey=a("li"),NIe=a("strong"),o7t=o("bert"),r7t=o(" \u2014 "),tce=a("a"),t7t=o("FlaxBertForSequenceClassification"),a7t=o(" (BERT model)"),n7t=l(),Cy=a("li"),qIe=a("strong"),s7t=o("big_bird"),l7t=o(" \u2014 "),ace=a("a"),i7t=o("FlaxBigBirdForSequenceClassification"),d7t=o(" (BigBird model)"),m7t=l(),wy=a("li"),DIe=a("strong"),c7t=o("distilbert"),f7t=o(" \u2014 "),nce=a("a"),g7t=o("FlaxDistilBertForSequenceClassification"),h7t=o(" (DistilBERT model)"),u7t=l(),Ay=a("li"),jIe=a("strong"),p7t=o("electra"),_7t=o(" \u2014 "),sce=a("a"),b7t=o("FlaxElectraForSequenceClassification"),v7t=o(" (ELECTRA model)"),F7t=l(),Ly=a("li"),GIe=a("strong"),T7t=o("mbart"),M7t=o(" \u2014 "),lce=a("a"),E7t=o("FlaxMBartForSequenceClassification"),C7t=o(" (mBART model)"),w7t=l(),yy=a("li"),OIe=a("strong"),A7t=o("roberta"),L7t=o(" \u2014 "),ice=a("a"),y7t=o("FlaxRobertaForSequenceClassification"),x7t=o(" (RoBERTa model)"),$7t=l(),xy=a("li"),VIe=a("strong"),k7t=o("roformer"),S7t=o(" \u2014 "),dce=a("a"),R7t=o("FlaxRoFormerForSequenceClassification"),P7t=o(" (RoFormer model)"),B7t=l(),$y=a("li"),XIe=a("strong"),I7t=o("xlm-roberta"),N7t=o(" \u2014 "),mce=a("a"),q7t=o("FlaxXLMRobertaForSequenceClassification"),D7t=o(" (XLM-RoBERTa model)"),j7t=l(),F(ky.$$.fragment),Edo=l(),Rf=a("h2"),Sy=a("a"),zIe=a("span"),F(LI.$$.fragment),G7t=l(),QIe=a("span"),O7t=o("FlaxAutoModelForQuestionAnswering"),Cdo=l(),Ir=a("div"),F(yI.$$.fragment),V7t=l(),Pf=a("p"),X7t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),cce=a("a"),z7t=o("from_pretrained()"),Q7t=o(" class method or the "),fce=a("a"),W7t=o("from_config()"),U7t=o(` class
method.`),H7t=l(),xI=a("p"),J7t=o("This class cannot be instantiated directly using "),WIe=a("code"),Y7t=o("__init__()"),Z7t=o(" (throws an error)."),K7t=l(),Ea=a("div"),F($I.$$.fragment),e8t=l(),UIe=a("p"),o8t=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),r8t=l(),Bf=a("p"),t8t=o(`Note:
Loading a model from its configuration file does `),HIe=a("strong"),a8t=o("not"),n8t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gce=a("a"),s8t=o("from_pretrained()"),l8t=o(" to load the model weights."),i8t=l(),F(Ry.$$.fragment),d8t=l(),ft=a("div"),F(kI.$$.fragment),m8t=l(),JIe=a("p"),c8t=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),f8t=l(),ds=a("p"),g8t=o("The model class to instantiate is selected based on the "),YIe=a("code"),h8t=o("model_type"),u8t=o(` property of the config object (either
passed as an argument or loaded from `),ZIe=a("code"),p8t=o("pretrained_model_name_or_path"),_8t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KIe=a("code"),b8t=o("pretrained_model_name_or_path"),v8t=o(":"),F8t=l(),Ie=a("ul"),Py=a("li"),eNe=a("strong"),T8t=o("albert"),M8t=o(" \u2014 "),hce=a("a"),E8t=o("FlaxAlbertForQuestionAnswering"),C8t=o(" (ALBERT model)"),w8t=l(),By=a("li"),oNe=a("strong"),A8t=o("bart"),L8t=o(" \u2014 "),uce=a("a"),y8t=o("FlaxBartForQuestionAnswering"),x8t=o(" (BART model)"),$8t=l(),Iy=a("li"),rNe=a("strong"),k8t=o("bert"),S8t=o(" \u2014 "),pce=a("a"),R8t=o("FlaxBertForQuestionAnswering"),P8t=o(" (BERT model)"),B8t=l(),Ny=a("li"),tNe=a("strong"),I8t=o("big_bird"),N8t=o(" \u2014 "),_ce=a("a"),q8t=o("FlaxBigBirdForQuestionAnswering"),D8t=o(" (BigBird model)"),j8t=l(),qy=a("li"),aNe=a("strong"),G8t=o("distilbert"),O8t=o(" \u2014 "),bce=a("a"),V8t=o("FlaxDistilBertForQuestionAnswering"),X8t=o(" (DistilBERT model)"),z8t=l(),Dy=a("li"),nNe=a("strong"),Q8t=o("electra"),W8t=o(" \u2014 "),vce=a("a"),U8t=o("FlaxElectraForQuestionAnswering"),H8t=o(" (ELECTRA model)"),J8t=l(),jy=a("li"),sNe=a("strong"),Y8t=o("mbart"),Z8t=o(" \u2014 "),Fce=a("a"),K8t=o("FlaxMBartForQuestionAnswering"),eLt=o(" (mBART model)"),oLt=l(),Gy=a("li"),lNe=a("strong"),rLt=o("roberta"),tLt=o(" \u2014 "),Tce=a("a"),aLt=o("FlaxRobertaForQuestionAnswering"),nLt=o(" (RoBERTa model)"),sLt=l(),Oy=a("li"),iNe=a("strong"),lLt=o("roformer"),iLt=o(" \u2014 "),Mce=a("a"),dLt=o("FlaxRoFormerForQuestionAnswering"),mLt=o(" (RoFormer model)"),cLt=l(),Vy=a("li"),dNe=a("strong"),fLt=o("xlm-roberta"),gLt=o(" \u2014 "),Ece=a("a"),hLt=o("FlaxXLMRobertaForQuestionAnswering"),uLt=o(" (XLM-RoBERTa model)"),pLt=l(),F(Xy.$$.fragment),wdo=l(),If=a("h2"),zy=a("a"),mNe=a("span"),F(SI.$$.fragment),_Lt=l(),cNe=a("span"),bLt=o("FlaxAutoModelForTokenClassification"),Ado=l(),Nr=a("div"),F(RI.$$.fragment),vLt=l(),Nf=a("p"),FLt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Cce=a("a"),TLt=o("from_pretrained()"),MLt=o(" class method or the "),wce=a("a"),ELt=o("from_config()"),CLt=o(` class
method.`),wLt=l(),PI=a("p"),ALt=o("This class cannot be instantiated directly using "),fNe=a("code"),LLt=o("__init__()"),yLt=o(" (throws an error)."),xLt=l(),Ca=a("div"),F(BI.$$.fragment),$Lt=l(),gNe=a("p"),kLt=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),SLt=l(),qf=a("p"),RLt=o(`Note:
Loading a model from its configuration file does `),hNe=a("strong"),PLt=o("not"),BLt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ace=a("a"),ILt=o("from_pretrained()"),NLt=o(" to load the model weights."),qLt=l(),F(Qy.$$.fragment),DLt=l(),gt=a("div"),F(II.$$.fragment),jLt=l(),uNe=a("p"),GLt=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),OLt=l(),ms=a("p"),VLt=o("The model class to instantiate is selected based on the "),pNe=a("code"),XLt=o("model_type"),zLt=o(` property of the config object (either
passed as an argument or loaded from `),_Ne=a("code"),QLt=o("pretrained_model_name_or_path"),WLt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bNe=a("code"),ULt=o("pretrained_model_name_or_path"),HLt=o(":"),JLt=l(),We=a("ul"),Wy=a("li"),vNe=a("strong"),YLt=o("albert"),ZLt=o(" \u2014 "),Lce=a("a"),KLt=o("FlaxAlbertForTokenClassification"),eyt=o(" (ALBERT model)"),oyt=l(),Uy=a("li"),FNe=a("strong"),ryt=o("bert"),tyt=o(" \u2014 "),yce=a("a"),ayt=o("FlaxBertForTokenClassification"),nyt=o(" (BERT model)"),syt=l(),Hy=a("li"),TNe=a("strong"),lyt=o("big_bird"),iyt=o(" \u2014 "),xce=a("a"),dyt=o("FlaxBigBirdForTokenClassification"),myt=o(" (BigBird model)"),cyt=l(),Jy=a("li"),MNe=a("strong"),fyt=o("distilbert"),gyt=o(" \u2014 "),$ce=a("a"),hyt=o("FlaxDistilBertForTokenClassification"),uyt=o(" (DistilBERT model)"),pyt=l(),Yy=a("li"),ENe=a("strong"),_yt=o("electra"),byt=o(" \u2014 "),kce=a("a"),vyt=o("FlaxElectraForTokenClassification"),Fyt=o(" (ELECTRA model)"),Tyt=l(),Zy=a("li"),CNe=a("strong"),Myt=o("roberta"),Eyt=o(" \u2014 "),Sce=a("a"),Cyt=o("FlaxRobertaForTokenClassification"),wyt=o(" (RoBERTa model)"),Ayt=l(),Ky=a("li"),wNe=a("strong"),Lyt=o("roformer"),yyt=o(" \u2014 "),Rce=a("a"),xyt=o("FlaxRoFormerForTokenClassification"),$yt=o(" (RoFormer model)"),kyt=l(),e9=a("li"),ANe=a("strong"),Syt=o("xlm-roberta"),Ryt=o(" \u2014 "),Pce=a("a"),Pyt=o("FlaxXLMRobertaForTokenClassification"),Byt=o(" (XLM-RoBERTa model)"),Iyt=l(),F(o9.$$.fragment),Ldo=l(),Df=a("h2"),r9=a("a"),LNe=a("span"),F(NI.$$.fragment),Nyt=l(),yNe=a("span"),qyt=o("FlaxAutoModelForMultipleChoice"),ydo=l(),qr=a("div"),F(qI.$$.fragment),Dyt=l(),jf=a("p"),jyt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Bce=a("a"),Gyt=o("from_pretrained()"),Oyt=o(" class method or the "),Ice=a("a"),Vyt=o("from_config()"),Xyt=o(` class
method.`),zyt=l(),DI=a("p"),Qyt=o("This class cannot be instantiated directly using "),xNe=a("code"),Wyt=o("__init__()"),Uyt=o(" (throws an error)."),Hyt=l(),wa=a("div"),F(jI.$$.fragment),Jyt=l(),$Ne=a("p"),Yyt=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Zyt=l(),Gf=a("p"),Kyt=o(`Note:
Loading a model from its configuration file does `),kNe=a("strong"),e9t=o("not"),o9t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Nce=a("a"),r9t=o("from_pretrained()"),t9t=o(" to load the model weights."),a9t=l(),F(t9.$$.fragment),n9t=l(),ht=a("div"),F(GI.$$.fragment),s9t=l(),SNe=a("p"),l9t=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),i9t=l(),cs=a("p"),d9t=o("The model class to instantiate is selected based on the "),RNe=a("code"),m9t=o("model_type"),c9t=o(` property of the config object (either
passed as an argument or loaded from `),PNe=a("code"),f9t=o("pretrained_model_name_or_path"),g9t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),BNe=a("code"),h9t=o("pretrained_model_name_or_path"),u9t=o(":"),p9t=l(),Ue=a("ul"),a9=a("li"),INe=a("strong"),_9t=o("albert"),b9t=o(" \u2014 "),qce=a("a"),v9t=o("FlaxAlbertForMultipleChoice"),F9t=o(" (ALBERT model)"),T9t=l(),n9=a("li"),NNe=a("strong"),M9t=o("bert"),E9t=o(" \u2014 "),Dce=a("a"),C9t=o("FlaxBertForMultipleChoice"),w9t=o(" (BERT model)"),A9t=l(),s9=a("li"),qNe=a("strong"),L9t=o("big_bird"),y9t=o(" \u2014 "),jce=a("a"),x9t=o("FlaxBigBirdForMultipleChoice"),$9t=o(" (BigBird model)"),k9t=l(),l9=a("li"),DNe=a("strong"),S9t=o("distilbert"),R9t=o(" \u2014 "),Gce=a("a"),P9t=o("FlaxDistilBertForMultipleChoice"),B9t=o(" (DistilBERT model)"),I9t=l(),i9=a("li"),jNe=a("strong"),N9t=o("electra"),q9t=o(" \u2014 "),Oce=a("a"),D9t=o("FlaxElectraForMultipleChoice"),j9t=o(" (ELECTRA model)"),G9t=l(),d9=a("li"),GNe=a("strong"),O9t=o("roberta"),V9t=o(" \u2014 "),Vce=a("a"),X9t=o("FlaxRobertaForMultipleChoice"),z9t=o(" (RoBERTa model)"),Q9t=l(),m9=a("li"),ONe=a("strong"),W9t=o("roformer"),U9t=o(" \u2014 "),Xce=a("a"),H9t=o("FlaxRoFormerForMultipleChoice"),J9t=o(" (RoFormer model)"),Y9t=l(),c9=a("li"),VNe=a("strong"),Z9t=o("xlm-roberta"),K9t=o(" \u2014 "),zce=a("a"),ext=o("FlaxXLMRobertaForMultipleChoice"),oxt=o(" (XLM-RoBERTa model)"),rxt=l(),F(f9.$$.fragment),xdo=l(),Of=a("h2"),g9=a("a"),XNe=a("span"),F(OI.$$.fragment),txt=l(),zNe=a("span"),axt=o("FlaxAutoModelForNextSentencePrediction"),$do=l(),Dr=a("div"),F(VI.$$.fragment),nxt=l(),Vf=a("p"),sxt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Qce=a("a"),lxt=o("from_pretrained()"),ixt=o(" class method or the "),Wce=a("a"),dxt=o("from_config()"),mxt=o(` class
method.`),cxt=l(),XI=a("p"),fxt=o("This class cannot be instantiated directly using "),QNe=a("code"),gxt=o("__init__()"),hxt=o(" (throws an error)."),uxt=l(),Aa=a("div"),F(zI.$$.fragment),pxt=l(),WNe=a("p"),_xt=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),bxt=l(),Xf=a("p"),vxt=o(`Note:
Loading a model from its configuration file does `),UNe=a("strong"),Fxt=o("not"),Txt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Uce=a("a"),Mxt=o("from_pretrained()"),Ext=o(" to load the model weights."),Cxt=l(),F(h9.$$.fragment),wxt=l(),ut=a("div"),F(QI.$$.fragment),Axt=l(),HNe=a("p"),Lxt=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),yxt=l(),fs=a("p"),xxt=o("The model class to instantiate is selected based on the "),JNe=a("code"),$xt=o("model_type"),kxt=o(` property of the config object (either
passed as an argument or loaded from `),YNe=a("code"),Sxt=o("pretrained_model_name_or_path"),Rxt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ZNe=a("code"),Pxt=o("pretrained_model_name_or_path"),Bxt=o(":"),Ixt=l(),KNe=a("ul"),u9=a("li"),eqe=a("strong"),Nxt=o("bert"),qxt=o(" \u2014 "),Hce=a("a"),Dxt=o("FlaxBertForNextSentencePrediction"),jxt=o(" (BERT model)"),Gxt=l(),F(p9.$$.fragment),kdo=l(),zf=a("h2"),_9=a("a"),oqe=a("span"),F(WI.$$.fragment),Oxt=l(),rqe=a("span"),Vxt=o("FlaxAutoModelForImageClassification"),Sdo=l(),jr=a("div"),F(UI.$$.fragment),Xxt=l(),Qf=a("p"),zxt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Jce=a("a"),Qxt=o("from_pretrained()"),Wxt=o(" class method or the "),Yce=a("a"),Uxt=o("from_config()"),Hxt=o(` class
method.`),Jxt=l(),HI=a("p"),Yxt=o("This class cannot be instantiated directly using "),tqe=a("code"),Zxt=o("__init__()"),Kxt=o(" (throws an error)."),e$t=l(),La=a("div"),F(JI.$$.fragment),o$t=l(),aqe=a("p"),r$t=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),t$t=l(),Wf=a("p"),a$t=o(`Note:
Loading a model from its configuration file does `),nqe=a("strong"),n$t=o("not"),s$t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Zce=a("a"),l$t=o("from_pretrained()"),i$t=o(" to load the model weights."),d$t=l(),F(b9.$$.fragment),m$t=l(),pt=a("div"),F(YI.$$.fragment),c$t=l(),sqe=a("p"),f$t=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),g$t=l(),gs=a("p"),h$t=o("The model class to instantiate is selected based on the "),lqe=a("code"),u$t=o("model_type"),p$t=o(` property of the config object (either
passed as an argument or loaded from `),iqe=a("code"),_$t=o("pretrained_model_name_or_path"),b$t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dqe=a("code"),v$t=o("pretrained_model_name_or_path"),F$t=o(":"),T$t=l(),ZI=a("ul"),v9=a("li"),mqe=a("strong"),M$t=o("beit"),E$t=o(" \u2014 "),Kce=a("a"),C$t=o("FlaxBeitForImageClassification"),w$t=o(" (BEiT model)"),A$t=l(),F9=a("li"),cqe=a("strong"),L$t=o("vit"),y$t=o(" \u2014 "),efe=a("a"),x$t=o("FlaxViTForImageClassification"),$$t=o(" (ViT model)"),k$t=l(),F(T9.$$.fragment),Rdo=l(),Uf=a("h2"),M9=a("a"),fqe=a("span"),F(KI.$$.fragment),S$t=l(),gqe=a("span"),R$t=o("FlaxAutoModelForVision2Seq"),Pdo=l(),Gr=a("div"),F(eN.$$.fragment),P$t=l(),Hf=a("p"),B$t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),ofe=a("a"),I$t=o("from_pretrained()"),N$t=o(" class method or the "),rfe=a("a"),q$t=o("from_config()"),D$t=o(` class
method.`),j$t=l(),oN=a("p"),G$t=o("This class cannot be instantiated directly using "),hqe=a("code"),O$t=o("__init__()"),V$t=o(" (throws an error)."),X$t=l(),ya=a("div"),F(rN.$$.fragment),z$t=l(),uqe=a("p"),Q$t=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),W$t=l(),Jf=a("p"),U$t=o(`Note:
Loading a model from its configuration file does `),pqe=a("strong"),H$t=o("not"),J$t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tfe=a("a"),Y$t=o("from_pretrained()"),Z$t=o(" to load the model weights."),K$t=l(),F(E9.$$.fragment),ekt=l(),_t=a("div"),F(tN.$$.fragment),okt=l(),_qe=a("p"),rkt=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),tkt=l(),hs=a("p"),akt=o("The model class to instantiate is selected based on the "),bqe=a("code"),nkt=o("model_type"),skt=o(` property of the config object (either
passed as an argument or loaded from `),vqe=a("code"),lkt=o("pretrained_model_name_or_path"),ikt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Fqe=a("code"),dkt=o("pretrained_model_name_or_path"),mkt=o(":"),ckt=l(),Tqe=a("ul"),C9=a("li"),Mqe=a("strong"),fkt=o("vision-encoder-decoder"),gkt=o(" \u2014 "),afe=a("a"),hkt=o("FlaxVisionEncoderDecoderModel"),ukt=o(" (Vision Encoder decoder model)"),pkt=l(),F(w9.$$.fragment),this.h()},l(c){const _=X9a('[data-svelte="svelte-1phssyn"]',document.head);g=n(_,"META",{name:!0,content:!0}),_.forEach(t),v=i(c),u=n(c,"H1",{class:!0});var aN=s(u);f=n(aN,"A",{id:!0,class:!0,href:!0});var Eqe=s(f);p=n(Eqe,"SPAN",{});var Cqe=s(p);T(m.$$.fragment,Cqe),Cqe.forEach(t),Eqe.forEach(t),h=i(aN),He=n(aN,"SPAN",{});var wqe=s(He);Ad=r(wqe,"Auto Classes"),wqe.forEach(t),aN.forEach(t),eg=i(c),wt=n(c,"P",{});var nN=s(wt);Ld=r(nN,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),yd=n(nN,"CODE",{});var Aqe=s(yd);ik=r(Aqe,"from_pretrained()"),Aqe.forEach(t),og=r(nN,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),nN.forEach(t),Qe=i(c),Ze=n(c,"P",{});var us=s(Ze);xd=r(us,"Instantiating one of "),ps=n(us,"A",{href:!0});var Lqe=s(ps);dk=r(Lqe,"AutoConfig"),Lqe.forEach(t),_s=r(us,", "),bs=n(us,"A",{href:!0});var yqe=s(bs);mk=r(yqe,"AutoModel"),yqe.forEach(t),$d=r(us,`, and
`),vs=n(us,"A",{href:!0});var xqe=s(vs);ck=r(xqe,"AutoTokenizer"),xqe.forEach(t),kd=r(us," will directly create a class of the relevant architecture. For instance"),us.forEach(t),rg=i(c),T(sn.$$.fragment,c),Ke=i(c),ye=n(c,"P",{});var sN=s(ye);Sq=r(sN,"will create a model that is an instance of "),Sd=n(sN,"A",{href:!0});var $qe=s(Sd);Rq=r($qe,"BertModel"),$qe.forEach(t),Pq=r(sN,"."),sN.forEach(t),Po=i(c),ln=n(c,"P",{});var lN=s(ln);Bq=r(lN,"There is one class of "),tg=n(lN,"CODE",{});var kqe=s(tg);Iq=r(kqe,"AutoModel"),kqe.forEach(t),ifo=r(lN," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),lN.forEach(t),plo=i(c),Rd=n(c,"H2",{class:!0});var iN=s(Rd);ag=n(iN,"A",{id:!0,class:!0,href:!0});var Sqe=s(ag);ghe=n(Sqe,"SPAN",{});var Rqe=s(ghe);T(fk.$$.fragment,Rqe),Rqe.forEach(t),Sqe.forEach(t),dfo=i(iN),hhe=n(iN,"SPAN",{});var Pqe=s(hhe);mfo=r(Pqe,"Extending the Auto Classes"),Pqe.forEach(t),iN.forEach(t),_lo=i(c),Fs=n(c,"P",{});var Yf=s(Fs);cfo=r(Yf,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),uhe=n(Yf,"CODE",{});var Bqe=s(uhe);ffo=r(Bqe,"NewModel"),Bqe.forEach(t),gfo=r(Yf,", make sure you have a "),phe=n(Yf,"CODE",{});var Iqe=s(phe);hfo=r(Iqe,"NewModelConfig"),Iqe.forEach(t),ufo=r(Yf,` then you can add those to the auto
classes like this:`),Yf.forEach(t),blo=i(c),T(gk.$$.fragment,c),vlo=i(c),Nq=n(c,"P",{});var Nqe=s(Nq);pfo=r(Nqe,"You will then be able to use the auto classes like you would usually do!"),Nqe.forEach(t),Flo=i(c),T(ng.$$.fragment,c),Tlo=i(c),Pd=n(c,"H2",{class:!0});var dN=s(Pd);sg=n(dN,"A",{id:!0,class:!0,href:!0});var qqe=s(sg);_he=n(qqe,"SPAN",{});var Dqe=s(_he);T(hk.$$.fragment,Dqe),Dqe.forEach(t),qqe.forEach(t),_fo=i(dN),bhe=n(dN,"SPAN",{});var jqe=s(bhe);bfo=r(jqe,"AutoConfig"),jqe.forEach(t),dN.forEach(t),Mlo=i(c),Bo=n(c,"DIV",{class:!0});var Et=s(Bo);T(uk.$$.fragment,Et),vfo=i(Et),pk=n(Et,"P",{});var mN=s(pk);Ffo=r(mN,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),qq=n(mN,"A",{href:!0});var Gqe=s(qq);Tfo=r(Gqe,"from_pretrained()"),Gqe.forEach(t),Mfo=r(mN," class method."),mN.forEach(t),Efo=i(Et),_k=n(Et,"P",{});var cN=s(_k);Cfo=r(cN,"This class cannot be instantiated directly using "),vhe=n(cN,"CODE",{});var Oqe=s(vhe);wfo=r(Oqe,"__init__()"),Oqe.forEach(t),Afo=r(cN," (throws an error)."),cN.forEach(t),Lfo=i(Et),Or=n(Et,"DIV",{class:!0});var Ct=s(Or);T(bk.$$.fragment,Ct),yfo=i(Ct),Fhe=n(Ct,"P",{});var Vqe=s(Fhe);xfo=r(Vqe,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),Vqe.forEach(t),$fo=i(Ct),Bd=n(Ct,"P",{});var Zf=s(Bd);kfo=r(Zf,"The configuration class to instantiate is selected based on the "),The=n(Zf,"CODE",{});var Xqe=s(The);Sfo=r(Xqe,"model_type"),Xqe.forEach(t),Rfo=r(Zf,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Mhe=n(Zf,"CODE",{});var zqe=s(Mhe);Pfo=r(zqe,"pretrained_model_name_or_path"),zqe.forEach(t),Bfo=r(Zf,":"),Zf.forEach(t),Ifo=i(Ct),A=n(Ct,"UL",{});var L=s(A);lg=n(L,"LI",{});var A9=s(lg);Ehe=n(A9,"STRONG",{});var Qqe=s(Ehe);Nfo=r(Qqe,"albert"),Qqe.forEach(t),qfo=r(A9," \u2014 "),Dq=n(A9,"A",{href:!0});var Wqe=s(Dq);Dfo=r(Wqe,"AlbertConfig"),Wqe.forEach(t),jfo=r(A9," (ALBERT model)"),A9.forEach(t),Gfo=i(L),ig=n(L,"LI",{});var L9=s(ig);Che=n(L9,"STRONG",{});var Uqe=s(Che);Ofo=r(Uqe,"bart"),Uqe.forEach(t),Vfo=r(L9," \u2014 "),jq=n(L9,"A",{href:!0});var Hqe=s(jq);Xfo=r(Hqe,"BartConfig"),Hqe.forEach(t),zfo=r(L9," (BART model)"),L9.forEach(t),Qfo=i(L),dg=n(L,"LI",{});var y9=s(dg);whe=n(y9,"STRONG",{});var Jqe=s(whe);Wfo=r(Jqe,"beit"),Jqe.forEach(t),Ufo=r(y9," \u2014 "),Gq=n(y9,"A",{href:!0});var Yqe=s(Gq);Hfo=r(Yqe,"BeitConfig"),Yqe.forEach(t),Jfo=r(y9," (BEiT model)"),y9.forEach(t),Yfo=i(L),mg=n(L,"LI",{});var x9=s(mg);Ahe=n(x9,"STRONG",{});var Zqe=s(Ahe);Zfo=r(Zqe,"bert"),Zqe.forEach(t),Kfo=r(x9," \u2014 "),Oq=n(x9,"A",{href:!0});var Kqe=s(Oq);ego=r(Kqe,"BertConfig"),Kqe.forEach(t),ogo=r(x9," (BERT model)"),x9.forEach(t),rgo=i(L),cg=n(L,"LI",{});var $9=s(cg);Lhe=n($9,"STRONG",{});var eDe=s(Lhe);tgo=r(eDe,"bert-generation"),eDe.forEach(t),ago=r($9," \u2014 "),Vq=n($9,"A",{href:!0});var oDe=s(Vq);ngo=r(oDe,"BertGenerationConfig"),oDe.forEach(t),sgo=r($9," (Bert Generation model)"),$9.forEach(t),lgo=i(L),fg=n(L,"LI",{});var k9=s(fg);yhe=n(k9,"STRONG",{});var rDe=s(yhe);igo=r(rDe,"big_bird"),rDe.forEach(t),dgo=r(k9," \u2014 "),Xq=n(k9,"A",{href:!0});var tDe=s(Xq);mgo=r(tDe,"BigBirdConfig"),tDe.forEach(t),cgo=r(k9," (BigBird model)"),k9.forEach(t),fgo=i(L),gg=n(L,"LI",{});var S9=s(gg);xhe=n(S9,"STRONG",{});var aDe=s(xhe);ggo=r(aDe,"bigbird_pegasus"),aDe.forEach(t),hgo=r(S9," \u2014 "),zq=n(S9,"A",{href:!0});var nDe=s(zq);ugo=r(nDe,"BigBirdPegasusConfig"),nDe.forEach(t),pgo=r(S9," (BigBird-Pegasus model)"),S9.forEach(t),_go=i(L),hg=n(L,"LI",{});var R9=s(hg);$he=n(R9,"STRONG",{});var sDe=s($he);bgo=r(sDe,"blenderbot"),sDe.forEach(t),vgo=r(R9," \u2014 "),Qq=n(R9,"A",{href:!0});var lDe=s(Qq);Fgo=r(lDe,"BlenderbotConfig"),lDe.forEach(t),Tgo=r(R9," (Blenderbot model)"),R9.forEach(t),Mgo=i(L),ug=n(L,"LI",{});var P9=s(ug);khe=n(P9,"STRONG",{});var iDe=s(khe);Ego=r(iDe,"blenderbot-small"),iDe.forEach(t),Cgo=r(P9," \u2014 "),Wq=n(P9,"A",{href:!0});var dDe=s(Wq);wgo=r(dDe,"BlenderbotSmallConfig"),dDe.forEach(t),Ago=r(P9," (BlenderbotSmall model)"),P9.forEach(t),Lgo=i(L),pg=n(L,"LI",{});var B9=s(pg);She=n(B9,"STRONG",{});var mDe=s(She);ygo=r(mDe,"bloom"),mDe.forEach(t),xgo=r(B9," \u2014 "),Uq=n(B9,"A",{href:!0});var cDe=s(Uq);$go=r(cDe,"BloomConfig"),cDe.forEach(t),kgo=r(B9," (BLOOM model)"),B9.forEach(t),Sgo=i(L),_g=n(L,"LI",{});var I9=s(_g);Rhe=n(I9,"STRONG",{});var fDe=s(Rhe);Rgo=r(fDe,"camembert"),fDe.forEach(t),Pgo=r(I9," \u2014 "),Hq=n(I9,"A",{href:!0});var gDe=s(Hq);Bgo=r(gDe,"CamembertConfig"),gDe.forEach(t),Igo=r(I9," (CamemBERT model)"),I9.forEach(t),Ngo=i(L),bg=n(L,"LI",{});var N9=s(bg);Phe=n(N9,"STRONG",{});var hDe=s(Phe);qgo=r(hDe,"canine"),hDe.forEach(t),Dgo=r(N9," \u2014 "),Jq=n(N9,"A",{href:!0});var uDe=s(Jq);jgo=r(uDe,"CanineConfig"),uDe.forEach(t),Ggo=r(N9," (CANINE model)"),N9.forEach(t),Ogo=i(L),vg=n(L,"LI",{});var q9=s(vg);Bhe=n(q9,"STRONG",{});var pDe=s(Bhe);Vgo=r(pDe,"clip"),pDe.forEach(t),Xgo=r(q9," \u2014 "),Yq=n(q9,"A",{href:!0});var _De=s(Yq);zgo=r(_De,"CLIPConfig"),_De.forEach(t),Qgo=r(q9," (CLIP model)"),q9.forEach(t),Wgo=i(L),Fg=n(L,"LI",{});var D9=s(Fg);Ihe=n(D9,"STRONG",{});var bDe=s(Ihe);Ugo=r(bDe,"clipseg"),bDe.forEach(t),Hgo=r(D9," \u2014 "),Zq=n(D9,"A",{href:!0});var vDe=s(Zq);Jgo=r(vDe,"CLIPSegConfig"),vDe.forEach(t),Ygo=r(D9," (CLIPSeg model)"),D9.forEach(t),Zgo=i(L),Tg=n(L,"LI",{});var j9=s(Tg);Nhe=n(j9,"STRONG",{});var FDe=s(Nhe);Kgo=r(FDe,"codegen"),FDe.forEach(t),eho=r(j9," \u2014 "),Kq=n(j9,"A",{href:!0});var TDe=s(Kq);oho=r(TDe,"CodeGenConfig"),TDe.forEach(t),rho=r(j9," (CodeGen model)"),j9.forEach(t),tho=i(L),Mg=n(L,"LI",{});var G9=s(Mg);qhe=n(G9,"STRONG",{});var MDe=s(qhe);aho=r(MDe,"conditional_detr"),MDe.forEach(t),nho=r(G9," \u2014 "),eD=n(G9,"A",{href:!0});var EDe=s(eD);sho=r(EDe,"ConditionalDetrConfig"),EDe.forEach(t),lho=r(G9," (Conditional DETR model)"),G9.forEach(t),iho=i(L),Eg=n(L,"LI",{});var O9=s(Eg);Dhe=n(O9,"STRONG",{});var CDe=s(Dhe);dho=r(CDe,"convbert"),CDe.forEach(t),mho=r(O9," \u2014 "),oD=n(O9,"A",{href:!0});var wDe=s(oD);cho=r(wDe,"ConvBertConfig"),wDe.forEach(t),fho=r(O9," (ConvBERT model)"),O9.forEach(t),gho=i(L),Cg=n(L,"LI",{});var V9=s(Cg);jhe=n(V9,"STRONG",{});var ADe=s(jhe);hho=r(ADe,"convnext"),ADe.forEach(t),uho=r(V9," \u2014 "),rD=n(V9,"A",{href:!0});var LDe=s(rD);pho=r(LDe,"ConvNextConfig"),LDe.forEach(t),_ho=r(V9," (ConvNeXT model)"),V9.forEach(t),bho=i(L),wg=n(L,"LI",{});var X9=s(wg);Ghe=n(X9,"STRONG",{});var yDe=s(Ghe);vho=r(yDe,"ctrl"),yDe.forEach(t),Fho=r(X9," \u2014 "),tD=n(X9,"A",{href:!0});var xDe=s(tD);Tho=r(xDe,"CTRLConfig"),xDe.forEach(t),Mho=r(X9," (CTRL model)"),X9.forEach(t),Eho=i(L),Ag=n(L,"LI",{});var z9=s(Ag);Ohe=n(z9,"STRONG",{});var $De=s(Ohe);Cho=r($De,"cvt"),$De.forEach(t),who=r(z9," \u2014 "),aD=n(z9,"A",{href:!0});var kDe=s(aD);Aho=r(kDe,"CvtConfig"),kDe.forEach(t),Lho=r(z9," (CvT model)"),z9.forEach(t),yho=i(L),Lg=n(L,"LI",{});var Q9=s(Lg);Vhe=n(Q9,"STRONG",{});var SDe=s(Vhe);xho=r(SDe,"data2vec-audio"),SDe.forEach(t),$ho=r(Q9," \u2014 "),nD=n(Q9,"A",{href:!0});var RDe=s(nD);kho=r(RDe,"Data2VecAudioConfig"),RDe.forEach(t),Sho=r(Q9," (Data2VecAudio model)"),Q9.forEach(t),Rho=i(L),yg=n(L,"LI",{});var W9=s(yg);Xhe=n(W9,"STRONG",{});var PDe=s(Xhe);Pho=r(PDe,"data2vec-text"),PDe.forEach(t),Bho=r(W9," \u2014 "),sD=n(W9,"A",{href:!0});var BDe=s(sD);Iho=r(BDe,"Data2VecTextConfig"),BDe.forEach(t),Nho=r(W9," (Data2VecText model)"),W9.forEach(t),qho=i(L),xg=n(L,"LI",{});var U9=s(xg);zhe=n(U9,"STRONG",{});var IDe=s(zhe);Dho=r(IDe,"data2vec-vision"),IDe.forEach(t),jho=r(U9," \u2014 "),lD=n(U9,"A",{href:!0});var NDe=s(lD);Gho=r(NDe,"Data2VecVisionConfig"),NDe.forEach(t),Oho=r(U9," (Data2VecVision model)"),U9.forEach(t),Vho=i(L),$g=n(L,"LI",{});var H9=s($g);Qhe=n(H9,"STRONG",{});var qDe=s(Qhe);Xho=r(qDe,"deberta"),qDe.forEach(t),zho=r(H9," \u2014 "),iD=n(H9,"A",{href:!0});var DDe=s(iD);Qho=r(DDe,"DebertaConfig"),DDe.forEach(t),Who=r(H9," (DeBERTa model)"),H9.forEach(t),Uho=i(L),kg=n(L,"LI",{});var J9=s(kg);Whe=n(J9,"STRONG",{});var jDe=s(Whe);Hho=r(jDe,"deberta-v2"),jDe.forEach(t),Jho=r(J9," \u2014 "),dD=n(J9,"A",{href:!0});var GDe=s(dD);Yho=r(GDe,"DebertaV2Config"),GDe.forEach(t),Zho=r(J9," (DeBERTa-v2 model)"),J9.forEach(t),Kho=i(L),Sg=n(L,"LI",{});var Y9=s(Sg);Uhe=n(Y9,"STRONG",{});var ODe=s(Uhe);euo=r(ODe,"decision_transformer"),ODe.forEach(t),ouo=r(Y9," \u2014 "),mD=n(Y9,"A",{href:!0});var VDe=s(mD);ruo=r(VDe,"DecisionTransformerConfig"),VDe.forEach(t),tuo=r(Y9," (Decision Transformer model)"),Y9.forEach(t),auo=i(L),Rg=n(L,"LI",{});var Z9=s(Rg);Hhe=n(Z9,"STRONG",{});var XDe=s(Hhe);nuo=r(XDe,"deformable_detr"),XDe.forEach(t),suo=r(Z9," \u2014 "),cD=n(Z9,"A",{href:!0});var zDe=s(cD);luo=r(zDe,"DeformableDetrConfig"),zDe.forEach(t),iuo=r(Z9," (Deformable DETR model)"),Z9.forEach(t),duo=i(L),Pg=n(L,"LI",{});var K9=s(Pg);Jhe=n(K9,"STRONG",{});var QDe=s(Jhe);muo=r(QDe,"deit"),QDe.forEach(t),cuo=r(K9," \u2014 "),fD=n(K9,"A",{href:!0});var WDe=s(fD);fuo=r(WDe,"DeiTConfig"),WDe.forEach(t),guo=r(K9," (DeiT model)"),K9.forEach(t),huo=i(L),Bg=n(L,"LI",{});var UDe=s(Bg);Yhe=n(UDe,"STRONG",{});var _kt=s(Yhe);uuo=r(_kt,"detr"),_kt.forEach(t),puo=r(UDe," \u2014 "),gD=n(UDe,"A",{href:!0});var bkt=s(gD);_uo=r(bkt,"DetrConfig"),bkt.forEach(t),buo=r(UDe," (DETR model)"),UDe.forEach(t),vuo=i(L),Ig=n(L,"LI",{});var HDe=s(Ig);Zhe=n(HDe,"STRONG",{});var vkt=s(Zhe);Fuo=r(vkt,"distilbert"),vkt.forEach(t),Tuo=r(HDe," \u2014 "),hD=n(HDe,"A",{href:!0});var Fkt=s(hD);Muo=r(Fkt,"DistilBertConfig"),Fkt.forEach(t),Euo=r(HDe," (DistilBERT model)"),HDe.forEach(t),Cuo=i(L),Ng=n(L,"LI",{});var JDe=s(Ng);Khe=n(JDe,"STRONG",{});var Tkt=s(Khe);wuo=r(Tkt,"donut-swin"),Tkt.forEach(t),Auo=r(JDe," \u2014 "),uD=n(JDe,"A",{href:!0});var Mkt=s(uD);Luo=r(Mkt,"DonutSwinConfig"),Mkt.forEach(t),yuo=r(JDe," (DonutSwin model)"),JDe.forEach(t),xuo=i(L),qg=n(L,"LI",{});var YDe=s(qg);eue=n(YDe,"STRONG",{});var Ekt=s(eue);$uo=r(Ekt,"dpr"),Ekt.forEach(t),kuo=r(YDe," \u2014 "),pD=n(YDe,"A",{href:!0});var Ckt=s(pD);Suo=r(Ckt,"DPRConfig"),Ckt.forEach(t),Ruo=r(YDe," (DPR model)"),YDe.forEach(t),Puo=i(L),Dg=n(L,"LI",{});var ZDe=s(Dg);oue=n(ZDe,"STRONG",{});var wkt=s(oue);Buo=r(wkt,"dpt"),wkt.forEach(t),Iuo=r(ZDe," \u2014 "),_D=n(ZDe,"A",{href:!0});var Akt=s(_D);Nuo=r(Akt,"DPTConfig"),Akt.forEach(t),quo=r(ZDe," (DPT model)"),ZDe.forEach(t),Duo=i(L),jg=n(L,"LI",{});var KDe=s(jg);rue=n(KDe,"STRONG",{});var Lkt=s(rue);juo=r(Lkt,"electra"),Lkt.forEach(t),Guo=r(KDe," \u2014 "),bD=n(KDe,"A",{href:!0});var ykt=s(bD);Ouo=r(ykt,"ElectraConfig"),ykt.forEach(t),Vuo=r(KDe," (ELECTRA model)"),KDe.forEach(t),Xuo=i(L),Gg=n(L,"LI",{});var eje=s(Gg);tue=n(eje,"STRONG",{});var xkt=s(tue);zuo=r(xkt,"encoder-decoder"),xkt.forEach(t),Quo=r(eje," \u2014 "),vD=n(eje,"A",{href:!0});var $kt=s(vD);Wuo=r($kt,"EncoderDecoderConfig"),$kt.forEach(t),Uuo=r(eje," (Encoder decoder model)"),eje.forEach(t),Huo=i(L),Og=n(L,"LI",{});var oje=s(Og);aue=n(oje,"STRONG",{});var kkt=s(aue);Juo=r(kkt,"ernie"),kkt.forEach(t),Yuo=r(oje," \u2014 "),FD=n(oje,"A",{href:!0});var Skt=s(FD);Zuo=r(Skt,"ErnieConfig"),Skt.forEach(t),Kuo=r(oje," (ERNIE model)"),oje.forEach(t),epo=i(L),Vg=n(L,"LI",{});var rje=s(Vg);nue=n(rje,"STRONG",{});var Rkt=s(nue);opo=r(Rkt,"esm"),Rkt.forEach(t),rpo=r(rje," \u2014 "),TD=n(rje,"A",{href:!0});var Pkt=s(TD);tpo=r(Pkt,"EsmConfig"),Pkt.forEach(t),apo=r(rje," (ESM model)"),rje.forEach(t),npo=i(L),Xg=n(L,"LI",{});var tje=s(Xg);sue=n(tje,"STRONG",{});var Bkt=s(sue);spo=r(Bkt,"flaubert"),Bkt.forEach(t),lpo=r(tje," \u2014 "),MD=n(tje,"A",{href:!0});var Ikt=s(MD);ipo=r(Ikt,"FlaubertConfig"),Ikt.forEach(t),dpo=r(tje," (FlauBERT model)"),tje.forEach(t),mpo=i(L),zg=n(L,"LI",{});var aje=s(zg);lue=n(aje,"STRONG",{});var Nkt=s(lue);cpo=r(Nkt,"flava"),Nkt.forEach(t),fpo=r(aje," \u2014 "),ED=n(aje,"A",{href:!0});var qkt=s(ED);gpo=r(qkt,"FlavaConfig"),qkt.forEach(t),hpo=r(aje," (FLAVA model)"),aje.forEach(t),upo=i(L),Qg=n(L,"LI",{});var nje=s(Qg);iue=n(nje,"STRONG",{});var Dkt=s(iue);ppo=r(Dkt,"fnet"),Dkt.forEach(t),_po=r(nje," \u2014 "),CD=n(nje,"A",{href:!0});var jkt=s(CD);bpo=r(jkt,"FNetConfig"),jkt.forEach(t),vpo=r(nje," (FNet model)"),nje.forEach(t),Fpo=i(L),Wg=n(L,"LI",{});var sje=s(Wg);due=n(sje,"STRONG",{});var Gkt=s(due);Tpo=r(Gkt,"fsmt"),Gkt.forEach(t),Mpo=r(sje," \u2014 "),wD=n(sje,"A",{href:!0});var Okt=s(wD);Epo=r(Okt,"FSMTConfig"),Okt.forEach(t),Cpo=r(sje," (FairSeq Machine-Translation model)"),sje.forEach(t),wpo=i(L),Ug=n(L,"LI",{});var lje=s(Ug);mue=n(lje,"STRONG",{});var Vkt=s(mue);Apo=r(Vkt,"funnel"),Vkt.forEach(t),Lpo=r(lje," \u2014 "),AD=n(lje,"A",{href:!0});var Xkt=s(AD);ypo=r(Xkt,"FunnelConfig"),Xkt.forEach(t),xpo=r(lje," (Funnel Transformer model)"),lje.forEach(t),$po=i(L),Hg=n(L,"LI",{});var ije=s(Hg);cue=n(ije,"STRONG",{});var zkt=s(cue);kpo=r(zkt,"glpn"),zkt.forEach(t),Spo=r(ije," \u2014 "),LD=n(ije,"A",{href:!0});var Qkt=s(LD);Rpo=r(Qkt,"GLPNConfig"),Qkt.forEach(t),Ppo=r(ije," (GLPN model)"),ije.forEach(t),Bpo=i(L),Jg=n(L,"LI",{});var dje=s(Jg);fue=n(dje,"STRONG",{});var Wkt=s(fue);Ipo=r(Wkt,"gpt2"),Wkt.forEach(t),Npo=r(dje," \u2014 "),yD=n(dje,"A",{href:!0});var Ukt=s(yD);qpo=r(Ukt,"GPT2Config"),Ukt.forEach(t),Dpo=r(dje," (OpenAI GPT-2 model)"),dje.forEach(t),jpo=i(L),Yg=n(L,"LI",{});var mje=s(Yg);gue=n(mje,"STRONG",{});var Hkt=s(gue);Gpo=r(Hkt,"gpt_neo"),Hkt.forEach(t),Opo=r(mje," \u2014 "),xD=n(mje,"A",{href:!0});var Jkt=s(xD);Vpo=r(Jkt,"GPTNeoConfig"),Jkt.forEach(t),Xpo=r(mje," (GPT Neo model)"),mje.forEach(t),zpo=i(L),Zg=n(L,"LI",{});var cje=s(Zg);hue=n(cje,"STRONG",{});var Ykt=s(hue);Qpo=r(Ykt,"gpt_neox"),Ykt.forEach(t),Wpo=r(cje," \u2014 "),$D=n(cje,"A",{href:!0});var Zkt=s($D);Upo=r(Zkt,"GPTNeoXConfig"),Zkt.forEach(t),Hpo=r(cje," (GPT NeoX model)"),cje.forEach(t),Jpo=i(L),Kg=n(L,"LI",{});var fje=s(Kg);uue=n(fje,"STRONG",{});var Kkt=s(uue);Ypo=r(Kkt,"gpt_neox_japanese"),Kkt.forEach(t),Zpo=r(fje," \u2014 "),kD=n(fje,"A",{href:!0});var eSt=s(kD);Kpo=r(eSt,"GPTNeoXJapaneseConfig"),eSt.forEach(t),e_o=r(fje," (GPT NeoX Japanese model)"),fje.forEach(t),o_o=i(L),eh=n(L,"LI",{});var gje=s(eh);pue=n(gje,"STRONG",{});var oSt=s(pue);r_o=r(oSt,"gptj"),oSt.forEach(t),t_o=r(gje," \u2014 "),SD=n(gje,"A",{href:!0});var rSt=s(SD);a_o=r(rSt,"GPTJConfig"),rSt.forEach(t),n_o=r(gje," (GPT-J model)"),gje.forEach(t),s_o=i(L),oh=n(L,"LI",{});var hje=s(oh);_ue=n(hje,"STRONG",{});var tSt=s(_ue);l_o=r(tSt,"groupvit"),tSt.forEach(t),i_o=r(hje," \u2014 "),RD=n(hje,"A",{href:!0});var aSt=s(RD);d_o=r(aSt,"GroupViTConfig"),aSt.forEach(t),m_o=r(hje," (GroupViT model)"),hje.forEach(t),c_o=i(L),rh=n(L,"LI",{});var uje=s(rh);bue=n(uje,"STRONG",{});var nSt=s(bue);f_o=r(nSt,"hubert"),nSt.forEach(t),g_o=r(uje," \u2014 "),PD=n(uje,"A",{href:!0});var sSt=s(PD);h_o=r(sSt,"HubertConfig"),sSt.forEach(t),u_o=r(uje," (Hubert model)"),uje.forEach(t),p_o=i(L),th=n(L,"LI",{});var pje=s(th);vue=n(pje,"STRONG",{});var lSt=s(vue);__o=r(lSt,"ibert"),lSt.forEach(t),b_o=r(pje," \u2014 "),BD=n(pje,"A",{href:!0});var iSt=s(BD);v_o=r(iSt,"IBertConfig"),iSt.forEach(t),F_o=r(pje," (I-BERT model)"),pje.forEach(t),T_o=i(L),ah=n(L,"LI",{});var _je=s(ah);Fue=n(_je,"STRONG",{});var dSt=s(Fue);M_o=r(dSt,"imagegpt"),dSt.forEach(t),E_o=r(_je," \u2014 "),ID=n(_je,"A",{href:!0});var mSt=s(ID);C_o=r(mSt,"ImageGPTConfig"),mSt.forEach(t),w_o=r(_je," (ImageGPT model)"),_je.forEach(t),A_o=i(L),nh=n(L,"LI",{});var bje=s(nh);Tue=n(bje,"STRONG",{});var cSt=s(Tue);L_o=r(cSt,"layoutlm"),cSt.forEach(t),y_o=r(bje," \u2014 "),ND=n(bje,"A",{href:!0});var fSt=s(ND);x_o=r(fSt,"LayoutLMConfig"),fSt.forEach(t),$_o=r(bje," (LayoutLM model)"),bje.forEach(t),k_o=i(L),sh=n(L,"LI",{});var vje=s(sh);Mue=n(vje,"STRONG",{});var gSt=s(Mue);S_o=r(gSt,"layoutlmv2"),gSt.forEach(t),R_o=r(vje," \u2014 "),qD=n(vje,"A",{href:!0});var hSt=s(qD);P_o=r(hSt,"LayoutLMv2Config"),hSt.forEach(t),B_o=r(vje," (LayoutLMv2 model)"),vje.forEach(t),I_o=i(L),lh=n(L,"LI",{});var Fje=s(lh);Eue=n(Fje,"STRONG",{});var uSt=s(Eue);N_o=r(uSt,"layoutlmv3"),uSt.forEach(t),q_o=r(Fje," \u2014 "),DD=n(Fje,"A",{href:!0});var pSt=s(DD);D_o=r(pSt,"LayoutLMv3Config"),pSt.forEach(t),j_o=r(Fje," (LayoutLMv3 model)"),Fje.forEach(t),G_o=i(L),ih=n(L,"LI",{});var Tje=s(ih);Cue=n(Tje,"STRONG",{});var _St=s(Cue);O_o=r(_St,"led"),_St.forEach(t),V_o=r(Tje," \u2014 "),jD=n(Tje,"A",{href:!0});var bSt=s(jD);X_o=r(bSt,"LEDConfig"),bSt.forEach(t),z_o=r(Tje," (LED model)"),Tje.forEach(t),Q_o=i(L),dh=n(L,"LI",{});var Mje=s(dh);wue=n(Mje,"STRONG",{});var vSt=s(wue);W_o=r(vSt,"levit"),vSt.forEach(t),U_o=r(Mje," \u2014 "),GD=n(Mje,"A",{href:!0});var FSt=s(GD);H_o=r(FSt,"LevitConfig"),FSt.forEach(t),J_o=r(Mje," (LeViT model)"),Mje.forEach(t),Y_o=i(L),mh=n(L,"LI",{});var Eje=s(mh);Aue=n(Eje,"STRONG",{});var TSt=s(Aue);Z_o=r(TSt,"lilt"),TSt.forEach(t),K_o=r(Eje," \u2014 "),OD=n(Eje,"A",{href:!0});var MSt=s(OD);e1o=r(MSt,"LiltConfig"),MSt.forEach(t),o1o=r(Eje," (LiLT model)"),Eje.forEach(t),r1o=i(L),ch=n(L,"LI",{});var Cje=s(ch);Lue=n(Cje,"STRONG",{});var ESt=s(Lue);t1o=r(ESt,"longformer"),ESt.forEach(t),a1o=r(Cje," \u2014 "),VD=n(Cje,"A",{href:!0});var CSt=s(VD);n1o=r(CSt,"LongformerConfig"),CSt.forEach(t),s1o=r(Cje," (Longformer model)"),Cje.forEach(t),l1o=i(L),fh=n(L,"LI",{});var wje=s(fh);yue=n(wje,"STRONG",{});var wSt=s(yue);i1o=r(wSt,"longt5"),wSt.forEach(t),d1o=r(wje," \u2014 "),XD=n(wje,"A",{href:!0});var ASt=s(XD);m1o=r(ASt,"LongT5Config"),ASt.forEach(t),c1o=r(wje," (LongT5 model)"),wje.forEach(t),f1o=i(L),gh=n(L,"LI",{});var Aje=s(gh);xue=n(Aje,"STRONG",{});var LSt=s(xue);g1o=r(LSt,"luke"),LSt.forEach(t),h1o=r(Aje," \u2014 "),zD=n(Aje,"A",{href:!0});var ySt=s(zD);u1o=r(ySt,"LukeConfig"),ySt.forEach(t),p1o=r(Aje," (LUKE model)"),Aje.forEach(t),_1o=i(L),hh=n(L,"LI",{});var Lje=s(hh);$ue=n(Lje,"STRONG",{});var xSt=s($ue);b1o=r(xSt,"lxmert"),xSt.forEach(t),v1o=r(Lje," \u2014 "),QD=n(Lje,"A",{href:!0});var $St=s(QD);F1o=r($St,"LxmertConfig"),$St.forEach(t),T1o=r(Lje," (LXMERT model)"),Lje.forEach(t),M1o=i(L),uh=n(L,"LI",{});var yje=s(uh);kue=n(yje,"STRONG",{});var kSt=s(kue);E1o=r(kSt,"m2m_100"),kSt.forEach(t),C1o=r(yje," \u2014 "),WD=n(yje,"A",{href:!0});var SSt=s(WD);w1o=r(SSt,"M2M100Config"),SSt.forEach(t),A1o=r(yje," (M2M100 model)"),yje.forEach(t),L1o=i(L),ph=n(L,"LI",{});var xje=s(ph);Sue=n(xje,"STRONG",{});var RSt=s(Sue);y1o=r(RSt,"marian"),RSt.forEach(t),x1o=r(xje," \u2014 "),UD=n(xje,"A",{href:!0});var PSt=s(UD);$1o=r(PSt,"MarianConfig"),PSt.forEach(t),k1o=r(xje," (Marian model)"),xje.forEach(t),S1o=i(L),_h=n(L,"LI",{});var $je=s(_h);Rue=n($je,"STRONG",{});var BSt=s(Rue);R1o=r(BSt,"markuplm"),BSt.forEach(t),P1o=r($je," \u2014 "),HD=n($je,"A",{href:!0});var ISt=s(HD);B1o=r(ISt,"MarkupLMConfig"),ISt.forEach(t),I1o=r($je," (MarkupLM model)"),$je.forEach(t),N1o=i(L),bh=n(L,"LI",{});var kje=s(bh);Pue=n(kje,"STRONG",{});var NSt=s(Pue);q1o=r(NSt,"maskformer"),NSt.forEach(t),D1o=r(kje," \u2014 "),JD=n(kje,"A",{href:!0});var qSt=s(JD);j1o=r(qSt,"MaskFormerConfig"),qSt.forEach(t),G1o=r(kje," (MaskFormer model)"),kje.forEach(t),O1o=i(L),vh=n(L,"LI",{});var Sje=s(vh);Bue=n(Sje,"STRONG",{});var DSt=s(Bue);V1o=r(DSt,"mbart"),DSt.forEach(t),X1o=r(Sje," \u2014 "),YD=n(Sje,"A",{href:!0});var jSt=s(YD);z1o=r(jSt,"MBartConfig"),jSt.forEach(t),Q1o=r(Sje," (mBART model)"),Sje.forEach(t),W1o=i(L),Fh=n(L,"LI",{});var Rje=s(Fh);Iue=n(Rje,"STRONG",{});var GSt=s(Iue);U1o=r(GSt,"mctct"),GSt.forEach(t),H1o=r(Rje," \u2014 "),ZD=n(Rje,"A",{href:!0});var OSt=s(ZD);J1o=r(OSt,"MCTCTConfig"),OSt.forEach(t),Y1o=r(Rje," (M-CTC-T model)"),Rje.forEach(t),Z1o=i(L),Th=n(L,"LI",{});var Pje=s(Th);Nue=n(Pje,"STRONG",{});var VSt=s(Nue);K1o=r(VSt,"megatron-bert"),VSt.forEach(t),e2o=r(Pje," \u2014 "),KD=n(Pje,"A",{href:!0});var XSt=s(KD);o2o=r(XSt,"MegatronBertConfig"),XSt.forEach(t),r2o=r(Pje," (Megatron-BERT model)"),Pje.forEach(t),t2o=i(L),Mh=n(L,"LI",{});var Bje=s(Mh);que=n(Bje,"STRONG",{});var zSt=s(que);a2o=r(zSt,"mobilebert"),zSt.forEach(t),n2o=r(Bje," \u2014 "),ej=n(Bje,"A",{href:!0});var QSt=s(ej);s2o=r(QSt,"MobileBertConfig"),QSt.forEach(t),l2o=r(Bje," (MobileBERT model)"),Bje.forEach(t),i2o=i(L),Eh=n(L,"LI",{});var Ije=s(Eh);Due=n(Ije,"STRONG",{});var WSt=s(Due);d2o=r(WSt,"mobilevit"),WSt.forEach(t),m2o=r(Ije," \u2014 "),oj=n(Ije,"A",{href:!0});var USt=s(oj);c2o=r(USt,"MobileViTConfig"),USt.forEach(t),f2o=r(Ije," (MobileViT model)"),Ije.forEach(t),g2o=i(L),Ch=n(L,"LI",{});var Nje=s(Ch);jue=n(Nje,"STRONG",{});var HSt=s(jue);h2o=r(HSt,"mpnet"),HSt.forEach(t),u2o=r(Nje," \u2014 "),rj=n(Nje,"A",{href:!0});var JSt=s(rj);p2o=r(JSt,"MPNetConfig"),JSt.forEach(t),_2o=r(Nje," (MPNet model)"),Nje.forEach(t),b2o=i(L),wh=n(L,"LI",{});var qje=s(wh);Gue=n(qje,"STRONG",{});var YSt=s(Gue);v2o=r(YSt,"mt5"),YSt.forEach(t),F2o=r(qje," \u2014 "),tj=n(qje,"A",{href:!0});var ZSt=s(tj);T2o=r(ZSt,"MT5Config"),ZSt.forEach(t),M2o=r(qje," (MT5 model)"),qje.forEach(t),E2o=i(L),Ah=n(L,"LI",{});var Dje=s(Ah);Oue=n(Dje,"STRONG",{});var KSt=s(Oue);C2o=r(KSt,"mvp"),KSt.forEach(t),w2o=r(Dje," \u2014 "),aj=n(Dje,"A",{href:!0});var eRt=s(aj);A2o=r(eRt,"MvpConfig"),eRt.forEach(t),L2o=r(Dje," (MVP model)"),Dje.forEach(t),y2o=i(L),Lh=n(L,"LI",{});var jje=s(Lh);Vue=n(jje,"STRONG",{});var oRt=s(Vue);x2o=r(oRt,"nezha"),oRt.forEach(t),$2o=r(jje," \u2014 "),nj=n(jje,"A",{href:!0});var rRt=s(nj);k2o=r(rRt,"NezhaConfig"),rRt.forEach(t),S2o=r(jje," (Nezha model)"),jje.forEach(t),R2o=i(L),yh=n(L,"LI",{});var Gje=s(yh);Xue=n(Gje,"STRONG",{});var tRt=s(Xue);P2o=r(tRt,"nystromformer"),tRt.forEach(t),B2o=r(Gje," \u2014 "),sj=n(Gje,"A",{href:!0});var aRt=s(sj);I2o=r(aRt,"NystromformerConfig"),aRt.forEach(t),N2o=r(Gje," (Nystr\xF6mformer model)"),Gje.forEach(t),q2o=i(L),xh=n(L,"LI",{});var Oje=s(xh);zue=n(Oje,"STRONG",{});var nRt=s(zue);D2o=r(nRt,"openai-gpt"),nRt.forEach(t),j2o=r(Oje," \u2014 "),lj=n(Oje,"A",{href:!0});var sRt=s(lj);G2o=r(sRt,"OpenAIGPTConfig"),sRt.forEach(t),O2o=r(Oje," (OpenAI GPT model)"),Oje.forEach(t),V2o=i(L),$h=n(L,"LI",{});var Vje=s($h);Que=n(Vje,"STRONG",{});var lRt=s(Que);X2o=r(lRt,"opt"),lRt.forEach(t),z2o=r(Vje," \u2014 "),ij=n(Vje,"A",{href:!0});var iRt=s(ij);Q2o=r(iRt,"OPTConfig"),iRt.forEach(t),W2o=r(Vje," (OPT model)"),Vje.forEach(t),U2o=i(L),kh=n(L,"LI",{});var Xje=s(kh);Wue=n(Xje,"STRONG",{});var dRt=s(Wue);H2o=r(dRt,"owlvit"),dRt.forEach(t),J2o=r(Xje," \u2014 "),dj=n(Xje,"A",{href:!0});var mRt=s(dj);Y2o=r(mRt,"OwlViTConfig"),mRt.forEach(t),Z2o=r(Xje," (OWL-ViT model)"),Xje.forEach(t),K2o=i(L),Sh=n(L,"LI",{});var zje=s(Sh);Uue=n(zje,"STRONG",{});var cRt=s(Uue);ebo=r(cRt,"pegasus"),cRt.forEach(t),obo=r(zje," \u2014 "),mj=n(zje,"A",{href:!0});var fRt=s(mj);rbo=r(fRt,"PegasusConfig"),fRt.forEach(t),tbo=r(zje," (Pegasus model)"),zje.forEach(t),abo=i(L),Rh=n(L,"LI",{});var Qje=s(Rh);Hue=n(Qje,"STRONG",{});var gRt=s(Hue);nbo=r(gRt,"pegasus_x"),gRt.forEach(t),sbo=r(Qje," \u2014 "),cj=n(Qje,"A",{href:!0});var hRt=s(cj);lbo=r(hRt,"PegasusXConfig"),hRt.forEach(t),ibo=r(Qje," (PEGASUS-X model)"),Qje.forEach(t),dbo=i(L),Ph=n(L,"LI",{});var Wje=s(Ph);Jue=n(Wje,"STRONG",{});var uRt=s(Jue);mbo=r(uRt,"perceiver"),uRt.forEach(t),cbo=r(Wje," \u2014 "),fj=n(Wje,"A",{href:!0});var pRt=s(fj);fbo=r(pRt,"PerceiverConfig"),pRt.forEach(t),gbo=r(Wje," (Perceiver model)"),Wje.forEach(t),hbo=i(L),Bh=n(L,"LI",{});var Uje=s(Bh);Yue=n(Uje,"STRONG",{});var _Rt=s(Yue);ubo=r(_Rt,"plbart"),_Rt.forEach(t),pbo=r(Uje," \u2014 "),gj=n(Uje,"A",{href:!0});var bRt=s(gj);_bo=r(bRt,"PLBartConfig"),bRt.forEach(t),bbo=r(Uje," (PLBart model)"),Uje.forEach(t),vbo=i(L),Ih=n(L,"LI",{});var Hje=s(Ih);Zue=n(Hje,"STRONG",{});var vRt=s(Zue);Fbo=r(vRt,"poolformer"),vRt.forEach(t),Tbo=r(Hje," \u2014 "),hj=n(Hje,"A",{href:!0});var FRt=s(hj);Mbo=r(FRt,"PoolFormerConfig"),FRt.forEach(t),Ebo=r(Hje," (PoolFormer model)"),Hje.forEach(t),Cbo=i(L),Nh=n(L,"LI",{});var Jje=s(Nh);Kue=n(Jje,"STRONG",{});var TRt=s(Kue);wbo=r(TRt,"prophetnet"),TRt.forEach(t),Abo=r(Jje," \u2014 "),uj=n(Jje,"A",{href:!0});var MRt=s(uj);Lbo=r(MRt,"ProphetNetConfig"),MRt.forEach(t),ybo=r(Jje," (ProphetNet model)"),Jje.forEach(t),xbo=i(L),qh=n(L,"LI",{});var Yje=s(qh);epe=n(Yje,"STRONG",{});var ERt=s(epe);$bo=r(ERt,"qdqbert"),ERt.forEach(t),kbo=r(Yje," \u2014 "),pj=n(Yje,"A",{href:!0});var CRt=s(pj);Sbo=r(CRt,"QDQBertConfig"),CRt.forEach(t),Rbo=r(Yje," (QDQBert model)"),Yje.forEach(t),Pbo=i(L),Dh=n(L,"LI",{});var Zje=s(Dh);ope=n(Zje,"STRONG",{});var wRt=s(ope);Bbo=r(wRt,"rag"),wRt.forEach(t),Ibo=r(Zje," \u2014 "),_j=n(Zje,"A",{href:!0});var ARt=s(_j);Nbo=r(ARt,"RagConfig"),ARt.forEach(t),qbo=r(Zje," (RAG model)"),Zje.forEach(t),Dbo=i(L),jh=n(L,"LI",{});var Kje=s(jh);rpe=n(Kje,"STRONG",{});var LRt=s(rpe);jbo=r(LRt,"realm"),LRt.forEach(t),Gbo=r(Kje," \u2014 "),bj=n(Kje,"A",{href:!0});var yRt=s(bj);Obo=r(yRt,"RealmConfig"),yRt.forEach(t),Vbo=r(Kje," (REALM model)"),Kje.forEach(t),Xbo=i(L),Gh=n(L,"LI",{});var eGe=s(Gh);tpe=n(eGe,"STRONG",{});var xRt=s(tpe);zbo=r(xRt,"reformer"),xRt.forEach(t),Qbo=r(eGe," \u2014 "),vj=n(eGe,"A",{href:!0});var $Rt=s(vj);Wbo=r($Rt,"ReformerConfig"),$Rt.forEach(t),Ubo=r(eGe," (Reformer model)"),eGe.forEach(t),Hbo=i(L),Oh=n(L,"LI",{});var oGe=s(Oh);ape=n(oGe,"STRONG",{});var kRt=s(ape);Jbo=r(kRt,"regnet"),kRt.forEach(t),Ybo=r(oGe," \u2014 "),Fj=n(oGe,"A",{href:!0});var SRt=s(Fj);Zbo=r(SRt,"RegNetConfig"),SRt.forEach(t),Kbo=r(oGe," (RegNet model)"),oGe.forEach(t),evo=i(L),Vh=n(L,"LI",{});var rGe=s(Vh);npe=n(rGe,"STRONG",{});var RRt=s(npe);ovo=r(RRt,"rembert"),RRt.forEach(t),rvo=r(rGe," \u2014 "),Tj=n(rGe,"A",{href:!0});var PRt=s(Tj);tvo=r(PRt,"RemBertConfig"),PRt.forEach(t),avo=r(rGe," (RemBERT model)"),rGe.forEach(t),nvo=i(L),Xh=n(L,"LI",{});var tGe=s(Xh);spe=n(tGe,"STRONG",{});var BRt=s(spe);svo=r(BRt,"resnet"),BRt.forEach(t),lvo=r(tGe," \u2014 "),Mj=n(tGe,"A",{href:!0});var IRt=s(Mj);ivo=r(IRt,"ResNetConfig"),IRt.forEach(t),dvo=r(tGe," (ResNet model)"),tGe.forEach(t),mvo=i(L),zh=n(L,"LI",{});var aGe=s(zh);lpe=n(aGe,"STRONG",{});var NRt=s(lpe);cvo=r(NRt,"retribert"),NRt.forEach(t),fvo=r(aGe," \u2014 "),Ej=n(aGe,"A",{href:!0});var qRt=s(Ej);gvo=r(qRt,"RetriBertConfig"),qRt.forEach(t),hvo=r(aGe," (RetriBERT model)"),aGe.forEach(t),uvo=i(L),Qh=n(L,"LI",{});var nGe=s(Qh);ipe=n(nGe,"STRONG",{});var DRt=s(ipe);pvo=r(DRt,"roberta"),DRt.forEach(t),_vo=r(nGe," \u2014 "),Cj=n(nGe,"A",{href:!0});var jRt=s(Cj);bvo=r(jRt,"RobertaConfig"),jRt.forEach(t),vvo=r(nGe," (RoBERTa model)"),nGe.forEach(t),Fvo=i(L),Wh=n(L,"LI",{});var sGe=s(Wh);dpe=n(sGe,"STRONG",{});var GRt=s(dpe);Tvo=r(GRt,"roc_bert"),GRt.forEach(t),Mvo=r(sGe," \u2014 "),wj=n(sGe,"A",{href:!0});var ORt=s(wj);Evo=r(ORt,"RoCBertConfig"),ORt.forEach(t),Cvo=r(sGe," (RoCBert model)"),sGe.forEach(t),wvo=i(L),Uh=n(L,"LI",{});var lGe=s(Uh);mpe=n(lGe,"STRONG",{});var VRt=s(mpe);Avo=r(VRt,"roformer"),VRt.forEach(t),Lvo=r(lGe," \u2014 "),Aj=n(lGe,"A",{href:!0});var XRt=s(Aj);yvo=r(XRt,"RoFormerConfig"),XRt.forEach(t),xvo=r(lGe," (RoFormer model)"),lGe.forEach(t),$vo=i(L),Hh=n(L,"LI",{});var iGe=s(Hh);cpe=n(iGe,"STRONG",{});var zRt=s(cpe);kvo=r(zRt,"segformer"),zRt.forEach(t),Svo=r(iGe," \u2014 "),Lj=n(iGe,"A",{href:!0});var QRt=s(Lj);Rvo=r(QRt,"SegformerConfig"),QRt.forEach(t),Pvo=r(iGe," (SegFormer model)"),iGe.forEach(t),Bvo=i(L),Jh=n(L,"LI",{});var dGe=s(Jh);fpe=n(dGe,"STRONG",{});var WRt=s(fpe);Ivo=r(WRt,"sew"),WRt.forEach(t),Nvo=r(dGe," \u2014 "),yj=n(dGe,"A",{href:!0});var URt=s(yj);qvo=r(URt,"SEWConfig"),URt.forEach(t),Dvo=r(dGe," (SEW model)"),dGe.forEach(t),jvo=i(L),Yh=n(L,"LI",{});var mGe=s(Yh);gpe=n(mGe,"STRONG",{});var HRt=s(gpe);Gvo=r(HRt,"sew-d"),HRt.forEach(t),Ovo=r(mGe," \u2014 "),xj=n(mGe,"A",{href:!0});var JRt=s(xj);Vvo=r(JRt,"SEWDConfig"),JRt.forEach(t),Xvo=r(mGe," (SEW-D model)"),mGe.forEach(t),zvo=i(L),Zh=n(L,"LI",{});var cGe=s(Zh);hpe=n(cGe,"STRONG",{});var YRt=s(hpe);Qvo=r(YRt,"speech-encoder-decoder"),YRt.forEach(t),Wvo=r(cGe," \u2014 "),$j=n(cGe,"A",{href:!0});var ZRt=s($j);Uvo=r(ZRt,"SpeechEncoderDecoderConfig"),ZRt.forEach(t),Hvo=r(cGe," (Speech Encoder decoder model)"),cGe.forEach(t),Jvo=i(L),Kh=n(L,"LI",{});var fGe=s(Kh);upe=n(fGe,"STRONG",{});var KRt=s(upe);Yvo=r(KRt,"speech_to_text"),KRt.forEach(t),Zvo=r(fGe," \u2014 "),kj=n(fGe,"A",{href:!0});var ePt=s(kj);Kvo=r(ePt,"Speech2TextConfig"),ePt.forEach(t),eFo=r(fGe," (Speech2Text model)"),fGe.forEach(t),oFo=i(L),eu=n(L,"LI",{});var gGe=s(eu);ppe=n(gGe,"STRONG",{});var oPt=s(ppe);rFo=r(oPt,"speech_to_text_2"),oPt.forEach(t),tFo=r(gGe," \u2014 "),Sj=n(gGe,"A",{href:!0});var rPt=s(Sj);aFo=r(rPt,"Speech2Text2Config"),rPt.forEach(t),nFo=r(gGe," (Speech2Text2 model)"),gGe.forEach(t),sFo=i(L),ou=n(L,"LI",{});var hGe=s(ou);_pe=n(hGe,"STRONG",{});var tPt=s(_pe);lFo=r(tPt,"splinter"),tPt.forEach(t),iFo=r(hGe," \u2014 "),Rj=n(hGe,"A",{href:!0});var aPt=s(Rj);dFo=r(aPt,"SplinterConfig"),aPt.forEach(t),mFo=r(hGe," (Splinter model)"),hGe.forEach(t),cFo=i(L),ru=n(L,"LI",{});var uGe=s(ru);bpe=n(uGe,"STRONG",{});var nPt=s(bpe);fFo=r(nPt,"squeezebert"),nPt.forEach(t),gFo=r(uGe," \u2014 "),Pj=n(uGe,"A",{href:!0});var sPt=s(Pj);hFo=r(sPt,"SqueezeBertConfig"),sPt.forEach(t),uFo=r(uGe," (SqueezeBERT model)"),uGe.forEach(t),pFo=i(L),tu=n(L,"LI",{});var pGe=s(tu);vpe=n(pGe,"STRONG",{});var lPt=s(vpe);_Fo=r(lPt,"swin"),lPt.forEach(t),bFo=r(pGe," \u2014 "),Bj=n(pGe,"A",{href:!0});var iPt=s(Bj);vFo=r(iPt,"SwinConfig"),iPt.forEach(t),FFo=r(pGe," (Swin Transformer model)"),pGe.forEach(t),TFo=i(L),au=n(L,"LI",{});var _Ge=s(au);Fpe=n(_Ge,"STRONG",{});var dPt=s(Fpe);MFo=r(dPt,"swinv2"),dPt.forEach(t),EFo=r(_Ge," \u2014 "),Ij=n(_Ge,"A",{href:!0});var mPt=s(Ij);CFo=r(mPt,"Swinv2Config"),mPt.forEach(t),wFo=r(_Ge," (Swin Transformer V2 model)"),_Ge.forEach(t),AFo=i(L),nu=n(L,"LI",{});var bGe=s(nu);Tpe=n(bGe,"STRONG",{});var cPt=s(Tpe);LFo=r(cPt,"t5"),cPt.forEach(t),yFo=r(bGe," \u2014 "),Nj=n(bGe,"A",{href:!0});var fPt=s(Nj);xFo=r(fPt,"T5Config"),fPt.forEach(t),$Fo=r(bGe," (T5 model)"),bGe.forEach(t),kFo=i(L),su=n(L,"LI",{});var vGe=s(su);Mpe=n(vGe,"STRONG",{});var gPt=s(Mpe);SFo=r(gPt,"table-transformer"),gPt.forEach(t),RFo=r(vGe," \u2014 "),qj=n(vGe,"A",{href:!0});var hPt=s(qj);PFo=r(hPt,"TableTransformerConfig"),hPt.forEach(t),BFo=r(vGe," (Table Transformer model)"),vGe.forEach(t),IFo=i(L),lu=n(L,"LI",{});var FGe=s(lu);Epe=n(FGe,"STRONG",{});var uPt=s(Epe);NFo=r(uPt,"tapas"),uPt.forEach(t),qFo=r(FGe," \u2014 "),Dj=n(FGe,"A",{href:!0});var pPt=s(Dj);DFo=r(pPt,"TapasConfig"),pPt.forEach(t),jFo=r(FGe," (TAPAS model)"),FGe.forEach(t),GFo=i(L),iu=n(L,"LI",{});var TGe=s(iu);Cpe=n(TGe,"STRONG",{});var _Pt=s(Cpe);OFo=r(_Pt,"time_series_transformer"),_Pt.forEach(t),VFo=r(TGe," \u2014 "),jj=n(TGe,"A",{href:!0});var bPt=s(jj);XFo=r(bPt,"TimeSeriesTransformerConfig"),bPt.forEach(t),zFo=r(TGe," (Time Series Transformer model)"),TGe.forEach(t),QFo=i(L),du=n(L,"LI",{});var MGe=s(du);wpe=n(MGe,"STRONG",{});var vPt=s(wpe);WFo=r(vPt,"trajectory_transformer"),vPt.forEach(t),UFo=r(MGe," \u2014 "),Gj=n(MGe,"A",{href:!0});var FPt=s(Gj);HFo=r(FPt,"TrajectoryTransformerConfig"),FPt.forEach(t),JFo=r(MGe," (Trajectory Transformer model)"),MGe.forEach(t),YFo=i(L),mu=n(L,"LI",{});var EGe=s(mu);Ape=n(EGe,"STRONG",{});var TPt=s(Ape);ZFo=r(TPt,"transfo-xl"),TPt.forEach(t),KFo=r(EGe," \u2014 "),Oj=n(EGe,"A",{href:!0});var MPt=s(Oj);eTo=r(MPt,"TransfoXLConfig"),MPt.forEach(t),oTo=r(EGe," (Transformer-XL model)"),EGe.forEach(t),rTo=i(L),cu=n(L,"LI",{});var CGe=s(cu);Lpe=n(CGe,"STRONG",{});var EPt=s(Lpe);tTo=r(EPt,"trocr"),EPt.forEach(t),aTo=r(CGe," \u2014 "),Vj=n(CGe,"A",{href:!0});var CPt=s(Vj);nTo=r(CPt,"TrOCRConfig"),CPt.forEach(t),sTo=r(CGe," (TrOCR model)"),CGe.forEach(t),lTo=i(L),fu=n(L,"LI",{});var wGe=s(fu);ype=n(wGe,"STRONG",{});var wPt=s(ype);iTo=r(wPt,"unispeech"),wPt.forEach(t),dTo=r(wGe," \u2014 "),Xj=n(wGe,"A",{href:!0});var APt=s(Xj);mTo=r(APt,"UniSpeechConfig"),APt.forEach(t),cTo=r(wGe," (UniSpeech model)"),wGe.forEach(t),fTo=i(L),gu=n(L,"LI",{});var AGe=s(gu);xpe=n(AGe,"STRONG",{});var LPt=s(xpe);gTo=r(LPt,"unispeech-sat"),LPt.forEach(t),hTo=r(AGe," \u2014 "),zj=n(AGe,"A",{href:!0});var yPt=s(zj);uTo=r(yPt,"UniSpeechSatConfig"),yPt.forEach(t),pTo=r(AGe," (UniSpeechSat model)"),AGe.forEach(t),_To=i(L),hu=n(L,"LI",{});var LGe=s(hu);$pe=n(LGe,"STRONG",{});var xPt=s($pe);bTo=r(xPt,"van"),xPt.forEach(t),vTo=r(LGe," \u2014 "),Qj=n(LGe,"A",{href:!0});var $Pt=s(Qj);FTo=r($Pt,"VanConfig"),$Pt.forEach(t),TTo=r(LGe," (VAN model)"),LGe.forEach(t),MTo=i(L),uu=n(L,"LI",{});var yGe=s(uu);kpe=n(yGe,"STRONG",{});var kPt=s(kpe);ETo=r(kPt,"videomae"),kPt.forEach(t),CTo=r(yGe," \u2014 "),Wj=n(yGe,"A",{href:!0});var SPt=s(Wj);wTo=r(SPt,"VideoMAEConfig"),SPt.forEach(t),ATo=r(yGe," (VideoMAE model)"),yGe.forEach(t),LTo=i(L),pu=n(L,"LI",{});var xGe=s(pu);Spe=n(xGe,"STRONG",{});var RPt=s(Spe);yTo=r(RPt,"vilt"),RPt.forEach(t),xTo=r(xGe," \u2014 "),Uj=n(xGe,"A",{href:!0});var PPt=s(Uj);$To=r(PPt,"ViltConfig"),PPt.forEach(t),kTo=r(xGe," (ViLT model)"),xGe.forEach(t),STo=i(L),_u=n(L,"LI",{});var $Ge=s(_u);Rpe=n($Ge,"STRONG",{});var BPt=s(Rpe);RTo=r(BPt,"vision-encoder-decoder"),BPt.forEach(t),PTo=r($Ge," \u2014 "),Hj=n($Ge,"A",{href:!0});var IPt=s(Hj);BTo=r(IPt,"VisionEncoderDecoderConfig"),IPt.forEach(t),ITo=r($Ge," (Vision Encoder decoder model)"),$Ge.forEach(t),NTo=i(L),bu=n(L,"LI",{});var kGe=s(bu);Ppe=n(kGe,"STRONG",{});var NPt=s(Ppe);qTo=r(NPt,"vision-text-dual-encoder"),NPt.forEach(t),DTo=r(kGe," \u2014 "),Jj=n(kGe,"A",{href:!0});var qPt=s(Jj);jTo=r(qPt,"VisionTextDualEncoderConfig"),qPt.forEach(t),GTo=r(kGe," (VisionTextDualEncoder model)"),kGe.forEach(t),OTo=i(L),vu=n(L,"LI",{});var SGe=s(vu);Bpe=n(SGe,"STRONG",{});var DPt=s(Bpe);VTo=r(DPt,"visual_bert"),DPt.forEach(t),XTo=r(SGe," \u2014 "),Yj=n(SGe,"A",{href:!0});var jPt=s(Yj);zTo=r(jPt,"VisualBertConfig"),jPt.forEach(t),QTo=r(SGe," (VisualBERT model)"),SGe.forEach(t),WTo=i(L),Fu=n(L,"LI",{});var RGe=s(Fu);Ipe=n(RGe,"STRONG",{});var GPt=s(Ipe);UTo=r(GPt,"vit"),GPt.forEach(t),HTo=r(RGe," \u2014 "),Zj=n(RGe,"A",{href:!0});var OPt=s(Zj);JTo=r(OPt,"ViTConfig"),OPt.forEach(t),YTo=r(RGe," (ViT model)"),RGe.forEach(t),ZTo=i(L),Tu=n(L,"LI",{});var PGe=s(Tu);Npe=n(PGe,"STRONG",{});var VPt=s(Npe);KTo=r(VPt,"vit_mae"),VPt.forEach(t),eMo=r(PGe," \u2014 "),Kj=n(PGe,"A",{href:!0});var XPt=s(Kj);oMo=r(XPt,"ViTMAEConfig"),XPt.forEach(t),rMo=r(PGe," (ViTMAE model)"),PGe.forEach(t),tMo=i(L),Mu=n(L,"LI",{});var BGe=s(Mu);qpe=n(BGe,"STRONG",{});var zPt=s(qpe);aMo=r(zPt,"vit_msn"),zPt.forEach(t),nMo=r(BGe," \u2014 "),eG=n(BGe,"A",{href:!0});var QPt=s(eG);sMo=r(QPt,"ViTMSNConfig"),QPt.forEach(t),lMo=r(BGe," (ViTMSN model)"),BGe.forEach(t),iMo=i(L),Eu=n(L,"LI",{});var IGe=s(Eu);Dpe=n(IGe,"STRONG",{});var WPt=s(Dpe);dMo=r(WPt,"wav2vec2"),WPt.forEach(t),mMo=r(IGe," \u2014 "),oG=n(IGe,"A",{href:!0});var UPt=s(oG);cMo=r(UPt,"Wav2Vec2Config"),UPt.forEach(t),fMo=r(IGe," (Wav2Vec2 model)"),IGe.forEach(t),gMo=i(L),Cu=n(L,"LI",{});var NGe=s(Cu);jpe=n(NGe,"STRONG",{});var HPt=s(jpe);hMo=r(HPt,"wav2vec2-conformer"),HPt.forEach(t),uMo=r(NGe," \u2014 "),rG=n(NGe,"A",{href:!0});var JPt=s(rG);pMo=r(JPt,"Wav2Vec2ConformerConfig"),JPt.forEach(t),_Mo=r(NGe," (Wav2Vec2-Conformer model)"),NGe.forEach(t),bMo=i(L),wu=n(L,"LI",{});var qGe=s(wu);Gpe=n(qGe,"STRONG",{});var YPt=s(Gpe);vMo=r(YPt,"wavlm"),YPt.forEach(t),FMo=r(qGe," \u2014 "),tG=n(qGe,"A",{href:!0});var ZPt=s(tG);TMo=r(ZPt,"WavLMConfig"),ZPt.forEach(t),MMo=r(qGe," (WavLM model)"),qGe.forEach(t),EMo=i(L),Au=n(L,"LI",{});var DGe=s(Au);Ope=n(DGe,"STRONG",{});var KPt=s(Ope);CMo=r(KPt,"whisper"),KPt.forEach(t),wMo=r(DGe," \u2014 "),aG=n(DGe,"A",{href:!0});var eBt=s(aG);AMo=r(eBt,"WhisperConfig"),eBt.forEach(t),LMo=r(DGe," (Whisper model)"),DGe.forEach(t),yMo=i(L),Lu=n(L,"LI",{});var jGe=s(Lu);Vpe=n(jGe,"STRONG",{});var oBt=s(Vpe);xMo=r(oBt,"xclip"),oBt.forEach(t),$Mo=r(jGe," \u2014 "),nG=n(jGe,"A",{href:!0});var rBt=s(nG);kMo=r(rBt,"XCLIPConfig"),rBt.forEach(t),SMo=r(jGe," (X-CLIP model)"),jGe.forEach(t),RMo=i(L),yu=n(L,"LI",{});var GGe=s(yu);Xpe=n(GGe,"STRONG",{});var tBt=s(Xpe);PMo=r(tBt,"xglm"),tBt.forEach(t),BMo=r(GGe," \u2014 "),sG=n(GGe,"A",{href:!0});var aBt=s(sG);IMo=r(aBt,"XGLMConfig"),aBt.forEach(t),NMo=r(GGe," (XGLM model)"),GGe.forEach(t),qMo=i(L),xu=n(L,"LI",{});var OGe=s(xu);zpe=n(OGe,"STRONG",{});var nBt=s(zpe);DMo=r(nBt,"xlm"),nBt.forEach(t),jMo=r(OGe," \u2014 "),lG=n(OGe,"A",{href:!0});var sBt=s(lG);GMo=r(sBt,"XLMConfig"),sBt.forEach(t),OMo=r(OGe," (XLM model)"),OGe.forEach(t),VMo=i(L),$u=n(L,"LI",{});var VGe=s($u);Qpe=n(VGe,"STRONG",{});var lBt=s(Qpe);XMo=r(lBt,"xlm-prophetnet"),lBt.forEach(t),zMo=r(VGe," \u2014 "),iG=n(VGe,"A",{href:!0});var iBt=s(iG);QMo=r(iBt,"XLMProphetNetConfig"),iBt.forEach(t),WMo=r(VGe," (XLM-ProphetNet model)"),VGe.forEach(t),UMo=i(L),ku=n(L,"LI",{});var XGe=s(ku);Wpe=n(XGe,"STRONG",{});var dBt=s(Wpe);HMo=r(dBt,"xlm-roberta"),dBt.forEach(t),JMo=r(XGe," \u2014 "),dG=n(XGe,"A",{href:!0});var mBt=s(dG);YMo=r(mBt,"XLMRobertaConfig"),mBt.forEach(t),ZMo=r(XGe," (XLM-RoBERTa model)"),XGe.forEach(t),KMo=i(L),Su=n(L,"LI",{});var zGe=s(Su);Upe=n(zGe,"STRONG",{});var cBt=s(Upe);eEo=r(cBt,"xlm-roberta-xl"),cBt.forEach(t),oEo=r(zGe," \u2014 "),mG=n(zGe,"A",{href:!0});var fBt=s(mG);rEo=r(fBt,"XLMRobertaXLConfig"),fBt.forEach(t),tEo=r(zGe," (XLM-RoBERTa-XL model)"),zGe.forEach(t),aEo=i(L),Ru=n(L,"LI",{});var QGe=s(Ru);Hpe=n(QGe,"STRONG",{});var gBt=s(Hpe);nEo=r(gBt,"xlnet"),gBt.forEach(t),sEo=r(QGe," \u2014 "),cG=n(QGe,"A",{href:!0});var hBt=s(cG);lEo=r(hBt,"XLNetConfig"),hBt.forEach(t),iEo=r(QGe," (XLNet model)"),QGe.forEach(t),dEo=i(L),Pu=n(L,"LI",{});var WGe=s(Pu);Jpe=n(WGe,"STRONG",{});var uBt=s(Jpe);mEo=r(uBt,"yolos"),uBt.forEach(t),cEo=r(WGe," \u2014 "),fG=n(WGe,"A",{href:!0});var pBt=s(fG);fEo=r(pBt,"YolosConfig"),pBt.forEach(t),gEo=r(WGe," (YOLOS model)"),WGe.forEach(t),hEo=i(L),Bu=n(L,"LI",{});var UGe=s(Bu);Ype=n(UGe,"STRONG",{});var _Bt=s(Ype);uEo=r(_Bt,"yoso"),_Bt.forEach(t),pEo=r(UGe," \u2014 "),gG=n(UGe,"A",{href:!0});var bBt=s(gG);_Eo=r(bBt,"YosoConfig"),bBt.forEach(t),bEo=r(UGe," (YOSO model)"),UGe.forEach(t),L.forEach(t),vEo=i(Ct),T(Iu.$$.fragment,Ct),Ct.forEach(t),FEo=i(Et),Nu=n(Et,"DIV",{class:!0});var Ido=s(Nu);T(vk.$$.fragment,Ido),TEo=i(Ido),Zpe=n(Ido,"P",{});var vBt=s(Zpe);MEo=r(vBt,"Register a new configuration for this class."),vBt.forEach(t),Ido.forEach(t),Et.forEach(t),Elo=i(c),Id=n(c,"H2",{class:!0});var Ndo=s(Id);qu=n(Ndo,"A",{id:!0,class:!0,href:!0});var FBt=s(qu);Kpe=n(FBt,"SPAN",{});var TBt=s(Kpe);T(Fk.$$.fragment,TBt),TBt.forEach(t),FBt.forEach(t),EEo=i(Ndo),e_e=n(Ndo,"SPAN",{});var MBt=s(e_e);CEo=r(MBt,"AutoTokenizer"),MBt.forEach(t),Ndo.forEach(t),Clo=i(c),Io=n(c,"DIV",{class:!0});var Gl=s(Io);T(Tk.$$.fragment,Gl),wEo=i(Gl),Mk=n(Gl,"P",{});var qdo=s(Mk);AEo=r(qdo,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),hG=n(qdo,"A",{href:!0});var EBt=s(hG);LEo=r(EBt,"AutoTokenizer.from_pretrained()"),EBt.forEach(t),yEo=r(qdo," class method."),qdo.forEach(t),xEo=i(Gl),Ek=n(Gl,"P",{});var Ddo=s(Ek);$Eo=r(Ddo,"This class cannot be instantiated directly using "),o_e=n(Ddo,"CODE",{});var CBt=s(o_e);kEo=r(CBt,"__init__()"),CBt.forEach(t),SEo=r(Ddo," (throws an error)."),Ddo.forEach(t),REo=i(Gl),Vr=n(Gl,"DIV",{class:!0});var Ol=s(Vr);T(Ck.$$.fragment,Ol),PEo=i(Ol),r_e=n(Ol,"P",{});var wBt=s(r_e);BEo=r(wBt,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),wBt.forEach(t),IEo=i(Ol),dn=n(Ol,"P",{});var ex=s(dn);NEo=r(ex,"The tokenizer class to instantiate is selected based on the "),t_e=n(ex,"CODE",{});var ABt=s(t_e);qEo=r(ABt,"model_type"),ABt.forEach(t),DEo=r(ex,` property of the config object (either
passed as an argument or loaded from `),a_e=n(ex,"CODE",{});var LBt=s(a_e);jEo=r(LBt,"pretrained_model_name_or_path"),LBt.forEach(t),GEo=r(ex,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n_e=n(ex,"CODE",{});var yBt=s(n_e);OEo=r(yBt,"pretrained_model_name_or_path"),yBt.forEach(t),VEo=r(ex,":"),ex.forEach(t),XEo=i(Ol),k=n(Ol,"UL",{});var S=s(k);Ts=n(S,"LI",{});var fN=s(Ts);s_e=n(fN,"STRONG",{});var xBt=s(s_e);zEo=r(xBt,"albert"),xBt.forEach(t),QEo=r(fN," \u2014 "),uG=n(fN,"A",{href:!0});var $Bt=s(uG);WEo=r($Bt,"AlbertTokenizer"),$Bt.forEach(t),UEo=r(fN," or "),pG=n(fN,"A",{href:!0});var kBt=s(pG);HEo=r(kBt,"AlbertTokenizerFast"),kBt.forEach(t),JEo=r(fN," (ALBERT model)"),fN.forEach(t),YEo=i(S),Ms=n(S,"LI",{});var gN=s(Ms);l_e=n(gN,"STRONG",{});var SBt=s(l_e);ZEo=r(SBt,"bart"),SBt.forEach(t),KEo=r(gN," \u2014 "),_G=n(gN,"A",{href:!0});var RBt=s(_G);e4o=r(RBt,"BartTokenizer"),RBt.forEach(t),o4o=r(gN," or "),bG=n(gN,"A",{href:!0});var PBt=s(bG);r4o=r(PBt,"BartTokenizerFast"),PBt.forEach(t),t4o=r(gN," (BART model)"),gN.forEach(t),a4o=i(S),Es=n(S,"LI",{});var hN=s(Es);i_e=n(hN,"STRONG",{});var BBt=s(i_e);n4o=r(BBt,"barthez"),BBt.forEach(t),s4o=r(hN," \u2014 "),vG=n(hN,"A",{href:!0});var IBt=s(vG);l4o=r(IBt,"BarthezTokenizer"),IBt.forEach(t),i4o=r(hN," or "),FG=n(hN,"A",{href:!0});var NBt=s(FG);d4o=r(NBt,"BarthezTokenizerFast"),NBt.forEach(t),m4o=r(hN," (BARThez model)"),hN.forEach(t),c4o=i(S),Du=n(S,"LI",{});var HGe=s(Du);d_e=n(HGe,"STRONG",{});var qBt=s(d_e);f4o=r(qBt,"bartpho"),qBt.forEach(t),g4o=r(HGe," \u2014 "),TG=n(HGe,"A",{href:!0});var DBt=s(TG);h4o=r(DBt,"BartphoTokenizer"),DBt.forEach(t),u4o=r(HGe," (BARTpho model)"),HGe.forEach(t),p4o=i(S),Cs=n(S,"LI",{});var uN=s(Cs);m_e=n(uN,"STRONG",{});var jBt=s(m_e);_4o=r(jBt,"bert"),jBt.forEach(t),b4o=r(uN," \u2014 "),MG=n(uN,"A",{href:!0});var GBt=s(MG);v4o=r(GBt,"BertTokenizer"),GBt.forEach(t),F4o=r(uN," or "),EG=n(uN,"A",{href:!0});var OBt=s(EG);T4o=r(OBt,"BertTokenizerFast"),OBt.forEach(t),M4o=r(uN," (BERT model)"),uN.forEach(t),E4o=i(S),ju=n(S,"LI",{});var JGe=s(ju);c_e=n(JGe,"STRONG",{});var VBt=s(c_e);C4o=r(VBt,"bert-generation"),VBt.forEach(t),w4o=r(JGe," \u2014 "),CG=n(JGe,"A",{href:!0});var XBt=s(CG);A4o=r(XBt,"BertGenerationTokenizer"),XBt.forEach(t),L4o=r(JGe," (Bert Generation model)"),JGe.forEach(t),y4o=i(S),Gu=n(S,"LI",{});var YGe=s(Gu);f_e=n(YGe,"STRONG",{});var zBt=s(f_e);x4o=r(zBt,"bert-japanese"),zBt.forEach(t),$4o=r(YGe," \u2014 "),wG=n(YGe,"A",{href:!0});var QBt=s(wG);k4o=r(QBt,"BertJapaneseTokenizer"),QBt.forEach(t),S4o=r(YGe," (BertJapanese model)"),YGe.forEach(t),R4o=i(S),Ou=n(S,"LI",{});var ZGe=s(Ou);g_e=n(ZGe,"STRONG",{});var WBt=s(g_e);P4o=r(WBt,"bertweet"),WBt.forEach(t),B4o=r(ZGe," \u2014 "),AG=n(ZGe,"A",{href:!0});var UBt=s(AG);I4o=r(UBt,"BertweetTokenizer"),UBt.forEach(t),N4o=r(ZGe," (BERTweet model)"),ZGe.forEach(t),q4o=i(S),ws=n(S,"LI",{});var pN=s(ws);h_e=n(pN,"STRONG",{});var HBt=s(h_e);D4o=r(HBt,"big_bird"),HBt.forEach(t),j4o=r(pN," \u2014 "),LG=n(pN,"A",{href:!0});var JBt=s(LG);G4o=r(JBt,"BigBirdTokenizer"),JBt.forEach(t),O4o=r(pN," or "),yG=n(pN,"A",{href:!0});var YBt=s(yG);V4o=r(YBt,"BigBirdTokenizerFast"),YBt.forEach(t),X4o=r(pN," (BigBird model)"),pN.forEach(t),z4o=i(S),As=n(S,"LI",{});var _N=s(As);u_e=n(_N,"STRONG",{});var ZBt=s(u_e);Q4o=r(ZBt,"bigbird_pegasus"),ZBt.forEach(t),W4o=r(_N," \u2014 "),xG=n(_N,"A",{href:!0});var KBt=s(xG);U4o=r(KBt,"PegasusTokenizer"),KBt.forEach(t),H4o=r(_N," or "),$G=n(_N,"A",{href:!0});var eIt=s($G);J4o=r(eIt,"PegasusTokenizerFast"),eIt.forEach(t),Y4o=r(_N," (BigBird-Pegasus model)"),_N.forEach(t),Z4o=i(S),Ls=n(S,"LI",{});var bN=s(Ls);p_e=n(bN,"STRONG",{});var oIt=s(p_e);K4o=r(oIt,"blenderbot"),oIt.forEach(t),eCo=r(bN," \u2014 "),kG=n(bN,"A",{href:!0});var rIt=s(kG);oCo=r(rIt,"BlenderbotTokenizer"),rIt.forEach(t),rCo=r(bN," or "),SG=n(bN,"A",{href:!0});var tIt=s(SG);tCo=r(tIt,"BlenderbotTokenizerFast"),tIt.forEach(t),aCo=r(bN," (Blenderbot model)"),bN.forEach(t),nCo=i(S),Vu=n(S,"LI",{});var KGe=s(Vu);__e=n(KGe,"STRONG",{});var aIt=s(__e);sCo=r(aIt,"blenderbot-small"),aIt.forEach(t),lCo=r(KGe," \u2014 "),RG=n(KGe,"A",{href:!0});var nIt=s(RG);iCo=r(nIt,"BlenderbotSmallTokenizer"),nIt.forEach(t),dCo=r(KGe," (BlenderbotSmall model)"),KGe.forEach(t),mCo=i(S),Xu=n(S,"LI",{});var eOe=s(Xu);b_e=n(eOe,"STRONG",{});var sIt=s(b_e);cCo=r(sIt,"bloom"),sIt.forEach(t),fCo=r(eOe," \u2014 "),PG=n(eOe,"A",{href:!0});var lIt=s(PG);gCo=r(lIt,"BloomTokenizerFast"),lIt.forEach(t),hCo=r(eOe," (BLOOM model)"),eOe.forEach(t),uCo=i(S),zu=n(S,"LI",{});var oOe=s(zu);v_e=n(oOe,"STRONG",{});var iIt=s(v_e);pCo=r(iIt,"byt5"),iIt.forEach(t),_Co=r(oOe," \u2014 "),BG=n(oOe,"A",{href:!0});var dIt=s(BG);bCo=r(dIt,"ByT5Tokenizer"),dIt.forEach(t),vCo=r(oOe," (ByT5 model)"),oOe.forEach(t),FCo=i(S),ys=n(S,"LI",{});var vN=s(ys);F_e=n(vN,"STRONG",{});var mIt=s(F_e);TCo=r(mIt,"camembert"),mIt.forEach(t),MCo=r(vN," \u2014 "),IG=n(vN,"A",{href:!0});var cIt=s(IG);ECo=r(cIt,"CamembertTokenizer"),cIt.forEach(t),CCo=r(vN," or "),NG=n(vN,"A",{href:!0});var fIt=s(NG);wCo=r(fIt,"CamembertTokenizerFast"),fIt.forEach(t),ACo=r(vN," (CamemBERT model)"),vN.forEach(t),LCo=i(S),Qu=n(S,"LI",{});var rOe=s(Qu);T_e=n(rOe,"STRONG",{});var gIt=s(T_e);yCo=r(gIt,"canine"),gIt.forEach(t),xCo=r(rOe," \u2014 "),qG=n(rOe,"A",{href:!0});var hIt=s(qG);$Co=r(hIt,"CanineTokenizer"),hIt.forEach(t),kCo=r(rOe," (CANINE model)"),rOe.forEach(t),SCo=i(S),xs=n(S,"LI",{});var FN=s(xs);M_e=n(FN,"STRONG",{});var uIt=s(M_e);RCo=r(uIt,"clip"),uIt.forEach(t),PCo=r(FN," \u2014 "),DG=n(FN,"A",{href:!0});var pIt=s(DG);BCo=r(pIt,"CLIPTokenizer"),pIt.forEach(t),ICo=r(FN," or "),jG=n(FN,"A",{href:!0});var _It=s(jG);NCo=r(_It,"CLIPTokenizerFast"),_It.forEach(t),qCo=r(FN," (CLIP model)"),FN.forEach(t),DCo=i(S),$s=n(S,"LI",{});var TN=s($s);E_e=n(TN,"STRONG",{});var bIt=s(E_e);jCo=r(bIt,"clipseg"),bIt.forEach(t),GCo=r(TN," \u2014 "),GG=n(TN,"A",{href:!0});var vIt=s(GG);OCo=r(vIt,"CLIPTokenizer"),vIt.forEach(t),VCo=r(TN," or "),OG=n(TN,"A",{href:!0});var FIt=s(OG);XCo=r(FIt,"CLIPTokenizerFast"),FIt.forEach(t),zCo=r(TN," (CLIPSeg model)"),TN.forEach(t),QCo=i(S),ks=n(S,"LI",{});var MN=s(ks);C_e=n(MN,"STRONG",{});var TIt=s(C_e);WCo=r(TIt,"codegen"),TIt.forEach(t),UCo=r(MN," \u2014 "),VG=n(MN,"A",{href:!0});var MIt=s(VG);HCo=r(MIt,"CodeGenTokenizer"),MIt.forEach(t),JCo=r(MN," or "),XG=n(MN,"A",{href:!0});var EIt=s(XG);YCo=r(EIt,"CodeGenTokenizerFast"),EIt.forEach(t),ZCo=r(MN," (CodeGen model)"),MN.forEach(t),KCo=i(S),Ss=n(S,"LI",{});var EN=s(Ss);w_e=n(EN,"STRONG",{});var CIt=s(w_e);e3o=r(CIt,"convbert"),CIt.forEach(t),o3o=r(EN," \u2014 "),zG=n(EN,"A",{href:!0});var wIt=s(zG);r3o=r(wIt,"ConvBertTokenizer"),wIt.forEach(t),t3o=r(EN," or "),QG=n(EN,"A",{href:!0});var AIt=s(QG);a3o=r(AIt,"ConvBertTokenizerFast"),AIt.forEach(t),n3o=r(EN," (ConvBERT model)"),EN.forEach(t),s3o=i(S),Rs=n(S,"LI",{});var CN=s(Rs);A_e=n(CN,"STRONG",{});var LIt=s(A_e);l3o=r(LIt,"cpm"),LIt.forEach(t),i3o=r(CN," \u2014 "),WG=n(CN,"A",{href:!0});var yIt=s(WG);d3o=r(yIt,"CpmTokenizer"),yIt.forEach(t),m3o=r(CN," or "),UG=n(CN,"A",{href:!0});var xIt=s(UG);c3o=r(xIt,"CpmTokenizerFast"),xIt.forEach(t),f3o=r(CN," (CPM model)"),CN.forEach(t),g3o=i(S),Wu=n(S,"LI",{});var tOe=s(Wu);L_e=n(tOe,"STRONG",{});var $It=s(L_e);h3o=r($It,"ctrl"),$It.forEach(t),u3o=r(tOe," \u2014 "),HG=n(tOe,"A",{href:!0});var kIt=s(HG);p3o=r(kIt,"CTRLTokenizer"),kIt.forEach(t),_3o=r(tOe," (CTRL model)"),tOe.forEach(t),b3o=i(S),Ps=n(S,"LI",{});var wN=s(Ps);y_e=n(wN,"STRONG",{});var SIt=s(y_e);v3o=r(SIt,"data2vec-text"),SIt.forEach(t),F3o=r(wN," \u2014 "),JG=n(wN,"A",{href:!0});var RIt=s(JG);T3o=r(RIt,"RobertaTokenizer"),RIt.forEach(t),M3o=r(wN," or "),YG=n(wN,"A",{href:!0});var PIt=s(YG);E3o=r(PIt,"RobertaTokenizerFast"),PIt.forEach(t),C3o=r(wN," (Data2VecText model)"),wN.forEach(t),w3o=i(S),Bs=n(S,"LI",{});var AN=s(Bs);x_e=n(AN,"STRONG",{});var BIt=s(x_e);A3o=r(BIt,"deberta"),BIt.forEach(t),L3o=r(AN," \u2014 "),ZG=n(AN,"A",{href:!0});var IIt=s(ZG);y3o=r(IIt,"DebertaTokenizer"),IIt.forEach(t),x3o=r(AN," or "),KG=n(AN,"A",{href:!0});var NIt=s(KG);$3o=r(NIt,"DebertaTokenizerFast"),NIt.forEach(t),k3o=r(AN," (DeBERTa model)"),AN.forEach(t),S3o=i(S),Is=n(S,"LI",{});var LN=s(Is);$_e=n(LN,"STRONG",{});var qIt=s($_e);R3o=r(qIt,"deberta-v2"),qIt.forEach(t),P3o=r(LN," \u2014 "),eO=n(LN,"A",{href:!0});var DIt=s(eO);B3o=r(DIt,"DebertaV2Tokenizer"),DIt.forEach(t),I3o=r(LN," or "),oO=n(LN,"A",{href:!0});var jIt=s(oO);N3o=r(jIt,"DebertaV2TokenizerFast"),jIt.forEach(t),q3o=r(LN," (DeBERTa-v2 model)"),LN.forEach(t),D3o=i(S),Ns=n(S,"LI",{});var yN=s(Ns);k_e=n(yN,"STRONG",{});var GIt=s(k_e);j3o=r(GIt,"distilbert"),GIt.forEach(t),G3o=r(yN," \u2014 "),rO=n(yN,"A",{href:!0});var OIt=s(rO);O3o=r(OIt,"DistilBertTokenizer"),OIt.forEach(t),V3o=r(yN," or "),tO=n(yN,"A",{href:!0});var VIt=s(tO);X3o=r(VIt,"DistilBertTokenizerFast"),VIt.forEach(t),z3o=r(yN," (DistilBERT model)"),yN.forEach(t),Q3o=i(S),qs=n(S,"LI",{});var xN=s(qs);S_e=n(xN,"STRONG",{});var XIt=s(S_e);W3o=r(XIt,"dpr"),XIt.forEach(t),U3o=r(xN," \u2014 "),aO=n(xN,"A",{href:!0});var zIt=s(aO);H3o=r(zIt,"DPRQuestionEncoderTokenizer"),zIt.forEach(t),J3o=r(xN," or "),nO=n(xN,"A",{href:!0});var QIt=s(nO);Y3o=r(QIt,"DPRQuestionEncoderTokenizerFast"),QIt.forEach(t),Z3o=r(xN," (DPR model)"),xN.forEach(t),K3o=i(S),Ds=n(S,"LI",{});var $N=s(Ds);R_e=n($N,"STRONG",{});var WIt=s(R_e);e5o=r(WIt,"electra"),WIt.forEach(t),o5o=r($N," \u2014 "),sO=n($N,"A",{href:!0});var UIt=s(sO);r5o=r(UIt,"ElectraTokenizer"),UIt.forEach(t),t5o=r($N," or "),lO=n($N,"A",{href:!0});var HIt=s(lO);a5o=r(HIt,"ElectraTokenizerFast"),HIt.forEach(t),n5o=r($N," (ELECTRA model)"),$N.forEach(t),s5o=i(S),js=n(S,"LI",{});var kN=s(js);P_e=n(kN,"STRONG",{});var JIt=s(P_e);l5o=r(JIt,"ernie"),JIt.forEach(t),i5o=r(kN," \u2014 "),iO=n(kN,"A",{href:!0});var YIt=s(iO);d5o=r(YIt,"BertTokenizer"),YIt.forEach(t),m5o=r(kN," or "),dO=n(kN,"A",{href:!0});var ZIt=s(dO);c5o=r(ZIt,"BertTokenizerFast"),ZIt.forEach(t),f5o=r(kN," (ERNIE model)"),kN.forEach(t),g5o=i(S),Uu=n(S,"LI",{});var aOe=s(Uu);B_e=n(aOe,"STRONG",{});var KIt=s(B_e);h5o=r(KIt,"esm"),KIt.forEach(t),u5o=r(aOe," \u2014 "),mO=n(aOe,"A",{href:!0});var eNt=s(mO);p5o=r(eNt,"EsmTokenizer"),eNt.forEach(t),_5o=r(aOe," (ESM model)"),aOe.forEach(t),b5o=i(S),Hu=n(S,"LI",{});var nOe=s(Hu);I_e=n(nOe,"STRONG",{});var oNt=s(I_e);v5o=r(oNt,"flaubert"),oNt.forEach(t),F5o=r(nOe," \u2014 "),cO=n(nOe,"A",{href:!0});var rNt=s(cO);T5o=r(rNt,"FlaubertTokenizer"),rNt.forEach(t),M5o=r(nOe," (FlauBERT model)"),nOe.forEach(t),E5o=i(S),Gs=n(S,"LI",{});var SN=s(Gs);N_e=n(SN,"STRONG",{});var tNt=s(N_e);C5o=r(tNt,"fnet"),tNt.forEach(t),w5o=r(SN," \u2014 "),fO=n(SN,"A",{href:!0});var aNt=s(fO);A5o=r(aNt,"FNetTokenizer"),aNt.forEach(t),L5o=r(SN," or "),gO=n(SN,"A",{href:!0});var nNt=s(gO);y5o=r(nNt,"FNetTokenizerFast"),nNt.forEach(t),x5o=r(SN," (FNet model)"),SN.forEach(t),$5o=i(S),Ju=n(S,"LI",{});var sOe=s(Ju);q_e=n(sOe,"STRONG",{});var sNt=s(q_e);k5o=r(sNt,"fsmt"),sNt.forEach(t),S5o=r(sOe," \u2014 "),hO=n(sOe,"A",{href:!0});var lNt=s(hO);R5o=r(lNt,"FSMTTokenizer"),lNt.forEach(t),P5o=r(sOe," (FairSeq Machine-Translation model)"),sOe.forEach(t),B5o=i(S),Os=n(S,"LI",{});var RN=s(Os);D_e=n(RN,"STRONG",{});var iNt=s(D_e);I5o=r(iNt,"funnel"),iNt.forEach(t),N5o=r(RN," \u2014 "),uO=n(RN,"A",{href:!0});var dNt=s(uO);q5o=r(dNt,"FunnelTokenizer"),dNt.forEach(t),D5o=r(RN," or "),pO=n(RN,"A",{href:!0});var mNt=s(pO);j5o=r(mNt,"FunnelTokenizerFast"),mNt.forEach(t),G5o=r(RN," (Funnel Transformer model)"),RN.forEach(t),O5o=i(S),Vs=n(S,"LI",{});var PN=s(Vs);j_e=n(PN,"STRONG",{});var cNt=s(j_e);V5o=r(cNt,"gpt2"),cNt.forEach(t),X5o=r(PN," \u2014 "),_O=n(PN,"A",{href:!0});var fNt=s(_O);z5o=r(fNt,"GPT2Tokenizer"),fNt.forEach(t),Q5o=r(PN," or "),bO=n(PN,"A",{href:!0});var gNt=s(bO);W5o=r(gNt,"GPT2TokenizerFast"),gNt.forEach(t),U5o=r(PN," (OpenAI GPT-2 model)"),PN.forEach(t),H5o=i(S),Xs=n(S,"LI",{});var BN=s(Xs);G_e=n(BN,"STRONG",{});var hNt=s(G_e);J5o=r(hNt,"gpt_neo"),hNt.forEach(t),Y5o=r(BN," \u2014 "),vO=n(BN,"A",{href:!0});var uNt=s(vO);Z5o=r(uNt,"GPT2Tokenizer"),uNt.forEach(t),K5o=r(BN," or "),FO=n(BN,"A",{href:!0});var pNt=s(FO);e0o=r(pNt,"GPT2TokenizerFast"),pNt.forEach(t),o0o=r(BN," (GPT Neo model)"),BN.forEach(t),r0o=i(S),Yu=n(S,"LI",{});var lOe=s(Yu);O_e=n(lOe,"STRONG",{});var _Nt=s(O_e);t0o=r(_Nt,"gpt_neox"),_Nt.forEach(t),a0o=r(lOe," \u2014 "),TO=n(lOe,"A",{href:!0});var bNt=s(TO);n0o=r(bNt,"GPTNeoXTokenizerFast"),bNt.forEach(t),s0o=r(lOe," (GPT NeoX model)"),lOe.forEach(t),l0o=i(S),Zu=n(S,"LI",{});var iOe=s(Zu);V_e=n(iOe,"STRONG",{});var vNt=s(V_e);i0o=r(vNt,"gpt_neox_japanese"),vNt.forEach(t),d0o=r(iOe," \u2014 "),MO=n(iOe,"A",{href:!0});var FNt=s(MO);m0o=r(FNt,"GPTNeoXJapaneseTokenizer"),FNt.forEach(t),c0o=r(iOe," (GPT NeoX Japanese model)"),iOe.forEach(t),f0o=i(S),zs=n(S,"LI",{});var IN=s(zs);X_e=n(IN,"STRONG",{});var TNt=s(X_e);g0o=r(TNt,"gptj"),TNt.forEach(t),h0o=r(IN," \u2014 "),EO=n(IN,"A",{href:!0});var MNt=s(EO);u0o=r(MNt,"GPT2Tokenizer"),MNt.forEach(t),p0o=r(IN," or "),CO=n(IN,"A",{href:!0});var ENt=s(CO);_0o=r(ENt,"GPT2TokenizerFast"),ENt.forEach(t),b0o=r(IN," (GPT-J model)"),IN.forEach(t),v0o=i(S),Qs=n(S,"LI",{});var NN=s(Qs);z_e=n(NN,"STRONG",{});var CNt=s(z_e);F0o=r(CNt,"groupvit"),CNt.forEach(t),T0o=r(NN," \u2014 "),wO=n(NN,"A",{href:!0});var wNt=s(wO);M0o=r(wNt,"CLIPTokenizer"),wNt.forEach(t),E0o=r(NN," or "),AO=n(NN,"A",{href:!0});var ANt=s(AO);C0o=r(ANt,"CLIPTokenizerFast"),ANt.forEach(t),w0o=r(NN," (GroupViT model)"),NN.forEach(t),A0o=i(S),Ws=n(S,"LI",{});var qN=s(Ws);Q_e=n(qN,"STRONG",{});var LNt=s(Q_e);L0o=r(LNt,"herbert"),LNt.forEach(t),y0o=r(qN," \u2014 "),LO=n(qN,"A",{href:!0});var yNt=s(LO);x0o=r(yNt,"HerbertTokenizer"),yNt.forEach(t),$0o=r(qN," or "),yO=n(qN,"A",{href:!0});var xNt=s(yO);k0o=r(xNt,"HerbertTokenizerFast"),xNt.forEach(t),S0o=r(qN," (HerBERT model)"),qN.forEach(t),R0o=i(S),Ku=n(S,"LI",{});var dOe=s(Ku);W_e=n(dOe,"STRONG",{});var $Nt=s(W_e);P0o=r($Nt,"hubert"),$Nt.forEach(t),B0o=r(dOe," \u2014 "),xO=n(dOe,"A",{href:!0});var kNt=s(xO);I0o=r(kNt,"Wav2Vec2CTCTokenizer"),kNt.forEach(t),N0o=r(dOe," (Hubert model)"),dOe.forEach(t),q0o=i(S),Us=n(S,"LI",{});var DN=s(Us);U_e=n(DN,"STRONG",{});var SNt=s(U_e);D0o=r(SNt,"ibert"),SNt.forEach(t),j0o=r(DN," \u2014 "),$O=n(DN,"A",{href:!0});var RNt=s($O);G0o=r(RNt,"RobertaTokenizer"),RNt.forEach(t),O0o=r(DN," or "),kO=n(DN,"A",{href:!0});var PNt=s(kO);V0o=r(PNt,"RobertaTokenizerFast"),PNt.forEach(t),X0o=r(DN," (I-BERT model)"),DN.forEach(t),z0o=i(S),Hs=n(S,"LI",{});var jN=s(Hs);H_e=n(jN,"STRONG",{});var BNt=s(H_e);Q0o=r(BNt,"layoutlm"),BNt.forEach(t),W0o=r(jN," \u2014 "),SO=n(jN,"A",{href:!0});var INt=s(SO);U0o=r(INt,"LayoutLMTokenizer"),INt.forEach(t),H0o=r(jN," or "),RO=n(jN,"A",{href:!0});var NNt=s(RO);J0o=r(NNt,"LayoutLMTokenizerFast"),NNt.forEach(t),Y0o=r(jN," (LayoutLM model)"),jN.forEach(t),Z0o=i(S),Js=n(S,"LI",{});var GN=s(Js);J_e=n(GN,"STRONG",{});var qNt=s(J_e);K0o=r(qNt,"layoutlmv2"),qNt.forEach(t),ewo=r(GN," \u2014 "),PO=n(GN,"A",{href:!0});var DNt=s(PO);owo=r(DNt,"LayoutLMv2Tokenizer"),DNt.forEach(t),rwo=r(GN," or "),BO=n(GN,"A",{href:!0});var jNt=s(BO);two=r(jNt,"LayoutLMv2TokenizerFast"),jNt.forEach(t),awo=r(GN," (LayoutLMv2 model)"),GN.forEach(t),nwo=i(S),Ys=n(S,"LI",{});var ON=s(Ys);Y_e=n(ON,"STRONG",{});var GNt=s(Y_e);swo=r(GNt,"layoutlmv3"),GNt.forEach(t),lwo=r(ON," \u2014 "),IO=n(ON,"A",{href:!0});var ONt=s(IO);iwo=r(ONt,"LayoutLMv3Tokenizer"),ONt.forEach(t),dwo=r(ON," or "),NO=n(ON,"A",{href:!0});var VNt=s(NO);mwo=r(VNt,"LayoutLMv3TokenizerFast"),VNt.forEach(t),cwo=r(ON," (LayoutLMv3 model)"),ON.forEach(t),fwo=i(S),Zs=n(S,"LI",{});var VN=s(Zs);Z_e=n(VN,"STRONG",{});var XNt=s(Z_e);gwo=r(XNt,"layoutxlm"),XNt.forEach(t),hwo=r(VN," \u2014 "),qO=n(VN,"A",{href:!0});var zNt=s(qO);uwo=r(zNt,"LayoutXLMTokenizer"),zNt.forEach(t),pwo=r(VN," or "),DO=n(VN,"A",{href:!0});var QNt=s(DO);_wo=r(QNt,"LayoutXLMTokenizerFast"),QNt.forEach(t),bwo=r(VN," (LayoutXLM model)"),VN.forEach(t),vwo=i(S),Ks=n(S,"LI",{});var XN=s(Ks);K_e=n(XN,"STRONG",{});var WNt=s(K_e);Fwo=r(WNt,"led"),WNt.forEach(t),Two=r(XN," \u2014 "),jO=n(XN,"A",{href:!0});var UNt=s(jO);Mwo=r(UNt,"LEDTokenizer"),UNt.forEach(t),Ewo=r(XN," or "),GO=n(XN,"A",{href:!0});var HNt=s(GO);Cwo=r(HNt,"LEDTokenizerFast"),HNt.forEach(t),wwo=r(XN," (LED model)"),XN.forEach(t),Awo=i(S),el=n(S,"LI",{});var zN=s(el);e1e=n(zN,"STRONG",{});var JNt=s(e1e);Lwo=r(JNt,"lilt"),JNt.forEach(t),ywo=r(zN," \u2014 "),OO=n(zN,"A",{href:!0});var YNt=s(OO);xwo=r(YNt,"LayoutLMv3Tokenizer"),YNt.forEach(t),$wo=r(zN," or "),VO=n(zN,"A",{href:!0});var ZNt=s(VO);kwo=r(ZNt,"LayoutLMv3TokenizerFast"),ZNt.forEach(t),Swo=r(zN," (LiLT model)"),zN.forEach(t),Rwo=i(S),ol=n(S,"LI",{});var QN=s(ol);o1e=n(QN,"STRONG",{});var KNt=s(o1e);Pwo=r(KNt,"longformer"),KNt.forEach(t),Bwo=r(QN," \u2014 "),XO=n(QN,"A",{href:!0});var eqt=s(XO);Iwo=r(eqt,"LongformerTokenizer"),eqt.forEach(t),Nwo=r(QN," or "),zO=n(QN,"A",{href:!0});var oqt=s(zO);qwo=r(oqt,"LongformerTokenizerFast"),oqt.forEach(t),Dwo=r(QN," (Longformer model)"),QN.forEach(t),jwo=i(S),rl=n(S,"LI",{});var WN=s(rl);r1e=n(WN,"STRONG",{});var rqt=s(r1e);Gwo=r(rqt,"longt5"),rqt.forEach(t),Owo=r(WN," \u2014 "),QO=n(WN,"A",{href:!0});var tqt=s(QO);Vwo=r(tqt,"T5Tokenizer"),tqt.forEach(t),Xwo=r(WN," or "),WO=n(WN,"A",{href:!0});var aqt=s(WO);zwo=r(aqt,"T5TokenizerFast"),aqt.forEach(t),Qwo=r(WN," (LongT5 model)"),WN.forEach(t),Wwo=i(S),ep=n(S,"LI",{});var mOe=s(ep);t1e=n(mOe,"STRONG",{});var nqt=s(t1e);Uwo=r(nqt,"luke"),nqt.forEach(t),Hwo=r(mOe," \u2014 "),UO=n(mOe,"A",{href:!0});var sqt=s(UO);Jwo=r(sqt,"LukeTokenizer"),sqt.forEach(t),Ywo=r(mOe," (LUKE model)"),mOe.forEach(t),Zwo=i(S),tl=n(S,"LI",{});var UN=s(tl);a1e=n(UN,"STRONG",{});var lqt=s(a1e);Kwo=r(lqt,"lxmert"),lqt.forEach(t),eAo=r(UN," \u2014 "),HO=n(UN,"A",{href:!0});var iqt=s(HO);oAo=r(iqt,"LxmertTokenizer"),iqt.forEach(t),rAo=r(UN," or "),JO=n(UN,"A",{href:!0});var dqt=s(JO);tAo=r(dqt,"LxmertTokenizerFast"),dqt.forEach(t),aAo=r(UN," (LXMERT model)"),UN.forEach(t),nAo=i(S),op=n(S,"LI",{});var cOe=s(op);n1e=n(cOe,"STRONG",{});var mqt=s(n1e);sAo=r(mqt,"m2m_100"),mqt.forEach(t),lAo=r(cOe," \u2014 "),YO=n(cOe,"A",{href:!0});var cqt=s(YO);iAo=r(cqt,"M2M100Tokenizer"),cqt.forEach(t),dAo=r(cOe," (M2M100 model)"),cOe.forEach(t),mAo=i(S),rp=n(S,"LI",{});var fOe=s(rp);s1e=n(fOe,"STRONG",{});var fqt=s(s1e);cAo=r(fqt,"marian"),fqt.forEach(t),fAo=r(fOe," \u2014 "),ZO=n(fOe,"A",{href:!0});var gqt=s(ZO);gAo=r(gqt,"MarianTokenizer"),gqt.forEach(t),hAo=r(fOe," (Marian model)"),fOe.forEach(t),uAo=i(S),al=n(S,"LI",{});var HN=s(al);l1e=n(HN,"STRONG",{});var hqt=s(l1e);pAo=r(hqt,"mbart"),hqt.forEach(t),_Ao=r(HN," \u2014 "),KO=n(HN,"A",{href:!0});var uqt=s(KO);bAo=r(uqt,"MBartTokenizer"),uqt.forEach(t),vAo=r(HN," or "),eV=n(HN,"A",{href:!0});var pqt=s(eV);FAo=r(pqt,"MBartTokenizerFast"),pqt.forEach(t),TAo=r(HN," (mBART model)"),HN.forEach(t),MAo=i(S),nl=n(S,"LI",{});var JN=s(nl);i1e=n(JN,"STRONG",{});var _qt=s(i1e);EAo=r(_qt,"mbart50"),_qt.forEach(t),CAo=r(JN," \u2014 "),oV=n(JN,"A",{href:!0});var bqt=s(oV);wAo=r(bqt,"MBart50Tokenizer"),bqt.forEach(t),AAo=r(JN," or "),rV=n(JN,"A",{href:!0});var vqt=s(rV);LAo=r(vqt,"MBart50TokenizerFast"),vqt.forEach(t),yAo=r(JN," (mBART-50 model)"),JN.forEach(t),xAo=i(S),sl=n(S,"LI",{});var YN=s(sl);d1e=n(YN,"STRONG",{});var Fqt=s(d1e);$Ao=r(Fqt,"megatron-bert"),Fqt.forEach(t),kAo=r(YN," \u2014 "),tV=n(YN,"A",{href:!0});var Tqt=s(tV);SAo=r(Tqt,"BertTokenizer"),Tqt.forEach(t),RAo=r(YN," or "),aV=n(YN,"A",{href:!0});var Mqt=s(aV);PAo=r(Mqt,"BertTokenizerFast"),Mqt.forEach(t),BAo=r(YN," (Megatron-BERT model)"),YN.forEach(t),IAo=i(S),tp=n(S,"LI",{});var gOe=s(tp);m1e=n(gOe,"STRONG",{});var Eqt=s(m1e);NAo=r(Eqt,"mluke"),Eqt.forEach(t),qAo=r(gOe," \u2014 "),nV=n(gOe,"A",{href:!0});var Cqt=s(nV);DAo=r(Cqt,"MLukeTokenizer"),Cqt.forEach(t),jAo=r(gOe," (mLUKE model)"),gOe.forEach(t),GAo=i(S),ll=n(S,"LI",{});var ZN=s(ll);c1e=n(ZN,"STRONG",{});var wqt=s(c1e);OAo=r(wqt,"mobilebert"),wqt.forEach(t),VAo=r(ZN," \u2014 "),sV=n(ZN,"A",{href:!0});var Aqt=s(sV);XAo=r(Aqt,"MobileBertTokenizer"),Aqt.forEach(t),zAo=r(ZN," or "),lV=n(ZN,"A",{href:!0});var Lqt=s(lV);QAo=r(Lqt,"MobileBertTokenizerFast"),Lqt.forEach(t),WAo=r(ZN," (MobileBERT model)"),ZN.forEach(t),UAo=i(S),il=n(S,"LI",{});var KN=s(il);f1e=n(KN,"STRONG",{});var yqt=s(f1e);HAo=r(yqt,"mpnet"),yqt.forEach(t),JAo=r(KN," \u2014 "),iV=n(KN,"A",{href:!0});var xqt=s(iV);YAo=r(xqt,"MPNetTokenizer"),xqt.forEach(t),ZAo=r(KN," or "),dV=n(KN,"A",{href:!0});var $qt=s(dV);KAo=r($qt,"MPNetTokenizerFast"),$qt.forEach(t),e6o=r(KN," (MPNet model)"),KN.forEach(t),o6o=i(S),dl=n(S,"LI",{});var eq=s(dl);g1e=n(eq,"STRONG",{});var kqt=s(g1e);r6o=r(kqt,"mt5"),kqt.forEach(t),t6o=r(eq," \u2014 "),mV=n(eq,"A",{href:!0});var Sqt=s(mV);a6o=r(Sqt,"MT5Tokenizer"),Sqt.forEach(t),n6o=r(eq," or "),cV=n(eq,"A",{href:!0});var Rqt=s(cV);s6o=r(Rqt,"MT5TokenizerFast"),Rqt.forEach(t),l6o=r(eq," (MT5 model)"),eq.forEach(t),i6o=i(S),ml=n(S,"LI",{});var oq=s(ml);h1e=n(oq,"STRONG",{});var Pqt=s(h1e);d6o=r(Pqt,"mvp"),Pqt.forEach(t),m6o=r(oq," \u2014 "),fV=n(oq,"A",{href:!0});var Bqt=s(fV);c6o=r(Bqt,"MvpTokenizer"),Bqt.forEach(t),f6o=r(oq," or "),gV=n(oq,"A",{href:!0});var Iqt=s(gV);g6o=r(Iqt,"MvpTokenizerFast"),Iqt.forEach(t),h6o=r(oq," (MVP model)"),oq.forEach(t),u6o=i(S),cl=n(S,"LI",{});var rq=s(cl);u1e=n(rq,"STRONG",{});var Nqt=s(u1e);p6o=r(Nqt,"nezha"),Nqt.forEach(t),_6o=r(rq," \u2014 "),hV=n(rq,"A",{href:!0});var qqt=s(hV);b6o=r(qqt,"BertTokenizer"),qqt.forEach(t),v6o=r(rq," or "),uV=n(rq,"A",{href:!0});var Dqt=s(uV);F6o=r(Dqt,"BertTokenizerFast"),Dqt.forEach(t),T6o=r(rq," (Nezha model)"),rq.forEach(t),M6o=i(S),fl=n(S,"LI",{});var tq=s(fl);p1e=n(tq,"STRONG",{});var jqt=s(p1e);E6o=r(jqt,"nllb"),jqt.forEach(t),C6o=r(tq," \u2014 "),pV=n(tq,"A",{href:!0});var Gqt=s(pV);w6o=r(Gqt,"NllbTokenizer"),Gqt.forEach(t),A6o=r(tq," or "),_V=n(tq,"A",{href:!0});var Oqt=s(_V);L6o=r(Oqt,"NllbTokenizerFast"),Oqt.forEach(t),y6o=r(tq," (NLLB model)"),tq.forEach(t),x6o=i(S),gl=n(S,"LI",{});var aq=s(gl);_1e=n(aq,"STRONG",{});var Vqt=s(_1e);$6o=r(Vqt,"nystromformer"),Vqt.forEach(t),k6o=r(aq," \u2014 "),bV=n(aq,"A",{href:!0});var Xqt=s(bV);S6o=r(Xqt,"AlbertTokenizer"),Xqt.forEach(t),R6o=r(aq," or "),vV=n(aq,"A",{href:!0});var zqt=s(vV);P6o=r(zqt,"AlbertTokenizerFast"),zqt.forEach(t),B6o=r(aq," (Nystr\xF6mformer model)"),aq.forEach(t),I6o=i(S),hl=n(S,"LI",{});var nq=s(hl);b1e=n(nq,"STRONG",{});var Qqt=s(b1e);N6o=r(Qqt,"openai-gpt"),Qqt.forEach(t),q6o=r(nq," \u2014 "),FV=n(nq,"A",{href:!0});var Wqt=s(FV);D6o=r(Wqt,"OpenAIGPTTokenizer"),Wqt.forEach(t),j6o=r(nq," or "),TV=n(nq,"A",{href:!0});var Uqt=s(TV);G6o=r(Uqt,"OpenAIGPTTokenizerFast"),Uqt.forEach(t),O6o=r(nq," (OpenAI GPT model)"),nq.forEach(t),V6o=i(S),ap=n(S,"LI",{});var hOe=s(ap);v1e=n(hOe,"STRONG",{});var Hqt=s(v1e);X6o=r(Hqt,"opt"),Hqt.forEach(t),z6o=r(hOe," \u2014 "),MV=n(hOe,"A",{href:!0});var Jqt=s(MV);Q6o=r(Jqt,"GPT2Tokenizer"),Jqt.forEach(t),W6o=r(hOe," (OPT model)"),hOe.forEach(t),U6o=i(S),ul=n(S,"LI",{});var sq=s(ul);F1e=n(sq,"STRONG",{});var Yqt=s(F1e);H6o=r(Yqt,"owlvit"),Yqt.forEach(t),J6o=r(sq," \u2014 "),EV=n(sq,"A",{href:!0});var Zqt=s(EV);Y6o=r(Zqt,"CLIPTokenizer"),Zqt.forEach(t),Z6o=r(sq," or "),CV=n(sq,"A",{href:!0});var Kqt=s(CV);K6o=r(Kqt,"CLIPTokenizerFast"),Kqt.forEach(t),e7o=r(sq," (OWL-ViT model)"),sq.forEach(t),o7o=i(S),pl=n(S,"LI",{});var lq=s(pl);T1e=n(lq,"STRONG",{});var eDt=s(T1e);r7o=r(eDt,"pegasus"),eDt.forEach(t),t7o=r(lq," \u2014 "),wV=n(lq,"A",{href:!0});var oDt=s(wV);a7o=r(oDt,"PegasusTokenizer"),oDt.forEach(t),n7o=r(lq," or "),AV=n(lq,"A",{href:!0});var rDt=s(AV);s7o=r(rDt,"PegasusTokenizerFast"),rDt.forEach(t),l7o=r(lq," (Pegasus model)"),lq.forEach(t),i7o=i(S),_l=n(S,"LI",{});var iq=s(_l);M1e=n(iq,"STRONG",{});var tDt=s(M1e);d7o=r(tDt,"pegasus_x"),tDt.forEach(t),m7o=r(iq," \u2014 "),LV=n(iq,"A",{href:!0});var aDt=s(LV);c7o=r(aDt,"PegasusTokenizer"),aDt.forEach(t),f7o=r(iq," or "),yV=n(iq,"A",{href:!0});var nDt=s(yV);g7o=r(nDt,"PegasusTokenizerFast"),nDt.forEach(t),h7o=r(iq," (PEGASUS-X model)"),iq.forEach(t),u7o=i(S),np=n(S,"LI",{});var uOe=s(np);E1e=n(uOe,"STRONG",{});var sDt=s(E1e);p7o=r(sDt,"perceiver"),sDt.forEach(t),_7o=r(uOe," \u2014 "),xV=n(uOe,"A",{href:!0});var lDt=s(xV);b7o=r(lDt,"PerceiverTokenizer"),lDt.forEach(t),v7o=r(uOe," (Perceiver model)"),uOe.forEach(t),F7o=i(S),sp=n(S,"LI",{});var pOe=s(sp);C1e=n(pOe,"STRONG",{});var iDt=s(C1e);T7o=r(iDt,"phobert"),iDt.forEach(t),M7o=r(pOe," \u2014 "),$V=n(pOe,"A",{href:!0});var dDt=s($V);E7o=r(dDt,"PhobertTokenizer"),dDt.forEach(t),C7o=r(pOe," (PhoBERT model)"),pOe.forEach(t),w7o=i(S),lp=n(S,"LI",{});var _Oe=s(lp);w1e=n(_Oe,"STRONG",{});var mDt=s(w1e);A7o=r(mDt,"plbart"),mDt.forEach(t),L7o=r(_Oe," \u2014 "),kV=n(_Oe,"A",{href:!0});var cDt=s(kV);y7o=r(cDt,"PLBartTokenizer"),cDt.forEach(t),x7o=r(_Oe," (PLBart model)"),_Oe.forEach(t),$7o=i(S),ip=n(S,"LI",{});var bOe=s(ip);A1e=n(bOe,"STRONG",{});var fDt=s(A1e);k7o=r(fDt,"prophetnet"),fDt.forEach(t),S7o=r(bOe," \u2014 "),SV=n(bOe,"A",{href:!0});var gDt=s(SV);R7o=r(gDt,"ProphetNetTokenizer"),gDt.forEach(t),P7o=r(bOe," (ProphetNet model)"),bOe.forEach(t),B7o=i(S),bl=n(S,"LI",{});var dq=s(bl);L1e=n(dq,"STRONG",{});var hDt=s(L1e);I7o=r(hDt,"qdqbert"),hDt.forEach(t),N7o=r(dq," \u2014 "),RV=n(dq,"A",{href:!0});var uDt=s(RV);q7o=r(uDt,"BertTokenizer"),uDt.forEach(t),D7o=r(dq," or "),PV=n(dq,"A",{href:!0});var pDt=s(PV);j7o=r(pDt,"BertTokenizerFast"),pDt.forEach(t),G7o=r(dq," (QDQBert model)"),dq.forEach(t),O7o=i(S),dp=n(S,"LI",{});var vOe=s(dp);y1e=n(vOe,"STRONG",{});var _Dt=s(y1e);V7o=r(_Dt,"rag"),_Dt.forEach(t),X7o=r(vOe," \u2014 "),BV=n(vOe,"A",{href:!0});var bDt=s(BV);z7o=r(bDt,"RagTokenizer"),bDt.forEach(t),Q7o=r(vOe," (RAG model)"),vOe.forEach(t),W7o=i(S),vl=n(S,"LI",{});var mq=s(vl);x1e=n(mq,"STRONG",{});var vDt=s(x1e);U7o=r(vDt,"realm"),vDt.forEach(t),H7o=r(mq," \u2014 "),IV=n(mq,"A",{href:!0});var FDt=s(IV);J7o=r(FDt,"RealmTokenizer"),FDt.forEach(t),Y7o=r(mq," or "),NV=n(mq,"A",{href:!0});var TDt=s(NV);Z7o=r(TDt,"RealmTokenizerFast"),TDt.forEach(t),K7o=r(mq," (REALM model)"),mq.forEach(t),e8o=i(S),Fl=n(S,"LI",{});var cq=s(Fl);$1e=n(cq,"STRONG",{});var MDt=s($1e);o8o=r(MDt,"reformer"),MDt.forEach(t),r8o=r(cq," \u2014 "),qV=n(cq,"A",{href:!0});var EDt=s(qV);t8o=r(EDt,"ReformerTokenizer"),EDt.forEach(t),a8o=r(cq," or "),DV=n(cq,"A",{href:!0});var CDt=s(DV);n8o=r(CDt,"ReformerTokenizerFast"),CDt.forEach(t),s8o=r(cq," (Reformer model)"),cq.forEach(t),l8o=i(S),Tl=n(S,"LI",{});var fq=s(Tl);k1e=n(fq,"STRONG",{});var wDt=s(k1e);i8o=r(wDt,"rembert"),wDt.forEach(t),d8o=r(fq," \u2014 "),jV=n(fq,"A",{href:!0});var ADt=s(jV);m8o=r(ADt,"RemBertTokenizer"),ADt.forEach(t),c8o=r(fq," or "),GV=n(fq,"A",{href:!0});var LDt=s(GV);f8o=r(LDt,"RemBertTokenizerFast"),LDt.forEach(t),g8o=r(fq," (RemBERT model)"),fq.forEach(t),h8o=i(S),Ml=n(S,"LI",{});var gq=s(Ml);S1e=n(gq,"STRONG",{});var yDt=s(S1e);u8o=r(yDt,"retribert"),yDt.forEach(t),p8o=r(gq," \u2014 "),OV=n(gq,"A",{href:!0});var xDt=s(OV);_8o=r(xDt,"RetriBertTokenizer"),xDt.forEach(t),b8o=r(gq," or "),VV=n(gq,"A",{href:!0});var $Dt=s(VV);v8o=r($Dt,"RetriBertTokenizerFast"),$Dt.forEach(t),F8o=r(gq," (RetriBERT model)"),gq.forEach(t),T8o=i(S),El=n(S,"LI",{});var hq=s(El);R1e=n(hq,"STRONG",{});var kDt=s(R1e);M8o=r(kDt,"roberta"),kDt.forEach(t),E8o=r(hq," \u2014 "),XV=n(hq,"A",{href:!0});var SDt=s(XV);C8o=r(SDt,"RobertaTokenizer"),SDt.forEach(t),w8o=r(hq," or "),zV=n(hq,"A",{href:!0});var RDt=s(zV);A8o=r(RDt,"RobertaTokenizerFast"),RDt.forEach(t),L8o=r(hq," (RoBERTa model)"),hq.forEach(t),y8o=i(S),mp=n(S,"LI",{});var FOe=s(mp);P1e=n(FOe,"STRONG",{});var PDt=s(P1e);x8o=r(PDt,"roc_bert"),PDt.forEach(t),$8o=r(FOe," \u2014 "),QV=n(FOe,"A",{href:!0});var BDt=s(QV);k8o=r(BDt,"RoCBertTokenizer"),BDt.forEach(t),S8o=r(FOe," (RoCBert model)"),FOe.forEach(t),R8o=i(S),Cl=n(S,"LI",{});var uq=s(Cl);B1e=n(uq,"STRONG",{});var IDt=s(B1e);P8o=r(IDt,"roformer"),IDt.forEach(t),B8o=r(uq," \u2014 "),WV=n(uq,"A",{href:!0});var NDt=s(WV);I8o=r(NDt,"RoFormerTokenizer"),NDt.forEach(t),N8o=r(uq," or "),UV=n(uq,"A",{href:!0});var qDt=s(UV);q8o=r(qDt,"RoFormerTokenizerFast"),qDt.forEach(t),D8o=r(uq," (RoFormer model)"),uq.forEach(t),j8o=i(S),cp=n(S,"LI",{});var TOe=s(cp);I1e=n(TOe,"STRONG",{});var DDt=s(I1e);G8o=r(DDt,"speech_to_text"),DDt.forEach(t),O8o=r(TOe," \u2014 "),HV=n(TOe,"A",{href:!0});var jDt=s(HV);V8o=r(jDt,"Speech2TextTokenizer"),jDt.forEach(t),X8o=r(TOe," (Speech2Text model)"),TOe.forEach(t),z8o=i(S),fp=n(S,"LI",{});var MOe=s(fp);N1e=n(MOe,"STRONG",{});var GDt=s(N1e);Q8o=r(GDt,"speech_to_text_2"),GDt.forEach(t),W8o=r(MOe," \u2014 "),JV=n(MOe,"A",{href:!0});var ODt=s(JV);U8o=r(ODt,"Speech2Text2Tokenizer"),ODt.forEach(t),H8o=r(MOe," (Speech2Text2 model)"),MOe.forEach(t),J8o=i(S),wl=n(S,"LI",{});var pq=s(wl);q1e=n(pq,"STRONG",{});var VDt=s(q1e);Y8o=r(VDt,"splinter"),VDt.forEach(t),Z8o=r(pq," \u2014 "),YV=n(pq,"A",{href:!0});var XDt=s(YV);K8o=r(XDt,"SplinterTokenizer"),XDt.forEach(t),eLo=r(pq," or "),ZV=n(pq,"A",{href:!0});var zDt=s(ZV);oLo=r(zDt,"SplinterTokenizerFast"),zDt.forEach(t),rLo=r(pq," (Splinter model)"),pq.forEach(t),tLo=i(S),Al=n(S,"LI",{});var _q=s(Al);D1e=n(_q,"STRONG",{});var QDt=s(D1e);aLo=r(QDt,"squeezebert"),QDt.forEach(t),nLo=r(_q," \u2014 "),KV=n(_q,"A",{href:!0});var WDt=s(KV);sLo=r(WDt,"SqueezeBertTokenizer"),WDt.forEach(t),lLo=r(_q," or "),eX=n(_q,"A",{href:!0});var UDt=s(eX);iLo=r(UDt,"SqueezeBertTokenizerFast"),UDt.forEach(t),dLo=r(_q," (SqueezeBERT model)"),_q.forEach(t),mLo=i(S),Ll=n(S,"LI",{});var bq=s(Ll);j1e=n(bq,"STRONG",{});var HDt=s(j1e);cLo=r(HDt,"t5"),HDt.forEach(t),fLo=r(bq," \u2014 "),oX=n(bq,"A",{href:!0});var JDt=s(oX);gLo=r(JDt,"T5Tokenizer"),JDt.forEach(t),hLo=r(bq," or "),rX=n(bq,"A",{href:!0});var YDt=s(rX);uLo=r(YDt,"T5TokenizerFast"),YDt.forEach(t),pLo=r(bq," (T5 model)"),bq.forEach(t),_Lo=i(S),gp=n(S,"LI",{});var EOe=s(gp);G1e=n(EOe,"STRONG",{});var ZDt=s(G1e);bLo=r(ZDt,"tapas"),ZDt.forEach(t),vLo=r(EOe," \u2014 "),tX=n(EOe,"A",{href:!0});var KDt=s(tX);FLo=r(KDt,"TapasTokenizer"),KDt.forEach(t),TLo=r(EOe," (TAPAS model)"),EOe.forEach(t),MLo=i(S),hp=n(S,"LI",{});var COe=s(hp);O1e=n(COe,"STRONG",{});var ejt=s(O1e);ELo=r(ejt,"tapex"),ejt.forEach(t),CLo=r(COe," \u2014 "),aX=n(COe,"A",{href:!0});var ojt=s(aX);wLo=r(ojt,"TapexTokenizer"),ojt.forEach(t),ALo=r(COe," (TAPEX model)"),COe.forEach(t),LLo=i(S),up=n(S,"LI",{});var wOe=s(up);V1e=n(wOe,"STRONG",{});var rjt=s(V1e);yLo=r(rjt,"transfo-xl"),rjt.forEach(t),xLo=r(wOe," \u2014 "),nX=n(wOe,"A",{href:!0});var tjt=s(nX);$Lo=r(tjt,"TransfoXLTokenizer"),tjt.forEach(t),kLo=r(wOe," (Transformer-XL model)"),wOe.forEach(t),SLo=i(S),yl=n(S,"LI",{});var vq=s(yl);X1e=n(vq,"STRONG",{});var ajt=s(X1e);RLo=r(ajt,"vilt"),ajt.forEach(t),PLo=r(vq," \u2014 "),sX=n(vq,"A",{href:!0});var njt=s(sX);BLo=r(njt,"BertTokenizer"),njt.forEach(t),ILo=r(vq," or "),lX=n(vq,"A",{href:!0});var sjt=s(lX);NLo=r(sjt,"BertTokenizerFast"),sjt.forEach(t),qLo=r(vq," (ViLT model)"),vq.forEach(t),DLo=i(S),xl=n(S,"LI",{});var Fq=s(xl);z1e=n(Fq,"STRONG",{});var ljt=s(z1e);jLo=r(ljt,"visual_bert"),ljt.forEach(t),GLo=r(Fq," \u2014 "),iX=n(Fq,"A",{href:!0});var ijt=s(iX);OLo=r(ijt,"BertTokenizer"),ijt.forEach(t),VLo=r(Fq," or "),dX=n(Fq,"A",{href:!0});var djt=s(dX);XLo=r(djt,"BertTokenizerFast"),djt.forEach(t),zLo=r(Fq," (VisualBERT model)"),Fq.forEach(t),QLo=i(S),pp=n(S,"LI",{});var AOe=s(pp);Q1e=n(AOe,"STRONG",{});var mjt=s(Q1e);WLo=r(mjt,"wav2vec2"),mjt.forEach(t),ULo=r(AOe," \u2014 "),mX=n(AOe,"A",{href:!0});var cjt=s(mX);HLo=r(cjt,"Wav2Vec2CTCTokenizer"),cjt.forEach(t),JLo=r(AOe," (Wav2Vec2 model)"),AOe.forEach(t),YLo=i(S),_p=n(S,"LI",{});var LOe=s(_p);W1e=n(LOe,"STRONG",{});var fjt=s(W1e);ZLo=r(fjt,"wav2vec2-conformer"),fjt.forEach(t),KLo=r(LOe," \u2014 "),cX=n(LOe,"A",{href:!0});var gjt=s(cX);eyo=r(gjt,"Wav2Vec2CTCTokenizer"),gjt.forEach(t),oyo=r(LOe," (Wav2Vec2-Conformer model)"),LOe.forEach(t),ryo=i(S),bp=n(S,"LI",{});var yOe=s(bp);U1e=n(yOe,"STRONG",{});var hjt=s(U1e);tyo=r(hjt,"wav2vec2_phoneme"),hjt.forEach(t),ayo=r(yOe," \u2014 "),fX=n(yOe,"A",{href:!0});var ujt=s(fX);nyo=r(ujt,"Wav2Vec2PhonemeCTCTokenizer"),ujt.forEach(t),syo=r(yOe," (Wav2Vec2Phoneme model)"),yOe.forEach(t),lyo=i(S),vp=n(S,"LI",{});var xOe=s(vp);H1e=n(xOe,"STRONG",{});var pjt=s(H1e);iyo=r(pjt,"whisper"),pjt.forEach(t),dyo=r(xOe," \u2014 "),gX=n(xOe,"A",{href:!0});var _jt=s(gX);myo=r(_jt,"WhisperTokenizer"),_jt.forEach(t),cyo=r(xOe," (Whisper model)"),xOe.forEach(t),fyo=i(S),$l=n(S,"LI",{});var Tq=s($l);J1e=n(Tq,"STRONG",{});var bjt=s(J1e);gyo=r(bjt,"xclip"),bjt.forEach(t),hyo=r(Tq," \u2014 "),hX=n(Tq,"A",{href:!0});var vjt=s(hX);uyo=r(vjt,"CLIPTokenizer"),vjt.forEach(t),pyo=r(Tq," or "),uX=n(Tq,"A",{href:!0});var Fjt=s(uX);_yo=r(Fjt,"CLIPTokenizerFast"),Fjt.forEach(t),byo=r(Tq," (X-CLIP model)"),Tq.forEach(t),vyo=i(S),kl=n(S,"LI",{});var Mq=s(kl);Y1e=n(Mq,"STRONG",{});var Tjt=s(Y1e);Fyo=r(Tjt,"xglm"),Tjt.forEach(t),Tyo=r(Mq," \u2014 "),pX=n(Mq,"A",{href:!0});var Mjt=s(pX);Myo=r(Mjt,"XGLMTokenizer"),Mjt.forEach(t),Eyo=r(Mq," or "),_X=n(Mq,"A",{href:!0});var Ejt=s(_X);Cyo=r(Ejt,"XGLMTokenizerFast"),Ejt.forEach(t),wyo=r(Mq," (XGLM model)"),Mq.forEach(t),Ayo=i(S),Fp=n(S,"LI",{});var $Oe=s(Fp);Z1e=n($Oe,"STRONG",{});var Cjt=s(Z1e);Lyo=r(Cjt,"xlm"),Cjt.forEach(t),yyo=r($Oe," \u2014 "),bX=n($Oe,"A",{href:!0});var wjt=s(bX);xyo=r(wjt,"XLMTokenizer"),wjt.forEach(t),$yo=r($Oe," (XLM model)"),$Oe.forEach(t),kyo=i(S),Tp=n(S,"LI",{});var kOe=s(Tp);K1e=n(kOe,"STRONG",{});var Ajt=s(K1e);Syo=r(Ajt,"xlm-prophetnet"),Ajt.forEach(t),Ryo=r(kOe," \u2014 "),vX=n(kOe,"A",{href:!0});var Ljt=s(vX);Pyo=r(Ljt,"XLMProphetNetTokenizer"),Ljt.forEach(t),Byo=r(kOe," (XLM-ProphetNet model)"),kOe.forEach(t),Iyo=i(S),Sl=n(S,"LI",{});var Eq=s(Sl);e2e=n(Eq,"STRONG",{});var yjt=s(e2e);Nyo=r(yjt,"xlm-roberta"),yjt.forEach(t),qyo=r(Eq," \u2014 "),FX=n(Eq,"A",{href:!0});var xjt=s(FX);Dyo=r(xjt,"XLMRobertaTokenizer"),xjt.forEach(t),jyo=r(Eq," or "),TX=n(Eq,"A",{href:!0});var $jt=s(TX);Gyo=r($jt,"XLMRobertaTokenizerFast"),$jt.forEach(t),Oyo=r(Eq," (XLM-RoBERTa model)"),Eq.forEach(t),Vyo=i(S),Rl=n(S,"LI",{});var Cq=s(Rl);o2e=n(Cq,"STRONG",{});var kjt=s(o2e);Xyo=r(kjt,"xlm-roberta-xl"),kjt.forEach(t),zyo=r(Cq," \u2014 "),MX=n(Cq,"A",{href:!0});var Sjt=s(MX);Qyo=r(Sjt,"XLMRobertaTokenizer"),Sjt.forEach(t),Wyo=r(Cq," or "),EX=n(Cq,"A",{href:!0});var Rjt=s(EX);Uyo=r(Rjt,"XLMRobertaTokenizerFast"),Rjt.forEach(t),Hyo=r(Cq," (XLM-RoBERTa-XL model)"),Cq.forEach(t),Jyo=i(S),Pl=n(S,"LI",{});var wq=s(Pl);r2e=n(wq,"STRONG",{});var Pjt=s(r2e);Yyo=r(Pjt,"xlnet"),Pjt.forEach(t),Zyo=r(wq," \u2014 "),CX=n(wq,"A",{href:!0});var Bjt=s(CX);Kyo=r(Bjt,"XLNetTokenizer"),Bjt.forEach(t),e9o=r(wq," or "),wX=n(wq,"A",{href:!0});var Ijt=s(wX);o9o=r(Ijt,"XLNetTokenizerFast"),Ijt.forEach(t),r9o=r(wq," (XLNet model)"),wq.forEach(t),t9o=i(S),Bl=n(S,"LI",{});var Aq=s(Bl);t2e=n(Aq,"STRONG",{});var Njt=s(t2e);a9o=r(Njt,"yoso"),Njt.forEach(t),n9o=r(Aq," \u2014 "),AX=n(Aq,"A",{href:!0});var qjt=s(AX);s9o=r(qjt,"AlbertTokenizer"),qjt.forEach(t),l9o=r(Aq," or "),LX=n(Aq,"A",{href:!0});var Djt=s(LX);i9o=r(Djt,"AlbertTokenizerFast"),Djt.forEach(t),d9o=r(Aq," (YOSO model)"),Aq.forEach(t),S.forEach(t),m9o=i(Ol),T(Mp.$$.fragment,Ol),Ol.forEach(t),c9o=i(Gl),Ep=n(Gl,"DIV",{class:!0});var jdo=s(Ep);T(wk.$$.fragment,jdo),f9o=i(jdo),a2e=n(jdo,"P",{});var jjt=s(a2e);g9o=r(jjt,"Register a new tokenizer in this mapping."),jjt.forEach(t),jdo.forEach(t),Gl.forEach(t),wlo=i(c),Nd=n(c,"H2",{class:!0});var Gdo=s(Nd);Cp=n(Gdo,"A",{id:!0,class:!0,href:!0});var Gjt=s(Cp);n2e=n(Gjt,"SPAN",{});var Ojt=s(n2e);T(Ak.$$.fragment,Ojt),Ojt.forEach(t),Gjt.forEach(t),h9o=i(Gdo),s2e=n(Gdo,"SPAN",{});var Vjt=s(s2e);u9o=r(Vjt,"AutoFeatureExtractor"),Vjt.forEach(t),Gdo.forEach(t),Alo=i(c),No=n(c,"DIV",{class:!0});var Vl=s(No);T(Lk.$$.fragment,Vl),p9o=i(Vl),yk=n(Vl,"P",{});var Odo=s(yk);_9o=r(Odo,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),yX=n(Odo,"A",{href:!0});var Xjt=s(yX);b9o=r(Xjt,"AutoFeatureExtractor.from_pretrained()"),Xjt.forEach(t),v9o=r(Odo," class method."),Odo.forEach(t),F9o=i(Vl),xk=n(Vl,"P",{});var Vdo=s(xk);T9o=r(Vdo,"This class cannot be instantiated directly using "),l2e=n(Vdo,"CODE",{});var zjt=s(l2e);M9o=r(zjt,"__init__()"),zjt.forEach(t),E9o=r(Vdo," (throws an error)."),Vdo.forEach(t),C9o=i(Vl),eo=n(Vl,"DIV",{class:!0});var xa=s(eo);T($k.$$.fragment,xa),w9o=i(xa),i2e=n(xa,"P",{});var Qjt=s(i2e);A9o=r(Qjt,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),Qjt.forEach(t),L9o=i(xa),mn=n(xa,"P",{});var ox=s(mn);y9o=r(ox,"The feature extractor class to instantiate is selected based on the "),d2e=n(ox,"CODE",{});var Wjt=s(d2e);x9o=r(Wjt,"model_type"),Wjt.forEach(t),$9o=r(ox,` property of the config object
(either passed as an argument or loaded from `),m2e=n(ox,"CODE",{});var Ujt=s(m2e);k9o=r(Ujt,"pretrained_model_name_or_path"),Ujt.forEach(t),S9o=r(ox,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),c2e=n(ox,"CODE",{});var Hjt=s(c2e);R9o=r(Hjt,"pretrained_model_name_or_path"),Hjt.forEach(t),P9o=r(ox,":"),ox.forEach(t),B9o=i(xa),z=n(xa,"UL",{});var Q=s(z);wp=n(Q,"LI",{});var SOe=s(wp);f2e=n(SOe,"STRONG",{});var Jjt=s(f2e);I9o=r(Jjt,"beit"),Jjt.forEach(t),N9o=r(SOe," \u2014 "),xX=n(SOe,"A",{href:!0});var Yjt=s(xX);q9o=r(Yjt,"BeitFeatureExtractor"),Yjt.forEach(t),D9o=r(SOe," (BEiT model)"),SOe.forEach(t),j9o=i(Q),Ap=n(Q,"LI",{});var ROe=s(Ap);g2e=n(ROe,"STRONG",{});var Zjt=s(g2e);G9o=r(Zjt,"clip"),Zjt.forEach(t),O9o=r(ROe," \u2014 "),$X=n(ROe,"A",{href:!0});var Kjt=s($X);V9o=r(Kjt,"CLIPFeatureExtractor"),Kjt.forEach(t),X9o=r(ROe," (CLIP model)"),ROe.forEach(t),z9o=i(Q),Lp=n(Q,"LI",{});var POe=s(Lp);h2e=n(POe,"STRONG",{});var eGt=s(h2e);Q9o=r(eGt,"clipseg"),eGt.forEach(t),W9o=r(POe," \u2014 "),kX=n(POe,"A",{href:!0});var oGt=s(kX);U9o=r(oGt,"ViTFeatureExtractor"),oGt.forEach(t),H9o=r(POe," (CLIPSeg model)"),POe.forEach(t),J9o=i(Q),yp=n(Q,"LI",{});var BOe=s(yp);u2e=n(BOe,"STRONG",{});var rGt=s(u2e);Y9o=r(rGt,"conditional_detr"),rGt.forEach(t),Z9o=r(BOe," \u2014 "),SX=n(BOe,"A",{href:!0});var tGt=s(SX);K9o=r(tGt,"ConditionalDetrFeatureExtractor"),tGt.forEach(t),exo=r(BOe," (Conditional DETR model)"),BOe.forEach(t),oxo=i(Q),xp=n(Q,"LI",{});var IOe=s(xp);p2e=n(IOe,"STRONG",{});var aGt=s(p2e);rxo=r(aGt,"convnext"),aGt.forEach(t),txo=r(IOe," \u2014 "),RX=n(IOe,"A",{href:!0});var nGt=s(RX);axo=r(nGt,"ConvNextFeatureExtractor"),nGt.forEach(t),nxo=r(IOe," (ConvNeXT model)"),IOe.forEach(t),sxo=i(Q),$p=n(Q,"LI",{});var NOe=s($p);_2e=n(NOe,"STRONG",{});var sGt=s(_2e);lxo=r(sGt,"cvt"),sGt.forEach(t),ixo=r(NOe," \u2014 "),PX=n(NOe,"A",{href:!0});var lGt=s(PX);dxo=r(lGt,"ConvNextFeatureExtractor"),lGt.forEach(t),mxo=r(NOe," (CvT model)"),NOe.forEach(t),cxo=i(Q),kp=n(Q,"LI",{});var qOe=s(kp);b2e=n(qOe,"STRONG",{});var iGt=s(b2e);fxo=r(iGt,"data2vec-audio"),iGt.forEach(t),gxo=r(qOe," \u2014 "),BX=n(qOe,"A",{href:!0});var dGt=s(BX);hxo=r(dGt,"Wav2Vec2FeatureExtractor"),dGt.forEach(t),uxo=r(qOe," (Data2VecAudio model)"),qOe.forEach(t),pxo=i(Q),Sp=n(Q,"LI",{});var DOe=s(Sp);v2e=n(DOe,"STRONG",{});var mGt=s(v2e);_xo=r(mGt,"data2vec-vision"),mGt.forEach(t),bxo=r(DOe," \u2014 "),IX=n(DOe,"A",{href:!0});var cGt=s(IX);vxo=r(cGt,"BeitFeatureExtractor"),cGt.forEach(t),Fxo=r(DOe," (Data2VecVision model)"),DOe.forEach(t),Txo=i(Q),Rp=n(Q,"LI",{});var jOe=s(Rp);F2e=n(jOe,"STRONG",{});var fGt=s(F2e);Mxo=r(fGt,"deformable_detr"),fGt.forEach(t),Exo=r(jOe," \u2014 "),NX=n(jOe,"A",{href:!0});var gGt=s(NX);Cxo=r(gGt,"DeformableDetrFeatureExtractor"),gGt.forEach(t),wxo=r(jOe," (Deformable DETR model)"),jOe.forEach(t),Axo=i(Q),Pp=n(Q,"LI",{});var GOe=s(Pp);T2e=n(GOe,"STRONG",{});var hGt=s(T2e);Lxo=r(hGt,"deit"),hGt.forEach(t),yxo=r(GOe," \u2014 "),qX=n(GOe,"A",{href:!0});var uGt=s(qX);xxo=r(uGt,"DeiTFeatureExtractor"),uGt.forEach(t),$xo=r(GOe," (DeiT model)"),GOe.forEach(t),kxo=i(Q),Bp=n(Q,"LI",{});var OOe=s(Bp);M2e=n(OOe,"STRONG",{});var pGt=s(M2e);Sxo=r(pGt,"detr"),pGt.forEach(t),Rxo=r(OOe," \u2014 "),DX=n(OOe,"A",{href:!0});var _Gt=s(DX);Pxo=r(_Gt,"DetrFeatureExtractor"),_Gt.forEach(t),Bxo=r(OOe," (DETR model)"),OOe.forEach(t),Ixo=i(Q),Ip=n(Q,"LI",{});var VOe=s(Ip);E2e=n(VOe,"STRONG",{});var bGt=s(E2e);Nxo=r(bGt,"donut-swin"),bGt.forEach(t),qxo=r(VOe," \u2014 "),jX=n(VOe,"A",{href:!0});var vGt=s(jX);Dxo=r(vGt,"DonutFeatureExtractor"),vGt.forEach(t),jxo=r(VOe," (DonutSwin model)"),VOe.forEach(t),Gxo=i(Q),Np=n(Q,"LI",{});var XOe=s(Np);C2e=n(XOe,"STRONG",{});var FGt=s(C2e);Oxo=r(FGt,"dpt"),FGt.forEach(t),Vxo=r(XOe," \u2014 "),GX=n(XOe,"A",{href:!0});var TGt=s(GX);Xxo=r(TGt,"DPTFeatureExtractor"),TGt.forEach(t),zxo=r(XOe," (DPT model)"),XOe.forEach(t),Qxo=i(Q),qp=n(Q,"LI",{});var zOe=s(qp);w2e=n(zOe,"STRONG",{});var MGt=s(w2e);Wxo=r(MGt,"flava"),MGt.forEach(t),Uxo=r(zOe," \u2014 "),OX=n(zOe,"A",{href:!0});var EGt=s(OX);Hxo=r(EGt,"FlavaFeatureExtractor"),EGt.forEach(t),Jxo=r(zOe," (FLAVA model)"),zOe.forEach(t),Yxo=i(Q),Dp=n(Q,"LI",{});var QOe=s(Dp);A2e=n(QOe,"STRONG",{});var CGt=s(A2e);Zxo=r(CGt,"glpn"),CGt.forEach(t),Kxo=r(QOe," \u2014 "),VX=n(QOe,"A",{href:!0});var wGt=s(VX);e$o=r(wGt,"GLPNFeatureExtractor"),wGt.forEach(t),o$o=r(QOe," (GLPN model)"),QOe.forEach(t),r$o=i(Q),jp=n(Q,"LI",{});var WOe=s(jp);L2e=n(WOe,"STRONG",{});var AGt=s(L2e);t$o=r(AGt,"groupvit"),AGt.forEach(t),a$o=r(WOe," \u2014 "),XX=n(WOe,"A",{href:!0});var LGt=s(XX);n$o=r(LGt,"CLIPFeatureExtractor"),LGt.forEach(t),s$o=r(WOe," (GroupViT model)"),WOe.forEach(t),l$o=i(Q),Gp=n(Q,"LI",{});var UOe=s(Gp);y2e=n(UOe,"STRONG",{});var yGt=s(y2e);i$o=r(yGt,"hubert"),yGt.forEach(t),d$o=r(UOe," \u2014 "),zX=n(UOe,"A",{href:!0});var xGt=s(zX);m$o=r(xGt,"Wav2Vec2FeatureExtractor"),xGt.forEach(t),c$o=r(UOe," (Hubert model)"),UOe.forEach(t),f$o=i(Q),Op=n(Q,"LI",{});var HOe=s(Op);x2e=n(HOe,"STRONG",{});var $Gt=s(x2e);g$o=r($Gt,"imagegpt"),$Gt.forEach(t),h$o=r(HOe," \u2014 "),QX=n(HOe,"A",{href:!0});var kGt=s(QX);u$o=r(kGt,"ImageGPTFeatureExtractor"),kGt.forEach(t),p$o=r(HOe," (ImageGPT model)"),HOe.forEach(t),_$o=i(Q),Vp=n(Q,"LI",{});var JOe=s(Vp);$2e=n(JOe,"STRONG",{});var SGt=s($2e);b$o=r(SGt,"layoutlmv2"),SGt.forEach(t),v$o=r(JOe," \u2014 "),WX=n(JOe,"A",{href:!0});var RGt=s(WX);F$o=r(RGt,"LayoutLMv2FeatureExtractor"),RGt.forEach(t),T$o=r(JOe," (LayoutLMv2 model)"),JOe.forEach(t),M$o=i(Q),Xp=n(Q,"LI",{});var YOe=s(Xp);k2e=n(YOe,"STRONG",{});var PGt=s(k2e);E$o=r(PGt,"layoutlmv3"),PGt.forEach(t),C$o=r(YOe," \u2014 "),UX=n(YOe,"A",{href:!0});var BGt=s(UX);w$o=r(BGt,"LayoutLMv3FeatureExtractor"),BGt.forEach(t),A$o=r(YOe," (LayoutLMv3 model)"),YOe.forEach(t),L$o=i(Q),zp=n(Q,"LI",{});var ZOe=s(zp);S2e=n(ZOe,"STRONG",{});var IGt=s(S2e);y$o=r(IGt,"levit"),IGt.forEach(t),x$o=r(ZOe," \u2014 "),HX=n(ZOe,"A",{href:!0});var NGt=s(HX);$$o=r(NGt,"LevitFeatureExtractor"),NGt.forEach(t),k$o=r(ZOe," (LeViT model)"),ZOe.forEach(t),S$o=i(Q),Qp=n(Q,"LI",{});var KOe=s(Qp);R2e=n(KOe,"STRONG",{});var qGt=s(R2e);R$o=r(qGt,"maskformer"),qGt.forEach(t),P$o=r(KOe," \u2014 "),JX=n(KOe,"A",{href:!0});var DGt=s(JX);B$o=r(DGt,"MaskFormerFeatureExtractor"),DGt.forEach(t),I$o=r(KOe," (MaskFormer model)"),KOe.forEach(t),N$o=i(Q),Wp=n(Q,"LI",{});var eVe=s(Wp);P2e=n(eVe,"STRONG",{});var jGt=s(P2e);q$o=r(jGt,"mctct"),jGt.forEach(t),D$o=r(eVe," \u2014 "),YX=n(eVe,"A",{href:!0});var GGt=s(YX);j$o=r(GGt,"MCTCTFeatureExtractor"),GGt.forEach(t),G$o=r(eVe," (M-CTC-T model)"),eVe.forEach(t),O$o=i(Q),Up=n(Q,"LI",{});var oVe=s(Up);B2e=n(oVe,"STRONG",{});var OGt=s(B2e);V$o=r(OGt,"mobilevit"),OGt.forEach(t),X$o=r(oVe," \u2014 "),ZX=n(oVe,"A",{href:!0});var VGt=s(ZX);z$o=r(VGt,"MobileViTFeatureExtractor"),VGt.forEach(t),Q$o=r(oVe," (MobileViT model)"),oVe.forEach(t),W$o=i(Q),Hp=n(Q,"LI",{});var rVe=s(Hp);I2e=n(rVe,"STRONG",{});var XGt=s(I2e);U$o=r(XGt,"owlvit"),XGt.forEach(t),H$o=r(rVe," \u2014 "),KX=n(rVe,"A",{href:!0});var zGt=s(KX);J$o=r(zGt,"OwlViTFeatureExtractor"),zGt.forEach(t),Y$o=r(rVe," (OWL-ViT model)"),rVe.forEach(t),Z$o=i(Q),Jp=n(Q,"LI",{});var tVe=s(Jp);N2e=n(tVe,"STRONG",{});var QGt=s(N2e);K$o=r(QGt,"perceiver"),QGt.forEach(t),eko=r(tVe," \u2014 "),ez=n(tVe,"A",{href:!0});var WGt=s(ez);oko=r(WGt,"PerceiverFeatureExtractor"),WGt.forEach(t),rko=r(tVe," (Perceiver model)"),tVe.forEach(t),tko=i(Q),Yp=n(Q,"LI",{});var aVe=s(Yp);q2e=n(aVe,"STRONG",{});var UGt=s(q2e);ako=r(UGt,"poolformer"),UGt.forEach(t),nko=r(aVe," \u2014 "),oz=n(aVe,"A",{href:!0});var HGt=s(oz);sko=r(HGt,"PoolFormerFeatureExtractor"),HGt.forEach(t),lko=r(aVe," (PoolFormer model)"),aVe.forEach(t),iko=i(Q),Zp=n(Q,"LI",{});var nVe=s(Zp);D2e=n(nVe,"STRONG",{});var JGt=s(D2e);dko=r(JGt,"regnet"),JGt.forEach(t),mko=r(nVe," \u2014 "),rz=n(nVe,"A",{href:!0});var YGt=s(rz);cko=r(YGt,"ConvNextFeatureExtractor"),YGt.forEach(t),fko=r(nVe," (RegNet model)"),nVe.forEach(t),gko=i(Q),Kp=n(Q,"LI",{});var sVe=s(Kp);j2e=n(sVe,"STRONG",{});var ZGt=s(j2e);hko=r(ZGt,"resnet"),ZGt.forEach(t),uko=r(sVe," \u2014 "),tz=n(sVe,"A",{href:!0});var KGt=s(tz);pko=r(KGt,"ConvNextFeatureExtractor"),KGt.forEach(t),_ko=r(sVe," (ResNet model)"),sVe.forEach(t),bko=i(Q),e_=n(Q,"LI",{});var lVe=s(e_);G2e=n(lVe,"STRONG",{});var eOt=s(G2e);vko=r(eOt,"segformer"),eOt.forEach(t),Fko=r(lVe," \u2014 "),az=n(lVe,"A",{href:!0});var oOt=s(az);Tko=r(oOt,"SegformerFeatureExtractor"),oOt.forEach(t),Mko=r(lVe," (SegFormer model)"),lVe.forEach(t),Eko=i(Q),o_=n(Q,"LI",{});var iVe=s(o_);O2e=n(iVe,"STRONG",{});var rOt=s(O2e);Cko=r(rOt,"speech_to_text"),rOt.forEach(t),wko=r(iVe," \u2014 "),nz=n(iVe,"A",{href:!0});var tOt=s(nz);Ako=r(tOt,"Speech2TextFeatureExtractor"),tOt.forEach(t),Lko=r(iVe," (Speech2Text model)"),iVe.forEach(t),yko=i(Q),r_=n(Q,"LI",{});var dVe=s(r_);V2e=n(dVe,"STRONG",{});var aOt=s(V2e);xko=r(aOt,"swin"),aOt.forEach(t),$ko=r(dVe," \u2014 "),sz=n(dVe,"A",{href:!0});var nOt=s(sz);kko=r(nOt,"ViTFeatureExtractor"),nOt.forEach(t),Sko=r(dVe," (Swin Transformer model)"),dVe.forEach(t),Rko=i(Q),t_=n(Q,"LI",{});var mVe=s(t_);X2e=n(mVe,"STRONG",{});var sOt=s(X2e);Pko=r(sOt,"swinv2"),sOt.forEach(t),Bko=r(mVe," \u2014 "),lz=n(mVe,"A",{href:!0});var lOt=s(lz);Iko=r(lOt,"ViTFeatureExtractor"),lOt.forEach(t),Nko=r(mVe," (Swin Transformer V2 model)"),mVe.forEach(t),qko=i(Q),a_=n(Q,"LI",{});var cVe=s(a_);z2e=n(cVe,"STRONG",{});var iOt=s(z2e);Dko=r(iOt,"table-transformer"),iOt.forEach(t),jko=r(cVe," \u2014 "),iz=n(cVe,"A",{href:!0});var dOt=s(iz);Gko=r(dOt,"DetrFeatureExtractor"),dOt.forEach(t),Oko=r(cVe," (Table Transformer model)"),cVe.forEach(t),Vko=i(Q),n_=n(Q,"LI",{});var fVe=s(n_);Q2e=n(fVe,"STRONG",{});var mOt=s(Q2e);Xko=r(mOt,"van"),mOt.forEach(t),zko=r(fVe," \u2014 "),dz=n(fVe,"A",{href:!0});var cOt=s(dz);Qko=r(cOt,"ConvNextFeatureExtractor"),cOt.forEach(t),Wko=r(fVe," (VAN model)"),fVe.forEach(t),Uko=i(Q),s_=n(Q,"LI",{});var gVe=s(s_);W2e=n(gVe,"STRONG",{});var fOt=s(W2e);Hko=r(fOt,"videomae"),fOt.forEach(t),Jko=r(gVe," \u2014 "),mz=n(gVe,"A",{href:!0});var gOt=s(mz);Yko=r(gOt,"VideoMAEFeatureExtractor"),gOt.forEach(t),Zko=r(gVe," (VideoMAE model)"),gVe.forEach(t),Kko=i(Q),l_=n(Q,"LI",{});var hVe=s(l_);U2e=n(hVe,"STRONG",{});var hOt=s(U2e);eSo=r(hOt,"vilt"),hOt.forEach(t),oSo=r(hVe," \u2014 "),cz=n(hVe,"A",{href:!0});var uOt=s(cz);rSo=r(uOt,"ViltFeatureExtractor"),uOt.forEach(t),tSo=r(hVe," (ViLT model)"),hVe.forEach(t),aSo=i(Q),i_=n(Q,"LI",{});var uVe=s(i_);H2e=n(uVe,"STRONG",{});var pOt=s(H2e);nSo=r(pOt,"vit"),pOt.forEach(t),sSo=r(uVe," \u2014 "),fz=n(uVe,"A",{href:!0});var _Ot=s(fz);lSo=r(_Ot,"ViTFeatureExtractor"),_Ot.forEach(t),iSo=r(uVe," (ViT model)"),uVe.forEach(t),dSo=i(Q),d_=n(Q,"LI",{});var pVe=s(d_);J2e=n(pVe,"STRONG",{});var bOt=s(J2e);mSo=r(bOt,"vit_mae"),bOt.forEach(t),cSo=r(pVe," \u2014 "),gz=n(pVe,"A",{href:!0});var vOt=s(gz);fSo=r(vOt,"ViTFeatureExtractor"),vOt.forEach(t),gSo=r(pVe," (ViTMAE model)"),pVe.forEach(t),hSo=i(Q),m_=n(Q,"LI",{});var _Ve=s(m_);Y2e=n(_Ve,"STRONG",{});var FOt=s(Y2e);uSo=r(FOt,"vit_msn"),FOt.forEach(t),pSo=r(_Ve," \u2014 "),hz=n(_Ve,"A",{href:!0});var TOt=s(hz);_So=r(TOt,"ViTFeatureExtractor"),TOt.forEach(t),bSo=r(_Ve," (ViTMSN model)"),_Ve.forEach(t),vSo=i(Q),c_=n(Q,"LI",{});var bVe=s(c_);Z2e=n(bVe,"STRONG",{});var MOt=s(Z2e);FSo=r(MOt,"wav2vec2"),MOt.forEach(t),TSo=r(bVe," \u2014 "),uz=n(bVe,"A",{href:!0});var EOt=s(uz);MSo=r(EOt,"Wav2Vec2FeatureExtractor"),EOt.forEach(t),ESo=r(bVe," (Wav2Vec2 model)"),bVe.forEach(t),CSo=i(Q),f_=n(Q,"LI",{});var vVe=s(f_);K2e=n(vVe,"STRONG",{});var COt=s(K2e);wSo=r(COt,"wav2vec2-conformer"),COt.forEach(t),ASo=r(vVe," \u2014 "),pz=n(vVe,"A",{href:!0});var wOt=s(pz);LSo=r(wOt,"Wav2Vec2FeatureExtractor"),wOt.forEach(t),ySo=r(vVe," (Wav2Vec2-Conformer model)"),vVe.forEach(t),xSo=i(Q),g_=n(Q,"LI",{});var FVe=s(g_);ebe=n(FVe,"STRONG",{});var AOt=s(ebe);$So=r(AOt,"whisper"),AOt.forEach(t),kSo=r(FVe," \u2014 "),_z=n(FVe,"A",{href:!0});var LOt=s(_z);SSo=r(LOt,"WhisperFeatureExtractor"),LOt.forEach(t),RSo=r(FVe," (Whisper model)"),FVe.forEach(t),PSo=i(Q),h_=n(Q,"LI",{});var TVe=s(h_);obe=n(TVe,"STRONG",{});var yOt=s(obe);BSo=r(yOt,"xclip"),yOt.forEach(t),ISo=r(TVe," \u2014 "),bz=n(TVe,"A",{href:!0});var xOt=s(bz);NSo=r(xOt,"CLIPFeatureExtractor"),xOt.forEach(t),qSo=r(TVe," (X-CLIP model)"),TVe.forEach(t),DSo=i(Q),u_=n(Q,"LI",{});var MVe=s(u_);rbe=n(MVe,"STRONG",{});var $Ot=s(rbe);jSo=r($Ot,"yolos"),$Ot.forEach(t),GSo=r(MVe," \u2014 "),vz=n(MVe,"A",{href:!0});var kOt=s(vz);OSo=r(kOt,"YolosFeatureExtractor"),kOt.forEach(t),VSo=r(MVe," (YOLOS model)"),MVe.forEach(t),Q.forEach(t),XSo=i(xa),T(p_.$$.fragment,xa),zSo=i(xa),T(__.$$.fragment,xa),xa.forEach(t),QSo=i(Vl),b_=n(Vl,"DIV",{class:!0});var Xdo=s(b_);T(kk.$$.fragment,Xdo),WSo=i(Xdo),tbe=n(Xdo,"P",{});var SOt=s(tbe);USo=r(SOt,"Register a new feature extractor for this class."),SOt.forEach(t),Xdo.forEach(t),Vl.forEach(t),Llo=i(c),qd=n(c,"H2",{class:!0});var zdo=s(qd);v_=n(zdo,"A",{id:!0,class:!0,href:!0});var ROt=s(v_);abe=n(ROt,"SPAN",{});var POt=s(abe);T(Sk.$$.fragment,POt),POt.forEach(t),ROt.forEach(t),HSo=i(zdo),nbe=n(zdo,"SPAN",{});var BOt=s(nbe);JSo=r(BOt,"AutoImageProcessor"),BOt.forEach(t),zdo.forEach(t),ylo=i(c),qo=n(c,"DIV",{class:!0});var Xl=s(qo);T(Rk.$$.fragment,Xl),YSo=i(Xl),Pk=n(Xl,"P",{});var Qdo=s(Pk);ZSo=r(Qdo,`This is a generic image processor class that will be instantiated as one of the image processor classes of the
library when created with the `),Fz=n(Qdo,"A",{href:!0});var IOt=s(Fz);KSo=r(IOt,"AutoImageProcessor.from_pretrained()"),IOt.forEach(t),eRo=r(Qdo," class method."),Qdo.forEach(t),oRo=i(Xl),Bk=n(Xl,"P",{});var Wdo=s(Bk);rRo=r(Wdo,"This class cannot be instantiated directly using "),sbe=n(Wdo,"CODE",{});var NOt=s(sbe);tRo=r(NOt,"__init__()"),NOt.forEach(t),aRo=r(Wdo," (throws an error)."),Wdo.forEach(t),nRo=i(Xl),oo=n(Xl,"DIV",{class:!0});var $a=s(oo);T(Ik.$$.fragment,$a),sRo=i($a),lbe=n($a,"P",{});var qOt=s(lbe);lRo=r(qOt,"Instantiate one of the image processor classes of the library from a pretrained model vocabulary."),qOt.forEach(t),iRo=i($a),cn=n($a,"P",{});var rx=s(cn);dRo=r(rx,"The image processor class to instantiate is selected based on the "),ibe=n(rx,"CODE",{});var DOt=s(ibe);mRo=r(DOt,"model_type"),DOt.forEach(t),cRo=r(rx,` property of the config object
(either passed as an argument or loaded from `),dbe=n(rx,"CODE",{});var jOt=s(dbe);fRo=r(jOt,"pretrained_model_name_or_path"),jOt.forEach(t),gRo=r(rx,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),mbe=n(rx,"CODE",{});var GOt=s(mbe);hRo=r(GOt,"pretrained_model_name_or_path"),GOt.forEach(t),uRo=r(rx,":"),rx.forEach(t),pRo=i($a),re=n($a,"UL",{});var ae=s(re);F_=n(ae,"LI",{});var EVe=s(F_);cbe=n(EVe,"STRONG",{});var OOt=s(cbe);_Ro=r(OOt,"beit"),OOt.forEach(t),bRo=r(EVe," \u2014 "),Tz=n(EVe,"A",{href:!0});var VOt=s(Tz);vRo=r(VOt,"BeitImageProcessor"),VOt.forEach(t),FRo=r(EVe," (BEiT model)"),EVe.forEach(t),TRo=i(ae),T_=n(ae,"LI",{});var CVe=s(T_);fbe=n(CVe,"STRONG",{});var XOt=s(fbe);MRo=r(XOt,"clip"),XOt.forEach(t),ERo=r(CVe," \u2014 "),Mz=n(CVe,"A",{href:!0});var zOt=s(Mz);CRo=r(zOt,"CLIPImageProcessor"),zOt.forEach(t),wRo=r(CVe," (CLIP model)"),CVe.forEach(t),ARo=i(ae),M_=n(ae,"LI",{});var wVe=s(M_);gbe=n(wVe,"STRONG",{});var QOt=s(gbe);LRo=r(QOt,"convnext"),QOt.forEach(t),yRo=r(wVe," \u2014 "),Ez=n(wVe,"A",{href:!0});var WOt=s(Ez);xRo=r(WOt,"ConvNextImageProcessor"),WOt.forEach(t),$Ro=r(wVe," (ConvNeXT model)"),wVe.forEach(t),kRo=i(ae),E_=n(ae,"LI",{});var AVe=s(E_);hbe=n(AVe,"STRONG",{});var UOt=s(hbe);SRo=r(UOt,"cvt"),UOt.forEach(t),RRo=r(AVe," \u2014 "),Cz=n(AVe,"A",{href:!0});var HOt=s(Cz);PRo=r(HOt,"ConvNextImageProcessor"),HOt.forEach(t),BRo=r(AVe," (CvT model)"),AVe.forEach(t),IRo=i(ae),C_=n(ae,"LI",{});var LVe=s(C_);ube=n(LVe,"STRONG",{});var JOt=s(ube);NRo=r(JOt,"data2vec-vision"),JOt.forEach(t),qRo=r(LVe," \u2014 "),wz=n(LVe,"A",{href:!0});var YOt=s(wz);DRo=r(YOt,"BeitImageProcessor"),YOt.forEach(t),jRo=r(LVe," (Data2VecVision model)"),LVe.forEach(t),GRo=i(ae),w_=n(ae,"LI",{});var yVe=s(w_);pbe=n(yVe,"STRONG",{});var ZOt=s(pbe);ORo=r(ZOt,"deit"),ZOt.forEach(t),VRo=r(yVe," \u2014 "),Az=n(yVe,"A",{href:!0});var KOt=s(Az);XRo=r(KOt,"DeiTImageProcessor"),KOt.forEach(t),zRo=r(yVe," (DeiT model)"),yVe.forEach(t),QRo=i(ae),A_=n(ae,"LI",{});var xVe=s(A_);_be=n(xVe,"STRONG",{});var eVt=s(_be);WRo=r(eVt,"dpt"),eVt.forEach(t),URo=r(xVe," \u2014 "),Lz=n(xVe,"A",{href:!0});var oVt=s(Lz);HRo=r(oVt,"DPTImageProcessor"),oVt.forEach(t),JRo=r(xVe," (DPT model)"),xVe.forEach(t),YRo=i(ae),L_=n(ae,"LI",{});var $Ve=s(L_);bbe=n($Ve,"STRONG",{});var rVt=s(bbe);ZRo=r(rVt,"flava"),rVt.forEach(t),KRo=r($Ve," \u2014 "),yz=n($Ve,"A",{href:!0});var tVt=s(yz);ePo=r(tVt,"FlavaImageProcessor"),tVt.forEach(t),oPo=r($Ve," (FLAVA model)"),$Ve.forEach(t),rPo=i(ae),y_=n(ae,"LI",{});var kVe=s(y_);vbe=n(kVe,"STRONG",{});var aVt=s(vbe);tPo=r(aVt,"glpn"),aVt.forEach(t),aPo=r(kVe," \u2014 "),xz=n(kVe,"A",{href:!0});var nVt=s(xz);nPo=r(nVt,"GLPNImageProcessor"),nVt.forEach(t),sPo=r(kVe," (GLPN model)"),kVe.forEach(t),lPo=i(ae),x_=n(ae,"LI",{});var SVe=s(x_);Fbe=n(SVe,"STRONG",{});var sVt=s(Fbe);iPo=r(sVt,"groupvit"),sVt.forEach(t),dPo=r(SVe," \u2014 "),$z=n(SVe,"A",{href:!0});var lVt=s($z);mPo=r(lVt,"CLIPImageProcessor"),lVt.forEach(t),cPo=r(SVe," (GroupViT model)"),SVe.forEach(t),fPo=i(ae),$_=n(ae,"LI",{});var RVe=s($_);Tbe=n(RVe,"STRONG",{});var iVt=s(Tbe);gPo=r(iVt,"imagegpt"),iVt.forEach(t),hPo=r(RVe," \u2014 "),kz=n(RVe,"A",{href:!0});var dVt=s(kz);uPo=r(dVt,"ImageGPTImageProcessor"),dVt.forEach(t),pPo=r(RVe," (ImageGPT model)"),RVe.forEach(t),_Po=i(ae),k_=n(ae,"LI",{});var PVe=s(k_);Mbe=n(PVe,"STRONG",{});var mVt=s(Mbe);bPo=r(mVt,"layoutlmv2"),mVt.forEach(t),vPo=r(PVe," \u2014 "),Sz=n(PVe,"A",{href:!0});var cVt=s(Sz);FPo=r(cVt,"LayoutLMv2ImageProcessor"),cVt.forEach(t),TPo=r(PVe," (LayoutLMv2 model)"),PVe.forEach(t),MPo=i(ae),S_=n(ae,"LI",{});var BVe=s(S_);Ebe=n(BVe,"STRONG",{});var fVt=s(Ebe);EPo=r(fVt,"layoutlmv3"),fVt.forEach(t),CPo=r(BVe," \u2014 "),Rz=n(BVe,"A",{href:!0});var gVt=s(Rz);wPo=r(gVt,"LayoutLMv3ImageProcessor"),gVt.forEach(t),APo=r(BVe," (LayoutLMv3 model)"),BVe.forEach(t),LPo=i(ae),R_=n(ae,"LI",{});var IVe=s(R_);Cbe=n(IVe,"STRONG",{});var hVt=s(Cbe);yPo=r(hVt,"levit"),hVt.forEach(t),xPo=r(IVe," \u2014 "),Pz=n(IVe,"A",{href:!0});var uVt=s(Pz);$Po=r(uVt,"LevitImageProcessor"),uVt.forEach(t),kPo=r(IVe," (LeViT model)"),IVe.forEach(t),SPo=i(ae),P_=n(ae,"LI",{});var NVe=s(P_);wbe=n(NVe,"STRONG",{});var pVt=s(wbe);RPo=r(pVt,"mobilevit"),pVt.forEach(t),PPo=r(NVe," \u2014 "),Bz=n(NVe,"A",{href:!0});var _Vt=s(Bz);BPo=r(_Vt,"MobileViTImageProcessor"),_Vt.forEach(t),IPo=r(NVe," (MobileViT model)"),NVe.forEach(t),NPo=i(ae),B_=n(ae,"LI",{});var qVe=s(B_);Abe=n(qVe,"STRONG",{});var bVt=s(Abe);qPo=r(bVt,"perceiver"),bVt.forEach(t),DPo=r(qVe," \u2014 "),Iz=n(qVe,"A",{href:!0});var vVt=s(Iz);jPo=r(vVt,"PerceiverImageProcessor"),vVt.forEach(t),GPo=r(qVe," (Perceiver model)"),qVe.forEach(t),OPo=i(ae),I_=n(ae,"LI",{});var DVe=s(I_);Lbe=n(DVe,"STRONG",{});var FVt=s(Lbe);VPo=r(FVt,"poolformer"),FVt.forEach(t),XPo=r(DVe," \u2014 "),Nz=n(DVe,"A",{href:!0});var TVt=s(Nz);zPo=r(TVt,"PoolFormerImageProcessor"),TVt.forEach(t),QPo=r(DVe," (PoolFormer model)"),DVe.forEach(t),WPo=i(ae),N_=n(ae,"LI",{});var jVe=s(N_);ybe=n(jVe,"STRONG",{});var MVt=s(ybe);UPo=r(MVt,"regnet"),MVt.forEach(t),HPo=r(jVe," \u2014 "),qz=n(jVe,"A",{href:!0});var EVt=s(qz);JPo=r(EVt,"ConvNextImageProcessor"),EVt.forEach(t),YPo=r(jVe," (RegNet model)"),jVe.forEach(t),ZPo=i(ae),q_=n(ae,"LI",{});var GVe=s(q_);xbe=n(GVe,"STRONG",{});var CVt=s(xbe);KPo=r(CVt,"resnet"),CVt.forEach(t),eBo=r(GVe," \u2014 "),Dz=n(GVe,"A",{href:!0});var wVt=s(Dz);oBo=r(wVt,"ConvNextImageProcessor"),wVt.forEach(t),rBo=r(GVe," (ResNet model)"),GVe.forEach(t),tBo=i(ae),D_=n(ae,"LI",{});var OVe=s(D_);$be=n(OVe,"STRONG",{});var AVt=s($be);aBo=r(AVt,"segformer"),AVt.forEach(t),nBo=r(OVe," \u2014 "),jz=n(OVe,"A",{href:!0});var LVt=s(jz);sBo=r(LVt,"SegformerImageProcessor"),LVt.forEach(t),lBo=r(OVe," (SegFormer model)"),OVe.forEach(t),iBo=i(ae),j_=n(ae,"LI",{});var VVe=s(j_);kbe=n(VVe,"STRONG",{});var yVt=s(kbe);dBo=r(yVt,"swin"),yVt.forEach(t),mBo=r(VVe," \u2014 "),Gz=n(VVe,"A",{href:!0});var xVt=s(Gz);cBo=r(xVt,"ViTImageProcessor"),xVt.forEach(t),fBo=r(VVe," (Swin Transformer model)"),VVe.forEach(t),gBo=i(ae),G_=n(ae,"LI",{});var XVe=s(G_);Sbe=n(XVe,"STRONG",{});var $Vt=s(Sbe);hBo=r($Vt,"swinv2"),$Vt.forEach(t),uBo=r(XVe," \u2014 "),Oz=n(XVe,"A",{href:!0});var kVt=s(Oz);pBo=r(kVt,"ViTImageProcessor"),kVt.forEach(t),_Bo=r(XVe," (Swin Transformer V2 model)"),XVe.forEach(t),bBo=i(ae),O_=n(ae,"LI",{});var zVe=s(O_);Rbe=n(zVe,"STRONG",{});var SVt=s(Rbe);vBo=r(SVt,"van"),SVt.forEach(t),FBo=r(zVe," \u2014 "),Vz=n(zVe,"A",{href:!0});var RVt=s(Vz);TBo=r(RVt,"ConvNextImageProcessor"),RVt.forEach(t),MBo=r(zVe," (VAN model)"),zVe.forEach(t),EBo=i(ae),V_=n(ae,"LI",{});var QVe=s(V_);Pbe=n(QVe,"STRONG",{});var PVt=s(Pbe);CBo=r(PVt,"videomae"),PVt.forEach(t),wBo=r(QVe," \u2014 "),Xz=n(QVe,"A",{href:!0});var BVt=s(Xz);ABo=r(BVt,"VideoMAEImageProcessor"),BVt.forEach(t),LBo=r(QVe," (VideoMAE model)"),QVe.forEach(t),yBo=i(ae),X_=n(ae,"LI",{});var WVe=s(X_);Bbe=n(WVe,"STRONG",{});var IVt=s(Bbe);xBo=r(IVt,"vilt"),IVt.forEach(t),$Bo=r(WVe," \u2014 "),zz=n(WVe,"A",{href:!0});var NVt=s(zz);kBo=r(NVt,"ViltImageProcessor"),NVt.forEach(t),SBo=r(WVe," (ViLT model)"),WVe.forEach(t),RBo=i(ae),z_=n(ae,"LI",{});var UVe=s(z_);Ibe=n(UVe,"STRONG",{});var qVt=s(Ibe);PBo=r(qVt,"vit"),qVt.forEach(t),BBo=r(UVe," \u2014 "),Qz=n(UVe,"A",{href:!0});var DVt=s(Qz);IBo=r(DVt,"ViTImageProcessor"),DVt.forEach(t),NBo=r(UVe," (ViT model)"),UVe.forEach(t),qBo=i(ae),Q_=n(ae,"LI",{});var HVe=s(Q_);Nbe=n(HVe,"STRONG",{});var jVt=s(Nbe);DBo=r(jVt,"vit_mae"),jVt.forEach(t),jBo=r(HVe," \u2014 "),Wz=n(HVe,"A",{href:!0});var GVt=s(Wz);GBo=r(GVt,"ViTImageProcessor"),GVt.forEach(t),OBo=r(HVe," (ViTMAE model)"),HVe.forEach(t),VBo=i(ae),W_=n(ae,"LI",{});var JVe=s(W_);qbe=n(JVe,"STRONG",{});var OVt=s(qbe);XBo=r(OVt,"vit_msn"),OVt.forEach(t),zBo=r(JVe," \u2014 "),Uz=n(JVe,"A",{href:!0});var VVt=s(Uz);QBo=r(VVt,"ViTImageProcessor"),VVt.forEach(t),WBo=r(JVe," (ViTMSN model)"),JVe.forEach(t),UBo=i(ae),U_=n(ae,"LI",{});var YVe=s(U_);Dbe=n(YVe,"STRONG",{});var XVt=s(Dbe);HBo=r(XVt,"xclip"),XVt.forEach(t),JBo=r(YVe," \u2014 "),Hz=n(YVe,"A",{href:!0});var zVt=s(Hz);YBo=r(zVt,"CLIPImageProcessor"),zVt.forEach(t),ZBo=r(YVe," (X-CLIP model)"),YVe.forEach(t),ae.forEach(t),KBo=i($a),T(H_.$$.fragment,$a),eIo=i($a),T(J_.$$.fragment,$a),$a.forEach(t),oIo=i(Xl),Y_=n(Xl,"DIV",{class:!0});var Udo=s(Y_);T(Nk.$$.fragment,Udo),rIo=i(Udo),jbe=n(Udo,"P",{});var QVt=s(jbe);tIo=r(QVt,"Register a new image processor for this class."),QVt.forEach(t),Udo.forEach(t),Xl.forEach(t),xlo=i(c),Dd=n(c,"H2",{class:!0});var Hdo=s(Dd);Z_=n(Hdo,"A",{id:!0,class:!0,href:!0});var WVt=s(Z_);Gbe=n(WVt,"SPAN",{});var UVt=s(Gbe);T(qk.$$.fragment,UVt),UVt.forEach(t),WVt.forEach(t),aIo=i(Hdo),Obe=n(Hdo,"SPAN",{});var HVt=s(Obe);nIo=r(HVt,"AutoProcessor"),HVt.forEach(t),Hdo.forEach(t),$lo=i(c),Do=n(c,"DIV",{class:!0});var zl=s(Do);T(Dk.$$.fragment,zl),sIo=i(zl),jk=n(zl,"P",{});var Jdo=s(jk);lIo=r(Jdo,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),Jz=n(Jdo,"A",{href:!0});var JVt=s(Jz);iIo=r(JVt,"AutoProcessor.from_pretrained()"),JVt.forEach(t),dIo=r(Jdo," class method."),Jdo.forEach(t),mIo=i(zl),Gk=n(zl,"P",{});var Ydo=s(Gk);cIo=r(Ydo,"This class cannot be instantiated directly using "),Vbe=n(Ydo,"CODE",{});var YVt=s(Vbe);fIo=r(YVt,"__init__()"),YVt.forEach(t),gIo=r(Ydo," (throws an error)."),Ydo.forEach(t),hIo=i(zl),ro=n(zl,"DIV",{class:!0});var ka=s(ro);T(Ok.$$.fragment,ka),uIo=i(ka),Xbe=n(ka,"P",{});var ZVt=s(Xbe);pIo=r(ZVt,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),ZVt.forEach(t),_Io=i(ka),jd=n(ka,"P",{});var nfe=s(jd);bIo=r(nfe,"The processor class to instantiate is selected based on the "),zbe=n(nfe,"CODE",{});var KVt=s(zbe);vIo=r(KVt,"model_type"),KVt.forEach(t),FIo=r(nfe,` property of the config object (either
passed as an argument or loaded from `),Qbe=n(nfe,"CODE",{});var eXt=s(Qbe);TIo=r(eXt,"pretrained_model_name_or_path"),eXt.forEach(t),MIo=r(nfe," if possible):"),nfe.forEach(t),EIo=i(ka),ie=n(ka,"UL",{});var ce=s(ie);K_=n(ce,"LI",{});var ZVe=s(K_);Wbe=n(ZVe,"STRONG",{});var oXt=s(Wbe);CIo=r(oXt,"clip"),oXt.forEach(t),wIo=r(ZVe," \u2014 "),Yz=n(ZVe,"A",{href:!0});var rXt=s(Yz);AIo=r(rXt,"CLIPProcessor"),rXt.forEach(t),LIo=r(ZVe," (CLIP model)"),ZVe.forEach(t),yIo=i(ce),e1=n(ce,"LI",{});var KVe=s(e1);Ube=n(KVe,"STRONG",{});var tXt=s(Ube);xIo=r(tXt,"clipseg"),tXt.forEach(t),$Io=r(KVe," \u2014 "),Zz=n(KVe,"A",{href:!0});var aXt=s(Zz);kIo=r(aXt,"CLIPSegProcessor"),aXt.forEach(t),SIo=r(KVe," (CLIPSeg model)"),KVe.forEach(t),RIo=i(ce),o1=n(ce,"LI",{});var eXe=s(o1);Hbe=n(eXe,"STRONG",{});var nXt=s(Hbe);PIo=r(nXt,"flava"),nXt.forEach(t),BIo=r(eXe," \u2014 "),Kz=n(eXe,"A",{href:!0});var sXt=s(Kz);IIo=r(sXt,"FlavaProcessor"),sXt.forEach(t),NIo=r(eXe," (FLAVA model)"),eXe.forEach(t),qIo=i(ce),r1=n(ce,"LI",{});var oXe=s(r1);Jbe=n(oXe,"STRONG",{});var lXt=s(Jbe);DIo=r(lXt,"groupvit"),lXt.forEach(t),jIo=r(oXe," \u2014 "),eQ=n(oXe,"A",{href:!0});var iXt=s(eQ);GIo=r(iXt,"CLIPProcessor"),iXt.forEach(t),OIo=r(oXe," (GroupViT model)"),oXe.forEach(t),VIo=i(ce),t1=n(ce,"LI",{});var rXe=s(t1);Ybe=n(rXe,"STRONG",{});var dXt=s(Ybe);XIo=r(dXt,"layoutlmv2"),dXt.forEach(t),zIo=r(rXe," \u2014 "),oQ=n(rXe,"A",{href:!0});var mXt=s(oQ);QIo=r(mXt,"LayoutLMv2Processor"),mXt.forEach(t),WIo=r(rXe," (LayoutLMv2 model)"),rXe.forEach(t),UIo=i(ce),a1=n(ce,"LI",{});var tXe=s(a1);Zbe=n(tXe,"STRONG",{});var cXt=s(Zbe);HIo=r(cXt,"layoutlmv3"),cXt.forEach(t),JIo=r(tXe," \u2014 "),rQ=n(tXe,"A",{href:!0});var fXt=s(rQ);YIo=r(fXt,"LayoutLMv3Processor"),fXt.forEach(t),ZIo=r(tXe," (LayoutLMv3 model)"),tXe.forEach(t),KIo=i(ce),n1=n(ce,"LI",{});var aXe=s(n1);Kbe=n(aXe,"STRONG",{});var gXt=s(Kbe);eNo=r(gXt,"layoutxlm"),gXt.forEach(t),oNo=r(aXe," \u2014 "),tQ=n(aXe,"A",{href:!0});var hXt=s(tQ);rNo=r(hXt,"LayoutXLMProcessor"),hXt.forEach(t),tNo=r(aXe," (LayoutXLM model)"),aXe.forEach(t),aNo=i(ce),s1=n(ce,"LI",{});var nXe=s(s1);eve=n(nXe,"STRONG",{});var uXt=s(eve);nNo=r(uXt,"markuplm"),uXt.forEach(t),sNo=r(nXe," \u2014 "),aQ=n(nXe,"A",{href:!0});var pXt=s(aQ);lNo=r(pXt,"MarkupLMProcessor"),pXt.forEach(t),iNo=r(nXe," (MarkupLM model)"),nXe.forEach(t),dNo=i(ce),l1=n(ce,"LI",{});var sXe=s(l1);ove=n(sXe,"STRONG",{});var _Xt=s(ove);mNo=r(_Xt,"owlvit"),_Xt.forEach(t),cNo=r(sXe," \u2014 "),nQ=n(sXe,"A",{href:!0});var bXt=s(nQ);fNo=r(bXt,"OwlViTProcessor"),bXt.forEach(t),gNo=r(sXe," (OWL-ViT model)"),sXe.forEach(t),hNo=i(ce),i1=n(ce,"LI",{});var lXe=s(i1);rve=n(lXe,"STRONG",{});var vXt=s(rve);uNo=r(vXt,"sew"),vXt.forEach(t),pNo=r(lXe," \u2014 "),sQ=n(lXe,"A",{href:!0});var FXt=s(sQ);_No=r(FXt,"Wav2Vec2Processor"),FXt.forEach(t),bNo=r(lXe," (SEW model)"),lXe.forEach(t),vNo=i(ce),d1=n(ce,"LI",{});var iXe=s(d1);tve=n(iXe,"STRONG",{});var TXt=s(tve);FNo=r(TXt,"sew-d"),TXt.forEach(t),TNo=r(iXe," \u2014 "),lQ=n(iXe,"A",{href:!0});var MXt=s(lQ);MNo=r(MXt,"Wav2Vec2Processor"),MXt.forEach(t),ENo=r(iXe," (SEW-D model)"),iXe.forEach(t),CNo=i(ce),m1=n(ce,"LI",{});var dXe=s(m1);ave=n(dXe,"STRONG",{});var EXt=s(ave);wNo=r(EXt,"speech_to_text"),EXt.forEach(t),ANo=r(dXe," \u2014 "),iQ=n(dXe,"A",{href:!0});var CXt=s(iQ);LNo=r(CXt,"Speech2TextProcessor"),CXt.forEach(t),yNo=r(dXe," (Speech2Text model)"),dXe.forEach(t),xNo=i(ce),c1=n(ce,"LI",{});var mXe=s(c1);nve=n(mXe,"STRONG",{});var wXt=s(nve);$No=r(wXt,"speech_to_text_2"),wXt.forEach(t),kNo=r(mXe," \u2014 "),dQ=n(mXe,"A",{href:!0});var AXt=s(dQ);SNo=r(AXt,"Speech2Text2Processor"),AXt.forEach(t),RNo=r(mXe," (Speech2Text2 model)"),mXe.forEach(t),PNo=i(ce),f1=n(ce,"LI",{});var cXe=s(f1);sve=n(cXe,"STRONG",{});var LXt=s(sve);BNo=r(LXt,"trocr"),LXt.forEach(t),INo=r(cXe," \u2014 "),mQ=n(cXe,"A",{href:!0});var yXt=s(mQ);NNo=r(yXt,"TrOCRProcessor"),yXt.forEach(t),qNo=r(cXe," (TrOCR model)"),cXe.forEach(t),DNo=i(ce),g1=n(ce,"LI",{});var fXe=s(g1);lve=n(fXe,"STRONG",{});var xXt=s(lve);jNo=r(xXt,"unispeech"),xXt.forEach(t),GNo=r(fXe," \u2014 "),cQ=n(fXe,"A",{href:!0});var $Xt=s(cQ);ONo=r($Xt,"Wav2Vec2Processor"),$Xt.forEach(t),VNo=r(fXe," (UniSpeech model)"),fXe.forEach(t),XNo=i(ce),h1=n(ce,"LI",{});var gXe=s(h1);ive=n(gXe,"STRONG",{});var kXt=s(ive);zNo=r(kXt,"unispeech-sat"),kXt.forEach(t),QNo=r(gXe," \u2014 "),fQ=n(gXe,"A",{href:!0});var SXt=s(fQ);WNo=r(SXt,"Wav2Vec2Processor"),SXt.forEach(t),UNo=r(gXe," (UniSpeechSat model)"),gXe.forEach(t),HNo=i(ce),u1=n(ce,"LI",{});var hXe=s(u1);dve=n(hXe,"STRONG",{});var RXt=s(dve);JNo=r(RXt,"vilt"),RXt.forEach(t),YNo=r(hXe," \u2014 "),gQ=n(hXe,"A",{href:!0});var PXt=s(gQ);ZNo=r(PXt,"ViltProcessor"),PXt.forEach(t),KNo=r(hXe," (ViLT model)"),hXe.forEach(t),eqo=i(ce),p1=n(ce,"LI",{});var uXe=s(p1);mve=n(uXe,"STRONG",{});var BXt=s(mve);oqo=r(BXt,"vision-text-dual-encoder"),BXt.forEach(t),rqo=r(uXe," \u2014 "),hQ=n(uXe,"A",{href:!0});var IXt=s(hQ);tqo=r(IXt,"VisionTextDualEncoderProcessor"),IXt.forEach(t),aqo=r(uXe," (VisionTextDualEncoder model)"),uXe.forEach(t),nqo=i(ce),_1=n(ce,"LI",{});var pXe=s(_1);cve=n(pXe,"STRONG",{});var NXt=s(cve);sqo=r(NXt,"wav2vec2"),NXt.forEach(t),lqo=r(pXe," \u2014 "),uQ=n(pXe,"A",{href:!0});var qXt=s(uQ);iqo=r(qXt,"Wav2Vec2Processor"),qXt.forEach(t),dqo=r(pXe," (Wav2Vec2 model)"),pXe.forEach(t),mqo=i(ce),b1=n(ce,"LI",{});var _Xe=s(b1);fve=n(_Xe,"STRONG",{});var DXt=s(fve);cqo=r(DXt,"wav2vec2-conformer"),DXt.forEach(t),fqo=r(_Xe," \u2014 "),pQ=n(_Xe,"A",{href:!0});var jXt=s(pQ);gqo=r(jXt,"Wav2Vec2Processor"),jXt.forEach(t),hqo=r(_Xe," (Wav2Vec2-Conformer model)"),_Xe.forEach(t),uqo=i(ce),v1=n(ce,"LI",{});var bXe=s(v1);gve=n(bXe,"STRONG",{});var GXt=s(gve);pqo=r(GXt,"wavlm"),GXt.forEach(t),_qo=r(bXe," \u2014 "),_Q=n(bXe,"A",{href:!0});var OXt=s(_Q);bqo=r(OXt,"Wav2Vec2Processor"),OXt.forEach(t),vqo=r(bXe," (WavLM model)"),bXe.forEach(t),Fqo=i(ce),F1=n(ce,"LI",{});var vXe=s(F1);hve=n(vXe,"STRONG",{});var VXt=s(hve);Tqo=r(VXt,"whisper"),VXt.forEach(t),Mqo=r(vXe," \u2014 "),bQ=n(vXe,"A",{href:!0});var XXt=s(bQ);Eqo=r(XXt,"WhisperProcessor"),XXt.forEach(t),Cqo=r(vXe," (Whisper model)"),vXe.forEach(t),wqo=i(ce),T1=n(ce,"LI",{});var FXe=s(T1);uve=n(FXe,"STRONG",{});var zXt=s(uve);Aqo=r(zXt,"xclip"),zXt.forEach(t),Lqo=r(FXe," \u2014 "),vQ=n(FXe,"A",{href:!0});var QXt=s(vQ);yqo=r(QXt,"XCLIPProcessor"),QXt.forEach(t),xqo=r(FXe," (X-CLIP model)"),FXe.forEach(t),ce.forEach(t),$qo=i(ka),T(M1.$$.fragment,ka),kqo=i(ka),T(E1.$$.fragment,ka),ka.forEach(t),Sqo=i(zl),C1=n(zl,"DIV",{class:!0});var Zdo=s(C1);T(Vk.$$.fragment,Zdo),Rqo=i(Zdo),pve=n(Zdo,"P",{});var WXt=s(pve);Pqo=r(WXt,"Register a new processor for this class."),WXt.forEach(t),Zdo.forEach(t),zl.forEach(t),klo=i(c),Gd=n(c,"H2",{class:!0});var Kdo=s(Gd);w1=n(Kdo,"A",{id:!0,class:!0,href:!0});var UXt=s(w1);_ve=n(UXt,"SPAN",{});var HXt=s(_ve);T(Xk.$$.fragment,HXt),HXt.forEach(t),UXt.forEach(t),Bqo=i(Kdo),bve=n(Kdo,"SPAN",{});var JXt=s(bve);Iqo=r(JXt,"AutoModel"),JXt.forEach(t),Kdo.forEach(t),Slo=i(c),jo=n(c,"DIV",{class:!0});var Ql=s(jo);T(zk.$$.fragment,Ql),Nqo=i(Ql),Od=n(Ql,"P",{});var sfe=s(Od);qqo=r(sfe,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),FQ=n(sfe,"A",{href:!0});var YXt=s(FQ);Dqo=r(YXt,"from_pretrained()"),YXt.forEach(t),jqo=r(sfe," class method or the "),TQ=n(sfe,"A",{href:!0});var ZXt=s(TQ);Gqo=r(ZXt,"from_config()"),ZXt.forEach(t),Oqo=r(sfe,` class
method.`),sfe.forEach(t),Vqo=i(Ql),Qk=n(Ql,"P",{});var emo=s(Qk);Xqo=r(emo,"This class cannot be instantiated directly using "),vve=n(emo,"CODE",{});var KXt=s(vve);zqo=r(KXt,"__init__()"),KXt.forEach(t),Qqo=r(emo," (throws an error)."),emo.forEach(t),Wqo=i(Ql),At=n(Ql,"DIV",{class:!0});var tx=s(At);T(Wk.$$.fragment,tx),Uqo=i(tx),Fve=n(tx,"P",{});var ezt=s(Fve);Hqo=r(ezt,"Instantiates one of the base model classes of the library from a configuration."),ezt.forEach(t),Jqo=i(tx),Vd=n(tx,"P",{});var lfe=s(Vd);Yqo=r(lfe,`Note:
Loading a model from its configuration file does `),Tve=n(lfe,"STRONG",{});var ozt=s(Tve);Zqo=r(ozt,"not"),ozt.forEach(t),Kqo=r(lfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),MQ=n(lfe,"A",{href:!0});var rzt=s(MQ);eDo=r(rzt,"from_pretrained()"),rzt.forEach(t),oDo=r(lfe," to load the model weights."),lfe.forEach(t),rDo=i(tx),T(A1.$$.fragment,tx),tx.forEach(t),tDo=i(Ql),to=n(Ql,"DIV",{class:!0});var Sa=s(to);T(Uk.$$.fragment,Sa),aDo=i(Sa),Mve=n(Sa,"P",{});var tzt=s(Mve);nDo=r(tzt,"Instantiate one of the base model classes of the library from a pretrained model."),tzt.forEach(t),sDo=i(Sa),fn=n(Sa,"P",{});var ax=s(fn);lDo=r(ax,"The model class to instantiate is selected based on the "),Eve=n(ax,"CODE",{});var azt=s(Eve);iDo=r(azt,"model_type"),azt.forEach(t),dDo=r(ax,` property of the config object (either
passed as an argument or loaded from `),Cve=n(ax,"CODE",{});var nzt=s(Cve);mDo=r(nzt,"pretrained_model_name_or_path"),nzt.forEach(t),cDo=r(ax,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wve=n(ax,"CODE",{});var szt=s(wve);fDo=r(szt,"pretrained_model_name_or_path"),szt.forEach(t),gDo=r(ax,":"),ax.forEach(t),hDo=i(Sa),y=n(Sa,"UL",{});var x=s(y);L1=n(x,"LI",{});var TXe=s(L1);Ave=n(TXe,"STRONG",{});var lzt=s(Ave);uDo=r(lzt,"albert"),lzt.forEach(t),pDo=r(TXe," \u2014 "),EQ=n(TXe,"A",{href:!0});var izt=s(EQ);_Do=r(izt,"AlbertModel"),izt.forEach(t),bDo=r(TXe," (ALBERT model)"),TXe.forEach(t),vDo=i(x),y1=n(x,"LI",{});var MXe=s(y1);Lve=n(MXe,"STRONG",{});var dzt=s(Lve);FDo=r(dzt,"bart"),dzt.forEach(t),TDo=r(MXe," \u2014 "),CQ=n(MXe,"A",{href:!0});var mzt=s(CQ);MDo=r(mzt,"BartModel"),mzt.forEach(t),EDo=r(MXe," (BART model)"),MXe.forEach(t),CDo=i(x),x1=n(x,"LI",{});var EXe=s(x1);yve=n(EXe,"STRONG",{});var czt=s(yve);wDo=r(czt,"beit"),czt.forEach(t),ADo=r(EXe," \u2014 "),wQ=n(EXe,"A",{href:!0});var fzt=s(wQ);LDo=r(fzt,"BeitModel"),fzt.forEach(t),yDo=r(EXe," (BEiT model)"),EXe.forEach(t),xDo=i(x),$1=n(x,"LI",{});var CXe=s($1);xve=n(CXe,"STRONG",{});var gzt=s(xve);$Do=r(gzt,"bert"),gzt.forEach(t),kDo=r(CXe," \u2014 "),AQ=n(CXe,"A",{href:!0});var hzt=s(AQ);SDo=r(hzt,"BertModel"),hzt.forEach(t),RDo=r(CXe," (BERT model)"),CXe.forEach(t),PDo=i(x),k1=n(x,"LI",{});var wXe=s(k1);$ve=n(wXe,"STRONG",{});var uzt=s($ve);BDo=r(uzt,"bert-generation"),uzt.forEach(t),IDo=r(wXe," \u2014 "),LQ=n(wXe,"A",{href:!0});var pzt=s(LQ);NDo=r(pzt,"BertGenerationEncoder"),pzt.forEach(t),qDo=r(wXe," (Bert Generation model)"),wXe.forEach(t),DDo=i(x),S1=n(x,"LI",{});var AXe=s(S1);kve=n(AXe,"STRONG",{});var _zt=s(kve);jDo=r(_zt,"big_bird"),_zt.forEach(t),GDo=r(AXe," \u2014 "),yQ=n(AXe,"A",{href:!0});var bzt=s(yQ);ODo=r(bzt,"BigBirdModel"),bzt.forEach(t),VDo=r(AXe," (BigBird model)"),AXe.forEach(t),XDo=i(x),R1=n(x,"LI",{});var LXe=s(R1);Sve=n(LXe,"STRONG",{});var vzt=s(Sve);zDo=r(vzt,"bigbird_pegasus"),vzt.forEach(t),QDo=r(LXe," \u2014 "),xQ=n(LXe,"A",{href:!0});var Fzt=s(xQ);WDo=r(Fzt,"BigBirdPegasusModel"),Fzt.forEach(t),UDo=r(LXe," (BigBird-Pegasus model)"),LXe.forEach(t),HDo=i(x),P1=n(x,"LI",{});var yXe=s(P1);Rve=n(yXe,"STRONG",{});var Tzt=s(Rve);JDo=r(Tzt,"blenderbot"),Tzt.forEach(t),YDo=r(yXe," \u2014 "),$Q=n(yXe,"A",{href:!0});var Mzt=s($Q);ZDo=r(Mzt,"BlenderbotModel"),Mzt.forEach(t),KDo=r(yXe," (Blenderbot model)"),yXe.forEach(t),ejo=i(x),B1=n(x,"LI",{});var xXe=s(B1);Pve=n(xXe,"STRONG",{});var Ezt=s(Pve);ojo=r(Ezt,"blenderbot-small"),Ezt.forEach(t),rjo=r(xXe," \u2014 "),kQ=n(xXe,"A",{href:!0});var Czt=s(kQ);tjo=r(Czt,"BlenderbotSmallModel"),Czt.forEach(t),ajo=r(xXe," (BlenderbotSmall model)"),xXe.forEach(t),njo=i(x),I1=n(x,"LI",{});var $Xe=s(I1);Bve=n($Xe,"STRONG",{});var wzt=s(Bve);sjo=r(wzt,"bloom"),wzt.forEach(t),ljo=r($Xe," \u2014 "),SQ=n($Xe,"A",{href:!0});var Azt=s(SQ);ijo=r(Azt,"BloomModel"),Azt.forEach(t),djo=r($Xe," (BLOOM model)"),$Xe.forEach(t),mjo=i(x),N1=n(x,"LI",{});var kXe=s(N1);Ive=n(kXe,"STRONG",{});var Lzt=s(Ive);cjo=r(Lzt,"camembert"),Lzt.forEach(t),fjo=r(kXe," \u2014 "),RQ=n(kXe,"A",{href:!0});var yzt=s(RQ);gjo=r(yzt,"CamembertModel"),yzt.forEach(t),hjo=r(kXe," (CamemBERT model)"),kXe.forEach(t),ujo=i(x),q1=n(x,"LI",{});var SXe=s(q1);Nve=n(SXe,"STRONG",{});var xzt=s(Nve);pjo=r(xzt,"canine"),xzt.forEach(t),_jo=r(SXe," \u2014 "),PQ=n(SXe,"A",{href:!0});var $zt=s(PQ);bjo=r($zt,"CanineModel"),$zt.forEach(t),vjo=r(SXe," (CANINE model)"),SXe.forEach(t),Fjo=i(x),D1=n(x,"LI",{});var RXe=s(D1);qve=n(RXe,"STRONG",{});var kzt=s(qve);Tjo=r(kzt,"clip"),kzt.forEach(t),Mjo=r(RXe," \u2014 "),BQ=n(RXe,"A",{href:!0});var Szt=s(BQ);Ejo=r(Szt,"CLIPModel"),Szt.forEach(t),Cjo=r(RXe," (CLIP model)"),RXe.forEach(t),wjo=i(x),j1=n(x,"LI",{});var PXe=s(j1);Dve=n(PXe,"STRONG",{});var Rzt=s(Dve);Ajo=r(Rzt,"clipseg"),Rzt.forEach(t),Ljo=r(PXe," \u2014 "),IQ=n(PXe,"A",{href:!0});var Pzt=s(IQ);yjo=r(Pzt,"CLIPSegModel"),Pzt.forEach(t),xjo=r(PXe," (CLIPSeg model)"),PXe.forEach(t),$jo=i(x),G1=n(x,"LI",{});var BXe=s(G1);jve=n(BXe,"STRONG",{});var Bzt=s(jve);kjo=r(Bzt,"codegen"),Bzt.forEach(t),Sjo=r(BXe," \u2014 "),NQ=n(BXe,"A",{href:!0});var Izt=s(NQ);Rjo=r(Izt,"CodeGenModel"),Izt.forEach(t),Pjo=r(BXe," (CodeGen model)"),BXe.forEach(t),Bjo=i(x),O1=n(x,"LI",{});var IXe=s(O1);Gve=n(IXe,"STRONG",{});var Nzt=s(Gve);Ijo=r(Nzt,"conditional_detr"),Nzt.forEach(t),Njo=r(IXe," \u2014 "),qQ=n(IXe,"A",{href:!0});var qzt=s(qQ);qjo=r(qzt,"ConditionalDetrModel"),qzt.forEach(t),Djo=r(IXe," (Conditional DETR model)"),IXe.forEach(t),jjo=i(x),V1=n(x,"LI",{});var NXe=s(V1);Ove=n(NXe,"STRONG",{});var Dzt=s(Ove);Gjo=r(Dzt,"convbert"),Dzt.forEach(t),Ojo=r(NXe," \u2014 "),DQ=n(NXe,"A",{href:!0});var jzt=s(DQ);Vjo=r(jzt,"ConvBertModel"),jzt.forEach(t),Xjo=r(NXe," (ConvBERT model)"),NXe.forEach(t),zjo=i(x),X1=n(x,"LI",{});var qXe=s(X1);Vve=n(qXe,"STRONG",{});var Gzt=s(Vve);Qjo=r(Gzt,"convnext"),Gzt.forEach(t),Wjo=r(qXe," \u2014 "),jQ=n(qXe,"A",{href:!0});var Ozt=s(jQ);Ujo=r(Ozt,"ConvNextModel"),Ozt.forEach(t),Hjo=r(qXe," (ConvNeXT model)"),qXe.forEach(t),Jjo=i(x),z1=n(x,"LI",{});var DXe=s(z1);Xve=n(DXe,"STRONG",{});var Vzt=s(Xve);Yjo=r(Vzt,"ctrl"),Vzt.forEach(t),Zjo=r(DXe," \u2014 "),GQ=n(DXe,"A",{href:!0});var Xzt=s(GQ);Kjo=r(Xzt,"CTRLModel"),Xzt.forEach(t),eGo=r(DXe," (CTRL model)"),DXe.forEach(t),oGo=i(x),Q1=n(x,"LI",{});var jXe=s(Q1);zve=n(jXe,"STRONG",{});var zzt=s(zve);rGo=r(zzt,"cvt"),zzt.forEach(t),tGo=r(jXe," \u2014 "),OQ=n(jXe,"A",{href:!0});var Qzt=s(OQ);aGo=r(Qzt,"CvtModel"),Qzt.forEach(t),nGo=r(jXe," (CvT model)"),jXe.forEach(t),sGo=i(x),W1=n(x,"LI",{});var GXe=s(W1);Qve=n(GXe,"STRONG",{});var Wzt=s(Qve);lGo=r(Wzt,"data2vec-audio"),Wzt.forEach(t),iGo=r(GXe," \u2014 "),VQ=n(GXe,"A",{href:!0});var Uzt=s(VQ);dGo=r(Uzt,"Data2VecAudioModel"),Uzt.forEach(t),mGo=r(GXe," (Data2VecAudio model)"),GXe.forEach(t),cGo=i(x),U1=n(x,"LI",{});var OXe=s(U1);Wve=n(OXe,"STRONG",{});var Hzt=s(Wve);fGo=r(Hzt,"data2vec-text"),Hzt.forEach(t),gGo=r(OXe," \u2014 "),XQ=n(OXe,"A",{href:!0});var Jzt=s(XQ);hGo=r(Jzt,"Data2VecTextModel"),Jzt.forEach(t),uGo=r(OXe," (Data2VecText model)"),OXe.forEach(t),pGo=i(x),H1=n(x,"LI",{});var VXe=s(H1);Uve=n(VXe,"STRONG",{});var Yzt=s(Uve);_Go=r(Yzt,"data2vec-vision"),Yzt.forEach(t),bGo=r(VXe," \u2014 "),zQ=n(VXe,"A",{href:!0});var Zzt=s(zQ);vGo=r(Zzt,"Data2VecVisionModel"),Zzt.forEach(t),FGo=r(VXe," (Data2VecVision model)"),VXe.forEach(t),TGo=i(x),J1=n(x,"LI",{});var XXe=s(J1);Hve=n(XXe,"STRONG",{});var Kzt=s(Hve);MGo=r(Kzt,"deberta"),Kzt.forEach(t),EGo=r(XXe," \u2014 "),QQ=n(XXe,"A",{href:!0});var eQt=s(QQ);CGo=r(eQt,"DebertaModel"),eQt.forEach(t),wGo=r(XXe," (DeBERTa model)"),XXe.forEach(t),AGo=i(x),Y1=n(x,"LI",{});var zXe=s(Y1);Jve=n(zXe,"STRONG",{});var oQt=s(Jve);LGo=r(oQt,"deberta-v2"),oQt.forEach(t),yGo=r(zXe," \u2014 "),WQ=n(zXe,"A",{href:!0});var rQt=s(WQ);xGo=r(rQt,"DebertaV2Model"),rQt.forEach(t),$Go=r(zXe," (DeBERTa-v2 model)"),zXe.forEach(t),kGo=i(x),Z1=n(x,"LI",{});var QXe=s(Z1);Yve=n(QXe,"STRONG",{});var tQt=s(Yve);SGo=r(tQt,"decision_transformer"),tQt.forEach(t),RGo=r(QXe," \u2014 "),UQ=n(QXe,"A",{href:!0});var aQt=s(UQ);PGo=r(aQt,"DecisionTransformerModel"),aQt.forEach(t),BGo=r(QXe," (Decision Transformer model)"),QXe.forEach(t),IGo=i(x),K1=n(x,"LI",{});var WXe=s(K1);Zve=n(WXe,"STRONG",{});var nQt=s(Zve);NGo=r(nQt,"deformable_detr"),nQt.forEach(t),qGo=r(WXe," \u2014 "),HQ=n(WXe,"A",{href:!0});var sQt=s(HQ);DGo=r(sQt,"DeformableDetrModel"),sQt.forEach(t),jGo=r(WXe," (Deformable DETR model)"),WXe.forEach(t),GGo=i(x),e2=n(x,"LI",{});var UXe=s(e2);Kve=n(UXe,"STRONG",{});var lQt=s(Kve);OGo=r(lQt,"deit"),lQt.forEach(t),VGo=r(UXe," \u2014 "),JQ=n(UXe,"A",{href:!0});var iQt=s(JQ);XGo=r(iQt,"DeiTModel"),iQt.forEach(t),zGo=r(UXe," (DeiT model)"),UXe.forEach(t),QGo=i(x),o2=n(x,"LI",{});var HXe=s(o2);eFe=n(HXe,"STRONG",{});var dQt=s(eFe);WGo=r(dQt,"detr"),dQt.forEach(t),UGo=r(HXe," \u2014 "),YQ=n(HXe,"A",{href:!0});var mQt=s(YQ);HGo=r(mQt,"DetrModel"),mQt.forEach(t),JGo=r(HXe," (DETR model)"),HXe.forEach(t),YGo=i(x),r2=n(x,"LI",{});var JXe=s(r2);oFe=n(JXe,"STRONG",{});var cQt=s(oFe);ZGo=r(cQt,"distilbert"),cQt.forEach(t),KGo=r(JXe," \u2014 "),ZQ=n(JXe,"A",{href:!0});var fQt=s(ZQ);eOo=r(fQt,"DistilBertModel"),fQt.forEach(t),oOo=r(JXe," (DistilBERT model)"),JXe.forEach(t),rOo=i(x),t2=n(x,"LI",{});var YXe=s(t2);rFe=n(YXe,"STRONG",{});var gQt=s(rFe);tOo=r(gQt,"donut-swin"),gQt.forEach(t),aOo=r(YXe," \u2014 "),KQ=n(YXe,"A",{href:!0});var hQt=s(KQ);nOo=r(hQt,"DonutSwinModel"),hQt.forEach(t),sOo=r(YXe," (DonutSwin model)"),YXe.forEach(t),lOo=i(x),a2=n(x,"LI",{});var ZXe=s(a2);tFe=n(ZXe,"STRONG",{});var uQt=s(tFe);iOo=r(uQt,"dpr"),uQt.forEach(t),dOo=r(ZXe," \u2014 "),eW=n(ZXe,"A",{href:!0});var pQt=s(eW);mOo=r(pQt,"DPRQuestionEncoder"),pQt.forEach(t),cOo=r(ZXe," (DPR model)"),ZXe.forEach(t),fOo=i(x),n2=n(x,"LI",{});var KXe=s(n2);aFe=n(KXe,"STRONG",{});var _Qt=s(aFe);gOo=r(_Qt,"dpt"),_Qt.forEach(t),hOo=r(KXe," \u2014 "),oW=n(KXe,"A",{href:!0});var bQt=s(oW);uOo=r(bQt,"DPTModel"),bQt.forEach(t),pOo=r(KXe," (DPT model)"),KXe.forEach(t),_Oo=i(x),s2=n(x,"LI",{});var eze=s(s2);nFe=n(eze,"STRONG",{});var vQt=s(nFe);bOo=r(vQt,"electra"),vQt.forEach(t),vOo=r(eze," \u2014 "),rW=n(eze,"A",{href:!0});var FQt=s(rW);FOo=r(FQt,"ElectraModel"),FQt.forEach(t),TOo=r(eze," (ELECTRA model)"),eze.forEach(t),MOo=i(x),l2=n(x,"LI",{});var oze=s(l2);sFe=n(oze,"STRONG",{});var TQt=s(sFe);EOo=r(TQt,"ernie"),TQt.forEach(t),COo=r(oze," \u2014 "),tW=n(oze,"A",{href:!0});var MQt=s(tW);wOo=r(MQt,"ErnieModel"),MQt.forEach(t),AOo=r(oze," (ERNIE model)"),oze.forEach(t),LOo=i(x),i2=n(x,"LI",{});var rze=s(i2);lFe=n(rze,"STRONG",{});var EQt=s(lFe);yOo=r(EQt,"esm"),EQt.forEach(t),xOo=r(rze," \u2014 "),aW=n(rze,"A",{href:!0});var CQt=s(aW);$Oo=r(CQt,"EsmModel"),CQt.forEach(t),kOo=r(rze," (ESM model)"),rze.forEach(t),SOo=i(x),d2=n(x,"LI",{});var tze=s(d2);iFe=n(tze,"STRONG",{});var wQt=s(iFe);ROo=r(wQt,"flaubert"),wQt.forEach(t),POo=r(tze," \u2014 "),nW=n(tze,"A",{href:!0});var AQt=s(nW);BOo=r(AQt,"FlaubertModel"),AQt.forEach(t),IOo=r(tze," (FlauBERT model)"),tze.forEach(t),NOo=i(x),m2=n(x,"LI",{});var aze=s(m2);dFe=n(aze,"STRONG",{});var LQt=s(dFe);qOo=r(LQt,"flava"),LQt.forEach(t),DOo=r(aze," \u2014 "),sW=n(aze,"A",{href:!0});var yQt=s(sW);jOo=r(yQt,"FlavaModel"),yQt.forEach(t),GOo=r(aze," (FLAVA model)"),aze.forEach(t),OOo=i(x),c2=n(x,"LI",{});var nze=s(c2);mFe=n(nze,"STRONG",{});var xQt=s(mFe);VOo=r(xQt,"fnet"),xQt.forEach(t),XOo=r(nze," \u2014 "),lW=n(nze,"A",{href:!0});var $Qt=s(lW);zOo=r($Qt,"FNetModel"),$Qt.forEach(t),QOo=r(nze," (FNet model)"),nze.forEach(t),WOo=i(x),f2=n(x,"LI",{});var sze=s(f2);cFe=n(sze,"STRONG",{});var kQt=s(cFe);UOo=r(kQt,"fsmt"),kQt.forEach(t),HOo=r(sze," \u2014 "),iW=n(sze,"A",{href:!0});var SQt=s(iW);JOo=r(SQt,"FSMTModel"),SQt.forEach(t),YOo=r(sze," (FairSeq Machine-Translation model)"),sze.forEach(t),ZOo=i(x),Il=n(x,"LI",{});var Lq=s(Il);fFe=n(Lq,"STRONG",{});var RQt=s(fFe);KOo=r(RQt,"funnel"),RQt.forEach(t),eVo=r(Lq," \u2014 "),dW=n(Lq,"A",{href:!0});var PQt=s(dW);oVo=r(PQt,"FunnelModel"),PQt.forEach(t),rVo=r(Lq," or "),mW=n(Lq,"A",{href:!0});var BQt=s(mW);tVo=r(BQt,"FunnelBaseModel"),BQt.forEach(t),aVo=r(Lq," (Funnel Transformer model)"),Lq.forEach(t),nVo=i(x),g2=n(x,"LI",{});var lze=s(g2);gFe=n(lze,"STRONG",{});var IQt=s(gFe);sVo=r(IQt,"glpn"),IQt.forEach(t),lVo=r(lze," \u2014 "),cW=n(lze,"A",{href:!0});var NQt=s(cW);iVo=r(NQt,"GLPNModel"),NQt.forEach(t),dVo=r(lze," (GLPN model)"),lze.forEach(t),mVo=i(x),h2=n(x,"LI",{});var ize=s(h2);hFe=n(ize,"STRONG",{});var qQt=s(hFe);cVo=r(qQt,"gpt2"),qQt.forEach(t),fVo=r(ize," \u2014 "),fW=n(ize,"A",{href:!0});var DQt=s(fW);gVo=r(DQt,"GPT2Model"),DQt.forEach(t),hVo=r(ize," (OpenAI GPT-2 model)"),ize.forEach(t),uVo=i(x),u2=n(x,"LI",{});var dze=s(u2);uFe=n(dze,"STRONG",{});var jQt=s(uFe);pVo=r(jQt,"gpt_neo"),jQt.forEach(t),_Vo=r(dze," \u2014 "),gW=n(dze,"A",{href:!0});var GQt=s(gW);bVo=r(GQt,"GPTNeoModel"),GQt.forEach(t),vVo=r(dze," (GPT Neo model)"),dze.forEach(t),FVo=i(x),p2=n(x,"LI",{});var mze=s(p2);pFe=n(mze,"STRONG",{});var OQt=s(pFe);TVo=r(OQt,"gpt_neox"),OQt.forEach(t),MVo=r(mze," \u2014 "),hW=n(mze,"A",{href:!0});var VQt=s(hW);EVo=r(VQt,"GPTNeoXModel"),VQt.forEach(t),CVo=r(mze," (GPT NeoX model)"),mze.forEach(t),wVo=i(x),_2=n(x,"LI",{});var cze=s(_2);_Fe=n(cze,"STRONG",{});var XQt=s(_Fe);AVo=r(XQt,"gpt_neox_japanese"),XQt.forEach(t),LVo=r(cze," \u2014 "),uW=n(cze,"A",{href:!0});var zQt=s(uW);yVo=r(zQt,"GPTNeoXJapaneseModel"),zQt.forEach(t),xVo=r(cze," (GPT NeoX Japanese model)"),cze.forEach(t),$Vo=i(x),b2=n(x,"LI",{});var fze=s(b2);bFe=n(fze,"STRONG",{});var QQt=s(bFe);kVo=r(QQt,"gptj"),QQt.forEach(t),SVo=r(fze," \u2014 "),pW=n(fze,"A",{href:!0});var WQt=s(pW);RVo=r(WQt,"GPTJModel"),WQt.forEach(t),PVo=r(fze," (GPT-J model)"),fze.forEach(t),BVo=i(x),v2=n(x,"LI",{});var gze=s(v2);vFe=n(gze,"STRONG",{});var UQt=s(vFe);IVo=r(UQt,"groupvit"),UQt.forEach(t),NVo=r(gze," \u2014 "),_W=n(gze,"A",{href:!0});var HQt=s(_W);qVo=r(HQt,"GroupViTModel"),HQt.forEach(t),DVo=r(gze," (GroupViT model)"),gze.forEach(t),jVo=i(x),F2=n(x,"LI",{});var hze=s(F2);FFe=n(hze,"STRONG",{});var JQt=s(FFe);GVo=r(JQt,"hubert"),JQt.forEach(t),OVo=r(hze," \u2014 "),bW=n(hze,"A",{href:!0});var YQt=s(bW);VVo=r(YQt,"HubertModel"),YQt.forEach(t),XVo=r(hze," (Hubert model)"),hze.forEach(t),zVo=i(x),T2=n(x,"LI",{});var uze=s(T2);TFe=n(uze,"STRONG",{});var ZQt=s(TFe);QVo=r(ZQt,"ibert"),ZQt.forEach(t),WVo=r(uze," \u2014 "),vW=n(uze,"A",{href:!0});var KQt=s(vW);UVo=r(KQt,"IBertModel"),KQt.forEach(t),HVo=r(uze," (I-BERT model)"),uze.forEach(t),JVo=i(x),M2=n(x,"LI",{});var pze=s(M2);MFe=n(pze,"STRONG",{});var eWt=s(MFe);YVo=r(eWt,"imagegpt"),eWt.forEach(t),ZVo=r(pze," \u2014 "),FW=n(pze,"A",{href:!0});var oWt=s(FW);KVo=r(oWt,"ImageGPTModel"),oWt.forEach(t),eXo=r(pze," (ImageGPT model)"),pze.forEach(t),oXo=i(x),E2=n(x,"LI",{});var _ze=s(E2);EFe=n(_ze,"STRONG",{});var rWt=s(EFe);rXo=r(rWt,"layoutlm"),rWt.forEach(t),tXo=r(_ze," \u2014 "),TW=n(_ze,"A",{href:!0});var tWt=s(TW);aXo=r(tWt,"LayoutLMModel"),tWt.forEach(t),nXo=r(_ze," (LayoutLM model)"),_ze.forEach(t),sXo=i(x),C2=n(x,"LI",{});var bze=s(C2);CFe=n(bze,"STRONG",{});var aWt=s(CFe);lXo=r(aWt,"layoutlmv2"),aWt.forEach(t),iXo=r(bze," \u2014 "),MW=n(bze,"A",{href:!0});var nWt=s(MW);dXo=r(nWt,"LayoutLMv2Model"),nWt.forEach(t),mXo=r(bze," (LayoutLMv2 model)"),bze.forEach(t),cXo=i(x),w2=n(x,"LI",{});var vze=s(w2);wFe=n(vze,"STRONG",{});var sWt=s(wFe);fXo=r(sWt,"layoutlmv3"),sWt.forEach(t),gXo=r(vze," \u2014 "),EW=n(vze,"A",{href:!0});var lWt=s(EW);hXo=r(lWt,"LayoutLMv3Model"),lWt.forEach(t),uXo=r(vze," (LayoutLMv3 model)"),vze.forEach(t),pXo=i(x),A2=n(x,"LI",{});var Fze=s(A2);AFe=n(Fze,"STRONG",{});var iWt=s(AFe);_Xo=r(iWt,"led"),iWt.forEach(t),bXo=r(Fze," \u2014 "),CW=n(Fze,"A",{href:!0});var dWt=s(CW);vXo=r(dWt,"LEDModel"),dWt.forEach(t),FXo=r(Fze," (LED model)"),Fze.forEach(t),TXo=i(x),L2=n(x,"LI",{});var Tze=s(L2);LFe=n(Tze,"STRONG",{});var mWt=s(LFe);MXo=r(mWt,"levit"),mWt.forEach(t),EXo=r(Tze," \u2014 "),wW=n(Tze,"A",{href:!0});var cWt=s(wW);CXo=r(cWt,"LevitModel"),cWt.forEach(t),wXo=r(Tze," (LeViT model)"),Tze.forEach(t),AXo=i(x),y2=n(x,"LI",{});var Mze=s(y2);yFe=n(Mze,"STRONG",{});var fWt=s(yFe);LXo=r(fWt,"lilt"),fWt.forEach(t),yXo=r(Mze," \u2014 "),AW=n(Mze,"A",{href:!0});var gWt=s(AW);xXo=r(gWt,"LiltModel"),gWt.forEach(t),$Xo=r(Mze," (LiLT model)"),Mze.forEach(t),kXo=i(x),x2=n(x,"LI",{});var Eze=s(x2);xFe=n(Eze,"STRONG",{});var hWt=s(xFe);SXo=r(hWt,"longformer"),hWt.forEach(t),RXo=r(Eze," \u2014 "),LW=n(Eze,"A",{href:!0});var uWt=s(LW);PXo=r(uWt,"LongformerModel"),uWt.forEach(t),BXo=r(Eze," (Longformer model)"),Eze.forEach(t),IXo=i(x),$2=n(x,"LI",{});var Cze=s($2);$Fe=n(Cze,"STRONG",{});var pWt=s($Fe);NXo=r(pWt,"longt5"),pWt.forEach(t),qXo=r(Cze," \u2014 "),yW=n(Cze,"A",{href:!0});var _Wt=s(yW);DXo=r(_Wt,"LongT5Model"),_Wt.forEach(t),jXo=r(Cze," (LongT5 model)"),Cze.forEach(t),GXo=i(x),k2=n(x,"LI",{});var wze=s(k2);kFe=n(wze,"STRONG",{});var bWt=s(kFe);OXo=r(bWt,"luke"),bWt.forEach(t),VXo=r(wze," \u2014 "),xW=n(wze,"A",{href:!0});var vWt=s(xW);XXo=r(vWt,"LukeModel"),vWt.forEach(t),zXo=r(wze," (LUKE model)"),wze.forEach(t),QXo=i(x),S2=n(x,"LI",{});var Aze=s(S2);SFe=n(Aze,"STRONG",{});var FWt=s(SFe);WXo=r(FWt,"lxmert"),FWt.forEach(t),UXo=r(Aze," \u2014 "),$W=n(Aze,"A",{href:!0});var TWt=s($W);HXo=r(TWt,"LxmertModel"),TWt.forEach(t),JXo=r(Aze," (LXMERT model)"),Aze.forEach(t),YXo=i(x),R2=n(x,"LI",{});var Lze=s(R2);RFe=n(Lze,"STRONG",{});var MWt=s(RFe);ZXo=r(MWt,"m2m_100"),MWt.forEach(t),KXo=r(Lze," \u2014 "),kW=n(Lze,"A",{href:!0});var EWt=s(kW);ezo=r(EWt,"M2M100Model"),EWt.forEach(t),ozo=r(Lze," (M2M100 model)"),Lze.forEach(t),rzo=i(x),P2=n(x,"LI",{});var yze=s(P2);PFe=n(yze,"STRONG",{});var CWt=s(PFe);tzo=r(CWt,"marian"),CWt.forEach(t),azo=r(yze," \u2014 "),SW=n(yze,"A",{href:!0});var wWt=s(SW);nzo=r(wWt,"MarianModel"),wWt.forEach(t),szo=r(yze," (Marian model)"),yze.forEach(t),lzo=i(x),B2=n(x,"LI",{});var xze=s(B2);BFe=n(xze,"STRONG",{});var AWt=s(BFe);izo=r(AWt,"markuplm"),AWt.forEach(t),dzo=r(xze," \u2014 "),RW=n(xze,"A",{href:!0});var LWt=s(RW);mzo=r(LWt,"MarkupLMModel"),LWt.forEach(t),czo=r(xze," (MarkupLM model)"),xze.forEach(t),fzo=i(x),I2=n(x,"LI",{});var $ze=s(I2);IFe=n($ze,"STRONG",{});var yWt=s(IFe);gzo=r(yWt,"maskformer"),yWt.forEach(t),hzo=r($ze," \u2014 "),PW=n($ze,"A",{href:!0});var xWt=s(PW);uzo=r(xWt,"MaskFormerModel"),xWt.forEach(t),pzo=r($ze," (MaskFormer model)"),$ze.forEach(t),_zo=i(x),N2=n(x,"LI",{});var kze=s(N2);NFe=n(kze,"STRONG",{});var $Wt=s(NFe);bzo=r($Wt,"mbart"),$Wt.forEach(t),vzo=r(kze," \u2014 "),BW=n(kze,"A",{href:!0});var kWt=s(BW);Fzo=r(kWt,"MBartModel"),kWt.forEach(t),Tzo=r(kze," (mBART model)"),kze.forEach(t),Mzo=i(x),q2=n(x,"LI",{});var Sze=s(q2);qFe=n(Sze,"STRONG",{});var SWt=s(qFe);Ezo=r(SWt,"mctct"),SWt.forEach(t),Czo=r(Sze," \u2014 "),IW=n(Sze,"A",{href:!0});var RWt=s(IW);wzo=r(RWt,"MCTCTModel"),RWt.forEach(t),Azo=r(Sze," (M-CTC-T model)"),Sze.forEach(t),Lzo=i(x),D2=n(x,"LI",{});var Rze=s(D2);DFe=n(Rze,"STRONG",{});var PWt=s(DFe);yzo=r(PWt,"megatron-bert"),PWt.forEach(t),xzo=r(Rze," \u2014 "),NW=n(Rze,"A",{href:!0});var BWt=s(NW);$zo=r(BWt,"MegatronBertModel"),BWt.forEach(t),kzo=r(Rze," (Megatron-BERT model)"),Rze.forEach(t),Szo=i(x),j2=n(x,"LI",{});var Pze=s(j2);jFe=n(Pze,"STRONG",{});var IWt=s(jFe);Rzo=r(IWt,"mobilebert"),IWt.forEach(t),Pzo=r(Pze," \u2014 "),qW=n(Pze,"A",{href:!0});var NWt=s(qW);Bzo=r(NWt,"MobileBertModel"),NWt.forEach(t),Izo=r(Pze," (MobileBERT model)"),Pze.forEach(t),Nzo=i(x),G2=n(x,"LI",{});var Bze=s(G2);GFe=n(Bze,"STRONG",{});var qWt=s(GFe);qzo=r(qWt,"mobilevit"),qWt.forEach(t),Dzo=r(Bze," \u2014 "),DW=n(Bze,"A",{href:!0});var DWt=s(DW);jzo=r(DWt,"MobileViTModel"),DWt.forEach(t),Gzo=r(Bze," (MobileViT model)"),Bze.forEach(t),Ozo=i(x),O2=n(x,"LI",{});var Ize=s(O2);OFe=n(Ize,"STRONG",{});var jWt=s(OFe);Vzo=r(jWt,"mpnet"),jWt.forEach(t),Xzo=r(Ize," \u2014 "),jW=n(Ize,"A",{href:!0});var GWt=s(jW);zzo=r(GWt,"MPNetModel"),GWt.forEach(t),Qzo=r(Ize," (MPNet model)"),Ize.forEach(t),Wzo=i(x),V2=n(x,"LI",{});var Nze=s(V2);VFe=n(Nze,"STRONG",{});var OWt=s(VFe);Uzo=r(OWt,"mt5"),OWt.forEach(t),Hzo=r(Nze," \u2014 "),GW=n(Nze,"A",{href:!0});var VWt=s(GW);Jzo=r(VWt,"MT5Model"),VWt.forEach(t),Yzo=r(Nze," (MT5 model)"),Nze.forEach(t),Zzo=i(x),X2=n(x,"LI",{});var qze=s(X2);XFe=n(qze,"STRONG",{});var XWt=s(XFe);Kzo=r(XWt,"mvp"),XWt.forEach(t),eQo=r(qze," \u2014 "),OW=n(qze,"A",{href:!0});var zWt=s(OW);oQo=r(zWt,"MvpModel"),zWt.forEach(t),rQo=r(qze," (MVP model)"),qze.forEach(t),tQo=i(x),z2=n(x,"LI",{});var Dze=s(z2);zFe=n(Dze,"STRONG",{});var QWt=s(zFe);aQo=r(QWt,"nezha"),QWt.forEach(t),nQo=r(Dze," \u2014 "),VW=n(Dze,"A",{href:!0});var WWt=s(VW);sQo=r(WWt,"NezhaModel"),WWt.forEach(t),lQo=r(Dze," (Nezha model)"),Dze.forEach(t),iQo=i(x),Q2=n(x,"LI",{});var jze=s(Q2);QFe=n(jze,"STRONG",{});var UWt=s(QFe);dQo=r(UWt,"nllb"),UWt.forEach(t),mQo=r(jze," \u2014 "),XW=n(jze,"A",{href:!0});var HWt=s(XW);cQo=r(HWt,"M2M100Model"),HWt.forEach(t),fQo=r(jze," (NLLB model)"),jze.forEach(t),gQo=i(x),W2=n(x,"LI",{});var Gze=s(W2);WFe=n(Gze,"STRONG",{});var JWt=s(WFe);hQo=r(JWt,"nystromformer"),JWt.forEach(t),uQo=r(Gze," \u2014 "),zW=n(Gze,"A",{href:!0});var YWt=s(zW);pQo=r(YWt,"NystromformerModel"),YWt.forEach(t),_Qo=r(Gze," (Nystr\xF6mformer model)"),Gze.forEach(t),bQo=i(x),U2=n(x,"LI",{});var Oze=s(U2);UFe=n(Oze,"STRONG",{});var ZWt=s(UFe);vQo=r(ZWt,"openai-gpt"),ZWt.forEach(t),FQo=r(Oze," \u2014 "),QW=n(Oze,"A",{href:!0});var KWt=s(QW);TQo=r(KWt,"OpenAIGPTModel"),KWt.forEach(t),MQo=r(Oze," (OpenAI GPT model)"),Oze.forEach(t),EQo=i(x),H2=n(x,"LI",{});var Vze=s(H2);HFe=n(Vze,"STRONG",{});var eUt=s(HFe);CQo=r(eUt,"opt"),eUt.forEach(t),wQo=r(Vze," \u2014 "),WW=n(Vze,"A",{href:!0});var oUt=s(WW);AQo=r(oUt,"OPTModel"),oUt.forEach(t),LQo=r(Vze," (OPT model)"),Vze.forEach(t),yQo=i(x),J2=n(x,"LI",{});var Xze=s(J2);JFe=n(Xze,"STRONG",{});var rUt=s(JFe);xQo=r(rUt,"owlvit"),rUt.forEach(t),$Qo=r(Xze," \u2014 "),UW=n(Xze,"A",{href:!0});var tUt=s(UW);kQo=r(tUt,"OwlViTModel"),tUt.forEach(t),SQo=r(Xze," (OWL-ViT model)"),Xze.forEach(t),RQo=i(x),Y2=n(x,"LI",{});var zze=s(Y2);YFe=n(zze,"STRONG",{});var aUt=s(YFe);PQo=r(aUt,"pegasus"),aUt.forEach(t),BQo=r(zze," \u2014 "),HW=n(zze,"A",{href:!0});var nUt=s(HW);IQo=r(nUt,"PegasusModel"),nUt.forEach(t),NQo=r(zze," (Pegasus model)"),zze.forEach(t),qQo=i(x),Z2=n(x,"LI",{});var Qze=s(Z2);ZFe=n(Qze,"STRONG",{});var sUt=s(ZFe);DQo=r(sUt,"pegasus_x"),sUt.forEach(t),jQo=r(Qze," \u2014 "),JW=n(Qze,"A",{href:!0});var lUt=s(JW);GQo=r(lUt,"PegasusXModel"),lUt.forEach(t),OQo=r(Qze," (PEGASUS-X model)"),Qze.forEach(t),VQo=i(x),K2=n(x,"LI",{});var Wze=s(K2);KFe=n(Wze,"STRONG",{});var iUt=s(KFe);XQo=r(iUt,"perceiver"),iUt.forEach(t),zQo=r(Wze," \u2014 "),YW=n(Wze,"A",{href:!0});var dUt=s(YW);QQo=r(dUt,"PerceiverModel"),dUt.forEach(t),WQo=r(Wze," (Perceiver model)"),Wze.forEach(t),UQo=i(x),eb=n(x,"LI",{});var Uze=s(eb);eTe=n(Uze,"STRONG",{});var mUt=s(eTe);HQo=r(mUt,"plbart"),mUt.forEach(t),JQo=r(Uze," \u2014 "),ZW=n(Uze,"A",{href:!0});var cUt=s(ZW);YQo=r(cUt,"PLBartModel"),cUt.forEach(t),ZQo=r(Uze," (PLBart model)"),Uze.forEach(t),KQo=i(x),ob=n(x,"LI",{});var Hze=s(ob);oTe=n(Hze,"STRONG",{});var fUt=s(oTe);eWo=r(fUt,"poolformer"),fUt.forEach(t),oWo=r(Hze," \u2014 "),KW=n(Hze,"A",{href:!0});var gUt=s(KW);rWo=r(gUt,"PoolFormerModel"),gUt.forEach(t),tWo=r(Hze," (PoolFormer model)"),Hze.forEach(t),aWo=i(x),rb=n(x,"LI",{});var Jze=s(rb);rTe=n(Jze,"STRONG",{});var hUt=s(rTe);nWo=r(hUt,"prophetnet"),hUt.forEach(t),sWo=r(Jze," \u2014 "),eU=n(Jze,"A",{href:!0});var uUt=s(eU);lWo=r(uUt,"ProphetNetModel"),uUt.forEach(t),iWo=r(Jze," (ProphetNet model)"),Jze.forEach(t),dWo=i(x),tb=n(x,"LI",{});var Yze=s(tb);tTe=n(Yze,"STRONG",{});var pUt=s(tTe);mWo=r(pUt,"qdqbert"),pUt.forEach(t),cWo=r(Yze," \u2014 "),oU=n(Yze,"A",{href:!0});var _Ut=s(oU);fWo=r(_Ut,"QDQBertModel"),_Ut.forEach(t),gWo=r(Yze," (QDQBert model)"),Yze.forEach(t),hWo=i(x),ab=n(x,"LI",{});var Zze=s(ab);aTe=n(Zze,"STRONG",{});var bUt=s(aTe);uWo=r(bUt,"reformer"),bUt.forEach(t),pWo=r(Zze," \u2014 "),rU=n(Zze,"A",{href:!0});var vUt=s(rU);_Wo=r(vUt,"ReformerModel"),vUt.forEach(t),bWo=r(Zze," (Reformer model)"),Zze.forEach(t),vWo=i(x),nb=n(x,"LI",{});var Kze=s(nb);nTe=n(Kze,"STRONG",{});var FUt=s(nTe);FWo=r(FUt,"regnet"),FUt.forEach(t),TWo=r(Kze," \u2014 "),tU=n(Kze,"A",{href:!0});var TUt=s(tU);MWo=r(TUt,"RegNetModel"),TUt.forEach(t),EWo=r(Kze," (RegNet model)"),Kze.forEach(t),CWo=i(x),sb=n(x,"LI",{});var eQe=s(sb);sTe=n(eQe,"STRONG",{});var MUt=s(sTe);wWo=r(MUt,"rembert"),MUt.forEach(t),AWo=r(eQe," \u2014 "),aU=n(eQe,"A",{href:!0});var EUt=s(aU);LWo=r(EUt,"RemBertModel"),EUt.forEach(t),yWo=r(eQe," (RemBERT model)"),eQe.forEach(t),xWo=i(x),lb=n(x,"LI",{});var oQe=s(lb);lTe=n(oQe,"STRONG",{});var CUt=s(lTe);$Wo=r(CUt,"resnet"),CUt.forEach(t),kWo=r(oQe," \u2014 "),nU=n(oQe,"A",{href:!0});var wUt=s(nU);SWo=r(wUt,"ResNetModel"),wUt.forEach(t),RWo=r(oQe," (ResNet model)"),oQe.forEach(t),PWo=i(x),ib=n(x,"LI",{});var rQe=s(ib);iTe=n(rQe,"STRONG",{});var AUt=s(iTe);BWo=r(AUt,"retribert"),AUt.forEach(t),IWo=r(rQe," \u2014 "),sU=n(rQe,"A",{href:!0});var LUt=s(sU);NWo=r(LUt,"RetriBertModel"),LUt.forEach(t),qWo=r(rQe," (RetriBERT model)"),rQe.forEach(t),DWo=i(x),db=n(x,"LI",{});var tQe=s(db);dTe=n(tQe,"STRONG",{});var yUt=s(dTe);jWo=r(yUt,"roberta"),yUt.forEach(t),GWo=r(tQe," \u2014 "),lU=n(tQe,"A",{href:!0});var xUt=s(lU);OWo=r(xUt,"RobertaModel"),xUt.forEach(t),VWo=r(tQe," (RoBERTa model)"),tQe.forEach(t),XWo=i(x),mb=n(x,"LI",{});var aQe=s(mb);mTe=n(aQe,"STRONG",{});var $Ut=s(mTe);zWo=r($Ut,"roc_bert"),$Ut.forEach(t),QWo=r(aQe," \u2014 "),iU=n(aQe,"A",{href:!0});var kUt=s(iU);WWo=r(kUt,"RoCBertModel"),kUt.forEach(t),UWo=r(aQe," (RoCBert model)"),aQe.forEach(t),HWo=i(x),cb=n(x,"LI",{});var nQe=s(cb);cTe=n(nQe,"STRONG",{});var SUt=s(cTe);JWo=r(SUt,"roformer"),SUt.forEach(t),YWo=r(nQe," \u2014 "),dU=n(nQe,"A",{href:!0});var RUt=s(dU);ZWo=r(RUt,"RoFormerModel"),RUt.forEach(t),KWo=r(nQe," (RoFormer model)"),nQe.forEach(t),eUo=i(x),fb=n(x,"LI",{});var sQe=s(fb);fTe=n(sQe,"STRONG",{});var PUt=s(fTe);oUo=r(PUt,"segformer"),PUt.forEach(t),rUo=r(sQe," \u2014 "),mU=n(sQe,"A",{href:!0});var BUt=s(mU);tUo=r(BUt,"SegformerModel"),BUt.forEach(t),aUo=r(sQe," (SegFormer model)"),sQe.forEach(t),nUo=i(x),gb=n(x,"LI",{});var lQe=s(gb);gTe=n(lQe,"STRONG",{});var IUt=s(gTe);sUo=r(IUt,"sew"),IUt.forEach(t),lUo=r(lQe," \u2014 "),cU=n(lQe,"A",{href:!0});var NUt=s(cU);iUo=r(NUt,"SEWModel"),NUt.forEach(t),dUo=r(lQe," (SEW model)"),lQe.forEach(t),mUo=i(x),hb=n(x,"LI",{});var iQe=s(hb);hTe=n(iQe,"STRONG",{});var qUt=s(hTe);cUo=r(qUt,"sew-d"),qUt.forEach(t),fUo=r(iQe," \u2014 "),fU=n(iQe,"A",{href:!0});var DUt=s(fU);gUo=r(DUt,"SEWDModel"),DUt.forEach(t),hUo=r(iQe," (SEW-D model)"),iQe.forEach(t),uUo=i(x),ub=n(x,"LI",{});var dQe=s(ub);uTe=n(dQe,"STRONG",{});var jUt=s(uTe);pUo=r(jUt,"speech_to_text"),jUt.forEach(t),_Uo=r(dQe," \u2014 "),gU=n(dQe,"A",{href:!0});var GUt=s(gU);bUo=r(GUt,"Speech2TextModel"),GUt.forEach(t),vUo=r(dQe," (Speech2Text model)"),dQe.forEach(t),FUo=i(x),pb=n(x,"LI",{});var mQe=s(pb);pTe=n(mQe,"STRONG",{});var OUt=s(pTe);TUo=r(OUt,"splinter"),OUt.forEach(t),MUo=r(mQe," \u2014 "),hU=n(mQe,"A",{href:!0});var VUt=s(hU);EUo=r(VUt,"SplinterModel"),VUt.forEach(t),CUo=r(mQe," (Splinter model)"),mQe.forEach(t),wUo=i(x),_b=n(x,"LI",{});var cQe=s(_b);_Te=n(cQe,"STRONG",{});var XUt=s(_Te);AUo=r(XUt,"squeezebert"),XUt.forEach(t),LUo=r(cQe," \u2014 "),uU=n(cQe,"A",{href:!0});var zUt=s(uU);yUo=r(zUt,"SqueezeBertModel"),zUt.forEach(t),xUo=r(cQe," (SqueezeBERT model)"),cQe.forEach(t),$Uo=i(x),bb=n(x,"LI",{});var fQe=s(bb);bTe=n(fQe,"STRONG",{});var QUt=s(bTe);kUo=r(QUt,"swin"),QUt.forEach(t),SUo=r(fQe," \u2014 "),pU=n(fQe,"A",{href:!0});var WUt=s(pU);RUo=r(WUt,"SwinModel"),WUt.forEach(t),PUo=r(fQe," (Swin Transformer model)"),fQe.forEach(t),BUo=i(x),vb=n(x,"LI",{});var gQe=s(vb);vTe=n(gQe,"STRONG",{});var UUt=s(vTe);IUo=r(UUt,"swinv2"),UUt.forEach(t),NUo=r(gQe," \u2014 "),_U=n(gQe,"A",{href:!0});var HUt=s(_U);qUo=r(HUt,"Swinv2Model"),HUt.forEach(t),DUo=r(gQe," (Swin Transformer V2 model)"),gQe.forEach(t),jUo=i(x),Fb=n(x,"LI",{});var hQe=s(Fb);FTe=n(hQe,"STRONG",{});var JUt=s(FTe);GUo=r(JUt,"t5"),JUt.forEach(t),OUo=r(hQe," \u2014 "),bU=n(hQe,"A",{href:!0});var YUt=s(bU);VUo=r(YUt,"T5Model"),YUt.forEach(t),XUo=r(hQe," (T5 model)"),hQe.forEach(t),zUo=i(x),Tb=n(x,"LI",{});var uQe=s(Tb);TTe=n(uQe,"STRONG",{});var ZUt=s(TTe);QUo=r(ZUt,"table-transformer"),ZUt.forEach(t),WUo=r(uQe," \u2014 "),vU=n(uQe,"A",{href:!0});var KUt=s(vU);UUo=r(KUt,"TableTransformerModel"),KUt.forEach(t),HUo=r(uQe," (Table Transformer model)"),uQe.forEach(t),JUo=i(x),Mb=n(x,"LI",{});var pQe=s(Mb);MTe=n(pQe,"STRONG",{});var eHt=s(MTe);YUo=r(eHt,"tapas"),eHt.forEach(t),ZUo=r(pQe," \u2014 "),FU=n(pQe,"A",{href:!0});var oHt=s(FU);KUo=r(oHt,"TapasModel"),oHt.forEach(t),eHo=r(pQe," (TAPAS model)"),pQe.forEach(t),oHo=i(x),Eb=n(x,"LI",{});var _Qe=s(Eb);ETe=n(_Qe,"STRONG",{});var rHt=s(ETe);rHo=r(rHt,"time_series_transformer"),rHt.forEach(t),tHo=r(_Qe," \u2014 "),TU=n(_Qe,"A",{href:!0});var tHt=s(TU);aHo=r(tHt,"TimeSeriesTransformerModel"),tHt.forEach(t),nHo=r(_Qe," (Time Series Transformer model)"),_Qe.forEach(t),sHo=i(x),Cb=n(x,"LI",{});var bQe=s(Cb);CTe=n(bQe,"STRONG",{});var aHt=s(CTe);lHo=r(aHt,"trajectory_transformer"),aHt.forEach(t),iHo=r(bQe," \u2014 "),MU=n(bQe,"A",{href:!0});var nHt=s(MU);dHo=r(nHt,"TrajectoryTransformerModel"),nHt.forEach(t),mHo=r(bQe," (Trajectory Transformer model)"),bQe.forEach(t),cHo=i(x),wb=n(x,"LI",{});var vQe=s(wb);wTe=n(vQe,"STRONG",{});var sHt=s(wTe);fHo=r(sHt,"transfo-xl"),sHt.forEach(t),gHo=r(vQe," \u2014 "),EU=n(vQe,"A",{href:!0});var lHt=s(EU);hHo=r(lHt,"TransfoXLModel"),lHt.forEach(t),uHo=r(vQe," (Transformer-XL model)"),vQe.forEach(t),pHo=i(x),Ab=n(x,"LI",{});var FQe=s(Ab);ATe=n(FQe,"STRONG",{});var iHt=s(ATe);_Ho=r(iHt,"unispeech"),iHt.forEach(t),bHo=r(FQe," \u2014 "),CU=n(FQe,"A",{href:!0});var dHt=s(CU);vHo=r(dHt,"UniSpeechModel"),dHt.forEach(t),FHo=r(FQe," (UniSpeech model)"),FQe.forEach(t),THo=i(x),Lb=n(x,"LI",{});var TQe=s(Lb);LTe=n(TQe,"STRONG",{});var mHt=s(LTe);MHo=r(mHt,"unispeech-sat"),mHt.forEach(t),EHo=r(TQe," \u2014 "),wU=n(TQe,"A",{href:!0});var cHt=s(wU);CHo=r(cHt,"UniSpeechSatModel"),cHt.forEach(t),wHo=r(TQe," (UniSpeechSat model)"),TQe.forEach(t),AHo=i(x),yb=n(x,"LI",{});var MQe=s(yb);yTe=n(MQe,"STRONG",{});var fHt=s(yTe);LHo=r(fHt,"van"),fHt.forEach(t),yHo=r(MQe," \u2014 "),AU=n(MQe,"A",{href:!0});var gHt=s(AU);xHo=r(gHt,"VanModel"),gHt.forEach(t),$Ho=r(MQe," (VAN model)"),MQe.forEach(t),kHo=i(x),xb=n(x,"LI",{});var EQe=s(xb);xTe=n(EQe,"STRONG",{});var hHt=s(xTe);SHo=r(hHt,"videomae"),hHt.forEach(t),RHo=r(EQe," \u2014 "),LU=n(EQe,"A",{href:!0});var uHt=s(LU);PHo=r(uHt,"VideoMAEModel"),uHt.forEach(t),BHo=r(EQe," (VideoMAE model)"),EQe.forEach(t),IHo=i(x),$b=n(x,"LI",{});var CQe=s($b);$Te=n(CQe,"STRONG",{});var pHt=s($Te);NHo=r(pHt,"vilt"),pHt.forEach(t),qHo=r(CQe," \u2014 "),yU=n(CQe,"A",{href:!0});var _Ht=s(yU);DHo=r(_Ht,"ViltModel"),_Ht.forEach(t),jHo=r(CQe," (ViLT model)"),CQe.forEach(t),GHo=i(x),kb=n(x,"LI",{});var wQe=s(kb);kTe=n(wQe,"STRONG",{});var bHt=s(kTe);OHo=r(bHt,"vision-text-dual-encoder"),bHt.forEach(t),VHo=r(wQe," \u2014 "),xU=n(wQe,"A",{href:!0});var vHt=s(xU);XHo=r(vHt,"VisionTextDualEncoderModel"),vHt.forEach(t),zHo=r(wQe," (VisionTextDualEncoder model)"),wQe.forEach(t),QHo=i(x),Sb=n(x,"LI",{});var AQe=s(Sb);STe=n(AQe,"STRONG",{});var FHt=s(STe);WHo=r(FHt,"visual_bert"),FHt.forEach(t),UHo=r(AQe," \u2014 "),$U=n(AQe,"A",{href:!0});var THt=s($U);HHo=r(THt,"VisualBertModel"),THt.forEach(t),JHo=r(AQe," (VisualBERT model)"),AQe.forEach(t),YHo=i(x),Rb=n(x,"LI",{});var LQe=s(Rb);RTe=n(LQe,"STRONG",{});var MHt=s(RTe);ZHo=r(MHt,"vit"),MHt.forEach(t),KHo=r(LQe," \u2014 "),kU=n(LQe,"A",{href:!0});var EHt=s(kU);eJo=r(EHt,"ViTModel"),EHt.forEach(t),oJo=r(LQe," (ViT model)"),LQe.forEach(t),rJo=i(x),Pb=n(x,"LI",{});var yQe=s(Pb);PTe=n(yQe,"STRONG",{});var CHt=s(PTe);tJo=r(CHt,"vit_mae"),CHt.forEach(t),aJo=r(yQe," \u2014 "),SU=n(yQe,"A",{href:!0});var wHt=s(SU);nJo=r(wHt,"ViTMAEModel"),wHt.forEach(t),sJo=r(yQe," (ViTMAE model)"),yQe.forEach(t),lJo=i(x),Bb=n(x,"LI",{});var xQe=s(Bb);BTe=n(xQe,"STRONG",{});var AHt=s(BTe);iJo=r(AHt,"vit_msn"),AHt.forEach(t),dJo=r(xQe," \u2014 "),RU=n(xQe,"A",{href:!0});var LHt=s(RU);mJo=r(LHt,"ViTMSNModel"),LHt.forEach(t),cJo=r(xQe," (ViTMSN model)"),xQe.forEach(t),fJo=i(x),Ib=n(x,"LI",{});var $Qe=s(Ib);ITe=n($Qe,"STRONG",{});var yHt=s(ITe);gJo=r(yHt,"wav2vec2"),yHt.forEach(t),hJo=r($Qe," \u2014 "),PU=n($Qe,"A",{href:!0});var xHt=s(PU);uJo=r(xHt,"Wav2Vec2Model"),xHt.forEach(t),pJo=r($Qe," (Wav2Vec2 model)"),$Qe.forEach(t),_Jo=i(x),Nb=n(x,"LI",{});var kQe=s(Nb);NTe=n(kQe,"STRONG",{});var $Ht=s(NTe);bJo=r($Ht,"wav2vec2-conformer"),$Ht.forEach(t),vJo=r(kQe," \u2014 "),BU=n(kQe,"A",{href:!0});var kHt=s(BU);FJo=r(kHt,"Wav2Vec2ConformerModel"),kHt.forEach(t),TJo=r(kQe," (Wav2Vec2-Conformer model)"),kQe.forEach(t),MJo=i(x),qb=n(x,"LI",{});var SQe=s(qb);qTe=n(SQe,"STRONG",{});var SHt=s(qTe);EJo=r(SHt,"wavlm"),SHt.forEach(t),CJo=r(SQe," \u2014 "),IU=n(SQe,"A",{href:!0});var RHt=s(IU);wJo=r(RHt,"WavLMModel"),RHt.forEach(t),AJo=r(SQe," (WavLM model)"),SQe.forEach(t),LJo=i(x),Db=n(x,"LI",{});var RQe=s(Db);DTe=n(RQe,"STRONG",{});var PHt=s(DTe);yJo=r(PHt,"whisper"),PHt.forEach(t),xJo=r(RQe," \u2014 "),NU=n(RQe,"A",{href:!0});var BHt=s(NU);$Jo=r(BHt,"WhisperModel"),BHt.forEach(t),kJo=r(RQe," (Whisper model)"),RQe.forEach(t),SJo=i(x),jb=n(x,"LI",{});var PQe=s(jb);jTe=n(PQe,"STRONG",{});var IHt=s(jTe);RJo=r(IHt,"xclip"),IHt.forEach(t),PJo=r(PQe," \u2014 "),qU=n(PQe,"A",{href:!0});var NHt=s(qU);BJo=r(NHt,"XCLIPModel"),NHt.forEach(t),IJo=r(PQe," (X-CLIP model)"),PQe.forEach(t),NJo=i(x),Gb=n(x,"LI",{});var BQe=s(Gb);GTe=n(BQe,"STRONG",{});var qHt=s(GTe);qJo=r(qHt,"xglm"),qHt.forEach(t),DJo=r(BQe," \u2014 "),DU=n(BQe,"A",{href:!0});var DHt=s(DU);jJo=r(DHt,"XGLMModel"),DHt.forEach(t),GJo=r(BQe," (XGLM model)"),BQe.forEach(t),OJo=i(x),Ob=n(x,"LI",{});var IQe=s(Ob);OTe=n(IQe,"STRONG",{});var jHt=s(OTe);VJo=r(jHt,"xlm"),jHt.forEach(t),XJo=r(IQe," \u2014 "),jU=n(IQe,"A",{href:!0});var GHt=s(jU);zJo=r(GHt,"XLMModel"),GHt.forEach(t),QJo=r(IQe," (XLM model)"),IQe.forEach(t),WJo=i(x),Vb=n(x,"LI",{});var NQe=s(Vb);VTe=n(NQe,"STRONG",{});var OHt=s(VTe);UJo=r(OHt,"xlm-prophetnet"),OHt.forEach(t),HJo=r(NQe," \u2014 "),GU=n(NQe,"A",{href:!0});var VHt=s(GU);JJo=r(VHt,"XLMProphetNetModel"),VHt.forEach(t),YJo=r(NQe," (XLM-ProphetNet model)"),NQe.forEach(t),ZJo=i(x),Xb=n(x,"LI",{});var qQe=s(Xb);XTe=n(qQe,"STRONG",{});var XHt=s(XTe);KJo=r(XHt,"xlm-roberta"),XHt.forEach(t),eYo=r(qQe," \u2014 "),OU=n(qQe,"A",{href:!0});var zHt=s(OU);oYo=r(zHt,"XLMRobertaModel"),zHt.forEach(t),rYo=r(qQe," (XLM-RoBERTa model)"),qQe.forEach(t),tYo=i(x),zb=n(x,"LI",{});var DQe=s(zb);zTe=n(DQe,"STRONG",{});var QHt=s(zTe);aYo=r(QHt,"xlm-roberta-xl"),QHt.forEach(t),nYo=r(DQe," \u2014 "),VU=n(DQe,"A",{href:!0});var WHt=s(VU);sYo=r(WHt,"XLMRobertaXLModel"),WHt.forEach(t),lYo=r(DQe," (XLM-RoBERTa-XL model)"),DQe.forEach(t),iYo=i(x),Qb=n(x,"LI",{});var jQe=s(Qb);QTe=n(jQe,"STRONG",{});var UHt=s(QTe);dYo=r(UHt,"xlnet"),UHt.forEach(t),mYo=r(jQe," \u2014 "),XU=n(jQe,"A",{href:!0});var HHt=s(XU);cYo=r(HHt,"XLNetModel"),HHt.forEach(t),fYo=r(jQe," (XLNet model)"),jQe.forEach(t),gYo=i(x),Wb=n(x,"LI",{});var GQe=s(Wb);WTe=n(GQe,"STRONG",{});var JHt=s(WTe);hYo=r(JHt,"yolos"),JHt.forEach(t),uYo=r(GQe," \u2014 "),zU=n(GQe,"A",{href:!0});var YHt=s(zU);pYo=r(YHt,"YolosModel"),YHt.forEach(t),_Yo=r(GQe," (YOLOS model)"),GQe.forEach(t),bYo=i(x),Ub=n(x,"LI",{});var OQe=s(Ub);UTe=n(OQe,"STRONG",{});var ZHt=s(UTe);vYo=r(ZHt,"yoso"),ZHt.forEach(t),FYo=r(OQe," \u2014 "),QU=n(OQe,"A",{href:!0});var KHt=s(QU);TYo=r(KHt,"YosoModel"),KHt.forEach(t),MYo=r(OQe," (YOSO model)"),OQe.forEach(t),x.forEach(t),EYo=i(Sa),Hb=n(Sa,"P",{});var VQe=s(Hb);CYo=r(VQe,"The model is set in evaluation mode by default using "),HTe=n(VQe,"CODE",{});var eJt=s(HTe);wYo=r(eJt,"model.eval()"),eJt.forEach(t),AYo=r(VQe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),JTe=n(VQe,"CODE",{});var oJt=s(JTe);LYo=r(oJt,"model.train()"),oJt.forEach(t),VQe.forEach(t),yYo=i(Sa),T(Jb.$$.fragment,Sa),Sa.forEach(t),Ql.forEach(t),Rlo=i(c),Xd=n(c,"H2",{class:!0});var omo=s(Xd);Yb=n(omo,"A",{id:!0,class:!0,href:!0});var rJt=s(Yb);YTe=n(rJt,"SPAN",{});var tJt=s(YTe);T(Hk.$$.fragment,tJt),tJt.forEach(t),rJt.forEach(t),xYo=i(omo),ZTe=n(omo,"SPAN",{});var aJt=s(ZTe);$Yo=r(aJt,"AutoModelForPreTraining"),aJt.forEach(t),omo.forEach(t),Plo=i(c),Go=n(c,"DIV",{class:!0});var Wl=s(Go);T(Jk.$$.fragment,Wl),kYo=i(Wl),zd=n(Wl,"P",{});var ife=s(zd);SYo=r(ife,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),WU=n(ife,"A",{href:!0});var nJt=s(WU);RYo=r(nJt,"from_pretrained()"),nJt.forEach(t),PYo=r(ife," class method or the "),UU=n(ife,"A",{href:!0});var sJt=s(UU);BYo=r(sJt,"from_config()"),sJt.forEach(t),IYo=r(ife,` class
method.`),ife.forEach(t),NYo=i(Wl),Yk=n(Wl,"P",{});var rmo=s(Yk);qYo=r(rmo,"This class cannot be instantiated directly using "),KTe=n(rmo,"CODE",{});var lJt=s(KTe);DYo=r(lJt,"__init__()"),lJt.forEach(t),jYo=r(rmo," (throws an error)."),rmo.forEach(t),GYo=i(Wl),Lt=n(Wl,"DIV",{class:!0});var nx=s(Lt);T(Zk.$$.fragment,nx),OYo=i(nx),eMe=n(nx,"P",{});var iJt=s(eMe);VYo=r(iJt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),iJt.forEach(t),XYo=i(nx),Qd=n(nx,"P",{});var dfe=s(Qd);zYo=r(dfe,`Note:
Loading a model from its configuration file does `),oMe=n(dfe,"STRONG",{});var dJt=s(oMe);QYo=r(dJt,"not"),dJt.forEach(t),WYo=r(dfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),HU=n(dfe,"A",{href:!0});var mJt=s(HU);UYo=r(mJt,"from_pretrained()"),mJt.forEach(t),HYo=r(dfe," to load the model weights."),dfe.forEach(t),JYo=i(nx),T(Zb.$$.fragment,nx),nx.forEach(t),YYo=i(Wl),ao=n(Wl,"DIV",{class:!0});var Ra=s(ao);T(Kk.$$.fragment,Ra),ZYo=i(Ra),rMe=n(Ra,"P",{});var cJt=s(rMe);KYo=r(cJt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),cJt.forEach(t),eZo=i(Ra),gn=n(Ra,"P",{});var sx=s(gn);oZo=r(sx,"The model class to instantiate is selected based on the "),tMe=n(sx,"CODE",{});var fJt=s(tMe);rZo=r(fJt,"model_type"),fJt.forEach(t),tZo=r(sx,` property of the config object (either
passed as an argument or loaded from `),aMe=n(sx,"CODE",{});var gJt=s(aMe);aZo=r(gJt,"pretrained_model_name_or_path"),gJt.forEach(t),nZo=r(sx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nMe=n(sx,"CODE",{});var hJt=s(nMe);sZo=r(hJt,"pretrained_model_name_or_path"),hJt.forEach(t),lZo=r(sx,":"),sx.forEach(t),iZo=i(Ra),G=n(Ra,"UL",{});var V=s(G);Kb=n(V,"LI",{});var XQe=s(Kb);sMe=n(XQe,"STRONG",{});var uJt=s(sMe);dZo=r(uJt,"albert"),uJt.forEach(t),mZo=r(XQe," \u2014 "),JU=n(XQe,"A",{href:!0});var pJt=s(JU);cZo=r(pJt,"AlbertForPreTraining"),pJt.forEach(t),fZo=r(XQe," (ALBERT model)"),XQe.forEach(t),gZo=i(V),ev=n(V,"LI",{});var zQe=s(ev);lMe=n(zQe,"STRONG",{});var _Jt=s(lMe);hZo=r(_Jt,"bart"),_Jt.forEach(t),uZo=r(zQe," \u2014 "),YU=n(zQe,"A",{href:!0});var bJt=s(YU);pZo=r(bJt,"BartForConditionalGeneration"),bJt.forEach(t),_Zo=r(zQe," (BART model)"),zQe.forEach(t),bZo=i(V),ov=n(V,"LI",{});var QQe=s(ov);iMe=n(QQe,"STRONG",{});var vJt=s(iMe);vZo=r(vJt,"bert"),vJt.forEach(t),FZo=r(QQe," \u2014 "),ZU=n(QQe,"A",{href:!0});var FJt=s(ZU);TZo=r(FJt,"BertForPreTraining"),FJt.forEach(t),MZo=r(QQe," (BERT model)"),QQe.forEach(t),EZo=i(V),rv=n(V,"LI",{});var WQe=s(rv);dMe=n(WQe,"STRONG",{});var TJt=s(dMe);CZo=r(TJt,"big_bird"),TJt.forEach(t),wZo=r(WQe," \u2014 "),KU=n(WQe,"A",{href:!0});var MJt=s(KU);AZo=r(MJt,"BigBirdForPreTraining"),MJt.forEach(t),LZo=r(WQe," (BigBird model)"),WQe.forEach(t),yZo=i(V),tv=n(V,"LI",{});var UQe=s(tv);mMe=n(UQe,"STRONG",{});var EJt=s(mMe);xZo=r(EJt,"bloom"),EJt.forEach(t),$Zo=r(UQe," \u2014 "),eH=n(UQe,"A",{href:!0});var CJt=s(eH);kZo=r(CJt,"BloomForCausalLM"),CJt.forEach(t),SZo=r(UQe," (BLOOM model)"),UQe.forEach(t),RZo=i(V),av=n(V,"LI",{});var HQe=s(av);cMe=n(HQe,"STRONG",{});var wJt=s(cMe);PZo=r(wJt,"camembert"),wJt.forEach(t),BZo=r(HQe," \u2014 "),oH=n(HQe,"A",{href:!0});var AJt=s(oH);IZo=r(AJt,"CamembertForMaskedLM"),AJt.forEach(t),NZo=r(HQe," (CamemBERT model)"),HQe.forEach(t),qZo=i(V),nv=n(V,"LI",{});var JQe=s(nv);fMe=n(JQe,"STRONG",{});var LJt=s(fMe);DZo=r(LJt,"ctrl"),LJt.forEach(t),jZo=r(JQe," \u2014 "),rH=n(JQe,"A",{href:!0});var yJt=s(rH);GZo=r(yJt,"CTRLLMHeadModel"),yJt.forEach(t),OZo=r(JQe," (CTRL model)"),JQe.forEach(t),VZo=i(V),sv=n(V,"LI",{});var YQe=s(sv);gMe=n(YQe,"STRONG",{});var xJt=s(gMe);XZo=r(xJt,"data2vec-text"),xJt.forEach(t),zZo=r(YQe," \u2014 "),tH=n(YQe,"A",{href:!0});var $Jt=s(tH);QZo=r($Jt,"Data2VecTextForMaskedLM"),$Jt.forEach(t),WZo=r(YQe," (Data2VecText model)"),YQe.forEach(t),UZo=i(V),lv=n(V,"LI",{});var ZQe=s(lv);hMe=n(ZQe,"STRONG",{});var kJt=s(hMe);HZo=r(kJt,"deberta"),kJt.forEach(t),JZo=r(ZQe," \u2014 "),aH=n(ZQe,"A",{href:!0});var SJt=s(aH);YZo=r(SJt,"DebertaForMaskedLM"),SJt.forEach(t),ZZo=r(ZQe," (DeBERTa model)"),ZQe.forEach(t),KZo=i(V),iv=n(V,"LI",{});var KQe=s(iv);uMe=n(KQe,"STRONG",{});var RJt=s(uMe);eKo=r(RJt,"deberta-v2"),RJt.forEach(t),oKo=r(KQe," \u2014 "),nH=n(KQe,"A",{href:!0});var PJt=s(nH);rKo=r(PJt,"DebertaV2ForMaskedLM"),PJt.forEach(t),tKo=r(KQe," (DeBERTa-v2 model)"),KQe.forEach(t),aKo=i(V),dv=n(V,"LI",{});var eWe=s(dv);pMe=n(eWe,"STRONG",{});var BJt=s(pMe);nKo=r(BJt,"distilbert"),BJt.forEach(t),sKo=r(eWe," \u2014 "),sH=n(eWe,"A",{href:!0});var IJt=s(sH);lKo=r(IJt,"DistilBertForMaskedLM"),IJt.forEach(t),iKo=r(eWe," (DistilBERT model)"),eWe.forEach(t),dKo=i(V),mv=n(V,"LI",{});var oWe=s(mv);_Me=n(oWe,"STRONG",{});var NJt=s(_Me);mKo=r(NJt,"electra"),NJt.forEach(t),cKo=r(oWe," \u2014 "),lH=n(oWe,"A",{href:!0});var qJt=s(lH);fKo=r(qJt,"ElectraForPreTraining"),qJt.forEach(t),gKo=r(oWe," (ELECTRA model)"),oWe.forEach(t),hKo=i(V),cv=n(V,"LI",{});var rWe=s(cv);bMe=n(rWe,"STRONG",{});var DJt=s(bMe);uKo=r(DJt,"ernie"),DJt.forEach(t),pKo=r(rWe," \u2014 "),iH=n(rWe,"A",{href:!0});var jJt=s(iH);_Ko=r(jJt,"ErnieForPreTraining"),jJt.forEach(t),bKo=r(rWe," (ERNIE model)"),rWe.forEach(t),vKo=i(V),fv=n(V,"LI",{});var tWe=s(fv);vMe=n(tWe,"STRONG",{});var GJt=s(vMe);FKo=r(GJt,"flaubert"),GJt.forEach(t),TKo=r(tWe," \u2014 "),dH=n(tWe,"A",{href:!0});var OJt=s(dH);MKo=r(OJt,"FlaubertWithLMHeadModel"),OJt.forEach(t),EKo=r(tWe," (FlauBERT model)"),tWe.forEach(t),CKo=i(V),gv=n(V,"LI",{});var aWe=s(gv);FMe=n(aWe,"STRONG",{});var VJt=s(FMe);wKo=r(VJt,"flava"),VJt.forEach(t),AKo=r(aWe," \u2014 "),mH=n(aWe,"A",{href:!0});var XJt=s(mH);LKo=r(XJt,"FlavaForPreTraining"),XJt.forEach(t),yKo=r(aWe," (FLAVA model)"),aWe.forEach(t),xKo=i(V),hv=n(V,"LI",{});var nWe=s(hv);TMe=n(nWe,"STRONG",{});var zJt=s(TMe);$Ko=r(zJt,"fnet"),zJt.forEach(t),kKo=r(nWe," \u2014 "),cH=n(nWe,"A",{href:!0});var QJt=s(cH);SKo=r(QJt,"FNetForPreTraining"),QJt.forEach(t),RKo=r(nWe," (FNet model)"),nWe.forEach(t),PKo=i(V),uv=n(V,"LI",{});var sWe=s(uv);MMe=n(sWe,"STRONG",{});var WJt=s(MMe);BKo=r(WJt,"fsmt"),WJt.forEach(t),IKo=r(sWe," \u2014 "),fH=n(sWe,"A",{href:!0});var UJt=s(fH);NKo=r(UJt,"FSMTForConditionalGeneration"),UJt.forEach(t),qKo=r(sWe," (FairSeq Machine-Translation model)"),sWe.forEach(t),DKo=i(V),pv=n(V,"LI",{});var lWe=s(pv);EMe=n(lWe,"STRONG",{});var HJt=s(EMe);jKo=r(HJt,"funnel"),HJt.forEach(t),GKo=r(lWe," \u2014 "),gH=n(lWe,"A",{href:!0});var JJt=s(gH);OKo=r(JJt,"FunnelForPreTraining"),JJt.forEach(t),VKo=r(lWe," (Funnel Transformer model)"),lWe.forEach(t),XKo=i(V),_v=n(V,"LI",{});var iWe=s(_v);CMe=n(iWe,"STRONG",{});var YJt=s(CMe);zKo=r(YJt,"gpt2"),YJt.forEach(t),QKo=r(iWe," \u2014 "),hH=n(iWe,"A",{href:!0});var ZJt=s(hH);WKo=r(ZJt,"GPT2LMHeadModel"),ZJt.forEach(t),UKo=r(iWe," (OpenAI GPT-2 model)"),iWe.forEach(t),HKo=i(V),bv=n(V,"LI",{});var dWe=s(bv);wMe=n(dWe,"STRONG",{});var KJt=s(wMe);JKo=r(KJt,"ibert"),KJt.forEach(t),YKo=r(dWe," \u2014 "),uH=n(dWe,"A",{href:!0});var eYt=s(uH);ZKo=r(eYt,"IBertForMaskedLM"),eYt.forEach(t),KKo=r(dWe," (I-BERT model)"),dWe.forEach(t),eer=i(V),vv=n(V,"LI",{});var mWe=s(vv);AMe=n(mWe,"STRONG",{});var oYt=s(AMe);oer=r(oYt,"layoutlm"),oYt.forEach(t),rer=r(mWe," \u2014 "),pH=n(mWe,"A",{href:!0});var rYt=s(pH);ter=r(rYt,"LayoutLMForMaskedLM"),rYt.forEach(t),aer=r(mWe," (LayoutLM model)"),mWe.forEach(t),ner=i(V),Fv=n(V,"LI",{});var cWe=s(Fv);LMe=n(cWe,"STRONG",{});var tYt=s(LMe);ser=r(tYt,"longformer"),tYt.forEach(t),ler=r(cWe," \u2014 "),_H=n(cWe,"A",{href:!0});var aYt=s(_H);ier=r(aYt,"LongformerForMaskedLM"),aYt.forEach(t),der=r(cWe," (Longformer model)"),cWe.forEach(t),mer=i(V),Tv=n(V,"LI",{});var fWe=s(Tv);yMe=n(fWe,"STRONG",{});var nYt=s(yMe);cer=r(nYt,"luke"),nYt.forEach(t),fer=r(fWe," \u2014 "),bH=n(fWe,"A",{href:!0});var sYt=s(bH);ger=r(sYt,"LukeForMaskedLM"),sYt.forEach(t),her=r(fWe," (LUKE model)"),fWe.forEach(t),uer=i(V),Mv=n(V,"LI",{});var gWe=s(Mv);xMe=n(gWe,"STRONG",{});var lYt=s(xMe);per=r(lYt,"lxmert"),lYt.forEach(t),_er=r(gWe," \u2014 "),vH=n(gWe,"A",{href:!0});var iYt=s(vH);ber=r(iYt,"LxmertForPreTraining"),iYt.forEach(t),ver=r(gWe," (LXMERT model)"),gWe.forEach(t),Fer=i(V),Ev=n(V,"LI",{});var hWe=s(Ev);$Me=n(hWe,"STRONG",{});var dYt=s($Me);Ter=r(dYt,"megatron-bert"),dYt.forEach(t),Mer=r(hWe," \u2014 "),FH=n(hWe,"A",{href:!0});var mYt=s(FH);Eer=r(mYt,"MegatronBertForPreTraining"),mYt.forEach(t),Cer=r(hWe," (Megatron-BERT model)"),hWe.forEach(t),wer=i(V),Cv=n(V,"LI",{});var uWe=s(Cv);kMe=n(uWe,"STRONG",{});var cYt=s(kMe);Aer=r(cYt,"mobilebert"),cYt.forEach(t),Ler=r(uWe," \u2014 "),TH=n(uWe,"A",{href:!0});var fYt=s(TH);yer=r(fYt,"MobileBertForPreTraining"),fYt.forEach(t),xer=r(uWe," (MobileBERT model)"),uWe.forEach(t),$er=i(V),wv=n(V,"LI",{});var pWe=s(wv);SMe=n(pWe,"STRONG",{});var gYt=s(SMe);ker=r(gYt,"mpnet"),gYt.forEach(t),Ser=r(pWe," \u2014 "),MH=n(pWe,"A",{href:!0});var hYt=s(MH);Rer=r(hYt,"MPNetForMaskedLM"),hYt.forEach(t),Per=r(pWe," (MPNet model)"),pWe.forEach(t),Ber=i(V),Av=n(V,"LI",{});var _We=s(Av);RMe=n(_We,"STRONG",{});var uYt=s(RMe);Ier=r(uYt,"mvp"),uYt.forEach(t),Ner=r(_We," \u2014 "),EH=n(_We,"A",{href:!0});var pYt=s(EH);qer=r(pYt,"MvpForConditionalGeneration"),pYt.forEach(t),Der=r(_We," (MVP model)"),_We.forEach(t),jer=i(V),Lv=n(V,"LI",{});var bWe=s(Lv);PMe=n(bWe,"STRONG",{});var _Yt=s(PMe);Ger=r(_Yt,"nezha"),_Yt.forEach(t),Oer=r(bWe," \u2014 "),CH=n(bWe,"A",{href:!0});var bYt=s(CH);Ver=r(bYt,"NezhaForPreTraining"),bYt.forEach(t),Xer=r(bWe," (Nezha model)"),bWe.forEach(t),zer=i(V),yv=n(V,"LI",{});var vWe=s(yv);BMe=n(vWe,"STRONG",{});var vYt=s(BMe);Qer=r(vYt,"openai-gpt"),vYt.forEach(t),Wer=r(vWe," \u2014 "),wH=n(vWe,"A",{href:!0});var FYt=s(wH);Uer=r(FYt,"OpenAIGPTLMHeadModel"),FYt.forEach(t),Her=r(vWe," (OpenAI GPT model)"),vWe.forEach(t),Jer=i(V),xv=n(V,"LI",{});var FWe=s(xv);IMe=n(FWe,"STRONG",{});var TYt=s(IMe);Yer=r(TYt,"retribert"),TYt.forEach(t),Zer=r(FWe," \u2014 "),AH=n(FWe,"A",{href:!0});var MYt=s(AH);Ker=r(MYt,"RetriBertModel"),MYt.forEach(t),eor=r(FWe," (RetriBERT model)"),FWe.forEach(t),oor=i(V),$v=n(V,"LI",{});var TWe=s($v);NMe=n(TWe,"STRONG",{});var EYt=s(NMe);ror=r(EYt,"roberta"),EYt.forEach(t),tor=r(TWe," \u2014 "),LH=n(TWe,"A",{href:!0});var CYt=s(LH);aor=r(CYt,"RobertaForMaskedLM"),CYt.forEach(t),nor=r(TWe," (RoBERTa model)"),TWe.forEach(t),sor=i(V),kv=n(V,"LI",{});var MWe=s(kv);qMe=n(MWe,"STRONG",{});var wYt=s(qMe);lor=r(wYt,"roc_bert"),wYt.forEach(t),ior=r(MWe," \u2014 "),yH=n(MWe,"A",{href:!0});var AYt=s(yH);dor=r(AYt,"RoCBertForPreTraining"),AYt.forEach(t),mor=r(MWe," (RoCBert model)"),MWe.forEach(t),cor=i(V),Sv=n(V,"LI",{});var EWe=s(Sv);DMe=n(EWe,"STRONG",{});var LYt=s(DMe);gor=r(LYt,"splinter"),LYt.forEach(t),hor=r(EWe," \u2014 "),xH=n(EWe,"A",{href:!0});var yYt=s(xH);uor=r(yYt,"SplinterForPreTraining"),yYt.forEach(t),por=r(EWe," (Splinter model)"),EWe.forEach(t),_or=i(V),Rv=n(V,"LI",{});var CWe=s(Rv);jMe=n(CWe,"STRONG",{});var xYt=s(jMe);bor=r(xYt,"squeezebert"),xYt.forEach(t),vor=r(CWe," \u2014 "),$H=n(CWe,"A",{href:!0});var $Yt=s($H);For=r($Yt,"SqueezeBertForMaskedLM"),$Yt.forEach(t),Tor=r(CWe," (SqueezeBERT model)"),CWe.forEach(t),Mor=i(V),Pv=n(V,"LI",{});var wWe=s(Pv);GMe=n(wWe,"STRONG",{});var kYt=s(GMe);Eor=r(kYt,"t5"),kYt.forEach(t),Cor=r(wWe," \u2014 "),kH=n(wWe,"A",{href:!0});var SYt=s(kH);wor=r(SYt,"T5ForConditionalGeneration"),SYt.forEach(t),Aor=r(wWe," (T5 model)"),wWe.forEach(t),Lor=i(V),Bv=n(V,"LI",{});var AWe=s(Bv);OMe=n(AWe,"STRONG",{});var RYt=s(OMe);yor=r(RYt,"tapas"),RYt.forEach(t),xor=r(AWe," \u2014 "),SH=n(AWe,"A",{href:!0});var PYt=s(SH);$or=r(PYt,"TapasForMaskedLM"),PYt.forEach(t),kor=r(AWe," (TAPAS model)"),AWe.forEach(t),Sor=i(V),Iv=n(V,"LI",{});var LWe=s(Iv);VMe=n(LWe,"STRONG",{});var BYt=s(VMe);Ror=r(BYt,"transfo-xl"),BYt.forEach(t),Por=r(LWe," \u2014 "),RH=n(LWe,"A",{href:!0});var IYt=s(RH);Bor=r(IYt,"TransfoXLLMHeadModel"),IYt.forEach(t),Ior=r(LWe," (Transformer-XL model)"),LWe.forEach(t),Nor=i(V),Nv=n(V,"LI",{});var yWe=s(Nv);XMe=n(yWe,"STRONG",{});var NYt=s(XMe);qor=r(NYt,"unispeech"),NYt.forEach(t),Dor=r(yWe," \u2014 "),PH=n(yWe,"A",{href:!0});var qYt=s(PH);jor=r(qYt,"UniSpeechForPreTraining"),qYt.forEach(t),Gor=r(yWe," (UniSpeech model)"),yWe.forEach(t),Oor=i(V),qv=n(V,"LI",{});var xWe=s(qv);zMe=n(xWe,"STRONG",{});var DYt=s(zMe);Vor=r(DYt,"unispeech-sat"),DYt.forEach(t),Xor=r(xWe," \u2014 "),BH=n(xWe,"A",{href:!0});var jYt=s(BH);zor=r(jYt,"UniSpeechSatForPreTraining"),jYt.forEach(t),Qor=r(xWe," (UniSpeechSat model)"),xWe.forEach(t),Wor=i(V),Dv=n(V,"LI",{});var $We=s(Dv);QMe=n($We,"STRONG",{});var GYt=s(QMe);Uor=r(GYt,"videomae"),GYt.forEach(t),Hor=r($We," \u2014 "),IH=n($We,"A",{href:!0});var OYt=s(IH);Jor=r(OYt,"VideoMAEForPreTraining"),OYt.forEach(t),Yor=r($We," (VideoMAE model)"),$We.forEach(t),Zor=i(V),jv=n(V,"LI",{});var kWe=s(jv);WMe=n(kWe,"STRONG",{});var VYt=s(WMe);Kor=r(VYt,"visual_bert"),VYt.forEach(t),err=r(kWe," \u2014 "),NH=n(kWe,"A",{href:!0});var XYt=s(NH);orr=r(XYt,"VisualBertForPreTraining"),XYt.forEach(t),rrr=r(kWe," (VisualBERT model)"),kWe.forEach(t),trr=i(V),Gv=n(V,"LI",{});var SWe=s(Gv);UMe=n(SWe,"STRONG",{});var zYt=s(UMe);arr=r(zYt,"vit_mae"),zYt.forEach(t),nrr=r(SWe," \u2014 "),qH=n(SWe,"A",{href:!0});var QYt=s(qH);srr=r(QYt,"ViTMAEForPreTraining"),QYt.forEach(t),lrr=r(SWe," (ViTMAE model)"),SWe.forEach(t),irr=i(V),Ov=n(V,"LI",{});var RWe=s(Ov);HMe=n(RWe,"STRONG",{});var WYt=s(HMe);drr=r(WYt,"wav2vec2"),WYt.forEach(t),mrr=r(RWe," \u2014 "),DH=n(RWe,"A",{href:!0});var UYt=s(DH);crr=r(UYt,"Wav2Vec2ForPreTraining"),UYt.forEach(t),frr=r(RWe," (Wav2Vec2 model)"),RWe.forEach(t),grr=i(V),Vv=n(V,"LI",{});var PWe=s(Vv);JMe=n(PWe,"STRONG",{});var HYt=s(JMe);hrr=r(HYt,"wav2vec2-conformer"),HYt.forEach(t),urr=r(PWe," \u2014 "),jH=n(PWe,"A",{href:!0});var JYt=s(jH);prr=r(JYt,"Wav2Vec2ConformerForPreTraining"),JYt.forEach(t),_rr=r(PWe," (Wav2Vec2-Conformer model)"),PWe.forEach(t),brr=i(V),Xv=n(V,"LI",{});var BWe=s(Xv);YMe=n(BWe,"STRONG",{});var YYt=s(YMe);vrr=r(YYt,"xlm"),YYt.forEach(t),Frr=r(BWe," \u2014 "),GH=n(BWe,"A",{href:!0});var ZYt=s(GH);Trr=r(ZYt,"XLMWithLMHeadModel"),ZYt.forEach(t),Mrr=r(BWe," (XLM model)"),BWe.forEach(t),Err=i(V),zv=n(V,"LI",{});var IWe=s(zv);ZMe=n(IWe,"STRONG",{});var KYt=s(ZMe);Crr=r(KYt,"xlm-roberta"),KYt.forEach(t),wrr=r(IWe," \u2014 "),OH=n(IWe,"A",{href:!0});var eZt=s(OH);Arr=r(eZt,"XLMRobertaForMaskedLM"),eZt.forEach(t),Lrr=r(IWe," (XLM-RoBERTa model)"),IWe.forEach(t),yrr=i(V),Qv=n(V,"LI",{});var NWe=s(Qv);KMe=n(NWe,"STRONG",{});var oZt=s(KMe);xrr=r(oZt,"xlm-roberta-xl"),oZt.forEach(t),$rr=r(NWe," \u2014 "),VH=n(NWe,"A",{href:!0});var rZt=s(VH);krr=r(rZt,"XLMRobertaXLForMaskedLM"),rZt.forEach(t),Srr=r(NWe," (XLM-RoBERTa-XL model)"),NWe.forEach(t),Rrr=i(V),Wv=n(V,"LI",{});var qWe=s(Wv);eEe=n(qWe,"STRONG",{});var tZt=s(eEe);Prr=r(tZt,"xlnet"),tZt.forEach(t),Brr=r(qWe," \u2014 "),XH=n(qWe,"A",{href:!0});var aZt=s(XH);Irr=r(aZt,"XLNetLMHeadModel"),aZt.forEach(t),Nrr=r(qWe," (XLNet model)"),qWe.forEach(t),V.forEach(t),qrr=i(Ra),Uv=n(Ra,"P",{});var DWe=s(Uv);Drr=r(DWe,"The model is set in evaluation mode by default using "),oEe=n(DWe,"CODE",{});var nZt=s(oEe);jrr=r(nZt,"model.eval()"),nZt.forEach(t),Grr=r(DWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),rEe=n(DWe,"CODE",{});var sZt=s(rEe);Orr=r(sZt,"model.train()"),sZt.forEach(t),DWe.forEach(t),Vrr=i(Ra),T(Hv.$$.fragment,Ra),Ra.forEach(t),Wl.forEach(t),Blo=i(c),Wd=n(c,"H2",{class:!0});var tmo=s(Wd);Jv=n(tmo,"A",{id:!0,class:!0,href:!0});var lZt=s(Jv);tEe=n(lZt,"SPAN",{});var iZt=s(tEe);T(eS.$$.fragment,iZt),iZt.forEach(t),lZt.forEach(t),Xrr=i(tmo),aEe=n(tmo,"SPAN",{});var dZt=s(aEe);zrr=r(dZt,"AutoModelForCausalLM"),dZt.forEach(t),tmo.forEach(t),Ilo=i(c),Oo=n(c,"DIV",{class:!0});var Ul=s(Oo);T(oS.$$.fragment,Ul),Qrr=i(Ul),Ud=n(Ul,"P",{});var mfe=s(Ud);Wrr=r(mfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),zH=n(mfe,"A",{href:!0});var mZt=s(zH);Urr=r(mZt,"from_pretrained()"),mZt.forEach(t),Hrr=r(mfe," class method or the "),QH=n(mfe,"A",{href:!0});var cZt=s(QH);Jrr=r(cZt,"from_config()"),cZt.forEach(t),Yrr=r(mfe,` class
method.`),mfe.forEach(t),Zrr=i(Ul),rS=n(Ul,"P",{});var amo=s(rS);Krr=r(amo,"This class cannot be instantiated directly using "),nEe=n(amo,"CODE",{});var fZt=s(nEe);etr=r(fZt,"__init__()"),fZt.forEach(t),otr=r(amo," (throws an error)."),amo.forEach(t),rtr=i(Ul),yt=n(Ul,"DIV",{class:!0});var lx=s(yt);T(tS.$$.fragment,lx),ttr=i(lx),sEe=n(lx,"P",{});var gZt=s(sEe);atr=r(gZt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),gZt.forEach(t),ntr=i(lx),Hd=n(lx,"P",{});var cfe=s(Hd);str=r(cfe,`Note:
Loading a model from its configuration file does `),lEe=n(cfe,"STRONG",{});var hZt=s(lEe);ltr=r(hZt,"not"),hZt.forEach(t),itr=r(cfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),WH=n(cfe,"A",{href:!0});var uZt=s(WH);dtr=r(uZt,"from_pretrained()"),uZt.forEach(t),mtr=r(cfe," to load the model weights."),cfe.forEach(t),ctr=i(lx),T(Yv.$$.fragment,lx),lx.forEach(t),ftr=i(Ul),no=n(Ul,"DIV",{class:!0});var Pa=s(no);T(aS.$$.fragment,Pa),gtr=i(Pa),iEe=n(Pa,"P",{});var pZt=s(iEe);htr=r(pZt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),pZt.forEach(t),utr=i(Pa),hn=n(Pa,"P",{});var ix=s(hn);ptr=r(ix,"The model class to instantiate is selected based on the "),dEe=n(ix,"CODE",{});var _Zt=s(dEe);_tr=r(_Zt,"model_type"),_Zt.forEach(t),btr=r(ix,` property of the config object (either
passed as an argument or loaded from `),mEe=n(ix,"CODE",{});var bZt=s(mEe);vtr=r(bZt,"pretrained_model_name_or_path"),bZt.forEach(t),Ftr=r(ix,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cEe=n(ix,"CODE",{});var vZt=s(cEe);Ttr=r(vZt,"pretrained_model_name_or_path"),vZt.forEach(t),Mtr=r(ix,":"),ix.forEach(t),Etr=i(Pa),W=n(Pa,"UL",{});var H=s(W);Zv=n(H,"LI",{});var jWe=s(Zv);fEe=n(jWe,"STRONG",{});var FZt=s(fEe);Ctr=r(FZt,"bart"),FZt.forEach(t),wtr=r(jWe," \u2014 "),UH=n(jWe,"A",{href:!0});var TZt=s(UH);Atr=r(TZt,"BartForCausalLM"),TZt.forEach(t),Ltr=r(jWe," (BART model)"),jWe.forEach(t),ytr=i(H),Kv=n(H,"LI",{});var GWe=s(Kv);gEe=n(GWe,"STRONG",{});var MZt=s(gEe);xtr=r(MZt,"bert"),MZt.forEach(t),$tr=r(GWe," \u2014 "),HH=n(GWe,"A",{href:!0});var EZt=s(HH);ktr=r(EZt,"BertLMHeadModel"),EZt.forEach(t),Str=r(GWe," (BERT model)"),GWe.forEach(t),Rtr=i(H),eF=n(H,"LI",{});var OWe=s(eF);hEe=n(OWe,"STRONG",{});var CZt=s(hEe);Ptr=r(CZt,"bert-generation"),CZt.forEach(t),Btr=r(OWe," \u2014 "),JH=n(OWe,"A",{href:!0});var wZt=s(JH);Itr=r(wZt,"BertGenerationDecoder"),wZt.forEach(t),Ntr=r(OWe," (Bert Generation model)"),OWe.forEach(t),qtr=i(H),oF=n(H,"LI",{});var VWe=s(oF);uEe=n(VWe,"STRONG",{});var AZt=s(uEe);Dtr=r(AZt,"big_bird"),AZt.forEach(t),jtr=r(VWe," \u2014 "),YH=n(VWe,"A",{href:!0});var LZt=s(YH);Gtr=r(LZt,"BigBirdForCausalLM"),LZt.forEach(t),Otr=r(VWe," (BigBird model)"),VWe.forEach(t),Vtr=i(H),rF=n(H,"LI",{});var XWe=s(rF);pEe=n(XWe,"STRONG",{});var yZt=s(pEe);Xtr=r(yZt,"bigbird_pegasus"),yZt.forEach(t),ztr=r(XWe," \u2014 "),ZH=n(XWe,"A",{href:!0});var xZt=s(ZH);Qtr=r(xZt,"BigBirdPegasusForCausalLM"),xZt.forEach(t),Wtr=r(XWe," (BigBird-Pegasus model)"),XWe.forEach(t),Utr=i(H),tF=n(H,"LI",{});var zWe=s(tF);_Ee=n(zWe,"STRONG",{});var $Zt=s(_Ee);Htr=r($Zt,"blenderbot"),$Zt.forEach(t),Jtr=r(zWe," \u2014 "),KH=n(zWe,"A",{href:!0});var kZt=s(KH);Ytr=r(kZt,"BlenderbotForCausalLM"),kZt.forEach(t),Ztr=r(zWe," (Blenderbot model)"),zWe.forEach(t),Ktr=i(H),aF=n(H,"LI",{});var QWe=s(aF);bEe=n(QWe,"STRONG",{});var SZt=s(bEe);ear=r(SZt,"blenderbot-small"),SZt.forEach(t),oar=r(QWe," \u2014 "),eJ=n(QWe,"A",{href:!0});var RZt=s(eJ);rar=r(RZt,"BlenderbotSmallForCausalLM"),RZt.forEach(t),tar=r(QWe," (BlenderbotSmall model)"),QWe.forEach(t),aar=i(H),nF=n(H,"LI",{});var WWe=s(nF);vEe=n(WWe,"STRONG",{});var PZt=s(vEe);nar=r(PZt,"bloom"),PZt.forEach(t),sar=r(WWe," \u2014 "),oJ=n(WWe,"A",{href:!0});var BZt=s(oJ);lar=r(BZt,"BloomForCausalLM"),BZt.forEach(t),iar=r(WWe," (BLOOM model)"),WWe.forEach(t),dar=i(H),sF=n(H,"LI",{});var UWe=s(sF);FEe=n(UWe,"STRONG",{});var IZt=s(FEe);mar=r(IZt,"camembert"),IZt.forEach(t),car=r(UWe," \u2014 "),rJ=n(UWe,"A",{href:!0});var NZt=s(rJ);far=r(NZt,"CamembertForCausalLM"),NZt.forEach(t),gar=r(UWe," (CamemBERT model)"),UWe.forEach(t),har=i(H),lF=n(H,"LI",{});var HWe=s(lF);TEe=n(HWe,"STRONG",{});var qZt=s(TEe);uar=r(qZt,"codegen"),qZt.forEach(t),par=r(HWe," \u2014 "),tJ=n(HWe,"A",{href:!0});var DZt=s(tJ);_ar=r(DZt,"CodeGenForCausalLM"),DZt.forEach(t),bar=r(HWe," (CodeGen model)"),HWe.forEach(t),Far=i(H),iF=n(H,"LI",{});var JWe=s(iF);MEe=n(JWe,"STRONG",{});var jZt=s(MEe);Tar=r(jZt,"ctrl"),jZt.forEach(t),Mar=r(JWe," \u2014 "),aJ=n(JWe,"A",{href:!0});var GZt=s(aJ);Ear=r(GZt,"CTRLLMHeadModel"),GZt.forEach(t),Car=r(JWe," (CTRL model)"),JWe.forEach(t),war=i(H),dF=n(H,"LI",{});var YWe=s(dF);EEe=n(YWe,"STRONG",{});var OZt=s(EEe);Aar=r(OZt,"data2vec-text"),OZt.forEach(t),Lar=r(YWe," \u2014 "),nJ=n(YWe,"A",{href:!0});var VZt=s(nJ);yar=r(VZt,"Data2VecTextForCausalLM"),VZt.forEach(t),xar=r(YWe," (Data2VecText model)"),YWe.forEach(t),$ar=i(H),mF=n(H,"LI",{});var ZWe=s(mF);CEe=n(ZWe,"STRONG",{});var XZt=s(CEe);kar=r(XZt,"electra"),XZt.forEach(t),Sar=r(ZWe," \u2014 "),sJ=n(ZWe,"A",{href:!0});var zZt=s(sJ);Rar=r(zZt,"ElectraForCausalLM"),zZt.forEach(t),Par=r(ZWe," (ELECTRA model)"),ZWe.forEach(t),Bar=i(H),cF=n(H,"LI",{});var KWe=s(cF);wEe=n(KWe,"STRONG",{});var QZt=s(wEe);Iar=r(QZt,"ernie"),QZt.forEach(t),Nar=r(KWe," \u2014 "),lJ=n(KWe,"A",{href:!0});var WZt=s(lJ);qar=r(WZt,"ErnieForCausalLM"),WZt.forEach(t),Dar=r(KWe," (ERNIE model)"),KWe.forEach(t),jar=i(H),fF=n(H,"LI",{});var eUe=s(fF);AEe=n(eUe,"STRONG",{});var UZt=s(AEe);Gar=r(UZt,"gpt2"),UZt.forEach(t),Oar=r(eUe," \u2014 "),iJ=n(eUe,"A",{href:!0});var HZt=s(iJ);Var=r(HZt,"GPT2LMHeadModel"),HZt.forEach(t),Xar=r(eUe," (OpenAI GPT-2 model)"),eUe.forEach(t),zar=i(H),gF=n(H,"LI",{});var oUe=s(gF);LEe=n(oUe,"STRONG",{});var JZt=s(LEe);Qar=r(JZt,"gpt_neo"),JZt.forEach(t),War=r(oUe," \u2014 "),dJ=n(oUe,"A",{href:!0});var YZt=s(dJ);Uar=r(YZt,"GPTNeoForCausalLM"),YZt.forEach(t),Har=r(oUe," (GPT Neo model)"),oUe.forEach(t),Jar=i(H),hF=n(H,"LI",{});var rUe=s(hF);yEe=n(rUe,"STRONG",{});var ZZt=s(yEe);Yar=r(ZZt,"gpt_neox"),ZZt.forEach(t),Zar=r(rUe," \u2014 "),mJ=n(rUe,"A",{href:!0});var KZt=s(mJ);Kar=r(KZt,"GPTNeoXForCausalLM"),KZt.forEach(t),enr=r(rUe," (GPT NeoX model)"),rUe.forEach(t),onr=i(H),uF=n(H,"LI",{});var tUe=s(uF);xEe=n(tUe,"STRONG",{});var eKt=s(xEe);rnr=r(eKt,"gpt_neox_japanese"),eKt.forEach(t),tnr=r(tUe," \u2014 "),cJ=n(tUe,"A",{href:!0});var oKt=s(cJ);anr=r(oKt,"GPTNeoXJapaneseForCausalLM"),oKt.forEach(t),nnr=r(tUe," (GPT NeoX Japanese model)"),tUe.forEach(t),snr=i(H),pF=n(H,"LI",{});var aUe=s(pF);$Ee=n(aUe,"STRONG",{});var rKt=s($Ee);lnr=r(rKt,"gptj"),rKt.forEach(t),inr=r(aUe," \u2014 "),fJ=n(aUe,"A",{href:!0});var tKt=s(fJ);dnr=r(tKt,"GPTJForCausalLM"),tKt.forEach(t),mnr=r(aUe," (GPT-J model)"),aUe.forEach(t),cnr=i(H),_F=n(H,"LI",{});var nUe=s(_F);kEe=n(nUe,"STRONG",{});var aKt=s(kEe);fnr=r(aKt,"marian"),aKt.forEach(t),gnr=r(nUe," \u2014 "),gJ=n(nUe,"A",{href:!0});var nKt=s(gJ);hnr=r(nKt,"MarianForCausalLM"),nKt.forEach(t),unr=r(nUe," (Marian model)"),nUe.forEach(t),pnr=i(H),bF=n(H,"LI",{});var sUe=s(bF);SEe=n(sUe,"STRONG",{});var sKt=s(SEe);_nr=r(sKt,"mbart"),sKt.forEach(t),bnr=r(sUe," \u2014 "),hJ=n(sUe,"A",{href:!0});var lKt=s(hJ);vnr=r(lKt,"MBartForCausalLM"),lKt.forEach(t),Fnr=r(sUe," (mBART model)"),sUe.forEach(t),Tnr=i(H),vF=n(H,"LI",{});var lUe=s(vF);REe=n(lUe,"STRONG",{});var iKt=s(REe);Mnr=r(iKt,"megatron-bert"),iKt.forEach(t),Enr=r(lUe," \u2014 "),uJ=n(lUe,"A",{href:!0});var dKt=s(uJ);Cnr=r(dKt,"MegatronBertForCausalLM"),dKt.forEach(t),wnr=r(lUe," (Megatron-BERT model)"),lUe.forEach(t),Anr=i(H),FF=n(H,"LI",{});var iUe=s(FF);PEe=n(iUe,"STRONG",{});var mKt=s(PEe);Lnr=r(mKt,"mvp"),mKt.forEach(t),ynr=r(iUe," \u2014 "),pJ=n(iUe,"A",{href:!0});var cKt=s(pJ);xnr=r(cKt,"MvpForCausalLM"),cKt.forEach(t),$nr=r(iUe," (MVP model)"),iUe.forEach(t),knr=i(H),TF=n(H,"LI",{});var dUe=s(TF);BEe=n(dUe,"STRONG",{});var fKt=s(BEe);Snr=r(fKt,"openai-gpt"),fKt.forEach(t),Rnr=r(dUe," \u2014 "),_J=n(dUe,"A",{href:!0});var gKt=s(_J);Pnr=r(gKt,"OpenAIGPTLMHeadModel"),gKt.forEach(t),Bnr=r(dUe," (OpenAI GPT model)"),dUe.forEach(t),Inr=i(H),MF=n(H,"LI",{});var mUe=s(MF);IEe=n(mUe,"STRONG",{});var hKt=s(IEe);Nnr=r(hKt,"opt"),hKt.forEach(t),qnr=r(mUe," \u2014 "),bJ=n(mUe,"A",{href:!0});var uKt=s(bJ);Dnr=r(uKt,"OPTForCausalLM"),uKt.forEach(t),jnr=r(mUe," (OPT model)"),mUe.forEach(t),Gnr=i(H),EF=n(H,"LI",{});var cUe=s(EF);NEe=n(cUe,"STRONG",{});var pKt=s(NEe);Onr=r(pKt,"pegasus"),pKt.forEach(t),Vnr=r(cUe," \u2014 "),vJ=n(cUe,"A",{href:!0});var _Kt=s(vJ);Xnr=r(_Kt,"PegasusForCausalLM"),_Kt.forEach(t),znr=r(cUe," (Pegasus model)"),cUe.forEach(t),Qnr=i(H),CF=n(H,"LI",{});var fUe=s(CF);qEe=n(fUe,"STRONG",{});var bKt=s(qEe);Wnr=r(bKt,"plbart"),bKt.forEach(t),Unr=r(fUe," \u2014 "),FJ=n(fUe,"A",{href:!0});var vKt=s(FJ);Hnr=r(vKt,"PLBartForCausalLM"),vKt.forEach(t),Jnr=r(fUe," (PLBart model)"),fUe.forEach(t),Ynr=i(H),wF=n(H,"LI",{});var gUe=s(wF);DEe=n(gUe,"STRONG",{});var FKt=s(DEe);Znr=r(FKt,"prophetnet"),FKt.forEach(t),Knr=r(gUe," \u2014 "),TJ=n(gUe,"A",{href:!0});var TKt=s(TJ);esr=r(TKt,"ProphetNetForCausalLM"),TKt.forEach(t),osr=r(gUe," (ProphetNet model)"),gUe.forEach(t),rsr=i(H),AF=n(H,"LI",{});var hUe=s(AF);jEe=n(hUe,"STRONG",{});var MKt=s(jEe);tsr=r(MKt,"qdqbert"),MKt.forEach(t),asr=r(hUe," \u2014 "),MJ=n(hUe,"A",{href:!0});var EKt=s(MJ);nsr=r(EKt,"QDQBertLMHeadModel"),EKt.forEach(t),ssr=r(hUe," (QDQBert model)"),hUe.forEach(t),lsr=i(H),LF=n(H,"LI",{});var uUe=s(LF);GEe=n(uUe,"STRONG",{});var CKt=s(GEe);isr=r(CKt,"reformer"),CKt.forEach(t),dsr=r(uUe," \u2014 "),EJ=n(uUe,"A",{href:!0});var wKt=s(EJ);msr=r(wKt,"ReformerModelWithLMHead"),wKt.forEach(t),csr=r(uUe," (Reformer model)"),uUe.forEach(t),fsr=i(H),yF=n(H,"LI",{});var pUe=s(yF);OEe=n(pUe,"STRONG",{});var AKt=s(OEe);gsr=r(AKt,"rembert"),AKt.forEach(t),hsr=r(pUe," \u2014 "),CJ=n(pUe,"A",{href:!0});var LKt=s(CJ);usr=r(LKt,"RemBertForCausalLM"),LKt.forEach(t),psr=r(pUe," (RemBERT model)"),pUe.forEach(t),_sr=i(H),xF=n(H,"LI",{});var _Ue=s(xF);VEe=n(_Ue,"STRONG",{});var yKt=s(VEe);bsr=r(yKt,"roberta"),yKt.forEach(t),vsr=r(_Ue," \u2014 "),wJ=n(_Ue,"A",{href:!0});var xKt=s(wJ);Fsr=r(xKt,"RobertaForCausalLM"),xKt.forEach(t),Tsr=r(_Ue," (RoBERTa model)"),_Ue.forEach(t),Msr=i(H),$F=n(H,"LI",{});var bUe=s($F);XEe=n(bUe,"STRONG",{});var $Kt=s(XEe);Esr=r($Kt,"roc_bert"),$Kt.forEach(t),Csr=r(bUe," \u2014 "),AJ=n(bUe,"A",{href:!0});var kKt=s(AJ);wsr=r(kKt,"RoCBertForCausalLM"),kKt.forEach(t),Asr=r(bUe," (RoCBert model)"),bUe.forEach(t),Lsr=i(H),kF=n(H,"LI",{});var vUe=s(kF);zEe=n(vUe,"STRONG",{});var SKt=s(zEe);ysr=r(SKt,"roformer"),SKt.forEach(t),xsr=r(vUe," \u2014 "),LJ=n(vUe,"A",{href:!0});var RKt=s(LJ);$sr=r(RKt,"RoFormerForCausalLM"),RKt.forEach(t),ksr=r(vUe," (RoFormer model)"),vUe.forEach(t),Ssr=i(H),SF=n(H,"LI",{});var FUe=s(SF);QEe=n(FUe,"STRONG",{});var PKt=s(QEe);Rsr=r(PKt,"speech_to_text_2"),PKt.forEach(t),Psr=r(FUe," \u2014 "),yJ=n(FUe,"A",{href:!0});var BKt=s(yJ);Bsr=r(BKt,"Speech2Text2ForCausalLM"),BKt.forEach(t),Isr=r(FUe," (Speech2Text2 model)"),FUe.forEach(t),Nsr=i(H),RF=n(H,"LI",{});var TUe=s(RF);WEe=n(TUe,"STRONG",{});var IKt=s(WEe);qsr=r(IKt,"transfo-xl"),IKt.forEach(t),Dsr=r(TUe," \u2014 "),xJ=n(TUe,"A",{href:!0});var NKt=s(xJ);jsr=r(NKt,"TransfoXLLMHeadModel"),NKt.forEach(t),Gsr=r(TUe," (Transformer-XL model)"),TUe.forEach(t),Osr=i(H),PF=n(H,"LI",{});var MUe=s(PF);UEe=n(MUe,"STRONG",{});var qKt=s(UEe);Vsr=r(qKt,"trocr"),qKt.forEach(t),Xsr=r(MUe," \u2014 "),$J=n(MUe,"A",{href:!0});var DKt=s($J);zsr=r(DKt,"TrOCRForCausalLM"),DKt.forEach(t),Qsr=r(MUe," (TrOCR model)"),MUe.forEach(t),Wsr=i(H),BF=n(H,"LI",{});var EUe=s(BF);HEe=n(EUe,"STRONG",{});var jKt=s(HEe);Usr=r(jKt,"xglm"),jKt.forEach(t),Hsr=r(EUe," \u2014 "),kJ=n(EUe,"A",{href:!0});var GKt=s(kJ);Jsr=r(GKt,"XGLMForCausalLM"),GKt.forEach(t),Ysr=r(EUe," (XGLM model)"),EUe.forEach(t),Zsr=i(H),IF=n(H,"LI",{});var CUe=s(IF);JEe=n(CUe,"STRONG",{});var OKt=s(JEe);Ksr=r(OKt,"xlm"),OKt.forEach(t),elr=r(CUe," \u2014 "),SJ=n(CUe,"A",{href:!0});var VKt=s(SJ);olr=r(VKt,"XLMWithLMHeadModel"),VKt.forEach(t),rlr=r(CUe," (XLM model)"),CUe.forEach(t),tlr=i(H),NF=n(H,"LI",{});var wUe=s(NF);YEe=n(wUe,"STRONG",{});var XKt=s(YEe);alr=r(XKt,"xlm-prophetnet"),XKt.forEach(t),nlr=r(wUe," \u2014 "),RJ=n(wUe,"A",{href:!0});var zKt=s(RJ);slr=r(zKt,"XLMProphetNetForCausalLM"),zKt.forEach(t),llr=r(wUe," (XLM-ProphetNet model)"),wUe.forEach(t),ilr=i(H),qF=n(H,"LI",{});var AUe=s(qF);ZEe=n(AUe,"STRONG",{});var QKt=s(ZEe);dlr=r(QKt,"xlm-roberta"),QKt.forEach(t),mlr=r(AUe," \u2014 "),PJ=n(AUe,"A",{href:!0});var WKt=s(PJ);clr=r(WKt,"XLMRobertaForCausalLM"),WKt.forEach(t),flr=r(AUe," (XLM-RoBERTa model)"),AUe.forEach(t),glr=i(H),DF=n(H,"LI",{});var LUe=s(DF);KEe=n(LUe,"STRONG",{});var UKt=s(KEe);hlr=r(UKt,"xlm-roberta-xl"),UKt.forEach(t),ulr=r(LUe," \u2014 "),BJ=n(LUe,"A",{href:!0});var HKt=s(BJ);plr=r(HKt,"XLMRobertaXLForCausalLM"),HKt.forEach(t),_lr=r(LUe," (XLM-RoBERTa-XL model)"),LUe.forEach(t),blr=i(H),jF=n(H,"LI",{});var yUe=s(jF);e4e=n(yUe,"STRONG",{});var JKt=s(e4e);vlr=r(JKt,"xlnet"),JKt.forEach(t),Flr=r(yUe," \u2014 "),IJ=n(yUe,"A",{href:!0});var YKt=s(IJ);Tlr=r(YKt,"XLNetLMHeadModel"),YKt.forEach(t),Mlr=r(yUe," (XLNet model)"),yUe.forEach(t),H.forEach(t),Elr=i(Pa),GF=n(Pa,"P",{});var xUe=s(GF);Clr=r(xUe,"The model is set in evaluation mode by default using "),o4e=n(xUe,"CODE",{});var ZKt=s(o4e);wlr=r(ZKt,"model.eval()"),ZKt.forEach(t),Alr=r(xUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),r4e=n(xUe,"CODE",{});var KKt=s(r4e);Llr=r(KKt,"model.train()"),KKt.forEach(t),xUe.forEach(t),ylr=i(Pa),T(OF.$$.fragment,Pa),Pa.forEach(t),Ul.forEach(t),Nlo=i(c),Jd=n(c,"H2",{class:!0});var nmo=s(Jd);VF=n(nmo,"A",{id:!0,class:!0,href:!0});var eea=s(VF);t4e=n(eea,"SPAN",{});var oea=s(t4e);T(nS.$$.fragment,oea),oea.forEach(t),eea.forEach(t),xlr=i(nmo),a4e=n(nmo,"SPAN",{});var rea=s(a4e);$lr=r(rea,"AutoModelForDepthEstimation"),rea.forEach(t),nmo.forEach(t),qlo=i(c),Vo=n(c,"DIV",{class:!0});var Hl=s(Vo);T(sS.$$.fragment,Hl),klr=i(Hl),Yd=n(Hl,"P",{});var ffe=s(Yd);Slr=r(ffe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a depth estimation head) when created
with the `),NJ=n(ffe,"A",{href:!0});var tea=s(NJ);Rlr=r(tea,"from_pretrained()"),tea.forEach(t),Plr=r(ffe," class method or the "),qJ=n(ffe,"A",{href:!0});var aea=s(qJ);Blr=r(aea,"from_config()"),aea.forEach(t),Ilr=r(ffe,` class
method.`),ffe.forEach(t),Nlr=i(Hl),lS=n(Hl,"P",{});var smo=s(lS);qlr=r(smo,"This class cannot be instantiated directly using "),n4e=n(smo,"CODE",{});var nea=s(n4e);Dlr=r(nea,"__init__()"),nea.forEach(t),jlr=r(smo," (throws an error)."),smo.forEach(t),Glr=i(Hl),xt=n(Hl,"DIV",{class:!0});var dx=s(xt);T(iS.$$.fragment,dx),Olr=i(dx),s4e=n(dx,"P",{});var sea=s(s4e);Vlr=r(sea,"Instantiates one of the model classes of the library (with a depth estimation head) from a configuration."),sea.forEach(t),Xlr=i(dx),Zd=n(dx,"P",{});var gfe=s(Zd);zlr=r(gfe,`Note:
Loading a model from its configuration file does `),l4e=n(gfe,"STRONG",{});var lea=s(l4e);Qlr=r(lea,"not"),lea.forEach(t),Wlr=r(gfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),DJ=n(gfe,"A",{href:!0});var iea=s(DJ);Ulr=r(iea,"from_pretrained()"),iea.forEach(t),Hlr=r(gfe," to load the model weights."),gfe.forEach(t),Jlr=i(dx),T(XF.$$.fragment,dx),dx.forEach(t),Ylr=i(Hl),so=n(Hl,"DIV",{class:!0});var Ba=s(so);T(dS.$$.fragment,Ba),Zlr=i(Ba),i4e=n(Ba,"P",{});var dea=s(i4e);Klr=r(dea,"Instantiate one of the model classes of the library (with a depth estimation head) from a pretrained model."),dea.forEach(t),eir=i(Ba),un=n(Ba,"P",{});var mx=s(un);oir=r(mx,"The model class to instantiate is selected based on the "),d4e=n(mx,"CODE",{});var mea=s(d4e);rir=r(mea,"model_type"),mea.forEach(t),tir=r(mx,` property of the config object (either
passed as an argument or loaded from `),m4e=n(mx,"CODE",{});var cea=s(m4e);air=r(cea,"pretrained_model_name_or_path"),cea.forEach(t),nir=r(mx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c4e=n(mx,"CODE",{});var fea=s(c4e);sir=r(fea,"pretrained_model_name_or_path"),fea.forEach(t),lir=r(mx,":"),mx.forEach(t),iir=i(Ba),mS=n(Ba,"UL",{});var lmo=s(mS);zF=n(lmo,"LI",{});var $Ue=s(zF);f4e=n($Ue,"STRONG",{});var gea=s(f4e);dir=r(gea,"dpt"),gea.forEach(t),mir=r($Ue," \u2014 "),jJ=n($Ue,"A",{href:!0});var hea=s(jJ);cir=r(hea,"DPTForDepthEstimation"),hea.forEach(t),fir=r($Ue," (DPT model)"),$Ue.forEach(t),gir=i(lmo),QF=n(lmo,"LI",{});var kUe=s(QF);g4e=n(kUe,"STRONG",{});var uea=s(g4e);hir=r(uea,"glpn"),uea.forEach(t),uir=r(kUe," \u2014 "),GJ=n(kUe,"A",{href:!0});var pea=s(GJ);pir=r(pea,"GLPNForDepthEstimation"),pea.forEach(t),_ir=r(kUe," (GLPN model)"),kUe.forEach(t),lmo.forEach(t),bir=i(Ba),WF=n(Ba,"P",{});var SUe=s(WF);vir=r(SUe,"The model is set in evaluation mode by default using "),h4e=n(SUe,"CODE",{});var _ea=s(h4e);Fir=r(_ea,"model.eval()"),_ea.forEach(t),Tir=r(SUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),u4e=n(SUe,"CODE",{});var bea=s(u4e);Mir=r(bea,"model.train()"),bea.forEach(t),SUe.forEach(t),Eir=i(Ba),T(UF.$$.fragment,Ba),Ba.forEach(t),Hl.forEach(t),Dlo=i(c),Kd=n(c,"H2",{class:!0});var imo=s(Kd);HF=n(imo,"A",{id:!0,class:!0,href:!0});var vea=s(HF);p4e=n(vea,"SPAN",{});var Fea=s(p4e);T(cS.$$.fragment,Fea),Fea.forEach(t),vea.forEach(t),Cir=i(imo),_4e=n(imo,"SPAN",{});var Tea=s(_4e);wir=r(Tea,"AutoModelForMaskedLM"),Tea.forEach(t),imo.forEach(t),jlo=i(c),Xo=n(c,"DIV",{class:!0});var Jl=s(Xo);T(fS.$$.fragment,Jl),Air=i(Jl),em=n(Jl,"P",{});var hfe=s(em);Lir=r(hfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),OJ=n(hfe,"A",{href:!0});var Mea=s(OJ);yir=r(Mea,"from_pretrained()"),Mea.forEach(t),xir=r(hfe," class method or the "),VJ=n(hfe,"A",{href:!0});var Eea=s(VJ);$ir=r(Eea,"from_config()"),Eea.forEach(t),kir=r(hfe,` class
method.`),hfe.forEach(t),Sir=i(Jl),gS=n(Jl,"P",{});var dmo=s(gS);Rir=r(dmo,"This class cannot be instantiated directly using "),b4e=n(dmo,"CODE",{});var Cea=s(b4e);Pir=r(Cea,"__init__()"),Cea.forEach(t),Bir=r(dmo," (throws an error)."),dmo.forEach(t),Iir=i(Jl),$t=n(Jl,"DIV",{class:!0});var cx=s($t);T(hS.$$.fragment,cx),Nir=i(cx),v4e=n(cx,"P",{});var wea=s(v4e);qir=r(wea,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),wea.forEach(t),Dir=i(cx),om=n(cx,"P",{});var ufe=s(om);jir=r(ufe,`Note:
Loading a model from its configuration file does `),F4e=n(ufe,"STRONG",{});var Aea=s(F4e);Gir=r(Aea,"not"),Aea.forEach(t),Oir=r(ufe,` load the model weights. It only affects the
model\u2019s configuration. Use `),XJ=n(ufe,"A",{href:!0});var Lea=s(XJ);Vir=r(Lea,"from_pretrained()"),Lea.forEach(t),Xir=r(ufe," to load the model weights."),ufe.forEach(t),zir=i(cx),T(JF.$$.fragment,cx),cx.forEach(t),Qir=i(Jl),lo=n(Jl,"DIV",{class:!0});var Ia=s(lo);T(uS.$$.fragment,Ia),Wir=i(Ia),T4e=n(Ia,"P",{});var yea=s(T4e);Uir=r(yea,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),yea.forEach(t),Hir=i(Ia),pn=n(Ia,"P",{});var fx=s(pn);Jir=r(fx,"The model class to instantiate is selected based on the "),M4e=n(fx,"CODE",{});var xea=s(M4e);Yir=r(xea,"model_type"),xea.forEach(t),Zir=r(fx,` property of the config object (either
passed as an argument or loaded from `),E4e=n(fx,"CODE",{});var $ea=s(E4e);Kir=r($ea,"pretrained_model_name_or_path"),$ea.forEach(t),edr=r(fx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C4e=n(fx,"CODE",{});var kea=s(C4e);odr=r(kea,"pretrained_model_name_or_path"),kea.forEach(t),rdr=r(fx,":"),fx.forEach(t),tdr=i(Ia),Y=n(Ia,"UL",{});var Z=s(Y);YF=n(Z,"LI",{});var RUe=s(YF);w4e=n(RUe,"STRONG",{});var Sea=s(w4e);adr=r(Sea,"albert"),Sea.forEach(t),ndr=r(RUe," \u2014 "),zJ=n(RUe,"A",{href:!0});var Rea=s(zJ);sdr=r(Rea,"AlbertForMaskedLM"),Rea.forEach(t),ldr=r(RUe," (ALBERT model)"),RUe.forEach(t),idr=i(Z),ZF=n(Z,"LI",{});var PUe=s(ZF);A4e=n(PUe,"STRONG",{});var Pea=s(A4e);ddr=r(Pea,"bart"),Pea.forEach(t),mdr=r(PUe," \u2014 "),QJ=n(PUe,"A",{href:!0});var Bea=s(QJ);cdr=r(Bea,"BartForConditionalGeneration"),Bea.forEach(t),fdr=r(PUe," (BART model)"),PUe.forEach(t),gdr=i(Z),KF=n(Z,"LI",{});var BUe=s(KF);L4e=n(BUe,"STRONG",{});var Iea=s(L4e);hdr=r(Iea,"bert"),Iea.forEach(t),udr=r(BUe," \u2014 "),WJ=n(BUe,"A",{href:!0});var Nea=s(WJ);pdr=r(Nea,"BertForMaskedLM"),Nea.forEach(t),_dr=r(BUe," (BERT model)"),BUe.forEach(t),bdr=i(Z),eT=n(Z,"LI",{});var IUe=s(eT);y4e=n(IUe,"STRONG",{});var qea=s(y4e);vdr=r(qea,"big_bird"),qea.forEach(t),Fdr=r(IUe," \u2014 "),UJ=n(IUe,"A",{href:!0});var Dea=s(UJ);Tdr=r(Dea,"BigBirdForMaskedLM"),Dea.forEach(t),Mdr=r(IUe," (BigBird model)"),IUe.forEach(t),Edr=i(Z),oT=n(Z,"LI",{});var NUe=s(oT);x4e=n(NUe,"STRONG",{});var jea=s(x4e);Cdr=r(jea,"camembert"),jea.forEach(t),wdr=r(NUe," \u2014 "),HJ=n(NUe,"A",{href:!0});var Gea=s(HJ);Adr=r(Gea,"CamembertForMaskedLM"),Gea.forEach(t),Ldr=r(NUe," (CamemBERT model)"),NUe.forEach(t),ydr=i(Z),rT=n(Z,"LI",{});var qUe=s(rT);$4e=n(qUe,"STRONG",{});var Oea=s($4e);xdr=r(Oea,"convbert"),Oea.forEach(t),$dr=r(qUe," \u2014 "),JJ=n(qUe,"A",{href:!0});var Vea=s(JJ);kdr=r(Vea,"ConvBertForMaskedLM"),Vea.forEach(t),Sdr=r(qUe," (ConvBERT model)"),qUe.forEach(t),Rdr=i(Z),tT=n(Z,"LI",{});var DUe=s(tT);k4e=n(DUe,"STRONG",{});var Xea=s(k4e);Pdr=r(Xea,"data2vec-text"),Xea.forEach(t),Bdr=r(DUe," \u2014 "),YJ=n(DUe,"A",{href:!0});var zea=s(YJ);Idr=r(zea,"Data2VecTextForMaskedLM"),zea.forEach(t),Ndr=r(DUe," (Data2VecText model)"),DUe.forEach(t),qdr=i(Z),aT=n(Z,"LI",{});var jUe=s(aT);S4e=n(jUe,"STRONG",{});var Qea=s(S4e);Ddr=r(Qea,"deberta"),Qea.forEach(t),jdr=r(jUe," \u2014 "),ZJ=n(jUe,"A",{href:!0});var Wea=s(ZJ);Gdr=r(Wea,"DebertaForMaskedLM"),Wea.forEach(t),Odr=r(jUe," (DeBERTa model)"),jUe.forEach(t),Vdr=i(Z),nT=n(Z,"LI",{});var GUe=s(nT);R4e=n(GUe,"STRONG",{});var Uea=s(R4e);Xdr=r(Uea,"deberta-v2"),Uea.forEach(t),zdr=r(GUe," \u2014 "),KJ=n(GUe,"A",{href:!0});var Hea=s(KJ);Qdr=r(Hea,"DebertaV2ForMaskedLM"),Hea.forEach(t),Wdr=r(GUe," (DeBERTa-v2 model)"),GUe.forEach(t),Udr=i(Z),sT=n(Z,"LI",{});var OUe=s(sT);P4e=n(OUe,"STRONG",{});var Jea=s(P4e);Hdr=r(Jea,"distilbert"),Jea.forEach(t),Jdr=r(OUe," \u2014 "),eY=n(OUe,"A",{href:!0});var Yea=s(eY);Ydr=r(Yea,"DistilBertForMaskedLM"),Yea.forEach(t),Zdr=r(OUe," (DistilBERT model)"),OUe.forEach(t),Kdr=i(Z),lT=n(Z,"LI",{});var VUe=s(lT);B4e=n(VUe,"STRONG",{});var Zea=s(B4e);emr=r(Zea,"electra"),Zea.forEach(t),omr=r(VUe," \u2014 "),oY=n(VUe,"A",{href:!0});var Kea=s(oY);rmr=r(Kea,"ElectraForMaskedLM"),Kea.forEach(t),tmr=r(VUe," (ELECTRA model)"),VUe.forEach(t),amr=i(Z),iT=n(Z,"LI",{});var XUe=s(iT);I4e=n(XUe,"STRONG",{});var eoa=s(I4e);nmr=r(eoa,"ernie"),eoa.forEach(t),smr=r(XUe," \u2014 "),rY=n(XUe,"A",{href:!0});var ooa=s(rY);lmr=r(ooa,"ErnieForMaskedLM"),ooa.forEach(t),imr=r(XUe," (ERNIE model)"),XUe.forEach(t),dmr=i(Z),dT=n(Z,"LI",{});var zUe=s(dT);N4e=n(zUe,"STRONG",{});var roa=s(N4e);mmr=r(roa,"flaubert"),roa.forEach(t),cmr=r(zUe," \u2014 "),tY=n(zUe,"A",{href:!0});var toa=s(tY);fmr=r(toa,"FlaubertWithLMHeadModel"),toa.forEach(t),gmr=r(zUe," (FlauBERT model)"),zUe.forEach(t),hmr=i(Z),mT=n(Z,"LI",{});var QUe=s(mT);q4e=n(QUe,"STRONG",{});var aoa=s(q4e);umr=r(aoa,"fnet"),aoa.forEach(t),pmr=r(QUe," \u2014 "),aY=n(QUe,"A",{href:!0});var noa=s(aY);_mr=r(noa,"FNetForMaskedLM"),noa.forEach(t),bmr=r(QUe," (FNet model)"),QUe.forEach(t),vmr=i(Z),cT=n(Z,"LI",{});var WUe=s(cT);D4e=n(WUe,"STRONG",{});var soa=s(D4e);Fmr=r(soa,"funnel"),soa.forEach(t),Tmr=r(WUe," \u2014 "),nY=n(WUe,"A",{href:!0});var loa=s(nY);Mmr=r(loa,"FunnelForMaskedLM"),loa.forEach(t),Emr=r(WUe," (Funnel Transformer model)"),WUe.forEach(t),Cmr=i(Z),fT=n(Z,"LI",{});var UUe=s(fT);j4e=n(UUe,"STRONG",{});var ioa=s(j4e);wmr=r(ioa,"ibert"),ioa.forEach(t),Amr=r(UUe," \u2014 "),sY=n(UUe,"A",{href:!0});var doa=s(sY);Lmr=r(doa,"IBertForMaskedLM"),doa.forEach(t),ymr=r(UUe," (I-BERT model)"),UUe.forEach(t),xmr=i(Z),gT=n(Z,"LI",{});var HUe=s(gT);G4e=n(HUe,"STRONG",{});var moa=s(G4e);$mr=r(moa,"layoutlm"),moa.forEach(t),kmr=r(HUe," \u2014 "),lY=n(HUe,"A",{href:!0});var coa=s(lY);Smr=r(coa,"LayoutLMForMaskedLM"),coa.forEach(t),Rmr=r(HUe," (LayoutLM model)"),HUe.forEach(t),Pmr=i(Z),hT=n(Z,"LI",{});var JUe=s(hT);O4e=n(JUe,"STRONG",{});var foa=s(O4e);Bmr=r(foa,"longformer"),foa.forEach(t),Imr=r(JUe," \u2014 "),iY=n(JUe,"A",{href:!0});var goa=s(iY);Nmr=r(goa,"LongformerForMaskedLM"),goa.forEach(t),qmr=r(JUe," (Longformer model)"),JUe.forEach(t),Dmr=i(Z),uT=n(Z,"LI",{});var YUe=s(uT);V4e=n(YUe,"STRONG",{});var hoa=s(V4e);jmr=r(hoa,"luke"),hoa.forEach(t),Gmr=r(YUe," \u2014 "),dY=n(YUe,"A",{href:!0});var uoa=s(dY);Omr=r(uoa,"LukeForMaskedLM"),uoa.forEach(t),Vmr=r(YUe," (LUKE model)"),YUe.forEach(t),Xmr=i(Z),pT=n(Z,"LI",{});var ZUe=s(pT);X4e=n(ZUe,"STRONG",{});var poa=s(X4e);zmr=r(poa,"mbart"),poa.forEach(t),Qmr=r(ZUe," \u2014 "),mY=n(ZUe,"A",{href:!0});var _oa=s(mY);Wmr=r(_oa,"MBartForConditionalGeneration"),_oa.forEach(t),Umr=r(ZUe," (mBART model)"),ZUe.forEach(t),Hmr=i(Z),_T=n(Z,"LI",{});var KUe=s(_T);z4e=n(KUe,"STRONG",{});var boa=s(z4e);Jmr=r(boa,"megatron-bert"),boa.forEach(t),Ymr=r(KUe," \u2014 "),cY=n(KUe,"A",{href:!0});var voa=s(cY);Zmr=r(voa,"MegatronBertForMaskedLM"),voa.forEach(t),Kmr=r(KUe," (Megatron-BERT model)"),KUe.forEach(t),ecr=i(Z),bT=n(Z,"LI",{});var eHe=s(bT);Q4e=n(eHe,"STRONG",{});var Foa=s(Q4e);ocr=r(Foa,"mobilebert"),Foa.forEach(t),rcr=r(eHe," \u2014 "),fY=n(eHe,"A",{href:!0});var Toa=s(fY);tcr=r(Toa,"MobileBertForMaskedLM"),Toa.forEach(t),acr=r(eHe," (MobileBERT model)"),eHe.forEach(t),ncr=i(Z),vT=n(Z,"LI",{});var oHe=s(vT);W4e=n(oHe,"STRONG",{});var Moa=s(W4e);scr=r(Moa,"mpnet"),Moa.forEach(t),lcr=r(oHe," \u2014 "),gY=n(oHe,"A",{href:!0});var Eoa=s(gY);icr=r(Eoa,"MPNetForMaskedLM"),Eoa.forEach(t),dcr=r(oHe," (MPNet model)"),oHe.forEach(t),mcr=i(Z),FT=n(Z,"LI",{});var rHe=s(FT);U4e=n(rHe,"STRONG",{});var Coa=s(U4e);ccr=r(Coa,"mvp"),Coa.forEach(t),fcr=r(rHe," \u2014 "),hY=n(rHe,"A",{href:!0});var woa=s(hY);gcr=r(woa,"MvpForConditionalGeneration"),woa.forEach(t),hcr=r(rHe," (MVP model)"),rHe.forEach(t),ucr=i(Z),TT=n(Z,"LI",{});var tHe=s(TT);H4e=n(tHe,"STRONG",{});var Aoa=s(H4e);pcr=r(Aoa,"nezha"),Aoa.forEach(t),_cr=r(tHe," \u2014 "),uY=n(tHe,"A",{href:!0});var Loa=s(uY);bcr=r(Loa,"NezhaForMaskedLM"),Loa.forEach(t),vcr=r(tHe," (Nezha model)"),tHe.forEach(t),Fcr=i(Z),MT=n(Z,"LI",{});var aHe=s(MT);J4e=n(aHe,"STRONG",{});var yoa=s(J4e);Tcr=r(yoa,"nystromformer"),yoa.forEach(t),Mcr=r(aHe," \u2014 "),pY=n(aHe,"A",{href:!0});var xoa=s(pY);Ecr=r(xoa,"NystromformerForMaskedLM"),xoa.forEach(t),Ccr=r(aHe," (Nystr\xF6mformer model)"),aHe.forEach(t),wcr=i(Z),ET=n(Z,"LI",{});var nHe=s(ET);Y4e=n(nHe,"STRONG",{});var $oa=s(Y4e);Acr=r($oa,"perceiver"),$oa.forEach(t),Lcr=r(nHe," \u2014 "),_Y=n(nHe,"A",{href:!0});var koa=s(_Y);ycr=r(koa,"PerceiverForMaskedLM"),koa.forEach(t),xcr=r(nHe," (Perceiver model)"),nHe.forEach(t),$cr=i(Z),CT=n(Z,"LI",{});var sHe=s(CT);Z4e=n(sHe,"STRONG",{});var Soa=s(Z4e);kcr=r(Soa,"qdqbert"),Soa.forEach(t),Scr=r(sHe," \u2014 "),bY=n(sHe,"A",{href:!0});var Roa=s(bY);Rcr=r(Roa,"QDQBertForMaskedLM"),Roa.forEach(t),Pcr=r(sHe," (QDQBert model)"),sHe.forEach(t),Bcr=i(Z),wT=n(Z,"LI",{});var lHe=s(wT);K4e=n(lHe,"STRONG",{});var Poa=s(K4e);Icr=r(Poa,"reformer"),Poa.forEach(t),Ncr=r(lHe," \u2014 "),vY=n(lHe,"A",{href:!0});var Boa=s(vY);qcr=r(Boa,"ReformerForMaskedLM"),Boa.forEach(t),Dcr=r(lHe," (Reformer model)"),lHe.forEach(t),jcr=i(Z),AT=n(Z,"LI",{});var iHe=s(AT);eCe=n(iHe,"STRONG",{});var Ioa=s(eCe);Gcr=r(Ioa,"rembert"),Ioa.forEach(t),Ocr=r(iHe," \u2014 "),FY=n(iHe,"A",{href:!0});var Noa=s(FY);Vcr=r(Noa,"RemBertForMaskedLM"),Noa.forEach(t),Xcr=r(iHe," (RemBERT model)"),iHe.forEach(t),zcr=i(Z),LT=n(Z,"LI",{});var dHe=s(LT);oCe=n(dHe,"STRONG",{});var qoa=s(oCe);Qcr=r(qoa,"roberta"),qoa.forEach(t),Wcr=r(dHe," \u2014 "),TY=n(dHe,"A",{href:!0});var Doa=s(TY);Ucr=r(Doa,"RobertaForMaskedLM"),Doa.forEach(t),Hcr=r(dHe," (RoBERTa model)"),dHe.forEach(t),Jcr=i(Z),yT=n(Z,"LI",{});var mHe=s(yT);rCe=n(mHe,"STRONG",{});var joa=s(rCe);Ycr=r(joa,"roc_bert"),joa.forEach(t),Zcr=r(mHe," \u2014 "),MY=n(mHe,"A",{href:!0});var Goa=s(MY);Kcr=r(Goa,"RoCBertForMaskedLM"),Goa.forEach(t),efr=r(mHe," (RoCBert model)"),mHe.forEach(t),ofr=i(Z),xT=n(Z,"LI",{});var cHe=s(xT);tCe=n(cHe,"STRONG",{});var Ooa=s(tCe);rfr=r(Ooa,"roformer"),Ooa.forEach(t),tfr=r(cHe," \u2014 "),EY=n(cHe,"A",{href:!0});var Voa=s(EY);afr=r(Voa,"RoFormerForMaskedLM"),Voa.forEach(t),nfr=r(cHe," (RoFormer model)"),cHe.forEach(t),sfr=i(Z),$T=n(Z,"LI",{});var fHe=s($T);aCe=n(fHe,"STRONG",{});var Xoa=s(aCe);lfr=r(Xoa,"squeezebert"),Xoa.forEach(t),ifr=r(fHe," \u2014 "),CY=n(fHe,"A",{href:!0});var zoa=s(CY);dfr=r(zoa,"SqueezeBertForMaskedLM"),zoa.forEach(t),mfr=r(fHe," (SqueezeBERT model)"),fHe.forEach(t),cfr=i(Z),kT=n(Z,"LI",{});var gHe=s(kT);nCe=n(gHe,"STRONG",{});var Qoa=s(nCe);ffr=r(Qoa,"tapas"),Qoa.forEach(t),gfr=r(gHe," \u2014 "),wY=n(gHe,"A",{href:!0});var Woa=s(wY);hfr=r(Woa,"TapasForMaskedLM"),Woa.forEach(t),ufr=r(gHe," (TAPAS model)"),gHe.forEach(t),pfr=i(Z),ST=n(Z,"LI",{});var hHe=s(ST);sCe=n(hHe,"STRONG",{});var Uoa=s(sCe);_fr=r(Uoa,"wav2vec2"),Uoa.forEach(t),bfr=r(hHe," \u2014 "),lCe=n(hHe,"CODE",{});var Hoa=s(lCe);vfr=r(Hoa,"Wav2Vec2ForMaskedLM"),Hoa.forEach(t),Ffr=r(hHe," (Wav2Vec2 model)"),hHe.forEach(t),Tfr=i(Z),RT=n(Z,"LI",{});var uHe=s(RT);iCe=n(uHe,"STRONG",{});var Joa=s(iCe);Mfr=r(Joa,"xlm"),Joa.forEach(t),Efr=r(uHe," \u2014 "),AY=n(uHe,"A",{href:!0});var Yoa=s(AY);Cfr=r(Yoa,"XLMWithLMHeadModel"),Yoa.forEach(t),wfr=r(uHe," (XLM model)"),uHe.forEach(t),Afr=i(Z),PT=n(Z,"LI",{});var pHe=s(PT);dCe=n(pHe,"STRONG",{});var Zoa=s(dCe);Lfr=r(Zoa,"xlm-roberta"),Zoa.forEach(t),yfr=r(pHe," \u2014 "),LY=n(pHe,"A",{href:!0});var Koa=s(LY);xfr=r(Koa,"XLMRobertaForMaskedLM"),Koa.forEach(t),$fr=r(pHe," (XLM-RoBERTa model)"),pHe.forEach(t),kfr=i(Z),BT=n(Z,"LI",{});var _He=s(BT);mCe=n(_He,"STRONG",{});var era=s(mCe);Sfr=r(era,"xlm-roberta-xl"),era.forEach(t),Rfr=r(_He," \u2014 "),yY=n(_He,"A",{href:!0});var ora=s(yY);Pfr=r(ora,"XLMRobertaXLForMaskedLM"),ora.forEach(t),Bfr=r(_He," (XLM-RoBERTa-XL model)"),_He.forEach(t),Ifr=i(Z),IT=n(Z,"LI",{});var bHe=s(IT);cCe=n(bHe,"STRONG",{});var rra=s(cCe);Nfr=r(rra,"yoso"),rra.forEach(t),qfr=r(bHe," \u2014 "),xY=n(bHe,"A",{href:!0});var tra=s(xY);Dfr=r(tra,"YosoForMaskedLM"),tra.forEach(t),jfr=r(bHe," (YOSO model)"),bHe.forEach(t),Z.forEach(t),Gfr=i(Ia),NT=n(Ia,"P",{});var vHe=s(NT);Ofr=r(vHe,"The model is set in evaluation mode by default using "),fCe=n(vHe,"CODE",{});var ara=s(fCe);Vfr=r(ara,"model.eval()"),ara.forEach(t),Xfr=r(vHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gCe=n(vHe,"CODE",{});var nra=s(gCe);zfr=r(nra,"model.train()"),nra.forEach(t),vHe.forEach(t),Qfr=i(Ia),T(qT.$$.fragment,Ia),Ia.forEach(t),Jl.forEach(t),Glo=i(c),rm=n(c,"H2",{class:!0});var mmo=s(rm);DT=n(mmo,"A",{id:!0,class:!0,href:!0});var sra=s(DT);hCe=n(sra,"SPAN",{});var lra=s(hCe);T(pS.$$.fragment,lra),lra.forEach(t),sra.forEach(t),Wfr=i(mmo),uCe=n(mmo,"SPAN",{});var ira=s(uCe);Ufr=r(ira,"AutoModelForSeq2SeqLM"),ira.forEach(t),mmo.forEach(t),Olo=i(c),zo=n(c,"DIV",{class:!0});var Yl=s(zo);T(_S.$$.fragment,Yl),Hfr=i(Yl),tm=n(Yl,"P",{});var pfe=s(tm);Jfr=r(pfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),$Y=n(pfe,"A",{href:!0});var dra=s($Y);Yfr=r(dra,"from_pretrained()"),dra.forEach(t),Zfr=r(pfe," class method or the "),kY=n(pfe,"A",{href:!0});var mra=s(kY);Kfr=r(mra,"from_config()"),mra.forEach(t),egr=r(pfe,` class
method.`),pfe.forEach(t),ogr=i(Yl),bS=n(Yl,"P",{});var cmo=s(bS);rgr=r(cmo,"This class cannot be instantiated directly using "),pCe=n(cmo,"CODE",{});var cra=s(pCe);tgr=r(cra,"__init__()"),cra.forEach(t),agr=r(cmo," (throws an error)."),cmo.forEach(t),ngr=i(Yl),kt=n(Yl,"DIV",{class:!0});var gx=s(kt);T(vS.$$.fragment,gx),sgr=i(gx),_Ce=n(gx,"P",{});var fra=s(_Ce);lgr=r(fra,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),fra.forEach(t),igr=i(gx),am=n(gx,"P",{});var _fe=s(am);dgr=r(_fe,`Note:
Loading a model from its configuration file does `),bCe=n(_fe,"STRONG",{});var gra=s(bCe);mgr=r(gra,"not"),gra.forEach(t),cgr=r(_fe,` load the model weights. It only affects the
model\u2019s configuration. Use `),SY=n(_fe,"A",{href:!0});var hra=s(SY);fgr=r(hra,"from_pretrained()"),hra.forEach(t),ggr=r(_fe," to load the model weights."),_fe.forEach(t),hgr=i(gx),T(jT.$$.fragment,gx),gx.forEach(t),ugr=i(Yl),io=n(Yl,"DIV",{class:!0});var Na=s(io);T(FS.$$.fragment,Na),pgr=i(Na),vCe=n(Na,"P",{});var ura=s(vCe);_gr=r(ura,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),ura.forEach(t),bgr=i(Na),_n=n(Na,"P",{});var hx=s(_n);vgr=r(hx,"The model class to instantiate is selected based on the "),FCe=n(hx,"CODE",{});var pra=s(FCe);Fgr=r(pra,"model_type"),pra.forEach(t),Tgr=r(hx,` property of the config object (either
passed as an argument or loaded from `),TCe=n(hx,"CODE",{});var _ra=s(TCe);Mgr=r(_ra,"pretrained_model_name_or_path"),_ra.forEach(t),Egr=r(hx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MCe=n(hx,"CODE",{});var bra=s(MCe);Cgr=r(bra,"pretrained_model_name_or_path"),bra.forEach(t),wgr=r(hx,":"),hx.forEach(t),Agr=i(Na),pe=n(Na,"UL",{});var ve=s(pe);GT=n(ve,"LI",{});var FHe=s(GT);ECe=n(FHe,"STRONG",{});var vra=s(ECe);Lgr=r(vra,"bart"),vra.forEach(t),ygr=r(FHe," \u2014 "),RY=n(FHe,"A",{href:!0});var Fra=s(RY);xgr=r(Fra,"BartForConditionalGeneration"),Fra.forEach(t),$gr=r(FHe," (BART model)"),FHe.forEach(t),kgr=i(ve),OT=n(ve,"LI",{});var THe=s(OT);CCe=n(THe,"STRONG",{});var Tra=s(CCe);Sgr=r(Tra,"bigbird_pegasus"),Tra.forEach(t),Rgr=r(THe," \u2014 "),PY=n(THe,"A",{href:!0});var Mra=s(PY);Pgr=r(Mra,"BigBirdPegasusForConditionalGeneration"),Mra.forEach(t),Bgr=r(THe," (BigBird-Pegasus model)"),THe.forEach(t),Igr=i(ve),VT=n(ve,"LI",{});var MHe=s(VT);wCe=n(MHe,"STRONG",{});var Era=s(wCe);Ngr=r(Era,"blenderbot"),Era.forEach(t),qgr=r(MHe," \u2014 "),BY=n(MHe,"A",{href:!0});var Cra=s(BY);Dgr=r(Cra,"BlenderbotForConditionalGeneration"),Cra.forEach(t),jgr=r(MHe," (Blenderbot model)"),MHe.forEach(t),Ggr=i(ve),XT=n(ve,"LI",{});var EHe=s(XT);ACe=n(EHe,"STRONG",{});var wra=s(ACe);Ogr=r(wra,"blenderbot-small"),wra.forEach(t),Vgr=r(EHe," \u2014 "),IY=n(EHe,"A",{href:!0});var Ara=s(IY);Xgr=r(Ara,"BlenderbotSmallForConditionalGeneration"),Ara.forEach(t),zgr=r(EHe," (BlenderbotSmall model)"),EHe.forEach(t),Qgr=i(ve),zT=n(ve,"LI",{});var CHe=s(zT);LCe=n(CHe,"STRONG",{});var Lra=s(LCe);Wgr=r(Lra,"encoder-decoder"),Lra.forEach(t),Ugr=r(CHe," \u2014 "),NY=n(CHe,"A",{href:!0});var yra=s(NY);Hgr=r(yra,"EncoderDecoderModel"),yra.forEach(t),Jgr=r(CHe," (Encoder decoder model)"),CHe.forEach(t),Ygr=i(ve),QT=n(ve,"LI",{});var wHe=s(QT);yCe=n(wHe,"STRONG",{});var xra=s(yCe);Zgr=r(xra,"fsmt"),xra.forEach(t),Kgr=r(wHe," \u2014 "),qY=n(wHe,"A",{href:!0});var $ra=s(qY);ehr=r($ra,"FSMTForConditionalGeneration"),$ra.forEach(t),ohr=r(wHe," (FairSeq Machine-Translation model)"),wHe.forEach(t),rhr=i(ve),WT=n(ve,"LI",{});var AHe=s(WT);xCe=n(AHe,"STRONG",{});var kra=s(xCe);thr=r(kra,"led"),kra.forEach(t),ahr=r(AHe," \u2014 "),DY=n(AHe,"A",{href:!0});var Sra=s(DY);nhr=r(Sra,"LEDForConditionalGeneration"),Sra.forEach(t),shr=r(AHe," (LED model)"),AHe.forEach(t),lhr=i(ve),UT=n(ve,"LI",{});var LHe=s(UT);$Ce=n(LHe,"STRONG",{});var Rra=s($Ce);ihr=r(Rra,"longt5"),Rra.forEach(t),dhr=r(LHe," \u2014 "),jY=n(LHe,"A",{href:!0});var Pra=s(jY);mhr=r(Pra,"LongT5ForConditionalGeneration"),Pra.forEach(t),chr=r(LHe," (LongT5 model)"),LHe.forEach(t),fhr=i(ve),HT=n(ve,"LI",{});var yHe=s(HT);kCe=n(yHe,"STRONG",{});var Bra=s(kCe);ghr=r(Bra,"m2m_100"),Bra.forEach(t),hhr=r(yHe," \u2014 "),GY=n(yHe,"A",{href:!0});var Ira=s(GY);uhr=r(Ira,"M2M100ForConditionalGeneration"),Ira.forEach(t),phr=r(yHe," (M2M100 model)"),yHe.forEach(t),_hr=i(ve),JT=n(ve,"LI",{});var xHe=s(JT);SCe=n(xHe,"STRONG",{});var Nra=s(SCe);bhr=r(Nra,"marian"),Nra.forEach(t),vhr=r(xHe," \u2014 "),OY=n(xHe,"A",{href:!0});var qra=s(OY);Fhr=r(qra,"MarianMTModel"),qra.forEach(t),Thr=r(xHe," (Marian model)"),xHe.forEach(t),Mhr=i(ve),YT=n(ve,"LI",{});var $He=s(YT);RCe=n($He,"STRONG",{});var Dra=s(RCe);Ehr=r(Dra,"mbart"),Dra.forEach(t),Chr=r($He," \u2014 "),VY=n($He,"A",{href:!0});var jra=s(VY);whr=r(jra,"MBartForConditionalGeneration"),jra.forEach(t),Ahr=r($He," (mBART model)"),$He.forEach(t),Lhr=i(ve),ZT=n(ve,"LI",{});var kHe=s(ZT);PCe=n(kHe,"STRONG",{});var Gra=s(PCe);yhr=r(Gra,"mt5"),Gra.forEach(t),xhr=r(kHe," \u2014 "),XY=n(kHe,"A",{href:!0});var Ora=s(XY);$hr=r(Ora,"MT5ForConditionalGeneration"),Ora.forEach(t),khr=r(kHe," (MT5 model)"),kHe.forEach(t),Shr=i(ve),KT=n(ve,"LI",{});var SHe=s(KT);BCe=n(SHe,"STRONG",{});var Vra=s(BCe);Rhr=r(Vra,"mvp"),Vra.forEach(t),Phr=r(SHe," \u2014 "),zY=n(SHe,"A",{href:!0});var Xra=s(zY);Bhr=r(Xra,"MvpForConditionalGeneration"),Xra.forEach(t),Ihr=r(SHe," (MVP model)"),SHe.forEach(t),Nhr=i(ve),eM=n(ve,"LI",{});var RHe=s(eM);ICe=n(RHe,"STRONG",{});var zra=s(ICe);qhr=r(zra,"nllb"),zra.forEach(t),Dhr=r(RHe," \u2014 "),QY=n(RHe,"A",{href:!0});var Qra=s(QY);jhr=r(Qra,"M2M100ForConditionalGeneration"),Qra.forEach(t),Ghr=r(RHe," (NLLB model)"),RHe.forEach(t),Ohr=i(ve),oM=n(ve,"LI",{});var PHe=s(oM);NCe=n(PHe,"STRONG",{});var Wra=s(NCe);Vhr=r(Wra,"pegasus"),Wra.forEach(t),Xhr=r(PHe," \u2014 "),WY=n(PHe,"A",{href:!0});var Ura=s(WY);zhr=r(Ura,"PegasusForConditionalGeneration"),Ura.forEach(t),Qhr=r(PHe," (Pegasus model)"),PHe.forEach(t),Whr=i(ve),rM=n(ve,"LI",{});var BHe=s(rM);qCe=n(BHe,"STRONG",{});var Hra=s(qCe);Uhr=r(Hra,"pegasus_x"),Hra.forEach(t),Hhr=r(BHe," \u2014 "),UY=n(BHe,"A",{href:!0});var Jra=s(UY);Jhr=r(Jra,"PegasusXForConditionalGeneration"),Jra.forEach(t),Yhr=r(BHe," (PEGASUS-X model)"),BHe.forEach(t),Zhr=i(ve),tM=n(ve,"LI",{});var IHe=s(tM);DCe=n(IHe,"STRONG",{});var Yra=s(DCe);Khr=r(Yra,"plbart"),Yra.forEach(t),eur=r(IHe," \u2014 "),HY=n(IHe,"A",{href:!0});var Zra=s(HY);our=r(Zra,"PLBartForConditionalGeneration"),Zra.forEach(t),rur=r(IHe," (PLBart model)"),IHe.forEach(t),tur=i(ve),aM=n(ve,"LI",{});var NHe=s(aM);jCe=n(NHe,"STRONG",{});var Kra=s(jCe);aur=r(Kra,"prophetnet"),Kra.forEach(t),nur=r(NHe," \u2014 "),JY=n(NHe,"A",{href:!0});var eta=s(JY);sur=r(eta,"ProphetNetForConditionalGeneration"),eta.forEach(t),lur=r(NHe," (ProphetNet model)"),NHe.forEach(t),iur=i(ve),nM=n(ve,"LI",{});var qHe=s(nM);GCe=n(qHe,"STRONG",{});var ota=s(GCe);dur=r(ota,"t5"),ota.forEach(t),mur=r(qHe," \u2014 "),YY=n(qHe,"A",{href:!0});var rta=s(YY);cur=r(rta,"T5ForConditionalGeneration"),rta.forEach(t),fur=r(qHe," (T5 model)"),qHe.forEach(t),gur=i(ve),sM=n(ve,"LI",{});var DHe=s(sM);OCe=n(DHe,"STRONG",{});var tta=s(OCe);hur=r(tta,"xlm-prophetnet"),tta.forEach(t),uur=r(DHe," \u2014 "),ZY=n(DHe,"A",{href:!0});var ata=s(ZY);pur=r(ata,"XLMProphetNetForConditionalGeneration"),ata.forEach(t),_ur=r(DHe," (XLM-ProphetNet model)"),DHe.forEach(t),ve.forEach(t),bur=i(Na),lM=n(Na,"P",{});var jHe=s(lM);vur=r(jHe,"The model is set in evaluation mode by default using "),VCe=n(jHe,"CODE",{});var nta=s(VCe);Fur=r(nta,"model.eval()"),nta.forEach(t),Tur=r(jHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),XCe=n(jHe,"CODE",{});var sta=s(XCe);Mur=r(sta,"model.train()"),sta.forEach(t),jHe.forEach(t),Eur=i(Na),T(iM.$$.fragment,Na),Na.forEach(t),Yl.forEach(t),Vlo=i(c),nm=n(c,"H2",{class:!0});var fmo=s(nm);dM=n(fmo,"A",{id:!0,class:!0,href:!0});var lta=s(dM);zCe=n(lta,"SPAN",{});var ita=s(zCe);T(TS.$$.fragment,ita),ita.forEach(t),lta.forEach(t),Cur=i(fmo),QCe=n(fmo,"SPAN",{});var dta=s(QCe);wur=r(dta,"AutoModelForSequenceClassification"),dta.forEach(t),fmo.forEach(t),Xlo=i(c),Qo=n(c,"DIV",{class:!0});var Zl=s(Qo);T(MS.$$.fragment,Zl),Aur=i(Zl),sm=n(Zl,"P",{});var bfe=s(sm);Lur=r(bfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),KY=n(bfe,"A",{href:!0});var mta=s(KY);yur=r(mta,"from_pretrained()"),mta.forEach(t),xur=r(bfe," class method or the "),eZ=n(bfe,"A",{href:!0});var cta=s(eZ);$ur=r(cta,"from_config()"),cta.forEach(t),kur=r(bfe,` class
method.`),bfe.forEach(t),Sur=i(Zl),ES=n(Zl,"P",{});var gmo=s(ES);Rur=r(gmo,"This class cannot be instantiated directly using "),WCe=n(gmo,"CODE",{});var fta=s(WCe);Pur=r(fta,"__init__()"),fta.forEach(t),Bur=r(gmo," (throws an error)."),gmo.forEach(t),Iur=i(Zl),St=n(Zl,"DIV",{class:!0});var ux=s(St);T(CS.$$.fragment,ux),Nur=i(ux),UCe=n(ux,"P",{});var gta=s(UCe);qur=r(gta,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),gta.forEach(t),Dur=i(ux),lm=n(ux,"P",{});var vfe=s(lm);jur=r(vfe,`Note:
Loading a model from its configuration file does `),HCe=n(vfe,"STRONG",{});var hta=s(HCe);Gur=r(hta,"not"),hta.forEach(t),Our=r(vfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),oZ=n(vfe,"A",{href:!0});var uta=s(oZ);Vur=r(uta,"from_pretrained()"),uta.forEach(t),Xur=r(vfe," to load the model weights."),vfe.forEach(t),zur=i(ux),T(mM.$$.fragment,ux),ux.forEach(t),Qur=i(Zl),mo=n(Zl,"DIV",{class:!0});var qa=s(mo);T(wS.$$.fragment,qa),Wur=i(qa),JCe=n(qa,"P",{});var pta=s(JCe);Uur=r(pta,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),pta.forEach(t),Hur=i(qa),bn=n(qa,"P",{});var px=s(bn);Jur=r(px,"The model class to instantiate is selected based on the "),YCe=n(px,"CODE",{});var _ta=s(YCe);Yur=r(_ta,"model_type"),_ta.forEach(t),Zur=r(px,` property of the config object (either
passed as an argument or loaded from `),ZCe=n(px,"CODE",{});var bta=s(ZCe);Kur=r(bta,"pretrained_model_name_or_path"),bta.forEach(t),epr=r(px,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KCe=n(px,"CODE",{});var vta=s(KCe);opr=r(vta,"pretrained_model_name_or_path"),vta.forEach(t),rpr=r(px,":"),px.forEach(t),tpr=i(qa),I=n(qa,"UL",{});var j=s(I);cM=n(j,"LI",{});var GHe=s(cM);e3e=n(GHe,"STRONG",{});var Fta=s(e3e);apr=r(Fta,"albert"),Fta.forEach(t),npr=r(GHe," \u2014 "),rZ=n(GHe,"A",{href:!0});var Tta=s(rZ);spr=r(Tta,"AlbertForSequenceClassification"),Tta.forEach(t),lpr=r(GHe," (ALBERT model)"),GHe.forEach(t),ipr=i(j),fM=n(j,"LI",{});var OHe=s(fM);o3e=n(OHe,"STRONG",{});var Mta=s(o3e);dpr=r(Mta,"bart"),Mta.forEach(t),mpr=r(OHe," \u2014 "),tZ=n(OHe,"A",{href:!0});var Eta=s(tZ);cpr=r(Eta,"BartForSequenceClassification"),Eta.forEach(t),fpr=r(OHe," (BART model)"),OHe.forEach(t),gpr=i(j),gM=n(j,"LI",{});var VHe=s(gM);r3e=n(VHe,"STRONG",{});var Cta=s(r3e);hpr=r(Cta,"bert"),Cta.forEach(t),upr=r(VHe," \u2014 "),aZ=n(VHe,"A",{href:!0});var wta=s(aZ);ppr=r(wta,"BertForSequenceClassification"),wta.forEach(t),_pr=r(VHe," (BERT model)"),VHe.forEach(t),bpr=i(j),hM=n(j,"LI",{});var XHe=s(hM);t3e=n(XHe,"STRONG",{});var Ata=s(t3e);vpr=r(Ata,"big_bird"),Ata.forEach(t),Fpr=r(XHe," \u2014 "),nZ=n(XHe,"A",{href:!0});var Lta=s(nZ);Tpr=r(Lta,"BigBirdForSequenceClassification"),Lta.forEach(t),Mpr=r(XHe," (BigBird model)"),XHe.forEach(t),Epr=i(j),uM=n(j,"LI",{});var zHe=s(uM);a3e=n(zHe,"STRONG",{});var yta=s(a3e);Cpr=r(yta,"bigbird_pegasus"),yta.forEach(t),wpr=r(zHe," \u2014 "),sZ=n(zHe,"A",{href:!0});var xta=s(sZ);Apr=r(xta,"BigBirdPegasusForSequenceClassification"),xta.forEach(t),Lpr=r(zHe," (BigBird-Pegasus model)"),zHe.forEach(t),ypr=i(j),pM=n(j,"LI",{});var QHe=s(pM);n3e=n(QHe,"STRONG",{});var $ta=s(n3e);xpr=r($ta,"bloom"),$ta.forEach(t),$pr=r(QHe," \u2014 "),lZ=n(QHe,"A",{href:!0});var kta=s(lZ);kpr=r(kta,"BloomForSequenceClassification"),kta.forEach(t),Spr=r(QHe," (BLOOM model)"),QHe.forEach(t),Rpr=i(j),_M=n(j,"LI",{});var WHe=s(_M);s3e=n(WHe,"STRONG",{});var Sta=s(s3e);Ppr=r(Sta,"camembert"),Sta.forEach(t),Bpr=r(WHe," \u2014 "),iZ=n(WHe,"A",{href:!0});var Rta=s(iZ);Ipr=r(Rta,"CamembertForSequenceClassification"),Rta.forEach(t),Npr=r(WHe," (CamemBERT model)"),WHe.forEach(t),qpr=i(j),bM=n(j,"LI",{});var UHe=s(bM);l3e=n(UHe,"STRONG",{});var Pta=s(l3e);Dpr=r(Pta,"canine"),Pta.forEach(t),jpr=r(UHe," \u2014 "),dZ=n(UHe,"A",{href:!0});var Bta=s(dZ);Gpr=r(Bta,"CanineForSequenceClassification"),Bta.forEach(t),Opr=r(UHe," (CANINE model)"),UHe.forEach(t),Vpr=i(j),vM=n(j,"LI",{});var HHe=s(vM);i3e=n(HHe,"STRONG",{});var Ita=s(i3e);Xpr=r(Ita,"convbert"),Ita.forEach(t),zpr=r(HHe," \u2014 "),mZ=n(HHe,"A",{href:!0});var Nta=s(mZ);Qpr=r(Nta,"ConvBertForSequenceClassification"),Nta.forEach(t),Wpr=r(HHe," (ConvBERT model)"),HHe.forEach(t),Upr=i(j),FM=n(j,"LI",{});var JHe=s(FM);d3e=n(JHe,"STRONG",{});var qta=s(d3e);Hpr=r(qta,"ctrl"),qta.forEach(t),Jpr=r(JHe," \u2014 "),cZ=n(JHe,"A",{href:!0});var Dta=s(cZ);Ypr=r(Dta,"CTRLForSequenceClassification"),Dta.forEach(t),Zpr=r(JHe," (CTRL model)"),JHe.forEach(t),Kpr=i(j),TM=n(j,"LI",{});var YHe=s(TM);m3e=n(YHe,"STRONG",{});var jta=s(m3e);e_r=r(jta,"data2vec-text"),jta.forEach(t),o_r=r(YHe," \u2014 "),fZ=n(YHe,"A",{href:!0});var Gta=s(fZ);r_r=r(Gta,"Data2VecTextForSequenceClassification"),Gta.forEach(t),t_r=r(YHe," (Data2VecText model)"),YHe.forEach(t),a_r=i(j),MM=n(j,"LI",{});var ZHe=s(MM);c3e=n(ZHe,"STRONG",{});var Ota=s(c3e);n_r=r(Ota,"deberta"),Ota.forEach(t),s_r=r(ZHe," \u2014 "),gZ=n(ZHe,"A",{href:!0});var Vta=s(gZ);l_r=r(Vta,"DebertaForSequenceClassification"),Vta.forEach(t),i_r=r(ZHe," (DeBERTa model)"),ZHe.forEach(t),d_r=i(j),EM=n(j,"LI",{});var KHe=s(EM);f3e=n(KHe,"STRONG",{});var Xta=s(f3e);m_r=r(Xta,"deberta-v2"),Xta.forEach(t),c_r=r(KHe," \u2014 "),hZ=n(KHe,"A",{href:!0});var zta=s(hZ);f_r=r(zta,"DebertaV2ForSequenceClassification"),zta.forEach(t),g_r=r(KHe," (DeBERTa-v2 model)"),KHe.forEach(t),h_r=i(j),CM=n(j,"LI",{});var eJe=s(CM);g3e=n(eJe,"STRONG",{});var Qta=s(g3e);u_r=r(Qta,"distilbert"),Qta.forEach(t),p_r=r(eJe," \u2014 "),uZ=n(eJe,"A",{href:!0});var Wta=s(uZ);__r=r(Wta,"DistilBertForSequenceClassification"),Wta.forEach(t),b_r=r(eJe," (DistilBERT model)"),eJe.forEach(t),v_r=i(j),wM=n(j,"LI",{});var oJe=s(wM);h3e=n(oJe,"STRONG",{});var Uta=s(h3e);F_r=r(Uta,"electra"),Uta.forEach(t),T_r=r(oJe," \u2014 "),pZ=n(oJe,"A",{href:!0});var Hta=s(pZ);M_r=r(Hta,"ElectraForSequenceClassification"),Hta.forEach(t),E_r=r(oJe," (ELECTRA model)"),oJe.forEach(t),C_r=i(j),AM=n(j,"LI",{});var rJe=s(AM);u3e=n(rJe,"STRONG",{});var Jta=s(u3e);w_r=r(Jta,"ernie"),Jta.forEach(t),A_r=r(rJe," \u2014 "),_Z=n(rJe,"A",{href:!0});var Yta=s(_Z);L_r=r(Yta,"ErnieForSequenceClassification"),Yta.forEach(t),y_r=r(rJe," (ERNIE model)"),rJe.forEach(t),x_r=i(j),LM=n(j,"LI",{});var tJe=s(LM);p3e=n(tJe,"STRONG",{});var Zta=s(p3e);$_r=r(Zta,"esm"),Zta.forEach(t),k_r=r(tJe," \u2014 "),bZ=n(tJe,"A",{href:!0});var Kta=s(bZ);S_r=r(Kta,"EsmForSequenceClassification"),Kta.forEach(t),R_r=r(tJe," (ESM model)"),tJe.forEach(t),P_r=i(j),yM=n(j,"LI",{});var aJe=s(yM);_3e=n(aJe,"STRONG",{});var eaa=s(_3e);B_r=r(eaa,"flaubert"),eaa.forEach(t),I_r=r(aJe," \u2014 "),vZ=n(aJe,"A",{href:!0});var oaa=s(vZ);N_r=r(oaa,"FlaubertForSequenceClassification"),oaa.forEach(t),q_r=r(aJe," (FlauBERT model)"),aJe.forEach(t),D_r=i(j),xM=n(j,"LI",{});var nJe=s(xM);b3e=n(nJe,"STRONG",{});var raa=s(b3e);j_r=r(raa,"fnet"),raa.forEach(t),G_r=r(nJe," \u2014 "),FZ=n(nJe,"A",{href:!0});var taa=s(FZ);O_r=r(taa,"FNetForSequenceClassification"),taa.forEach(t),V_r=r(nJe," (FNet model)"),nJe.forEach(t),X_r=i(j),$M=n(j,"LI",{});var sJe=s($M);v3e=n(sJe,"STRONG",{});var aaa=s(v3e);z_r=r(aaa,"funnel"),aaa.forEach(t),Q_r=r(sJe," \u2014 "),TZ=n(sJe,"A",{href:!0});var naa=s(TZ);W_r=r(naa,"FunnelForSequenceClassification"),naa.forEach(t),U_r=r(sJe," (Funnel Transformer model)"),sJe.forEach(t),H_r=i(j),kM=n(j,"LI",{});var lJe=s(kM);F3e=n(lJe,"STRONG",{});var saa=s(F3e);J_r=r(saa,"gpt2"),saa.forEach(t),Y_r=r(lJe," \u2014 "),MZ=n(lJe,"A",{href:!0});var laa=s(MZ);Z_r=r(laa,"GPT2ForSequenceClassification"),laa.forEach(t),K_r=r(lJe," (OpenAI GPT-2 model)"),lJe.forEach(t),e1r=i(j),SM=n(j,"LI",{});var iJe=s(SM);T3e=n(iJe,"STRONG",{});var iaa=s(T3e);o1r=r(iaa,"gpt_neo"),iaa.forEach(t),r1r=r(iJe," \u2014 "),EZ=n(iJe,"A",{href:!0});var daa=s(EZ);t1r=r(daa,"GPTNeoForSequenceClassification"),daa.forEach(t),a1r=r(iJe," (GPT Neo model)"),iJe.forEach(t),n1r=i(j),RM=n(j,"LI",{});var dJe=s(RM);M3e=n(dJe,"STRONG",{});var maa=s(M3e);s1r=r(maa,"gptj"),maa.forEach(t),l1r=r(dJe," \u2014 "),CZ=n(dJe,"A",{href:!0});var caa=s(CZ);i1r=r(caa,"GPTJForSequenceClassification"),caa.forEach(t),d1r=r(dJe," (GPT-J model)"),dJe.forEach(t),m1r=i(j),PM=n(j,"LI",{});var mJe=s(PM);E3e=n(mJe,"STRONG",{});var faa=s(E3e);c1r=r(faa,"ibert"),faa.forEach(t),f1r=r(mJe," \u2014 "),wZ=n(mJe,"A",{href:!0});var gaa=s(wZ);g1r=r(gaa,"IBertForSequenceClassification"),gaa.forEach(t),h1r=r(mJe," (I-BERT model)"),mJe.forEach(t),u1r=i(j),BM=n(j,"LI",{});var cJe=s(BM);C3e=n(cJe,"STRONG",{});var haa=s(C3e);p1r=r(haa,"layoutlm"),haa.forEach(t),_1r=r(cJe," \u2014 "),AZ=n(cJe,"A",{href:!0});var uaa=s(AZ);b1r=r(uaa,"LayoutLMForSequenceClassification"),uaa.forEach(t),v1r=r(cJe," (LayoutLM model)"),cJe.forEach(t),F1r=i(j),IM=n(j,"LI",{});var fJe=s(IM);w3e=n(fJe,"STRONG",{});var paa=s(w3e);T1r=r(paa,"layoutlmv2"),paa.forEach(t),M1r=r(fJe," \u2014 "),LZ=n(fJe,"A",{href:!0});var _aa=s(LZ);E1r=r(_aa,"LayoutLMv2ForSequenceClassification"),_aa.forEach(t),C1r=r(fJe," (LayoutLMv2 model)"),fJe.forEach(t),w1r=i(j),NM=n(j,"LI",{});var gJe=s(NM);A3e=n(gJe,"STRONG",{});var baa=s(A3e);A1r=r(baa,"layoutlmv3"),baa.forEach(t),L1r=r(gJe," \u2014 "),yZ=n(gJe,"A",{href:!0});var vaa=s(yZ);y1r=r(vaa,"LayoutLMv3ForSequenceClassification"),vaa.forEach(t),x1r=r(gJe," (LayoutLMv3 model)"),gJe.forEach(t),$1r=i(j),qM=n(j,"LI",{});var hJe=s(qM);L3e=n(hJe,"STRONG",{});var Faa=s(L3e);k1r=r(Faa,"led"),Faa.forEach(t),S1r=r(hJe," \u2014 "),xZ=n(hJe,"A",{href:!0});var Taa=s(xZ);R1r=r(Taa,"LEDForSequenceClassification"),Taa.forEach(t),P1r=r(hJe," (LED model)"),hJe.forEach(t),B1r=i(j),DM=n(j,"LI",{});var uJe=s(DM);y3e=n(uJe,"STRONG",{});var Maa=s(y3e);I1r=r(Maa,"lilt"),Maa.forEach(t),N1r=r(uJe," \u2014 "),$Z=n(uJe,"A",{href:!0});var Eaa=s($Z);q1r=r(Eaa,"LiltForSequenceClassification"),Eaa.forEach(t),D1r=r(uJe," (LiLT model)"),uJe.forEach(t),j1r=i(j),jM=n(j,"LI",{});var pJe=s(jM);x3e=n(pJe,"STRONG",{});var Caa=s(x3e);G1r=r(Caa,"longformer"),Caa.forEach(t),O1r=r(pJe," \u2014 "),kZ=n(pJe,"A",{href:!0});var waa=s(kZ);V1r=r(waa,"LongformerForSequenceClassification"),waa.forEach(t),X1r=r(pJe," (Longformer model)"),pJe.forEach(t),z1r=i(j),GM=n(j,"LI",{});var _Je=s(GM);$3e=n(_Je,"STRONG",{});var Aaa=s($3e);Q1r=r(Aaa,"luke"),Aaa.forEach(t),W1r=r(_Je," \u2014 "),SZ=n(_Je,"A",{href:!0});var Laa=s(SZ);U1r=r(Laa,"LukeForSequenceClassification"),Laa.forEach(t),H1r=r(_Je," (LUKE model)"),_Je.forEach(t),J1r=i(j),OM=n(j,"LI",{});var bJe=s(OM);k3e=n(bJe,"STRONG",{});var yaa=s(k3e);Y1r=r(yaa,"markuplm"),yaa.forEach(t),Z1r=r(bJe," \u2014 "),RZ=n(bJe,"A",{href:!0});var xaa=s(RZ);K1r=r(xaa,"MarkupLMForSequenceClassification"),xaa.forEach(t),e2r=r(bJe," (MarkupLM model)"),bJe.forEach(t),o2r=i(j),VM=n(j,"LI",{});var vJe=s(VM);S3e=n(vJe,"STRONG",{});var $aa=s(S3e);r2r=r($aa,"mbart"),$aa.forEach(t),t2r=r(vJe," \u2014 "),PZ=n(vJe,"A",{href:!0});var kaa=s(PZ);a2r=r(kaa,"MBartForSequenceClassification"),kaa.forEach(t),n2r=r(vJe," (mBART model)"),vJe.forEach(t),s2r=i(j),XM=n(j,"LI",{});var FJe=s(XM);R3e=n(FJe,"STRONG",{});var Saa=s(R3e);l2r=r(Saa,"megatron-bert"),Saa.forEach(t),i2r=r(FJe," \u2014 "),BZ=n(FJe,"A",{href:!0});var Raa=s(BZ);d2r=r(Raa,"MegatronBertForSequenceClassification"),Raa.forEach(t),m2r=r(FJe," (Megatron-BERT model)"),FJe.forEach(t),c2r=i(j),zM=n(j,"LI",{});var TJe=s(zM);P3e=n(TJe,"STRONG",{});var Paa=s(P3e);f2r=r(Paa,"mobilebert"),Paa.forEach(t),g2r=r(TJe," \u2014 "),IZ=n(TJe,"A",{href:!0});var Baa=s(IZ);h2r=r(Baa,"MobileBertForSequenceClassification"),Baa.forEach(t),u2r=r(TJe," (MobileBERT model)"),TJe.forEach(t),p2r=i(j),QM=n(j,"LI",{});var MJe=s(QM);B3e=n(MJe,"STRONG",{});var Iaa=s(B3e);_2r=r(Iaa,"mpnet"),Iaa.forEach(t),b2r=r(MJe," \u2014 "),NZ=n(MJe,"A",{href:!0});var Naa=s(NZ);v2r=r(Naa,"MPNetForSequenceClassification"),Naa.forEach(t),F2r=r(MJe," (MPNet model)"),MJe.forEach(t),T2r=i(j),WM=n(j,"LI",{});var EJe=s(WM);I3e=n(EJe,"STRONG",{});var qaa=s(I3e);M2r=r(qaa,"mvp"),qaa.forEach(t),E2r=r(EJe," \u2014 "),qZ=n(EJe,"A",{href:!0});var Daa=s(qZ);C2r=r(Daa,"MvpForSequenceClassification"),Daa.forEach(t),w2r=r(EJe," (MVP model)"),EJe.forEach(t),A2r=i(j),UM=n(j,"LI",{});var CJe=s(UM);N3e=n(CJe,"STRONG",{});var jaa=s(N3e);L2r=r(jaa,"nezha"),jaa.forEach(t),y2r=r(CJe," \u2014 "),DZ=n(CJe,"A",{href:!0});var Gaa=s(DZ);x2r=r(Gaa,"NezhaForSequenceClassification"),Gaa.forEach(t),$2r=r(CJe," (Nezha model)"),CJe.forEach(t),k2r=i(j),HM=n(j,"LI",{});var wJe=s(HM);q3e=n(wJe,"STRONG",{});var Oaa=s(q3e);S2r=r(Oaa,"nystromformer"),Oaa.forEach(t),R2r=r(wJe," \u2014 "),jZ=n(wJe,"A",{href:!0});var Vaa=s(jZ);P2r=r(Vaa,"NystromformerForSequenceClassification"),Vaa.forEach(t),B2r=r(wJe," (Nystr\xF6mformer model)"),wJe.forEach(t),I2r=i(j),JM=n(j,"LI",{});var AJe=s(JM);D3e=n(AJe,"STRONG",{});var Xaa=s(D3e);N2r=r(Xaa,"openai-gpt"),Xaa.forEach(t),q2r=r(AJe," \u2014 "),GZ=n(AJe,"A",{href:!0});var zaa=s(GZ);D2r=r(zaa,"OpenAIGPTForSequenceClassification"),zaa.forEach(t),j2r=r(AJe," (OpenAI GPT model)"),AJe.forEach(t),G2r=i(j),YM=n(j,"LI",{});var LJe=s(YM);j3e=n(LJe,"STRONG",{});var Qaa=s(j3e);O2r=r(Qaa,"opt"),Qaa.forEach(t),V2r=r(LJe," \u2014 "),OZ=n(LJe,"A",{href:!0});var Waa=s(OZ);X2r=r(Waa,"OPTForSequenceClassification"),Waa.forEach(t),z2r=r(LJe," (OPT model)"),LJe.forEach(t),Q2r=i(j),ZM=n(j,"LI",{});var yJe=s(ZM);G3e=n(yJe,"STRONG",{});var Uaa=s(G3e);W2r=r(Uaa,"perceiver"),Uaa.forEach(t),U2r=r(yJe," \u2014 "),VZ=n(yJe,"A",{href:!0});var Haa=s(VZ);H2r=r(Haa,"PerceiverForSequenceClassification"),Haa.forEach(t),J2r=r(yJe," (Perceiver model)"),yJe.forEach(t),Y2r=i(j),KM=n(j,"LI",{});var xJe=s(KM);O3e=n(xJe,"STRONG",{});var Jaa=s(O3e);Z2r=r(Jaa,"plbart"),Jaa.forEach(t),K2r=r(xJe," \u2014 "),XZ=n(xJe,"A",{href:!0});var Yaa=s(XZ);ebr=r(Yaa,"PLBartForSequenceClassification"),Yaa.forEach(t),obr=r(xJe," (PLBart model)"),xJe.forEach(t),rbr=i(j),eE=n(j,"LI",{});var $Je=s(eE);V3e=n($Je,"STRONG",{});var Zaa=s(V3e);tbr=r(Zaa,"qdqbert"),Zaa.forEach(t),abr=r($Je," \u2014 "),zZ=n($Je,"A",{href:!0});var Kaa=s(zZ);nbr=r(Kaa,"QDQBertForSequenceClassification"),Kaa.forEach(t),sbr=r($Je," (QDQBert model)"),$Je.forEach(t),lbr=i(j),oE=n(j,"LI",{});var kJe=s(oE);X3e=n(kJe,"STRONG",{});var ena=s(X3e);ibr=r(ena,"reformer"),ena.forEach(t),dbr=r(kJe," \u2014 "),QZ=n(kJe,"A",{href:!0});var ona=s(QZ);mbr=r(ona,"ReformerForSequenceClassification"),ona.forEach(t),cbr=r(kJe," (Reformer model)"),kJe.forEach(t),fbr=i(j),rE=n(j,"LI",{});var SJe=s(rE);z3e=n(SJe,"STRONG",{});var rna=s(z3e);gbr=r(rna,"rembert"),rna.forEach(t),hbr=r(SJe," \u2014 "),WZ=n(SJe,"A",{href:!0});var tna=s(WZ);ubr=r(tna,"RemBertForSequenceClassification"),tna.forEach(t),pbr=r(SJe," (RemBERT model)"),SJe.forEach(t),_br=i(j),tE=n(j,"LI",{});var RJe=s(tE);Q3e=n(RJe,"STRONG",{});var ana=s(Q3e);bbr=r(ana,"roberta"),ana.forEach(t),vbr=r(RJe," \u2014 "),UZ=n(RJe,"A",{href:!0});var nna=s(UZ);Fbr=r(nna,"RobertaForSequenceClassification"),nna.forEach(t),Tbr=r(RJe," (RoBERTa model)"),RJe.forEach(t),Mbr=i(j),aE=n(j,"LI",{});var PJe=s(aE);W3e=n(PJe,"STRONG",{});var sna=s(W3e);Ebr=r(sna,"roc_bert"),sna.forEach(t),Cbr=r(PJe," \u2014 "),HZ=n(PJe,"A",{href:!0});var lna=s(HZ);wbr=r(lna,"RoCBertForSequenceClassification"),lna.forEach(t),Abr=r(PJe," (RoCBert model)"),PJe.forEach(t),Lbr=i(j),nE=n(j,"LI",{});var BJe=s(nE);U3e=n(BJe,"STRONG",{});var ina=s(U3e);ybr=r(ina,"roformer"),ina.forEach(t),xbr=r(BJe," \u2014 "),JZ=n(BJe,"A",{href:!0});var dna=s(JZ);$br=r(dna,"RoFormerForSequenceClassification"),dna.forEach(t),kbr=r(BJe," (RoFormer model)"),BJe.forEach(t),Sbr=i(j),sE=n(j,"LI",{});var IJe=s(sE);H3e=n(IJe,"STRONG",{});var mna=s(H3e);Rbr=r(mna,"squeezebert"),mna.forEach(t),Pbr=r(IJe," \u2014 "),YZ=n(IJe,"A",{href:!0});var cna=s(YZ);Bbr=r(cna,"SqueezeBertForSequenceClassification"),cna.forEach(t),Ibr=r(IJe," (SqueezeBERT model)"),IJe.forEach(t),Nbr=i(j),lE=n(j,"LI",{});var NJe=s(lE);J3e=n(NJe,"STRONG",{});var fna=s(J3e);qbr=r(fna,"tapas"),fna.forEach(t),Dbr=r(NJe," \u2014 "),ZZ=n(NJe,"A",{href:!0});var gna=s(ZZ);jbr=r(gna,"TapasForSequenceClassification"),gna.forEach(t),Gbr=r(NJe," (TAPAS model)"),NJe.forEach(t),Obr=i(j),iE=n(j,"LI",{});var qJe=s(iE);Y3e=n(qJe,"STRONG",{});var hna=s(Y3e);Vbr=r(hna,"transfo-xl"),hna.forEach(t),Xbr=r(qJe," \u2014 "),KZ=n(qJe,"A",{href:!0});var una=s(KZ);zbr=r(una,"TransfoXLForSequenceClassification"),una.forEach(t),Qbr=r(qJe," (Transformer-XL model)"),qJe.forEach(t),Wbr=i(j),dE=n(j,"LI",{});var DJe=s(dE);Z3e=n(DJe,"STRONG",{});var pna=s(Z3e);Ubr=r(pna,"xlm"),pna.forEach(t),Hbr=r(DJe," \u2014 "),eK=n(DJe,"A",{href:!0});var _na=s(eK);Jbr=r(_na,"XLMForSequenceClassification"),_na.forEach(t),Ybr=r(DJe," (XLM model)"),DJe.forEach(t),Zbr=i(j),mE=n(j,"LI",{});var jJe=s(mE);K3e=n(jJe,"STRONG",{});var bna=s(K3e);Kbr=r(bna,"xlm-roberta"),bna.forEach(t),evr=r(jJe," \u2014 "),oK=n(jJe,"A",{href:!0});var vna=s(oK);ovr=r(vna,"XLMRobertaForSequenceClassification"),vna.forEach(t),rvr=r(jJe," (XLM-RoBERTa model)"),jJe.forEach(t),tvr=i(j),cE=n(j,"LI",{});var GJe=s(cE);e5e=n(GJe,"STRONG",{});var Fna=s(e5e);avr=r(Fna,"xlm-roberta-xl"),Fna.forEach(t),nvr=r(GJe," \u2014 "),rK=n(GJe,"A",{href:!0});var Tna=s(rK);svr=r(Tna,"XLMRobertaXLForSequenceClassification"),Tna.forEach(t),lvr=r(GJe," (XLM-RoBERTa-XL model)"),GJe.forEach(t),ivr=i(j),fE=n(j,"LI",{});var OJe=s(fE);o5e=n(OJe,"STRONG",{});var Mna=s(o5e);dvr=r(Mna,"xlnet"),Mna.forEach(t),mvr=r(OJe," \u2014 "),tK=n(OJe,"A",{href:!0});var Ena=s(tK);cvr=r(Ena,"XLNetForSequenceClassification"),Ena.forEach(t),fvr=r(OJe," (XLNet model)"),OJe.forEach(t),gvr=i(j),gE=n(j,"LI",{});var VJe=s(gE);r5e=n(VJe,"STRONG",{});var Cna=s(r5e);hvr=r(Cna,"yoso"),Cna.forEach(t),uvr=r(VJe," \u2014 "),aK=n(VJe,"A",{href:!0});var wna=s(aK);pvr=r(wna,"YosoForSequenceClassification"),wna.forEach(t),_vr=r(VJe," (YOSO model)"),VJe.forEach(t),j.forEach(t),bvr=i(qa),hE=n(qa,"P",{});var XJe=s(hE);vvr=r(XJe,"The model is set in evaluation mode by default using "),t5e=n(XJe,"CODE",{});var Ana=s(t5e);Fvr=r(Ana,"model.eval()"),Ana.forEach(t),Tvr=r(XJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),a5e=n(XJe,"CODE",{});var Lna=s(a5e);Mvr=r(Lna,"model.train()"),Lna.forEach(t),XJe.forEach(t),Evr=i(qa),T(uE.$$.fragment,qa),qa.forEach(t),Zl.forEach(t),zlo=i(c),im=n(c,"H2",{class:!0});var hmo=s(im);pE=n(hmo,"A",{id:!0,class:!0,href:!0});var yna=s(pE);n5e=n(yna,"SPAN",{});var xna=s(n5e);T(AS.$$.fragment,xna),xna.forEach(t),yna.forEach(t),Cvr=i(hmo),s5e=n(hmo,"SPAN",{});var $na=s(s5e);wvr=r($na,"AutoModelForMultipleChoice"),$na.forEach(t),hmo.forEach(t),Qlo=i(c),Wo=n(c,"DIV",{class:!0});var Kl=s(Wo);T(LS.$$.fragment,Kl),Avr=i(Kl),dm=n(Kl,"P",{});var Ffe=s(dm);Lvr=r(Ffe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),nK=n(Ffe,"A",{href:!0});var kna=s(nK);yvr=r(kna,"from_pretrained()"),kna.forEach(t),xvr=r(Ffe," class method or the "),sK=n(Ffe,"A",{href:!0});var Sna=s(sK);$vr=r(Sna,"from_config()"),Sna.forEach(t),kvr=r(Ffe,` class
method.`),Ffe.forEach(t),Svr=i(Kl),yS=n(Kl,"P",{});var umo=s(yS);Rvr=r(umo,"This class cannot be instantiated directly using "),l5e=n(umo,"CODE",{});var Rna=s(l5e);Pvr=r(Rna,"__init__()"),Rna.forEach(t),Bvr=r(umo," (throws an error)."),umo.forEach(t),Ivr=i(Kl),Rt=n(Kl,"DIV",{class:!0});var _x=s(Rt);T(xS.$$.fragment,_x),Nvr=i(_x),i5e=n(_x,"P",{});var Pna=s(i5e);qvr=r(Pna,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Pna.forEach(t),Dvr=i(_x),mm=n(_x,"P",{});var Tfe=s(mm);jvr=r(Tfe,`Note:
Loading a model from its configuration file does `),d5e=n(Tfe,"STRONG",{});var Bna=s(d5e);Gvr=r(Bna,"not"),Bna.forEach(t),Ovr=r(Tfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),lK=n(Tfe,"A",{href:!0});var Ina=s(lK);Vvr=r(Ina,"from_pretrained()"),Ina.forEach(t),Xvr=r(Tfe," to load the model weights."),Tfe.forEach(t),zvr=i(_x),T(_E.$$.fragment,_x),_x.forEach(t),Qvr=i(Kl),co=n(Kl,"DIV",{class:!0});var Da=s(co);T($S.$$.fragment,Da),Wvr=i(Da),m5e=n(Da,"P",{});var Nna=s(m5e);Uvr=r(Nna,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Nna.forEach(t),Hvr=i(Da),vn=n(Da,"P",{});var bx=s(vn);Jvr=r(bx,"The model class to instantiate is selected based on the "),c5e=n(bx,"CODE",{});var qna=s(c5e);Yvr=r(qna,"model_type"),qna.forEach(t),Zvr=r(bx,` property of the config object (either
passed as an argument or loaded from `),f5e=n(bx,"CODE",{});var Dna=s(f5e);Kvr=r(Dna,"pretrained_model_name_or_path"),Dna.forEach(t),eFr=r(bx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),g5e=n(bx,"CODE",{});var jna=s(g5e);oFr=r(jna,"pretrained_model_name_or_path"),jna.forEach(t),rFr=r(bx,":"),bx.forEach(t),tFr=i(Da),K=n(Da,"UL",{});var ee=s(K);bE=n(ee,"LI",{});var zJe=s(bE);h5e=n(zJe,"STRONG",{});var Gna=s(h5e);aFr=r(Gna,"albert"),Gna.forEach(t),nFr=r(zJe," \u2014 "),iK=n(zJe,"A",{href:!0});var Ona=s(iK);sFr=r(Ona,"AlbertForMultipleChoice"),Ona.forEach(t),lFr=r(zJe," (ALBERT model)"),zJe.forEach(t),iFr=i(ee),vE=n(ee,"LI",{});var QJe=s(vE);u5e=n(QJe,"STRONG",{});var Vna=s(u5e);dFr=r(Vna,"bert"),Vna.forEach(t),mFr=r(QJe," \u2014 "),dK=n(QJe,"A",{href:!0});var Xna=s(dK);cFr=r(Xna,"BertForMultipleChoice"),Xna.forEach(t),fFr=r(QJe," (BERT model)"),QJe.forEach(t),gFr=i(ee),FE=n(ee,"LI",{});var WJe=s(FE);p5e=n(WJe,"STRONG",{});var zna=s(p5e);hFr=r(zna,"big_bird"),zna.forEach(t),uFr=r(WJe," \u2014 "),mK=n(WJe,"A",{href:!0});var Qna=s(mK);pFr=r(Qna,"BigBirdForMultipleChoice"),Qna.forEach(t),_Fr=r(WJe," (BigBird model)"),WJe.forEach(t),bFr=i(ee),TE=n(ee,"LI",{});var UJe=s(TE);_5e=n(UJe,"STRONG",{});var Wna=s(_5e);vFr=r(Wna,"camembert"),Wna.forEach(t),FFr=r(UJe," \u2014 "),cK=n(UJe,"A",{href:!0});var Una=s(cK);TFr=r(Una,"CamembertForMultipleChoice"),Una.forEach(t),MFr=r(UJe," (CamemBERT model)"),UJe.forEach(t),EFr=i(ee),ME=n(ee,"LI",{});var HJe=s(ME);b5e=n(HJe,"STRONG",{});var Hna=s(b5e);CFr=r(Hna,"canine"),Hna.forEach(t),wFr=r(HJe," \u2014 "),fK=n(HJe,"A",{href:!0});var Jna=s(fK);AFr=r(Jna,"CanineForMultipleChoice"),Jna.forEach(t),LFr=r(HJe," (CANINE model)"),HJe.forEach(t),yFr=i(ee),EE=n(ee,"LI",{});var JJe=s(EE);v5e=n(JJe,"STRONG",{});var Yna=s(v5e);xFr=r(Yna,"convbert"),Yna.forEach(t),$Fr=r(JJe," \u2014 "),gK=n(JJe,"A",{href:!0});var Zna=s(gK);kFr=r(Zna,"ConvBertForMultipleChoice"),Zna.forEach(t),SFr=r(JJe," (ConvBERT model)"),JJe.forEach(t),RFr=i(ee),CE=n(ee,"LI",{});var YJe=s(CE);F5e=n(YJe,"STRONG",{});var Kna=s(F5e);PFr=r(Kna,"data2vec-text"),Kna.forEach(t),BFr=r(YJe," \u2014 "),hK=n(YJe,"A",{href:!0});var esa=s(hK);IFr=r(esa,"Data2VecTextForMultipleChoice"),esa.forEach(t),NFr=r(YJe," (Data2VecText model)"),YJe.forEach(t),qFr=i(ee),wE=n(ee,"LI",{});var ZJe=s(wE);T5e=n(ZJe,"STRONG",{});var osa=s(T5e);DFr=r(osa,"deberta-v2"),osa.forEach(t),jFr=r(ZJe," \u2014 "),uK=n(ZJe,"A",{href:!0});var rsa=s(uK);GFr=r(rsa,"DebertaV2ForMultipleChoice"),rsa.forEach(t),OFr=r(ZJe," (DeBERTa-v2 model)"),ZJe.forEach(t),VFr=i(ee),AE=n(ee,"LI",{});var KJe=s(AE);M5e=n(KJe,"STRONG",{});var tsa=s(M5e);XFr=r(tsa,"distilbert"),tsa.forEach(t),zFr=r(KJe," \u2014 "),pK=n(KJe,"A",{href:!0});var asa=s(pK);QFr=r(asa,"DistilBertForMultipleChoice"),asa.forEach(t),WFr=r(KJe," (DistilBERT model)"),KJe.forEach(t),UFr=i(ee),LE=n(ee,"LI",{});var eYe=s(LE);E5e=n(eYe,"STRONG",{});var nsa=s(E5e);HFr=r(nsa,"electra"),nsa.forEach(t),JFr=r(eYe," \u2014 "),_K=n(eYe,"A",{href:!0});var ssa=s(_K);YFr=r(ssa,"ElectraForMultipleChoice"),ssa.forEach(t),ZFr=r(eYe," (ELECTRA model)"),eYe.forEach(t),KFr=i(ee),yE=n(ee,"LI",{});var oYe=s(yE);C5e=n(oYe,"STRONG",{});var lsa=s(C5e);eTr=r(lsa,"ernie"),lsa.forEach(t),oTr=r(oYe," \u2014 "),bK=n(oYe,"A",{href:!0});var isa=s(bK);rTr=r(isa,"ErnieForMultipleChoice"),isa.forEach(t),tTr=r(oYe," (ERNIE model)"),oYe.forEach(t),aTr=i(ee),xE=n(ee,"LI",{});var rYe=s(xE);w5e=n(rYe,"STRONG",{});var dsa=s(w5e);nTr=r(dsa,"flaubert"),dsa.forEach(t),sTr=r(rYe," \u2014 "),vK=n(rYe,"A",{href:!0});var msa=s(vK);lTr=r(msa,"FlaubertForMultipleChoice"),msa.forEach(t),iTr=r(rYe," (FlauBERT model)"),rYe.forEach(t),dTr=i(ee),$E=n(ee,"LI",{});var tYe=s($E);A5e=n(tYe,"STRONG",{});var csa=s(A5e);mTr=r(csa,"fnet"),csa.forEach(t),cTr=r(tYe," \u2014 "),FK=n(tYe,"A",{href:!0});var fsa=s(FK);fTr=r(fsa,"FNetForMultipleChoice"),fsa.forEach(t),gTr=r(tYe," (FNet model)"),tYe.forEach(t),hTr=i(ee),kE=n(ee,"LI",{});var aYe=s(kE);L5e=n(aYe,"STRONG",{});var gsa=s(L5e);uTr=r(gsa,"funnel"),gsa.forEach(t),pTr=r(aYe," \u2014 "),TK=n(aYe,"A",{href:!0});var hsa=s(TK);_Tr=r(hsa,"FunnelForMultipleChoice"),hsa.forEach(t),bTr=r(aYe," (Funnel Transformer model)"),aYe.forEach(t),vTr=i(ee),SE=n(ee,"LI",{});var nYe=s(SE);y5e=n(nYe,"STRONG",{});var usa=s(y5e);FTr=r(usa,"ibert"),usa.forEach(t),TTr=r(nYe," \u2014 "),MK=n(nYe,"A",{href:!0});var psa=s(MK);MTr=r(psa,"IBertForMultipleChoice"),psa.forEach(t),ETr=r(nYe," (I-BERT model)"),nYe.forEach(t),CTr=i(ee),RE=n(ee,"LI",{});var sYe=s(RE);x5e=n(sYe,"STRONG",{});var _sa=s(x5e);wTr=r(_sa,"longformer"),_sa.forEach(t),ATr=r(sYe," \u2014 "),EK=n(sYe,"A",{href:!0});var bsa=s(EK);LTr=r(bsa,"LongformerForMultipleChoice"),bsa.forEach(t),yTr=r(sYe," (Longformer model)"),sYe.forEach(t),xTr=i(ee),PE=n(ee,"LI",{});var lYe=s(PE);$5e=n(lYe,"STRONG",{});var vsa=s($5e);$Tr=r(vsa,"luke"),vsa.forEach(t),kTr=r(lYe," \u2014 "),CK=n(lYe,"A",{href:!0});var Fsa=s(CK);STr=r(Fsa,"LukeForMultipleChoice"),Fsa.forEach(t),RTr=r(lYe," (LUKE model)"),lYe.forEach(t),PTr=i(ee),BE=n(ee,"LI",{});var iYe=s(BE);k5e=n(iYe,"STRONG",{});var Tsa=s(k5e);BTr=r(Tsa,"megatron-bert"),Tsa.forEach(t),ITr=r(iYe," \u2014 "),wK=n(iYe,"A",{href:!0});var Msa=s(wK);NTr=r(Msa,"MegatronBertForMultipleChoice"),Msa.forEach(t),qTr=r(iYe," (Megatron-BERT model)"),iYe.forEach(t),DTr=i(ee),IE=n(ee,"LI",{});var dYe=s(IE);S5e=n(dYe,"STRONG",{});var Esa=s(S5e);jTr=r(Esa,"mobilebert"),Esa.forEach(t),GTr=r(dYe," \u2014 "),AK=n(dYe,"A",{href:!0});var Csa=s(AK);OTr=r(Csa,"MobileBertForMultipleChoice"),Csa.forEach(t),VTr=r(dYe," (MobileBERT model)"),dYe.forEach(t),XTr=i(ee),NE=n(ee,"LI",{});var mYe=s(NE);R5e=n(mYe,"STRONG",{});var wsa=s(R5e);zTr=r(wsa,"mpnet"),wsa.forEach(t),QTr=r(mYe," \u2014 "),LK=n(mYe,"A",{href:!0});var Asa=s(LK);WTr=r(Asa,"MPNetForMultipleChoice"),Asa.forEach(t),UTr=r(mYe," (MPNet model)"),mYe.forEach(t),HTr=i(ee),qE=n(ee,"LI",{});var cYe=s(qE);P5e=n(cYe,"STRONG",{});var Lsa=s(P5e);JTr=r(Lsa,"nezha"),Lsa.forEach(t),YTr=r(cYe," \u2014 "),yK=n(cYe,"A",{href:!0});var ysa=s(yK);ZTr=r(ysa,"NezhaForMultipleChoice"),ysa.forEach(t),KTr=r(cYe," (Nezha model)"),cYe.forEach(t),eMr=i(ee),DE=n(ee,"LI",{});var fYe=s(DE);B5e=n(fYe,"STRONG",{});var xsa=s(B5e);oMr=r(xsa,"nystromformer"),xsa.forEach(t),rMr=r(fYe," \u2014 "),xK=n(fYe,"A",{href:!0});var $sa=s(xK);tMr=r($sa,"NystromformerForMultipleChoice"),$sa.forEach(t),aMr=r(fYe," (Nystr\xF6mformer model)"),fYe.forEach(t),nMr=i(ee),jE=n(ee,"LI",{});var gYe=s(jE);I5e=n(gYe,"STRONG",{});var ksa=s(I5e);sMr=r(ksa,"qdqbert"),ksa.forEach(t),lMr=r(gYe," \u2014 "),$K=n(gYe,"A",{href:!0});var Ssa=s($K);iMr=r(Ssa,"QDQBertForMultipleChoice"),Ssa.forEach(t),dMr=r(gYe," (QDQBert model)"),gYe.forEach(t),mMr=i(ee),GE=n(ee,"LI",{});var hYe=s(GE);N5e=n(hYe,"STRONG",{});var Rsa=s(N5e);cMr=r(Rsa,"rembert"),Rsa.forEach(t),fMr=r(hYe," \u2014 "),kK=n(hYe,"A",{href:!0});var Psa=s(kK);gMr=r(Psa,"RemBertForMultipleChoice"),Psa.forEach(t),hMr=r(hYe," (RemBERT model)"),hYe.forEach(t),uMr=i(ee),OE=n(ee,"LI",{});var uYe=s(OE);q5e=n(uYe,"STRONG",{});var Bsa=s(q5e);pMr=r(Bsa,"roberta"),Bsa.forEach(t),_Mr=r(uYe," \u2014 "),SK=n(uYe,"A",{href:!0});var Isa=s(SK);bMr=r(Isa,"RobertaForMultipleChoice"),Isa.forEach(t),vMr=r(uYe," (RoBERTa model)"),uYe.forEach(t),FMr=i(ee),VE=n(ee,"LI",{});var pYe=s(VE);D5e=n(pYe,"STRONG",{});var Nsa=s(D5e);TMr=r(Nsa,"roc_bert"),Nsa.forEach(t),MMr=r(pYe," \u2014 "),RK=n(pYe,"A",{href:!0});var qsa=s(RK);EMr=r(qsa,"RoCBertForMultipleChoice"),qsa.forEach(t),CMr=r(pYe," (RoCBert model)"),pYe.forEach(t),wMr=i(ee),XE=n(ee,"LI",{});var _Ye=s(XE);j5e=n(_Ye,"STRONG",{});var Dsa=s(j5e);AMr=r(Dsa,"roformer"),Dsa.forEach(t),LMr=r(_Ye," \u2014 "),PK=n(_Ye,"A",{href:!0});var jsa=s(PK);yMr=r(jsa,"RoFormerForMultipleChoice"),jsa.forEach(t),xMr=r(_Ye," (RoFormer model)"),_Ye.forEach(t),$Mr=i(ee),zE=n(ee,"LI",{});var bYe=s(zE);G5e=n(bYe,"STRONG",{});var Gsa=s(G5e);kMr=r(Gsa,"squeezebert"),Gsa.forEach(t),SMr=r(bYe," \u2014 "),BK=n(bYe,"A",{href:!0});var Osa=s(BK);RMr=r(Osa,"SqueezeBertForMultipleChoice"),Osa.forEach(t),PMr=r(bYe," (SqueezeBERT model)"),bYe.forEach(t),BMr=i(ee),QE=n(ee,"LI",{});var vYe=s(QE);O5e=n(vYe,"STRONG",{});var Vsa=s(O5e);IMr=r(Vsa,"xlm"),Vsa.forEach(t),NMr=r(vYe," \u2014 "),IK=n(vYe,"A",{href:!0});var Xsa=s(IK);qMr=r(Xsa,"XLMForMultipleChoice"),Xsa.forEach(t),DMr=r(vYe," (XLM model)"),vYe.forEach(t),jMr=i(ee),WE=n(ee,"LI",{});var FYe=s(WE);V5e=n(FYe,"STRONG",{});var zsa=s(V5e);GMr=r(zsa,"xlm-roberta"),zsa.forEach(t),OMr=r(FYe," \u2014 "),NK=n(FYe,"A",{href:!0});var Qsa=s(NK);VMr=r(Qsa,"XLMRobertaForMultipleChoice"),Qsa.forEach(t),XMr=r(FYe," (XLM-RoBERTa model)"),FYe.forEach(t),zMr=i(ee),UE=n(ee,"LI",{});var TYe=s(UE);X5e=n(TYe,"STRONG",{});var Wsa=s(X5e);QMr=r(Wsa,"xlm-roberta-xl"),Wsa.forEach(t),WMr=r(TYe," \u2014 "),qK=n(TYe,"A",{href:!0});var Usa=s(qK);UMr=r(Usa,"XLMRobertaXLForMultipleChoice"),Usa.forEach(t),HMr=r(TYe," (XLM-RoBERTa-XL model)"),TYe.forEach(t),JMr=i(ee),HE=n(ee,"LI",{});var MYe=s(HE);z5e=n(MYe,"STRONG",{});var Hsa=s(z5e);YMr=r(Hsa,"xlnet"),Hsa.forEach(t),ZMr=r(MYe," \u2014 "),DK=n(MYe,"A",{href:!0});var Jsa=s(DK);KMr=r(Jsa,"XLNetForMultipleChoice"),Jsa.forEach(t),eEr=r(MYe," (XLNet model)"),MYe.forEach(t),oEr=i(ee),JE=n(ee,"LI",{});var EYe=s(JE);Q5e=n(EYe,"STRONG",{});var Ysa=s(Q5e);rEr=r(Ysa,"yoso"),Ysa.forEach(t),tEr=r(EYe," \u2014 "),jK=n(EYe,"A",{href:!0});var Zsa=s(jK);aEr=r(Zsa,"YosoForMultipleChoice"),Zsa.forEach(t),nEr=r(EYe," (YOSO model)"),EYe.forEach(t),ee.forEach(t),sEr=i(Da),YE=n(Da,"P",{});var CYe=s(YE);lEr=r(CYe,"The model is set in evaluation mode by default using "),W5e=n(CYe,"CODE",{});var Ksa=s(W5e);iEr=r(Ksa,"model.eval()"),Ksa.forEach(t),dEr=r(CYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),U5e=n(CYe,"CODE",{});var ela=s(U5e);mEr=r(ela,"model.train()"),ela.forEach(t),CYe.forEach(t),cEr=i(Da),T(ZE.$$.fragment,Da),Da.forEach(t),Kl.forEach(t),Wlo=i(c),cm=n(c,"H2",{class:!0});var pmo=s(cm);KE=n(pmo,"A",{id:!0,class:!0,href:!0});var ola=s(KE);H5e=n(ola,"SPAN",{});var rla=s(H5e);T(kS.$$.fragment,rla),rla.forEach(t),ola.forEach(t),fEr=i(pmo),J5e=n(pmo,"SPAN",{});var tla=s(J5e);gEr=r(tla,"AutoModelForNextSentencePrediction"),tla.forEach(t),pmo.forEach(t),Ulo=i(c),Uo=n(c,"DIV",{class:!0});var ei=s(Uo);T(SS.$$.fragment,ei),hEr=i(ei),fm=n(ei,"P",{});var Mfe=s(fm);uEr=r(Mfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),GK=n(Mfe,"A",{href:!0});var ala=s(GK);pEr=r(ala,"from_pretrained()"),ala.forEach(t),_Er=r(Mfe," class method or the "),OK=n(Mfe,"A",{href:!0});var nla=s(OK);bEr=r(nla,"from_config()"),nla.forEach(t),vEr=r(Mfe,` class
method.`),Mfe.forEach(t),FEr=i(ei),RS=n(ei,"P",{});var _mo=s(RS);TEr=r(_mo,"This class cannot be instantiated directly using "),Y5e=n(_mo,"CODE",{});var sla=s(Y5e);MEr=r(sla,"__init__()"),sla.forEach(t),EEr=r(_mo," (throws an error)."),_mo.forEach(t),CEr=i(ei),Pt=n(ei,"DIV",{class:!0});var vx=s(Pt);T(PS.$$.fragment,vx),wEr=i(vx),Z5e=n(vx,"P",{});var lla=s(Z5e);AEr=r(lla,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),lla.forEach(t),LEr=i(vx),gm=n(vx,"P",{});var Efe=s(gm);yEr=r(Efe,`Note:
Loading a model from its configuration file does `),K5e=n(Efe,"STRONG",{});var ila=s(K5e);xEr=r(ila,"not"),ila.forEach(t),$Er=r(Efe,` load the model weights. It only affects the
model\u2019s configuration. Use `),VK=n(Efe,"A",{href:!0});var dla=s(VK);kEr=r(dla,"from_pretrained()"),dla.forEach(t),SEr=r(Efe," to load the model weights."),Efe.forEach(t),REr=i(vx),T(e4.$$.fragment,vx),vx.forEach(t),PEr=i(ei),fo=n(ei,"DIV",{class:!0});var ja=s(fo);T(BS.$$.fragment,ja),BEr=i(ja),e0e=n(ja,"P",{});var mla=s(e0e);IEr=r(mla,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),mla.forEach(t),NEr=i(ja),Fn=n(ja,"P",{});var Fx=s(Fn);qEr=r(Fx,"The model class to instantiate is selected based on the "),o0e=n(Fx,"CODE",{});var cla=s(o0e);DEr=r(cla,"model_type"),cla.forEach(t),jEr=r(Fx,` property of the config object (either
passed as an argument or loaded from `),r0e=n(Fx,"CODE",{});var fla=s(r0e);GEr=r(fla,"pretrained_model_name_or_path"),fla.forEach(t),OEr=r(Fx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),t0e=n(Fx,"CODE",{});var gla=s(t0e);VEr=r(gla,"pretrained_model_name_or_path"),gla.forEach(t),XEr=r(Fx,":"),Fx.forEach(t),zEr=i(ja),Ye=n(ja,"UL",{});var bt=s(Ye);o4=n(bt,"LI",{});var wYe=s(o4);a0e=n(wYe,"STRONG",{});var hla=s(a0e);QEr=r(hla,"bert"),hla.forEach(t),WEr=r(wYe," \u2014 "),XK=n(wYe,"A",{href:!0});var ula=s(XK);UEr=r(ula,"BertForNextSentencePrediction"),ula.forEach(t),HEr=r(wYe," (BERT model)"),wYe.forEach(t),JEr=i(bt),r4=n(bt,"LI",{});var AYe=s(r4);n0e=n(AYe,"STRONG",{});var pla=s(n0e);YEr=r(pla,"ernie"),pla.forEach(t),ZEr=r(AYe," \u2014 "),zK=n(AYe,"A",{href:!0});var _la=s(zK);KEr=r(_la,"ErnieForNextSentencePrediction"),_la.forEach(t),e4r=r(AYe," (ERNIE model)"),AYe.forEach(t),o4r=i(bt),t4=n(bt,"LI",{});var LYe=s(t4);s0e=n(LYe,"STRONG",{});var bla=s(s0e);r4r=r(bla,"fnet"),bla.forEach(t),t4r=r(LYe," \u2014 "),QK=n(LYe,"A",{href:!0});var vla=s(QK);a4r=r(vla,"FNetForNextSentencePrediction"),vla.forEach(t),n4r=r(LYe," (FNet model)"),LYe.forEach(t),s4r=i(bt),a4=n(bt,"LI",{});var yYe=s(a4);l0e=n(yYe,"STRONG",{});var Fla=s(l0e);l4r=r(Fla,"megatron-bert"),Fla.forEach(t),i4r=r(yYe," \u2014 "),WK=n(yYe,"A",{href:!0});var Tla=s(WK);d4r=r(Tla,"MegatronBertForNextSentencePrediction"),Tla.forEach(t),m4r=r(yYe," (Megatron-BERT model)"),yYe.forEach(t),c4r=i(bt),n4=n(bt,"LI",{});var xYe=s(n4);i0e=n(xYe,"STRONG",{});var Mla=s(i0e);f4r=r(Mla,"mobilebert"),Mla.forEach(t),g4r=r(xYe," \u2014 "),UK=n(xYe,"A",{href:!0});var Ela=s(UK);h4r=r(Ela,"MobileBertForNextSentencePrediction"),Ela.forEach(t),u4r=r(xYe," (MobileBERT model)"),xYe.forEach(t),p4r=i(bt),s4=n(bt,"LI",{});var $Ye=s(s4);d0e=n($Ye,"STRONG",{});var Cla=s(d0e);_4r=r(Cla,"nezha"),Cla.forEach(t),b4r=r($Ye," \u2014 "),HK=n($Ye,"A",{href:!0});var wla=s(HK);v4r=r(wla,"NezhaForNextSentencePrediction"),wla.forEach(t),F4r=r($Ye," (Nezha model)"),$Ye.forEach(t),T4r=i(bt),l4=n(bt,"LI",{});var kYe=s(l4);m0e=n(kYe,"STRONG",{});var Ala=s(m0e);M4r=r(Ala,"qdqbert"),Ala.forEach(t),E4r=r(kYe," \u2014 "),JK=n(kYe,"A",{href:!0});var Lla=s(JK);C4r=r(Lla,"QDQBertForNextSentencePrediction"),Lla.forEach(t),w4r=r(kYe," (QDQBert model)"),kYe.forEach(t),bt.forEach(t),A4r=i(ja),i4=n(ja,"P",{});var SYe=s(i4);L4r=r(SYe,"The model is set in evaluation mode by default using "),c0e=n(SYe,"CODE",{});var yla=s(c0e);y4r=r(yla,"model.eval()"),yla.forEach(t),x4r=r(SYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),f0e=n(SYe,"CODE",{});var xla=s(f0e);$4r=r(xla,"model.train()"),xla.forEach(t),SYe.forEach(t),k4r=i(ja),T(d4.$$.fragment,ja),ja.forEach(t),ei.forEach(t),Hlo=i(c),hm=n(c,"H2",{class:!0});var bmo=s(hm);m4=n(bmo,"A",{id:!0,class:!0,href:!0});var $la=s(m4);g0e=n($la,"SPAN",{});var kla=s(g0e);T(IS.$$.fragment,kla),kla.forEach(t),$la.forEach(t),S4r=i(bmo),h0e=n(bmo,"SPAN",{});var Sla=s(h0e);R4r=r(Sla,"AutoModelForTokenClassification"),Sla.forEach(t),bmo.forEach(t),Jlo=i(c),Ho=n(c,"DIV",{class:!0});var oi=s(Ho);T(NS.$$.fragment,oi),P4r=i(oi),um=n(oi,"P",{});var Cfe=s(um);B4r=r(Cfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),YK=n(Cfe,"A",{href:!0});var Rla=s(YK);I4r=r(Rla,"from_pretrained()"),Rla.forEach(t),N4r=r(Cfe," class method or the "),ZK=n(Cfe,"A",{href:!0});var Pla=s(ZK);q4r=r(Pla,"from_config()"),Pla.forEach(t),D4r=r(Cfe,` class
method.`),Cfe.forEach(t),j4r=i(oi),qS=n(oi,"P",{});var vmo=s(qS);G4r=r(vmo,"This class cannot be instantiated directly using "),u0e=n(vmo,"CODE",{});var Bla=s(u0e);O4r=r(Bla,"__init__()"),Bla.forEach(t),V4r=r(vmo," (throws an error)."),vmo.forEach(t),X4r=i(oi),Bt=n(oi,"DIV",{class:!0});var Tx=s(Bt);T(DS.$$.fragment,Tx),z4r=i(Tx),p0e=n(Tx,"P",{});var Ila=s(p0e);Q4r=r(Ila,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Ila.forEach(t),W4r=i(Tx),pm=n(Tx,"P",{});var wfe=s(pm);U4r=r(wfe,`Note:
Loading a model from its configuration file does `),_0e=n(wfe,"STRONG",{});var Nla=s(_0e);H4r=r(Nla,"not"),Nla.forEach(t),J4r=r(wfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),KK=n(wfe,"A",{href:!0});var qla=s(KK);Y4r=r(qla,"from_pretrained()"),qla.forEach(t),Z4r=r(wfe," to load the model weights."),wfe.forEach(t),K4r=i(Tx),T(c4.$$.fragment,Tx),Tx.forEach(t),eCr=i(oi),go=n(oi,"DIV",{class:!0});var Ga=s(go);T(jS.$$.fragment,Ga),oCr=i(Ga),b0e=n(Ga,"P",{});var Dla=s(b0e);rCr=r(Dla,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Dla.forEach(t),tCr=i(Ga),Tn=n(Ga,"P",{});var Mx=s(Tn);aCr=r(Mx,"The model class to instantiate is selected based on the "),v0e=n(Mx,"CODE",{});var jla=s(v0e);nCr=r(jla,"model_type"),jla.forEach(t),sCr=r(Mx,` property of the config object (either
passed as an argument or loaded from `),F0e=n(Mx,"CODE",{});var Gla=s(F0e);lCr=r(Gla,"pretrained_model_name_or_path"),Gla.forEach(t),iCr=r(Mx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T0e=n(Mx,"CODE",{});var Ola=s(T0e);dCr=r(Ola,"pretrained_model_name_or_path"),Ola.forEach(t),mCr=r(Mx,":"),Mx.forEach(t),cCr=i(Ga),U=n(Ga,"UL",{});var J=s(U);f4=n(J,"LI",{});var RYe=s(f4);M0e=n(RYe,"STRONG",{});var Vla=s(M0e);fCr=r(Vla,"albert"),Vla.forEach(t),gCr=r(RYe," \u2014 "),eee=n(RYe,"A",{href:!0});var Xla=s(eee);hCr=r(Xla,"AlbertForTokenClassification"),Xla.forEach(t),uCr=r(RYe," (ALBERT model)"),RYe.forEach(t),pCr=i(J),g4=n(J,"LI",{});var PYe=s(g4);E0e=n(PYe,"STRONG",{});var zla=s(E0e);_Cr=r(zla,"bert"),zla.forEach(t),bCr=r(PYe," \u2014 "),oee=n(PYe,"A",{href:!0});var Qla=s(oee);vCr=r(Qla,"BertForTokenClassification"),Qla.forEach(t),FCr=r(PYe," (BERT model)"),PYe.forEach(t),TCr=i(J),h4=n(J,"LI",{});var BYe=s(h4);C0e=n(BYe,"STRONG",{});var Wla=s(C0e);MCr=r(Wla,"big_bird"),Wla.forEach(t),ECr=r(BYe," \u2014 "),ree=n(BYe,"A",{href:!0});var Ula=s(ree);CCr=r(Ula,"BigBirdForTokenClassification"),Ula.forEach(t),wCr=r(BYe," (BigBird model)"),BYe.forEach(t),ACr=i(J),u4=n(J,"LI",{});var IYe=s(u4);w0e=n(IYe,"STRONG",{});var Hla=s(w0e);LCr=r(Hla,"bloom"),Hla.forEach(t),yCr=r(IYe," \u2014 "),tee=n(IYe,"A",{href:!0});var Jla=s(tee);xCr=r(Jla,"BloomForTokenClassification"),Jla.forEach(t),$Cr=r(IYe," (BLOOM model)"),IYe.forEach(t),kCr=i(J),p4=n(J,"LI",{});var NYe=s(p4);A0e=n(NYe,"STRONG",{});var Yla=s(A0e);SCr=r(Yla,"camembert"),Yla.forEach(t),RCr=r(NYe," \u2014 "),aee=n(NYe,"A",{href:!0});var Zla=s(aee);PCr=r(Zla,"CamembertForTokenClassification"),Zla.forEach(t),BCr=r(NYe," (CamemBERT model)"),NYe.forEach(t),ICr=i(J),_4=n(J,"LI",{});var qYe=s(_4);L0e=n(qYe,"STRONG",{});var Kla=s(L0e);NCr=r(Kla,"canine"),Kla.forEach(t),qCr=r(qYe," \u2014 "),nee=n(qYe,"A",{href:!0});var eia=s(nee);DCr=r(eia,"CanineForTokenClassification"),eia.forEach(t),jCr=r(qYe," (CANINE model)"),qYe.forEach(t),GCr=i(J),b4=n(J,"LI",{});var DYe=s(b4);y0e=n(DYe,"STRONG",{});var oia=s(y0e);OCr=r(oia,"convbert"),oia.forEach(t),VCr=r(DYe," \u2014 "),see=n(DYe,"A",{href:!0});var ria=s(see);XCr=r(ria,"ConvBertForTokenClassification"),ria.forEach(t),zCr=r(DYe," (ConvBERT model)"),DYe.forEach(t),QCr=i(J),v4=n(J,"LI",{});var jYe=s(v4);x0e=n(jYe,"STRONG",{});var tia=s(x0e);WCr=r(tia,"data2vec-text"),tia.forEach(t),UCr=r(jYe," \u2014 "),lee=n(jYe,"A",{href:!0});var aia=s(lee);HCr=r(aia,"Data2VecTextForTokenClassification"),aia.forEach(t),JCr=r(jYe," (Data2VecText model)"),jYe.forEach(t),YCr=i(J),F4=n(J,"LI",{});var GYe=s(F4);$0e=n(GYe,"STRONG",{});var nia=s($0e);ZCr=r(nia,"deberta"),nia.forEach(t),KCr=r(GYe," \u2014 "),iee=n(GYe,"A",{href:!0});var sia=s(iee);e3r=r(sia,"DebertaForTokenClassification"),sia.forEach(t),o3r=r(GYe," (DeBERTa model)"),GYe.forEach(t),r3r=i(J),T4=n(J,"LI",{});var OYe=s(T4);k0e=n(OYe,"STRONG",{});var lia=s(k0e);t3r=r(lia,"deberta-v2"),lia.forEach(t),a3r=r(OYe," \u2014 "),dee=n(OYe,"A",{href:!0});var iia=s(dee);n3r=r(iia,"DebertaV2ForTokenClassification"),iia.forEach(t),s3r=r(OYe," (DeBERTa-v2 model)"),OYe.forEach(t),l3r=i(J),M4=n(J,"LI",{});var VYe=s(M4);S0e=n(VYe,"STRONG",{});var dia=s(S0e);i3r=r(dia,"distilbert"),dia.forEach(t),d3r=r(VYe," \u2014 "),mee=n(VYe,"A",{href:!0});var mia=s(mee);m3r=r(mia,"DistilBertForTokenClassification"),mia.forEach(t),c3r=r(VYe," (DistilBERT model)"),VYe.forEach(t),f3r=i(J),E4=n(J,"LI",{});var XYe=s(E4);R0e=n(XYe,"STRONG",{});var cia=s(R0e);g3r=r(cia,"electra"),cia.forEach(t),h3r=r(XYe," \u2014 "),cee=n(XYe,"A",{href:!0});var fia=s(cee);u3r=r(fia,"ElectraForTokenClassification"),fia.forEach(t),p3r=r(XYe," (ELECTRA model)"),XYe.forEach(t),_3r=i(J),C4=n(J,"LI",{});var zYe=s(C4);P0e=n(zYe,"STRONG",{});var gia=s(P0e);b3r=r(gia,"ernie"),gia.forEach(t),v3r=r(zYe," \u2014 "),fee=n(zYe,"A",{href:!0});var hia=s(fee);F3r=r(hia,"ErnieForTokenClassification"),hia.forEach(t),T3r=r(zYe," (ERNIE model)"),zYe.forEach(t),M3r=i(J),w4=n(J,"LI",{});var QYe=s(w4);B0e=n(QYe,"STRONG",{});var uia=s(B0e);E3r=r(uia,"esm"),uia.forEach(t),C3r=r(QYe," \u2014 "),gee=n(QYe,"A",{href:!0});var pia=s(gee);w3r=r(pia,"EsmForTokenClassification"),pia.forEach(t),A3r=r(QYe," (ESM model)"),QYe.forEach(t),L3r=i(J),A4=n(J,"LI",{});var WYe=s(A4);I0e=n(WYe,"STRONG",{});var _ia=s(I0e);y3r=r(_ia,"flaubert"),_ia.forEach(t),x3r=r(WYe," \u2014 "),hee=n(WYe,"A",{href:!0});var bia=s(hee);$3r=r(bia,"FlaubertForTokenClassification"),bia.forEach(t),k3r=r(WYe," (FlauBERT model)"),WYe.forEach(t),S3r=i(J),L4=n(J,"LI",{});var UYe=s(L4);N0e=n(UYe,"STRONG",{});var via=s(N0e);R3r=r(via,"fnet"),via.forEach(t),P3r=r(UYe," \u2014 "),uee=n(UYe,"A",{href:!0});var Fia=s(uee);B3r=r(Fia,"FNetForTokenClassification"),Fia.forEach(t),I3r=r(UYe," (FNet model)"),UYe.forEach(t),N3r=i(J),y4=n(J,"LI",{});var HYe=s(y4);q0e=n(HYe,"STRONG",{});var Tia=s(q0e);q3r=r(Tia,"funnel"),Tia.forEach(t),D3r=r(HYe," \u2014 "),pee=n(HYe,"A",{href:!0});var Mia=s(pee);j3r=r(Mia,"FunnelForTokenClassification"),Mia.forEach(t),G3r=r(HYe," (Funnel Transformer model)"),HYe.forEach(t),O3r=i(J),x4=n(J,"LI",{});var JYe=s(x4);D0e=n(JYe,"STRONG",{});var Eia=s(D0e);V3r=r(Eia,"gpt2"),Eia.forEach(t),X3r=r(JYe," \u2014 "),_ee=n(JYe,"A",{href:!0});var Cia=s(_ee);z3r=r(Cia,"GPT2ForTokenClassification"),Cia.forEach(t),Q3r=r(JYe," (OpenAI GPT-2 model)"),JYe.forEach(t),W3r=i(J),$4=n(J,"LI",{});var YYe=s($4);j0e=n(YYe,"STRONG",{});var wia=s(j0e);U3r=r(wia,"ibert"),wia.forEach(t),H3r=r(YYe," \u2014 "),bee=n(YYe,"A",{href:!0});var Aia=s(bee);J3r=r(Aia,"IBertForTokenClassification"),Aia.forEach(t),Y3r=r(YYe," (I-BERT model)"),YYe.forEach(t),Z3r=i(J),k4=n(J,"LI",{});var ZYe=s(k4);G0e=n(ZYe,"STRONG",{});var Lia=s(G0e);K3r=r(Lia,"layoutlm"),Lia.forEach(t),e5r=r(ZYe," \u2014 "),vee=n(ZYe,"A",{href:!0});var yia=s(vee);o5r=r(yia,"LayoutLMForTokenClassification"),yia.forEach(t),r5r=r(ZYe," (LayoutLM model)"),ZYe.forEach(t),t5r=i(J),S4=n(J,"LI",{});var KYe=s(S4);O0e=n(KYe,"STRONG",{});var xia=s(O0e);a5r=r(xia,"layoutlmv2"),xia.forEach(t),n5r=r(KYe," \u2014 "),Fee=n(KYe,"A",{href:!0});var $ia=s(Fee);s5r=r($ia,"LayoutLMv2ForTokenClassification"),$ia.forEach(t),l5r=r(KYe," (LayoutLMv2 model)"),KYe.forEach(t),i5r=i(J),R4=n(J,"LI",{});var eZe=s(R4);V0e=n(eZe,"STRONG",{});var kia=s(V0e);d5r=r(kia,"layoutlmv3"),kia.forEach(t),m5r=r(eZe," \u2014 "),Tee=n(eZe,"A",{href:!0});var Sia=s(Tee);c5r=r(Sia,"LayoutLMv3ForTokenClassification"),Sia.forEach(t),f5r=r(eZe," (LayoutLMv3 model)"),eZe.forEach(t),g5r=i(J),P4=n(J,"LI",{});var oZe=s(P4);X0e=n(oZe,"STRONG",{});var Ria=s(X0e);h5r=r(Ria,"lilt"),Ria.forEach(t),u5r=r(oZe," \u2014 "),Mee=n(oZe,"A",{href:!0});var Pia=s(Mee);p5r=r(Pia,"LiltForTokenClassification"),Pia.forEach(t),_5r=r(oZe," (LiLT model)"),oZe.forEach(t),b5r=i(J),B4=n(J,"LI",{});var rZe=s(B4);z0e=n(rZe,"STRONG",{});var Bia=s(z0e);v5r=r(Bia,"longformer"),Bia.forEach(t),F5r=r(rZe," \u2014 "),Eee=n(rZe,"A",{href:!0});var Iia=s(Eee);T5r=r(Iia,"LongformerForTokenClassification"),Iia.forEach(t),M5r=r(rZe," (Longformer model)"),rZe.forEach(t),E5r=i(J),I4=n(J,"LI",{});var tZe=s(I4);Q0e=n(tZe,"STRONG",{});var Nia=s(Q0e);C5r=r(Nia,"luke"),Nia.forEach(t),w5r=r(tZe," \u2014 "),Cee=n(tZe,"A",{href:!0});var qia=s(Cee);A5r=r(qia,"LukeForTokenClassification"),qia.forEach(t),L5r=r(tZe," (LUKE model)"),tZe.forEach(t),y5r=i(J),N4=n(J,"LI",{});var aZe=s(N4);W0e=n(aZe,"STRONG",{});var Dia=s(W0e);x5r=r(Dia,"markuplm"),Dia.forEach(t),$5r=r(aZe," \u2014 "),wee=n(aZe,"A",{href:!0});var jia=s(wee);k5r=r(jia,"MarkupLMForTokenClassification"),jia.forEach(t),S5r=r(aZe," (MarkupLM model)"),aZe.forEach(t),R5r=i(J),q4=n(J,"LI",{});var nZe=s(q4);U0e=n(nZe,"STRONG",{});var Gia=s(U0e);P5r=r(Gia,"megatron-bert"),Gia.forEach(t),B5r=r(nZe," \u2014 "),Aee=n(nZe,"A",{href:!0});var Oia=s(Aee);I5r=r(Oia,"MegatronBertForTokenClassification"),Oia.forEach(t),N5r=r(nZe," (Megatron-BERT model)"),nZe.forEach(t),q5r=i(J),D4=n(J,"LI",{});var sZe=s(D4);H0e=n(sZe,"STRONG",{});var Via=s(H0e);D5r=r(Via,"mobilebert"),Via.forEach(t),j5r=r(sZe," \u2014 "),Lee=n(sZe,"A",{href:!0});var Xia=s(Lee);G5r=r(Xia,"MobileBertForTokenClassification"),Xia.forEach(t),O5r=r(sZe," (MobileBERT model)"),sZe.forEach(t),V5r=i(J),j4=n(J,"LI",{});var lZe=s(j4);J0e=n(lZe,"STRONG",{});var zia=s(J0e);X5r=r(zia,"mpnet"),zia.forEach(t),z5r=r(lZe," \u2014 "),yee=n(lZe,"A",{href:!0});var Qia=s(yee);Q5r=r(Qia,"MPNetForTokenClassification"),Qia.forEach(t),W5r=r(lZe," (MPNet model)"),lZe.forEach(t),U5r=i(J),G4=n(J,"LI",{});var iZe=s(G4);Y0e=n(iZe,"STRONG",{});var Wia=s(Y0e);H5r=r(Wia,"nezha"),Wia.forEach(t),J5r=r(iZe," \u2014 "),xee=n(iZe,"A",{href:!0});var Uia=s(xee);Y5r=r(Uia,"NezhaForTokenClassification"),Uia.forEach(t),Z5r=r(iZe," (Nezha model)"),iZe.forEach(t),K5r=i(J),O4=n(J,"LI",{});var dZe=s(O4);Z0e=n(dZe,"STRONG",{});var Hia=s(Z0e);e0r=r(Hia,"nystromformer"),Hia.forEach(t),o0r=r(dZe," \u2014 "),$ee=n(dZe,"A",{href:!0});var Jia=s($ee);r0r=r(Jia,"NystromformerForTokenClassification"),Jia.forEach(t),t0r=r(dZe," (Nystr\xF6mformer model)"),dZe.forEach(t),a0r=i(J),V4=n(J,"LI",{});var mZe=s(V4);K0e=n(mZe,"STRONG",{});var Yia=s(K0e);n0r=r(Yia,"qdqbert"),Yia.forEach(t),s0r=r(mZe," \u2014 "),kee=n(mZe,"A",{href:!0});var Zia=s(kee);l0r=r(Zia,"QDQBertForTokenClassification"),Zia.forEach(t),i0r=r(mZe," (QDQBert model)"),mZe.forEach(t),d0r=i(J),X4=n(J,"LI",{});var cZe=s(X4);ewe=n(cZe,"STRONG",{});var Kia=s(ewe);m0r=r(Kia,"rembert"),Kia.forEach(t),c0r=r(cZe," \u2014 "),See=n(cZe,"A",{href:!0});var eda=s(See);f0r=r(eda,"RemBertForTokenClassification"),eda.forEach(t),g0r=r(cZe," (RemBERT model)"),cZe.forEach(t),h0r=i(J),z4=n(J,"LI",{});var fZe=s(z4);owe=n(fZe,"STRONG",{});var oda=s(owe);u0r=r(oda,"roberta"),oda.forEach(t),p0r=r(fZe," \u2014 "),Ree=n(fZe,"A",{href:!0});var rda=s(Ree);_0r=r(rda,"RobertaForTokenClassification"),rda.forEach(t),b0r=r(fZe," (RoBERTa model)"),fZe.forEach(t),v0r=i(J),Q4=n(J,"LI",{});var gZe=s(Q4);rwe=n(gZe,"STRONG",{});var tda=s(rwe);F0r=r(tda,"roc_bert"),tda.forEach(t),T0r=r(gZe," \u2014 "),Pee=n(gZe,"A",{href:!0});var ada=s(Pee);M0r=r(ada,"RoCBertForTokenClassification"),ada.forEach(t),E0r=r(gZe," (RoCBert model)"),gZe.forEach(t),C0r=i(J),W4=n(J,"LI",{});var hZe=s(W4);twe=n(hZe,"STRONG",{});var nda=s(twe);w0r=r(nda,"roformer"),nda.forEach(t),A0r=r(hZe," \u2014 "),Bee=n(hZe,"A",{href:!0});var sda=s(Bee);L0r=r(sda,"RoFormerForTokenClassification"),sda.forEach(t),y0r=r(hZe," (RoFormer model)"),hZe.forEach(t),x0r=i(J),U4=n(J,"LI",{});var uZe=s(U4);awe=n(uZe,"STRONG",{});var lda=s(awe);$0r=r(lda,"squeezebert"),lda.forEach(t),k0r=r(uZe," \u2014 "),Iee=n(uZe,"A",{href:!0});var ida=s(Iee);S0r=r(ida,"SqueezeBertForTokenClassification"),ida.forEach(t),R0r=r(uZe," (SqueezeBERT model)"),uZe.forEach(t),P0r=i(J),H4=n(J,"LI",{});var pZe=s(H4);nwe=n(pZe,"STRONG",{});var dda=s(nwe);B0r=r(dda,"xlm"),dda.forEach(t),I0r=r(pZe," \u2014 "),Nee=n(pZe,"A",{href:!0});var mda=s(Nee);N0r=r(mda,"XLMForTokenClassification"),mda.forEach(t),q0r=r(pZe," (XLM model)"),pZe.forEach(t),D0r=i(J),J4=n(J,"LI",{});var _Ze=s(J4);swe=n(_Ze,"STRONG",{});var cda=s(swe);j0r=r(cda,"xlm-roberta"),cda.forEach(t),G0r=r(_Ze," \u2014 "),qee=n(_Ze,"A",{href:!0});var fda=s(qee);O0r=r(fda,"XLMRobertaForTokenClassification"),fda.forEach(t),V0r=r(_Ze," (XLM-RoBERTa model)"),_Ze.forEach(t),X0r=i(J),Y4=n(J,"LI",{});var bZe=s(Y4);lwe=n(bZe,"STRONG",{});var gda=s(lwe);z0r=r(gda,"xlm-roberta-xl"),gda.forEach(t),Q0r=r(bZe," \u2014 "),Dee=n(bZe,"A",{href:!0});var hda=s(Dee);W0r=r(hda,"XLMRobertaXLForTokenClassification"),hda.forEach(t),U0r=r(bZe," (XLM-RoBERTa-XL model)"),bZe.forEach(t),H0r=i(J),Z4=n(J,"LI",{});var vZe=s(Z4);iwe=n(vZe,"STRONG",{});var uda=s(iwe);J0r=r(uda,"xlnet"),uda.forEach(t),Y0r=r(vZe," \u2014 "),jee=n(vZe,"A",{href:!0});var pda=s(jee);Z0r=r(pda,"XLNetForTokenClassification"),pda.forEach(t),K0r=r(vZe," (XLNet model)"),vZe.forEach(t),ewr=i(J),K4=n(J,"LI",{});var FZe=s(K4);dwe=n(FZe,"STRONG",{});var _da=s(dwe);owr=r(_da,"yoso"),_da.forEach(t),rwr=r(FZe," \u2014 "),Gee=n(FZe,"A",{href:!0});var bda=s(Gee);twr=r(bda,"YosoForTokenClassification"),bda.forEach(t),awr=r(FZe," (YOSO model)"),FZe.forEach(t),J.forEach(t),nwr=i(Ga),eC=n(Ga,"P",{});var TZe=s(eC);swr=r(TZe,"The model is set in evaluation mode by default using "),mwe=n(TZe,"CODE",{});var vda=s(mwe);lwr=r(vda,"model.eval()"),vda.forEach(t),iwr=r(TZe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cwe=n(TZe,"CODE",{});var Fda=s(cwe);dwr=r(Fda,"model.train()"),Fda.forEach(t),TZe.forEach(t),mwr=i(Ga),T(oC.$$.fragment,Ga),Ga.forEach(t),oi.forEach(t),Ylo=i(c),_m=n(c,"H2",{class:!0});var Fmo=s(_m);rC=n(Fmo,"A",{id:!0,class:!0,href:!0});var Tda=s(rC);fwe=n(Tda,"SPAN",{});var Mda=s(fwe);T(GS.$$.fragment,Mda),Mda.forEach(t),Tda.forEach(t),cwr=i(Fmo),gwe=n(Fmo,"SPAN",{});var Eda=s(gwe);fwr=r(Eda,"AutoModelForQuestionAnswering"),Eda.forEach(t),Fmo.forEach(t),Zlo=i(c),Jo=n(c,"DIV",{class:!0});var ri=s(Jo);T(OS.$$.fragment,ri),gwr=i(ri),bm=n(ri,"P",{});var Afe=s(bm);hwr=r(Afe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Oee=n(Afe,"A",{href:!0});var Cda=s(Oee);uwr=r(Cda,"from_pretrained()"),Cda.forEach(t),pwr=r(Afe," class method or the "),Vee=n(Afe,"A",{href:!0});var wda=s(Vee);_wr=r(wda,"from_config()"),wda.forEach(t),bwr=r(Afe,` class
method.`),Afe.forEach(t),vwr=i(ri),VS=n(ri,"P",{});var Tmo=s(VS);Fwr=r(Tmo,"This class cannot be instantiated directly using "),hwe=n(Tmo,"CODE",{});var Ada=s(hwe);Twr=r(Ada,"__init__()"),Ada.forEach(t),Mwr=r(Tmo," (throws an error)."),Tmo.forEach(t),Ewr=i(ri),It=n(ri,"DIV",{class:!0});var Ex=s(It);T(XS.$$.fragment,Ex),Cwr=i(Ex),uwe=n(Ex,"P",{});var Lda=s(uwe);wwr=r(Lda,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Lda.forEach(t),Awr=i(Ex),vm=n(Ex,"P",{});var Lfe=s(vm);Lwr=r(Lfe,`Note:
Loading a model from its configuration file does `),pwe=n(Lfe,"STRONG",{});var yda=s(pwe);ywr=r(yda,"not"),yda.forEach(t),xwr=r(Lfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Xee=n(Lfe,"A",{href:!0});var xda=s(Xee);$wr=r(xda,"from_pretrained()"),xda.forEach(t),kwr=r(Lfe," to load the model weights."),Lfe.forEach(t),Swr=i(Ex),T(tC.$$.fragment,Ex),Ex.forEach(t),Rwr=i(ri),ho=n(ri,"DIV",{class:!0});var Oa=s(ho);T(zS.$$.fragment,Oa),Pwr=i(Oa),_we=n(Oa,"P",{});var $da=s(_we);Bwr=r($da,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),$da.forEach(t),Iwr=i(Oa),Mn=n(Oa,"P",{});var Cx=s(Mn);Nwr=r(Cx,"The model class to instantiate is selected based on the "),bwe=n(Cx,"CODE",{});var kda=s(bwe);qwr=r(kda,"model_type"),kda.forEach(t),Dwr=r(Cx,` property of the config object (either
passed as an argument or loaded from `),vwe=n(Cx,"CODE",{});var Sda=s(vwe);jwr=r(Sda,"pretrained_model_name_or_path"),Sda.forEach(t),Gwr=r(Cx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Fwe=n(Cx,"CODE",{});var Rda=s(Fwe);Owr=r(Rda,"pretrained_model_name_or_path"),Rda.forEach(t),Vwr=r(Cx,":"),Cx.forEach(t),Xwr=i(Oa),O=n(Oa,"UL",{});var X=s(O);aC=n(X,"LI",{});var MZe=s(aC);Twe=n(MZe,"STRONG",{});var Pda=s(Twe);zwr=r(Pda,"albert"),Pda.forEach(t),Qwr=r(MZe," \u2014 "),zee=n(MZe,"A",{href:!0});var Bda=s(zee);Wwr=r(Bda,"AlbertForQuestionAnswering"),Bda.forEach(t),Uwr=r(MZe," (ALBERT model)"),MZe.forEach(t),Hwr=i(X),nC=n(X,"LI",{});var EZe=s(nC);Mwe=n(EZe,"STRONG",{});var Ida=s(Mwe);Jwr=r(Ida,"bart"),Ida.forEach(t),Ywr=r(EZe," \u2014 "),Qee=n(EZe,"A",{href:!0});var Nda=s(Qee);Zwr=r(Nda,"BartForQuestionAnswering"),Nda.forEach(t),Kwr=r(EZe," (BART model)"),EZe.forEach(t),eAr=i(X),sC=n(X,"LI",{});var CZe=s(sC);Ewe=n(CZe,"STRONG",{});var qda=s(Ewe);oAr=r(qda,"bert"),qda.forEach(t),rAr=r(CZe," \u2014 "),Wee=n(CZe,"A",{href:!0});var Dda=s(Wee);tAr=r(Dda,"BertForQuestionAnswering"),Dda.forEach(t),aAr=r(CZe," (BERT model)"),CZe.forEach(t),nAr=i(X),lC=n(X,"LI",{});var wZe=s(lC);Cwe=n(wZe,"STRONG",{});var jda=s(Cwe);sAr=r(jda,"big_bird"),jda.forEach(t),lAr=r(wZe," \u2014 "),Uee=n(wZe,"A",{href:!0});var Gda=s(Uee);iAr=r(Gda,"BigBirdForQuestionAnswering"),Gda.forEach(t),dAr=r(wZe," (BigBird model)"),wZe.forEach(t),mAr=i(X),iC=n(X,"LI",{});var AZe=s(iC);wwe=n(AZe,"STRONG",{});var Oda=s(wwe);cAr=r(Oda,"bigbird_pegasus"),Oda.forEach(t),fAr=r(AZe," \u2014 "),Hee=n(AZe,"A",{href:!0});var Vda=s(Hee);gAr=r(Vda,"BigBirdPegasusForQuestionAnswering"),Vda.forEach(t),hAr=r(AZe," (BigBird-Pegasus model)"),AZe.forEach(t),uAr=i(X),dC=n(X,"LI",{});var LZe=s(dC);Awe=n(LZe,"STRONG",{});var Xda=s(Awe);pAr=r(Xda,"bloom"),Xda.forEach(t),_Ar=r(LZe," \u2014 "),Jee=n(LZe,"A",{href:!0});var zda=s(Jee);bAr=r(zda,"BloomForQuestionAnswering"),zda.forEach(t),vAr=r(LZe," (BLOOM model)"),LZe.forEach(t),FAr=i(X),mC=n(X,"LI",{});var yZe=s(mC);Lwe=n(yZe,"STRONG",{});var Qda=s(Lwe);TAr=r(Qda,"camembert"),Qda.forEach(t),MAr=r(yZe," \u2014 "),Yee=n(yZe,"A",{href:!0});var Wda=s(Yee);EAr=r(Wda,"CamembertForQuestionAnswering"),Wda.forEach(t),CAr=r(yZe," (CamemBERT model)"),yZe.forEach(t),wAr=i(X),cC=n(X,"LI",{});var xZe=s(cC);ywe=n(xZe,"STRONG",{});var Uda=s(ywe);AAr=r(Uda,"canine"),Uda.forEach(t),LAr=r(xZe," \u2014 "),Zee=n(xZe,"A",{href:!0});var Hda=s(Zee);yAr=r(Hda,"CanineForQuestionAnswering"),Hda.forEach(t),xAr=r(xZe," (CANINE model)"),xZe.forEach(t),$Ar=i(X),fC=n(X,"LI",{});var $Ze=s(fC);xwe=n($Ze,"STRONG",{});var Jda=s(xwe);kAr=r(Jda,"convbert"),Jda.forEach(t),SAr=r($Ze," \u2014 "),Kee=n($Ze,"A",{href:!0});var Yda=s(Kee);RAr=r(Yda,"ConvBertForQuestionAnswering"),Yda.forEach(t),PAr=r($Ze," (ConvBERT model)"),$Ze.forEach(t),BAr=i(X),gC=n(X,"LI",{});var kZe=s(gC);$we=n(kZe,"STRONG",{});var Zda=s($we);IAr=r(Zda,"data2vec-text"),Zda.forEach(t),NAr=r(kZe," \u2014 "),eoe=n(kZe,"A",{href:!0});var Kda=s(eoe);qAr=r(Kda,"Data2VecTextForQuestionAnswering"),Kda.forEach(t),DAr=r(kZe," (Data2VecText model)"),kZe.forEach(t),jAr=i(X),hC=n(X,"LI",{});var SZe=s(hC);kwe=n(SZe,"STRONG",{});var ema=s(kwe);GAr=r(ema,"deberta"),ema.forEach(t),OAr=r(SZe," \u2014 "),ooe=n(SZe,"A",{href:!0});var oma=s(ooe);VAr=r(oma,"DebertaForQuestionAnswering"),oma.forEach(t),XAr=r(SZe," (DeBERTa model)"),SZe.forEach(t),zAr=i(X),uC=n(X,"LI",{});var RZe=s(uC);Swe=n(RZe,"STRONG",{});var rma=s(Swe);QAr=r(rma,"deberta-v2"),rma.forEach(t),WAr=r(RZe," \u2014 "),roe=n(RZe,"A",{href:!0});var tma=s(roe);UAr=r(tma,"DebertaV2ForQuestionAnswering"),tma.forEach(t),HAr=r(RZe," (DeBERTa-v2 model)"),RZe.forEach(t),JAr=i(X),pC=n(X,"LI",{});var PZe=s(pC);Rwe=n(PZe,"STRONG",{});var ama=s(Rwe);YAr=r(ama,"distilbert"),ama.forEach(t),ZAr=r(PZe," \u2014 "),toe=n(PZe,"A",{href:!0});var nma=s(toe);KAr=r(nma,"DistilBertForQuestionAnswering"),nma.forEach(t),e6r=r(PZe," (DistilBERT model)"),PZe.forEach(t),o6r=i(X),_C=n(X,"LI",{});var BZe=s(_C);Pwe=n(BZe,"STRONG",{});var sma=s(Pwe);r6r=r(sma,"electra"),sma.forEach(t),t6r=r(BZe," \u2014 "),aoe=n(BZe,"A",{href:!0});var lma=s(aoe);a6r=r(lma,"ElectraForQuestionAnswering"),lma.forEach(t),n6r=r(BZe," (ELECTRA model)"),BZe.forEach(t),s6r=i(X),bC=n(X,"LI",{});var IZe=s(bC);Bwe=n(IZe,"STRONG",{});var ima=s(Bwe);l6r=r(ima,"ernie"),ima.forEach(t),i6r=r(IZe," \u2014 "),noe=n(IZe,"A",{href:!0});var dma=s(noe);d6r=r(dma,"ErnieForQuestionAnswering"),dma.forEach(t),m6r=r(IZe," (ERNIE model)"),IZe.forEach(t),c6r=i(X),vC=n(X,"LI",{});var NZe=s(vC);Iwe=n(NZe,"STRONG",{});var mma=s(Iwe);f6r=r(mma,"flaubert"),mma.forEach(t),g6r=r(NZe," \u2014 "),soe=n(NZe,"A",{href:!0});var cma=s(soe);h6r=r(cma,"FlaubertForQuestionAnsweringSimple"),cma.forEach(t),u6r=r(NZe," (FlauBERT model)"),NZe.forEach(t),p6r=i(X),FC=n(X,"LI",{});var qZe=s(FC);Nwe=n(qZe,"STRONG",{});var fma=s(Nwe);_6r=r(fma,"fnet"),fma.forEach(t),b6r=r(qZe," \u2014 "),loe=n(qZe,"A",{href:!0});var gma=s(loe);v6r=r(gma,"FNetForQuestionAnswering"),gma.forEach(t),F6r=r(qZe," (FNet model)"),qZe.forEach(t),T6r=i(X),TC=n(X,"LI",{});var DZe=s(TC);qwe=n(DZe,"STRONG",{});var hma=s(qwe);M6r=r(hma,"funnel"),hma.forEach(t),E6r=r(DZe," \u2014 "),ioe=n(DZe,"A",{href:!0});var uma=s(ioe);C6r=r(uma,"FunnelForQuestionAnswering"),uma.forEach(t),w6r=r(DZe," (Funnel Transformer model)"),DZe.forEach(t),A6r=i(X),MC=n(X,"LI",{});var jZe=s(MC);Dwe=n(jZe,"STRONG",{});var pma=s(Dwe);L6r=r(pma,"gptj"),pma.forEach(t),y6r=r(jZe," \u2014 "),doe=n(jZe,"A",{href:!0});var _ma=s(doe);x6r=r(_ma,"GPTJForQuestionAnswering"),_ma.forEach(t),$6r=r(jZe," (GPT-J model)"),jZe.forEach(t),k6r=i(X),EC=n(X,"LI",{});var GZe=s(EC);jwe=n(GZe,"STRONG",{});var bma=s(jwe);S6r=r(bma,"ibert"),bma.forEach(t),R6r=r(GZe," \u2014 "),moe=n(GZe,"A",{href:!0});var vma=s(moe);P6r=r(vma,"IBertForQuestionAnswering"),vma.forEach(t),B6r=r(GZe," (I-BERT model)"),GZe.forEach(t),I6r=i(X),CC=n(X,"LI",{});var OZe=s(CC);Gwe=n(OZe,"STRONG",{});var Fma=s(Gwe);N6r=r(Fma,"layoutlmv2"),Fma.forEach(t),q6r=r(OZe," \u2014 "),coe=n(OZe,"A",{href:!0});var Tma=s(coe);D6r=r(Tma,"LayoutLMv2ForQuestionAnswering"),Tma.forEach(t),j6r=r(OZe," (LayoutLMv2 model)"),OZe.forEach(t),G6r=i(X),wC=n(X,"LI",{});var VZe=s(wC);Owe=n(VZe,"STRONG",{});var Mma=s(Owe);O6r=r(Mma,"layoutlmv3"),Mma.forEach(t),V6r=r(VZe," \u2014 "),foe=n(VZe,"A",{href:!0});var Ema=s(foe);X6r=r(Ema,"LayoutLMv3ForQuestionAnswering"),Ema.forEach(t),z6r=r(VZe," (LayoutLMv3 model)"),VZe.forEach(t),Q6r=i(X),AC=n(X,"LI",{});var XZe=s(AC);Vwe=n(XZe,"STRONG",{});var Cma=s(Vwe);W6r=r(Cma,"led"),Cma.forEach(t),U6r=r(XZe," \u2014 "),goe=n(XZe,"A",{href:!0});var wma=s(goe);H6r=r(wma,"LEDForQuestionAnswering"),wma.forEach(t),J6r=r(XZe," (LED model)"),XZe.forEach(t),Y6r=i(X),LC=n(X,"LI",{});var zZe=s(LC);Xwe=n(zZe,"STRONG",{});var Ama=s(Xwe);Z6r=r(Ama,"lilt"),Ama.forEach(t),K6r=r(zZe," \u2014 "),hoe=n(zZe,"A",{href:!0});var Lma=s(hoe);e7r=r(Lma,"LiltForQuestionAnswering"),Lma.forEach(t),o7r=r(zZe," (LiLT model)"),zZe.forEach(t),r7r=i(X),yC=n(X,"LI",{});var QZe=s(yC);zwe=n(QZe,"STRONG",{});var yma=s(zwe);t7r=r(yma,"longformer"),yma.forEach(t),a7r=r(QZe," \u2014 "),uoe=n(QZe,"A",{href:!0});var xma=s(uoe);n7r=r(xma,"LongformerForQuestionAnswering"),xma.forEach(t),s7r=r(QZe," (Longformer model)"),QZe.forEach(t),l7r=i(X),xC=n(X,"LI",{});var WZe=s(xC);Qwe=n(WZe,"STRONG",{});var $ma=s(Qwe);i7r=r($ma,"luke"),$ma.forEach(t),d7r=r(WZe," \u2014 "),poe=n(WZe,"A",{href:!0});var kma=s(poe);m7r=r(kma,"LukeForQuestionAnswering"),kma.forEach(t),c7r=r(WZe," (LUKE model)"),WZe.forEach(t),f7r=i(X),$C=n(X,"LI",{});var UZe=s($C);Wwe=n(UZe,"STRONG",{});var Sma=s(Wwe);g7r=r(Sma,"lxmert"),Sma.forEach(t),h7r=r(UZe," \u2014 "),_oe=n(UZe,"A",{href:!0});var Rma=s(_oe);u7r=r(Rma,"LxmertForQuestionAnswering"),Rma.forEach(t),p7r=r(UZe," (LXMERT model)"),UZe.forEach(t),_7r=i(X),kC=n(X,"LI",{});var HZe=s(kC);Uwe=n(HZe,"STRONG",{});var Pma=s(Uwe);b7r=r(Pma,"markuplm"),Pma.forEach(t),v7r=r(HZe," \u2014 "),boe=n(HZe,"A",{href:!0});var Bma=s(boe);F7r=r(Bma,"MarkupLMForQuestionAnswering"),Bma.forEach(t),T7r=r(HZe," (MarkupLM model)"),HZe.forEach(t),M7r=i(X),SC=n(X,"LI",{});var JZe=s(SC);Hwe=n(JZe,"STRONG",{});var Ima=s(Hwe);E7r=r(Ima,"mbart"),Ima.forEach(t),C7r=r(JZe," \u2014 "),voe=n(JZe,"A",{href:!0});var Nma=s(voe);w7r=r(Nma,"MBartForQuestionAnswering"),Nma.forEach(t),A7r=r(JZe," (mBART model)"),JZe.forEach(t),L7r=i(X),RC=n(X,"LI",{});var YZe=s(RC);Jwe=n(YZe,"STRONG",{});var qma=s(Jwe);y7r=r(qma,"megatron-bert"),qma.forEach(t),x7r=r(YZe," \u2014 "),Foe=n(YZe,"A",{href:!0});var Dma=s(Foe);$7r=r(Dma,"MegatronBertForQuestionAnswering"),Dma.forEach(t),k7r=r(YZe," (Megatron-BERT model)"),YZe.forEach(t),S7r=i(X),PC=n(X,"LI",{});var ZZe=s(PC);Ywe=n(ZZe,"STRONG",{});var jma=s(Ywe);R7r=r(jma,"mobilebert"),jma.forEach(t),P7r=r(ZZe," \u2014 "),Toe=n(ZZe,"A",{href:!0});var Gma=s(Toe);B7r=r(Gma,"MobileBertForQuestionAnswering"),Gma.forEach(t),I7r=r(ZZe," (MobileBERT model)"),ZZe.forEach(t),N7r=i(X),BC=n(X,"LI",{});var KZe=s(BC);Zwe=n(KZe,"STRONG",{});var Oma=s(Zwe);q7r=r(Oma,"mpnet"),Oma.forEach(t),D7r=r(KZe," \u2014 "),Moe=n(KZe,"A",{href:!0});var Vma=s(Moe);j7r=r(Vma,"MPNetForQuestionAnswering"),Vma.forEach(t),G7r=r(KZe," (MPNet model)"),KZe.forEach(t),O7r=i(X),IC=n(X,"LI",{});var eKe=s(IC);Kwe=n(eKe,"STRONG",{});var Xma=s(Kwe);V7r=r(Xma,"mvp"),Xma.forEach(t),X7r=r(eKe," \u2014 "),Eoe=n(eKe,"A",{href:!0});var zma=s(Eoe);z7r=r(zma,"MvpForQuestionAnswering"),zma.forEach(t),Q7r=r(eKe," (MVP model)"),eKe.forEach(t),W7r=i(X),NC=n(X,"LI",{});var oKe=s(NC);eAe=n(oKe,"STRONG",{});var Qma=s(eAe);U7r=r(Qma,"nezha"),Qma.forEach(t),H7r=r(oKe," \u2014 "),Coe=n(oKe,"A",{href:!0});var Wma=s(Coe);J7r=r(Wma,"NezhaForQuestionAnswering"),Wma.forEach(t),Y7r=r(oKe," (Nezha model)"),oKe.forEach(t),Z7r=i(X),qC=n(X,"LI",{});var rKe=s(qC);oAe=n(rKe,"STRONG",{});var Uma=s(oAe);K7r=r(Uma,"nystromformer"),Uma.forEach(t),e8r=r(rKe," \u2014 "),woe=n(rKe,"A",{href:!0});var Hma=s(woe);o8r=r(Hma,"NystromformerForQuestionAnswering"),Hma.forEach(t),r8r=r(rKe," (Nystr\xF6mformer model)"),rKe.forEach(t),t8r=i(X),DC=n(X,"LI",{});var tKe=s(DC);rAe=n(tKe,"STRONG",{});var Jma=s(rAe);a8r=r(Jma,"opt"),Jma.forEach(t),n8r=r(tKe," \u2014 "),Aoe=n(tKe,"A",{href:!0});var Yma=s(Aoe);s8r=r(Yma,"OPTForQuestionAnswering"),Yma.forEach(t),l8r=r(tKe," (OPT model)"),tKe.forEach(t),i8r=i(X),jC=n(X,"LI",{});var aKe=s(jC);tAe=n(aKe,"STRONG",{});var Zma=s(tAe);d8r=r(Zma,"qdqbert"),Zma.forEach(t),m8r=r(aKe," \u2014 "),Loe=n(aKe,"A",{href:!0});var Kma=s(Loe);c8r=r(Kma,"QDQBertForQuestionAnswering"),Kma.forEach(t),f8r=r(aKe," (QDQBert model)"),aKe.forEach(t),g8r=i(X),GC=n(X,"LI",{});var nKe=s(GC);aAe=n(nKe,"STRONG",{});var eca=s(aAe);h8r=r(eca,"reformer"),eca.forEach(t),u8r=r(nKe," \u2014 "),yoe=n(nKe,"A",{href:!0});var oca=s(yoe);p8r=r(oca,"ReformerForQuestionAnswering"),oca.forEach(t),_8r=r(nKe," (Reformer model)"),nKe.forEach(t),b8r=i(X),OC=n(X,"LI",{});var sKe=s(OC);nAe=n(sKe,"STRONG",{});var rca=s(nAe);v8r=r(rca,"rembert"),rca.forEach(t),F8r=r(sKe," \u2014 "),xoe=n(sKe,"A",{href:!0});var tca=s(xoe);T8r=r(tca,"RemBertForQuestionAnswering"),tca.forEach(t),M8r=r(sKe," (RemBERT model)"),sKe.forEach(t),E8r=i(X),VC=n(X,"LI",{});var lKe=s(VC);sAe=n(lKe,"STRONG",{});var aca=s(sAe);C8r=r(aca,"roberta"),aca.forEach(t),w8r=r(lKe," \u2014 "),$oe=n(lKe,"A",{href:!0});var nca=s($oe);A8r=r(nca,"RobertaForQuestionAnswering"),nca.forEach(t),L8r=r(lKe," (RoBERTa model)"),lKe.forEach(t),y8r=i(X),XC=n(X,"LI",{});var iKe=s(XC);lAe=n(iKe,"STRONG",{});var sca=s(lAe);x8r=r(sca,"roc_bert"),sca.forEach(t),$8r=r(iKe," \u2014 "),koe=n(iKe,"A",{href:!0});var lca=s(koe);k8r=r(lca,"RoCBertForQuestionAnswering"),lca.forEach(t),S8r=r(iKe," (RoCBert model)"),iKe.forEach(t),R8r=i(X),zC=n(X,"LI",{});var dKe=s(zC);iAe=n(dKe,"STRONG",{});var ica=s(iAe);P8r=r(ica,"roformer"),ica.forEach(t),B8r=r(dKe," \u2014 "),Soe=n(dKe,"A",{href:!0});var dca=s(Soe);I8r=r(dca,"RoFormerForQuestionAnswering"),dca.forEach(t),N8r=r(dKe," (RoFormer model)"),dKe.forEach(t),q8r=i(X),QC=n(X,"LI",{});var mKe=s(QC);dAe=n(mKe,"STRONG",{});var mca=s(dAe);D8r=r(mca,"splinter"),mca.forEach(t),j8r=r(mKe," \u2014 "),Roe=n(mKe,"A",{href:!0});var cca=s(Roe);G8r=r(cca,"SplinterForQuestionAnswering"),cca.forEach(t),O8r=r(mKe," (Splinter model)"),mKe.forEach(t),V8r=i(X),WC=n(X,"LI",{});var cKe=s(WC);mAe=n(cKe,"STRONG",{});var fca=s(mAe);X8r=r(fca,"squeezebert"),fca.forEach(t),z8r=r(cKe," \u2014 "),Poe=n(cKe,"A",{href:!0});var gca=s(Poe);Q8r=r(gca,"SqueezeBertForQuestionAnswering"),gca.forEach(t),W8r=r(cKe," (SqueezeBERT model)"),cKe.forEach(t),U8r=i(X),UC=n(X,"LI",{});var fKe=s(UC);cAe=n(fKe,"STRONG",{});var hca=s(cAe);H8r=r(hca,"xlm"),hca.forEach(t),J8r=r(fKe," \u2014 "),Boe=n(fKe,"A",{href:!0});var uca=s(Boe);Y8r=r(uca,"XLMForQuestionAnsweringSimple"),uca.forEach(t),Z8r=r(fKe," (XLM model)"),fKe.forEach(t),K8r=i(X),HC=n(X,"LI",{});var gKe=s(HC);fAe=n(gKe,"STRONG",{});var pca=s(fAe);eLr=r(pca,"xlm-roberta"),pca.forEach(t),oLr=r(gKe," \u2014 "),Ioe=n(gKe,"A",{href:!0});var _ca=s(Ioe);rLr=r(_ca,"XLMRobertaForQuestionAnswering"),_ca.forEach(t),tLr=r(gKe," (XLM-RoBERTa model)"),gKe.forEach(t),aLr=i(X),JC=n(X,"LI",{});var hKe=s(JC);gAe=n(hKe,"STRONG",{});var bca=s(gAe);nLr=r(bca,"xlm-roberta-xl"),bca.forEach(t),sLr=r(hKe," \u2014 "),Noe=n(hKe,"A",{href:!0});var vca=s(Noe);lLr=r(vca,"XLMRobertaXLForQuestionAnswering"),vca.forEach(t),iLr=r(hKe," (XLM-RoBERTa-XL model)"),hKe.forEach(t),dLr=i(X),YC=n(X,"LI",{});var uKe=s(YC);hAe=n(uKe,"STRONG",{});var Fca=s(hAe);mLr=r(Fca,"xlnet"),Fca.forEach(t),cLr=r(uKe," \u2014 "),qoe=n(uKe,"A",{href:!0});var Tca=s(qoe);fLr=r(Tca,"XLNetForQuestionAnsweringSimple"),Tca.forEach(t),gLr=r(uKe," (XLNet model)"),uKe.forEach(t),hLr=i(X),ZC=n(X,"LI",{});var pKe=s(ZC);uAe=n(pKe,"STRONG",{});var Mca=s(uAe);uLr=r(Mca,"yoso"),Mca.forEach(t),pLr=r(pKe," \u2014 "),Doe=n(pKe,"A",{href:!0});var Eca=s(Doe);_Lr=r(Eca,"YosoForQuestionAnswering"),Eca.forEach(t),bLr=r(pKe," (YOSO model)"),pKe.forEach(t),X.forEach(t),vLr=i(Oa),KC=n(Oa,"P",{});var _Ke=s(KC);FLr=r(_Ke,"The model is set in evaluation mode by default using "),pAe=n(_Ke,"CODE",{});var Cca=s(pAe);TLr=r(Cca,"model.eval()"),Cca.forEach(t),MLr=r(_Ke,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_Ae=n(_Ke,"CODE",{});var wca=s(_Ae);ELr=r(wca,"model.train()"),wca.forEach(t),_Ke.forEach(t),CLr=i(Oa),T(e3.$$.fragment,Oa),Oa.forEach(t),ri.forEach(t),Klo=i(c),Fm=n(c,"H2",{class:!0});var Mmo=s(Fm);o3=n(Mmo,"A",{id:!0,class:!0,href:!0});var Aca=s(o3);bAe=n(Aca,"SPAN",{});var Lca=s(bAe);T(QS.$$.fragment,Lca),Lca.forEach(t),Aca.forEach(t),wLr=i(Mmo),vAe=n(Mmo,"SPAN",{});var yca=s(vAe);ALr=r(yca,"AutoModelForTableQuestionAnswering"),yca.forEach(t),Mmo.forEach(t),eio=i(c),Yo=n(c,"DIV",{class:!0});var ti=s(Yo);T(WS.$$.fragment,ti),LLr=i(ti),Tm=n(ti,"P",{});var yfe=s(Tm);yLr=r(yfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),joe=n(yfe,"A",{href:!0});var xca=s(joe);xLr=r(xca,"from_pretrained()"),xca.forEach(t),$Lr=r(yfe," class method or the "),Goe=n(yfe,"A",{href:!0});var $ca=s(Goe);kLr=r($ca,"from_config()"),$ca.forEach(t),SLr=r(yfe,` class
method.`),yfe.forEach(t),RLr=i(ti),US=n(ti,"P",{});var Emo=s(US);PLr=r(Emo,"This class cannot be instantiated directly using "),FAe=n(Emo,"CODE",{});var kca=s(FAe);BLr=r(kca,"__init__()"),kca.forEach(t),ILr=r(Emo," (throws an error)."),Emo.forEach(t),NLr=i(ti),Nt=n(ti,"DIV",{class:!0});var wx=s(Nt);T(HS.$$.fragment,wx),qLr=i(wx),TAe=n(wx,"P",{});var Sca=s(TAe);DLr=r(Sca,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Sca.forEach(t),jLr=i(wx),Mm=n(wx,"P",{});var xfe=s(Mm);GLr=r(xfe,`Note:
Loading a model from its configuration file does `),MAe=n(xfe,"STRONG",{});var Rca=s(MAe);OLr=r(Rca,"not"),Rca.forEach(t),VLr=r(xfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ooe=n(xfe,"A",{href:!0});var Pca=s(Ooe);XLr=r(Pca,"from_pretrained()"),Pca.forEach(t),zLr=r(xfe," to load the model weights."),xfe.forEach(t),QLr=i(wx),T(r3.$$.fragment,wx),wx.forEach(t),WLr=i(ti),uo=n(ti,"DIV",{class:!0});var Va=s(uo);T(JS.$$.fragment,Va),ULr=i(Va),EAe=n(Va,"P",{});var Bca=s(EAe);HLr=r(Bca,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Bca.forEach(t),JLr=i(Va),En=n(Va,"P",{});var Ax=s(En);YLr=r(Ax,"The model class to instantiate is selected based on the "),CAe=n(Ax,"CODE",{});var Ica=s(CAe);ZLr=r(Ica,"model_type"),Ica.forEach(t),KLr=r(Ax,` property of the config object (either
passed as an argument or loaded from `),wAe=n(Ax,"CODE",{});var Nca=s(wAe);eyr=r(Nca,"pretrained_model_name_or_path"),Nca.forEach(t),oyr=r(Ax,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),AAe=n(Ax,"CODE",{});var qca=s(AAe);ryr=r(qca,"pretrained_model_name_or_path"),qca.forEach(t),tyr=r(Ax,":"),Ax.forEach(t),ayr=i(Va),LAe=n(Va,"UL",{});var Dca=s(LAe);t3=n(Dca,"LI",{});var bKe=s(t3);yAe=n(bKe,"STRONG",{});var jca=s(yAe);nyr=r(jca,"tapas"),jca.forEach(t),syr=r(bKe," \u2014 "),Voe=n(bKe,"A",{href:!0});var Gca=s(Voe);lyr=r(Gca,"TapasForQuestionAnswering"),Gca.forEach(t),iyr=r(bKe," (TAPAS model)"),bKe.forEach(t),Dca.forEach(t),dyr=i(Va),a3=n(Va,"P",{});var vKe=s(a3);myr=r(vKe,"The model is set in evaluation mode by default using "),xAe=n(vKe,"CODE",{});var Oca=s(xAe);cyr=r(Oca,"model.eval()"),Oca.forEach(t),fyr=r(vKe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$Ae=n(vKe,"CODE",{});var Vca=s($Ae);gyr=r(Vca,"model.train()"),Vca.forEach(t),vKe.forEach(t),hyr=i(Va),T(n3.$$.fragment,Va),Va.forEach(t),ti.forEach(t),oio=i(c),Em=n(c,"H2",{class:!0});var Cmo=s(Em);s3=n(Cmo,"A",{id:!0,class:!0,href:!0});var Xca=s(s3);kAe=n(Xca,"SPAN",{});var zca=s(kAe);T(YS.$$.fragment,zca),zca.forEach(t),Xca.forEach(t),uyr=i(Cmo),SAe=n(Cmo,"SPAN",{});var Qca=s(SAe);pyr=r(Qca,"AutoModelForDocumentQuestionAnswering"),Qca.forEach(t),Cmo.forEach(t),rio=i(c),Zo=n(c,"DIV",{class:!0});var ai=s(Zo);T(ZS.$$.fragment,ai),_yr=i(ai),Cm=n(ai,"P",{});var $fe=s(Cm);byr=r($fe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),Xoe=n($fe,"A",{href:!0});var Wca=s(Xoe);vyr=r(Wca,"from_pretrained()"),Wca.forEach(t),Fyr=r($fe," class method or the "),zoe=n($fe,"A",{href:!0});var Uca=s(zoe);Tyr=r(Uca,"from_config()"),Uca.forEach(t),Myr=r($fe,` class
method.`),$fe.forEach(t),Eyr=i(ai),KS=n(ai,"P",{});var wmo=s(KS);Cyr=r(wmo,"This class cannot be instantiated directly using "),RAe=n(wmo,"CODE",{});var Hca=s(RAe);wyr=r(Hca,"__init__()"),Hca.forEach(t),Ayr=r(wmo," (throws an error)."),wmo.forEach(t),Lyr=i(ai),qt=n(ai,"DIV",{class:!0});var Lx=s(qt);T(eR.$$.fragment,Lx),yyr=i(Lx),PAe=n(Lx,"P",{});var Jca=s(PAe);xyr=r(Jca,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),Jca.forEach(t),$yr=i(Lx),wm=n(Lx,"P",{});var kfe=s(wm);kyr=r(kfe,`Note:
Loading a model from its configuration file does `),BAe=n(kfe,"STRONG",{});var Yca=s(BAe);Syr=r(Yca,"not"),Yca.forEach(t),Ryr=r(kfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Qoe=n(kfe,"A",{href:!0});var Zca=s(Qoe);Pyr=r(Zca,"from_pretrained()"),Zca.forEach(t),Byr=r(kfe," to load the model weights."),kfe.forEach(t),Iyr=i(Lx),T(l3.$$.fragment,Lx),Lx.forEach(t),Nyr=i(ai),po=n(ai,"DIV",{class:!0});var Xa=s(po);T(oR.$$.fragment,Xa),qyr=i(Xa),IAe=n(Xa,"P",{});var Kca=s(IAe);Dyr=r(Kca,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),Kca.forEach(t),jyr=i(Xa),Cn=n(Xa,"P",{});var yx=s(Cn);Gyr=r(yx,"The model class to instantiate is selected based on the "),NAe=n(yx,"CODE",{});var efa=s(NAe);Oyr=r(efa,"model_type"),efa.forEach(t),Vyr=r(yx,` property of the config object (either
passed as an argument or loaded from `),qAe=n(yx,"CODE",{});var ofa=s(qAe);Xyr=r(ofa,"pretrained_model_name_or_path"),ofa.forEach(t),zyr=r(yx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),DAe=n(yx,"CODE",{});var rfa=s(DAe);Qyr=r(rfa,"pretrained_model_name_or_path"),rfa.forEach(t),Wyr=r(yx,":"),yx.forEach(t),Uyr=i(Xa),Am=n(Xa,"UL",{});var Sfe=s(Am);i3=n(Sfe,"LI",{});var FKe=s(i3);jAe=n(FKe,"STRONG",{});var tfa=s(jAe);Hyr=r(tfa,"layoutlm"),tfa.forEach(t),Jyr=r(FKe," \u2014 "),Woe=n(FKe,"A",{href:!0});var afa=s(Woe);Yyr=r(afa,"LayoutLMForQuestionAnswering"),afa.forEach(t),Zyr=r(FKe," (LayoutLM model)"),FKe.forEach(t),Kyr=i(Sfe),d3=n(Sfe,"LI",{});var TKe=s(d3);GAe=n(TKe,"STRONG",{});var nfa=s(GAe);e9r=r(nfa,"layoutlmv2"),nfa.forEach(t),o9r=r(TKe," \u2014 "),Uoe=n(TKe,"A",{href:!0});var sfa=s(Uoe);r9r=r(sfa,"LayoutLMv2ForQuestionAnswering"),sfa.forEach(t),t9r=r(TKe," (LayoutLMv2 model)"),TKe.forEach(t),a9r=i(Sfe),m3=n(Sfe,"LI",{});var MKe=s(m3);OAe=n(MKe,"STRONG",{});var lfa=s(OAe);n9r=r(lfa,"layoutlmv3"),lfa.forEach(t),s9r=r(MKe," \u2014 "),Hoe=n(MKe,"A",{href:!0});var ifa=s(Hoe);l9r=r(ifa,"LayoutLMv3ForQuestionAnswering"),ifa.forEach(t),i9r=r(MKe," (LayoutLMv3 model)"),MKe.forEach(t),Sfe.forEach(t),d9r=i(Xa),c3=n(Xa,"P",{});var EKe=s(c3);m9r=r(EKe,"The model is set in evaluation mode by default using "),VAe=n(EKe,"CODE",{});var dfa=s(VAe);c9r=r(dfa,"model.eval()"),dfa.forEach(t),f9r=r(EKe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),XAe=n(EKe,"CODE",{});var mfa=s(XAe);g9r=r(mfa,"model.train()"),mfa.forEach(t),EKe.forEach(t),h9r=i(Xa),T(f3.$$.fragment,Xa),Xa.forEach(t),ai.forEach(t),tio=i(c),Lm=n(c,"H2",{class:!0});var Amo=s(Lm);g3=n(Amo,"A",{id:!0,class:!0,href:!0});var cfa=s(g3);zAe=n(cfa,"SPAN",{});var ffa=s(zAe);T(rR.$$.fragment,ffa),ffa.forEach(t),cfa.forEach(t),u9r=i(Amo),QAe=n(Amo,"SPAN",{});var gfa=s(QAe);p9r=r(gfa,"AutoModelForImageClassification"),gfa.forEach(t),Amo.forEach(t),aio=i(c),Ko=n(c,"DIV",{class:!0});var ni=s(Ko);T(tR.$$.fragment,ni),_9r=i(ni),ym=n(ni,"P",{});var Rfe=s(ym);b9r=r(Rfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Joe=n(Rfe,"A",{href:!0});var hfa=s(Joe);v9r=r(hfa,"from_pretrained()"),hfa.forEach(t),F9r=r(Rfe," class method or the "),Yoe=n(Rfe,"A",{href:!0});var ufa=s(Yoe);T9r=r(ufa,"from_config()"),ufa.forEach(t),M9r=r(Rfe,` class
method.`),Rfe.forEach(t),E9r=i(ni),aR=n(ni,"P",{});var Lmo=s(aR);C9r=r(Lmo,"This class cannot be instantiated directly using "),WAe=n(Lmo,"CODE",{});var pfa=s(WAe);w9r=r(pfa,"__init__()"),pfa.forEach(t),A9r=r(Lmo," (throws an error)."),Lmo.forEach(t),L9r=i(ni),Dt=n(ni,"DIV",{class:!0});var xx=s(Dt);T(nR.$$.fragment,xx),y9r=i(xx),UAe=n(xx,"P",{});var _fa=s(UAe);x9r=r(_fa,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),_fa.forEach(t),$9r=i(xx),xm=n(xx,"P",{});var Pfe=s(xm);k9r=r(Pfe,`Note:
Loading a model from its configuration file does `),HAe=n(Pfe,"STRONG",{});var bfa=s(HAe);S9r=r(bfa,"not"),bfa.forEach(t),R9r=r(Pfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Zoe=n(Pfe,"A",{href:!0});var vfa=s(Zoe);P9r=r(vfa,"from_pretrained()"),vfa.forEach(t),B9r=r(Pfe," to load the model weights."),Pfe.forEach(t),I9r=i(xx),T(h3.$$.fragment,xx),xx.forEach(t),N9r=i(ni),_o=n(ni,"DIV",{class:!0});var za=s(_o);T(sR.$$.fragment,za),q9r=i(za),JAe=n(za,"P",{});var Ffa=s(JAe);D9r=r(Ffa,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Ffa.forEach(t),j9r=i(za),wn=n(za,"P",{});var $x=s(wn);G9r=r($x,"The model class to instantiate is selected based on the "),YAe=n($x,"CODE",{});var Tfa=s(YAe);O9r=r(Tfa,"model_type"),Tfa.forEach(t),V9r=r($x,` property of the config object (either
passed as an argument or loaded from `),ZAe=n($x,"CODE",{});var Mfa=s(ZAe);X9r=r(Mfa,"pretrained_model_name_or_path"),Mfa.forEach(t),z9r=r($x,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KAe=n($x,"CODE",{});var Efa=s(KAe);Q9r=r(Efa,"pretrained_model_name_or_path"),Efa.forEach(t),W9r=r($x,":"),$x.forEach(t),U9r=i(za),Fe=n(za,"UL",{});var Me=s(Fe);u3=n(Me,"LI",{});var CKe=s(u3);e6e=n(CKe,"STRONG",{});var Cfa=s(e6e);H9r=r(Cfa,"beit"),Cfa.forEach(t),J9r=r(CKe," \u2014 "),Koe=n(CKe,"A",{href:!0});var wfa=s(Koe);Y9r=r(wfa,"BeitForImageClassification"),wfa.forEach(t),Z9r=r(CKe," (BEiT model)"),CKe.forEach(t),K9r=i(Me),p3=n(Me,"LI",{});var wKe=s(p3);o6e=n(wKe,"STRONG",{});var Afa=s(o6e);exr=r(Afa,"convnext"),Afa.forEach(t),oxr=r(wKe," \u2014 "),ere=n(wKe,"A",{href:!0});var Lfa=s(ere);rxr=r(Lfa,"ConvNextForImageClassification"),Lfa.forEach(t),txr=r(wKe," (ConvNeXT model)"),wKe.forEach(t),axr=i(Me),_3=n(Me,"LI",{});var AKe=s(_3);r6e=n(AKe,"STRONG",{});var yfa=s(r6e);nxr=r(yfa,"cvt"),yfa.forEach(t),sxr=r(AKe," \u2014 "),ore=n(AKe,"A",{href:!0});var xfa=s(ore);lxr=r(xfa,"CvtForImageClassification"),xfa.forEach(t),ixr=r(AKe," (CvT model)"),AKe.forEach(t),dxr=i(Me),b3=n(Me,"LI",{});var LKe=s(b3);t6e=n(LKe,"STRONG",{});var $fa=s(t6e);mxr=r($fa,"data2vec-vision"),$fa.forEach(t),cxr=r(LKe," \u2014 "),rre=n(LKe,"A",{href:!0});var kfa=s(rre);fxr=r(kfa,"Data2VecVisionForImageClassification"),kfa.forEach(t),gxr=r(LKe," (Data2VecVision model)"),LKe.forEach(t),hxr=i(Me),Nl=n(Me,"LI",{});var yq=s(Nl);a6e=n(yq,"STRONG",{});var Sfa=s(a6e);uxr=r(Sfa,"deit"),Sfa.forEach(t),pxr=r(yq," \u2014 "),tre=n(yq,"A",{href:!0});var Rfa=s(tre);_xr=r(Rfa,"DeiTForImageClassification"),Rfa.forEach(t),bxr=r(yq," or "),are=n(yq,"A",{href:!0});var Pfa=s(are);vxr=r(Pfa,"DeiTForImageClassificationWithTeacher"),Pfa.forEach(t),Fxr=r(yq," (DeiT model)"),yq.forEach(t),Txr=i(Me),v3=n(Me,"LI",{});var yKe=s(v3);n6e=n(yKe,"STRONG",{});var Bfa=s(n6e);Mxr=r(Bfa,"imagegpt"),Bfa.forEach(t),Exr=r(yKe," \u2014 "),nre=n(yKe,"A",{href:!0});var Ifa=s(nre);Cxr=r(Ifa,"ImageGPTForImageClassification"),Ifa.forEach(t),wxr=r(yKe," (ImageGPT model)"),yKe.forEach(t),Axr=i(Me),ql=n(Me,"LI",{});var xq=s(ql);s6e=n(xq,"STRONG",{});var Nfa=s(s6e);Lxr=r(Nfa,"levit"),Nfa.forEach(t),yxr=r(xq," \u2014 "),sre=n(xq,"A",{href:!0});var qfa=s(sre);xxr=r(qfa,"LevitForImageClassification"),qfa.forEach(t),$xr=r(xq," or "),lre=n(xq,"A",{href:!0});var Dfa=s(lre);kxr=r(Dfa,"LevitForImageClassificationWithTeacher"),Dfa.forEach(t),Sxr=r(xq," (LeViT model)"),xq.forEach(t),Rxr=i(Me),F3=n(Me,"LI",{});var xKe=s(F3);l6e=n(xKe,"STRONG",{});var jfa=s(l6e);Pxr=r(jfa,"mobilevit"),jfa.forEach(t),Bxr=r(xKe," \u2014 "),ire=n(xKe,"A",{href:!0});var Gfa=s(ire);Ixr=r(Gfa,"MobileViTForImageClassification"),Gfa.forEach(t),Nxr=r(xKe," (MobileViT model)"),xKe.forEach(t),qxr=i(Me),jt=n(Me,"LI",{});var Kf=s(jt);i6e=n(Kf,"STRONG",{});var Ofa=s(i6e);Dxr=r(Ofa,"perceiver"),Ofa.forEach(t),jxr=r(Kf," \u2014 "),dre=n(Kf,"A",{href:!0});var Vfa=s(dre);Gxr=r(Vfa,"PerceiverForImageClassificationLearned"),Vfa.forEach(t),Oxr=r(Kf," or "),mre=n(Kf,"A",{href:!0});var Xfa=s(mre);Vxr=r(Xfa,"PerceiverForImageClassificationFourier"),Xfa.forEach(t),Xxr=r(Kf," or "),cre=n(Kf,"A",{href:!0});var zfa=s(cre);zxr=r(zfa,"PerceiverForImageClassificationConvProcessing"),zfa.forEach(t),Qxr=r(Kf," (Perceiver model)"),Kf.forEach(t),Wxr=i(Me),T3=n(Me,"LI",{});var $Ke=s(T3);d6e=n($Ke,"STRONG",{});var Qfa=s(d6e);Uxr=r(Qfa,"poolformer"),Qfa.forEach(t),Hxr=r($Ke," \u2014 "),fre=n($Ke,"A",{href:!0});var Wfa=s(fre);Jxr=r(Wfa,"PoolFormerForImageClassification"),Wfa.forEach(t),Yxr=r($Ke," (PoolFormer model)"),$Ke.forEach(t),Zxr=i(Me),M3=n(Me,"LI",{});var kKe=s(M3);m6e=n(kKe,"STRONG",{});var Ufa=s(m6e);Kxr=r(Ufa,"regnet"),Ufa.forEach(t),e$r=r(kKe," \u2014 "),gre=n(kKe,"A",{href:!0});var Hfa=s(gre);o$r=r(Hfa,"RegNetForImageClassification"),Hfa.forEach(t),r$r=r(kKe," (RegNet model)"),kKe.forEach(t),t$r=i(Me),E3=n(Me,"LI",{});var SKe=s(E3);c6e=n(SKe,"STRONG",{});var Jfa=s(c6e);a$r=r(Jfa,"resnet"),Jfa.forEach(t),n$r=r(SKe," \u2014 "),hre=n(SKe,"A",{href:!0});var Yfa=s(hre);s$r=r(Yfa,"ResNetForImageClassification"),Yfa.forEach(t),l$r=r(SKe," (ResNet model)"),SKe.forEach(t),i$r=i(Me),C3=n(Me,"LI",{});var RKe=s(C3);f6e=n(RKe,"STRONG",{});var Zfa=s(f6e);d$r=r(Zfa,"segformer"),Zfa.forEach(t),m$r=r(RKe," \u2014 "),ure=n(RKe,"A",{href:!0});var Kfa=s(ure);c$r=r(Kfa,"SegformerForImageClassification"),Kfa.forEach(t),f$r=r(RKe," (SegFormer model)"),RKe.forEach(t),g$r=i(Me),w3=n(Me,"LI",{});var PKe=s(w3);g6e=n(PKe,"STRONG",{});var ega=s(g6e);h$r=r(ega,"swin"),ega.forEach(t),u$r=r(PKe," \u2014 "),pre=n(PKe,"A",{href:!0});var oga=s(pre);p$r=r(oga,"SwinForImageClassification"),oga.forEach(t),_$r=r(PKe," (Swin Transformer model)"),PKe.forEach(t),b$r=i(Me),A3=n(Me,"LI",{});var BKe=s(A3);h6e=n(BKe,"STRONG",{});var rga=s(h6e);v$r=r(rga,"swinv2"),rga.forEach(t),F$r=r(BKe," \u2014 "),_re=n(BKe,"A",{href:!0});var tga=s(_re);T$r=r(tga,"Swinv2ForImageClassification"),tga.forEach(t),M$r=r(BKe," (Swin Transformer V2 model)"),BKe.forEach(t),E$r=i(Me),L3=n(Me,"LI",{});var IKe=s(L3);u6e=n(IKe,"STRONG",{});var aga=s(u6e);C$r=r(aga,"van"),aga.forEach(t),w$r=r(IKe," \u2014 "),bre=n(IKe,"A",{href:!0});var nga=s(bre);A$r=r(nga,"VanForImageClassification"),nga.forEach(t),L$r=r(IKe," (VAN model)"),IKe.forEach(t),y$r=i(Me),y3=n(Me,"LI",{});var NKe=s(y3);p6e=n(NKe,"STRONG",{});var sga=s(p6e);x$r=r(sga,"vit"),sga.forEach(t),$$r=r(NKe," \u2014 "),vre=n(NKe,"A",{href:!0});var lga=s(vre);k$r=r(lga,"ViTForImageClassification"),lga.forEach(t),S$r=r(NKe," (ViT model)"),NKe.forEach(t),R$r=i(Me),x3=n(Me,"LI",{});var qKe=s(x3);_6e=n(qKe,"STRONG",{});var iga=s(_6e);P$r=r(iga,"vit_msn"),iga.forEach(t),B$r=r(qKe," \u2014 "),Fre=n(qKe,"A",{href:!0});var dga=s(Fre);I$r=r(dga,"ViTMSNForImageClassification"),dga.forEach(t),N$r=r(qKe," (ViTMSN model)"),qKe.forEach(t),Me.forEach(t),q$r=i(za),$3=n(za,"P",{});var DKe=s($3);D$r=r(DKe,"The model is set in evaluation mode by default using "),b6e=n(DKe,"CODE",{});var mga=s(b6e);j$r=r(mga,"model.eval()"),mga.forEach(t),G$r=r(DKe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),v6e=n(DKe,"CODE",{});var cga=s(v6e);O$r=r(cga,"model.train()"),cga.forEach(t),DKe.forEach(t),V$r=i(za),T(k3.$$.fragment,za),za.forEach(t),ni.forEach(t),nio=i(c),$m=n(c,"H2",{class:!0});var ymo=s($m);S3=n(ymo,"A",{id:!0,class:!0,href:!0});var fga=s(S3);F6e=n(fga,"SPAN",{});var gga=s(F6e);T(lR.$$.fragment,gga),gga.forEach(t),fga.forEach(t),X$r=i(ymo),T6e=n(ymo,"SPAN",{});var hga=s(T6e);z$r=r(hga,"AutoModelForVideoClassification"),hga.forEach(t),ymo.forEach(t),sio=i(c),er=n(c,"DIV",{class:!0});var si=s(er);T(iR.$$.fragment,si),Q$r=i(si),km=n(si,"P",{});var Bfe=s(km);W$r=r(Bfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),Tre=n(Bfe,"A",{href:!0});var uga=s(Tre);U$r=r(uga,"from_pretrained()"),uga.forEach(t),H$r=r(Bfe," class method or the "),Mre=n(Bfe,"A",{href:!0});var pga=s(Mre);J$r=r(pga,"from_config()"),pga.forEach(t),Y$r=r(Bfe,` class
method.`),Bfe.forEach(t),Z$r=i(si),dR=n(si,"P",{});var xmo=s(dR);K$r=r(xmo,"This class cannot be instantiated directly using "),M6e=n(xmo,"CODE",{});var _ga=s(M6e);ekr=r(_ga,"__init__()"),_ga.forEach(t),okr=r(xmo," (throws an error)."),xmo.forEach(t),rkr=i(si),Gt=n(si,"DIV",{class:!0});var kx=s(Gt);T(mR.$$.fragment,kx),tkr=i(kx),E6e=n(kx,"P",{});var bga=s(E6e);akr=r(bga,"Instantiates one of the model classes of the library (with a video classification head) from a configuration."),bga.forEach(t),nkr=i(kx),Sm=n(kx,"P",{});var Ife=s(Sm);skr=r(Ife,`Note:
Loading a model from its configuration file does `),C6e=n(Ife,"STRONG",{});var vga=s(C6e);lkr=r(vga,"not"),vga.forEach(t),ikr=r(Ife,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ere=n(Ife,"A",{href:!0});var Fga=s(Ere);dkr=r(Fga,"from_pretrained()"),Fga.forEach(t),mkr=r(Ife," to load the model weights."),Ife.forEach(t),ckr=i(kx),T(R3.$$.fragment,kx),kx.forEach(t),fkr=i(si),bo=n(si,"DIV",{class:!0});var Qa=s(bo);T(cR.$$.fragment,Qa),gkr=i(Qa),w6e=n(Qa,"P",{});var Tga=s(w6e);hkr=r(Tga,"Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),Tga.forEach(t),ukr=i(Qa),An=n(Qa,"P",{});var Sx=s(An);pkr=r(Sx,"The model class to instantiate is selected based on the "),A6e=n(Sx,"CODE",{});var Mga=s(A6e);_kr=r(Mga,"model_type"),Mga.forEach(t),bkr=r(Sx,` property of the config object (either
passed as an argument or loaded from `),L6e=n(Sx,"CODE",{});var Ega=s(L6e);vkr=r(Ega,"pretrained_model_name_or_path"),Ega.forEach(t),Fkr=r(Sx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),y6e=n(Sx,"CODE",{});var Cga=s(y6e);Tkr=r(Cga,"pretrained_model_name_or_path"),Cga.forEach(t),Mkr=r(Sx,":"),Sx.forEach(t),Ekr=i(Qa),x6e=n(Qa,"UL",{});var wga=s(x6e);P3=n(wga,"LI",{});var jKe=s(P3);$6e=n(jKe,"STRONG",{});var Aga=s($6e);Ckr=r(Aga,"videomae"),Aga.forEach(t),wkr=r(jKe," \u2014 "),Cre=n(jKe,"A",{href:!0});var Lga=s(Cre);Akr=r(Lga,"VideoMAEForVideoClassification"),Lga.forEach(t),Lkr=r(jKe," (VideoMAE model)"),jKe.forEach(t),wga.forEach(t),ykr=i(Qa),B3=n(Qa,"P",{});var GKe=s(B3);xkr=r(GKe,"The model is set in evaluation mode by default using "),k6e=n(GKe,"CODE",{});var yga=s(k6e);$kr=r(yga,"model.eval()"),yga.forEach(t),kkr=r(GKe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),S6e=n(GKe,"CODE",{});var xga=s(S6e);Skr=r(xga,"model.train()"),xga.forEach(t),GKe.forEach(t),Rkr=i(Qa),T(I3.$$.fragment,Qa),Qa.forEach(t),si.forEach(t),lio=i(c),Rm=n(c,"H2",{class:!0});var $mo=s(Rm);N3=n($mo,"A",{id:!0,class:!0,href:!0});var $ga=s(N3);R6e=n($ga,"SPAN",{});var kga=s(R6e);T(fR.$$.fragment,kga),kga.forEach(t),$ga.forEach(t),Pkr=i($mo),P6e=n($mo,"SPAN",{});var Sga=s(P6e);Bkr=r(Sga,"AutoModelForVision2Seq"),Sga.forEach(t),$mo.forEach(t),iio=i(c),or=n(c,"DIV",{class:!0});var li=s(or);T(gR.$$.fragment,li),Ikr=i(li),Pm=n(li,"P",{});var Nfe=s(Pm);Nkr=r(Nfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),wre=n(Nfe,"A",{href:!0});var Rga=s(wre);qkr=r(Rga,"from_pretrained()"),Rga.forEach(t),Dkr=r(Nfe," class method or the "),Are=n(Nfe,"A",{href:!0});var Pga=s(Are);jkr=r(Pga,"from_config()"),Pga.forEach(t),Gkr=r(Nfe,` class
method.`),Nfe.forEach(t),Okr=i(li),hR=n(li,"P",{});var kmo=s(hR);Vkr=r(kmo,"This class cannot be instantiated directly using "),B6e=n(kmo,"CODE",{});var Bga=s(B6e);Xkr=r(Bga,"__init__()"),Bga.forEach(t),zkr=r(kmo," (throws an error)."),kmo.forEach(t),Qkr=i(li),Ot=n(li,"DIV",{class:!0});var Rx=s(Ot);T(uR.$$.fragment,Rx),Wkr=i(Rx),I6e=n(Rx,"P",{});var Iga=s(I6e);Ukr=r(Iga,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Iga.forEach(t),Hkr=i(Rx),Bm=n(Rx,"P",{});var qfe=s(Bm);Jkr=r(qfe,`Note:
Loading a model from its configuration file does `),N6e=n(qfe,"STRONG",{});var Nga=s(N6e);Ykr=r(Nga,"not"),Nga.forEach(t),Zkr=r(qfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Lre=n(qfe,"A",{href:!0});var qga=s(Lre);Kkr=r(qga,"from_pretrained()"),qga.forEach(t),eSr=r(qfe," to load the model weights."),qfe.forEach(t),oSr=i(Rx),T(q3.$$.fragment,Rx),Rx.forEach(t),rSr=i(li),vo=n(li,"DIV",{class:!0});var Wa=s(vo);T(pR.$$.fragment,Wa),tSr=i(Wa),q6e=n(Wa,"P",{});var Dga=s(q6e);aSr=r(Dga,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Dga.forEach(t),nSr=i(Wa),Ln=n(Wa,"P",{});var Px=s(Ln);sSr=r(Px,"The model class to instantiate is selected based on the "),D6e=n(Px,"CODE",{});var jga=s(D6e);lSr=r(jga,"model_type"),jga.forEach(t),iSr=r(Px,` property of the config object (either
passed as an argument or loaded from `),j6e=n(Px,"CODE",{});var Gga=s(j6e);dSr=r(Gga,"pretrained_model_name_or_path"),Gga.forEach(t),mSr=r(Px,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G6e=n(Px,"CODE",{});var Oga=s(G6e);cSr=r(Oga,"pretrained_model_name_or_path"),Oga.forEach(t),fSr=r(Px,":"),Px.forEach(t),gSr=i(Wa),O6e=n(Wa,"UL",{});var Vga=s(O6e);D3=n(Vga,"LI",{});var OKe=s(D3);V6e=n(OKe,"STRONG",{});var Xga=s(V6e);hSr=r(Xga,"vision-encoder-decoder"),Xga.forEach(t),uSr=r(OKe," \u2014 "),yre=n(OKe,"A",{href:!0});var zga=s(yre);pSr=r(zga,"VisionEncoderDecoderModel"),zga.forEach(t),_Sr=r(OKe," (Vision Encoder decoder model)"),OKe.forEach(t),Vga.forEach(t),bSr=i(Wa),j3=n(Wa,"P",{});var VKe=s(j3);vSr=r(VKe,"The model is set in evaluation mode by default using "),X6e=n(VKe,"CODE",{});var Qga=s(X6e);FSr=r(Qga,"model.eval()"),Qga.forEach(t),TSr=r(VKe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),z6e=n(VKe,"CODE",{});var Wga=s(z6e);MSr=r(Wga,"model.train()"),Wga.forEach(t),VKe.forEach(t),ESr=i(Wa),T(G3.$$.fragment,Wa),Wa.forEach(t),li.forEach(t),dio=i(c),Im=n(c,"H2",{class:!0});var Smo=s(Im);O3=n(Smo,"A",{id:!0,class:!0,href:!0});var Uga=s(O3);Q6e=n(Uga,"SPAN",{});var Hga=s(Q6e);T(_R.$$.fragment,Hga),Hga.forEach(t),Uga.forEach(t),CSr=i(Smo),W6e=n(Smo,"SPAN",{});var Jga=s(W6e);wSr=r(Jga,"AutoModelForVisualQuestionAnswering"),Jga.forEach(t),Smo.forEach(t),mio=i(c),rr=n(c,"DIV",{class:!0});var ii=s(rr);T(bR.$$.fragment,ii),ASr=i(ii),Nm=n(ii,"P",{});var Dfe=s(Nm);LSr=r(Dfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),xre=n(Dfe,"A",{href:!0});var Yga=s(xre);ySr=r(Yga,"from_pretrained()"),Yga.forEach(t),xSr=r(Dfe," class method or the "),$re=n(Dfe,"A",{href:!0});var Zga=s($re);$Sr=r(Zga,"from_config()"),Zga.forEach(t),kSr=r(Dfe,` class
method.`),Dfe.forEach(t),SSr=i(ii),vR=n(ii,"P",{});var Rmo=s(vR);RSr=r(Rmo,"This class cannot be instantiated directly using "),U6e=n(Rmo,"CODE",{});var Kga=s(U6e);PSr=r(Kga,"__init__()"),Kga.forEach(t),BSr=r(Rmo," (throws an error)."),Rmo.forEach(t),ISr=i(ii),Vt=n(ii,"DIV",{class:!0});var Bx=s(Vt);T(FR.$$.fragment,Bx),NSr=i(Bx),H6e=n(Bx,"P",{});var eha=s(H6e);qSr=r(eha,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),eha.forEach(t),DSr=i(Bx),qm=n(Bx,"P",{});var jfe=s(qm);jSr=r(jfe,`Note:
Loading a model from its configuration file does `),J6e=n(jfe,"STRONG",{});var oha=s(J6e);GSr=r(oha,"not"),oha.forEach(t),OSr=r(jfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),kre=n(jfe,"A",{href:!0});var rha=s(kre);VSr=r(rha,"from_pretrained()"),rha.forEach(t),XSr=r(jfe," to load the model weights."),jfe.forEach(t),zSr=i(Bx),T(V3.$$.fragment,Bx),Bx.forEach(t),QSr=i(ii),Fo=n(ii,"DIV",{class:!0});var Ua=s(Fo);T(TR.$$.fragment,Ua),WSr=i(Ua),Y6e=n(Ua,"P",{});var tha=s(Y6e);USr=r(tha,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),tha.forEach(t),HSr=i(Ua),yn=n(Ua,"P",{});var Ix=s(yn);JSr=r(Ix,"The model class to instantiate is selected based on the "),Z6e=n(Ix,"CODE",{});var aha=s(Z6e);YSr=r(aha,"model_type"),aha.forEach(t),ZSr=r(Ix,` property of the config object (either
passed as an argument or loaded from `),K6e=n(Ix,"CODE",{});var nha=s(K6e);KSr=r(nha,"pretrained_model_name_or_path"),nha.forEach(t),eRr=r(Ix,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e7e=n(Ix,"CODE",{});var sha=s(e7e);oRr=r(sha,"pretrained_model_name_or_path"),sha.forEach(t),rRr=r(Ix,":"),Ix.forEach(t),tRr=i(Ua),o7e=n(Ua,"UL",{});var lha=s(o7e);X3=n(lha,"LI",{});var XKe=s(X3);r7e=n(XKe,"STRONG",{});var iha=s(r7e);aRr=r(iha,"vilt"),iha.forEach(t),nRr=r(XKe," \u2014 "),Sre=n(XKe,"A",{href:!0});var dha=s(Sre);sRr=r(dha,"ViltForQuestionAnswering"),dha.forEach(t),lRr=r(XKe," (ViLT model)"),XKe.forEach(t),lha.forEach(t),iRr=i(Ua),z3=n(Ua,"P",{});var zKe=s(z3);dRr=r(zKe,"The model is set in evaluation mode by default using "),t7e=n(zKe,"CODE",{});var mha=s(t7e);mRr=r(mha,"model.eval()"),mha.forEach(t),cRr=r(zKe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),a7e=n(zKe,"CODE",{});var cha=s(a7e);fRr=r(cha,"model.train()"),cha.forEach(t),zKe.forEach(t),gRr=i(Ua),T(Q3.$$.fragment,Ua),Ua.forEach(t),ii.forEach(t),cio=i(c),Dm=n(c,"H2",{class:!0});var Pmo=s(Dm);W3=n(Pmo,"A",{id:!0,class:!0,href:!0});var fha=s(W3);n7e=n(fha,"SPAN",{});var gha=s(n7e);T(MR.$$.fragment,gha),gha.forEach(t),fha.forEach(t),hRr=i(Pmo),s7e=n(Pmo,"SPAN",{});var hha=s(s7e);uRr=r(hha,"AutoModelForAudioClassification"),hha.forEach(t),Pmo.forEach(t),fio=i(c),tr=n(c,"DIV",{class:!0});var di=s(tr);T(ER.$$.fragment,di),pRr=i(di),jm=n(di,"P",{});var Gfe=s(jm);_Rr=r(Gfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),Rre=n(Gfe,"A",{href:!0});var uha=s(Rre);bRr=r(uha,"from_pretrained()"),uha.forEach(t),vRr=r(Gfe," class method or the "),Pre=n(Gfe,"A",{href:!0});var pha=s(Pre);FRr=r(pha,"from_config()"),pha.forEach(t),TRr=r(Gfe,` class
method.`),Gfe.forEach(t),MRr=i(di),CR=n(di,"P",{});var Bmo=s(CR);ERr=r(Bmo,"This class cannot be instantiated directly using "),l7e=n(Bmo,"CODE",{});var _ha=s(l7e);CRr=r(_ha,"__init__()"),_ha.forEach(t),wRr=r(Bmo," (throws an error)."),Bmo.forEach(t),ARr=i(di),Xt=n(di,"DIV",{class:!0});var Nx=s(Xt);T(wR.$$.fragment,Nx),LRr=i(Nx),i7e=n(Nx,"P",{});var bha=s(i7e);yRr=r(bha,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),bha.forEach(t),xRr=i(Nx),Gm=n(Nx,"P",{});var Ofe=s(Gm);$Rr=r(Ofe,`Note:
Loading a model from its configuration file does `),d7e=n(Ofe,"STRONG",{});var vha=s(d7e);kRr=r(vha,"not"),vha.forEach(t),SRr=r(Ofe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Bre=n(Ofe,"A",{href:!0});var Fha=s(Bre);RRr=r(Fha,"from_pretrained()"),Fha.forEach(t),PRr=r(Ofe," to load the model weights."),Ofe.forEach(t),BRr=i(Nx),T(U3.$$.fragment,Nx),Nx.forEach(t),IRr=i(di),To=n(di,"DIV",{class:!0});var Ha=s(To);T(AR.$$.fragment,Ha),NRr=i(Ha),m7e=n(Ha,"P",{});var Tha=s(m7e);qRr=r(Tha,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),Tha.forEach(t),DRr=i(Ha),xn=n(Ha,"P",{});var qx=s(xn);jRr=r(qx,"The model class to instantiate is selected based on the "),c7e=n(qx,"CODE",{});var Mha=s(c7e);GRr=r(Mha,"model_type"),Mha.forEach(t),ORr=r(qx,` property of the config object (either
passed as an argument or loaded from `),f7e=n(qx,"CODE",{});var Eha=s(f7e);VRr=r(Eha,"pretrained_model_name_or_path"),Eha.forEach(t),XRr=r(qx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),g7e=n(qx,"CODE",{});var Cha=s(g7e);zRr=r(Cha,"pretrained_model_name_or_path"),Cha.forEach(t),QRr=r(qx,":"),qx.forEach(t),WRr=i(Ha),Ne=n(Ha,"UL",{});var Je=s(Ne);H3=n(Je,"LI",{});var QKe=s(H3);h7e=n(QKe,"STRONG",{});var wha=s(h7e);URr=r(wha,"data2vec-audio"),wha.forEach(t),HRr=r(QKe," \u2014 "),Ire=n(QKe,"A",{href:!0});var Aha=s(Ire);JRr=r(Aha,"Data2VecAudioForSequenceClassification"),Aha.forEach(t),YRr=r(QKe," (Data2VecAudio model)"),QKe.forEach(t),ZRr=i(Je),J3=n(Je,"LI",{});var WKe=s(J3);u7e=n(WKe,"STRONG",{});var Lha=s(u7e);KRr=r(Lha,"hubert"),Lha.forEach(t),ePr=r(WKe," \u2014 "),Nre=n(WKe,"A",{href:!0});var yha=s(Nre);oPr=r(yha,"HubertForSequenceClassification"),yha.forEach(t),rPr=r(WKe," (Hubert model)"),WKe.forEach(t),tPr=i(Je),Y3=n(Je,"LI",{});var UKe=s(Y3);p7e=n(UKe,"STRONG",{});var xha=s(p7e);aPr=r(xha,"sew"),xha.forEach(t),nPr=r(UKe," \u2014 "),qre=n(UKe,"A",{href:!0});var $ha=s(qre);sPr=r($ha,"SEWForSequenceClassification"),$ha.forEach(t),lPr=r(UKe," (SEW model)"),UKe.forEach(t),iPr=i(Je),Z3=n(Je,"LI",{});var HKe=s(Z3);_7e=n(HKe,"STRONG",{});var kha=s(_7e);dPr=r(kha,"sew-d"),kha.forEach(t),mPr=r(HKe," \u2014 "),Dre=n(HKe,"A",{href:!0});var Sha=s(Dre);cPr=r(Sha,"SEWDForSequenceClassification"),Sha.forEach(t),fPr=r(HKe," (SEW-D model)"),HKe.forEach(t),gPr=i(Je),K3=n(Je,"LI",{});var JKe=s(K3);b7e=n(JKe,"STRONG",{});var Rha=s(b7e);hPr=r(Rha,"unispeech"),Rha.forEach(t),uPr=r(JKe," \u2014 "),jre=n(JKe,"A",{href:!0});var Pha=s(jre);pPr=r(Pha,"UniSpeechForSequenceClassification"),Pha.forEach(t),_Pr=r(JKe," (UniSpeech model)"),JKe.forEach(t),bPr=i(Je),e5=n(Je,"LI",{});var YKe=s(e5);v7e=n(YKe,"STRONG",{});var Bha=s(v7e);vPr=r(Bha,"unispeech-sat"),Bha.forEach(t),FPr=r(YKe," \u2014 "),Gre=n(YKe,"A",{href:!0});var Iha=s(Gre);TPr=r(Iha,"UniSpeechSatForSequenceClassification"),Iha.forEach(t),MPr=r(YKe," (UniSpeechSat model)"),YKe.forEach(t),EPr=i(Je),o5=n(Je,"LI",{});var ZKe=s(o5);F7e=n(ZKe,"STRONG",{});var Nha=s(F7e);CPr=r(Nha,"wav2vec2"),Nha.forEach(t),wPr=r(ZKe," \u2014 "),Ore=n(ZKe,"A",{href:!0});var qha=s(Ore);APr=r(qha,"Wav2Vec2ForSequenceClassification"),qha.forEach(t),LPr=r(ZKe," (Wav2Vec2 model)"),ZKe.forEach(t),yPr=i(Je),r5=n(Je,"LI",{});var KKe=s(r5);T7e=n(KKe,"STRONG",{});var Dha=s(T7e);xPr=r(Dha,"wav2vec2-conformer"),Dha.forEach(t),$Pr=r(KKe," \u2014 "),Vre=n(KKe,"A",{href:!0});var jha=s(Vre);kPr=r(jha,"Wav2Vec2ConformerForSequenceClassification"),jha.forEach(t),SPr=r(KKe," (Wav2Vec2-Conformer model)"),KKe.forEach(t),RPr=i(Je),t5=n(Je,"LI",{});var eeo=s(t5);M7e=n(eeo,"STRONG",{});var Gha=s(M7e);PPr=r(Gha,"wavlm"),Gha.forEach(t),BPr=r(eeo," \u2014 "),Xre=n(eeo,"A",{href:!0});var Oha=s(Xre);IPr=r(Oha,"WavLMForSequenceClassification"),Oha.forEach(t),NPr=r(eeo," (WavLM model)"),eeo.forEach(t),Je.forEach(t),qPr=i(Ha),a5=n(Ha,"P",{});var oeo=s(a5);DPr=r(oeo,"The model is set in evaluation mode by default using "),E7e=n(oeo,"CODE",{});var Vha=s(E7e);jPr=r(Vha,"model.eval()"),Vha.forEach(t),GPr=r(oeo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),C7e=n(oeo,"CODE",{});var Xha=s(C7e);OPr=r(Xha,"model.train()"),Xha.forEach(t),oeo.forEach(t),VPr=i(Ha),T(n5.$$.fragment,Ha),Ha.forEach(t),di.forEach(t),gio=i(c),Om=n(c,"H2",{class:!0});var Imo=s(Om);s5=n(Imo,"A",{id:!0,class:!0,href:!0});var zha=s(s5);w7e=n(zha,"SPAN",{});var Qha=s(w7e);T(LR.$$.fragment,Qha),Qha.forEach(t),zha.forEach(t),XPr=i(Imo),A7e=n(Imo,"SPAN",{});var Wha=s(A7e);zPr=r(Wha,"AutoModelForAudioFrameClassification"),Wha.forEach(t),Imo.forEach(t),hio=i(c),ar=n(c,"DIV",{class:!0});var mi=s(ar);T(yR.$$.fragment,mi),QPr=i(mi),Vm=n(mi,"P",{});var Vfe=s(Vm);WPr=r(Vfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),zre=n(Vfe,"A",{href:!0});var Uha=s(zre);UPr=r(Uha,"from_pretrained()"),Uha.forEach(t),HPr=r(Vfe," class method or the "),Qre=n(Vfe,"A",{href:!0});var Hha=s(Qre);JPr=r(Hha,"from_config()"),Hha.forEach(t),YPr=r(Vfe,` class
method.`),Vfe.forEach(t),ZPr=i(mi),xR=n(mi,"P",{});var Nmo=s(xR);KPr=r(Nmo,"This class cannot be instantiated directly using "),L7e=n(Nmo,"CODE",{});var Jha=s(L7e);eBr=r(Jha,"__init__()"),Jha.forEach(t),oBr=r(Nmo," (throws an error)."),Nmo.forEach(t),rBr=i(mi),zt=n(mi,"DIV",{class:!0});var Dx=s(zt);T($R.$$.fragment,Dx),tBr=i(Dx),y7e=n(Dx,"P",{});var Yha=s(y7e);aBr=r(Yha,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),Yha.forEach(t),nBr=i(Dx),Xm=n(Dx,"P",{});var Xfe=s(Xm);sBr=r(Xfe,`Note:
Loading a model from its configuration file does `),x7e=n(Xfe,"STRONG",{});var Zha=s(x7e);lBr=r(Zha,"not"),Zha.forEach(t),iBr=r(Xfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Wre=n(Xfe,"A",{href:!0});var Kha=s(Wre);dBr=r(Kha,"from_pretrained()"),Kha.forEach(t),mBr=r(Xfe," to load the model weights."),Xfe.forEach(t),cBr=i(Dx),T(l5.$$.fragment,Dx),Dx.forEach(t),fBr=i(mi),Mo=n(mi,"DIV",{class:!0});var Ja=s(Mo);T(kR.$$.fragment,Ja),gBr=i(Ja),$7e=n(Ja,"P",{});var eua=s($7e);hBr=r(eua,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),eua.forEach(t),uBr=i(Ja),$n=n(Ja,"P",{});var jx=s($n);pBr=r(jx,"The model class to instantiate is selected based on the "),k7e=n(jx,"CODE",{});var oua=s(k7e);_Br=r(oua,"model_type"),oua.forEach(t),bBr=r(jx,` property of the config object (either
passed as an argument or loaded from `),S7e=n(jx,"CODE",{});var rua=s(S7e);vBr=r(rua,"pretrained_model_name_or_path"),rua.forEach(t),FBr=r(jx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R7e=n(jx,"CODE",{});var tua=s(R7e);TBr=r(tua,"pretrained_model_name_or_path"),tua.forEach(t),MBr=r(jx,":"),jx.forEach(t),EBr=i(Ja),vt=n(Ja,"UL",{});var ci=s(vt);i5=n(ci,"LI",{});var reo=s(i5);P7e=n(reo,"STRONG",{});var aua=s(P7e);CBr=r(aua,"data2vec-audio"),aua.forEach(t),wBr=r(reo," \u2014 "),Ure=n(reo,"A",{href:!0});var nua=s(Ure);ABr=r(nua,"Data2VecAudioForAudioFrameClassification"),nua.forEach(t),LBr=r(reo," (Data2VecAudio model)"),reo.forEach(t),yBr=i(ci),d5=n(ci,"LI",{});var teo=s(d5);B7e=n(teo,"STRONG",{});var sua=s(B7e);xBr=r(sua,"unispeech-sat"),sua.forEach(t),$Br=r(teo," \u2014 "),Hre=n(teo,"A",{href:!0});var lua=s(Hre);kBr=r(lua,"UniSpeechSatForAudioFrameClassification"),lua.forEach(t),SBr=r(teo," (UniSpeechSat model)"),teo.forEach(t),RBr=i(ci),m5=n(ci,"LI",{});var aeo=s(m5);I7e=n(aeo,"STRONG",{});var iua=s(I7e);PBr=r(iua,"wav2vec2"),iua.forEach(t),BBr=r(aeo," \u2014 "),Jre=n(aeo,"A",{href:!0});var dua=s(Jre);IBr=r(dua,"Wav2Vec2ForAudioFrameClassification"),dua.forEach(t),NBr=r(aeo," (Wav2Vec2 model)"),aeo.forEach(t),qBr=i(ci),c5=n(ci,"LI",{});var neo=s(c5);N7e=n(neo,"STRONG",{});var mua=s(N7e);DBr=r(mua,"wav2vec2-conformer"),mua.forEach(t),jBr=r(neo," \u2014 "),Yre=n(neo,"A",{href:!0});var cua=s(Yre);GBr=r(cua,"Wav2Vec2ConformerForAudioFrameClassification"),cua.forEach(t),OBr=r(neo," (Wav2Vec2-Conformer model)"),neo.forEach(t),VBr=i(ci),f5=n(ci,"LI",{});var seo=s(f5);q7e=n(seo,"STRONG",{});var fua=s(q7e);XBr=r(fua,"wavlm"),fua.forEach(t),zBr=r(seo," \u2014 "),Zre=n(seo,"A",{href:!0});var gua=s(Zre);QBr=r(gua,"WavLMForAudioFrameClassification"),gua.forEach(t),WBr=r(seo," (WavLM model)"),seo.forEach(t),ci.forEach(t),UBr=i(Ja),g5=n(Ja,"P",{});var leo=s(g5);HBr=r(leo,"The model is set in evaluation mode by default using "),D7e=n(leo,"CODE",{});var hua=s(D7e);JBr=r(hua,"model.eval()"),hua.forEach(t),YBr=r(leo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),j7e=n(leo,"CODE",{});var uua=s(j7e);ZBr=r(uua,"model.train()"),uua.forEach(t),leo.forEach(t),KBr=i(Ja),T(h5.$$.fragment,Ja),Ja.forEach(t),mi.forEach(t),uio=i(c),zm=n(c,"H2",{class:!0});var qmo=s(zm);u5=n(qmo,"A",{id:!0,class:!0,href:!0});var pua=s(u5);G7e=n(pua,"SPAN",{});var _ua=s(G7e);T(SR.$$.fragment,_ua),_ua.forEach(t),pua.forEach(t),eIr=i(qmo),O7e=n(qmo,"SPAN",{});var bua=s(O7e);oIr=r(bua,"AutoModelForCTC"),bua.forEach(t),qmo.forEach(t),pio=i(c),nr=n(c,"DIV",{class:!0});var fi=s(nr);T(RR.$$.fragment,fi),rIr=i(fi),Qm=n(fi,"P",{});var zfe=s(Qm);tIr=r(zfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),Kre=n(zfe,"A",{href:!0});var vua=s(Kre);aIr=r(vua,"from_pretrained()"),vua.forEach(t),nIr=r(zfe," class method or the "),ete=n(zfe,"A",{href:!0});var Fua=s(ete);sIr=r(Fua,"from_config()"),Fua.forEach(t),lIr=r(zfe,` class
method.`),zfe.forEach(t),iIr=i(fi),PR=n(fi,"P",{});var Dmo=s(PR);dIr=r(Dmo,"This class cannot be instantiated directly using "),V7e=n(Dmo,"CODE",{});var Tua=s(V7e);mIr=r(Tua,"__init__()"),Tua.forEach(t),cIr=r(Dmo," (throws an error)."),Dmo.forEach(t),fIr=i(fi),Qt=n(fi,"DIV",{class:!0});var Gx=s(Qt);T(BR.$$.fragment,Gx),gIr=i(Gx),X7e=n(Gx,"P",{});var Mua=s(X7e);hIr=r(Mua,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),Mua.forEach(t),uIr=i(Gx),Wm=n(Gx,"P",{});var Qfe=s(Wm);pIr=r(Qfe,`Note:
Loading a model from its configuration file does `),z7e=n(Qfe,"STRONG",{});var Eua=s(z7e);_Ir=r(Eua,"not"),Eua.forEach(t),bIr=r(Qfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),ote=n(Qfe,"A",{href:!0});var Cua=s(ote);vIr=r(Cua,"from_pretrained()"),Cua.forEach(t),FIr=r(Qfe," to load the model weights."),Qfe.forEach(t),TIr=i(Gx),T(p5.$$.fragment,Gx),Gx.forEach(t),MIr=i(fi),Eo=n(fi,"DIV",{class:!0});var Ya=s(Eo);T(IR.$$.fragment,Ya),EIr=i(Ya),Q7e=n(Ya,"P",{});var wua=s(Q7e);CIr=r(wua,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),wua.forEach(t),wIr=i(Ya),kn=n(Ya,"P",{});var Ox=s(kn);AIr=r(Ox,"The model class to instantiate is selected based on the "),W7e=n(Ox,"CODE",{});var Aua=s(W7e);LIr=r(Aua,"model_type"),Aua.forEach(t),yIr=r(Ox,` property of the config object (either
passed as an argument or loaded from `),U7e=n(Ox,"CODE",{});var Lua=s(U7e);xIr=r(Lua,"pretrained_model_name_or_path"),Lua.forEach(t),$Ir=r(Ox,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),H7e=n(Ox,"CODE",{});var yua=s(H7e);kIr=r(yua,"pretrained_model_name_or_path"),yua.forEach(t),SIr=r(Ox,":"),Ox.forEach(t),RIr=i(Ya),xe=n(Ya,"UL",{});var qe=s(xe);_5=n(qe,"LI",{});var ieo=s(_5);J7e=n(ieo,"STRONG",{});var xua=s(J7e);PIr=r(xua,"data2vec-audio"),xua.forEach(t),BIr=r(ieo," \u2014 "),rte=n(ieo,"A",{href:!0});var $ua=s(rte);IIr=r($ua,"Data2VecAudioForCTC"),$ua.forEach(t),NIr=r(ieo," (Data2VecAudio model)"),ieo.forEach(t),qIr=i(qe),b5=n(qe,"LI",{});var deo=s(b5);Y7e=n(deo,"STRONG",{});var kua=s(Y7e);DIr=r(kua,"hubert"),kua.forEach(t),jIr=r(deo," \u2014 "),tte=n(deo,"A",{href:!0});var Sua=s(tte);GIr=r(Sua,"HubertForCTC"),Sua.forEach(t),OIr=r(deo," (Hubert model)"),deo.forEach(t),VIr=i(qe),v5=n(qe,"LI",{});var meo=s(v5);Z7e=n(meo,"STRONG",{});var Rua=s(Z7e);XIr=r(Rua,"mctct"),Rua.forEach(t),zIr=r(meo," \u2014 "),ate=n(meo,"A",{href:!0});var Pua=s(ate);QIr=r(Pua,"MCTCTForCTC"),Pua.forEach(t),WIr=r(meo," (M-CTC-T model)"),meo.forEach(t),UIr=i(qe),F5=n(qe,"LI",{});var ceo=s(F5);K7e=n(ceo,"STRONG",{});var Bua=s(K7e);HIr=r(Bua,"sew"),Bua.forEach(t),JIr=r(ceo," \u2014 "),nte=n(ceo,"A",{href:!0});var Iua=s(nte);YIr=r(Iua,"SEWForCTC"),Iua.forEach(t),ZIr=r(ceo," (SEW model)"),ceo.forEach(t),KIr=i(qe),T5=n(qe,"LI",{});var feo=s(T5);e8e=n(feo,"STRONG",{});var Nua=s(e8e);eNr=r(Nua,"sew-d"),Nua.forEach(t),oNr=r(feo," \u2014 "),ste=n(feo,"A",{href:!0});var qua=s(ste);rNr=r(qua,"SEWDForCTC"),qua.forEach(t),tNr=r(feo," (SEW-D model)"),feo.forEach(t),aNr=i(qe),M5=n(qe,"LI",{});var geo=s(M5);o8e=n(geo,"STRONG",{});var Dua=s(o8e);nNr=r(Dua,"unispeech"),Dua.forEach(t),sNr=r(geo," \u2014 "),lte=n(geo,"A",{href:!0});var jua=s(lte);lNr=r(jua,"UniSpeechForCTC"),jua.forEach(t),iNr=r(geo," (UniSpeech model)"),geo.forEach(t),dNr=i(qe),E5=n(qe,"LI",{});var heo=s(E5);r8e=n(heo,"STRONG",{});var Gua=s(r8e);mNr=r(Gua,"unispeech-sat"),Gua.forEach(t),cNr=r(heo," \u2014 "),ite=n(heo,"A",{href:!0});var Oua=s(ite);fNr=r(Oua,"UniSpeechSatForCTC"),Oua.forEach(t),gNr=r(heo," (UniSpeechSat model)"),heo.forEach(t),hNr=i(qe),C5=n(qe,"LI",{});var ueo=s(C5);t8e=n(ueo,"STRONG",{});var Vua=s(t8e);uNr=r(Vua,"wav2vec2"),Vua.forEach(t),pNr=r(ueo," \u2014 "),dte=n(ueo,"A",{href:!0});var Xua=s(dte);_Nr=r(Xua,"Wav2Vec2ForCTC"),Xua.forEach(t),bNr=r(ueo," (Wav2Vec2 model)"),ueo.forEach(t),vNr=i(qe),w5=n(qe,"LI",{});var peo=s(w5);a8e=n(peo,"STRONG",{});var zua=s(a8e);FNr=r(zua,"wav2vec2-conformer"),zua.forEach(t),TNr=r(peo," \u2014 "),mte=n(peo,"A",{href:!0});var Qua=s(mte);MNr=r(Qua,"Wav2Vec2ConformerForCTC"),Qua.forEach(t),ENr=r(peo," (Wav2Vec2-Conformer model)"),peo.forEach(t),CNr=i(qe),A5=n(qe,"LI",{});var _eo=s(A5);n8e=n(_eo,"STRONG",{});var Wua=s(n8e);wNr=r(Wua,"wavlm"),Wua.forEach(t),ANr=r(_eo," \u2014 "),cte=n(_eo,"A",{href:!0});var Uua=s(cte);LNr=r(Uua,"WavLMForCTC"),Uua.forEach(t),yNr=r(_eo," (WavLM model)"),_eo.forEach(t),qe.forEach(t),xNr=i(Ya),L5=n(Ya,"P",{});var beo=s(L5);$Nr=r(beo,"The model is set in evaluation mode by default using "),s8e=n(beo,"CODE",{});var Hua=s(s8e);kNr=r(Hua,"model.eval()"),Hua.forEach(t),SNr=r(beo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),l8e=n(beo,"CODE",{});var Jua=s(l8e);RNr=r(Jua,"model.train()"),Jua.forEach(t),beo.forEach(t),PNr=i(Ya),T(y5.$$.fragment,Ya),Ya.forEach(t),fi.forEach(t),_io=i(c),Um=n(c,"H2",{class:!0});var jmo=s(Um);x5=n(jmo,"A",{id:!0,class:!0,href:!0});var Yua=s(x5);i8e=n(Yua,"SPAN",{});var Zua=s(i8e);T(NR.$$.fragment,Zua),Zua.forEach(t),Yua.forEach(t),BNr=i(jmo),d8e=n(jmo,"SPAN",{});var Kua=s(d8e);INr=r(Kua,"AutoModelForSpeechSeq2Seq"),Kua.forEach(t),jmo.forEach(t),bio=i(c),sr=n(c,"DIV",{class:!0});var gi=s(sr);T(qR.$$.fragment,gi),NNr=i(gi),Hm=n(gi,"P",{});var Wfe=s(Hm);qNr=r(Wfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),fte=n(Wfe,"A",{href:!0});var epa=s(fte);DNr=r(epa,"from_pretrained()"),epa.forEach(t),jNr=r(Wfe," class method or the "),gte=n(Wfe,"A",{href:!0});var opa=s(gte);GNr=r(opa,"from_config()"),opa.forEach(t),ONr=r(Wfe,` class
method.`),Wfe.forEach(t),VNr=i(gi),DR=n(gi,"P",{});var Gmo=s(DR);XNr=r(Gmo,"This class cannot be instantiated directly using "),m8e=n(Gmo,"CODE",{});var rpa=s(m8e);zNr=r(rpa,"__init__()"),rpa.forEach(t),QNr=r(Gmo," (throws an error)."),Gmo.forEach(t),WNr=i(gi),Wt=n(gi,"DIV",{class:!0});var Vx=s(Wt);T(jR.$$.fragment,Vx),UNr=i(Vx),c8e=n(Vx,"P",{});var tpa=s(c8e);HNr=r(tpa,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),tpa.forEach(t),JNr=i(Vx),Jm=n(Vx,"P",{});var Ufe=s(Jm);YNr=r(Ufe,`Note:
Loading a model from its configuration file does `),f8e=n(Ufe,"STRONG",{});var apa=s(f8e);ZNr=r(apa,"not"),apa.forEach(t),KNr=r(Ufe,` load the model weights. It only affects the
model\u2019s configuration. Use `),hte=n(Ufe,"A",{href:!0});var npa=s(hte);eqr=r(npa,"from_pretrained()"),npa.forEach(t),oqr=r(Ufe," to load the model weights."),Ufe.forEach(t),rqr=i(Vx),T($5.$$.fragment,Vx),Vx.forEach(t),tqr=i(gi),Co=n(gi,"DIV",{class:!0});var Za=s(Co);T(GR.$$.fragment,Za),aqr=i(Za),g8e=n(Za,"P",{});var spa=s(g8e);nqr=r(spa,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),spa.forEach(t),sqr=i(Za),Sn=n(Za,"P",{});var Xx=s(Sn);lqr=r(Xx,"The model class to instantiate is selected based on the "),h8e=n(Xx,"CODE",{});var lpa=s(h8e);iqr=r(lpa,"model_type"),lpa.forEach(t),dqr=r(Xx,` property of the config object (either
passed as an argument or loaded from `),u8e=n(Xx,"CODE",{});var ipa=s(u8e);mqr=r(ipa,"pretrained_model_name_or_path"),ipa.forEach(t),cqr=r(Xx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p8e=n(Xx,"CODE",{});var dpa=s(p8e);fqr=r(dpa,"pretrained_model_name_or_path"),dpa.forEach(t),gqr=r(Xx,":"),Xx.forEach(t),hqr=i(Za),Ym=n(Za,"UL",{});var Hfe=s(Ym);k5=n(Hfe,"LI",{});var veo=s(k5);_8e=n(veo,"STRONG",{});var mpa=s(_8e);uqr=r(mpa,"speech-encoder-decoder"),mpa.forEach(t),pqr=r(veo," \u2014 "),ute=n(veo,"A",{href:!0});var cpa=s(ute);_qr=r(cpa,"SpeechEncoderDecoderModel"),cpa.forEach(t),bqr=r(veo," (Speech Encoder decoder model)"),veo.forEach(t),vqr=i(Hfe),S5=n(Hfe,"LI",{});var Feo=s(S5);b8e=n(Feo,"STRONG",{});var fpa=s(b8e);Fqr=r(fpa,"speech_to_text"),fpa.forEach(t),Tqr=r(Feo," \u2014 "),pte=n(Feo,"A",{href:!0});var gpa=s(pte);Mqr=r(gpa,"Speech2TextForConditionalGeneration"),gpa.forEach(t),Eqr=r(Feo," (Speech2Text model)"),Feo.forEach(t),Cqr=i(Hfe),R5=n(Hfe,"LI",{});var Teo=s(R5);v8e=n(Teo,"STRONG",{});var hpa=s(v8e);wqr=r(hpa,"whisper"),hpa.forEach(t),Aqr=r(Teo," \u2014 "),_te=n(Teo,"A",{href:!0});var upa=s(_te);Lqr=r(upa,"WhisperForConditionalGeneration"),upa.forEach(t),yqr=r(Teo," (Whisper model)"),Teo.forEach(t),Hfe.forEach(t),xqr=i(Za),P5=n(Za,"P",{});var Meo=s(P5);$qr=r(Meo,"The model is set in evaluation mode by default using "),F8e=n(Meo,"CODE",{});var ppa=s(F8e);kqr=r(ppa,"model.eval()"),ppa.forEach(t),Sqr=r(Meo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),T8e=n(Meo,"CODE",{});var _pa=s(T8e);Rqr=r(_pa,"model.train()"),_pa.forEach(t),Meo.forEach(t),Pqr=i(Za),T(B5.$$.fragment,Za),Za.forEach(t),gi.forEach(t),vio=i(c),Zm=n(c,"H2",{class:!0});var Omo=s(Zm);I5=n(Omo,"A",{id:!0,class:!0,href:!0});var bpa=s(I5);M8e=n(bpa,"SPAN",{});var vpa=s(M8e);T(OR.$$.fragment,vpa),vpa.forEach(t),bpa.forEach(t),Bqr=i(Omo),E8e=n(Omo,"SPAN",{});var Fpa=s(E8e);Iqr=r(Fpa,"AutoModelForAudioXVector"),Fpa.forEach(t),Omo.forEach(t),Fio=i(c),lr=n(c,"DIV",{class:!0});var hi=s(lr);T(VR.$$.fragment,hi),Nqr=i(hi),Km=n(hi,"P",{});var Jfe=s(Km);qqr=r(Jfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),bte=n(Jfe,"A",{href:!0});var Tpa=s(bte);Dqr=r(Tpa,"from_pretrained()"),Tpa.forEach(t),jqr=r(Jfe," class method or the "),vte=n(Jfe,"A",{href:!0});var Mpa=s(vte);Gqr=r(Mpa,"from_config()"),Mpa.forEach(t),Oqr=r(Jfe,` class
method.`),Jfe.forEach(t),Vqr=i(hi),XR=n(hi,"P",{});var Vmo=s(XR);Xqr=r(Vmo,"This class cannot be instantiated directly using "),C8e=n(Vmo,"CODE",{});var Epa=s(C8e);zqr=r(Epa,"__init__()"),Epa.forEach(t),Qqr=r(Vmo," (throws an error)."),Vmo.forEach(t),Wqr=i(hi),Ut=n(hi,"DIV",{class:!0});var zx=s(Ut);T(zR.$$.fragment,zx),Uqr=i(zx),w8e=n(zx,"P",{});var Cpa=s(w8e);Hqr=r(Cpa,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),Cpa.forEach(t),Jqr=i(zx),ec=n(zx,"P",{});var Yfe=s(ec);Yqr=r(Yfe,`Note:
Loading a model from its configuration file does `),A8e=n(Yfe,"STRONG",{});var wpa=s(A8e);Zqr=r(wpa,"not"),wpa.forEach(t),Kqr=r(Yfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Fte=n(Yfe,"A",{href:!0});var Apa=s(Fte);eDr=r(Apa,"from_pretrained()"),Apa.forEach(t),oDr=r(Yfe," to load the model weights."),Yfe.forEach(t),rDr=i(zx),T(N5.$$.fragment,zx),zx.forEach(t),tDr=i(hi),wo=n(hi,"DIV",{class:!0});var Ka=s(wo);T(QR.$$.fragment,Ka),aDr=i(Ka),L8e=n(Ka,"P",{});var Lpa=s(L8e);nDr=r(Lpa,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),Lpa.forEach(t),sDr=i(Ka),Rn=n(Ka,"P",{});var Qx=s(Rn);lDr=r(Qx,"The model class to instantiate is selected based on the "),y8e=n(Qx,"CODE",{});var ypa=s(y8e);iDr=r(ypa,"model_type"),ypa.forEach(t),dDr=r(Qx,` property of the config object (either
passed as an argument or loaded from `),x8e=n(Qx,"CODE",{});var xpa=s(x8e);mDr=r(xpa,"pretrained_model_name_or_path"),xpa.forEach(t),cDr=r(Qx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$8e=n(Qx,"CODE",{});var $pa=s($8e);fDr=r($pa,"pretrained_model_name_or_path"),$pa.forEach(t),gDr=r(Qx,":"),Qx.forEach(t),hDr=i(Ka),Ft=n(Ka,"UL",{});var ui=s(Ft);q5=n(ui,"LI",{});var Eeo=s(q5);k8e=n(Eeo,"STRONG",{});var kpa=s(k8e);uDr=r(kpa,"data2vec-audio"),kpa.forEach(t),pDr=r(Eeo," \u2014 "),Tte=n(Eeo,"A",{href:!0});var Spa=s(Tte);_Dr=r(Spa,"Data2VecAudioForXVector"),Spa.forEach(t),bDr=r(Eeo," (Data2VecAudio model)"),Eeo.forEach(t),vDr=i(ui),D5=n(ui,"LI",{});var Ceo=s(D5);S8e=n(Ceo,"STRONG",{});var Rpa=s(S8e);FDr=r(Rpa,"unispeech-sat"),Rpa.forEach(t),TDr=r(Ceo," \u2014 "),Mte=n(Ceo,"A",{href:!0});var Ppa=s(Mte);MDr=r(Ppa,"UniSpeechSatForXVector"),Ppa.forEach(t),EDr=r(Ceo," (UniSpeechSat model)"),Ceo.forEach(t),CDr=i(ui),j5=n(ui,"LI",{});var weo=s(j5);R8e=n(weo,"STRONG",{});var Bpa=s(R8e);wDr=r(Bpa,"wav2vec2"),Bpa.forEach(t),ADr=r(weo," \u2014 "),Ete=n(weo,"A",{href:!0});var Ipa=s(Ete);LDr=r(Ipa,"Wav2Vec2ForXVector"),Ipa.forEach(t),yDr=r(weo," (Wav2Vec2 model)"),weo.forEach(t),xDr=i(ui),G5=n(ui,"LI",{});var Aeo=s(G5);P8e=n(Aeo,"STRONG",{});var Npa=s(P8e);$Dr=r(Npa,"wav2vec2-conformer"),Npa.forEach(t),kDr=r(Aeo," \u2014 "),Cte=n(Aeo,"A",{href:!0});var qpa=s(Cte);SDr=r(qpa,"Wav2Vec2ConformerForXVector"),qpa.forEach(t),RDr=r(Aeo," (Wav2Vec2-Conformer model)"),Aeo.forEach(t),PDr=i(ui),O5=n(ui,"LI",{});var Leo=s(O5);B8e=n(Leo,"STRONG",{});var Dpa=s(B8e);BDr=r(Dpa,"wavlm"),Dpa.forEach(t),IDr=r(Leo," \u2014 "),wte=n(Leo,"A",{href:!0});var jpa=s(wte);NDr=r(jpa,"WavLMForXVector"),jpa.forEach(t),qDr=r(Leo," (WavLM model)"),Leo.forEach(t),ui.forEach(t),DDr=i(Ka),V5=n(Ka,"P",{});var yeo=s(V5);jDr=r(yeo,"The model is set in evaluation mode by default using "),I8e=n(yeo,"CODE",{});var Gpa=s(I8e);GDr=r(Gpa,"model.eval()"),Gpa.forEach(t),ODr=r(yeo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),N8e=n(yeo,"CODE",{});var Opa=s(N8e);VDr=r(Opa,"model.train()"),Opa.forEach(t),yeo.forEach(t),XDr=i(Ka),T(X5.$$.fragment,Ka),Ka.forEach(t),hi.forEach(t),Tio=i(c),oc=n(c,"H2",{class:!0});var Xmo=s(oc);z5=n(Xmo,"A",{id:!0,class:!0,href:!0});var Vpa=s(z5);q8e=n(Vpa,"SPAN",{});var Xpa=s(q8e);T(WR.$$.fragment,Xpa),Xpa.forEach(t),Vpa.forEach(t),zDr=i(Xmo),D8e=n(Xmo,"SPAN",{});var zpa=s(D8e);QDr=r(zpa,"AutoModelForMaskedImageModeling"),zpa.forEach(t),Xmo.forEach(t),Mio=i(c),ir=n(c,"DIV",{class:!0});var pi=s(ir);T(UR.$$.fragment,pi),WDr=i(pi),rc=n(pi,"P",{});var Zfe=s(rc);UDr=r(Zfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),Ate=n(Zfe,"A",{href:!0});var Qpa=s(Ate);HDr=r(Qpa,"from_pretrained()"),Qpa.forEach(t),JDr=r(Zfe," class method or the "),Lte=n(Zfe,"A",{href:!0});var Wpa=s(Lte);YDr=r(Wpa,"from_config()"),Wpa.forEach(t),ZDr=r(Zfe,` class
method.`),Zfe.forEach(t),KDr=i(pi),HR=n(pi,"P",{});var zmo=s(HR);ejr=r(zmo,"This class cannot be instantiated directly using "),j8e=n(zmo,"CODE",{});var Upa=s(j8e);ojr=r(Upa,"__init__()"),Upa.forEach(t),rjr=r(zmo," (throws an error)."),zmo.forEach(t),tjr=i(pi),Ht=n(pi,"DIV",{class:!0});var Wx=s(Ht);T(JR.$$.fragment,Wx),ajr=i(Wx),G8e=n(Wx,"P",{});var Hpa=s(G8e);njr=r(Hpa,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),Hpa.forEach(t),sjr=i(Wx),tc=n(Wx,"P",{});var Kfe=s(tc);ljr=r(Kfe,`Note:
Loading a model from its configuration file does `),O8e=n(Kfe,"STRONG",{});var Jpa=s(O8e);ijr=r(Jpa,"not"),Jpa.forEach(t),djr=r(Kfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),yte=n(Kfe,"A",{href:!0});var Ypa=s(yte);mjr=r(Ypa,"from_pretrained()"),Ypa.forEach(t),cjr=r(Kfe," to load the model weights."),Kfe.forEach(t),fjr=i(Wx),T(Q5.$$.fragment,Wx),Wx.forEach(t),gjr=i(pi),Ao=n(pi,"DIV",{class:!0});var en=s(Ao);T(YR.$$.fragment,en),hjr=i(en),V8e=n(en,"P",{});var Zpa=s(V8e);ujr=r(Zpa,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),Zpa.forEach(t),pjr=i(en),Pn=n(en,"P",{});var Ux=s(Pn);_jr=r(Ux,"The model class to instantiate is selected based on the "),X8e=n(Ux,"CODE",{});var Kpa=s(X8e);bjr=r(Kpa,"model_type"),Kpa.forEach(t),vjr=r(Ux,` property of the config object (either
passed as an argument or loaded from `),z8e=n(Ux,"CODE",{});var e_a=s(z8e);Fjr=r(e_a,"pretrained_model_name_or_path"),e_a.forEach(t),Tjr=r(Ux,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q8e=n(Ux,"CODE",{});var o_a=s(Q8e);Mjr=r(o_a,"pretrained_model_name_or_path"),o_a.forEach(t),Ejr=r(Ux,":"),Ux.forEach(t),Cjr=i(en),Bn=n(en,"UL",{});var Hx=s(Bn);W5=n(Hx,"LI",{});var xeo=s(W5);W8e=n(xeo,"STRONG",{});var r_a=s(W8e);wjr=r(r_a,"deit"),r_a.forEach(t),Ajr=r(xeo," \u2014 "),xte=n(xeo,"A",{href:!0});var t_a=s(xte);Ljr=r(t_a,"DeiTForMaskedImageModeling"),t_a.forEach(t),yjr=r(xeo," (DeiT model)"),xeo.forEach(t),xjr=i(Hx),U5=n(Hx,"LI",{});var $eo=s(U5);U8e=n($eo,"STRONG",{});var a_a=s(U8e);$jr=r(a_a,"swin"),a_a.forEach(t),kjr=r($eo," \u2014 "),$te=n($eo,"A",{href:!0});var n_a=s($te);Sjr=r(n_a,"SwinForMaskedImageModeling"),n_a.forEach(t),Rjr=r($eo," (Swin Transformer model)"),$eo.forEach(t),Pjr=i(Hx),H5=n(Hx,"LI",{});var keo=s(H5);H8e=n(keo,"STRONG",{});var s_a=s(H8e);Bjr=r(s_a,"swinv2"),s_a.forEach(t),Ijr=r(keo," \u2014 "),kte=n(keo,"A",{href:!0});var l_a=s(kte);Njr=r(l_a,"Swinv2ForMaskedImageModeling"),l_a.forEach(t),qjr=r(keo," (Swin Transformer V2 model)"),keo.forEach(t),Djr=i(Hx),J5=n(Hx,"LI",{});var Seo=s(J5);J8e=n(Seo,"STRONG",{});var i_a=s(J8e);jjr=r(i_a,"vit"),i_a.forEach(t),Gjr=r(Seo," \u2014 "),Ste=n(Seo,"A",{href:!0});var d_a=s(Ste);Ojr=r(d_a,"ViTForMaskedImageModeling"),d_a.forEach(t),Vjr=r(Seo," (ViT model)"),Seo.forEach(t),Hx.forEach(t),Xjr=i(en),Y5=n(en,"P",{});var Reo=s(Y5);zjr=r(Reo,"The model is set in evaluation mode by default using "),Y8e=n(Reo,"CODE",{});var m_a=s(Y8e);Qjr=r(m_a,"model.eval()"),m_a.forEach(t),Wjr=r(Reo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Z8e=n(Reo,"CODE",{});var c_a=s(Z8e);Ujr=r(c_a,"model.train()"),c_a.forEach(t),Reo.forEach(t),Hjr=i(en),T(Z5.$$.fragment,en),en.forEach(t),pi.forEach(t),Eio=i(c),ac=n(c,"H2",{class:!0});var Qmo=s(ac);K5=n(Qmo,"A",{id:!0,class:!0,href:!0});var f_a=s(K5);K8e=n(f_a,"SPAN",{});var g_a=s(K8e);T(ZR.$$.fragment,g_a),g_a.forEach(t),f_a.forEach(t),Jjr=i(Qmo),eLe=n(Qmo,"SPAN",{});var h_a=s(eLe);Yjr=r(h_a,"AutoModelForObjectDetection"),h_a.forEach(t),Qmo.forEach(t),Cio=i(c),dr=n(c,"DIV",{class:!0});var _i=s(dr);T(KR.$$.fragment,_i),Zjr=i(_i),nc=n(_i,"P",{});var ege=s(nc);Kjr=r(ege,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),Rte=n(ege,"A",{href:!0});var u_a=s(Rte);eGr=r(u_a,"from_pretrained()"),u_a.forEach(t),oGr=r(ege," class method or the "),Pte=n(ege,"A",{href:!0});var p_a=s(Pte);rGr=r(p_a,"from_config()"),p_a.forEach(t),tGr=r(ege,` class
method.`),ege.forEach(t),aGr=i(_i),eP=n(_i,"P",{});var Wmo=s(eP);nGr=r(Wmo,"This class cannot be instantiated directly using "),oLe=n(Wmo,"CODE",{});var __a=s(oLe);sGr=r(__a,"__init__()"),__a.forEach(t),lGr=r(Wmo," (throws an error)."),Wmo.forEach(t),iGr=i(_i),Jt=n(_i,"DIV",{class:!0});var Jx=s(Jt);T(oP.$$.fragment,Jx),dGr=i(Jx),rLe=n(Jx,"P",{});var b_a=s(rLe);mGr=r(b_a,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),b_a.forEach(t),cGr=i(Jx),sc=n(Jx,"P",{});var oge=s(sc);fGr=r(oge,`Note:
Loading a model from its configuration file does `),tLe=n(oge,"STRONG",{});var v_a=s(tLe);gGr=r(v_a,"not"),v_a.forEach(t),hGr=r(oge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Bte=n(oge,"A",{href:!0});var F_a=s(Bte);uGr=r(F_a,"from_pretrained()"),F_a.forEach(t),pGr=r(oge," to load the model weights."),oge.forEach(t),_Gr=i(Jx),T(e0.$$.fragment,Jx),Jx.forEach(t),bGr=i(_i),Lo=n(_i,"DIV",{class:!0});var on=s(Lo);T(rP.$$.fragment,on),vGr=i(on),aLe=n(on,"P",{});var T_a=s(aLe);FGr=r(T_a,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),T_a.forEach(t),TGr=i(on),In=n(on,"P",{});var Yx=s(In);MGr=r(Yx,"The model class to instantiate is selected based on the "),nLe=n(Yx,"CODE",{});var M_a=s(nLe);EGr=r(M_a,"model_type"),M_a.forEach(t),CGr=r(Yx,` property of the config object (either
passed as an argument or loaded from `),sLe=n(Yx,"CODE",{});var E_a=s(sLe);wGr=r(E_a,"pretrained_model_name_or_path"),E_a.forEach(t),AGr=r(Yx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lLe=n(Yx,"CODE",{});var C_a=s(lLe);LGr=r(C_a,"pretrained_model_name_or_path"),C_a.forEach(t),yGr=r(Yx,":"),Yx.forEach(t),xGr=i(on),Tt=n(on,"UL",{});var bi=s(Tt);o0=n(bi,"LI",{});var Peo=s(o0);iLe=n(Peo,"STRONG",{});var w_a=s(iLe);$Gr=r(w_a,"conditional_detr"),w_a.forEach(t),kGr=r(Peo," \u2014 "),Ite=n(Peo,"A",{href:!0});var A_a=s(Ite);SGr=r(A_a,"ConditionalDetrForObjectDetection"),A_a.forEach(t),RGr=r(Peo," (Conditional DETR model)"),Peo.forEach(t),PGr=i(bi),r0=n(bi,"LI",{});var Beo=s(r0);dLe=n(Beo,"STRONG",{});var L_a=s(dLe);BGr=r(L_a,"deformable_detr"),L_a.forEach(t),IGr=r(Beo," \u2014 "),Nte=n(Beo,"A",{href:!0});var y_a=s(Nte);NGr=r(y_a,"DeformableDetrForObjectDetection"),y_a.forEach(t),qGr=r(Beo," (Deformable DETR model)"),Beo.forEach(t),DGr=i(bi),t0=n(bi,"LI",{});var Ieo=s(t0);mLe=n(Ieo,"STRONG",{});var x_a=s(mLe);jGr=r(x_a,"detr"),x_a.forEach(t),GGr=r(Ieo," \u2014 "),qte=n(Ieo,"A",{href:!0});var $_a=s(qte);OGr=r($_a,"DetrForObjectDetection"),$_a.forEach(t),VGr=r(Ieo," (DETR model)"),Ieo.forEach(t),XGr=i(bi),a0=n(bi,"LI",{});var Neo=s(a0);cLe=n(Neo,"STRONG",{});var k_a=s(cLe);zGr=r(k_a,"table-transformer"),k_a.forEach(t),QGr=r(Neo," \u2014 "),Dte=n(Neo,"A",{href:!0});var S_a=s(Dte);WGr=r(S_a,"TableTransformerForObjectDetection"),S_a.forEach(t),UGr=r(Neo," (Table Transformer model)"),Neo.forEach(t),HGr=i(bi),n0=n(bi,"LI",{});var qeo=s(n0);fLe=n(qeo,"STRONG",{});var R_a=s(fLe);JGr=r(R_a,"yolos"),R_a.forEach(t),YGr=r(qeo," \u2014 "),jte=n(qeo,"A",{href:!0});var P_a=s(jte);ZGr=r(P_a,"YolosForObjectDetection"),P_a.forEach(t),KGr=r(qeo," (YOLOS model)"),qeo.forEach(t),bi.forEach(t),eOr=i(on),s0=n(on,"P",{});var Deo=s(s0);oOr=r(Deo,"The model is set in evaluation mode by default using "),gLe=n(Deo,"CODE",{});var B_a=s(gLe);rOr=r(B_a,"model.eval()"),B_a.forEach(t),tOr=r(Deo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),hLe=n(Deo,"CODE",{});var I_a=s(hLe);aOr=r(I_a,"model.train()"),I_a.forEach(t),Deo.forEach(t),nOr=i(on),T(l0.$$.fragment,on),on.forEach(t),_i.forEach(t),wio=i(c),lc=n(c,"H2",{class:!0});var Umo=s(lc);i0=n(Umo,"A",{id:!0,class:!0,href:!0});var N_a=s(i0);uLe=n(N_a,"SPAN",{});var q_a=s(uLe);T(tP.$$.fragment,q_a),q_a.forEach(t),N_a.forEach(t),sOr=i(Umo),pLe=n(Umo,"SPAN",{});var D_a=s(pLe);lOr=r(D_a,"AutoModelForImageSegmentation"),D_a.forEach(t),Umo.forEach(t),Aio=i(c),mr=n(c,"DIV",{class:!0});var vi=s(mr);T(aP.$$.fragment,vi),iOr=i(vi),ic=n(vi,"P",{});var rge=s(ic);dOr=r(rge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),Gte=n(rge,"A",{href:!0});var j_a=s(Gte);mOr=r(j_a,"from_pretrained()"),j_a.forEach(t),cOr=r(rge," class method or the "),Ote=n(rge,"A",{href:!0});var G_a=s(Ote);fOr=r(G_a,"from_config()"),G_a.forEach(t),gOr=r(rge,` class
method.`),rge.forEach(t),hOr=i(vi),nP=n(vi,"P",{});var Hmo=s(nP);uOr=r(Hmo,"This class cannot be instantiated directly using "),_Le=n(Hmo,"CODE",{});var O_a=s(_Le);pOr=r(O_a,"__init__()"),O_a.forEach(t),_Or=r(Hmo," (throws an error)."),Hmo.forEach(t),bOr=i(vi),Yt=n(vi,"DIV",{class:!0});var Zx=s(Yt);T(sP.$$.fragment,Zx),vOr=i(Zx),bLe=n(Zx,"P",{});var V_a=s(bLe);FOr=r(V_a,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),V_a.forEach(t),TOr=i(Zx),dc=n(Zx,"P",{});var tge=s(dc);MOr=r(tge,`Note:
Loading a model from its configuration file does `),vLe=n(tge,"STRONG",{});var X_a=s(vLe);EOr=r(X_a,"not"),X_a.forEach(t),COr=r(tge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Vte=n(tge,"A",{href:!0});var z_a=s(Vte);wOr=r(z_a,"from_pretrained()"),z_a.forEach(t),AOr=r(tge," to load the model weights."),tge.forEach(t),LOr=i(Zx),T(d0.$$.fragment,Zx),Zx.forEach(t),yOr=i(vi),yo=n(vi,"DIV",{class:!0});var rn=s(yo);T(lP.$$.fragment,rn),xOr=i(rn),FLe=n(rn,"P",{});var Q_a=s(FLe);$Or=r(Q_a,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),Q_a.forEach(t),kOr=i(rn),Nn=n(rn,"P",{});var Kx=s(Nn);SOr=r(Kx,"The model class to instantiate is selected based on the "),TLe=n(Kx,"CODE",{});var W_a=s(TLe);ROr=r(W_a,"model_type"),W_a.forEach(t),POr=r(Kx,` property of the config object (either
passed as an argument or loaded from `),MLe=n(Kx,"CODE",{});var U_a=s(MLe);BOr=r(U_a,"pretrained_model_name_or_path"),U_a.forEach(t),IOr=r(Kx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ELe=n(Kx,"CODE",{});var H_a=s(ELe);NOr=r(H_a,"pretrained_model_name_or_path"),H_a.forEach(t),qOr=r(Kx,":"),Kx.forEach(t),DOr=i(rn),CLe=n(rn,"UL",{});var J_a=s(CLe);m0=n(J_a,"LI",{});var jeo=s(m0);wLe=n(jeo,"STRONG",{});var Y_a=s(wLe);jOr=r(Y_a,"detr"),Y_a.forEach(t),GOr=r(jeo," \u2014 "),Xte=n(jeo,"A",{href:!0});var Z_a=s(Xte);OOr=r(Z_a,"DetrForSegmentation"),Z_a.forEach(t),VOr=r(jeo," (DETR model)"),jeo.forEach(t),J_a.forEach(t),XOr=i(rn),c0=n(rn,"P",{});var Geo=s(c0);zOr=r(Geo,"The model is set in evaluation mode by default using "),ALe=n(Geo,"CODE",{});var K_a=s(ALe);QOr=r(K_a,"model.eval()"),K_a.forEach(t),WOr=r(Geo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),LLe=n(Geo,"CODE",{});var e1a=s(LLe);UOr=r(e1a,"model.train()"),e1a.forEach(t),Geo.forEach(t),HOr=i(rn),T(f0.$$.fragment,rn),rn.forEach(t),vi.forEach(t),Lio=i(c),mc=n(c,"H2",{class:!0});var Jmo=s(mc);g0=n(Jmo,"A",{id:!0,class:!0,href:!0});var o1a=s(g0);yLe=n(o1a,"SPAN",{});var r1a=s(yLe);T(iP.$$.fragment,r1a),r1a.forEach(t),o1a.forEach(t),JOr=i(Jmo),xLe=n(Jmo,"SPAN",{});var t1a=s(xLe);YOr=r(t1a,"AutoModelForSemanticSegmentation"),t1a.forEach(t),Jmo.forEach(t),yio=i(c),cr=n(c,"DIV",{class:!0});var Fi=s(cr);T(dP.$$.fragment,Fi),ZOr=i(Fi),cc=n(Fi,"P",{});var age=s(cc);KOr=r(age,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),zte=n(age,"A",{href:!0});var a1a=s(zte);eVr=r(a1a,"from_pretrained()"),a1a.forEach(t),oVr=r(age," class method or the "),Qte=n(age,"A",{href:!0});var n1a=s(Qte);rVr=r(n1a,"from_config()"),n1a.forEach(t),tVr=r(age,` class
method.`),age.forEach(t),aVr=i(Fi),mP=n(Fi,"P",{});var Ymo=s(mP);nVr=r(Ymo,"This class cannot be instantiated directly using "),$Le=n(Ymo,"CODE",{});var s1a=s($Le);sVr=r(s1a,"__init__()"),s1a.forEach(t),lVr=r(Ymo," (throws an error)."),Ymo.forEach(t),iVr=i(Fi),Zt=n(Fi,"DIV",{class:!0});var e$=s(Zt);T(cP.$$.fragment,e$),dVr=i(e$),kLe=n(e$,"P",{});var l1a=s(kLe);mVr=r(l1a,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),l1a.forEach(t),cVr=i(e$),fc=n(e$,"P",{});var nge=s(fc);fVr=r(nge,`Note:
Loading a model from its configuration file does `),SLe=n(nge,"STRONG",{});var i1a=s(SLe);gVr=r(i1a,"not"),i1a.forEach(t),hVr=r(nge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Wte=n(nge,"A",{href:!0});var d1a=s(Wte);uVr=r(d1a,"from_pretrained()"),d1a.forEach(t),pVr=r(nge," to load the model weights."),nge.forEach(t),_Vr=i(e$),T(h0.$$.fragment,e$),e$.forEach(t),bVr=i(Fi),xo=n(Fi,"DIV",{class:!0});var tn=s(xo);T(fP.$$.fragment,tn),vVr=i(tn),RLe=n(tn,"P",{});var m1a=s(RLe);FVr=r(m1a,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),m1a.forEach(t),TVr=i(tn),qn=n(tn,"P",{});var o$=s(qn);MVr=r(o$,"The model class to instantiate is selected based on the "),PLe=n(o$,"CODE",{});var c1a=s(PLe);EVr=r(c1a,"model_type"),c1a.forEach(t),CVr=r(o$,` property of the config object (either
passed as an argument or loaded from `),BLe=n(o$,"CODE",{});var f1a=s(BLe);wVr=r(f1a,"pretrained_model_name_or_path"),f1a.forEach(t),AVr=r(o$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ILe=n(o$,"CODE",{});var g1a=s(ILe);LVr=r(g1a,"pretrained_model_name_or_path"),g1a.forEach(t),yVr=r(o$,":"),o$.forEach(t),xVr=i(tn),Mt=n(tn,"UL",{});var Ti=s(Mt);u0=n(Ti,"LI",{});var Oeo=s(u0);NLe=n(Oeo,"STRONG",{});var h1a=s(NLe);$Vr=r(h1a,"beit"),h1a.forEach(t),kVr=r(Oeo," \u2014 "),Ute=n(Oeo,"A",{href:!0});var u1a=s(Ute);SVr=r(u1a,"BeitForSemanticSegmentation"),u1a.forEach(t),RVr=r(Oeo," (BEiT model)"),Oeo.forEach(t),PVr=i(Ti),p0=n(Ti,"LI",{});var Veo=s(p0);qLe=n(Veo,"STRONG",{});var p1a=s(qLe);BVr=r(p1a,"data2vec-vision"),p1a.forEach(t),IVr=r(Veo," \u2014 "),Hte=n(Veo,"A",{href:!0});var _1a=s(Hte);NVr=r(_1a,"Data2VecVisionForSemanticSegmentation"),_1a.forEach(t),qVr=r(Veo," (Data2VecVision model)"),Veo.forEach(t),DVr=i(Ti),_0=n(Ti,"LI",{});var Xeo=s(_0);DLe=n(Xeo,"STRONG",{});var b1a=s(DLe);jVr=r(b1a,"dpt"),b1a.forEach(t),GVr=r(Xeo," \u2014 "),Jte=n(Xeo,"A",{href:!0});var v1a=s(Jte);OVr=r(v1a,"DPTForSemanticSegmentation"),v1a.forEach(t),VVr=r(Xeo," (DPT model)"),Xeo.forEach(t),XVr=i(Ti),b0=n(Ti,"LI",{});var zeo=s(b0);jLe=n(zeo,"STRONG",{});var F1a=s(jLe);zVr=r(F1a,"mobilevit"),F1a.forEach(t),QVr=r(zeo," \u2014 "),Yte=n(zeo,"A",{href:!0});var T1a=s(Yte);WVr=r(T1a,"MobileViTForSemanticSegmentation"),T1a.forEach(t),UVr=r(zeo," (MobileViT model)"),zeo.forEach(t),HVr=i(Ti),v0=n(Ti,"LI",{});var Qeo=s(v0);GLe=n(Qeo,"STRONG",{});var M1a=s(GLe);JVr=r(M1a,"segformer"),M1a.forEach(t),YVr=r(Qeo," \u2014 "),Zte=n(Qeo,"A",{href:!0});var E1a=s(Zte);ZVr=r(E1a,"SegformerForSemanticSegmentation"),E1a.forEach(t),KVr=r(Qeo," (SegFormer model)"),Qeo.forEach(t),Ti.forEach(t),eXr=i(tn),F0=n(tn,"P",{});var Weo=s(F0);oXr=r(Weo,"The model is set in evaluation mode by default using "),OLe=n(Weo,"CODE",{});var C1a=s(OLe);rXr=r(C1a,"model.eval()"),C1a.forEach(t),tXr=r(Weo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),VLe=n(Weo,"CODE",{});var w1a=s(VLe);aXr=r(w1a,"model.train()"),w1a.forEach(t),Weo.forEach(t),nXr=i(tn),T(T0.$$.fragment,tn),tn.forEach(t),Fi.forEach(t),xio=i(c),gc=n(c,"H2",{class:!0});var Zmo=s(gc);M0=n(Zmo,"A",{id:!0,class:!0,href:!0});var A1a=s(M0);XLe=n(A1a,"SPAN",{});var L1a=s(XLe);T(gP.$$.fragment,L1a),L1a.forEach(t),A1a.forEach(t),sXr=i(Zmo),zLe=n(Zmo,"SPAN",{});var y1a=s(zLe);lXr=r(y1a,"AutoModelForInstanceSegmentation"),y1a.forEach(t),Zmo.forEach(t),$io=i(c),fr=n(c,"DIV",{class:!0});var Mi=s(fr);T(hP.$$.fragment,Mi),iXr=i(Mi),hc=n(Mi,"P",{});var sge=s(hc);dXr=r(sge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),Kte=n(sge,"A",{href:!0});var x1a=s(Kte);mXr=r(x1a,"from_pretrained()"),x1a.forEach(t),cXr=r(sge," class method or the "),eae=n(sge,"A",{href:!0});var $1a=s(eae);fXr=r($1a,"from_config()"),$1a.forEach(t),gXr=r(sge,` class
method.`),sge.forEach(t),hXr=i(Mi),uP=n(Mi,"P",{});var Kmo=s(uP);uXr=r(Kmo,"This class cannot be instantiated directly using "),QLe=n(Kmo,"CODE",{});var k1a=s(QLe);pXr=r(k1a,"__init__()"),k1a.forEach(t),_Xr=r(Kmo," (throws an error)."),Kmo.forEach(t),bXr=i(Mi),Kt=n(Mi,"DIV",{class:!0});var r$=s(Kt);T(pP.$$.fragment,r$),vXr=i(r$),WLe=n(r$,"P",{});var S1a=s(WLe);FXr=r(S1a,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),S1a.forEach(t),TXr=i(r$),uc=n(r$,"P",{});var lge=s(uc);MXr=r(lge,`Note:
Loading a model from its configuration file does `),ULe=n(lge,"STRONG",{});var R1a=s(ULe);EXr=r(R1a,"not"),R1a.forEach(t),CXr=r(lge,` load the model weights. It only affects the
model\u2019s configuration. Use `),oae=n(lge,"A",{href:!0});var P1a=s(oae);wXr=r(P1a,"from_pretrained()"),P1a.forEach(t),AXr=r(lge," to load the model weights."),lge.forEach(t),LXr=i(r$),T(E0.$$.fragment,r$),r$.forEach(t),yXr=i(Mi),$o=n(Mi,"DIV",{class:!0});var an=s($o);T(_P.$$.fragment,an),xXr=i(an),HLe=n(an,"P",{});var B1a=s(HLe);$Xr=r(B1a,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),B1a.forEach(t),kXr=i(an),Dn=n(an,"P",{});var t$=s(Dn);SXr=r(t$,"The model class to instantiate is selected based on the "),JLe=n(t$,"CODE",{});var I1a=s(JLe);RXr=r(I1a,"model_type"),I1a.forEach(t),PXr=r(t$,` property of the config object (either
passed as an argument or loaded from `),YLe=n(t$,"CODE",{});var N1a=s(YLe);BXr=r(N1a,"pretrained_model_name_or_path"),N1a.forEach(t),IXr=r(t$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ZLe=n(t$,"CODE",{});var q1a=s(ZLe);NXr=r(q1a,"pretrained_model_name_or_path"),q1a.forEach(t),qXr=r(t$,":"),t$.forEach(t),DXr=i(an),KLe=n(an,"UL",{});var D1a=s(KLe);C0=n(D1a,"LI",{});var Ueo=s(C0);eye=n(Ueo,"STRONG",{});var j1a=s(eye);jXr=r(j1a,"maskformer"),j1a.forEach(t),GXr=r(Ueo," \u2014 "),rae=n(Ueo,"A",{href:!0});var G1a=s(rae);OXr=r(G1a,"MaskFormerForInstanceSegmentation"),G1a.forEach(t),VXr=r(Ueo," (MaskFormer model)"),Ueo.forEach(t),D1a.forEach(t),XXr=i(an),w0=n(an,"P",{});var Heo=s(w0);zXr=r(Heo,"The model is set in evaluation mode by default using "),oye=n(Heo,"CODE",{});var O1a=s(oye);QXr=r(O1a,"model.eval()"),O1a.forEach(t),WXr=r(Heo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),rye=n(Heo,"CODE",{});var V1a=s(rye);UXr=r(V1a,"model.train()"),V1a.forEach(t),Heo.forEach(t),HXr=i(an),T(A0.$$.fragment,an),an.forEach(t),Mi.forEach(t),kio=i(c),pc=n(c,"H2",{class:!0});var eco=s(pc);L0=n(eco,"A",{id:!0,class:!0,href:!0});var X1a=s(L0);tye=n(X1a,"SPAN",{});var z1a=s(tye);T(bP.$$.fragment,z1a),z1a.forEach(t),X1a.forEach(t),JXr=i(eco),aye=n(eco,"SPAN",{});var Q1a=s(aye);YXr=r(Q1a,"AutoModelForZeroShotObjectDetection"),Q1a.forEach(t),eco.forEach(t),Sio=i(c),gr=n(c,"DIV",{class:!0});var Ei=s(gr);T(vP.$$.fragment,Ei),ZXr=i(Ei),_c=n(Ei,"P",{});var ige=s(_c);KXr=r(ige,`This is a generic model class that will be instantiated as one of the model classes of the library (with a zero-shot object detection head) when created
with the `),tae=n(ige,"A",{href:!0});var W1a=s(tae);ezr=r(W1a,"from_pretrained()"),W1a.forEach(t),ozr=r(ige," class method or the "),aae=n(ige,"A",{href:!0});var U1a=s(aae);rzr=r(U1a,"from_config()"),U1a.forEach(t),tzr=r(ige,` class
method.`),ige.forEach(t),azr=i(Ei),FP=n(Ei,"P",{});var oco=s(FP);nzr=r(oco,"This class cannot be instantiated directly using "),nye=n(oco,"CODE",{});var H1a=s(nye);szr=r(H1a,"__init__()"),H1a.forEach(t),lzr=r(oco," (throws an error)."),oco.forEach(t),izr=i(Ei),ea=n(Ei,"DIV",{class:!0});var a$=s(ea);T(TP.$$.fragment,a$),dzr=i(a$),sye=n(a$,"P",{});var J1a=s(sye);mzr=r(J1a,"Instantiates one of the model classes of the library (with a zero-shot object detection head) from a configuration."),J1a.forEach(t),czr=i(a$),bc=n(a$,"P",{});var dge=s(bc);fzr=r(dge,`Note:
Loading a model from its configuration file does `),lye=n(dge,"STRONG",{});var Y1a=s(lye);gzr=r(Y1a,"not"),Y1a.forEach(t),hzr=r(dge,` load the model weights. It only affects the
model\u2019s configuration. Use `),nae=n(dge,"A",{href:!0});var Z1a=s(nae);uzr=r(Z1a,"from_pretrained()"),Z1a.forEach(t),pzr=r(dge," to load the model weights."),dge.forEach(t),_zr=i(a$),T(y0.$$.fragment,a$),a$.forEach(t),bzr=i(Ei),ko=n(Ei,"DIV",{class:!0});var nn=s(ko);T(MP.$$.fragment,nn),vzr=i(nn),iye=n(nn,"P",{});var K1a=s(iye);Fzr=r(K1a,"Instantiate one of the model classes of the library (with a zero-shot object detection head) from a pretrained model."),K1a.forEach(t),Tzr=i(nn),jn=n(nn,"P",{});var n$=s(jn);Mzr=r(n$,"The model class to instantiate is selected based on the "),dye=n(n$,"CODE",{});var e2a=s(dye);Ezr=r(e2a,"model_type"),e2a.forEach(t),Czr=r(n$,` property of the config object (either
passed as an argument or loaded from `),mye=n(n$,"CODE",{});var o2a=s(mye);wzr=r(o2a,"pretrained_model_name_or_path"),o2a.forEach(t),Azr=r(n$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cye=n(n$,"CODE",{});var r2a=s(cye);Lzr=r(r2a,"pretrained_model_name_or_path"),r2a.forEach(t),yzr=r(n$,":"),n$.forEach(t),xzr=i(nn),fye=n(nn,"UL",{});var t2a=s(fye);x0=n(t2a,"LI",{});var Jeo=s(x0);gye=n(Jeo,"STRONG",{});var a2a=s(gye);$zr=r(a2a,"owlvit"),a2a.forEach(t),kzr=r(Jeo," \u2014 "),sae=n(Jeo,"A",{href:!0});var n2a=s(sae);Szr=r(n2a,"OwlViTForObjectDetection"),n2a.forEach(t),Rzr=r(Jeo," (OWL-ViT model)"),Jeo.forEach(t),t2a.forEach(t),Pzr=i(nn),$0=n(nn,"P",{});var Yeo=s($0);Bzr=r(Yeo,"The model is set in evaluation mode by default using "),hye=n(Yeo,"CODE",{});var s2a=s(hye);Izr=r(s2a,"model.eval()"),s2a.forEach(t),Nzr=r(Yeo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),uye=n(Yeo,"CODE",{});var l2a=s(uye);qzr=r(l2a,"model.train()"),l2a.forEach(t),Yeo.forEach(t),Dzr=i(nn),T(k0.$$.fragment,nn),nn.forEach(t),Ei.forEach(t),Rio=i(c),vc=n(c,"H2",{class:!0});var rco=s(vc);S0=n(rco,"A",{id:!0,class:!0,href:!0});var i2a=s(S0);pye=n(i2a,"SPAN",{});var d2a=s(pye);T(EP.$$.fragment,d2a),d2a.forEach(t),i2a.forEach(t),jzr=i(rco),_ye=n(rco,"SPAN",{});var m2a=s(_ye);Gzr=r(m2a,"TFAutoModel"),m2a.forEach(t),rco.forEach(t),Pio=i(c),hr=n(c,"DIV",{class:!0});var Ci=s(hr);T(CP.$$.fragment,Ci),Ozr=i(Ci),Fc=n(Ci,"P",{});var mge=s(Fc);Vzr=r(mge,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),lae=n(mge,"A",{href:!0});var c2a=s(lae);Xzr=r(c2a,"from_pretrained()"),c2a.forEach(t),zzr=r(mge," class method or the "),iae=n(mge,"A",{href:!0});var f2a=s(iae);Qzr=r(f2a,"from_config()"),f2a.forEach(t),Wzr=r(mge,` class
method.`),mge.forEach(t),Uzr=i(Ci),wP=n(Ci,"P",{});var tco=s(wP);Hzr=r(tco,"This class cannot be instantiated directly using "),bye=n(tco,"CODE",{});var g2a=s(bye);Jzr=r(g2a,"__init__()"),g2a.forEach(t),Yzr=r(tco," (throws an error)."),tco.forEach(t),Zzr=i(Ci),oa=n(Ci,"DIV",{class:!0});var s$=s(oa);T(AP.$$.fragment,s$),Kzr=i(s$),vye=n(s$,"P",{});var h2a=s(vye);eQr=r(h2a,"Instantiates one of the base model classes of the library from a configuration."),h2a.forEach(t),oQr=i(s$),Tc=n(s$,"P",{});var cge=s(Tc);rQr=r(cge,`Note:
Loading a model from its configuration file does `),Fye=n(cge,"STRONG",{});var u2a=s(Fye);tQr=r(u2a,"not"),u2a.forEach(t),aQr=r(cge,` load the model weights. It only affects the
model\u2019s configuration. Use `),dae=n(cge,"A",{href:!0});var p2a=s(dae);nQr=r(p2a,"from_pretrained()"),p2a.forEach(t),sQr=r(cge," to load the model weights."),cge.forEach(t),lQr=i(s$),T(R0.$$.fragment,s$),s$.forEach(t),iQr=i(Ci),Xr=n(Ci,"DIV",{class:!0});var wi=s(Xr);T(LP.$$.fragment,wi),dQr=i(wi),Tye=n(wi,"P",{});var _2a=s(Tye);mQr=r(_2a,"Instantiate one of the base model classes of the library from a pretrained model."),_2a.forEach(t),cQr=i(wi),Gn=n(wi,"P",{});var l$=s(Gn);fQr=r(l$,"The model class to instantiate is selected based on the "),Mye=n(l$,"CODE",{});var b2a=s(Mye);gQr=r(b2a,"model_type"),b2a.forEach(t),hQr=r(l$,` property of the config object (either
passed as an argument or loaded from `),Eye=n(l$,"CODE",{});var v2a=s(Eye);uQr=r(v2a,"pretrained_model_name_or_path"),v2a.forEach(t),pQr=r(l$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Cye=n(l$,"CODE",{});var F2a=s(Cye);_Qr=r(F2a,"pretrained_model_name_or_path"),F2a.forEach(t),bQr=r(l$,":"),l$.forEach(t),vQr=i(wi),P=n(wi,"UL",{});var D=s(P);P0=n(D,"LI",{});var Zeo=s(P0);wye=n(Zeo,"STRONG",{});var T2a=s(wye);FQr=r(T2a,"albert"),T2a.forEach(t),TQr=r(Zeo," \u2014 "),mae=n(Zeo,"A",{href:!0});var M2a=s(mae);MQr=r(M2a,"TFAlbertModel"),M2a.forEach(t),EQr=r(Zeo," (ALBERT model)"),Zeo.forEach(t),CQr=i(D),B0=n(D,"LI",{});var Keo=s(B0);Aye=n(Keo,"STRONG",{});var E2a=s(Aye);wQr=r(E2a,"bart"),E2a.forEach(t),AQr=r(Keo," \u2014 "),cae=n(Keo,"A",{href:!0});var C2a=s(cae);LQr=r(C2a,"TFBartModel"),C2a.forEach(t),yQr=r(Keo," (BART model)"),Keo.forEach(t),xQr=i(D),I0=n(D,"LI",{});var eoo=s(I0);Lye=n(eoo,"STRONG",{});var w2a=s(Lye);$Qr=r(w2a,"bert"),w2a.forEach(t),kQr=r(eoo," \u2014 "),fae=n(eoo,"A",{href:!0});var A2a=s(fae);SQr=r(A2a,"TFBertModel"),A2a.forEach(t),RQr=r(eoo," (BERT model)"),eoo.forEach(t),PQr=i(D),N0=n(D,"LI",{});var ooo=s(N0);yye=n(ooo,"STRONG",{});var L2a=s(yye);BQr=r(L2a,"blenderbot"),L2a.forEach(t),IQr=r(ooo," \u2014 "),gae=n(ooo,"A",{href:!0});var y2a=s(gae);NQr=r(y2a,"TFBlenderbotModel"),y2a.forEach(t),qQr=r(ooo," (Blenderbot model)"),ooo.forEach(t),DQr=i(D),q0=n(D,"LI",{});var roo=s(q0);xye=n(roo,"STRONG",{});var x2a=s(xye);jQr=r(x2a,"blenderbot-small"),x2a.forEach(t),GQr=r(roo," \u2014 "),hae=n(roo,"A",{href:!0});var $2a=s(hae);OQr=r($2a,"TFBlenderbotSmallModel"),$2a.forEach(t),VQr=r(roo," (BlenderbotSmall model)"),roo.forEach(t),XQr=i(D),D0=n(D,"LI",{});var too=s(D0);$ye=n(too,"STRONG",{});var k2a=s($ye);zQr=r(k2a,"camembert"),k2a.forEach(t),QQr=r(too," \u2014 "),uae=n(too,"A",{href:!0});var S2a=s(uae);WQr=r(S2a,"TFCamembertModel"),S2a.forEach(t),UQr=r(too," (CamemBERT model)"),too.forEach(t),HQr=i(D),j0=n(D,"LI",{});var aoo=s(j0);kye=n(aoo,"STRONG",{});var R2a=s(kye);JQr=r(R2a,"clip"),R2a.forEach(t),YQr=r(aoo," \u2014 "),pae=n(aoo,"A",{href:!0});var P2a=s(pae);ZQr=r(P2a,"TFCLIPModel"),P2a.forEach(t),KQr=r(aoo," (CLIP model)"),aoo.forEach(t),eWr=i(D),G0=n(D,"LI",{});var noo=s(G0);Sye=n(noo,"STRONG",{});var B2a=s(Sye);oWr=r(B2a,"convbert"),B2a.forEach(t),rWr=r(noo," \u2014 "),_ae=n(noo,"A",{href:!0});var I2a=s(_ae);tWr=r(I2a,"TFConvBertModel"),I2a.forEach(t),aWr=r(noo," (ConvBERT model)"),noo.forEach(t),nWr=i(D),O0=n(D,"LI",{});var soo=s(O0);Rye=n(soo,"STRONG",{});var N2a=s(Rye);sWr=r(N2a,"convnext"),N2a.forEach(t),lWr=r(soo," \u2014 "),bae=n(soo,"A",{href:!0});var q2a=s(bae);iWr=r(q2a,"TFConvNextModel"),q2a.forEach(t),dWr=r(soo," (ConvNeXT model)"),soo.forEach(t),mWr=i(D),V0=n(D,"LI",{});var loo=s(V0);Pye=n(loo,"STRONG",{});var D2a=s(Pye);cWr=r(D2a,"ctrl"),D2a.forEach(t),fWr=r(loo," \u2014 "),vae=n(loo,"A",{href:!0});var j2a=s(vae);gWr=r(j2a,"TFCTRLModel"),j2a.forEach(t),hWr=r(loo," (CTRL model)"),loo.forEach(t),uWr=i(D),X0=n(D,"LI",{});var ioo=s(X0);Bye=n(ioo,"STRONG",{});var G2a=s(Bye);pWr=r(G2a,"cvt"),G2a.forEach(t),_Wr=r(ioo," \u2014 "),Fae=n(ioo,"A",{href:!0});var O2a=s(Fae);bWr=r(O2a,"TFCvtModel"),O2a.forEach(t),vWr=r(ioo," (CvT model)"),ioo.forEach(t),FWr=i(D),z0=n(D,"LI",{});var doo=s(z0);Iye=n(doo,"STRONG",{});var V2a=s(Iye);TWr=r(V2a,"data2vec-vision"),V2a.forEach(t),MWr=r(doo," \u2014 "),Tae=n(doo,"A",{href:!0});var X2a=s(Tae);EWr=r(X2a,"TFData2VecVisionModel"),X2a.forEach(t),CWr=r(doo," (Data2VecVision model)"),doo.forEach(t),wWr=i(D),Q0=n(D,"LI",{});var moo=s(Q0);Nye=n(moo,"STRONG",{});var z2a=s(Nye);AWr=r(z2a,"deberta"),z2a.forEach(t),LWr=r(moo," \u2014 "),Mae=n(moo,"A",{href:!0});var Q2a=s(Mae);yWr=r(Q2a,"TFDebertaModel"),Q2a.forEach(t),xWr=r(moo," (DeBERTa model)"),moo.forEach(t),$Wr=i(D),W0=n(D,"LI",{});var coo=s(W0);qye=n(coo,"STRONG",{});var W2a=s(qye);kWr=r(W2a,"deberta-v2"),W2a.forEach(t),SWr=r(coo," \u2014 "),Eae=n(coo,"A",{href:!0});var U2a=s(Eae);RWr=r(U2a,"TFDebertaV2Model"),U2a.forEach(t),PWr=r(coo," (DeBERTa-v2 model)"),coo.forEach(t),BWr=i(D),U0=n(D,"LI",{});var foo=s(U0);Dye=n(foo,"STRONG",{});var H2a=s(Dye);IWr=r(H2a,"deit"),H2a.forEach(t),NWr=r(foo," \u2014 "),Cae=n(foo,"A",{href:!0});var J2a=s(Cae);qWr=r(J2a,"TFDeiTModel"),J2a.forEach(t),DWr=r(foo," (DeiT model)"),foo.forEach(t),jWr=i(D),H0=n(D,"LI",{});var goo=s(H0);jye=n(goo,"STRONG",{});var Y2a=s(jye);GWr=r(Y2a,"distilbert"),Y2a.forEach(t),OWr=r(goo," \u2014 "),wae=n(goo,"A",{href:!0});var Z2a=s(wae);VWr=r(Z2a,"TFDistilBertModel"),Z2a.forEach(t),XWr=r(goo," (DistilBERT model)"),goo.forEach(t),zWr=i(D),J0=n(D,"LI",{});var hoo=s(J0);Gye=n(hoo,"STRONG",{});var K2a=s(Gye);QWr=r(K2a,"dpr"),K2a.forEach(t),WWr=r(hoo," \u2014 "),Aae=n(hoo,"A",{href:!0});var eba=s(Aae);UWr=r(eba,"TFDPRQuestionEncoder"),eba.forEach(t),HWr=r(hoo," (DPR model)"),hoo.forEach(t),JWr=i(D),Y0=n(D,"LI",{});var uoo=s(Y0);Oye=n(uoo,"STRONG",{});var oba=s(Oye);YWr=r(oba,"electra"),oba.forEach(t),ZWr=r(uoo," \u2014 "),Lae=n(uoo,"A",{href:!0});var rba=s(Lae);KWr=r(rba,"TFElectraModel"),rba.forEach(t),eUr=r(uoo," (ELECTRA model)"),uoo.forEach(t),oUr=i(D),Z0=n(D,"LI",{});var poo=s(Z0);Vye=n(poo,"STRONG",{});var tba=s(Vye);rUr=r(tba,"esm"),tba.forEach(t),tUr=r(poo," \u2014 "),yae=n(poo,"A",{href:!0});var aba=s(yae);aUr=r(aba,"TFEsmModel"),aba.forEach(t),nUr=r(poo," (ESM model)"),poo.forEach(t),sUr=i(D),K0=n(D,"LI",{});var _oo=s(K0);Xye=n(_oo,"STRONG",{});var nba=s(Xye);lUr=r(nba,"flaubert"),nba.forEach(t),iUr=r(_oo," \u2014 "),xae=n(_oo,"A",{href:!0});var sba=s(xae);dUr=r(sba,"TFFlaubertModel"),sba.forEach(t),mUr=r(_oo," (FlauBERT model)"),_oo.forEach(t),cUr=i(D),Dl=n(D,"LI",{});var $q=s(Dl);zye=n($q,"STRONG",{});var lba=s(zye);fUr=r(lba,"funnel"),lba.forEach(t),gUr=r($q," \u2014 "),$ae=n($q,"A",{href:!0});var iba=s($ae);hUr=r(iba,"TFFunnelModel"),iba.forEach(t),uUr=r($q," or "),kae=n($q,"A",{href:!0});var dba=s(kae);pUr=r(dba,"TFFunnelBaseModel"),dba.forEach(t),_Ur=r($q," (Funnel Transformer model)"),$q.forEach(t),bUr=i(D),ew=n(D,"LI",{});var boo=s(ew);Qye=n(boo,"STRONG",{});var mba=s(Qye);vUr=r(mba,"gpt2"),mba.forEach(t),FUr=r(boo," \u2014 "),Sae=n(boo,"A",{href:!0});var cba=s(Sae);TUr=r(cba,"TFGPT2Model"),cba.forEach(t),MUr=r(boo," (OpenAI GPT-2 model)"),boo.forEach(t),EUr=i(D),ow=n(D,"LI",{});var voo=s(ow);Wye=n(voo,"STRONG",{});var fba=s(Wye);CUr=r(fba,"gptj"),fba.forEach(t),wUr=r(voo," \u2014 "),Rae=n(voo,"A",{href:!0});var gba=s(Rae);AUr=r(gba,"TFGPTJModel"),gba.forEach(t),LUr=r(voo," (GPT-J model)"),voo.forEach(t),yUr=i(D),rw=n(D,"LI",{});var Foo=s(rw);Uye=n(Foo,"STRONG",{});var hba=s(Uye);xUr=r(hba,"groupvit"),hba.forEach(t),$Ur=r(Foo," \u2014 "),Pae=n(Foo,"A",{href:!0});var uba=s(Pae);kUr=r(uba,"TFGroupViTModel"),uba.forEach(t),SUr=r(Foo," (GroupViT model)"),Foo.forEach(t),RUr=i(D),tw=n(D,"LI",{});var Too=s(tw);Hye=n(Too,"STRONG",{});var pba=s(Hye);PUr=r(pba,"hubert"),pba.forEach(t),BUr=r(Too," \u2014 "),Bae=n(Too,"A",{href:!0});var _ba=s(Bae);IUr=r(_ba,"TFHubertModel"),_ba.forEach(t),NUr=r(Too," (Hubert model)"),Too.forEach(t),qUr=i(D),aw=n(D,"LI",{});var Moo=s(aw);Jye=n(Moo,"STRONG",{});var bba=s(Jye);DUr=r(bba,"layoutlm"),bba.forEach(t),jUr=r(Moo," \u2014 "),Iae=n(Moo,"A",{href:!0});var vba=s(Iae);GUr=r(vba,"TFLayoutLMModel"),vba.forEach(t),OUr=r(Moo," (LayoutLM model)"),Moo.forEach(t),VUr=i(D),nw=n(D,"LI",{});var Eoo=s(nw);Yye=n(Eoo,"STRONG",{});var Fba=s(Yye);XUr=r(Fba,"layoutlmv3"),Fba.forEach(t),zUr=r(Eoo," \u2014 "),Nae=n(Eoo,"A",{href:!0});var Tba=s(Nae);QUr=r(Tba,"TFLayoutLMv3Model"),Tba.forEach(t),WUr=r(Eoo," (LayoutLMv3 model)"),Eoo.forEach(t),UUr=i(D),sw=n(D,"LI",{});var Coo=s(sw);Zye=n(Coo,"STRONG",{});var Mba=s(Zye);HUr=r(Mba,"led"),Mba.forEach(t),JUr=r(Coo," \u2014 "),qae=n(Coo,"A",{href:!0});var Eba=s(qae);YUr=r(Eba,"TFLEDModel"),Eba.forEach(t),ZUr=r(Coo," (LED model)"),Coo.forEach(t),KUr=i(D),lw=n(D,"LI",{});var woo=s(lw);Kye=n(woo,"STRONG",{});var Cba=s(Kye);eHr=r(Cba,"longformer"),Cba.forEach(t),oHr=r(woo," \u2014 "),Dae=n(woo,"A",{href:!0});var wba=s(Dae);rHr=r(wba,"TFLongformerModel"),wba.forEach(t),tHr=r(woo," (Longformer model)"),woo.forEach(t),aHr=i(D),iw=n(D,"LI",{});var Aoo=s(iw);e9e=n(Aoo,"STRONG",{});var Aba=s(e9e);nHr=r(Aba,"lxmert"),Aba.forEach(t),sHr=r(Aoo," \u2014 "),jae=n(Aoo,"A",{href:!0});var Lba=s(jae);lHr=r(Lba,"TFLxmertModel"),Lba.forEach(t),iHr=r(Aoo," (LXMERT model)"),Aoo.forEach(t),dHr=i(D),dw=n(D,"LI",{});var Loo=s(dw);o9e=n(Loo,"STRONG",{});var yba=s(o9e);mHr=r(yba,"marian"),yba.forEach(t),cHr=r(Loo," \u2014 "),Gae=n(Loo,"A",{href:!0});var xba=s(Gae);fHr=r(xba,"TFMarianModel"),xba.forEach(t),gHr=r(Loo," (Marian model)"),Loo.forEach(t),hHr=i(D),mw=n(D,"LI",{});var yoo=s(mw);r9e=n(yoo,"STRONG",{});var $ba=s(r9e);uHr=r($ba,"mbart"),$ba.forEach(t),pHr=r(yoo," \u2014 "),Oae=n(yoo,"A",{href:!0});var kba=s(Oae);_Hr=r(kba,"TFMBartModel"),kba.forEach(t),bHr=r(yoo," (mBART model)"),yoo.forEach(t),vHr=i(D),cw=n(D,"LI",{});var xoo=s(cw);t9e=n(xoo,"STRONG",{});var Sba=s(t9e);FHr=r(Sba,"mobilebert"),Sba.forEach(t),THr=r(xoo," \u2014 "),Vae=n(xoo,"A",{href:!0});var Rba=s(Vae);MHr=r(Rba,"TFMobileBertModel"),Rba.forEach(t),EHr=r(xoo," (MobileBERT model)"),xoo.forEach(t),CHr=i(D),fw=n(D,"LI",{});var $oo=s(fw);a9e=n($oo,"STRONG",{});var Pba=s(a9e);wHr=r(Pba,"mobilevit"),Pba.forEach(t),AHr=r($oo," \u2014 "),Xae=n($oo,"A",{href:!0});var Bba=s(Xae);LHr=r(Bba,"TFMobileViTModel"),Bba.forEach(t),yHr=r($oo," (MobileViT model)"),$oo.forEach(t),xHr=i(D),gw=n(D,"LI",{});var koo=s(gw);n9e=n(koo,"STRONG",{});var Iba=s(n9e);$Hr=r(Iba,"mpnet"),Iba.forEach(t),kHr=r(koo," \u2014 "),zae=n(koo,"A",{href:!0});var Nba=s(zae);SHr=r(Nba,"TFMPNetModel"),Nba.forEach(t),RHr=r(koo," (MPNet model)"),koo.forEach(t),PHr=i(D),hw=n(D,"LI",{});var Soo=s(hw);s9e=n(Soo,"STRONG",{});var qba=s(s9e);BHr=r(qba,"mt5"),qba.forEach(t),IHr=r(Soo," \u2014 "),Qae=n(Soo,"A",{href:!0});var Dba=s(Qae);NHr=r(Dba,"TFMT5Model"),Dba.forEach(t),qHr=r(Soo," (MT5 model)"),Soo.forEach(t),DHr=i(D),uw=n(D,"LI",{});var Roo=s(uw);l9e=n(Roo,"STRONG",{});var jba=s(l9e);jHr=r(jba,"openai-gpt"),jba.forEach(t),GHr=r(Roo," \u2014 "),Wae=n(Roo,"A",{href:!0});var Gba=s(Wae);OHr=r(Gba,"TFOpenAIGPTModel"),Gba.forEach(t),VHr=r(Roo," (OpenAI GPT model)"),Roo.forEach(t),XHr=i(D),pw=n(D,"LI",{});var Poo=s(pw);i9e=n(Poo,"STRONG",{});var Oba=s(i9e);zHr=r(Oba,"opt"),Oba.forEach(t),QHr=r(Poo," \u2014 "),Uae=n(Poo,"A",{href:!0});var Vba=s(Uae);WHr=r(Vba,"TFOPTModel"),Vba.forEach(t),UHr=r(Poo," (OPT model)"),Poo.forEach(t),HHr=i(D),_w=n(D,"LI",{});var Boo=s(_w);d9e=n(Boo,"STRONG",{});var Xba=s(d9e);JHr=r(Xba,"pegasus"),Xba.forEach(t),YHr=r(Boo," \u2014 "),Hae=n(Boo,"A",{href:!0});var zba=s(Hae);ZHr=r(zba,"TFPegasusModel"),zba.forEach(t),KHr=r(Boo," (Pegasus model)"),Boo.forEach(t),eJr=i(D),bw=n(D,"LI",{});var Ioo=s(bw);m9e=n(Ioo,"STRONG",{});var Qba=s(m9e);oJr=r(Qba,"regnet"),Qba.forEach(t),rJr=r(Ioo," \u2014 "),Jae=n(Ioo,"A",{href:!0});var Wba=s(Jae);tJr=r(Wba,"TFRegNetModel"),Wba.forEach(t),aJr=r(Ioo," (RegNet model)"),Ioo.forEach(t),nJr=i(D),vw=n(D,"LI",{});var Noo=s(vw);c9e=n(Noo,"STRONG",{});var Uba=s(c9e);sJr=r(Uba,"rembert"),Uba.forEach(t),lJr=r(Noo," \u2014 "),Yae=n(Noo,"A",{href:!0});var Hba=s(Yae);iJr=r(Hba,"TFRemBertModel"),Hba.forEach(t),dJr=r(Noo," (RemBERT model)"),Noo.forEach(t),mJr=i(D),Fw=n(D,"LI",{});var qoo=s(Fw);f9e=n(qoo,"STRONG",{});var Jba=s(f9e);cJr=r(Jba,"resnet"),Jba.forEach(t),fJr=r(qoo," \u2014 "),Zae=n(qoo,"A",{href:!0});var Yba=s(Zae);gJr=r(Yba,"TFResNetModel"),Yba.forEach(t),hJr=r(qoo," (ResNet model)"),qoo.forEach(t),uJr=i(D),Tw=n(D,"LI",{});var Doo=s(Tw);g9e=n(Doo,"STRONG",{});var Zba=s(g9e);pJr=r(Zba,"roberta"),Zba.forEach(t),_Jr=r(Doo," \u2014 "),Kae=n(Doo,"A",{href:!0});var Kba=s(Kae);bJr=r(Kba,"TFRobertaModel"),Kba.forEach(t),vJr=r(Doo," (RoBERTa model)"),Doo.forEach(t),FJr=i(D),Mw=n(D,"LI",{});var joo=s(Mw);h9e=n(joo,"STRONG",{});var eva=s(h9e);TJr=r(eva,"roformer"),eva.forEach(t),MJr=r(joo," \u2014 "),ene=n(joo,"A",{href:!0});var ova=s(ene);EJr=r(ova,"TFRoFormerModel"),ova.forEach(t),CJr=r(joo," (RoFormer model)"),joo.forEach(t),wJr=i(D),Ew=n(D,"LI",{});var Goo=s(Ew);u9e=n(Goo,"STRONG",{});var rva=s(u9e);AJr=r(rva,"segformer"),rva.forEach(t),LJr=r(Goo," \u2014 "),one=n(Goo,"A",{href:!0});var tva=s(one);yJr=r(tva,"TFSegformerModel"),tva.forEach(t),xJr=r(Goo," (SegFormer model)"),Goo.forEach(t),$Jr=i(D),Cw=n(D,"LI",{});var Ooo=s(Cw);p9e=n(Ooo,"STRONG",{});var ava=s(p9e);kJr=r(ava,"speech_to_text"),ava.forEach(t),SJr=r(Ooo," \u2014 "),rne=n(Ooo,"A",{href:!0});var nva=s(rne);RJr=r(nva,"TFSpeech2TextModel"),nva.forEach(t),PJr=r(Ooo," (Speech2Text model)"),Ooo.forEach(t),BJr=i(D),ww=n(D,"LI",{});var Voo=s(ww);_9e=n(Voo,"STRONG",{});var sva=s(_9e);IJr=r(sva,"swin"),sva.forEach(t),NJr=r(Voo," \u2014 "),tne=n(Voo,"A",{href:!0});var lva=s(tne);qJr=r(lva,"TFSwinModel"),lva.forEach(t),DJr=r(Voo," (Swin Transformer model)"),Voo.forEach(t),jJr=i(D),Aw=n(D,"LI",{});var Xoo=s(Aw);b9e=n(Xoo,"STRONG",{});var iva=s(b9e);GJr=r(iva,"t5"),iva.forEach(t),OJr=r(Xoo," \u2014 "),ane=n(Xoo,"A",{href:!0});var dva=s(ane);VJr=r(dva,"TFT5Model"),dva.forEach(t),XJr=r(Xoo," (T5 model)"),Xoo.forEach(t),zJr=i(D),Lw=n(D,"LI",{});var zoo=s(Lw);v9e=n(zoo,"STRONG",{});var mva=s(v9e);QJr=r(mva,"tapas"),mva.forEach(t),WJr=r(zoo," \u2014 "),nne=n(zoo,"A",{href:!0});var cva=s(nne);UJr=r(cva,"TFTapasModel"),cva.forEach(t),HJr=r(zoo," (TAPAS model)"),zoo.forEach(t),JJr=i(D),yw=n(D,"LI",{});var Qoo=s(yw);F9e=n(Qoo,"STRONG",{});var fva=s(F9e);YJr=r(fva,"transfo-xl"),fva.forEach(t),ZJr=r(Qoo," \u2014 "),sne=n(Qoo,"A",{href:!0});var gva=s(sne);KJr=r(gva,"TFTransfoXLModel"),gva.forEach(t),eYr=r(Qoo," (Transformer-XL model)"),Qoo.forEach(t),oYr=i(D),xw=n(D,"LI",{});var Woo=s(xw);T9e=n(Woo,"STRONG",{});var hva=s(T9e);rYr=r(hva,"vit"),hva.forEach(t),tYr=r(Woo," \u2014 "),lne=n(Woo,"A",{href:!0});var uva=s(lne);aYr=r(uva,"TFViTModel"),uva.forEach(t),nYr=r(Woo," (ViT model)"),Woo.forEach(t),sYr=i(D),$w=n(D,"LI",{});var Uoo=s($w);M9e=n(Uoo,"STRONG",{});var pva=s(M9e);lYr=r(pva,"vit_mae"),pva.forEach(t),iYr=r(Uoo," \u2014 "),ine=n(Uoo,"A",{href:!0});var _va=s(ine);dYr=r(_va,"TFViTMAEModel"),_va.forEach(t),mYr=r(Uoo," (ViTMAE model)"),Uoo.forEach(t),cYr=i(D),kw=n(D,"LI",{});var Hoo=s(kw);E9e=n(Hoo,"STRONG",{});var bva=s(E9e);fYr=r(bva,"wav2vec2"),bva.forEach(t),gYr=r(Hoo," \u2014 "),dne=n(Hoo,"A",{href:!0});var vva=s(dne);hYr=r(vva,"TFWav2Vec2Model"),vva.forEach(t),uYr=r(Hoo," (Wav2Vec2 model)"),Hoo.forEach(t),pYr=i(D),Sw=n(D,"LI",{});var Joo=s(Sw);C9e=n(Joo,"STRONG",{});var Fva=s(C9e);_Yr=r(Fva,"whisper"),Fva.forEach(t),bYr=r(Joo," \u2014 "),mne=n(Joo,"A",{href:!0});var Tva=s(mne);vYr=r(Tva,"TFWhisperModel"),Tva.forEach(t),FYr=r(Joo," (Whisper model)"),Joo.forEach(t),TYr=i(D),Rw=n(D,"LI",{});var Yoo=s(Rw);w9e=n(Yoo,"STRONG",{});var Mva=s(w9e);MYr=r(Mva,"xglm"),Mva.forEach(t),EYr=r(Yoo," \u2014 "),cne=n(Yoo,"A",{href:!0});var Eva=s(cne);CYr=r(Eva,"TFXGLMModel"),Eva.forEach(t),wYr=r(Yoo," (XGLM model)"),Yoo.forEach(t),AYr=i(D),Pw=n(D,"LI",{});var Zoo=s(Pw);A9e=n(Zoo,"STRONG",{});var Cva=s(A9e);LYr=r(Cva,"xlm"),Cva.forEach(t),yYr=r(Zoo," \u2014 "),fne=n(Zoo,"A",{href:!0});var wva=s(fne);xYr=r(wva,"TFXLMModel"),wva.forEach(t),$Yr=r(Zoo," (XLM model)"),Zoo.forEach(t),kYr=i(D),Bw=n(D,"LI",{});var Koo=s(Bw);L9e=n(Koo,"STRONG",{});var Ava=s(L9e);SYr=r(Ava,"xlm-roberta"),Ava.forEach(t),RYr=r(Koo," \u2014 "),gne=n(Koo,"A",{href:!0});var Lva=s(gne);PYr=r(Lva,"TFXLMRobertaModel"),Lva.forEach(t),BYr=r(Koo," (XLM-RoBERTa model)"),Koo.forEach(t),IYr=i(D),Iw=n(D,"LI",{});var ero=s(Iw);y9e=n(ero,"STRONG",{});var yva=s(y9e);NYr=r(yva,"xlnet"),yva.forEach(t),qYr=r(ero," \u2014 "),hne=n(ero,"A",{href:!0});var xva=s(hne);DYr=r(xva,"TFXLNetModel"),xva.forEach(t),jYr=r(ero," (XLNet model)"),ero.forEach(t),D.forEach(t),GYr=i(wi),T(Nw.$$.fragment,wi),wi.forEach(t),Ci.forEach(t),Bio=i(c),Mc=n(c,"H2",{class:!0});var aco=s(Mc);qw=n(aco,"A",{id:!0,class:!0,href:!0});var $va=s(qw);x9e=n($va,"SPAN",{});var kva=s(x9e);T(yP.$$.fragment,kva),kva.forEach(t),$va.forEach(t),OYr=i(aco),$9e=n(aco,"SPAN",{});var Sva=s($9e);VYr=r(Sva,"TFAutoModelForPreTraining"),Sva.forEach(t),aco.forEach(t),Iio=i(c),ur=n(c,"DIV",{class:!0});var Ai=s(ur);T(xP.$$.fragment,Ai),XYr=i(Ai),Ec=n(Ai,"P",{});var fge=s(Ec);zYr=r(fge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),une=n(fge,"A",{href:!0});var Rva=s(une);QYr=r(Rva,"from_pretrained()"),Rva.forEach(t),WYr=r(fge," class method or the "),pne=n(fge,"A",{href:!0});var Pva=s(pne);UYr=r(Pva,"from_config()"),Pva.forEach(t),HYr=r(fge,` class
method.`),fge.forEach(t),JYr=i(Ai),$P=n(Ai,"P",{});var nco=s($P);YYr=r(nco,"This class cannot be instantiated directly using "),k9e=n(nco,"CODE",{});var Bva=s(k9e);ZYr=r(Bva,"__init__()"),Bva.forEach(t),KYr=r(nco," (throws an error)."),nco.forEach(t),eZr=i(Ai),ra=n(Ai,"DIV",{class:!0});var i$=s(ra);T(kP.$$.fragment,i$),oZr=i(i$),S9e=n(i$,"P",{});var Iva=s(S9e);rZr=r(Iva,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Iva.forEach(t),tZr=i(i$),Cc=n(i$,"P",{});var gge=s(Cc);aZr=r(gge,`Note:
Loading a model from its configuration file does `),R9e=n(gge,"STRONG",{});var Nva=s(R9e);nZr=r(Nva,"not"),Nva.forEach(t),sZr=r(gge,` load the model weights. It only affects the
model\u2019s configuration. Use `),_ne=n(gge,"A",{href:!0});var qva=s(_ne);lZr=r(qva,"from_pretrained()"),qva.forEach(t),iZr=r(gge," to load the model weights."),gge.forEach(t),dZr=i(i$),T(Dw.$$.fragment,i$),i$.forEach(t),mZr=i(Ai),zr=n(Ai,"DIV",{class:!0});var Li=s(zr);T(SP.$$.fragment,Li),cZr=i(Li),P9e=n(Li,"P",{});var Dva=s(P9e);fZr=r(Dva,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Dva.forEach(t),gZr=i(Li),On=n(Li,"P",{});var d$=s(On);hZr=r(d$,"The model class to instantiate is selected based on the "),B9e=n(d$,"CODE",{});var jva=s(B9e);uZr=r(jva,"model_type"),jva.forEach(t),pZr=r(d$,` property of the config object (either
passed as an argument or loaded from `),I9e=n(d$,"CODE",{});var Gva=s(I9e);_Zr=r(Gva,"pretrained_model_name_or_path"),Gva.forEach(t),bZr=r(d$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N9e=n(d$,"CODE",{});var Ova=s(N9e);vZr=r(Ova,"pretrained_model_name_or_path"),Ova.forEach(t),FZr=r(d$,":"),d$.forEach(t),TZr=i(Li),de=n(Li,"UL",{});var fe=s(de);jw=n(fe,"LI",{});var oro=s(jw);q9e=n(oro,"STRONG",{});var Vva=s(q9e);MZr=r(Vva,"albert"),Vva.forEach(t),EZr=r(oro," \u2014 "),bne=n(oro,"A",{href:!0});var Xva=s(bne);CZr=r(Xva,"TFAlbertForPreTraining"),Xva.forEach(t),wZr=r(oro," (ALBERT model)"),oro.forEach(t),AZr=i(fe),Gw=n(fe,"LI",{});var rro=s(Gw);D9e=n(rro,"STRONG",{});var zva=s(D9e);LZr=r(zva,"bart"),zva.forEach(t),yZr=r(rro," \u2014 "),vne=n(rro,"A",{href:!0});var Qva=s(vne);xZr=r(Qva,"TFBartForConditionalGeneration"),Qva.forEach(t),$Zr=r(rro," (BART model)"),rro.forEach(t),kZr=i(fe),Ow=n(fe,"LI",{});var tro=s(Ow);j9e=n(tro,"STRONG",{});var Wva=s(j9e);SZr=r(Wva,"bert"),Wva.forEach(t),RZr=r(tro," \u2014 "),Fne=n(tro,"A",{href:!0});var Uva=s(Fne);PZr=r(Uva,"TFBertForPreTraining"),Uva.forEach(t),BZr=r(tro," (BERT model)"),tro.forEach(t),IZr=i(fe),Vw=n(fe,"LI",{});var aro=s(Vw);G9e=n(aro,"STRONG",{});var Hva=s(G9e);NZr=r(Hva,"camembert"),Hva.forEach(t),qZr=r(aro," \u2014 "),Tne=n(aro,"A",{href:!0});var Jva=s(Tne);DZr=r(Jva,"TFCamembertForMaskedLM"),Jva.forEach(t),jZr=r(aro," (CamemBERT model)"),aro.forEach(t),GZr=i(fe),Xw=n(fe,"LI",{});var nro=s(Xw);O9e=n(nro,"STRONG",{});var Yva=s(O9e);OZr=r(Yva,"ctrl"),Yva.forEach(t),VZr=r(nro," \u2014 "),Mne=n(nro,"A",{href:!0});var Zva=s(Mne);XZr=r(Zva,"TFCTRLLMHeadModel"),Zva.forEach(t),zZr=r(nro," (CTRL model)"),nro.forEach(t),QZr=i(fe),zw=n(fe,"LI",{});var sro=s(zw);V9e=n(sro,"STRONG",{});var Kva=s(V9e);WZr=r(Kva,"distilbert"),Kva.forEach(t),UZr=r(sro," \u2014 "),Ene=n(sro,"A",{href:!0});var eFa=s(Ene);HZr=r(eFa,"TFDistilBertForMaskedLM"),eFa.forEach(t),JZr=r(sro," (DistilBERT model)"),sro.forEach(t),YZr=i(fe),Qw=n(fe,"LI",{});var lro=s(Qw);X9e=n(lro,"STRONG",{});var oFa=s(X9e);ZZr=r(oFa,"electra"),oFa.forEach(t),KZr=r(lro," \u2014 "),Cne=n(lro,"A",{href:!0});var rFa=s(Cne);eKr=r(rFa,"TFElectraForPreTraining"),rFa.forEach(t),oKr=r(lro," (ELECTRA model)"),lro.forEach(t),rKr=i(fe),Ww=n(fe,"LI",{});var iro=s(Ww);z9e=n(iro,"STRONG",{});var tFa=s(z9e);tKr=r(tFa,"flaubert"),tFa.forEach(t),aKr=r(iro," \u2014 "),wne=n(iro,"A",{href:!0});var aFa=s(wne);nKr=r(aFa,"TFFlaubertWithLMHeadModel"),aFa.forEach(t),sKr=r(iro," (FlauBERT model)"),iro.forEach(t),lKr=i(fe),Uw=n(fe,"LI",{});var dro=s(Uw);Q9e=n(dro,"STRONG",{});var nFa=s(Q9e);iKr=r(nFa,"funnel"),nFa.forEach(t),dKr=r(dro," \u2014 "),Ane=n(dro,"A",{href:!0});var sFa=s(Ane);mKr=r(sFa,"TFFunnelForPreTraining"),sFa.forEach(t),cKr=r(dro," (Funnel Transformer model)"),dro.forEach(t),fKr=i(fe),Hw=n(fe,"LI",{});var mro=s(Hw);W9e=n(mro,"STRONG",{});var lFa=s(W9e);gKr=r(lFa,"gpt2"),lFa.forEach(t),hKr=r(mro," \u2014 "),Lne=n(mro,"A",{href:!0});var iFa=s(Lne);uKr=r(iFa,"TFGPT2LMHeadModel"),iFa.forEach(t),pKr=r(mro," (OpenAI GPT-2 model)"),mro.forEach(t),_Kr=i(fe),Jw=n(fe,"LI",{});var cro=s(Jw);U9e=n(cro,"STRONG",{});var dFa=s(U9e);bKr=r(dFa,"layoutlm"),dFa.forEach(t),vKr=r(cro," \u2014 "),yne=n(cro,"A",{href:!0});var mFa=s(yne);FKr=r(mFa,"TFLayoutLMForMaskedLM"),mFa.forEach(t),TKr=r(cro," (LayoutLM model)"),cro.forEach(t),MKr=i(fe),Yw=n(fe,"LI",{});var fro=s(Yw);H9e=n(fro,"STRONG",{});var cFa=s(H9e);EKr=r(cFa,"lxmert"),cFa.forEach(t),CKr=r(fro," \u2014 "),xne=n(fro,"A",{href:!0});var fFa=s(xne);wKr=r(fFa,"TFLxmertForPreTraining"),fFa.forEach(t),AKr=r(fro," (LXMERT model)"),fro.forEach(t),LKr=i(fe),Zw=n(fe,"LI",{});var gro=s(Zw);J9e=n(gro,"STRONG",{});var gFa=s(J9e);yKr=r(gFa,"mobilebert"),gFa.forEach(t),xKr=r(gro," \u2014 "),$ne=n(gro,"A",{href:!0});var hFa=s($ne);$Kr=r(hFa,"TFMobileBertForPreTraining"),hFa.forEach(t),kKr=r(gro," (MobileBERT model)"),gro.forEach(t),SKr=i(fe),Kw=n(fe,"LI",{});var hro=s(Kw);Y9e=n(hro,"STRONG",{});var uFa=s(Y9e);RKr=r(uFa,"mpnet"),uFa.forEach(t),PKr=r(hro," \u2014 "),kne=n(hro,"A",{href:!0});var pFa=s(kne);BKr=r(pFa,"TFMPNetForMaskedLM"),pFa.forEach(t),IKr=r(hro," (MPNet model)"),hro.forEach(t),NKr=i(fe),eA=n(fe,"LI",{});var uro=s(eA);Z9e=n(uro,"STRONG",{});var _Fa=s(Z9e);qKr=r(_Fa,"openai-gpt"),_Fa.forEach(t),DKr=r(uro," \u2014 "),Sne=n(uro,"A",{href:!0});var bFa=s(Sne);jKr=r(bFa,"TFOpenAIGPTLMHeadModel"),bFa.forEach(t),GKr=r(uro," (OpenAI GPT model)"),uro.forEach(t),OKr=i(fe),oA=n(fe,"LI",{});var pro=s(oA);K9e=n(pro,"STRONG",{});var vFa=s(K9e);VKr=r(vFa,"roberta"),vFa.forEach(t),XKr=r(pro," \u2014 "),Rne=n(pro,"A",{href:!0});var FFa=s(Rne);zKr=r(FFa,"TFRobertaForMaskedLM"),FFa.forEach(t),QKr=r(pro," (RoBERTa model)"),pro.forEach(t),WKr=i(fe),rA=n(fe,"LI",{});var _ro=s(rA);exe=n(_ro,"STRONG",{});var TFa=s(exe);UKr=r(TFa,"t5"),TFa.forEach(t),HKr=r(_ro," \u2014 "),Pne=n(_ro,"A",{href:!0});var MFa=s(Pne);JKr=r(MFa,"TFT5ForConditionalGeneration"),MFa.forEach(t),YKr=r(_ro," (T5 model)"),_ro.forEach(t),ZKr=i(fe),tA=n(fe,"LI",{});var bro=s(tA);oxe=n(bro,"STRONG",{});var EFa=s(oxe);KKr=r(EFa,"tapas"),EFa.forEach(t),eet=r(bro," \u2014 "),Bne=n(bro,"A",{href:!0});var CFa=s(Bne);oet=r(CFa,"TFTapasForMaskedLM"),CFa.forEach(t),ret=r(bro," (TAPAS model)"),bro.forEach(t),tet=i(fe),aA=n(fe,"LI",{});var vro=s(aA);rxe=n(vro,"STRONG",{});var wFa=s(rxe);aet=r(wFa,"transfo-xl"),wFa.forEach(t),net=r(vro," \u2014 "),Ine=n(vro,"A",{href:!0});var AFa=s(Ine);set=r(AFa,"TFTransfoXLLMHeadModel"),AFa.forEach(t),iet=r(vro," (Transformer-XL model)"),vro.forEach(t),det=i(fe),nA=n(fe,"LI",{});var Fro=s(nA);txe=n(Fro,"STRONG",{});var LFa=s(txe);met=r(LFa,"vit_mae"),LFa.forEach(t),cet=r(Fro," \u2014 "),Nne=n(Fro,"A",{href:!0});var yFa=s(Nne);fet=r(yFa,"TFViTMAEForPreTraining"),yFa.forEach(t),get=r(Fro," (ViTMAE model)"),Fro.forEach(t),het=i(fe),sA=n(fe,"LI",{});var Tro=s(sA);axe=n(Tro,"STRONG",{});var xFa=s(axe);uet=r(xFa,"xlm"),xFa.forEach(t),pet=r(Tro," \u2014 "),qne=n(Tro,"A",{href:!0});var $Fa=s(qne);_et=r($Fa,"TFXLMWithLMHeadModel"),$Fa.forEach(t),bet=r(Tro," (XLM model)"),Tro.forEach(t),vet=i(fe),lA=n(fe,"LI",{});var Mro=s(lA);nxe=n(Mro,"STRONG",{});var kFa=s(nxe);Fet=r(kFa,"xlm-roberta"),kFa.forEach(t),Tet=r(Mro," \u2014 "),Dne=n(Mro,"A",{href:!0});var SFa=s(Dne);Met=r(SFa,"TFXLMRobertaForMaskedLM"),SFa.forEach(t),Eet=r(Mro," (XLM-RoBERTa model)"),Mro.forEach(t),Cet=i(fe),iA=n(fe,"LI",{});var Ero=s(iA);sxe=n(Ero,"STRONG",{});var RFa=s(sxe);wet=r(RFa,"xlnet"),RFa.forEach(t),Aet=r(Ero," \u2014 "),jne=n(Ero,"A",{href:!0});var PFa=s(jne);Let=r(PFa,"TFXLNetLMHeadModel"),PFa.forEach(t),yet=r(Ero," (XLNet model)"),Ero.forEach(t),fe.forEach(t),xet=i(Li),T(dA.$$.fragment,Li),Li.forEach(t),Ai.forEach(t),Nio=i(c),wc=n(c,"H2",{class:!0});var sco=s(wc);mA=n(sco,"A",{id:!0,class:!0,href:!0});var BFa=s(mA);lxe=n(BFa,"SPAN",{});var IFa=s(lxe);T(RP.$$.fragment,IFa),IFa.forEach(t),BFa.forEach(t),$et=i(sco),ixe=n(sco,"SPAN",{});var NFa=s(ixe);ket=r(NFa,"TFAutoModelForCausalLM"),NFa.forEach(t),sco.forEach(t),qio=i(c),pr=n(c,"DIV",{class:!0});var yi=s(pr);T(PP.$$.fragment,yi),Set=i(yi),Ac=n(yi,"P",{});var hge=s(Ac);Ret=r(hge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Gne=n(hge,"A",{href:!0});var qFa=s(Gne);Pet=r(qFa,"from_pretrained()"),qFa.forEach(t),Bet=r(hge," class method or the "),One=n(hge,"A",{href:!0});var DFa=s(One);Iet=r(DFa,"from_config()"),DFa.forEach(t),Net=r(hge,` class
method.`),hge.forEach(t),qet=i(yi),BP=n(yi,"P",{});var lco=s(BP);Det=r(lco,"This class cannot be instantiated directly using "),dxe=n(lco,"CODE",{});var jFa=s(dxe);jet=r(jFa,"__init__()"),jFa.forEach(t),Get=r(lco," (throws an error)."),lco.forEach(t),Oet=i(yi),ta=n(yi,"DIV",{class:!0});var m$=s(ta);T(IP.$$.fragment,m$),Vet=i(m$),mxe=n(m$,"P",{});var GFa=s(mxe);Xet=r(GFa,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),GFa.forEach(t),zet=i(m$),Lc=n(m$,"P",{});var uge=s(Lc);Qet=r(uge,`Note:
Loading a model from its configuration file does `),cxe=n(uge,"STRONG",{});var OFa=s(cxe);Wet=r(OFa,"not"),OFa.forEach(t),Uet=r(uge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Vne=n(uge,"A",{href:!0});var VFa=s(Vne);Het=r(VFa,"from_pretrained()"),VFa.forEach(t),Jet=r(uge," to load the model weights."),uge.forEach(t),Yet=i(m$),T(cA.$$.fragment,m$),m$.forEach(t),Zet=i(yi),Qr=n(yi,"DIV",{class:!0});var xi=s(Qr);T(NP.$$.fragment,xi),Ket=i(xi),fxe=n(xi,"P",{});var XFa=s(fxe);eot=r(XFa,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),XFa.forEach(t),oot=i(xi),Vn=n(xi,"P",{});var c$=s(Vn);rot=r(c$,"The model class to instantiate is selected based on the "),gxe=n(c$,"CODE",{});var zFa=s(gxe);tot=r(zFa,"model_type"),zFa.forEach(t),aot=r(c$,` property of the config object (either
passed as an argument or loaded from `),hxe=n(c$,"CODE",{});var QFa=s(hxe);not=r(QFa,"pretrained_model_name_or_path"),QFa.forEach(t),sot=r(c$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uxe=n(c$,"CODE",{});var WFa=s(uxe);lot=r(WFa,"pretrained_model_name_or_path"),WFa.forEach(t),iot=r(c$,":"),c$.forEach(t),dot=i(xi),Ce=n(xi,"UL",{});var Ae=s(Ce);fA=n(Ae,"LI",{});var Cro=s(fA);pxe=n(Cro,"STRONG",{});var UFa=s(pxe);mot=r(UFa,"bert"),UFa.forEach(t),cot=r(Cro," \u2014 "),Xne=n(Cro,"A",{href:!0});var HFa=s(Xne);fot=r(HFa,"TFBertLMHeadModel"),HFa.forEach(t),got=r(Cro," (BERT model)"),Cro.forEach(t),hot=i(Ae),gA=n(Ae,"LI",{});var wro=s(gA);_xe=n(wro,"STRONG",{});var JFa=s(_xe);uot=r(JFa,"camembert"),JFa.forEach(t),pot=r(wro," \u2014 "),zne=n(wro,"A",{href:!0});var YFa=s(zne);_ot=r(YFa,"TFCamembertForCausalLM"),YFa.forEach(t),bot=r(wro," (CamemBERT model)"),wro.forEach(t),vot=i(Ae),hA=n(Ae,"LI",{});var Aro=s(hA);bxe=n(Aro,"STRONG",{});var ZFa=s(bxe);Fot=r(ZFa,"ctrl"),ZFa.forEach(t),Tot=r(Aro," \u2014 "),Qne=n(Aro,"A",{href:!0});var KFa=s(Qne);Mot=r(KFa,"TFCTRLLMHeadModel"),KFa.forEach(t),Eot=r(Aro," (CTRL model)"),Aro.forEach(t),Cot=i(Ae),uA=n(Ae,"LI",{});var Lro=s(uA);vxe=n(Lro,"STRONG",{});var eTa=s(vxe);wot=r(eTa,"gpt2"),eTa.forEach(t),Aot=r(Lro," \u2014 "),Wne=n(Lro,"A",{href:!0});var oTa=s(Wne);Lot=r(oTa,"TFGPT2LMHeadModel"),oTa.forEach(t),yot=r(Lro," (OpenAI GPT-2 model)"),Lro.forEach(t),xot=i(Ae),pA=n(Ae,"LI",{});var yro=s(pA);Fxe=n(yro,"STRONG",{});var rTa=s(Fxe);$ot=r(rTa,"gptj"),rTa.forEach(t),kot=r(yro," \u2014 "),Une=n(yro,"A",{href:!0});var tTa=s(Une);Sot=r(tTa,"TFGPTJForCausalLM"),tTa.forEach(t),Rot=r(yro," (GPT-J model)"),yro.forEach(t),Pot=i(Ae),_A=n(Ae,"LI",{});var xro=s(_A);Txe=n(xro,"STRONG",{});var aTa=s(Txe);Bot=r(aTa,"openai-gpt"),aTa.forEach(t),Iot=r(xro," \u2014 "),Hne=n(xro,"A",{href:!0});var nTa=s(Hne);Not=r(nTa,"TFOpenAIGPTLMHeadModel"),nTa.forEach(t),qot=r(xro," (OpenAI GPT model)"),xro.forEach(t),Dot=i(Ae),bA=n(Ae,"LI",{});var $ro=s(bA);Mxe=n($ro,"STRONG",{});var sTa=s(Mxe);jot=r(sTa,"opt"),sTa.forEach(t),Got=r($ro," \u2014 "),Jne=n($ro,"A",{href:!0});var lTa=s(Jne);Oot=r(lTa,"TFOPTForCausalLM"),lTa.forEach(t),Vot=r($ro," (OPT model)"),$ro.forEach(t),Xot=i(Ae),vA=n(Ae,"LI",{});var kro=s(vA);Exe=n(kro,"STRONG",{});var iTa=s(Exe);zot=r(iTa,"rembert"),iTa.forEach(t),Qot=r(kro," \u2014 "),Yne=n(kro,"A",{href:!0});var dTa=s(Yne);Wot=r(dTa,"TFRemBertForCausalLM"),dTa.forEach(t),Uot=r(kro," (RemBERT model)"),kro.forEach(t),Hot=i(Ae),FA=n(Ae,"LI",{});var Sro=s(FA);Cxe=n(Sro,"STRONG",{});var mTa=s(Cxe);Jot=r(mTa,"roberta"),mTa.forEach(t),Yot=r(Sro," \u2014 "),Zne=n(Sro,"A",{href:!0});var cTa=s(Zne);Zot=r(cTa,"TFRobertaForCausalLM"),cTa.forEach(t),Kot=r(Sro," (RoBERTa model)"),Sro.forEach(t),ert=i(Ae),TA=n(Ae,"LI",{});var Rro=s(TA);wxe=n(Rro,"STRONG",{});var fTa=s(wxe);ort=r(fTa,"roformer"),fTa.forEach(t),rrt=r(Rro," \u2014 "),Kne=n(Rro,"A",{href:!0});var gTa=s(Kne);trt=r(gTa,"TFRoFormerForCausalLM"),gTa.forEach(t),art=r(Rro," (RoFormer model)"),Rro.forEach(t),nrt=i(Ae),MA=n(Ae,"LI",{});var Pro=s(MA);Axe=n(Pro,"STRONG",{});var hTa=s(Axe);srt=r(hTa,"transfo-xl"),hTa.forEach(t),lrt=r(Pro," \u2014 "),ese=n(Pro,"A",{href:!0});var uTa=s(ese);irt=r(uTa,"TFTransfoXLLMHeadModel"),uTa.forEach(t),drt=r(Pro," (Transformer-XL model)"),Pro.forEach(t),mrt=i(Ae),EA=n(Ae,"LI",{});var Bro=s(EA);Lxe=n(Bro,"STRONG",{});var pTa=s(Lxe);crt=r(pTa,"xglm"),pTa.forEach(t),frt=r(Bro," \u2014 "),ose=n(Bro,"A",{href:!0});var _Ta=s(ose);grt=r(_Ta,"TFXGLMForCausalLM"),_Ta.forEach(t),hrt=r(Bro," (XGLM model)"),Bro.forEach(t),urt=i(Ae),CA=n(Ae,"LI",{});var Iro=s(CA);yxe=n(Iro,"STRONG",{});var bTa=s(yxe);prt=r(bTa,"xlm"),bTa.forEach(t),_rt=r(Iro," \u2014 "),rse=n(Iro,"A",{href:!0});var vTa=s(rse);brt=r(vTa,"TFXLMWithLMHeadModel"),vTa.forEach(t),vrt=r(Iro," (XLM model)"),Iro.forEach(t),Frt=i(Ae),wA=n(Ae,"LI",{});var Nro=s(wA);xxe=n(Nro,"STRONG",{});var FTa=s(xxe);Trt=r(FTa,"xlnet"),FTa.forEach(t),Mrt=r(Nro," \u2014 "),tse=n(Nro,"A",{href:!0});var TTa=s(tse);Ert=r(TTa,"TFXLNetLMHeadModel"),TTa.forEach(t),Crt=r(Nro," (XLNet model)"),Nro.forEach(t),Ae.forEach(t),wrt=i(xi),T(AA.$$.fragment,xi),xi.forEach(t),yi.forEach(t),Dio=i(c),yc=n(c,"H2",{class:!0});var ico=s(yc);LA=n(ico,"A",{id:!0,class:!0,href:!0});var MTa=s(LA);$xe=n(MTa,"SPAN",{});var ETa=s($xe);T(qP.$$.fragment,ETa),ETa.forEach(t),MTa.forEach(t),Art=i(ico),kxe=n(ico,"SPAN",{});var CTa=s(kxe);Lrt=r(CTa,"TFAutoModelForImageClassification"),CTa.forEach(t),ico.forEach(t),jio=i(c),_r=n(c,"DIV",{class:!0});var $i=s(_r);T(DP.$$.fragment,$i),yrt=i($i),xc=n($i,"P",{});var pge=s(xc);xrt=r(pge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),ase=n(pge,"A",{href:!0});var wTa=s(ase);$rt=r(wTa,"from_pretrained()"),wTa.forEach(t),krt=r(pge," class method or the "),nse=n(pge,"A",{href:!0});var ATa=s(nse);Srt=r(ATa,"from_config()"),ATa.forEach(t),Rrt=r(pge,` class
method.`),pge.forEach(t),Prt=i($i),jP=n($i,"P",{});var dco=s(jP);Brt=r(dco,"This class cannot be instantiated directly using "),Sxe=n(dco,"CODE",{});var LTa=s(Sxe);Irt=r(LTa,"__init__()"),LTa.forEach(t),Nrt=r(dco," (throws an error)."),dco.forEach(t),qrt=i($i),aa=n($i,"DIV",{class:!0});var f$=s(aa);T(GP.$$.fragment,f$),Drt=i(f$),Rxe=n(f$,"P",{});var yTa=s(Rxe);jrt=r(yTa,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),yTa.forEach(t),Grt=i(f$),$c=n(f$,"P",{});var _ge=s($c);Ort=r(_ge,`Note:
Loading a model from its configuration file does `),Pxe=n(_ge,"STRONG",{});var xTa=s(Pxe);Vrt=r(xTa,"not"),xTa.forEach(t),Xrt=r(_ge,` load the model weights. It only affects the
model\u2019s configuration. Use `),sse=n(_ge,"A",{href:!0});var $Ta=s(sse);zrt=r($Ta,"from_pretrained()"),$Ta.forEach(t),Qrt=r(_ge," to load the model weights."),_ge.forEach(t),Wrt=i(f$),T(yA.$$.fragment,f$),f$.forEach(t),Urt=i($i),Wr=n($i,"DIV",{class:!0});var ki=s(Wr);T(OP.$$.fragment,ki),Hrt=i(ki),Bxe=n(ki,"P",{});var kTa=s(Bxe);Jrt=r(kTa,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),kTa.forEach(t),Yrt=i(ki),Xn=n(ki,"P",{});var g$=s(Xn);Zrt=r(g$,"The model class to instantiate is selected based on the "),Ixe=n(g$,"CODE",{});var STa=s(Ixe);Krt=r(STa,"model_type"),STa.forEach(t),ett=r(g$,` property of the config object (either
passed as an argument or loaded from `),Nxe=n(g$,"CODE",{});var RTa=s(Nxe);ott=r(RTa,"pretrained_model_name_or_path"),RTa.forEach(t),rtt=r(g$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qxe=n(g$,"CODE",{});var PTa=s(qxe);ttt=r(PTa,"pretrained_model_name_or_path"),PTa.forEach(t),att=r(g$,":"),g$.forEach(t),ntt=i(ki),$e=n(ki,"UL",{});var De=s($e);xA=n(De,"LI",{});var qro=s(xA);Dxe=n(qro,"STRONG",{});var BTa=s(Dxe);stt=r(BTa,"convnext"),BTa.forEach(t),ltt=r(qro," \u2014 "),lse=n(qro,"A",{href:!0});var ITa=s(lse);itt=r(ITa,"TFConvNextForImageClassification"),ITa.forEach(t),dtt=r(qro," (ConvNeXT model)"),qro.forEach(t),mtt=i(De),$A=n(De,"LI",{});var Dro=s($A);jxe=n(Dro,"STRONG",{});var NTa=s(jxe);ctt=r(NTa,"cvt"),NTa.forEach(t),ftt=r(Dro," \u2014 "),ise=n(Dro,"A",{href:!0});var qTa=s(ise);gtt=r(qTa,"TFCvtForImageClassification"),qTa.forEach(t),htt=r(Dro," (CvT model)"),Dro.forEach(t),utt=i(De),kA=n(De,"LI",{});var jro=s(kA);Gxe=n(jro,"STRONG",{});var DTa=s(Gxe);ptt=r(DTa,"data2vec-vision"),DTa.forEach(t),_tt=r(jro," \u2014 "),dse=n(jro,"A",{href:!0});var jTa=s(dse);btt=r(jTa,"TFData2VecVisionForImageClassification"),jTa.forEach(t),vtt=r(jro," (Data2VecVision model)"),jro.forEach(t),Ftt=i(De),jl=n(De,"LI",{});var kq=s(jl);Oxe=n(kq,"STRONG",{});var GTa=s(Oxe);Ttt=r(GTa,"deit"),GTa.forEach(t),Mtt=r(kq," \u2014 "),mse=n(kq,"A",{href:!0});var OTa=s(mse);Ett=r(OTa,"TFDeiTForImageClassification"),OTa.forEach(t),Ctt=r(kq," or "),cse=n(kq,"A",{href:!0});var VTa=s(cse);wtt=r(VTa,"TFDeiTForImageClassificationWithTeacher"),VTa.forEach(t),Att=r(kq," (DeiT model)"),kq.forEach(t),Ltt=i(De),SA=n(De,"LI",{});var Gro=s(SA);Vxe=n(Gro,"STRONG",{});var XTa=s(Vxe);ytt=r(XTa,"mobilevit"),XTa.forEach(t),xtt=r(Gro," \u2014 "),fse=n(Gro,"A",{href:!0});var zTa=s(fse);$tt=r(zTa,"TFMobileViTForImageClassification"),zTa.forEach(t),ktt=r(Gro," (MobileViT model)"),Gro.forEach(t),Stt=i(De),RA=n(De,"LI",{});var Oro=s(RA);Xxe=n(Oro,"STRONG",{});var QTa=s(Xxe);Rtt=r(QTa,"regnet"),QTa.forEach(t),Ptt=r(Oro," \u2014 "),gse=n(Oro,"A",{href:!0});var WTa=s(gse);Btt=r(WTa,"TFRegNetForImageClassification"),WTa.forEach(t),Itt=r(Oro," (RegNet model)"),Oro.forEach(t),Ntt=i(De),PA=n(De,"LI",{});var Vro=s(PA);zxe=n(Vro,"STRONG",{});var UTa=s(zxe);qtt=r(UTa,"resnet"),UTa.forEach(t),Dtt=r(Vro," \u2014 "),hse=n(Vro,"A",{href:!0});var HTa=s(hse);jtt=r(HTa,"TFResNetForImageClassification"),HTa.forEach(t),Gtt=r(Vro," (ResNet model)"),Vro.forEach(t),Ott=i(De),BA=n(De,"LI",{});var Xro=s(BA);Qxe=n(Xro,"STRONG",{});var JTa=s(Qxe);Vtt=r(JTa,"segformer"),JTa.forEach(t),Xtt=r(Xro," \u2014 "),use=n(Xro,"A",{href:!0});var YTa=s(use);ztt=r(YTa,"TFSegformerForImageClassification"),YTa.forEach(t),Qtt=r(Xro," (SegFormer model)"),Xro.forEach(t),Wtt=i(De),IA=n(De,"LI",{});var zro=s(IA);Wxe=n(zro,"STRONG",{});var ZTa=s(Wxe);Utt=r(ZTa,"swin"),ZTa.forEach(t),Htt=r(zro," \u2014 "),pse=n(zro,"A",{href:!0});var KTa=s(pse);Jtt=r(KTa,"TFSwinForImageClassification"),KTa.forEach(t),Ytt=r(zro," (Swin Transformer model)"),zro.forEach(t),Ztt=i(De),NA=n(De,"LI",{});var Qro=s(NA);Uxe=n(Qro,"STRONG",{});var eMa=s(Uxe);Ktt=r(eMa,"vit"),eMa.forEach(t),eat=r(Qro," \u2014 "),_se=n(Qro,"A",{href:!0});var oMa=s(_se);oat=r(oMa,"TFViTForImageClassification"),oMa.forEach(t),rat=r(Qro," (ViT model)"),Qro.forEach(t),De.forEach(t),tat=i(ki),T(qA.$$.fragment,ki),ki.forEach(t),$i.forEach(t),Gio=i(c),kc=n(c,"H2",{class:!0});var mco=s(kc);DA=n(mco,"A",{id:!0,class:!0,href:!0});var rMa=s(DA);Hxe=n(rMa,"SPAN",{});var tMa=s(Hxe);T(VP.$$.fragment,tMa),tMa.forEach(t),rMa.forEach(t),aat=i(mco),Jxe=n(mco,"SPAN",{});var aMa=s(Jxe);nat=r(aMa,"TFAutoModelForSemanticSegmentation"),aMa.forEach(t),mco.forEach(t),Oio=i(c),br=n(c,"DIV",{class:!0});var Si=s(br);T(XP.$$.fragment,Si),sat=i(Si),Sc=n(Si,"P",{});var bge=s(Sc);lat=r(bge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),bse=n(bge,"A",{href:!0});var nMa=s(bse);iat=r(nMa,"from_pretrained()"),nMa.forEach(t),dat=r(bge," class method or the "),vse=n(bge,"A",{href:!0});var sMa=s(vse);mat=r(sMa,"from_config()"),sMa.forEach(t),cat=r(bge,` class
method.`),bge.forEach(t),fat=i(Si),zP=n(Si,"P",{});var cco=s(zP);gat=r(cco,"This class cannot be instantiated directly using "),Yxe=n(cco,"CODE",{});var lMa=s(Yxe);hat=r(lMa,"__init__()"),lMa.forEach(t),uat=r(cco," (throws an error)."),cco.forEach(t),pat=i(Si),na=n(Si,"DIV",{class:!0});var h$=s(na);T(QP.$$.fragment,h$),_at=i(h$),Zxe=n(h$,"P",{});var iMa=s(Zxe);bat=r(iMa,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),iMa.forEach(t),vat=i(h$),Rc=n(h$,"P",{});var vge=s(Rc);Fat=r(vge,`Note:
Loading a model from its configuration file does `),Kxe=n(vge,"STRONG",{});var dMa=s(Kxe);Tat=r(dMa,"not"),dMa.forEach(t),Mat=r(vge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Fse=n(vge,"A",{href:!0});var mMa=s(Fse);Eat=r(mMa,"from_pretrained()"),mMa.forEach(t),Cat=r(vge," to load the model weights."),vge.forEach(t),wat=i(h$),T(jA.$$.fragment,h$),h$.forEach(t),Aat=i(Si),Ur=n(Si,"DIV",{class:!0});var Ri=s(Ur);T(WP.$$.fragment,Ri),Lat=i(Ri),e$e=n(Ri,"P",{});var cMa=s(e$e);yat=r(cMa,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),cMa.forEach(t),xat=i(Ri),zn=n(Ri,"P",{});var u$=s(zn);$at=r(u$,"The model class to instantiate is selected based on the "),o$e=n(u$,"CODE",{});var fMa=s(o$e);kat=r(fMa,"model_type"),fMa.forEach(t),Sat=r(u$,` property of the config object (either
passed as an argument or loaded from `),r$e=n(u$,"CODE",{});var gMa=s(r$e);Rat=r(gMa,"pretrained_model_name_or_path"),gMa.forEach(t),Pat=r(u$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),t$e=n(u$,"CODE",{});var hMa=s(t$e);Bat=r(hMa,"pretrained_model_name_or_path"),hMa.forEach(t),Iat=r(u$,":"),u$.forEach(t),Nat=i(Ri),Pc=n(Ri,"UL",{});var Fge=s(Pc);GA=n(Fge,"LI",{});var Wro=s(GA);a$e=n(Wro,"STRONG",{});var uMa=s(a$e);qat=r(uMa,"data2vec-vision"),uMa.forEach(t),Dat=r(Wro," \u2014 "),Tse=n(Wro,"A",{href:!0});var pMa=s(Tse);jat=r(pMa,"TFData2VecVisionForSemanticSegmentation"),pMa.forEach(t),Gat=r(Wro," (Data2VecVision model)"),Wro.forEach(t),Oat=i(Fge),OA=n(Fge,"LI",{});var Uro=s(OA);n$e=n(Uro,"STRONG",{});var _Ma=s(n$e);Vat=r(_Ma,"mobilevit"),_Ma.forEach(t),Xat=r(Uro," \u2014 "),Mse=n(Uro,"A",{href:!0});var bMa=s(Mse);zat=r(bMa,"TFMobileViTForSemanticSegmentation"),bMa.forEach(t),Qat=r(Uro," (MobileViT model)"),Uro.forEach(t),Wat=i(Fge),VA=n(Fge,"LI",{});var Hro=s(VA);s$e=n(Hro,"STRONG",{});var vMa=s(s$e);Uat=r(vMa,"segformer"),vMa.forEach(t),Hat=r(Hro," \u2014 "),Ese=n(Hro,"A",{href:!0});var FMa=s(Ese);Jat=r(FMa,"TFSegformerForSemanticSegmentation"),FMa.forEach(t),Yat=r(Hro," (SegFormer model)"),Hro.forEach(t),Fge.forEach(t),Zat=i(Ri),T(XA.$$.fragment,Ri),Ri.forEach(t),Si.forEach(t),Vio=i(c),Bc=n(c,"H2",{class:!0});var fco=s(Bc);zA=n(fco,"A",{id:!0,class:!0,href:!0});var TMa=s(zA);l$e=n(TMa,"SPAN",{});var MMa=s(l$e);T(UP.$$.fragment,MMa),MMa.forEach(t),TMa.forEach(t),Kat=i(fco),i$e=n(fco,"SPAN",{});var EMa=s(i$e);ent=r(EMa,"TFAutoModelForMaskedLM"),EMa.forEach(t),fco.forEach(t),Xio=i(c),vr=n(c,"DIV",{class:!0});var Pi=s(vr);T(HP.$$.fragment,Pi),ont=i(Pi),Ic=n(Pi,"P",{});var Tge=s(Ic);rnt=r(Tge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Cse=n(Tge,"A",{href:!0});var CMa=s(Cse);tnt=r(CMa,"from_pretrained()"),CMa.forEach(t),ant=r(Tge," class method or the "),wse=n(Tge,"A",{href:!0});var wMa=s(wse);nnt=r(wMa,"from_config()"),wMa.forEach(t),snt=r(Tge,` class
method.`),Tge.forEach(t),lnt=i(Pi),JP=n(Pi,"P",{});var gco=s(JP);int=r(gco,"This class cannot be instantiated directly using "),d$e=n(gco,"CODE",{});var AMa=s(d$e);dnt=r(AMa,"__init__()"),AMa.forEach(t),mnt=r(gco," (throws an error)."),gco.forEach(t),cnt=i(Pi),sa=n(Pi,"DIV",{class:!0});var p$=s(sa);T(YP.$$.fragment,p$),fnt=i(p$),m$e=n(p$,"P",{});var LMa=s(m$e);gnt=r(LMa,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),LMa.forEach(t),hnt=i(p$),Nc=n(p$,"P",{});var Mge=s(Nc);unt=r(Mge,`Note:
Loading a model from its configuration file does `),c$e=n(Mge,"STRONG",{});var yMa=s(c$e);pnt=r(yMa,"not"),yMa.forEach(t),_nt=r(Mge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ase=n(Mge,"A",{href:!0});var xMa=s(Ase);bnt=r(xMa,"from_pretrained()"),xMa.forEach(t),vnt=r(Mge," to load the model weights."),Mge.forEach(t),Fnt=i(p$),T(QA.$$.fragment,p$),p$.forEach(t),Tnt=i(Pi),Hr=n(Pi,"DIV",{class:!0});var Bi=s(Hr);T(ZP.$$.fragment,Bi),Mnt=i(Bi),f$e=n(Bi,"P",{});var $Ma=s(f$e);Ent=r($Ma,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),$Ma.forEach(t),Cnt=i(Bi),Qn=n(Bi,"P",{});var _$=s(Qn);wnt=r(_$,"The model class to instantiate is selected based on the "),g$e=n(_$,"CODE",{});var kMa=s(g$e);Ant=r(kMa,"model_type"),kMa.forEach(t),Lnt=r(_$,` property of the config object (either
passed as an argument or loaded from `),h$e=n(_$,"CODE",{});var SMa=s(h$e);ynt=r(SMa,"pretrained_model_name_or_path"),SMa.forEach(t),xnt=r(_$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u$e=n(_$,"CODE",{});var RMa=s(u$e);$nt=r(RMa,"pretrained_model_name_or_path"),RMa.forEach(t),knt=r(_$,":"),_$.forEach(t),Snt=i(Bi),ge=n(Bi,"UL",{});var _e=s(ge);WA=n(_e,"LI",{});var Jro=s(WA);p$e=n(Jro,"STRONG",{});var PMa=s(p$e);Rnt=r(PMa,"albert"),PMa.forEach(t),Pnt=r(Jro," \u2014 "),Lse=n(Jro,"A",{href:!0});var BMa=s(Lse);Bnt=r(BMa,"TFAlbertForMaskedLM"),BMa.forEach(t),Int=r(Jro," (ALBERT model)"),Jro.forEach(t),Nnt=i(_e),UA=n(_e,"LI",{});var Yro=s(UA);_$e=n(Yro,"STRONG",{});var IMa=s(_$e);qnt=r(IMa,"bert"),IMa.forEach(t),Dnt=r(Yro," \u2014 "),yse=n(Yro,"A",{href:!0});var NMa=s(yse);jnt=r(NMa,"TFBertForMaskedLM"),NMa.forEach(t),Gnt=r(Yro," (BERT model)"),Yro.forEach(t),Ont=i(_e),HA=n(_e,"LI",{});var Zro=s(HA);b$e=n(Zro,"STRONG",{});var qMa=s(b$e);Vnt=r(qMa,"camembert"),qMa.forEach(t),Xnt=r(Zro," \u2014 "),xse=n(Zro,"A",{href:!0});var DMa=s(xse);znt=r(DMa,"TFCamembertForMaskedLM"),DMa.forEach(t),Qnt=r(Zro," (CamemBERT model)"),Zro.forEach(t),Wnt=i(_e),JA=n(_e,"LI",{});var Kro=s(JA);v$e=n(Kro,"STRONG",{});var jMa=s(v$e);Unt=r(jMa,"convbert"),jMa.forEach(t),Hnt=r(Kro," \u2014 "),$se=n(Kro,"A",{href:!0});var GMa=s($se);Jnt=r(GMa,"TFConvBertForMaskedLM"),GMa.forEach(t),Ynt=r(Kro," (ConvBERT model)"),Kro.forEach(t),Znt=i(_e),YA=n(_e,"LI",{});var eto=s(YA);F$e=n(eto,"STRONG",{});var OMa=s(F$e);Knt=r(OMa,"deberta"),OMa.forEach(t),est=r(eto," \u2014 "),kse=n(eto,"A",{href:!0});var VMa=s(kse);ost=r(VMa,"TFDebertaForMaskedLM"),VMa.forEach(t),rst=r(eto," (DeBERTa model)"),eto.forEach(t),tst=i(_e),ZA=n(_e,"LI",{});var oto=s(ZA);T$e=n(oto,"STRONG",{});var XMa=s(T$e);ast=r(XMa,"deberta-v2"),XMa.forEach(t),nst=r(oto," \u2014 "),Sse=n(oto,"A",{href:!0});var zMa=s(Sse);sst=r(zMa,"TFDebertaV2ForMaskedLM"),zMa.forEach(t),lst=r(oto," (DeBERTa-v2 model)"),oto.forEach(t),ist=i(_e),KA=n(_e,"LI",{});var rto=s(KA);M$e=n(rto,"STRONG",{});var QMa=s(M$e);dst=r(QMa,"distilbert"),QMa.forEach(t),mst=r(rto," \u2014 "),Rse=n(rto,"A",{href:!0});var WMa=s(Rse);cst=r(WMa,"TFDistilBertForMaskedLM"),WMa.forEach(t),fst=r(rto," (DistilBERT model)"),rto.forEach(t),gst=i(_e),e6=n(_e,"LI",{});var tto=s(e6);E$e=n(tto,"STRONG",{});var UMa=s(E$e);hst=r(UMa,"electra"),UMa.forEach(t),ust=r(tto," \u2014 "),Pse=n(tto,"A",{href:!0});var HMa=s(Pse);pst=r(HMa,"TFElectraForMaskedLM"),HMa.forEach(t),_st=r(tto," (ELECTRA model)"),tto.forEach(t),bst=i(_e),o6=n(_e,"LI",{});var ato=s(o6);C$e=n(ato,"STRONG",{});var JMa=s(C$e);vst=r(JMa,"esm"),JMa.forEach(t),Fst=r(ato," \u2014 "),Bse=n(ato,"A",{href:!0});var YMa=s(Bse);Tst=r(YMa,"TFEsmForMaskedLM"),YMa.forEach(t),Mst=r(ato," (ESM model)"),ato.forEach(t),Est=i(_e),r6=n(_e,"LI",{});var nto=s(r6);w$e=n(nto,"STRONG",{});var ZMa=s(w$e);Cst=r(ZMa,"flaubert"),ZMa.forEach(t),wst=r(nto," \u2014 "),Ise=n(nto,"A",{href:!0});var KMa=s(Ise);Ast=r(KMa,"TFFlaubertWithLMHeadModel"),KMa.forEach(t),Lst=r(nto," (FlauBERT model)"),nto.forEach(t),yst=i(_e),t6=n(_e,"LI",{});var sto=s(t6);A$e=n(sto,"STRONG",{});var eEa=s(A$e);xst=r(eEa,"funnel"),eEa.forEach(t),$st=r(sto," \u2014 "),Nse=n(sto,"A",{href:!0});var oEa=s(Nse);kst=r(oEa,"TFFunnelForMaskedLM"),oEa.forEach(t),Sst=r(sto," (Funnel Transformer model)"),sto.forEach(t),Rst=i(_e),a6=n(_e,"LI",{});var lto=s(a6);L$e=n(lto,"STRONG",{});var rEa=s(L$e);Pst=r(rEa,"layoutlm"),rEa.forEach(t),Bst=r(lto," \u2014 "),qse=n(lto,"A",{href:!0});var tEa=s(qse);Ist=r(tEa,"TFLayoutLMForMaskedLM"),tEa.forEach(t),Nst=r(lto," (LayoutLM model)"),lto.forEach(t),qst=i(_e),n6=n(_e,"LI",{});var ito=s(n6);y$e=n(ito,"STRONG",{});var aEa=s(y$e);Dst=r(aEa,"longformer"),aEa.forEach(t),jst=r(ito," \u2014 "),Dse=n(ito,"A",{href:!0});var nEa=s(Dse);Gst=r(nEa,"TFLongformerForMaskedLM"),nEa.forEach(t),Ost=r(ito," (Longformer model)"),ito.forEach(t),Vst=i(_e),s6=n(_e,"LI",{});var dto=s(s6);x$e=n(dto,"STRONG",{});var sEa=s(x$e);Xst=r(sEa,"mobilebert"),sEa.forEach(t),zst=r(dto," \u2014 "),jse=n(dto,"A",{href:!0});var lEa=s(jse);Qst=r(lEa,"TFMobileBertForMaskedLM"),lEa.forEach(t),Wst=r(dto," (MobileBERT model)"),dto.forEach(t),Ust=i(_e),l6=n(_e,"LI",{});var mto=s(l6);$$e=n(mto,"STRONG",{});var iEa=s($$e);Hst=r(iEa,"mpnet"),iEa.forEach(t),Jst=r(mto," \u2014 "),Gse=n(mto,"A",{href:!0});var dEa=s(Gse);Yst=r(dEa,"TFMPNetForMaskedLM"),dEa.forEach(t),Zst=r(mto," (MPNet model)"),mto.forEach(t),Kst=i(_e),i6=n(_e,"LI",{});var cto=s(i6);k$e=n(cto,"STRONG",{});var mEa=s(k$e);elt=r(mEa,"rembert"),mEa.forEach(t),olt=r(cto," \u2014 "),Ose=n(cto,"A",{href:!0});var cEa=s(Ose);rlt=r(cEa,"TFRemBertForMaskedLM"),cEa.forEach(t),tlt=r(cto," (RemBERT model)"),cto.forEach(t),alt=i(_e),d6=n(_e,"LI",{});var fto=s(d6);S$e=n(fto,"STRONG",{});var fEa=s(S$e);nlt=r(fEa,"roberta"),fEa.forEach(t),slt=r(fto," \u2014 "),Vse=n(fto,"A",{href:!0});var gEa=s(Vse);llt=r(gEa,"TFRobertaForMaskedLM"),gEa.forEach(t),ilt=r(fto," (RoBERTa model)"),fto.forEach(t),dlt=i(_e),m6=n(_e,"LI",{});var gto=s(m6);R$e=n(gto,"STRONG",{});var hEa=s(R$e);mlt=r(hEa,"roformer"),hEa.forEach(t),clt=r(gto," \u2014 "),Xse=n(gto,"A",{href:!0});var uEa=s(Xse);flt=r(uEa,"TFRoFormerForMaskedLM"),uEa.forEach(t),glt=r(gto," (RoFormer model)"),gto.forEach(t),hlt=i(_e),c6=n(_e,"LI",{});var hto=s(c6);P$e=n(hto,"STRONG",{});var pEa=s(P$e);ult=r(pEa,"tapas"),pEa.forEach(t),plt=r(hto," \u2014 "),zse=n(hto,"A",{href:!0});var _Ea=s(zse);_lt=r(_Ea,"TFTapasForMaskedLM"),_Ea.forEach(t),blt=r(hto," (TAPAS model)"),hto.forEach(t),vlt=i(_e),f6=n(_e,"LI",{});var uto=s(f6);B$e=n(uto,"STRONG",{});var bEa=s(B$e);Flt=r(bEa,"xlm"),bEa.forEach(t),Tlt=r(uto," \u2014 "),Qse=n(uto,"A",{href:!0});var vEa=s(Qse);Mlt=r(vEa,"TFXLMWithLMHeadModel"),vEa.forEach(t),Elt=r(uto," (XLM model)"),uto.forEach(t),Clt=i(_e),g6=n(_e,"LI",{});var pto=s(g6);I$e=n(pto,"STRONG",{});var FEa=s(I$e);wlt=r(FEa,"xlm-roberta"),FEa.forEach(t),Alt=r(pto," \u2014 "),Wse=n(pto,"A",{href:!0});var TEa=s(Wse);Llt=r(TEa,"TFXLMRobertaForMaskedLM"),TEa.forEach(t),ylt=r(pto," (XLM-RoBERTa model)"),pto.forEach(t),_e.forEach(t),xlt=i(Bi),T(h6.$$.fragment,Bi),Bi.forEach(t),Pi.forEach(t),zio=i(c),qc=n(c,"H2",{class:!0});var hco=s(qc);u6=n(hco,"A",{id:!0,class:!0,href:!0});var MEa=s(u6);N$e=n(MEa,"SPAN",{});var EEa=s(N$e);T(KP.$$.fragment,EEa),EEa.forEach(t),MEa.forEach(t),$lt=i(hco),q$e=n(hco,"SPAN",{});var CEa=s(q$e);klt=r(CEa,"TFAutoModelForSeq2SeqLM"),CEa.forEach(t),hco.forEach(t),Qio=i(c),Fr=n(c,"DIV",{class:!0});var Ii=s(Fr);T(eB.$$.fragment,Ii),Slt=i(Ii),Dc=n(Ii,"P",{});var Ege=s(Dc);Rlt=r(Ege,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Use=n(Ege,"A",{href:!0});var wEa=s(Use);Plt=r(wEa,"from_pretrained()"),wEa.forEach(t),Blt=r(Ege," class method or the "),Hse=n(Ege,"A",{href:!0});var AEa=s(Hse);Ilt=r(AEa,"from_config()"),AEa.forEach(t),Nlt=r(Ege,` class
method.`),Ege.forEach(t),qlt=i(Ii),oB=n(Ii,"P",{});var uco=s(oB);Dlt=r(uco,"This class cannot be instantiated directly using "),D$e=n(uco,"CODE",{});var LEa=s(D$e);jlt=r(LEa,"__init__()"),LEa.forEach(t),Glt=r(uco," (throws an error)."),uco.forEach(t),Olt=i(Ii),la=n(Ii,"DIV",{class:!0});var b$=s(la);T(rB.$$.fragment,b$),Vlt=i(b$),j$e=n(b$,"P",{});var yEa=s(j$e);Xlt=r(yEa,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),yEa.forEach(t),zlt=i(b$),jc=n(b$,"P",{});var Cge=s(jc);Qlt=r(Cge,`Note:
Loading a model from its configuration file does `),G$e=n(Cge,"STRONG",{});var xEa=s(G$e);Wlt=r(xEa,"not"),xEa.forEach(t),Ult=r(Cge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Jse=n(Cge,"A",{href:!0});var $Ea=s(Jse);Hlt=r($Ea,"from_pretrained()"),$Ea.forEach(t),Jlt=r(Cge," to load the model weights."),Cge.forEach(t),Ylt=i(b$),T(p6.$$.fragment,b$),b$.forEach(t),Zlt=i(Ii),Jr=n(Ii,"DIV",{class:!0});var Ni=s(Jr);T(tB.$$.fragment,Ni),Klt=i(Ni),O$e=n(Ni,"P",{});var kEa=s(O$e);eit=r(kEa,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),kEa.forEach(t),oit=i(Ni),Wn=n(Ni,"P",{});var v$=s(Wn);rit=r(v$,"The model class to instantiate is selected based on the "),V$e=n(v$,"CODE",{});var SEa=s(V$e);tit=r(SEa,"model_type"),SEa.forEach(t),ait=r(v$,` property of the config object (either
passed as an argument or loaded from `),X$e=n(v$,"CODE",{});var REa=s(X$e);nit=r(REa,"pretrained_model_name_or_path"),REa.forEach(t),sit=r(v$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z$e=n(v$,"CODE",{});var PEa=s(z$e);lit=r(PEa,"pretrained_model_name_or_path"),PEa.forEach(t),iit=r(v$,":"),v$.forEach(t),dit=i(Ni),ke=n(Ni,"UL",{});var je=s(ke);_6=n(je,"LI",{});var _to=s(_6);Q$e=n(_to,"STRONG",{});var BEa=s(Q$e);mit=r(BEa,"bart"),BEa.forEach(t),cit=r(_to," \u2014 "),Yse=n(_to,"A",{href:!0});var IEa=s(Yse);fit=r(IEa,"TFBartForConditionalGeneration"),IEa.forEach(t),git=r(_to," (BART model)"),_to.forEach(t),hit=i(je),b6=n(je,"LI",{});var bto=s(b6);W$e=n(bto,"STRONG",{});var NEa=s(W$e);uit=r(NEa,"blenderbot"),NEa.forEach(t),pit=r(bto," \u2014 "),Zse=n(bto,"A",{href:!0});var qEa=s(Zse);_it=r(qEa,"TFBlenderbotForConditionalGeneration"),qEa.forEach(t),bit=r(bto," (Blenderbot model)"),bto.forEach(t),vit=i(je),v6=n(je,"LI",{});var vto=s(v6);U$e=n(vto,"STRONG",{});var DEa=s(U$e);Fit=r(DEa,"blenderbot-small"),DEa.forEach(t),Tit=r(vto," \u2014 "),Kse=n(vto,"A",{href:!0});var jEa=s(Kse);Mit=r(jEa,"TFBlenderbotSmallForConditionalGeneration"),jEa.forEach(t),Eit=r(vto," (BlenderbotSmall model)"),vto.forEach(t),Cit=i(je),F6=n(je,"LI",{});var Fto=s(F6);H$e=n(Fto,"STRONG",{});var GEa=s(H$e);wit=r(GEa,"encoder-decoder"),GEa.forEach(t),Ait=r(Fto," \u2014 "),ele=n(Fto,"A",{href:!0});var OEa=s(ele);Lit=r(OEa,"TFEncoderDecoderModel"),OEa.forEach(t),yit=r(Fto," (Encoder decoder model)"),Fto.forEach(t),xit=i(je),T6=n(je,"LI",{});var Tto=s(T6);J$e=n(Tto,"STRONG",{});var VEa=s(J$e);$it=r(VEa,"led"),VEa.forEach(t),kit=r(Tto," \u2014 "),ole=n(Tto,"A",{href:!0});var XEa=s(ole);Sit=r(XEa,"TFLEDForConditionalGeneration"),XEa.forEach(t),Rit=r(Tto," (LED model)"),Tto.forEach(t),Pit=i(je),M6=n(je,"LI",{});var Mto=s(M6);Y$e=n(Mto,"STRONG",{});var zEa=s(Y$e);Bit=r(zEa,"marian"),zEa.forEach(t),Iit=r(Mto," \u2014 "),rle=n(Mto,"A",{href:!0});var QEa=s(rle);Nit=r(QEa,"TFMarianMTModel"),QEa.forEach(t),qit=r(Mto," (Marian model)"),Mto.forEach(t),Dit=i(je),E6=n(je,"LI",{});var Eto=s(E6);Z$e=n(Eto,"STRONG",{});var WEa=s(Z$e);jit=r(WEa,"mbart"),WEa.forEach(t),Git=r(Eto," \u2014 "),tle=n(Eto,"A",{href:!0});var UEa=s(tle);Oit=r(UEa,"TFMBartForConditionalGeneration"),UEa.forEach(t),Vit=r(Eto," (mBART model)"),Eto.forEach(t),Xit=i(je),C6=n(je,"LI",{});var Cto=s(C6);K$e=n(Cto,"STRONG",{});var HEa=s(K$e);zit=r(HEa,"mt5"),HEa.forEach(t),Qit=r(Cto," \u2014 "),ale=n(Cto,"A",{href:!0});var JEa=s(ale);Wit=r(JEa,"TFMT5ForConditionalGeneration"),JEa.forEach(t),Uit=r(Cto," (MT5 model)"),Cto.forEach(t),Hit=i(je),w6=n(je,"LI",{});var wto=s(w6);eke=n(wto,"STRONG",{});var YEa=s(eke);Jit=r(YEa,"pegasus"),YEa.forEach(t),Yit=r(wto," \u2014 "),nle=n(wto,"A",{href:!0});var ZEa=s(nle);Zit=r(ZEa,"TFPegasusForConditionalGeneration"),ZEa.forEach(t),Kit=r(wto," (Pegasus model)"),wto.forEach(t),edt=i(je),A6=n(je,"LI",{});var Ato=s(A6);oke=n(Ato,"STRONG",{});var KEa=s(oke);odt=r(KEa,"t5"),KEa.forEach(t),rdt=r(Ato," \u2014 "),sle=n(Ato,"A",{href:!0});var e4a=s(sle);tdt=r(e4a,"TFT5ForConditionalGeneration"),e4a.forEach(t),adt=r(Ato," (T5 model)"),Ato.forEach(t),je.forEach(t),ndt=i(Ni),T(L6.$$.fragment,Ni),Ni.forEach(t),Ii.forEach(t),Wio=i(c),Gc=n(c,"H2",{class:!0});var pco=s(Gc);y6=n(pco,"A",{id:!0,class:!0,href:!0});var o4a=s(y6);rke=n(o4a,"SPAN",{});var r4a=s(rke);T(aB.$$.fragment,r4a),r4a.forEach(t),o4a.forEach(t),sdt=i(pco),tke=n(pco,"SPAN",{});var t4a=s(tke);ldt=r(t4a,"TFAutoModelForSequenceClassification"),t4a.forEach(t),pco.forEach(t),Uio=i(c),Tr=n(c,"DIV",{class:!0});var qi=s(Tr);T(nB.$$.fragment,qi),idt=i(qi),Oc=n(qi,"P",{});var wge=s(Oc);ddt=r(wge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),lle=n(wge,"A",{href:!0});var a4a=s(lle);mdt=r(a4a,"from_pretrained()"),a4a.forEach(t),cdt=r(wge," class method or the "),ile=n(wge,"A",{href:!0});var n4a=s(ile);fdt=r(n4a,"from_config()"),n4a.forEach(t),gdt=r(wge,` class
method.`),wge.forEach(t),hdt=i(qi),sB=n(qi,"P",{});var _co=s(sB);udt=r(_co,"This class cannot be instantiated directly using "),ake=n(_co,"CODE",{});var s4a=s(ake);pdt=r(s4a,"__init__()"),s4a.forEach(t),_dt=r(_co," (throws an error)."),_co.forEach(t),bdt=i(qi),ia=n(qi,"DIV",{class:!0});var F$=s(ia);T(lB.$$.fragment,F$),vdt=i(F$),nke=n(F$,"P",{});var l4a=s(nke);Fdt=r(l4a,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),l4a.forEach(t),Tdt=i(F$),Vc=n(F$,"P",{});var Age=s(Vc);Mdt=r(Age,`Note:
Loading a model from its configuration file does `),ske=n(Age,"STRONG",{});var i4a=s(ske);Edt=r(i4a,"not"),i4a.forEach(t),Cdt=r(Age,` load the model weights. It only affects the
model\u2019s configuration. Use `),dle=n(Age,"A",{href:!0});var d4a=s(dle);wdt=r(d4a,"from_pretrained()"),d4a.forEach(t),Adt=r(Age," to load the model weights."),Age.forEach(t),Ldt=i(F$),T(x6.$$.fragment,F$),F$.forEach(t),ydt=i(qi),Yr=n(qi,"DIV",{class:!0});var Di=s(Yr);T(iB.$$.fragment,Di),xdt=i(Di),lke=n(Di,"P",{});var m4a=s(lke);$dt=r(m4a,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),m4a.forEach(t),kdt=i(Di),Un=n(Di,"P",{});var T$=s(Un);Sdt=r(T$,"The model class to instantiate is selected based on the "),ike=n(T$,"CODE",{});var c4a=s(ike);Rdt=r(c4a,"model_type"),c4a.forEach(t),Pdt=r(T$,` property of the config object (either
passed as an argument or loaded from `),dke=n(T$,"CODE",{});var f4a=s(dke);Bdt=r(f4a,"pretrained_model_name_or_path"),f4a.forEach(t),Idt=r(T$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mke=n(T$,"CODE",{});var g4a=s(mke);Ndt=r(g4a,"pretrained_model_name_or_path"),g4a.forEach(t),qdt=r(T$,":"),T$.forEach(t),Ddt=i(Di),te=n(Di,"UL",{});var se=s(te);$6=n(se,"LI",{});var Lto=s($6);cke=n(Lto,"STRONG",{});var h4a=s(cke);jdt=r(h4a,"albert"),h4a.forEach(t),Gdt=r(Lto," \u2014 "),mle=n(Lto,"A",{href:!0});var u4a=s(mle);Odt=r(u4a,"TFAlbertForSequenceClassification"),u4a.forEach(t),Vdt=r(Lto," (ALBERT model)"),Lto.forEach(t),Xdt=i(se),k6=n(se,"LI",{});var yto=s(k6);fke=n(yto,"STRONG",{});var p4a=s(fke);zdt=r(p4a,"bert"),p4a.forEach(t),Qdt=r(yto," \u2014 "),cle=n(yto,"A",{href:!0});var _4a=s(cle);Wdt=r(_4a,"TFBertForSequenceClassification"),_4a.forEach(t),Udt=r(yto," (BERT model)"),yto.forEach(t),Hdt=i(se),S6=n(se,"LI",{});var xto=s(S6);gke=n(xto,"STRONG",{});var b4a=s(gke);Jdt=r(b4a,"camembert"),b4a.forEach(t),Ydt=r(xto," \u2014 "),fle=n(xto,"A",{href:!0});var v4a=s(fle);Zdt=r(v4a,"TFCamembertForSequenceClassification"),v4a.forEach(t),Kdt=r(xto," (CamemBERT model)"),xto.forEach(t),emt=i(se),R6=n(se,"LI",{});var $to=s(R6);hke=n($to,"STRONG",{});var F4a=s(hke);omt=r(F4a,"convbert"),F4a.forEach(t),rmt=r($to," \u2014 "),gle=n($to,"A",{href:!0});var T4a=s(gle);tmt=r(T4a,"TFConvBertForSequenceClassification"),T4a.forEach(t),amt=r($to," (ConvBERT model)"),$to.forEach(t),nmt=i(se),P6=n(se,"LI",{});var kto=s(P6);uke=n(kto,"STRONG",{});var M4a=s(uke);smt=r(M4a,"ctrl"),M4a.forEach(t),lmt=r(kto," \u2014 "),hle=n(kto,"A",{href:!0});var E4a=s(hle);imt=r(E4a,"TFCTRLForSequenceClassification"),E4a.forEach(t),dmt=r(kto," (CTRL model)"),kto.forEach(t),mmt=i(se),B6=n(se,"LI",{});var Sto=s(B6);pke=n(Sto,"STRONG",{});var C4a=s(pke);cmt=r(C4a,"deberta"),C4a.forEach(t),fmt=r(Sto," \u2014 "),ule=n(Sto,"A",{href:!0});var w4a=s(ule);gmt=r(w4a,"TFDebertaForSequenceClassification"),w4a.forEach(t),hmt=r(Sto," (DeBERTa model)"),Sto.forEach(t),umt=i(se),I6=n(se,"LI",{});var Rto=s(I6);_ke=n(Rto,"STRONG",{});var A4a=s(_ke);pmt=r(A4a,"deberta-v2"),A4a.forEach(t),_mt=r(Rto," \u2014 "),ple=n(Rto,"A",{href:!0});var L4a=s(ple);bmt=r(L4a,"TFDebertaV2ForSequenceClassification"),L4a.forEach(t),vmt=r(Rto," (DeBERTa-v2 model)"),Rto.forEach(t),Fmt=i(se),N6=n(se,"LI",{});var Pto=s(N6);bke=n(Pto,"STRONG",{});var y4a=s(bke);Tmt=r(y4a,"distilbert"),y4a.forEach(t),Mmt=r(Pto," \u2014 "),_le=n(Pto,"A",{href:!0});var x4a=s(_le);Emt=r(x4a,"TFDistilBertForSequenceClassification"),x4a.forEach(t),Cmt=r(Pto," (DistilBERT model)"),Pto.forEach(t),wmt=i(se),q6=n(se,"LI",{});var Bto=s(q6);vke=n(Bto,"STRONG",{});var $4a=s(vke);Amt=r($4a,"electra"),$4a.forEach(t),Lmt=r(Bto," \u2014 "),ble=n(Bto,"A",{href:!0});var k4a=s(ble);ymt=r(k4a,"TFElectraForSequenceClassification"),k4a.forEach(t),xmt=r(Bto," (ELECTRA model)"),Bto.forEach(t),$mt=i(se),D6=n(se,"LI",{});var Ito=s(D6);Fke=n(Ito,"STRONG",{});var S4a=s(Fke);kmt=r(S4a,"esm"),S4a.forEach(t),Smt=r(Ito," \u2014 "),vle=n(Ito,"A",{href:!0});var R4a=s(vle);Rmt=r(R4a,"TFEsmForSequenceClassification"),R4a.forEach(t),Pmt=r(Ito," (ESM model)"),Ito.forEach(t),Bmt=i(se),j6=n(se,"LI",{});var Nto=s(j6);Tke=n(Nto,"STRONG",{});var P4a=s(Tke);Imt=r(P4a,"flaubert"),P4a.forEach(t),Nmt=r(Nto," \u2014 "),Fle=n(Nto,"A",{href:!0});var B4a=s(Fle);qmt=r(B4a,"TFFlaubertForSequenceClassification"),B4a.forEach(t),Dmt=r(Nto," (FlauBERT model)"),Nto.forEach(t),jmt=i(se),G6=n(se,"LI",{});var qto=s(G6);Mke=n(qto,"STRONG",{});var I4a=s(Mke);Gmt=r(I4a,"funnel"),I4a.forEach(t),Omt=r(qto," \u2014 "),Tle=n(qto,"A",{href:!0});var N4a=s(Tle);Vmt=r(N4a,"TFFunnelForSequenceClassification"),N4a.forEach(t),Xmt=r(qto," (Funnel Transformer model)"),qto.forEach(t),zmt=i(se),O6=n(se,"LI",{});var Dto=s(O6);Eke=n(Dto,"STRONG",{});var q4a=s(Eke);Qmt=r(q4a,"gpt2"),q4a.forEach(t),Wmt=r(Dto," \u2014 "),Mle=n(Dto,"A",{href:!0});var D4a=s(Mle);Umt=r(D4a,"TFGPT2ForSequenceClassification"),D4a.forEach(t),Hmt=r(Dto," (OpenAI GPT-2 model)"),Dto.forEach(t),Jmt=i(se),V6=n(se,"LI",{});var jto=s(V6);Cke=n(jto,"STRONG",{});var j4a=s(Cke);Ymt=r(j4a,"gptj"),j4a.forEach(t),Zmt=r(jto," \u2014 "),Ele=n(jto,"A",{href:!0});var G4a=s(Ele);Kmt=r(G4a,"TFGPTJForSequenceClassification"),G4a.forEach(t),ect=r(jto," (GPT-J model)"),jto.forEach(t),oct=i(se),X6=n(se,"LI",{});var Gto=s(X6);wke=n(Gto,"STRONG",{});var O4a=s(wke);rct=r(O4a,"layoutlm"),O4a.forEach(t),tct=r(Gto," \u2014 "),Cle=n(Gto,"A",{href:!0});var V4a=s(Cle);act=r(V4a,"TFLayoutLMForSequenceClassification"),V4a.forEach(t),nct=r(Gto," (LayoutLM model)"),Gto.forEach(t),sct=i(se),z6=n(se,"LI",{});var Oto=s(z6);Ake=n(Oto,"STRONG",{});var X4a=s(Ake);lct=r(X4a,"layoutlmv3"),X4a.forEach(t),ict=r(Oto," \u2014 "),wle=n(Oto,"A",{href:!0});var z4a=s(wle);dct=r(z4a,"TFLayoutLMv3ForSequenceClassification"),z4a.forEach(t),mct=r(Oto," (LayoutLMv3 model)"),Oto.forEach(t),cct=i(se),Q6=n(se,"LI",{});var Vto=s(Q6);Lke=n(Vto,"STRONG",{});var Q4a=s(Lke);fct=r(Q4a,"longformer"),Q4a.forEach(t),gct=r(Vto," \u2014 "),Ale=n(Vto,"A",{href:!0});var W4a=s(Ale);hct=r(W4a,"TFLongformerForSequenceClassification"),W4a.forEach(t),uct=r(Vto," (Longformer model)"),Vto.forEach(t),pct=i(se),W6=n(se,"LI",{});var Xto=s(W6);yke=n(Xto,"STRONG",{});var U4a=s(yke);_ct=r(U4a,"mobilebert"),U4a.forEach(t),bct=r(Xto," \u2014 "),Lle=n(Xto,"A",{href:!0});var H4a=s(Lle);vct=r(H4a,"TFMobileBertForSequenceClassification"),H4a.forEach(t),Fct=r(Xto," (MobileBERT model)"),Xto.forEach(t),Tct=i(se),U6=n(se,"LI",{});var zto=s(U6);xke=n(zto,"STRONG",{});var J4a=s(xke);Mct=r(J4a,"mpnet"),J4a.forEach(t),Ect=r(zto," \u2014 "),yle=n(zto,"A",{href:!0});var Y4a=s(yle);Cct=r(Y4a,"TFMPNetForSequenceClassification"),Y4a.forEach(t),wct=r(zto," (MPNet model)"),zto.forEach(t),Act=i(se),H6=n(se,"LI",{});var Qto=s(H6);$ke=n(Qto,"STRONG",{});var Z4a=s($ke);Lct=r(Z4a,"openai-gpt"),Z4a.forEach(t),yct=r(Qto," \u2014 "),xle=n(Qto,"A",{href:!0});var K4a=s(xle);xct=r(K4a,"TFOpenAIGPTForSequenceClassification"),K4a.forEach(t),$ct=r(Qto," (OpenAI GPT model)"),Qto.forEach(t),kct=i(se),J6=n(se,"LI",{});var Wto=s(J6);kke=n(Wto,"STRONG",{});var eCa=s(kke);Sct=r(eCa,"rembert"),eCa.forEach(t),Rct=r(Wto," \u2014 "),$le=n(Wto,"A",{href:!0});var oCa=s($le);Pct=r(oCa,"TFRemBertForSequenceClassification"),oCa.forEach(t),Bct=r(Wto," (RemBERT model)"),Wto.forEach(t),Ict=i(se),Y6=n(se,"LI",{});var Uto=s(Y6);Ske=n(Uto,"STRONG",{});var rCa=s(Ske);Nct=r(rCa,"roberta"),rCa.forEach(t),qct=r(Uto," \u2014 "),kle=n(Uto,"A",{href:!0});var tCa=s(kle);Dct=r(tCa,"TFRobertaForSequenceClassification"),tCa.forEach(t),jct=r(Uto," (RoBERTa model)"),Uto.forEach(t),Gct=i(se),Z6=n(se,"LI",{});var Hto=s(Z6);Rke=n(Hto,"STRONG",{});var aCa=s(Rke);Oct=r(aCa,"roformer"),aCa.forEach(t),Vct=r(Hto," \u2014 "),Sle=n(Hto,"A",{href:!0});var nCa=s(Sle);Xct=r(nCa,"TFRoFormerForSequenceClassification"),nCa.forEach(t),zct=r(Hto," (RoFormer model)"),Hto.forEach(t),Qct=i(se),K6=n(se,"LI",{});var Jto=s(K6);Pke=n(Jto,"STRONG",{});var sCa=s(Pke);Wct=r(sCa,"tapas"),sCa.forEach(t),Uct=r(Jto," \u2014 "),Rle=n(Jto,"A",{href:!0});var lCa=s(Rle);Hct=r(lCa,"TFTapasForSequenceClassification"),lCa.forEach(t),Jct=r(Jto," (TAPAS model)"),Jto.forEach(t),Yct=i(se),e7=n(se,"LI",{});var Yto=s(e7);Bke=n(Yto,"STRONG",{});var iCa=s(Bke);Zct=r(iCa,"transfo-xl"),iCa.forEach(t),Kct=r(Yto," \u2014 "),Ple=n(Yto,"A",{href:!0});var dCa=s(Ple);eft=r(dCa,"TFTransfoXLForSequenceClassification"),dCa.forEach(t),oft=r(Yto," (Transformer-XL model)"),Yto.forEach(t),rft=i(se),o7=n(se,"LI",{});var Zto=s(o7);Ike=n(Zto,"STRONG",{});var mCa=s(Ike);tft=r(mCa,"xlm"),mCa.forEach(t),aft=r(Zto," \u2014 "),Ble=n(Zto,"A",{href:!0});var cCa=s(Ble);nft=r(cCa,"TFXLMForSequenceClassification"),cCa.forEach(t),sft=r(Zto," (XLM model)"),Zto.forEach(t),lft=i(se),r7=n(se,"LI",{});var Kto=s(r7);Nke=n(Kto,"STRONG",{});var fCa=s(Nke);ift=r(fCa,"xlm-roberta"),fCa.forEach(t),dft=r(Kto," \u2014 "),Ile=n(Kto,"A",{href:!0});var gCa=s(Ile);mft=r(gCa,"TFXLMRobertaForSequenceClassification"),gCa.forEach(t),cft=r(Kto," (XLM-RoBERTa model)"),Kto.forEach(t),fft=i(se),t7=n(se,"LI",{});var eao=s(t7);qke=n(eao,"STRONG",{});var hCa=s(qke);gft=r(hCa,"xlnet"),hCa.forEach(t),hft=r(eao," \u2014 "),Nle=n(eao,"A",{href:!0});var uCa=s(Nle);uft=r(uCa,"TFXLNetForSequenceClassification"),uCa.forEach(t),pft=r(eao," (XLNet model)"),eao.forEach(t),se.forEach(t),_ft=i(Di),T(a7.$$.fragment,Di),Di.forEach(t),qi.forEach(t),Hio=i(c),Xc=n(c,"H2",{class:!0});var bco=s(Xc);n7=n(bco,"A",{id:!0,class:!0,href:!0});var pCa=s(n7);Dke=n(pCa,"SPAN",{});var _Ca=s(Dke);T(dB.$$.fragment,_Ca),_Ca.forEach(t),pCa.forEach(t),bft=i(bco),jke=n(bco,"SPAN",{});var bCa=s(jke);vft=r(bCa,"TFAutoModelForMultipleChoice"),bCa.forEach(t),bco.forEach(t),Jio=i(c),Mr=n(c,"DIV",{class:!0});var ji=s(Mr);T(mB.$$.fragment,ji),Fft=i(ji),zc=n(ji,"P",{});var Lge=s(zc);Tft=r(Lge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),qle=n(Lge,"A",{href:!0});var vCa=s(qle);Mft=r(vCa,"from_pretrained()"),vCa.forEach(t),Eft=r(Lge," class method or the "),Dle=n(Lge,"A",{href:!0});var FCa=s(Dle);Cft=r(FCa,"from_config()"),FCa.forEach(t),wft=r(Lge,` class
method.`),Lge.forEach(t),Aft=i(ji),cB=n(ji,"P",{});var vco=s(cB);Lft=r(vco,"This class cannot be instantiated directly using "),Gke=n(vco,"CODE",{});var TCa=s(Gke);yft=r(TCa,"__init__()"),TCa.forEach(t),xft=r(vco," (throws an error)."),vco.forEach(t),$ft=i(ji),da=n(ji,"DIV",{class:!0});var M$=s(da);T(fB.$$.fragment,M$),kft=i(M$),Oke=n(M$,"P",{});var MCa=s(Oke);Sft=r(MCa,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),MCa.forEach(t),Rft=i(M$),Qc=n(M$,"P",{});var yge=s(Qc);Pft=r(yge,`Note:
Loading a model from its configuration file does `),Vke=n(yge,"STRONG",{});var ECa=s(Vke);Bft=r(ECa,"not"),ECa.forEach(t),Ift=r(yge,` load the model weights. It only affects the
model\u2019s configuration. Use `),jle=n(yge,"A",{href:!0});var CCa=s(jle);Nft=r(CCa,"from_pretrained()"),CCa.forEach(t),qft=r(yge," to load the model weights."),yge.forEach(t),Dft=i(M$),T(s7.$$.fragment,M$),M$.forEach(t),jft=i(ji),Zr=n(ji,"DIV",{class:!0});var Gi=s(Zr);T(gB.$$.fragment,Gi),Gft=i(Gi),Xke=n(Gi,"P",{});var wCa=s(Xke);Oft=r(wCa,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),wCa.forEach(t),Vft=i(Gi),Hn=n(Gi,"P",{});var E$=s(Hn);Xft=r(E$,"The model class to instantiate is selected based on the "),zke=n(E$,"CODE",{});var ACa=s(zke);zft=r(ACa,"model_type"),ACa.forEach(t),Qft=r(E$,` property of the config object (either
passed as an argument or loaded from `),Qke=n(E$,"CODE",{});var LCa=s(Qke);Wft=r(LCa,"pretrained_model_name_or_path"),LCa.forEach(t),Uft=r(E$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wke=n(E$,"CODE",{});var yCa=s(Wke);Hft=r(yCa,"pretrained_model_name_or_path"),yCa.forEach(t),Jft=r(E$,":"),E$.forEach(t),Yft=i(Gi),Te=n(Gi,"UL",{});var Ee=s(Te);l7=n(Ee,"LI",{});var oao=s(l7);Uke=n(oao,"STRONG",{});var xCa=s(Uke);Zft=r(xCa,"albert"),xCa.forEach(t),Kft=r(oao," \u2014 "),Gle=n(oao,"A",{href:!0});var $Ca=s(Gle);egt=r($Ca,"TFAlbertForMultipleChoice"),$Ca.forEach(t),ogt=r(oao," (ALBERT model)"),oao.forEach(t),rgt=i(Ee),i7=n(Ee,"LI",{});var rao=s(i7);Hke=n(rao,"STRONG",{});var kCa=s(Hke);tgt=r(kCa,"bert"),kCa.forEach(t),agt=r(rao," \u2014 "),Ole=n(rao,"A",{href:!0});var SCa=s(Ole);ngt=r(SCa,"TFBertForMultipleChoice"),SCa.forEach(t),sgt=r(rao," (BERT model)"),rao.forEach(t),lgt=i(Ee),d7=n(Ee,"LI",{});var tao=s(d7);Jke=n(tao,"STRONG",{});var RCa=s(Jke);igt=r(RCa,"camembert"),RCa.forEach(t),dgt=r(tao," \u2014 "),Vle=n(tao,"A",{href:!0});var PCa=s(Vle);mgt=r(PCa,"TFCamembertForMultipleChoice"),PCa.forEach(t),cgt=r(tao," (CamemBERT model)"),tao.forEach(t),fgt=i(Ee),m7=n(Ee,"LI",{});var aao=s(m7);Yke=n(aao,"STRONG",{});var BCa=s(Yke);ggt=r(BCa,"convbert"),BCa.forEach(t),hgt=r(aao," \u2014 "),Xle=n(aao,"A",{href:!0});var ICa=s(Xle);ugt=r(ICa,"TFConvBertForMultipleChoice"),ICa.forEach(t),pgt=r(aao," (ConvBERT model)"),aao.forEach(t),_gt=i(Ee),c7=n(Ee,"LI",{});var nao=s(c7);Zke=n(nao,"STRONG",{});var NCa=s(Zke);bgt=r(NCa,"distilbert"),NCa.forEach(t),vgt=r(nao," \u2014 "),zle=n(nao,"A",{href:!0});var qCa=s(zle);Fgt=r(qCa,"TFDistilBertForMultipleChoice"),qCa.forEach(t),Tgt=r(nao," (DistilBERT model)"),nao.forEach(t),Mgt=i(Ee),f7=n(Ee,"LI",{});var sao=s(f7);Kke=n(sao,"STRONG",{});var DCa=s(Kke);Egt=r(DCa,"electra"),DCa.forEach(t),Cgt=r(sao," \u2014 "),Qle=n(sao,"A",{href:!0});var jCa=s(Qle);wgt=r(jCa,"TFElectraForMultipleChoice"),jCa.forEach(t),Agt=r(sao," (ELECTRA model)"),sao.forEach(t),Lgt=i(Ee),g7=n(Ee,"LI",{});var lao=s(g7);eSe=n(lao,"STRONG",{});var GCa=s(eSe);ygt=r(GCa,"flaubert"),GCa.forEach(t),xgt=r(lao," \u2014 "),Wle=n(lao,"A",{href:!0});var OCa=s(Wle);$gt=r(OCa,"TFFlaubertForMultipleChoice"),OCa.forEach(t),kgt=r(lao," (FlauBERT model)"),lao.forEach(t),Sgt=i(Ee),h7=n(Ee,"LI",{});var iao=s(h7);oSe=n(iao,"STRONG",{});var VCa=s(oSe);Rgt=r(VCa,"funnel"),VCa.forEach(t),Pgt=r(iao," \u2014 "),Ule=n(iao,"A",{href:!0});var XCa=s(Ule);Bgt=r(XCa,"TFFunnelForMultipleChoice"),XCa.forEach(t),Igt=r(iao," (Funnel Transformer model)"),iao.forEach(t),Ngt=i(Ee),u7=n(Ee,"LI",{});var dao=s(u7);rSe=n(dao,"STRONG",{});var zCa=s(rSe);qgt=r(zCa,"longformer"),zCa.forEach(t),Dgt=r(dao," \u2014 "),Hle=n(dao,"A",{href:!0});var QCa=s(Hle);jgt=r(QCa,"TFLongformerForMultipleChoice"),QCa.forEach(t),Ggt=r(dao," (Longformer model)"),dao.forEach(t),Ogt=i(Ee),p7=n(Ee,"LI",{});var mao=s(p7);tSe=n(mao,"STRONG",{});var WCa=s(tSe);Vgt=r(WCa,"mobilebert"),WCa.forEach(t),Xgt=r(mao," \u2014 "),Jle=n(mao,"A",{href:!0});var UCa=s(Jle);zgt=r(UCa,"TFMobileBertForMultipleChoice"),UCa.forEach(t),Qgt=r(mao," (MobileBERT model)"),mao.forEach(t),Wgt=i(Ee),_7=n(Ee,"LI",{});var cao=s(_7);aSe=n(cao,"STRONG",{});var HCa=s(aSe);Ugt=r(HCa,"mpnet"),HCa.forEach(t),Hgt=r(cao," \u2014 "),Yle=n(cao,"A",{href:!0});var JCa=s(Yle);Jgt=r(JCa,"TFMPNetForMultipleChoice"),JCa.forEach(t),Ygt=r(cao," (MPNet model)"),cao.forEach(t),Zgt=i(Ee),b7=n(Ee,"LI",{});var fao=s(b7);nSe=n(fao,"STRONG",{});var YCa=s(nSe);Kgt=r(YCa,"rembert"),YCa.forEach(t),eht=r(fao," \u2014 "),Zle=n(fao,"A",{href:!0});var ZCa=s(Zle);oht=r(ZCa,"TFRemBertForMultipleChoice"),ZCa.forEach(t),rht=r(fao," (RemBERT model)"),fao.forEach(t),tht=i(Ee),v7=n(Ee,"LI",{});var gao=s(v7);sSe=n(gao,"STRONG",{});var KCa=s(sSe);aht=r(KCa,"roberta"),KCa.forEach(t),nht=r(gao," \u2014 "),Kle=n(gao,"A",{href:!0});var e3a=s(Kle);sht=r(e3a,"TFRobertaForMultipleChoice"),e3a.forEach(t),lht=r(gao," (RoBERTa model)"),gao.forEach(t),iht=i(Ee),F7=n(Ee,"LI",{});var hao=s(F7);lSe=n(hao,"STRONG",{});var o3a=s(lSe);dht=r(o3a,"roformer"),o3a.forEach(t),mht=r(hao," \u2014 "),eie=n(hao,"A",{href:!0});var r3a=s(eie);cht=r(r3a,"TFRoFormerForMultipleChoice"),r3a.forEach(t),fht=r(hao," (RoFormer model)"),hao.forEach(t),ght=i(Ee),T7=n(Ee,"LI",{});var uao=s(T7);iSe=n(uao,"STRONG",{});var t3a=s(iSe);hht=r(t3a,"xlm"),t3a.forEach(t),uht=r(uao," \u2014 "),oie=n(uao,"A",{href:!0});var a3a=s(oie);pht=r(a3a,"TFXLMForMultipleChoice"),a3a.forEach(t),_ht=r(uao," (XLM model)"),uao.forEach(t),bht=i(Ee),M7=n(Ee,"LI",{});var pao=s(M7);dSe=n(pao,"STRONG",{});var n3a=s(dSe);vht=r(n3a,"xlm-roberta"),n3a.forEach(t),Fht=r(pao," \u2014 "),rie=n(pao,"A",{href:!0});var s3a=s(rie);Tht=r(s3a,"TFXLMRobertaForMultipleChoice"),s3a.forEach(t),Mht=r(pao," (XLM-RoBERTa model)"),pao.forEach(t),Eht=i(Ee),E7=n(Ee,"LI",{});var _ao=s(E7);mSe=n(_ao,"STRONG",{});var l3a=s(mSe);Cht=r(l3a,"xlnet"),l3a.forEach(t),wht=r(_ao," \u2014 "),tie=n(_ao,"A",{href:!0});var i3a=s(tie);Aht=r(i3a,"TFXLNetForMultipleChoice"),i3a.forEach(t),Lht=r(_ao," (XLNet model)"),_ao.forEach(t),Ee.forEach(t),yht=i(Gi),T(C7.$$.fragment,Gi),Gi.forEach(t),ji.forEach(t),Yio=i(c),Wc=n(c,"H2",{class:!0});var Fco=s(Wc);w7=n(Fco,"A",{id:!0,class:!0,href:!0});var d3a=s(w7);cSe=n(d3a,"SPAN",{});var m3a=s(cSe);T(hB.$$.fragment,m3a),m3a.forEach(t),d3a.forEach(t),xht=i(Fco),fSe=n(Fco,"SPAN",{});var c3a=s(fSe);$ht=r(c3a,"TFAutoModelForNextSentencePrediction"),c3a.forEach(t),Fco.forEach(t),Zio=i(c),Er=n(c,"DIV",{class:!0});var Oi=s(Er);T(uB.$$.fragment,Oi),kht=i(Oi),Uc=n(Oi,"P",{});var xge=s(Uc);Sht=r(xge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),aie=n(xge,"A",{href:!0});var f3a=s(aie);Rht=r(f3a,"from_pretrained()"),f3a.forEach(t),Pht=r(xge," class method or the "),nie=n(xge,"A",{href:!0});var g3a=s(nie);Bht=r(g3a,"from_config()"),g3a.forEach(t),Iht=r(xge,` class
method.`),xge.forEach(t),Nht=i(Oi),pB=n(Oi,"P",{});var Tco=s(pB);qht=r(Tco,"This class cannot be instantiated directly using "),gSe=n(Tco,"CODE",{});var h3a=s(gSe);Dht=r(h3a,"__init__()"),h3a.forEach(t),jht=r(Tco," (throws an error)."),Tco.forEach(t),Ght=i(Oi),ma=n(Oi,"DIV",{class:!0});var C$=s(ma);T(_B.$$.fragment,C$),Oht=i(C$),hSe=n(C$,"P",{});var u3a=s(hSe);Vht=r(u3a,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),u3a.forEach(t),Xht=i(C$),Hc=n(C$,"P",{});var $ge=s(Hc);zht=r($ge,`Note:
Loading a model from its configuration file does `),uSe=n($ge,"STRONG",{});var p3a=s(uSe);Qht=r(p3a,"not"),p3a.forEach(t),Wht=r($ge,` load the model weights. It only affects the
model\u2019s configuration. Use `),sie=n($ge,"A",{href:!0});var _3a=s(sie);Uht=r(_3a,"from_pretrained()"),_3a.forEach(t),Hht=r($ge," to load the model weights."),$ge.forEach(t),Jht=i(C$),T(A7.$$.fragment,C$),C$.forEach(t),Yht=i(Oi),Kr=n(Oi,"DIV",{class:!0});var Vi=s(Kr);T(bB.$$.fragment,Vi),Zht=i(Vi),pSe=n(Vi,"P",{});var b3a=s(pSe);Kht=r(b3a,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),b3a.forEach(t),eut=i(Vi),Jn=n(Vi,"P",{});var w$=s(Jn);out=r(w$,"The model class to instantiate is selected based on the "),_Se=n(w$,"CODE",{});var v3a=s(_Se);rut=r(v3a,"model_type"),v3a.forEach(t),tut=r(w$,` property of the config object (either
passed as an argument or loaded from `),bSe=n(w$,"CODE",{});var F3a=s(bSe);aut=r(F3a,"pretrained_model_name_or_path"),F3a.forEach(t),nut=r(w$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vSe=n(w$,"CODE",{});var T3a=s(vSe);sut=r(T3a,"pretrained_model_name_or_path"),T3a.forEach(t),lut=r(w$,":"),w$.forEach(t),iut=i(Vi),vB=n(Vi,"UL",{});var Mco=s(vB);L7=n(Mco,"LI",{});var bao=s(L7);FSe=n(bao,"STRONG",{});var M3a=s(FSe);dut=r(M3a,"bert"),M3a.forEach(t),mut=r(bao," \u2014 "),lie=n(bao,"A",{href:!0});var E3a=s(lie);cut=r(E3a,"TFBertForNextSentencePrediction"),E3a.forEach(t),fut=r(bao," (BERT model)"),bao.forEach(t),gut=i(Mco),y7=n(Mco,"LI",{});var vao=s(y7);TSe=n(vao,"STRONG",{});var C3a=s(TSe);hut=r(C3a,"mobilebert"),C3a.forEach(t),uut=r(vao," \u2014 "),iie=n(vao,"A",{href:!0});var w3a=s(iie);put=r(w3a,"TFMobileBertForNextSentencePrediction"),w3a.forEach(t),_ut=r(vao," (MobileBERT model)"),vao.forEach(t),Mco.forEach(t),but=i(Vi),T(x7.$$.fragment,Vi),Vi.forEach(t),Oi.forEach(t),Kio=i(c),Jc=n(c,"H2",{class:!0});var Eco=s(Jc);$7=n(Eco,"A",{id:!0,class:!0,href:!0});var A3a=s($7);MSe=n(A3a,"SPAN",{});var L3a=s(MSe);T(FB.$$.fragment,L3a),L3a.forEach(t),A3a.forEach(t),vut=i(Eco),ESe=n(Eco,"SPAN",{});var y3a=s(ESe);Fut=r(y3a,"TFAutoModelForTableQuestionAnswering"),y3a.forEach(t),Eco.forEach(t),edo=i(c),Cr=n(c,"DIV",{class:!0});var Xi=s(Cr);T(TB.$$.fragment,Xi),Tut=i(Xi),Yc=n(Xi,"P",{});var kge=s(Yc);Mut=r(kge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),die=n(kge,"A",{href:!0});var x3a=s(die);Eut=r(x3a,"from_pretrained()"),x3a.forEach(t),Cut=r(kge," class method or the "),mie=n(kge,"A",{href:!0});var $3a=s(mie);wut=r($3a,"from_config()"),$3a.forEach(t),Aut=r(kge,` class
method.`),kge.forEach(t),Lut=i(Xi),MB=n(Xi,"P",{});var Cco=s(MB);yut=r(Cco,"This class cannot be instantiated directly using "),CSe=n(Cco,"CODE",{});var k3a=s(CSe);xut=r(k3a,"__init__()"),k3a.forEach(t),$ut=r(Cco," (throws an error)."),Cco.forEach(t),kut=i(Xi),ca=n(Xi,"DIV",{class:!0});var A$=s(ca);T(EB.$$.fragment,A$),Sut=i(A$),wSe=n(A$,"P",{});var S3a=s(wSe);Rut=r(S3a,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),S3a.forEach(t),Put=i(A$),Zc=n(A$,"P",{});var Sge=s(Zc);But=r(Sge,`Note:
Loading a model from its configuration file does `),ASe=n(Sge,"STRONG",{});var R3a=s(ASe);Iut=r(R3a,"not"),R3a.forEach(t),Nut=r(Sge,` load the model weights. It only affects the
model\u2019s configuration. Use `),cie=n(Sge,"A",{href:!0});var P3a=s(cie);qut=r(P3a,"from_pretrained()"),P3a.forEach(t),Dut=r(Sge," to load the model weights."),Sge.forEach(t),jut=i(A$),T(k7.$$.fragment,A$),A$.forEach(t),Gut=i(Xi),et=n(Xi,"DIV",{class:!0});var zi=s(et);T(CB.$$.fragment,zi),Out=i(zi),LSe=n(zi,"P",{});var B3a=s(LSe);Vut=r(B3a,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),B3a.forEach(t),Xut=i(zi),Yn=n(zi,"P",{});var L$=s(Yn);zut=r(L$,"The model class to instantiate is selected based on the "),ySe=n(L$,"CODE",{});var I3a=s(ySe);Qut=r(I3a,"model_type"),I3a.forEach(t),Wut=r(L$,` property of the config object (either
passed as an argument or loaded from `),xSe=n(L$,"CODE",{});var N3a=s(xSe);Uut=r(N3a,"pretrained_model_name_or_path"),N3a.forEach(t),Hut=r(L$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$Se=n(L$,"CODE",{});var q3a=s($Se);Jut=r(q3a,"pretrained_model_name_or_path"),q3a.forEach(t),Yut=r(L$,":"),L$.forEach(t),Zut=i(zi),kSe=n(zi,"UL",{});var D3a=s(kSe);S7=n(D3a,"LI",{});var Fao=s(S7);SSe=n(Fao,"STRONG",{});var j3a=s(SSe);Kut=r(j3a,"tapas"),j3a.forEach(t),ept=r(Fao," \u2014 "),fie=n(Fao,"A",{href:!0});var G3a=s(fie);opt=r(G3a,"TFTapasForQuestionAnswering"),G3a.forEach(t),rpt=r(Fao," (TAPAS model)"),Fao.forEach(t),D3a.forEach(t),tpt=i(zi),T(R7.$$.fragment,zi),zi.forEach(t),Xi.forEach(t),odo=i(c),Kc=n(c,"H2",{class:!0});var wco=s(Kc);P7=n(wco,"A",{id:!0,class:!0,href:!0});var O3a=s(P7);RSe=n(O3a,"SPAN",{});var V3a=s(RSe);T(wB.$$.fragment,V3a),V3a.forEach(t),O3a.forEach(t),apt=i(wco),PSe=n(wco,"SPAN",{});var X3a=s(PSe);npt=r(X3a,"TFAutoModelForDocumentQuestionAnswering"),X3a.forEach(t),wco.forEach(t),rdo=i(c),wr=n(c,"DIV",{class:!0});var Qi=s(wr);T(AB.$$.fragment,Qi),spt=i(Qi),ef=n(Qi,"P",{});var Rge=s(ef);lpt=r(Rge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),gie=n(Rge,"A",{href:!0});var z3a=s(gie);ipt=r(z3a,"from_pretrained()"),z3a.forEach(t),dpt=r(Rge," class method or the "),hie=n(Rge,"A",{href:!0});var Q3a=s(hie);mpt=r(Q3a,"from_config()"),Q3a.forEach(t),cpt=r(Rge,` class
method.`),Rge.forEach(t),fpt=i(Qi),LB=n(Qi,"P",{});var Aco=s(LB);gpt=r(Aco,"This class cannot be instantiated directly using "),BSe=n(Aco,"CODE",{});var W3a=s(BSe);hpt=r(W3a,"__init__()"),W3a.forEach(t),upt=r(Aco," (throws an error)."),Aco.forEach(t),ppt=i(Qi),fa=n(Qi,"DIV",{class:!0});var y$=s(fa);T(yB.$$.fragment,y$),_pt=i(y$),ISe=n(y$,"P",{});var U3a=s(ISe);bpt=r(U3a,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),U3a.forEach(t),vpt=i(y$),of=n(y$,"P",{});var Pge=s(of);Fpt=r(Pge,`Note:
Loading a model from its configuration file does `),NSe=n(Pge,"STRONG",{});var H3a=s(NSe);Tpt=r(H3a,"not"),H3a.forEach(t),Mpt=r(Pge,` load the model weights. It only affects the
model\u2019s configuration. Use `),uie=n(Pge,"A",{href:!0});var J3a=s(uie);Ept=r(J3a,"from_pretrained()"),J3a.forEach(t),Cpt=r(Pge," to load the model weights."),Pge.forEach(t),wpt=i(y$),T(B7.$$.fragment,y$),y$.forEach(t),Apt=i(Qi),ot=n(Qi,"DIV",{class:!0});var Wi=s(ot);T(xB.$$.fragment,Wi),Lpt=i(Wi),qSe=n(Wi,"P",{});var Y3a=s(qSe);ypt=r(Y3a,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),Y3a.forEach(t),xpt=i(Wi),Zn=n(Wi,"P",{});var x$=s(Zn);$pt=r(x$,"The model class to instantiate is selected based on the "),DSe=n(x$,"CODE",{});var Z3a=s(DSe);kpt=r(Z3a,"model_type"),Z3a.forEach(t),Spt=r(x$,` property of the config object (either
passed as an argument or loaded from `),jSe=n(x$,"CODE",{});var K3a=s(jSe);Rpt=r(K3a,"pretrained_model_name_or_path"),K3a.forEach(t),Ppt=r(x$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),GSe=n(x$,"CODE",{});var e5a=s(GSe);Bpt=r(e5a,"pretrained_model_name_or_path"),e5a.forEach(t),Ipt=r(x$,":"),x$.forEach(t),Npt=i(Wi),OSe=n(Wi,"UL",{});var o5a=s(OSe);I7=n(o5a,"LI",{});var Tao=s(I7);VSe=n(Tao,"STRONG",{});var r5a=s(VSe);qpt=r(r5a,"layoutlm"),r5a.forEach(t),Dpt=r(Tao," \u2014 "),pie=n(Tao,"A",{href:!0});var t5a=s(pie);jpt=r(t5a,"TFLayoutLMForQuestionAnswering"),t5a.forEach(t),Gpt=r(Tao," (LayoutLM model)"),Tao.forEach(t),o5a.forEach(t),Opt=i(Wi),T(N7.$$.fragment,Wi),Wi.forEach(t),Qi.forEach(t),tdo=i(c),rf=n(c,"H2",{class:!0});var Lco=s(rf);q7=n(Lco,"A",{id:!0,class:!0,href:!0});var a5a=s(q7);XSe=n(a5a,"SPAN",{});var n5a=s(XSe);T($B.$$.fragment,n5a),n5a.forEach(t),a5a.forEach(t),Vpt=i(Lco),zSe=n(Lco,"SPAN",{});var s5a=s(zSe);Xpt=r(s5a,"TFAutoModelForTokenClassification"),s5a.forEach(t),Lco.forEach(t),ado=i(c),Ar=n(c,"DIV",{class:!0});var Ui=s(Ar);T(kB.$$.fragment,Ui),zpt=i(Ui),tf=n(Ui,"P",{});var Bge=s(tf);Qpt=r(Bge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),_ie=n(Bge,"A",{href:!0});var l5a=s(_ie);Wpt=r(l5a,"from_pretrained()"),l5a.forEach(t),Upt=r(Bge," class method or the "),bie=n(Bge,"A",{href:!0});var i5a=s(bie);Hpt=r(i5a,"from_config()"),i5a.forEach(t),Jpt=r(Bge,` class
method.`),Bge.forEach(t),Ypt=i(Ui),SB=n(Ui,"P",{});var yco=s(SB);Zpt=r(yco,"This class cannot be instantiated directly using "),QSe=n(yco,"CODE",{});var d5a=s(QSe);Kpt=r(d5a,"__init__()"),d5a.forEach(t),e_t=r(yco," (throws an error)."),yco.forEach(t),o_t=i(Ui),ga=n(Ui,"DIV",{class:!0});var $$=s(ga);T(RB.$$.fragment,$$),r_t=i($$),WSe=n($$,"P",{});var m5a=s(WSe);t_t=r(m5a,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),m5a.forEach(t),a_t=i($$),af=n($$,"P",{});var Ige=s(af);n_t=r(Ige,`Note:
Loading a model from its configuration file does `),USe=n(Ige,"STRONG",{});var c5a=s(USe);s_t=r(c5a,"not"),c5a.forEach(t),l_t=r(Ige,` load the model weights. It only affects the
model\u2019s configuration. Use `),vie=n(Ige,"A",{href:!0});var f5a=s(vie);i_t=r(f5a,"from_pretrained()"),f5a.forEach(t),d_t=r(Ige," to load the model weights."),Ige.forEach(t),m_t=i($$),T(D7.$$.fragment,$$),$$.forEach(t),c_t=i(Ui),rt=n(Ui,"DIV",{class:!0});var Hi=s(rt);T(PB.$$.fragment,Hi),f_t=i(Hi),HSe=n(Hi,"P",{});var g5a=s(HSe);g_t=r(g5a,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),g5a.forEach(t),h_t=i(Hi),Kn=n(Hi,"P",{});var k$=s(Kn);u_t=r(k$,"The model class to instantiate is selected based on the "),JSe=n(k$,"CODE",{});var h5a=s(JSe);p_t=r(h5a,"model_type"),h5a.forEach(t),__t=r(k$,` property of the config object (either
passed as an argument or loaded from `),YSe=n(k$,"CODE",{});var u5a=s(YSe);b_t=r(u5a,"pretrained_model_name_or_path"),u5a.forEach(t),v_t=r(k$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ZSe=n(k$,"CODE",{});var p5a=s(ZSe);F_t=r(p5a,"pretrained_model_name_or_path"),p5a.forEach(t),T_t=r(k$,":"),k$.forEach(t),M_t=i(Hi),me=n(Hi,"UL",{});var ue=s(me);j7=n(ue,"LI",{});var Mao=s(j7);KSe=n(Mao,"STRONG",{});var _5a=s(KSe);E_t=r(_5a,"albert"),_5a.forEach(t),C_t=r(Mao," \u2014 "),Fie=n(Mao,"A",{href:!0});var b5a=s(Fie);w_t=r(b5a,"TFAlbertForTokenClassification"),b5a.forEach(t),A_t=r(Mao," (ALBERT model)"),Mao.forEach(t),L_t=i(ue),G7=n(ue,"LI",{});var Eao=s(G7);eRe=n(Eao,"STRONG",{});var v5a=s(eRe);y_t=r(v5a,"bert"),v5a.forEach(t),x_t=r(Eao," \u2014 "),Tie=n(Eao,"A",{href:!0});var F5a=s(Tie);$_t=r(F5a,"TFBertForTokenClassification"),F5a.forEach(t),k_t=r(Eao," (BERT model)"),Eao.forEach(t),S_t=i(ue),O7=n(ue,"LI",{});var Cao=s(O7);oRe=n(Cao,"STRONG",{});var T5a=s(oRe);R_t=r(T5a,"camembert"),T5a.forEach(t),P_t=r(Cao," \u2014 "),Mie=n(Cao,"A",{href:!0});var M5a=s(Mie);B_t=r(M5a,"TFCamembertForTokenClassification"),M5a.forEach(t),I_t=r(Cao," (CamemBERT model)"),Cao.forEach(t),N_t=i(ue),V7=n(ue,"LI",{});var wao=s(V7);rRe=n(wao,"STRONG",{});var E5a=s(rRe);q_t=r(E5a,"convbert"),E5a.forEach(t),D_t=r(wao," \u2014 "),Eie=n(wao,"A",{href:!0});var C5a=s(Eie);j_t=r(C5a,"TFConvBertForTokenClassification"),C5a.forEach(t),G_t=r(wao," (ConvBERT model)"),wao.forEach(t),O_t=i(ue),X7=n(ue,"LI",{});var Aao=s(X7);tRe=n(Aao,"STRONG",{});var w5a=s(tRe);V_t=r(w5a,"deberta"),w5a.forEach(t),X_t=r(Aao," \u2014 "),Cie=n(Aao,"A",{href:!0});var A5a=s(Cie);z_t=r(A5a,"TFDebertaForTokenClassification"),A5a.forEach(t),Q_t=r(Aao," (DeBERTa model)"),Aao.forEach(t),W_t=i(ue),z7=n(ue,"LI",{});var Lao=s(z7);aRe=n(Lao,"STRONG",{});var L5a=s(aRe);U_t=r(L5a,"deberta-v2"),L5a.forEach(t),H_t=r(Lao," \u2014 "),wie=n(Lao,"A",{href:!0});var y5a=s(wie);J_t=r(y5a,"TFDebertaV2ForTokenClassification"),y5a.forEach(t),Y_t=r(Lao," (DeBERTa-v2 model)"),Lao.forEach(t),Z_t=i(ue),Q7=n(ue,"LI",{});var yao=s(Q7);nRe=n(yao,"STRONG",{});var x5a=s(nRe);K_t=r(x5a,"distilbert"),x5a.forEach(t),e1t=r(yao," \u2014 "),Aie=n(yao,"A",{href:!0});var $5a=s(Aie);o1t=r($5a,"TFDistilBertForTokenClassification"),$5a.forEach(t),r1t=r(yao," (DistilBERT model)"),yao.forEach(t),t1t=i(ue),W7=n(ue,"LI",{});var xao=s(W7);sRe=n(xao,"STRONG",{});var k5a=s(sRe);a1t=r(k5a,"electra"),k5a.forEach(t),n1t=r(xao," \u2014 "),Lie=n(xao,"A",{href:!0});var S5a=s(Lie);s1t=r(S5a,"TFElectraForTokenClassification"),S5a.forEach(t),l1t=r(xao," (ELECTRA model)"),xao.forEach(t),i1t=i(ue),U7=n(ue,"LI",{});var $ao=s(U7);lRe=n($ao,"STRONG",{});var R5a=s(lRe);d1t=r(R5a,"esm"),R5a.forEach(t),m1t=r($ao," \u2014 "),yie=n($ao,"A",{href:!0});var P5a=s(yie);c1t=r(P5a,"TFEsmForTokenClassification"),P5a.forEach(t),f1t=r($ao," (ESM model)"),$ao.forEach(t),g1t=i(ue),H7=n(ue,"LI",{});var kao=s(H7);iRe=n(kao,"STRONG",{});var B5a=s(iRe);h1t=r(B5a,"flaubert"),B5a.forEach(t),u1t=r(kao," \u2014 "),xie=n(kao,"A",{href:!0});var I5a=s(xie);p1t=r(I5a,"TFFlaubertForTokenClassification"),I5a.forEach(t),_1t=r(kao," (FlauBERT model)"),kao.forEach(t),b1t=i(ue),J7=n(ue,"LI",{});var Sao=s(J7);dRe=n(Sao,"STRONG",{});var N5a=s(dRe);v1t=r(N5a,"funnel"),N5a.forEach(t),F1t=r(Sao," \u2014 "),$ie=n(Sao,"A",{href:!0});var q5a=s($ie);T1t=r(q5a,"TFFunnelForTokenClassification"),q5a.forEach(t),M1t=r(Sao," (Funnel Transformer model)"),Sao.forEach(t),E1t=i(ue),Y7=n(ue,"LI",{});var Rao=s(Y7);mRe=n(Rao,"STRONG",{});var D5a=s(mRe);C1t=r(D5a,"layoutlm"),D5a.forEach(t),w1t=r(Rao," \u2014 "),kie=n(Rao,"A",{href:!0});var j5a=s(kie);A1t=r(j5a,"TFLayoutLMForTokenClassification"),j5a.forEach(t),L1t=r(Rao," (LayoutLM model)"),Rao.forEach(t),y1t=i(ue),Z7=n(ue,"LI",{});var Pao=s(Z7);cRe=n(Pao,"STRONG",{});var G5a=s(cRe);x1t=r(G5a,"layoutlmv3"),G5a.forEach(t),$1t=r(Pao," \u2014 "),Sie=n(Pao,"A",{href:!0});var O5a=s(Sie);k1t=r(O5a,"TFLayoutLMv3ForTokenClassification"),O5a.forEach(t),S1t=r(Pao," (LayoutLMv3 model)"),Pao.forEach(t),R1t=i(ue),K7=n(ue,"LI",{});var Bao=s(K7);fRe=n(Bao,"STRONG",{});var V5a=s(fRe);P1t=r(V5a,"longformer"),V5a.forEach(t),B1t=r(Bao," \u2014 "),Rie=n(Bao,"A",{href:!0});var X5a=s(Rie);I1t=r(X5a,"TFLongformerForTokenClassification"),X5a.forEach(t),N1t=r(Bao," (Longformer model)"),Bao.forEach(t),q1t=i(ue),e8=n(ue,"LI",{});var Iao=s(e8);gRe=n(Iao,"STRONG",{});var z5a=s(gRe);D1t=r(z5a,"mobilebert"),z5a.forEach(t),j1t=r(Iao," \u2014 "),Pie=n(Iao,"A",{href:!0});var Q5a=s(Pie);G1t=r(Q5a,"TFMobileBertForTokenClassification"),Q5a.forEach(t),O1t=r(Iao," (MobileBERT model)"),Iao.forEach(t),V1t=i(ue),o8=n(ue,"LI",{});var Nao=s(o8);hRe=n(Nao,"STRONG",{});var W5a=s(hRe);X1t=r(W5a,"mpnet"),W5a.forEach(t),z1t=r(Nao," \u2014 "),Bie=n(Nao,"A",{href:!0});var U5a=s(Bie);Q1t=r(U5a,"TFMPNetForTokenClassification"),U5a.forEach(t),W1t=r(Nao," (MPNet model)"),Nao.forEach(t),U1t=i(ue),r8=n(ue,"LI",{});var qao=s(r8);uRe=n(qao,"STRONG",{});var H5a=s(uRe);H1t=r(H5a,"rembert"),H5a.forEach(t),J1t=r(qao," \u2014 "),Iie=n(qao,"A",{href:!0});var J5a=s(Iie);Y1t=r(J5a,"TFRemBertForTokenClassification"),J5a.forEach(t),Z1t=r(qao," (RemBERT model)"),qao.forEach(t),K1t=i(ue),t8=n(ue,"LI",{});var Dao=s(t8);pRe=n(Dao,"STRONG",{});var Y5a=s(pRe);e2t=r(Y5a,"roberta"),Y5a.forEach(t),o2t=r(Dao," \u2014 "),Nie=n(Dao,"A",{href:!0});var Z5a=s(Nie);r2t=r(Z5a,"TFRobertaForTokenClassification"),Z5a.forEach(t),t2t=r(Dao," (RoBERTa model)"),Dao.forEach(t),a2t=i(ue),a8=n(ue,"LI",{});var jao=s(a8);_Re=n(jao,"STRONG",{});var K5a=s(_Re);n2t=r(K5a,"roformer"),K5a.forEach(t),s2t=r(jao," \u2014 "),qie=n(jao,"A",{href:!0});var e0a=s(qie);l2t=r(e0a,"TFRoFormerForTokenClassification"),e0a.forEach(t),i2t=r(jao," (RoFormer model)"),jao.forEach(t),d2t=i(ue),n8=n(ue,"LI",{});var Gao=s(n8);bRe=n(Gao,"STRONG",{});var o0a=s(bRe);m2t=r(o0a,"xlm"),o0a.forEach(t),c2t=r(Gao," \u2014 "),Die=n(Gao,"A",{href:!0});var r0a=s(Die);f2t=r(r0a,"TFXLMForTokenClassification"),r0a.forEach(t),g2t=r(Gao," (XLM model)"),Gao.forEach(t),h2t=i(ue),s8=n(ue,"LI",{});var Oao=s(s8);vRe=n(Oao,"STRONG",{});var t0a=s(vRe);u2t=r(t0a,"xlm-roberta"),t0a.forEach(t),p2t=r(Oao," \u2014 "),jie=n(Oao,"A",{href:!0});var a0a=s(jie);_2t=r(a0a,"TFXLMRobertaForTokenClassification"),a0a.forEach(t),b2t=r(Oao," (XLM-RoBERTa model)"),Oao.forEach(t),v2t=i(ue),l8=n(ue,"LI",{});var Vao=s(l8);FRe=n(Vao,"STRONG",{});var n0a=s(FRe);F2t=r(n0a,"xlnet"),n0a.forEach(t),T2t=r(Vao," \u2014 "),Gie=n(Vao,"A",{href:!0});var s0a=s(Gie);M2t=r(s0a,"TFXLNetForTokenClassification"),s0a.forEach(t),E2t=r(Vao," (XLNet model)"),Vao.forEach(t),ue.forEach(t),C2t=i(Hi),T(i8.$$.fragment,Hi),Hi.forEach(t),Ui.forEach(t),ndo=i(c),nf=n(c,"H2",{class:!0});var xco=s(nf);d8=n(xco,"A",{id:!0,class:!0,href:!0});var l0a=s(d8);TRe=n(l0a,"SPAN",{});var i0a=s(TRe);T(BB.$$.fragment,i0a),i0a.forEach(t),l0a.forEach(t),w2t=i(xco),MRe=n(xco,"SPAN",{});var d0a=s(MRe);A2t=r(d0a,"TFAutoModelForQuestionAnswering"),d0a.forEach(t),xco.forEach(t),sdo=i(c),Lr=n(c,"DIV",{class:!0});var Ji=s(Lr);T(IB.$$.fragment,Ji),L2t=i(Ji),sf=n(Ji,"P",{});var Nge=s(sf);y2t=r(Nge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Oie=n(Nge,"A",{href:!0});var m0a=s(Oie);x2t=r(m0a,"from_pretrained()"),m0a.forEach(t),$2t=r(Nge," class method or the "),Vie=n(Nge,"A",{href:!0});var c0a=s(Vie);k2t=r(c0a,"from_config()"),c0a.forEach(t),S2t=r(Nge,` class
method.`),Nge.forEach(t),R2t=i(Ji),NB=n(Ji,"P",{});var $co=s(NB);P2t=r($co,"This class cannot be instantiated directly using "),ERe=n($co,"CODE",{});var f0a=s(ERe);B2t=r(f0a,"__init__()"),f0a.forEach(t),I2t=r($co," (throws an error)."),$co.forEach(t),N2t=i(Ji),ha=n(Ji,"DIV",{class:!0});var S$=s(ha);T(qB.$$.fragment,S$),q2t=i(S$),CRe=n(S$,"P",{});var g0a=s(CRe);D2t=r(g0a,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),g0a.forEach(t),j2t=i(S$),lf=n(S$,"P",{});var qge=s(lf);G2t=r(qge,`Note:
Loading a model from its configuration file does `),wRe=n(qge,"STRONG",{});var h0a=s(wRe);O2t=r(h0a,"not"),h0a.forEach(t),V2t=r(qge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Xie=n(qge,"A",{href:!0});var u0a=s(Xie);X2t=r(u0a,"from_pretrained()"),u0a.forEach(t),z2t=r(qge," to load the model weights."),qge.forEach(t),Q2t=i(S$),T(m8.$$.fragment,S$),S$.forEach(t),W2t=i(Ji),tt=n(Ji,"DIV",{class:!0});var Yi=s(tt);T(DB.$$.fragment,Yi),U2t=i(Yi),ARe=n(Yi,"P",{});var p0a=s(ARe);H2t=r(p0a,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),p0a.forEach(t),J2t=i(Yi),es=n(Yi,"P",{});var R$=s(es);Y2t=r(R$,"The model class to instantiate is selected based on the "),LRe=n(R$,"CODE",{});var _0a=s(LRe);Z2t=r(_0a,"model_type"),_0a.forEach(t),K2t=r(R$,` property of the config object (either
passed as an argument or loaded from `),yRe=n(R$,"CODE",{});var b0a=s(yRe);ebt=r(b0a,"pretrained_model_name_or_path"),b0a.forEach(t),obt=r(R$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xRe=n(R$,"CODE",{});var v0a=s(xRe);rbt=r(v0a,"pretrained_model_name_or_path"),v0a.forEach(t),tbt=r(R$,":"),R$.forEach(t),abt=i(Yi),he=n(Yi,"UL",{});var be=s(he);c8=n(be,"LI",{});var Xao=s(c8);$Re=n(Xao,"STRONG",{});var F0a=s($Re);nbt=r(F0a,"albert"),F0a.forEach(t),sbt=r(Xao," \u2014 "),zie=n(Xao,"A",{href:!0});var T0a=s(zie);lbt=r(T0a,"TFAlbertForQuestionAnswering"),T0a.forEach(t),ibt=r(Xao," (ALBERT model)"),Xao.forEach(t),dbt=i(be),f8=n(be,"LI",{});var zao=s(f8);kRe=n(zao,"STRONG",{});var M0a=s(kRe);mbt=r(M0a,"bert"),M0a.forEach(t),cbt=r(zao," \u2014 "),Qie=n(zao,"A",{href:!0});var E0a=s(Qie);fbt=r(E0a,"TFBertForQuestionAnswering"),E0a.forEach(t),gbt=r(zao," (BERT model)"),zao.forEach(t),hbt=i(be),g8=n(be,"LI",{});var Qao=s(g8);SRe=n(Qao,"STRONG",{});var C0a=s(SRe);ubt=r(C0a,"camembert"),C0a.forEach(t),pbt=r(Qao," \u2014 "),Wie=n(Qao,"A",{href:!0});var w0a=s(Wie);_bt=r(w0a,"TFCamembertForQuestionAnswering"),w0a.forEach(t),bbt=r(Qao," (CamemBERT model)"),Qao.forEach(t),vbt=i(be),h8=n(be,"LI",{});var Wao=s(h8);RRe=n(Wao,"STRONG",{});var A0a=s(RRe);Fbt=r(A0a,"convbert"),A0a.forEach(t),Tbt=r(Wao," \u2014 "),Uie=n(Wao,"A",{href:!0});var L0a=s(Uie);Mbt=r(L0a,"TFConvBertForQuestionAnswering"),L0a.forEach(t),Ebt=r(Wao," (ConvBERT model)"),Wao.forEach(t),Cbt=i(be),u8=n(be,"LI",{});var Uao=s(u8);PRe=n(Uao,"STRONG",{});var y0a=s(PRe);wbt=r(y0a,"deberta"),y0a.forEach(t),Abt=r(Uao," \u2014 "),Hie=n(Uao,"A",{href:!0});var x0a=s(Hie);Lbt=r(x0a,"TFDebertaForQuestionAnswering"),x0a.forEach(t),ybt=r(Uao," (DeBERTa model)"),Uao.forEach(t),xbt=i(be),p8=n(be,"LI",{});var Hao=s(p8);BRe=n(Hao,"STRONG",{});var $0a=s(BRe);$bt=r($0a,"deberta-v2"),$0a.forEach(t),kbt=r(Hao," \u2014 "),Jie=n(Hao,"A",{href:!0});var k0a=s(Jie);Sbt=r(k0a,"TFDebertaV2ForQuestionAnswering"),k0a.forEach(t),Rbt=r(Hao," (DeBERTa-v2 model)"),Hao.forEach(t),Pbt=i(be),_8=n(be,"LI",{});var Jao=s(_8);IRe=n(Jao,"STRONG",{});var S0a=s(IRe);Bbt=r(S0a,"distilbert"),S0a.forEach(t),Ibt=r(Jao," \u2014 "),Yie=n(Jao,"A",{href:!0});var R0a=s(Yie);Nbt=r(R0a,"TFDistilBertForQuestionAnswering"),R0a.forEach(t),qbt=r(Jao," (DistilBERT model)"),Jao.forEach(t),Dbt=i(be),b8=n(be,"LI",{});var Yao=s(b8);NRe=n(Yao,"STRONG",{});var P0a=s(NRe);jbt=r(P0a,"electra"),P0a.forEach(t),Gbt=r(Yao," \u2014 "),Zie=n(Yao,"A",{href:!0});var B0a=s(Zie);Obt=r(B0a,"TFElectraForQuestionAnswering"),B0a.forEach(t),Vbt=r(Yao," (ELECTRA model)"),Yao.forEach(t),Xbt=i(be),v8=n(be,"LI",{});var Zao=s(v8);qRe=n(Zao,"STRONG",{});var I0a=s(qRe);zbt=r(I0a,"flaubert"),I0a.forEach(t),Qbt=r(Zao," \u2014 "),Kie=n(Zao,"A",{href:!0});var N0a=s(Kie);Wbt=r(N0a,"TFFlaubertForQuestionAnsweringSimple"),N0a.forEach(t),Ubt=r(Zao," (FlauBERT model)"),Zao.forEach(t),Hbt=i(be),F8=n(be,"LI",{});var Kao=s(F8);DRe=n(Kao,"STRONG",{});var q0a=s(DRe);Jbt=r(q0a,"funnel"),q0a.forEach(t),Ybt=r(Kao," \u2014 "),ede=n(Kao,"A",{href:!0});var D0a=s(ede);Zbt=r(D0a,"TFFunnelForQuestionAnswering"),D0a.forEach(t),Kbt=r(Kao," (Funnel Transformer model)"),Kao.forEach(t),evt=i(be),T8=n(be,"LI",{});var eno=s(T8);jRe=n(eno,"STRONG",{});var j0a=s(jRe);ovt=r(j0a,"gptj"),j0a.forEach(t),rvt=r(eno," \u2014 "),ode=n(eno,"A",{href:!0});var G0a=s(ode);tvt=r(G0a,"TFGPTJForQuestionAnswering"),G0a.forEach(t),avt=r(eno," (GPT-J model)"),eno.forEach(t),nvt=i(be),M8=n(be,"LI",{});var ono=s(M8);GRe=n(ono,"STRONG",{});var O0a=s(GRe);svt=r(O0a,"layoutlmv3"),O0a.forEach(t),lvt=r(ono," \u2014 "),rde=n(ono,"A",{href:!0});var V0a=s(rde);ivt=r(V0a,"TFLayoutLMv3ForQuestionAnswering"),V0a.forEach(t),dvt=r(ono," (LayoutLMv3 model)"),ono.forEach(t),mvt=i(be),E8=n(be,"LI",{});var rno=s(E8);ORe=n(rno,"STRONG",{});var X0a=s(ORe);cvt=r(X0a,"longformer"),X0a.forEach(t),fvt=r(rno," \u2014 "),tde=n(rno,"A",{href:!0});var z0a=s(tde);gvt=r(z0a,"TFLongformerForQuestionAnswering"),z0a.forEach(t),hvt=r(rno," (Longformer model)"),rno.forEach(t),uvt=i(be),C8=n(be,"LI",{});var tno=s(C8);VRe=n(tno,"STRONG",{});var Q0a=s(VRe);pvt=r(Q0a,"mobilebert"),Q0a.forEach(t),_vt=r(tno," \u2014 "),ade=n(tno,"A",{href:!0});var W0a=s(ade);bvt=r(W0a,"TFMobileBertForQuestionAnswering"),W0a.forEach(t),vvt=r(tno," (MobileBERT model)"),tno.forEach(t),Fvt=i(be),w8=n(be,"LI",{});var ano=s(w8);XRe=n(ano,"STRONG",{});var U0a=s(XRe);Tvt=r(U0a,"mpnet"),U0a.forEach(t),Mvt=r(ano," \u2014 "),nde=n(ano,"A",{href:!0});var H0a=s(nde);Evt=r(H0a,"TFMPNetForQuestionAnswering"),H0a.forEach(t),Cvt=r(ano," (MPNet model)"),ano.forEach(t),wvt=i(be),A8=n(be,"LI",{});var nno=s(A8);zRe=n(nno,"STRONG",{});var J0a=s(zRe);Avt=r(J0a,"rembert"),J0a.forEach(t),Lvt=r(nno," \u2014 "),sde=n(nno,"A",{href:!0});var Y0a=s(sde);yvt=r(Y0a,"TFRemBertForQuestionAnswering"),Y0a.forEach(t),xvt=r(nno," (RemBERT model)"),nno.forEach(t),$vt=i(be),L8=n(be,"LI",{});var sno=s(L8);QRe=n(sno,"STRONG",{});var Z0a=s(QRe);kvt=r(Z0a,"roberta"),Z0a.forEach(t),Svt=r(sno," \u2014 "),lde=n(sno,"A",{href:!0});var K0a=s(lde);Rvt=r(K0a,"TFRobertaForQuestionAnswering"),K0a.forEach(t),Pvt=r(sno," (RoBERTa model)"),sno.forEach(t),Bvt=i(be),y8=n(be,"LI",{});var lno=s(y8);WRe=n(lno,"STRONG",{});var ewa=s(WRe);Ivt=r(ewa,"roformer"),ewa.forEach(t),Nvt=r(lno," \u2014 "),ide=n(lno,"A",{href:!0});var owa=s(ide);qvt=r(owa,"TFRoFormerForQuestionAnswering"),owa.forEach(t),Dvt=r(lno," (RoFormer model)"),lno.forEach(t),jvt=i(be),x8=n(be,"LI",{});var ino=s(x8);URe=n(ino,"STRONG",{});var rwa=s(URe);Gvt=r(rwa,"xlm"),rwa.forEach(t),Ovt=r(ino," \u2014 "),dde=n(ino,"A",{href:!0});var twa=s(dde);Vvt=r(twa,"TFXLMForQuestionAnsweringSimple"),twa.forEach(t),Xvt=r(ino," (XLM model)"),ino.forEach(t),zvt=i(be),$8=n(be,"LI",{});var dno=s($8);HRe=n(dno,"STRONG",{});var awa=s(HRe);Qvt=r(awa,"xlm-roberta"),awa.forEach(t),Wvt=r(dno," \u2014 "),mde=n(dno,"A",{href:!0});var nwa=s(mde);Uvt=r(nwa,"TFXLMRobertaForQuestionAnswering"),nwa.forEach(t),Hvt=r(dno," (XLM-RoBERTa model)"),dno.forEach(t),Jvt=i(be),k8=n(be,"LI",{});var mno=s(k8);JRe=n(mno,"STRONG",{});var swa=s(JRe);Yvt=r(swa,"xlnet"),swa.forEach(t),Zvt=r(mno," \u2014 "),cde=n(mno,"A",{href:!0});var lwa=s(cde);Kvt=r(lwa,"TFXLNetForQuestionAnsweringSimple"),lwa.forEach(t),eFt=r(mno," (XLNet model)"),mno.forEach(t),be.forEach(t),oFt=i(Yi),T(S8.$$.fragment,Yi),Yi.forEach(t),Ji.forEach(t),ldo=i(c),df=n(c,"H2",{class:!0});var kco=s(df);R8=n(kco,"A",{id:!0,class:!0,href:!0});var iwa=s(R8);YRe=n(iwa,"SPAN",{});var dwa=s(YRe);T(jB.$$.fragment,dwa),dwa.forEach(t),iwa.forEach(t),rFt=i(kco),ZRe=n(kco,"SPAN",{});var mwa=s(ZRe);tFt=r(mwa,"TFAutoModelForVision2Seq"),mwa.forEach(t),kco.forEach(t),ido=i(c),yr=n(c,"DIV",{class:!0});var Zi=s(yr);T(GB.$$.fragment,Zi),aFt=i(Zi),mf=n(Zi,"P",{});var Dge=s(mf);nFt=r(Dge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),fde=n(Dge,"A",{href:!0});var cwa=s(fde);sFt=r(cwa,"from_pretrained()"),cwa.forEach(t),lFt=r(Dge," class method or the "),gde=n(Dge,"A",{href:!0});var fwa=s(gde);iFt=r(fwa,"from_config()"),fwa.forEach(t),dFt=r(Dge,` class
method.`),Dge.forEach(t),mFt=i(Zi),OB=n(Zi,"P",{});var Sco=s(OB);cFt=r(Sco,"This class cannot be instantiated directly using "),KRe=n(Sco,"CODE",{});var gwa=s(KRe);fFt=r(gwa,"__init__()"),gwa.forEach(t),gFt=r(Sco," (throws an error)."),Sco.forEach(t),hFt=i(Zi),ua=n(Zi,"DIV",{class:!0});var P$=s(ua);T(VB.$$.fragment,P$),uFt=i(P$),ePe=n(P$,"P",{});var hwa=s(ePe);pFt=r(hwa,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),hwa.forEach(t),_Ft=i(P$),cf=n(P$,"P",{});var jge=s(cf);bFt=r(jge,`Note:
Loading a model from its configuration file does `),oPe=n(jge,"STRONG",{});var uwa=s(oPe);vFt=r(uwa,"not"),uwa.forEach(t),FFt=r(jge,` load the model weights. It only affects the
model\u2019s configuration. Use `),hde=n(jge,"A",{href:!0});var pwa=s(hde);TFt=r(pwa,"from_pretrained()"),pwa.forEach(t),MFt=r(jge," to load the model weights."),jge.forEach(t),EFt=i(P$),T(P8.$$.fragment,P$),P$.forEach(t),CFt=i(Zi),at=n(Zi,"DIV",{class:!0});var Ki=s(at);T(XB.$$.fragment,Ki),wFt=i(Ki),rPe=n(Ki,"P",{});var _wa=s(rPe);AFt=r(_wa,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),_wa.forEach(t),LFt=i(Ki),os=n(Ki,"P",{});var B$=s(os);yFt=r(B$,"The model class to instantiate is selected based on the "),tPe=n(B$,"CODE",{});var bwa=s(tPe);xFt=r(bwa,"model_type"),bwa.forEach(t),$Ft=r(B$,` property of the config object (either
passed as an argument or loaded from `),aPe=n(B$,"CODE",{});var vwa=s(aPe);kFt=r(vwa,"pretrained_model_name_or_path"),vwa.forEach(t),SFt=r(B$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nPe=n(B$,"CODE",{});var Fwa=s(nPe);RFt=r(Fwa,"pretrained_model_name_or_path"),Fwa.forEach(t),PFt=r(B$,":"),B$.forEach(t),BFt=i(Ki),sPe=n(Ki,"UL",{});var Twa=s(sPe);B8=n(Twa,"LI",{});var cno=s(B8);lPe=n(cno,"STRONG",{});var Mwa=s(lPe);IFt=r(Mwa,"vision-encoder-decoder"),Mwa.forEach(t),NFt=r(cno," \u2014 "),ude=n(cno,"A",{href:!0});var Ewa=s(ude);qFt=r(Ewa,"TFVisionEncoderDecoderModel"),Ewa.forEach(t),DFt=r(cno," (Vision Encoder decoder model)"),cno.forEach(t),Twa.forEach(t),jFt=i(Ki),T(I8.$$.fragment,Ki),Ki.forEach(t),Zi.forEach(t),ddo=i(c),ff=n(c,"H2",{class:!0});var Rco=s(ff);N8=n(Rco,"A",{id:!0,class:!0,href:!0});var Cwa=s(N8);iPe=n(Cwa,"SPAN",{});var wwa=s(iPe);T(zB.$$.fragment,wwa),wwa.forEach(t),Cwa.forEach(t),GFt=i(Rco),dPe=n(Rco,"SPAN",{});var Awa=s(dPe);OFt=r(Awa,"TFAutoModelForSpeechSeq2Seq"),Awa.forEach(t),Rco.forEach(t),mdo=i(c),xr=n(c,"DIV",{class:!0});var ed=s(xr);T(QB.$$.fragment,ed),VFt=i(ed),gf=n(ed,"P",{});var Gge=s(gf);XFt=r(Gge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),pde=n(Gge,"A",{href:!0});var Lwa=s(pde);zFt=r(Lwa,"from_pretrained()"),Lwa.forEach(t),QFt=r(Gge," class method or the "),_de=n(Gge,"A",{href:!0});var ywa=s(_de);WFt=r(ywa,"from_config()"),ywa.forEach(t),UFt=r(Gge,` class
method.`),Gge.forEach(t),HFt=i(ed),WB=n(ed,"P",{});var Pco=s(WB);JFt=r(Pco,"This class cannot be instantiated directly using "),mPe=n(Pco,"CODE",{});var xwa=s(mPe);YFt=r(xwa,"__init__()"),xwa.forEach(t),ZFt=r(Pco," (throws an error)."),Pco.forEach(t),KFt=i(ed),pa=n(ed,"DIV",{class:!0});var I$=s(pa);T(UB.$$.fragment,I$),eTt=i(I$),cPe=n(I$,"P",{});var $wa=s(cPe);oTt=r($wa,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),$wa.forEach(t),rTt=i(I$),hf=n(I$,"P",{});var Oge=s(hf);tTt=r(Oge,`Note:
Loading a model from its configuration file does `),fPe=n(Oge,"STRONG",{});var kwa=s(fPe);aTt=r(kwa,"not"),kwa.forEach(t),nTt=r(Oge,` load the model weights. It only affects the
model\u2019s configuration. Use `),bde=n(Oge,"A",{href:!0});var Swa=s(bde);sTt=r(Swa,"from_pretrained()"),Swa.forEach(t),lTt=r(Oge," to load the model weights."),Oge.forEach(t),iTt=i(I$),T(q8.$$.fragment,I$),I$.forEach(t),dTt=i(ed),nt=n(ed,"DIV",{class:!0});var od=s(nt);T(HB.$$.fragment,od),mTt=i(od),gPe=n(od,"P",{});var Rwa=s(gPe);cTt=r(Rwa,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Rwa.forEach(t),fTt=i(od),rs=n(od,"P",{});var N$=s(rs);gTt=r(N$,"The model class to instantiate is selected based on the "),hPe=n(N$,"CODE",{});var Pwa=s(hPe);hTt=r(Pwa,"model_type"),Pwa.forEach(t),uTt=r(N$,` property of the config object (either
passed as an argument or loaded from `),uPe=n(N$,"CODE",{});var Bwa=s(uPe);pTt=r(Bwa,"pretrained_model_name_or_path"),Bwa.forEach(t),_Tt=r(N$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pPe=n(N$,"CODE",{});var Iwa=s(pPe);bTt=r(Iwa,"pretrained_model_name_or_path"),Iwa.forEach(t),vTt=r(N$,":"),N$.forEach(t),FTt=i(od),JB=n(od,"UL",{});var Bco=s(JB);D8=n(Bco,"LI",{});var fno=s(D8);_Pe=n(fno,"STRONG",{});var Nwa=s(_Pe);TTt=r(Nwa,"speech_to_text"),Nwa.forEach(t),MTt=r(fno," \u2014 "),vde=n(fno,"A",{href:!0});var qwa=s(vde);ETt=r(qwa,"TFSpeech2TextForConditionalGeneration"),qwa.forEach(t),CTt=r(fno," (Speech2Text model)"),fno.forEach(t),wTt=i(Bco),j8=n(Bco,"LI",{});var gno=s(j8);bPe=n(gno,"STRONG",{});var Dwa=s(bPe);ATt=r(Dwa,"whisper"),Dwa.forEach(t),LTt=r(gno," \u2014 "),Fde=n(gno,"A",{href:!0});var jwa=s(Fde);yTt=r(jwa,"TFWhisperForConditionalGeneration"),jwa.forEach(t),xTt=r(gno," (Whisper model)"),gno.forEach(t),Bco.forEach(t),$Tt=i(od),T(G8.$$.fragment,od),od.forEach(t),ed.forEach(t),cdo=i(c),uf=n(c,"H2",{class:!0});var Ico=s(uf);O8=n(Ico,"A",{id:!0,class:!0,href:!0});var Gwa=s(O8);vPe=n(Gwa,"SPAN",{});var Owa=s(vPe);T(YB.$$.fragment,Owa),Owa.forEach(t),Gwa.forEach(t),kTt=i(Ico),FPe=n(Ico,"SPAN",{});var Vwa=s(FPe);STt=r(Vwa,"FlaxAutoModel"),Vwa.forEach(t),Ico.forEach(t),fdo=i(c),$r=n(c,"DIV",{class:!0});var rd=s($r);T(ZB.$$.fragment,rd),RTt=i(rd),pf=n(rd,"P",{});var Vge=s(pf);PTt=r(Vge,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Tde=n(Vge,"A",{href:!0});var Xwa=s(Tde);BTt=r(Xwa,"from_pretrained()"),Xwa.forEach(t),ITt=r(Vge," class method or the "),Mde=n(Vge,"A",{href:!0});var zwa=s(Mde);NTt=r(zwa,"from_config()"),zwa.forEach(t),qTt=r(Vge,` class
method.`),Vge.forEach(t),DTt=i(rd),KB=n(rd,"P",{});var Nco=s(KB);jTt=r(Nco,"This class cannot be instantiated directly using "),TPe=n(Nco,"CODE",{});var Qwa=s(TPe);GTt=r(Qwa,"__init__()"),Qwa.forEach(t),OTt=r(Nco," (throws an error)."),Nco.forEach(t),VTt=i(rd),_a=n(rd,"DIV",{class:!0});var q$=s(_a);T(eI.$$.fragment,q$),XTt=i(q$),MPe=n(q$,"P",{});var Wwa=s(MPe);zTt=r(Wwa,"Instantiates one of the base model classes of the library from a configuration."),Wwa.forEach(t),QTt=i(q$),_f=n(q$,"P",{});var Xge=s(_f);WTt=r(Xge,`Note:
Loading a model from its configuration file does `),EPe=n(Xge,"STRONG",{});var Uwa=s(EPe);UTt=r(Uwa,"not"),Uwa.forEach(t),HTt=r(Xge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ede=n(Xge,"A",{href:!0});var Hwa=s(Ede);JTt=r(Hwa,"from_pretrained()"),Hwa.forEach(t),YTt=r(Xge," to load the model weights."),Xge.forEach(t),ZTt=i(q$),T(V8.$$.fragment,q$),q$.forEach(t),KTt=i(rd),st=n(rd,"DIV",{class:!0});var td=s(st);T(oI.$$.fragment,td),eMt=i(td),CPe=n(td,"P",{});var Jwa=s(CPe);oMt=r(Jwa,"Instantiate one of the base model classes of the library from a pretrained model."),Jwa.forEach(t),rMt=i(td),ts=n(td,"P",{});var D$=s(ts);tMt=r(D$,"The model class to instantiate is selected based on the "),wPe=n(D$,"CODE",{});var Ywa=s(wPe);aMt=r(Ywa,"model_type"),Ywa.forEach(t),nMt=r(D$,` property of the config object (either
passed as an argument or loaded from `),APe=n(D$,"CODE",{});var Zwa=s(APe);sMt=r(Zwa,"pretrained_model_name_or_path"),Zwa.forEach(t),lMt=r(D$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),LPe=n(D$,"CODE",{});var Kwa=s(LPe);iMt=r(Kwa,"pretrained_model_name_or_path"),Kwa.forEach(t),dMt=r(D$,":"),D$.forEach(t),mMt=i(td),ne=n(td,"UL",{});var le=s(ne);X8=n(le,"LI",{});var hno=s(X8);yPe=n(hno,"STRONG",{});var eAa=s(yPe);cMt=r(eAa,"albert"),eAa.forEach(t),fMt=r(hno," \u2014 "),Cde=n(hno,"A",{href:!0});var oAa=s(Cde);gMt=r(oAa,"FlaxAlbertModel"),oAa.forEach(t),hMt=r(hno," (ALBERT model)"),hno.forEach(t),uMt=i(le),z8=n(le,"LI",{});var uno=s(z8);xPe=n(uno,"STRONG",{});var rAa=s(xPe);pMt=r(rAa,"bart"),rAa.forEach(t),_Mt=r(uno," \u2014 "),wde=n(uno,"A",{href:!0});var tAa=s(wde);bMt=r(tAa,"FlaxBartModel"),tAa.forEach(t),vMt=r(uno," (BART model)"),uno.forEach(t),FMt=i(le),Q8=n(le,"LI",{});var pno=s(Q8);$Pe=n(pno,"STRONG",{});var aAa=s($Pe);TMt=r(aAa,"beit"),aAa.forEach(t),MMt=r(pno," \u2014 "),Ade=n(pno,"A",{href:!0});var nAa=s(Ade);EMt=r(nAa,"FlaxBeitModel"),nAa.forEach(t),CMt=r(pno," (BEiT model)"),pno.forEach(t),wMt=i(le),W8=n(le,"LI",{});var _no=s(W8);kPe=n(_no,"STRONG",{});var sAa=s(kPe);AMt=r(sAa,"bert"),sAa.forEach(t),LMt=r(_no," \u2014 "),Lde=n(_no,"A",{href:!0});var lAa=s(Lde);yMt=r(lAa,"FlaxBertModel"),lAa.forEach(t),xMt=r(_no," (BERT model)"),_no.forEach(t),$Mt=i(le),U8=n(le,"LI",{});var bno=s(U8);SPe=n(bno,"STRONG",{});var iAa=s(SPe);kMt=r(iAa,"big_bird"),iAa.forEach(t),SMt=r(bno," \u2014 "),yde=n(bno,"A",{href:!0});var dAa=s(yde);RMt=r(dAa,"FlaxBigBirdModel"),dAa.forEach(t),PMt=r(bno," (BigBird model)"),bno.forEach(t),BMt=i(le),H8=n(le,"LI",{});var vno=s(H8);RPe=n(vno,"STRONG",{});var mAa=s(RPe);IMt=r(mAa,"blenderbot"),mAa.forEach(t),NMt=r(vno," \u2014 "),xde=n(vno,"A",{href:!0});var cAa=s(xde);qMt=r(cAa,"FlaxBlenderbotModel"),cAa.forEach(t),DMt=r(vno," (Blenderbot model)"),vno.forEach(t),jMt=i(le),J8=n(le,"LI",{});var Fno=s(J8);PPe=n(Fno,"STRONG",{});var fAa=s(PPe);GMt=r(fAa,"blenderbot-small"),fAa.forEach(t),OMt=r(Fno," \u2014 "),$de=n(Fno,"A",{href:!0});var gAa=s($de);VMt=r(gAa,"FlaxBlenderbotSmallModel"),gAa.forEach(t),XMt=r(Fno," (BlenderbotSmall model)"),Fno.forEach(t),zMt=i(le),Y8=n(le,"LI",{});var Tno=s(Y8);BPe=n(Tno,"STRONG",{});var hAa=s(BPe);QMt=r(hAa,"clip"),hAa.forEach(t),WMt=r(Tno," \u2014 "),kde=n(Tno,"A",{href:!0});var uAa=s(kde);UMt=r(uAa,"FlaxCLIPModel"),uAa.forEach(t),HMt=r(Tno," (CLIP model)"),Tno.forEach(t),JMt=i(le),Z8=n(le,"LI",{});var Mno=s(Z8);IPe=n(Mno,"STRONG",{});var pAa=s(IPe);YMt=r(pAa,"distilbert"),pAa.forEach(t),ZMt=r(Mno," \u2014 "),Sde=n(Mno,"A",{href:!0});var _Aa=s(Sde);KMt=r(_Aa,"FlaxDistilBertModel"),_Aa.forEach(t),eEt=r(Mno," (DistilBERT model)"),Mno.forEach(t),oEt=i(le),K8=n(le,"LI",{});var Eno=s(K8);NPe=n(Eno,"STRONG",{});var bAa=s(NPe);rEt=r(bAa,"electra"),bAa.forEach(t),tEt=r(Eno," \u2014 "),Rde=n(Eno,"A",{href:!0});var vAa=s(Rde);aEt=r(vAa,"FlaxElectraModel"),vAa.forEach(t),nEt=r(Eno," (ELECTRA model)"),Eno.forEach(t),sEt=i(le),eL=n(le,"LI",{});var Cno=s(eL);qPe=n(Cno,"STRONG",{});var FAa=s(qPe);lEt=r(FAa,"gpt2"),FAa.forEach(t),iEt=r(Cno," \u2014 "),Pde=n(Cno,"A",{href:!0});var TAa=s(Pde);dEt=r(TAa,"FlaxGPT2Model"),TAa.forEach(t),mEt=r(Cno," (OpenAI GPT-2 model)"),Cno.forEach(t),cEt=i(le),oL=n(le,"LI",{});var wno=s(oL);DPe=n(wno,"STRONG",{});var MAa=s(DPe);fEt=r(MAa,"gpt_neo"),MAa.forEach(t),gEt=r(wno," \u2014 "),Bde=n(wno,"A",{href:!0});var EAa=s(Bde);hEt=r(EAa,"FlaxGPTNeoModel"),EAa.forEach(t),uEt=r(wno," (GPT Neo model)"),wno.forEach(t),pEt=i(le),rL=n(le,"LI",{});var Ano=s(rL);jPe=n(Ano,"STRONG",{});var CAa=s(jPe);_Et=r(CAa,"gptj"),CAa.forEach(t),bEt=r(Ano," \u2014 "),Ide=n(Ano,"A",{href:!0});var wAa=s(Ide);vEt=r(wAa,"FlaxGPTJModel"),wAa.forEach(t),FEt=r(Ano," (GPT-J model)"),Ano.forEach(t),TEt=i(le),tL=n(le,"LI",{});var Lno=s(tL);GPe=n(Lno,"STRONG",{});var AAa=s(GPe);MEt=r(AAa,"longt5"),AAa.forEach(t),EEt=r(Lno," \u2014 "),Nde=n(Lno,"A",{href:!0});var LAa=s(Nde);CEt=r(LAa,"FlaxLongT5Model"),LAa.forEach(t),wEt=r(Lno," (LongT5 model)"),Lno.forEach(t),AEt=i(le),aL=n(le,"LI",{});var yno=s(aL);OPe=n(yno,"STRONG",{});var yAa=s(OPe);LEt=r(yAa,"marian"),yAa.forEach(t),yEt=r(yno," \u2014 "),qde=n(yno,"A",{href:!0});var xAa=s(qde);xEt=r(xAa,"FlaxMarianModel"),xAa.forEach(t),$Et=r(yno," (Marian model)"),yno.forEach(t),kEt=i(le),nL=n(le,"LI",{});var xno=s(nL);VPe=n(xno,"STRONG",{});var $Aa=s(VPe);SEt=r($Aa,"mbart"),$Aa.forEach(t),REt=r(xno," \u2014 "),Dde=n(xno,"A",{href:!0});var kAa=s(Dde);PEt=r(kAa,"FlaxMBartModel"),kAa.forEach(t),BEt=r(xno," (mBART model)"),xno.forEach(t),IEt=i(le),sL=n(le,"LI",{});var $no=s(sL);XPe=n($no,"STRONG",{});var SAa=s(XPe);NEt=r(SAa,"mt5"),SAa.forEach(t),qEt=r($no," \u2014 "),jde=n($no,"A",{href:!0});var RAa=s(jde);DEt=r(RAa,"FlaxMT5Model"),RAa.forEach(t),jEt=r($no," (MT5 model)"),$no.forEach(t),GEt=i(le),lL=n(le,"LI",{});var kno=s(lL);zPe=n(kno,"STRONG",{});var PAa=s(zPe);OEt=r(PAa,"opt"),PAa.forEach(t),VEt=r(kno," \u2014 "),Gde=n(kno,"A",{href:!0});var BAa=s(Gde);XEt=r(BAa,"FlaxOPTModel"),BAa.forEach(t),zEt=r(kno," (OPT model)"),kno.forEach(t),QEt=i(le),iL=n(le,"LI",{});var Sno=s(iL);QPe=n(Sno,"STRONG",{});var IAa=s(QPe);WEt=r(IAa,"pegasus"),IAa.forEach(t),UEt=r(Sno," \u2014 "),Ode=n(Sno,"A",{href:!0});var NAa=s(Ode);HEt=r(NAa,"FlaxPegasusModel"),NAa.forEach(t),JEt=r(Sno," (Pegasus model)"),Sno.forEach(t),YEt=i(le),dL=n(le,"LI",{});var Rno=s(dL);WPe=n(Rno,"STRONG",{});var qAa=s(WPe);ZEt=r(qAa,"roberta"),qAa.forEach(t),KEt=r(Rno," \u2014 "),Vde=n(Rno,"A",{href:!0});var DAa=s(Vde);e4t=r(DAa,"FlaxRobertaModel"),DAa.forEach(t),o4t=r(Rno," (RoBERTa model)"),Rno.forEach(t),r4t=i(le),mL=n(le,"LI",{});var Pno=s(mL);UPe=n(Pno,"STRONG",{});var jAa=s(UPe);t4t=r(jAa,"roformer"),jAa.forEach(t),a4t=r(Pno," \u2014 "),Xde=n(Pno,"A",{href:!0});var GAa=s(Xde);n4t=r(GAa,"FlaxRoFormerModel"),GAa.forEach(t),s4t=r(Pno," (RoFormer model)"),Pno.forEach(t),l4t=i(le),cL=n(le,"LI",{});var Bno=s(cL);HPe=n(Bno,"STRONG",{});var OAa=s(HPe);i4t=r(OAa,"t5"),OAa.forEach(t),d4t=r(Bno," \u2014 "),zde=n(Bno,"A",{href:!0});var VAa=s(zde);m4t=r(VAa,"FlaxT5Model"),VAa.forEach(t),c4t=r(Bno," (T5 model)"),Bno.forEach(t),f4t=i(le),fL=n(le,"LI",{});var Ino=s(fL);JPe=n(Ino,"STRONG",{});var XAa=s(JPe);g4t=r(XAa,"vision-text-dual-encoder"),XAa.forEach(t),h4t=r(Ino," \u2014 "),Qde=n(Ino,"A",{href:!0});var zAa=s(Qde);u4t=r(zAa,"FlaxVisionTextDualEncoderModel"),zAa.forEach(t),p4t=r(Ino," (VisionTextDualEncoder model)"),Ino.forEach(t),_4t=i(le),gL=n(le,"LI",{});var Nno=s(gL);YPe=n(Nno,"STRONG",{});var QAa=s(YPe);b4t=r(QAa,"vit"),QAa.forEach(t),v4t=r(Nno," \u2014 "),Wde=n(Nno,"A",{href:!0});var WAa=s(Wde);F4t=r(WAa,"FlaxViTModel"),WAa.forEach(t),T4t=r(Nno," (ViT model)"),Nno.forEach(t),M4t=i(le),hL=n(le,"LI",{});var qno=s(hL);ZPe=n(qno,"STRONG",{});var UAa=s(ZPe);E4t=r(UAa,"wav2vec2"),UAa.forEach(t),C4t=r(qno," \u2014 "),Ude=n(qno,"A",{href:!0});var HAa=s(Ude);w4t=r(HAa,"FlaxWav2Vec2Model"),HAa.forEach(t),A4t=r(qno," (Wav2Vec2 model)"),qno.forEach(t),L4t=i(le),uL=n(le,"LI",{});var Dno=s(uL);KPe=n(Dno,"STRONG",{});var JAa=s(KPe);y4t=r(JAa,"xglm"),JAa.forEach(t),x4t=r(Dno," \u2014 "),Hde=n(Dno,"A",{href:!0});var YAa=s(Hde);$4t=r(YAa,"FlaxXGLMModel"),YAa.forEach(t),k4t=r(Dno," (XGLM model)"),Dno.forEach(t),S4t=i(le),pL=n(le,"LI",{});var jno=s(pL);eBe=n(jno,"STRONG",{});var ZAa=s(eBe);R4t=r(ZAa,"xlm-roberta"),ZAa.forEach(t),P4t=r(jno," \u2014 "),Jde=n(jno,"A",{href:!0});var KAa=s(Jde);B4t=r(KAa,"FlaxXLMRobertaModel"),KAa.forEach(t),I4t=r(jno," (XLM-RoBERTa model)"),jno.forEach(t),le.forEach(t),N4t=i(td),T(_L.$$.fragment,td),td.forEach(t),rd.forEach(t),gdo=i(c),bf=n(c,"H2",{class:!0});var qco=s(bf);bL=n(qco,"A",{id:!0,class:!0,href:!0});var e6a=s(bL);oBe=n(e6a,"SPAN",{});var o6a=s(oBe);T(rI.$$.fragment,o6a),o6a.forEach(t),e6a.forEach(t),q4t=i(qco),rBe=n(qco,"SPAN",{});var r6a=s(rBe);D4t=r(r6a,"FlaxAutoModelForCausalLM"),r6a.forEach(t),qco.forEach(t),hdo=i(c),kr=n(c,"DIV",{class:!0});var ad=s(kr);T(tI.$$.fragment,ad),j4t=i(ad),vf=n(ad,"P",{});var zge=s(vf);G4t=r(zge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Yde=n(zge,"A",{href:!0});var t6a=s(Yde);O4t=r(t6a,"from_pretrained()"),t6a.forEach(t),V4t=r(zge," class method or the "),Zde=n(zge,"A",{href:!0});var a6a=s(Zde);X4t=r(a6a,"from_config()"),a6a.forEach(t),z4t=r(zge,` class
method.`),zge.forEach(t),Q4t=i(ad),aI=n(ad,"P",{});var Dco=s(aI);W4t=r(Dco,"This class cannot be instantiated directly using "),tBe=n(Dco,"CODE",{});var n6a=s(tBe);U4t=r(n6a,"__init__()"),n6a.forEach(t),H4t=r(Dco," (throws an error)."),Dco.forEach(t),J4t=i(ad),ba=n(ad,"DIV",{class:!0});var j$=s(ba);T(nI.$$.fragment,j$),Y4t=i(j$),aBe=n(j$,"P",{});var s6a=s(aBe);Z4t=r(s6a,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),s6a.forEach(t),K4t=i(j$),Ff=n(j$,"P",{});var Qge=s(Ff);eCt=r(Qge,`Note:
Loading a model from its configuration file does `),nBe=n(Qge,"STRONG",{});var l6a=s(nBe);oCt=r(l6a,"not"),l6a.forEach(t),rCt=r(Qge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Kde=n(Qge,"A",{href:!0});var i6a=s(Kde);tCt=r(i6a,"from_pretrained()"),i6a.forEach(t),aCt=r(Qge," to load the model weights."),Qge.forEach(t),nCt=i(j$),T(vL.$$.fragment,j$),j$.forEach(t),sCt=i(ad),lt=n(ad,"DIV",{class:!0});var nd=s(lt);T(sI.$$.fragment,nd),lCt=i(nd),sBe=n(nd,"P",{});var d6a=s(sBe);iCt=r(d6a,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),d6a.forEach(t),dCt=i(nd),as=n(nd,"P",{});var G$=s(as);mCt=r(G$,"The model class to instantiate is selected based on the "),lBe=n(G$,"CODE",{});var m6a=s(lBe);cCt=r(m6a,"model_type"),m6a.forEach(t),fCt=r(G$,` property of the config object (either
passed as an argument or loaded from `),iBe=n(G$,"CODE",{});var c6a=s(iBe);gCt=r(c6a,"pretrained_model_name_or_path"),c6a.forEach(t),hCt=r(G$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dBe=n(G$,"CODE",{});var f6a=s(dBe);uCt=r(f6a,"pretrained_model_name_or_path"),f6a.forEach(t),pCt=r(G$,":"),G$.forEach(t),_Ct=i(nd),Se=n(nd,"UL",{});var Ge=s(Se);FL=n(Ge,"LI",{});var Gno=s(FL);mBe=n(Gno,"STRONG",{});var g6a=s(mBe);bCt=r(g6a,"bart"),g6a.forEach(t),vCt=r(Gno," \u2014 "),eme=n(Gno,"A",{href:!0});var h6a=s(eme);FCt=r(h6a,"FlaxBartForCausalLM"),h6a.forEach(t),TCt=r(Gno," (BART model)"),Gno.forEach(t),MCt=i(Ge),TL=n(Ge,"LI",{});var Ono=s(TL);cBe=n(Ono,"STRONG",{});var u6a=s(cBe);ECt=r(u6a,"bert"),u6a.forEach(t),CCt=r(Ono," \u2014 "),ome=n(Ono,"A",{href:!0});var p6a=s(ome);wCt=r(p6a,"FlaxBertForCausalLM"),p6a.forEach(t),ACt=r(Ono," (BERT model)"),Ono.forEach(t),LCt=i(Ge),ML=n(Ge,"LI",{});var Vno=s(ML);fBe=n(Vno,"STRONG",{});var _6a=s(fBe);yCt=r(_6a,"big_bird"),_6a.forEach(t),xCt=r(Vno," \u2014 "),rme=n(Vno,"A",{href:!0});var b6a=s(rme);$Ct=r(b6a,"FlaxBigBirdForCausalLM"),b6a.forEach(t),kCt=r(Vno," (BigBird model)"),Vno.forEach(t),SCt=i(Ge),EL=n(Ge,"LI",{});var Xno=s(EL);gBe=n(Xno,"STRONG",{});var v6a=s(gBe);RCt=r(v6a,"electra"),v6a.forEach(t),PCt=r(Xno," \u2014 "),tme=n(Xno,"A",{href:!0});var F6a=s(tme);BCt=r(F6a,"FlaxElectraForCausalLM"),F6a.forEach(t),ICt=r(Xno," (ELECTRA model)"),Xno.forEach(t),NCt=i(Ge),CL=n(Ge,"LI",{});var zno=s(CL);hBe=n(zno,"STRONG",{});var T6a=s(hBe);qCt=r(T6a,"gpt2"),T6a.forEach(t),DCt=r(zno," \u2014 "),ame=n(zno,"A",{href:!0});var M6a=s(ame);jCt=r(M6a,"FlaxGPT2LMHeadModel"),M6a.forEach(t),GCt=r(zno," (OpenAI GPT-2 model)"),zno.forEach(t),OCt=i(Ge),wL=n(Ge,"LI",{});var Qno=s(wL);uBe=n(Qno,"STRONG",{});var E6a=s(uBe);VCt=r(E6a,"gpt_neo"),E6a.forEach(t),XCt=r(Qno," \u2014 "),nme=n(Qno,"A",{href:!0});var C6a=s(nme);zCt=r(C6a,"FlaxGPTNeoForCausalLM"),C6a.forEach(t),QCt=r(Qno," (GPT Neo model)"),Qno.forEach(t),WCt=i(Ge),AL=n(Ge,"LI",{});var Wno=s(AL);pBe=n(Wno,"STRONG",{});var w6a=s(pBe);UCt=r(w6a,"gptj"),w6a.forEach(t),HCt=r(Wno," \u2014 "),sme=n(Wno,"A",{href:!0});var A6a=s(sme);JCt=r(A6a,"FlaxGPTJForCausalLM"),A6a.forEach(t),YCt=r(Wno," (GPT-J model)"),Wno.forEach(t),ZCt=i(Ge),LL=n(Ge,"LI",{});var Uno=s(LL);_Be=n(Uno,"STRONG",{});var L6a=s(_Be);KCt=r(L6a,"opt"),L6a.forEach(t),e3t=r(Uno," \u2014 "),lme=n(Uno,"A",{href:!0});var y6a=s(lme);o3t=r(y6a,"FlaxOPTForCausalLM"),y6a.forEach(t),r3t=r(Uno," (OPT model)"),Uno.forEach(t),t3t=i(Ge),yL=n(Ge,"LI",{});var Hno=s(yL);bBe=n(Hno,"STRONG",{});var x6a=s(bBe);a3t=r(x6a,"roberta"),x6a.forEach(t),n3t=r(Hno," \u2014 "),ime=n(Hno,"A",{href:!0});var $6a=s(ime);s3t=r($6a,"FlaxRobertaForCausalLM"),$6a.forEach(t),l3t=r(Hno," (RoBERTa model)"),Hno.forEach(t),i3t=i(Ge),xL=n(Ge,"LI",{});var Jno=s(xL);vBe=n(Jno,"STRONG",{});var k6a=s(vBe);d3t=r(k6a,"xglm"),k6a.forEach(t),m3t=r(Jno," \u2014 "),dme=n(Jno,"A",{href:!0});var S6a=s(dme);c3t=r(S6a,"FlaxXGLMForCausalLM"),S6a.forEach(t),f3t=r(Jno," (XGLM model)"),Jno.forEach(t),Ge.forEach(t),g3t=i(nd),T($L.$$.fragment,nd),nd.forEach(t),ad.forEach(t),udo=i(c),Tf=n(c,"H2",{class:!0});var jco=s(Tf);kL=n(jco,"A",{id:!0,class:!0,href:!0});var R6a=s(kL);FBe=n(R6a,"SPAN",{});var P6a=s(FBe);T(lI.$$.fragment,P6a),P6a.forEach(t),R6a.forEach(t),h3t=i(jco),TBe=n(jco,"SPAN",{});var B6a=s(TBe);u3t=r(B6a,"FlaxAutoModelForPreTraining"),B6a.forEach(t),jco.forEach(t),pdo=i(c),Sr=n(c,"DIV",{class:!0});var sd=s(Sr);T(iI.$$.fragment,sd),p3t=i(sd),Mf=n(sd,"P",{});var Wge=s(Mf);_3t=r(Wge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),mme=n(Wge,"A",{href:!0});var I6a=s(mme);b3t=r(I6a,"from_pretrained()"),I6a.forEach(t),v3t=r(Wge," class method or the "),cme=n(Wge,"A",{href:!0});var N6a=s(cme);F3t=r(N6a,"from_config()"),N6a.forEach(t),T3t=r(Wge,` class
method.`),Wge.forEach(t),M3t=i(sd),dI=n(sd,"P",{});var Gco=s(dI);E3t=r(Gco,"This class cannot be instantiated directly using "),MBe=n(Gco,"CODE",{});var q6a=s(MBe);C3t=r(q6a,"__init__()"),q6a.forEach(t),w3t=r(Gco," (throws an error)."),Gco.forEach(t),A3t=i(sd),va=n(sd,"DIV",{class:!0});var O$=s(va);T(mI.$$.fragment,O$),L3t=i(O$),EBe=n(O$,"P",{});var D6a=s(EBe);y3t=r(D6a,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),D6a.forEach(t),x3t=i(O$),Ef=n(O$,"P",{});var Uge=s(Ef);$3t=r(Uge,`Note:
Loading a model from its configuration file does `),CBe=n(Uge,"STRONG",{});var j6a=s(CBe);k3t=r(j6a,"not"),j6a.forEach(t),S3t=r(Uge,` load the model weights. It only affects the
model\u2019s configuration. Use `),fme=n(Uge,"A",{href:!0});var G6a=s(fme);R3t=r(G6a,"from_pretrained()"),G6a.forEach(t),P3t=r(Uge," to load the model weights."),Uge.forEach(t),B3t=i(O$),T(SL.$$.fragment,O$),O$.forEach(t),I3t=i(sd),it=n(sd,"DIV",{class:!0});var ld=s(it);T(cI.$$.fragment,ld),N3t=i(ld),wBe=n(ld,"P",{});var O6a=s(wBe);q3t=r(O6a,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),O6a.forEach(t),D3t=i(ld),ns=n(ld,"P",{});var V$=s(ns);j3t=r(V$,"The model class to instantiate is selected based on the "),ABe=n(V$,"CODE",{});var V6a=s(ABe);G3t=r(V6a,"model_type"),V6a.forEach(t),O3t=r(V$,` property of the config object (either
passed as an argument or loaded from `),LBe=n(V$,"CODE",{});var X6a=s(LBe);V3t=r(X6a,"pretrained_model_name_or_path"),X6a.forEach(t),X3t=r(V$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yBe=n(V$,"CODE",{});var z6a=s(yBe);z3t=r(z6a,"pretrained_model_name_or_path"),z6a.forEach(t),Q3t=r(V$,":"),V$.forEach(t),W3t=i(ld),we=n(ld,"UL",{});var Le=s(we);RL=n(Le,"LI",{});var Yno=s(RL);xBe=n(Yno,"STRONG",{});var Q6a=s(xBe);U3t=r(Q6a,"albert"),Q6a.forEach(t),H3t=r(Yno," \u2014 "),gme=n(Yno,"A",{href:!0});var W6a=s(gme);J3t=r(W6a,"FlaxAlbertForPreTraining"),W6a.forEach(t),Y3t=r(Yno," (ALBERT model)"),Yno.forEach(t),Z3t=i(Le),PL=n(Le,"LI",{});var Zno=s(PL);$Be=n(Zno,"STRONG",{});var U6a=s($Be);K3t=r(U6a,"bart"),U6a.forEach(t),e5t=r(Zno," \u2014 "),hme=n(Zno,"A",{href:!0});var H6a=s(hme);o5t=r(H6a,"FlaxBartForConditionalGeneration"),H6a.forEach(t),r5t=r(Zno," (BART model)"),Zno.forEach(t),t5t=i(Le),BL=n(Le,"LI",{});var Kno=s(BL);kBe=n(Kno,"STRONG",{});var J6a=s(kBe);a5t=r(J6a,"bert"),J6a.forEach(t),n5t=r(Kno," \u2014 "),ume=n(Kno,"A",{href:!0});var Y6a=s(ume);s5t=r(Y6a,"FlaxBertForPreTraining"),Y6a.forEach(t),l5t=r(Kno," (BERT model)"),Kno.forEach(t),i5t=i(Le),IL=n(Le,"LI",{});var eso=s(IL);SBe=n(eso,"STRONG",{});var Z6a=s(SBe);d5t=r(Z6a,"big_bird"),Z6a.forEach(t),m5t=r(eso," \u2014 "),pme=n(eso,"A",{href:!0});var K6a=s(pme);c5t=r(K6a,"FlaxBigBirdForPreTraining"),K6a.forEach(t),f5t=r(eso," (BigBird model)"),eso.forEach(t),g5t=i(Le),NL=n(Le,"LI",{});var oso=s(NL);RBe=n(oso,"STRONG",{});var e7a=s(RBe);h5t=r(e7a,"electra"),e7a.forEach(t),u5t=r(oso," \u2014 "),_me=n(oso,"A",{href:!0});var o7a=s(_me);p5t=r(o7a,"FlaxElectraForPreTraining"),o7a.forEach(t),_5t=r(oso," (ELECTRA model)"),oso.forEach(t),b5t=i(Le),qL=n(Le,"LI",{});var rso=s(qL);PBe=n(rso,"STRONG",{});var r7a=s(PBe);v5t=r(r7a,"longt5"),r7a.forEach(t),F5t=r(rso," \u2014 "),bme=n(rso,"A",{href:!0});var t7a=s(bme);T5t=r(t7a,"FlaxLongT5ForConditionalGeneration"),t7a.forEach(t),M5t=r(rso," (LongT5 model)"),rso.forEach(t),E5t=i(Le),DL=n(Le,"LI",{});var tso=s(DL);BBe=n(tso,"STRONG",{});var a7a=s(BBe);C5t=r(a7a,"mbart"),a7a.forEach(t),w5t=r(tso," \u2014 "),vme=n(tso,"A",{href:!0});var n7a=s(vme);A5t=r(n7a,"FlaxMBartForConditionalGeneration"),n7a.forEach(t),L5t=r(tso," (mBART model)"),tso.forEach(t),y5t=i(Le),jL=n(Le,"LI",{});var aso=s(jL);IBe=n(aso,"STRONG",{});var s7a=s(IBe);x5t=r(s7a,"mt5"),s7a.forEach(t),$5t=r(aso," \u2014 "),Fme=n(aso,"A",{href:!0});var l7a=s(Fme);k5t=r(l7a,"FlaxMT5ForConditionalGeneration"),l7a.forEach(t),S5t=r(aso," (MT5 model)"),aso.forEach(t),R5t=i(Le),GL=n(Le,"LI",{});var nso=s(GL);NBe=n(nso,"STRONG",{});var i7a=s(NBe);P5t=r(i7a,"roberta"),i7a.forEach(t),B5t=r(nso," \u2014 "),Tme=n(nso,"A",{href:!0});var d7a=s(Tme);I5t=r(d7a,"FlaxRobertaForMaskedLM"),d7a.forEach(t),N5t=r(nso," (RoBERTa model)"),nso.forEach(t),q5t=i(Le),OL=n(Le,"LI",{});var sso=s(OL);qBe=n(sso,"STRONG",{});var m7a=s(qBe);D5t=r(m7a,"roformer"),m7a.forEach(t),j5t=r(sso," \u2014 "),Mme=n(sso,"A",{href:!0});var c7a=s(Mme);G5t=r(c7a,"FlaxRoFormerForMaskedLM"),c7a.forEach(t),O5t=r(sso," (RoFormer model)"),sso.forEach(t),V5t=i(Le),VL=n(Le,"LI",{});var lso=s(VL);DBe=n(lso,"STRONG",{});var f7a=s(DBe);X5t=r(f7a,"t5"),f7a.forEach(t),z5t=r(lso," \u2014 "),Eme=n(lso,"A",{href:!0});var g7a=s(Eme);Q5t=r(g7a,"FlaxT5ForConditionalGeneration"),g7a.forEach(t),W5t=r(lso," (T5 model)"),lso.forEach(t),U5t=i(Le),XL=n(Le,"LI",{});var iso=s(XL);jBe=n(iso,"STRONG",{});var h7a=s(jBe);H5t=r(h7a,"wav2vec2"),h7a.forEach(t),J5t=r(iso," \u2014 "),Cme=n(iso,"A",{href:!0});var u7a=s(Cme);Y5t=r(u7a,"FlaxWav2Vec2ForPreTraining"),u7a.forEach(t),Z5t=r(iso," (Wav2Vec2 model)"),iso.forEach(t),K5t=i(Le),zL=n(Le,"LI",{});var dso=s(zL);GBe=n(dso,"STRONG",{});var p7a=s(GBe);e0t=r(p7a,"xlm-roberta"),p7a.forEach(t),o0t=r(dso," \u2014 "),wme=n(dso,"A",{href:!0});var _7a=s(wme);r0t=r(_7a,"FlaxXLMRobertaForMaskedLM"),_7a.forEach(t),t0t=r(dso," (XLM-RoBERTa model)"),dso.forEach(t),Le.forEach(t),a0t=i(ld),T(QL.$$.fragment,ld),ld.forEach(t),sd.forEach(t),_do=i(c),Cf=n(c,"H2",{class:!0});var Oco=s(Cf);WL=n(Oco,"A",{id:!0,class:!0,href:!0});var b7a=s(WL);OBe=n(b7a,"SPAN",{});var v7a=s(OBe);T(fI.$$.fragment,v7a),v7a.forEach(t),b7a.forEach(t),n0t=i(Oco),VBe=n(Oco,"SPAN",{});var F7a=s(VBe);s0t=r(F7a,"FlaxAutoModelForMaskedLM"),F7a.forEach(t),Oco.forEach(t),bdo=i(c),Rr=n(c,"DIV",{class:!0});var id=s(Rr);T(gI.$$.fragment,id),l0t=i(id),wf=n(id,"P",{});var Hge=s(wf);i0t=r(Hge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Ame=n(Hge,"A",{href:!0});var T7a=s(Ame);d0t=r(T7a,"from_pretrained()"),T7a.forEach(t),m0t=r(Hge," class method or the "),Lme=n(Hge,"A",{href:!0});var M7a=s(Lme);c0t=r(M7a,"from_config()"),M7a.forEach(t),f0t=r(Hge,` class
method.`),Hge.forEach(t),g0t=i(id),hI=n(id,"P",{});var Vco=s(hI);h0t=r(Vco,"This class cannot be instantiated directly using "),XBe=n(Vco,"CODE",{});var E7a=s(XBe);u0t=r(E7a,"__init__()"),E7a.forEach(t),p0t=r(Vco," (throws an error)."),Vco.forEach(t),_0t=i(id),Fa=n(id,"DIV",{class:!0});var X$=s(Fa);T(uI.$$.fragment,X$),b0t=i(X$),zBe=n(X$,"P",{});var C7a=s(zBe);v0t=r(C7a,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),C7a.forEach(t),F0t=i(X$),Af=n(X$,"P",{});var Jge=s(Af);T0t=r(Jge,`Note:
Loading a model from its configuration file does `),QBe=n(Jge,"STRONG",{});var w7a=s(QBe);M0t=r(w7a,"not"),w7a.forEach(t),E0t=r(Jge,` load the model weights. It only affects the
model\u2019s configuration. Use `),yme=n(Jge,"A",{href:!0});var A7a=s(yme);C0t=r(A7a,"from_pretrained()"),A7a.forEach(t),w0t=r(Jge," to load the model weights."),Jge.forEach(t),A0t=i(X$),T(UL.$$.fragment,X$),X$.forEach(t),L0t=i(id),dt=n(id,"DIV",{class:!0});var dd=s(dt);T(pI.$$.fragment,dd),y0t=i(dd),WBe=n(dd,"P",{});var L7a=s(WBe);x0t=r(L7a,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),L7a.forEach(t),$0t=i(dd),ss=n(dd,"P",{});var z$=s(ss);k0t=r(z$,"The model class to instantiate is selected based on the "),UBe=n(z$,"CODE",{});var y7a=s(UBe);S0t=r(y7a,"model_type"),y7a.forEach(t),R0t=r(z$,` property of the config object (either
passed as an argument or loaded from `),HBe=n(z$,"CODE",{});var x7a=s(HBe);P0t=r(x7a,"pretrained_model_name_or_path"),x7a.forEach(t),B0t=r(z$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JBe=n(z$,"CODE",{});var $7a=s(JBe);I0t=r($7a,"pretrained_model_name_or_path"),$7a.forEach(t),N0t=r(z$,":"),z$.forEach(t),q0t=i(dd),Re=n(dd,"UL",{});var Oe=s(Re);HL=n(Oe,"LI",{});var mso=s(HL);YBe=n(mso,"STRONG",{});var k7a=s(YBe);D0t=r(k7a,"albert"),k7a.forEach(t),j0t=r(mso," \u2014 "),xme=n(mso,"A",{href:!0});var S7a=s(xme);G0t=r(S7a,"FlaxAlbertForMaskedLM"),S7a.forEach(t),O0t=r(mso," (ALBERT model)"),mso.forEach(t),V0t=i(Oe),JL=n(Oe,"LI",{});var cso=s(JL);ZBe=n(cso,"STRONG",{});var R7a=s(ZBe);X0t=r(R7a,"bart"),R7a.forEach(t),z0t=r(cso," \u2014 "),$me=n(cso,"A",{href:!0});var P7a=s($me);Q0t=r(P7a,"FlaxBartForConditionalGeneration"),P7a.forEach(t),W0t=r(cso," (BART model)"),cso.forEach(t),U0t=i(Oe),YL=n(Oe,"LI",{});var fso=s(YL);KBe=n(fso,"STRONG",{});var B7a=s(KBe);H0t=r(B7a,"bert"),B7a.forEach(t),J0t=r(fso," \u2014 "),kme=n(fso,"A",{href:!0});var I7a=s(kme);Y0t=r(I7a,"FlaxBertForMaskedLM"),I7a.forEach(t),Z0t=r(fso," (BERT model)"),fso.forEach(t),K0t=i(Oe),ZL=n(Oe,"LI",{});var gso=s(ZL);eIe=n(gso,"STRONG",{});var N7a=s(eIe);ewt=r(N7a,"big_bird"),N7a.forEach(t),owt=r(gso," \u2014 "),Sme=n(gso,"A",{href:!0});var q7a=s(Sme);rwt=r(q7a,"FlaxBigBirdForMaskedLM"),q7a.forEach(t),twt=r(gso," (BigBird model)"),gso.forEach(t),awt=i(Oe),KL=n(Oe,"LI",{});var hso=s(KL);oIe=n(hso,"STRONG",{});var D7a=s(oIe);nwt=r(D7a,"distilbert"),D7a.forEach(t),swt=r(hso," \u2014 "),Rme=n(hso,"A",{href:!0});var j7a=s(Rme);lwt=r(j7a,"FlaxDistilBertForMaskedLM"),j7a.forEach(t),iwt=r(hso," (DistilBERT model)"),hso.forEach(t),dwt=i(Oe),ey=n(Oe,"LI",{});var uso=s(ey);rIe=n(uso,"STRONG",{});var G7a=s(rIe);mwt=r(G7a,"electra"),G7a.forEach(t),cwt=r(uso," \u2014 "),Pme=n(uso,"A",{href:!0});var O7a=s(Pme);fwt=r(O7a,"FlaxElectraForMaskedLM"),O7a.forEach(t),gwt=r(uso," (ELECTRA model)"),uso.forEach(t),hwt=i(Oe),oy=n(Oe,"LI",{});var pso=s(oy);tIe=n(pso,"STRONG",{});var V7a=s(tIe);uwt=r(V7a,"mbart"),V7a.forEach(t),pwt=r(pso," \u2014 "),Bme=n(pso,"A",{href:!0});var X7a=s(Bme);_wt=r(X7a,"FlaxMBartForConditionalGeneration"),X7a.forEach(t),bwt=r(pso," (mBART model)"),pso.forEach(t),vwt=i(Oe),ry=n(Oe,"LI",{});var _so=s(ry);aIe=n(_so,"STRONG",{});var z7a=s(aIe);Fwt=r(z7a,"roberta"),z7a.forEach(t),Twt=r(_so," \u2014 "),Ime=n(_so,"A",{href:!0});var Q7a=s(Ime);Mwt=r(Q7a,"FlaxRobertaForMaskedLM"),Q7a.forEach(t),Ewt=r(_so," (RoBERTa model)"),_so.forEach(t),Cwt=i(Oe),ty=n(Oe,"LI",{});var bso=s(ty);nIe=n(bso,"STRONG",{});var W7a=s(nIe);wwt=r(W7a,"roformer"),W7a.forEach(t),Awt=r(bso," \u2014 "),Nme=n(bso,"A",{href:!0});var U7a=s(Nme);Lwt=r(U7a,"FlaxRoFormerForMaskedLM"),U7a.forEach(t),ywt=r(bso," (RoFormer model)"),bso.forEach(t),xwt=i(Oe),ay=n(Oe,"LI",{});var vso=s(ay);sIe=n(vso,"STRONG",{});var H7a=s(sIe);$wt=r(H7a,"xlm-roberta"),H7a.forEach(t),kwt=r(vso," \u2014 "),qme=n(vso,"A",{href:!0});var J7a=s(qme);Swt=r(J7a,"FlaxXLMRobertaForMaskedLM"),J7a.forEach(t),Rwt=r(vso," (XLM-RoBERTa model)"),vso.forEach(t),Oe.forEach(t),Pwt=i(dd),T(ny.$$.fragment,dd),dd.forEach(t),id.forEach(t),vdo=i(c),Lf=n(c,"H2",{class:!0});var Xco=s(Lf);sy=n(Xco,"A",{id:!0,class:!0,href:!0});var Y7a=s(sy);lIe=n(Y7a,"SPAN",{});var Z7a=s(lIe);T(_I.$$.fragment,Z7a),Z7a.forEach(t),Y7a.forEach(t),Bwt=i(Xco),iIe=n(Xco,"SPAN",{});var K7a=s(iIe);Iwt=r(K7a,"FlaxAutoModelForSeq2SeqLM"),K7a.forEach(t),Xco.forEach(t),Fdo=i(c),Pr=n(c,"DIV",{class:!0});var md=s(Pr);T(bI.$$.fragment,md),Nwt=i(md),yf=n(md,"P",{});var Yge=s(yf);qwt=r(Yge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Dme=n(Yge,"A",{href:!0});var e8a=s(Dme);Dwt=r(e8a,"from_pretrained()"),e8a.forEach(t),jwt=r(Yge," class method or the "),jme=n(Yge,"A",{href:!0});var o8a=s(jme);Gwt=r(o8a,"from_config()"),o8a.forEach(t),Owt=r(Yge,` class
method.`),Yge.forEach(t),Vwt=i(md),vI=n(md,"P",{});var zco=s(vI);Xwt=r(zco,"This class cannot be instantiated directly using "),dIe=n(zco,"CODE",{});var r8a=s(dIe);zwt=r(r8a,"__init__()"),r8a.forEach(t),Qwt=r(zco," (throws an error)."),zco.forEach(t),Wwt=i(md),Ta=n(md,"DIV",{class:!0});var Q$=s(Ta);T(FI.$$.fragment,Q$),Uwt=i(Q$),mIe=n(Q$,"P",{});var t8a=s(mIe);Hwt=r(t8a,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),t8a.forEach(t),Jwt=i(Q$),xf=n(Q$,"P",{});var Zge=s(xf);Ywt=r(Zge,`Note:
Loading a model from its configuration file does `),cIe=n(Zge,"STRONG",{});var a8a=s(cIe);Zwt=r(a8a,"not"),a8a.forEach(t),Kwt=r(Zge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Gme=n(Zge,"A",{href:!0});var n8a=s(Gme);eAt=r(n8a,"from_pretrained()"),n8a.forEach(t),oAt=r(Zge," to load the model weights."),Zge.forEach(t),rAt=i(Q$),T(ly.$$.fragment,Q$),Q$.forEach(t),tAt=i(md),mt=n(md,"DIV",{class:!0});var cd=s(mt);T(TI.$$.fragment,cd),aAt=i(cd),fIe=n(cd,"P",{});var s8a=s(fIe);nAt=r(s8a,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),s8a.forEach(t),sAt=i(cd),ls=n(cd,"P",{});var W$=s(ls);lAt=r(W$,"The model class to instantiate is selected based on the "),gIe=n(W$,"CODE",{});var l8a=s(gIe);iAt=r(l8a,"model_type"),l8a.forEach(t),dAt=r(W$,` property of the config object (either
passed as an argument or loaded from `),hIe=n(W$,"CODE",{});var i8a=s(hIe);mAt=r(i8a,"pretrained_model_name_or_path"),i8a.forEach(t),cAt=r(W$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uIe=n(W$,"CODE",{});var d8a=s(uIe);fAt=r(d8a,"pretrained_model_name_or_path"),d8a.forEach(t),gAt=r(W$,":"),W$.forEach(t),hAt=i(cd),Pe=n(cd,"UL",{});var Ve=s(Pe);iy=n(Ve,"LI",{});var Fso=s(iy);pIe=n(Fso,"STRONG",{});var m8a=s(pIe);uAt=r(m8a,"bart"),m8a.forEach(t),pAt=r(Fso," \u2014 "),Ome=n(Fso,"A",{href:!0});var c8a=s(Ome);_At=r(c8a,"FlaxBartForConditionalGeneration"),c8a.forEach(t),bAt=r(Fso," (BART model)"),Fso.forEach(t),vAt=i(Ve),dy=n(Ve,"LI",{});var Tso=s(dy);_Ie=n(Tso,"STRONG",{});var f8a=s(_Ie);FAt=r(f8a,"blenderbot"),f8a.forEach(t),TAt=r(Tso," \u2014 "),Vme=n(Tso,"A",{href:!0});var g8a=s(Vme);MAt=r(g8a,"FlaxBlenderbotForConditionalGeneration"),g8a.forEach(t),EAt=r(Tso," (Blenderbot model)"),Tso.forEach(t),CAt=i(Ve),my=n(Ve,"LI",{});var Mso=s(my);bIe=n(Mso,"STRONG",{});var h8a=s(bIe);wAt=r(h8a,"blenderbot-small"),h8a.forEach(t),AAt=r(Mso," \u2014 "),Xme=n(Mso,"A",{href:!0});var u8a=s(Xme);LAt=r(u8a,"FlaxBlenderbotSmallForConditionalGeneration"),u8a.forEach(t),yAt=r(Mso," (BlenderbotSmall model)"),Mso.forEach(t),xAt=i(Ve),cy=n(Ve,"LI",{});var Eso=s(cy);vIe=n(Eso,"STRONG",{});var p8a=s(vIe);$At=r(p8a,"encoder-decoder"),p8a.forEach(t),kAt=r(Eso," \u2014 "),zme=n(Eso,"A",{href:!0});var _8a=s(zme);SAt=r(_8a,"FlaxEncoderDecoderModel"),_8a.forEach(t),RAt=r(Eso," (Encoder decoder model)"),Eso.forEach(t),PAt=i(Ve),fy=n(Ve,"LI",{});var Cso=s(fy);FIe=n(Cso,"STRONG",{});var b8a=s(FIe);BAt=r(b8a,"longt5"),b8a.forEach(t),IAt=r(Cso," \u2014 "),Qme=n(Cso,"A",{href:!0});var v8a=s(Qme);NAt=r(v8a,"FlaxLongT5ForConditionalGeneration"),v8a.forEach(t),qAt=r(Cso," (LongT5 model)"),Cso.forEach(t),DAt=i(Ve),gy=n(Ve,"LI",{});var wso=s(gy);TIe=n(wso,"STRONG",{});var F8a=s(TIe);jAt=r(F8a,"marian"),F8a.forEach(t),GAt=r(wso," \u2014 "),Wme=n(wso,"A",{href:!0});var T8a=s(Wme);OAt=r(T8a,"FlaxMarianMTModel"),T8a.forEach(t),VAt=r(wso," (Marian model)"),wso.forEach(t),XAt=i(Ve),hy=n(Ve,"LI",{});var Aso=s(hy);MIe=n(Aso,"STRONG",{});var M8a=s(MIe);zAt=r(M8a,"mbart"),M8a.forEach(t),QAt=r(Aso," \u2014 "),Ume=n(Aso,"A",{href:!0});var E8a=s(Ume);WAt=r(E8a,"FlaxMBartForConditionalGeneration"),E8a.forEach(t),UAt=r(Aso," (mBART model)"),Aso.forEach(t),HAt=i(Ve),uy=n(Ve,"LI",{});var Lso=s(uy);EIe=n(Lso,"STRONG",{});var C8a=s(EIe);JAt=r(C8a,"mt5"),C8a.forEach(t),YAt=r(Lso," \u2014 "),Hme=n(Lso,"A",{href:!0});var w8a=s(Hme);ZAt=r(w8a,"FlaxMT5ForConditionalGeneration"),w8a.forEach(t),KAt=r(Lso," (MT5 model)"),Lso.forEach(t),e6t=i(Ve),py=n(Ve,"LI",{});var yso=s(py);CIe=n(yso,"STRONG",{});var A8a=s(CIe);o6t=r(A8a,"pegasus"),A8a.forEach(t),r6t=r(yso," \u2014 "),Jme=n(yso,"A",{href:!0});var L8a=s(Jme);t6t=r(L8a,"FlaxPegasusForConditionalGeneration"),L8a.forEach(t),a6t=r(yso," (Pegasus model)"),yso.forEach(t),n6t=i(Ve),_y=n(Ve,"LI",{});var xso=s(_y);wIe=n(xso,"STRONG",{});var y8a=s(wIe);s6t=r(y8a,"t5"),y8a.forEach(t),l6t=r(xso," \u2014 "),Yme=n(xso,"A",{href:!0});var x8a=s(Yme);i6t=r(x8a,"FlaxT5ForConditionalGeneration"),x8a.forEach(t),d6t=r(xso," (T5 model)"),xso.forEach(t),Ve.forEach(t),m6t=i(cd),T(by.$$.fragment,cd),cd.forEach(t),md.forEach(t),Tdo=i(c),$f=n(c,"H2",{class:!0});var Qco=s($f);vy=n(Qco,"A",{id:!0,class:!0,href:!0});var $8a=s(vy);AIe=n($8a,"SPAN",{});var k8a=s(AIe);T(MI.$$.fragment,k8a),k8a.forEach(t),$8a.forEach(t),c6t=i(Qco),LIe=n(Qco,"SPAN",{});var S8a=s(LIe);f6t=r(S8a,"FlaxAutoModelForSequenceClassification"),S8a.forEach(t),Qco.forEach(t),Mdo=i(c),Br=n(c,"DIV",{class:!0});var fd=s(Br);T(EI.$$.fragment,fd),g6t=i(fd),kf=n(fd,"P",{});var Kge=s(kf);h6t=r(Kge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Zme=n(Kge,"A",{href:!0});var R8a=s(Zme);u6t=r(R8a,"from_pretrained()"),R8a.forEach(t),p6t=r(Kge," class method or the "),Kme=n(Kge,"A",{href:!0});var P8a=s(Kme);_6t=r(P8a,"from_config()"),P8a.forEach(t),b6t=r(Kge,` class
method.`),Kge.forEach(t),v6t=i(fd),CI=n(fd,"P",{});var Wco=s(CI);F6t=r(Wco,"This class cannot be instantiated directly using "),yIe=n(Wco,"CODE",{});var B8a=s(yIe);T6t=r(B8a,"__init__()"),B8a.forEach(t),M6t=r(Wco," (throws an error)."),Wco.forEach(t),E6t=i(fd),Ma=n(fd,"DIV",{class:!0});var U$=s(Ma);T(wI.$$.fragment,U$),C6t=i(U$),xIe=n(U$,"P",{});var I8a=s(xIe);w6t=r(I8a,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),I8a.forEach(t),A6t=i(U$),Sf=n(U$,"P",{});var ehe=s(Sf);L6t=r(ehe,`Note:
Loading a model from its configuration file does `),$Ie=n(ehe,"STRONG",{});var N8a=s($Ie);y6t=r(N8a,"not"),N8a.forEach(t),x6t=r(ehe,` load the model weights. It only affects the
model\u2019s configuration. Use `),ece=n(ehe,"A",{href:!0});var q8a=s(ece);$6t=r(q8a,"from_pretrained()"),q8a.forEach(t),k6t=r(ehe," to load the model weights."),ehe.forEach(t),S6t=i(U$),T(Fy.$$.fragment,U$),U$.forEach(t),R6t=i(fd),ct=n(fd,"DIV",{class:!0});var gd=s(ct);T(AI.$$.fragment,gd),P6t=i(gd),kIe=n(gd,"P",{});var D8a=s(kIe);B6t=r(D8a,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),D8a.forEach(t),I6t=i(gd),is=n(gd,"P",{});var H$=s(is);N6t=r(H$,"The model class to instantiate is selected based on the "),SIe=n(H$,"CODE",{});var j8a=s(SIe);q6t=r(j8a,"model_type"),j8a.forEach(t),D6t=r(H$,` property of the config object (either
passed as an argument or loaded from `),RIe=n(H$,"CODE",{});var G8a=s(RIe);j6t=r(G8a,"pretrained_model_name_or_path"),G8a.forEach(t),G6t=r(H$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),PIe=n(H$,"CODE",{});var O8a=s(PIe);O6t=r(O8a,"pretrained_model_name_or_path"),O8a.forEach(t),V6t=r(H$,":"),H$.forEach(t),X6t=i(gd),Be=n(gd,"UL",{});var Xe=s(Be);Ty=n(Xe,"LI",{});var $so=s(Ty);BIe=n($so,"STRONG",{});var V8a=s(BIe);z6t=r(V8a,"albert"),V8a.forEach(t),Q6t=r($so," \u2014 "),oce=n($so,"A",{href:!0});var X8a=s(oce);W6t=r(X8a,"FlaxAlbertForSequenceClassification"),X8a.forEach(t),U6t=r($so," (ALBERT model)"),$so.forEach(t),H6t=i(Xe),My=n(Xe,"LI",{});var kso=s(My);IIe=n(kso,"STRONG",{});var z8a=s(IIe);J6t=r(z8a,"bart"),z8a.forEach(t),Y6t=r(kso," \u2014 "),rce=n(kso,"A",{href:!0});var Q8a=s(rce);Z6t=r(Q8a,"FlaxBartForSequenceClassification"),Q8a.forEach(t),K6t=r(kso," (BART model)"),kso.forEach(t),e7t=i(Xe),Ey=n(Xe,"LI",{});var Sso=s(Ey);NIe=n(Sso,"STRONG",{});var W8a=s(NIe);o7t=r(W8a,"bert"),W8a.forEach(t),r7t=r(Sso," \u2014 "),tce=n(Sso,"A",{href:!0});var U8a=s(tce);t7t=r(U8a,"FlaxBertForSequenceClassification"),U8a.forEach(t),a7t=r(Sso," (BERT model)"),Sso.forEach(t),n7t=i(Xe),Cy=n(Xe,"LI",{});var Rso=s(Cy);qIe=n(Rso,"STRONG",{});var H8a=s(qIe);s7t=r(H8a,"big_bird"),H8a.forEach(t),l7t=r(Rso," \u2014 "),ace=n(Rso,"A",{href:!0});var J8a=s(ace);i7t=r(J8a,"FlaxBigBirdForSequenceClassification"),J8a.forEach(t),d7t=r(Rso," (BigBird model)"),Rso.forEach(t),m7t=i(Xe),wy=n(Xe,"LI",{});var Pso=s(wy);DIe=n(Pso,"STRONG",{});var Y8a=s(DIe);c7t=r(Y8a,"distilbert"),Y8a.forEach(t),f7t=r(Pso," \u2014 "),nce=n(Pso,"A",{href:!0});var Z8a=s(nce);g7t=r(Z8a,"FlaxDistilBertForSequenceClassification"),Z8a.forEach(t),h7t=r(Pso," (DistilBERT model)"),Pso.forEach(t),u7t=i(Xe),Ay=n(Xe,"LI",{});var Bso=s(Ay);jIe=n(Bso,"STRONG",{});var K8a=s(jIe);p7t=r(K8a,"electra"),K8a.forEach(t),_7t=r(Bso," \u2014 "),sce=n(Bso,"A",{href:!0});var eLa=s(sce);b7t=r(eLa,"FlaxElectraForSequenceClassification"),eLa.forEach(t),v7t=r(Bso," (ELECTRA model)"),Bso.forEach(t),F7t=i(Xe),Ly=n(Xe,"LI",{});var Iso=s(Ly);GIe=n(Iso,"STRONG",{});var oLa=s(GIe);T7t=r(oLa,"mbart"),oLa.forEach(t),M7t=r(Iso," \u2014 "),lce=n(Iso,"A",{href:!0});var rLa=s(lce);E7t=r(rLa,"FlaxMBartForSequenceClassification"),rLa.forEach(t),C7t=r(Iso," (mBART model)"),Iso.forEach(t),w7t=i(Xe),yy=n(Xe,"LI",{});var Nso=s(yy);OIe=n(Nso,"STRONG",{});var tLa=s(OIe);A7t=r(tLa,"roberta"),tLa.forEach(t),L7t=r(Nso," \u2014 "),ice=n(Nso,"A",{href:!0});var aLa=s(ice);y7t=r(aLa,"FlaxRobertaForSequenceClassification"),aLa.forEach(t),x7t=r(Nso," (RoBERTa model)"),Nso.forEach(t),$7t=i(Xe),xy=n(Xe,"LI",{});var qso=s(xy);VIe=n(qso,"STRONG",{});var nLa=s(VIe);k7t=r(nLa,"roformer"),nLa.forEach(t),S7t=r(qso," \u2014 "),dce=n(qso,"A",{href:!0});var sLa=s(dce);R7t=r(sLa,"FlaxRoFormerForSequenceClassification"),sLa.forEach(t),P7t=r(qso," (RoFormer model)"),qso.forEach(t),B7t=i(Xe),$y=n(Xe,"LI",{});var Dso=s($y);XIe=n(Dso,"STRONG",{});var lLa=s(XIe);I7t=r(lLa,"xlm-roberta"),lLa.forEach(t),N7t=r(Dso," \u2014 "),mce=n(Dso,"A",{href:!0});var iLa=s(mce);q7t=r(iLa,"FlaxXLMRobertaForSequenceClassification"),iLa.forEach(t),D7t=r(Dso," (XLM-RoBERTa model)"),Dso.forEach(t),Xe.forEach(t),j7t=i(gd),T(ky.$$.fragment,gd),gd.forEach(t),fd.forEach(t),Edo=i(c),Rf=n(c,"H2",{class:!0});var Uco=s(Rf);Sy=n(Uco,"A",{id:!0,class:!0,href:!0});var dLa=s(Sy);zIe=n(dLa,"SPAN",{});var mLa=s(zIe);T(LI.$$.fragment,mLa),mLa.forEach(t),dLa.forEach(t),G7t=i(Uco),QIe=n(Uco,"SPAN",{});var cLa=s(QIe);O7t=r(cLa,"FlaxAutoModelForQuestionAnswering"),cLa.forEach(t),Uco.forEach(t),Cdo=i(c),Ir=n(c,"DIV",{class:!0});var hd=s(Ir);T(yI.$$.fragment,hd),V7t=i(hd),Pf=n(hd,"P",{});var ohe=s(Pf);X7t=r(ohe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),cce=n(ohe,"A",{href:!0});var fLa=s(cce);z7t=r(fLa,"from_pretrained()"),fLa.forEach(t),Q7t=r(ohe," class method or the "),fce=n(ohe,"A",{href:!0});var gLa=s(fce);W7t=r(gLa,"from_config()"),gLa.forEach(t),U7t=r(ohe,` class
method.`),ohe.forEach(t),H7t=i(hd),xI=n(hd,"P",{});var Hco=s(xI);J7t=r(Hco,"This class cannot be instantiated directly using "),WIe=n(Hco,"CODE",{});var hLa=s(WIe);Y7t=r(hLa,"__init__()"),hLa.forEach(t),Z7t=r(Hco," (throws an error)."),Hco.forEach(t),K7t=i(hd),Ea=n(hd,"DIV",{class:!0});var J$=s(Ea);T($I.$$.fragment,J$),e8t=i(J$),UIe=n(J$,"P",{});var uLa=s(UIe);o8t=r(uLa,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),uLa.forEach(t),r8t=i(J$),Bf=n(J$,"P",{});var rhe=s(Bf);t8t=r(rhe,`Note:
Loading a model from its configuration file does `),HIe=n(rhe,"STRONG",{});var pLa=s(HIe);a8t=r(pLa,"not"),pLa.forEach(t),n8t=r(rhe,` load the model weights. It only affects the
model\u2019s configuration. Use `),gce=n(rhe,"A",{href:!0});var _La=s(gce);s8t=r(_La,"from_pretrained()"),_La.forEach(t),l8t=r(rhe," to load the model weights."),rhe.forEach(t),i8t=i(J$),T(Ry.$$.fragment,J$),J$.forEach(t),d8t=i(hd),ft=n(hd,"DIV",{class:!0});var ud=s(ft);T(kI.$$.fragment,ud),m8t=i(ud),JIe=n(ud,"P",{});var bLa=s(JIe);c8t=r(bLa,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),bLa.forEach(t),f8t=i(ud),ds=n(ud,"P",{});var Y$=s(ds);g8t=r(Y$,"The model class to instantiate is selected based on the "),YIe=n(Y$,"CODE",{});var vLa=s(YIe);h8t=r(vLa,"model_type"),vLa.forEach(t),u8t=r(Y$,` property of the config object (either
passed as an argument or loaded from `),ZIe=n(Y$,"CODE",{});var FLa=s(ZIe);p8t=r(FLa,"pretrained_model_name_or_path"),FLa.forEach(t),_8t=r(Y$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KIe=n(Y$,"CODE",{});var TLa=s(KIe);b8t=r(TLa,"pretrained_model_name_or_path"),TLa.forEach(t),v8t=r(Y$,":"),Y$.forEach(t),F8t=i(ud),Ie=n(ud,"UL",{});var ze=s(Ie);Py=n(ze,"LI",{});var jso=s(Py);eNe=n(jso,"STRONG",{});var MLa=s(eNe);T8t=r(MLa,"albert"),MLa.forEach(t),M8t=r(jso," \u2014 "),hce=n(jso,"A",{href:!0});var ELa=s(hce);E8t=r(ELa,"FlaxAlbertForQuestionAnswering"),ELa.forEach(t),C8t=r(jso," (ALBERT model)"),jso.forEach(t),w8t=i(ze),By=n(ze,"LI",{});var Gso=s(By);oNe=n(Gso,"STRONG",{});var CLa=s(oNe);A8t=r(CLa,"bart"),CLa.forEach(t),L8t=r(Gso," \u2014 "),uce=n(Gso,"A",{href:!0});var wLa=s(uce);y8t=r(wLa,"FlaxBartForQuestionAnswering"),wLa.forEach(t),x8t=r(Gso," (BART model)"),Gso.forEach(t),$8t=i(ze),Iy=n(ze,"LI",{});var Oso=s(Iy);rNe=n(Oso,"STRONG",{});var ALa=s(rNe);k8t=r(ALa,"bert"),ALa.forEach(t),S8t=r(Oso," \u2014 "),pce=n(Oso,"A",{href:!0});var LLa=s(pce);R8t=r(LLa,"FlaxBertForQuestionAnswering"),LLa.forEach(t),P8t=r(Oso," (BERT model)"),Oso.forEach(t),B8t=i(ze),Ny=n(ze,"LI",{});var Vso=s(Ny);tNe=n(Vso,"STRONG",{});var yLa=s(tNe);I8t=r(yLa,"big_bird"),yLa.forEach(t),N8t=r(Vso," \u2014 "),_ce=n(Vso,"A",{href:!0});var xLa=s(_ce);q8t=r(xLa,"FlaxBigBirdForQuestionAnswering"),xLa.forEach(t),D8t=r(Vso," (BigBird model)"),Vso.forEach(t),j8t=i(ze),qy=n(ze,"LI",{});var Xso=s(qy);aNe=n(Xso,"STRONG",{});var $La=s(aNe);G8t=r($La,"distilbert"),$La.forEach(t),O8t=r(Xso," \u2014 "),bce=n(Xso,"A",{href:!0});var kLa=s(bce);V8t=r(kLa,"FlaxDistilBertForQuestionAnswering"),kLa.forEach(t),X8t=r(Xso," (DistilBERT model)"),Xso.forEach(t),z8t=i(ze),Dy=n(ze,"LI",{});var zso=s(Dy);nNe=n(zso,"STRONG",{});var SLa=s(nNe);Q8t=r(SLa,"electra"),SLa.forEach(t),W8t=r(zso," \u2014 "),vce=n(zso,"A",{href:!0});var RLa=s(vce);U8t=r(RLa,"FlaxElectraForQuestionAnswering"),RLa.forEach(t),H8t=r(zso," (ELECTRA model)"),zso.forEach(t),J8t=i(ze),jy=n(ze,"LI",{});var Qso=s(jy);sNe=n(Qso,"STRONG",{});var PLa=s(sNe);Y8t=r(PLa,"mbart"),PLa.forEach(t),Z8t=r(Qso," \u2014 "),Fce=n(Qso,"A",{href:!0});var BLa=s(Fce);K8t=r(BLa,"FlaxMBartForQuestionAnswering"),BLa.forEach(t),eLt=r(Qso," (mBART model)"),Qso.forEach(t),oLt=i(ze),Gy=n(ze,"LI",{});var Wso=s(Gy);lNe=n(Wso,"STRONG",{});var ILa=s(lNe);rLt=r(ILa,"roberta"),ILa.forEach(t),tLt=r(Wso," \u2014 "),Tce=n(Wso,"A",{href:!0});var NLa=s(Tce);aLt=r(NLa,"FlaxRobertaForQuestionAnswering"),NLa.forEach(t),nLt=r(Wso," (RoBERTa model)"),Wso.forEach(t),sLt=i(ze),Oy=n(ze,"LI",{});var Uso=s(Oy);iNe=n(Uso,"STRONG",{});var qLa=s(iNe);lLt=r(qLa,"roformer"),qLa.forEach(t),iLt=r(Uso," \u2014 "),Mce=n(Uso,"A",{href:!0});var DLa=s(Mce);dLt=r(DLa,"FlaxRoFormerForQuestionAnswering"),DLa.forEach(t),mLt=r(Uso," (RoFormer model)"),Uso.forEach(t),cLt=i(ze),Vy=n(ze,"LI",{});var Hso=s(Vy);dNe=n(Hso,"STRONG",{});var jLa=s(dNe);fLt=r(jLa,"xlm-roberta"),jLa.forEach(t),gLt=r(Hso," \u2014 "),Ece=n(Hso,"A",{href:!0});var GLa=s(Ece);hLt=r(GLa,"FlaxXLMRobertaForQuestionAnswering"),GLa.forEach(t),uLt=r(Hso," (XLM-RoBERTa model)"),Hso.forEach(t),ze.forEach(t),pLt=i(ud),T(Xy.$$.fragment,ud),ud.forEach(t),hd.forEach(t),wdo=i(c),If=n(c,"H2",{class:!0});var Jco=s(If);zy=n(Jco,"A",{id:!0,class:!0,href:!0});var OLa=s(zy);mNe=n(OLa,"SPAN",{});var VLa=s(mNe);T(SI.$$.fragment,VLa),VLa.forEach(t),OLa.forEach(t),_Lt=i(Jco),cNe=n(Jco,"SPAN",{});var XLa=s(cNe);bLt=r(XLa,"FlaxAutoModelForTokenClassification"),XLa.forEach(t),Jco.forEach(t),Ado=i(c),Nr=n(c,"DIV",{class:!0});var pd=s(Nr);T(RI.$$.fragment,pd),vLt=i(pd),Nf=n(pd,"P",{});var the=s(Nf);FLt=r(the,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Cce=n(the,"A",{href:!0});var zLa=s(Cce);TLt=r(zLa,"from_pretrained()"),zLa.forEach(t),MLt=r(the," class method or the "),wce=n(the,"A",{href:!0});var QLa=s(wce);ELt=r(QLa,"from_config()"),QLa.forEach(t),CLt=r(the,` class
method.`),the.forEach(t),wLt=i(pd),PI=n(pd,"P",{});var Yco=s(PI);ALt=r(Yco,"This class cannot be instantiated directly using "),fNe=n(Yco,"CODE",{});var WLa=s(fNe);LLt=r(WLa,"__init__()"),WLa.forEach(t),yLt=r(Yco," (throws an error)."),Yco.forEach(t),xLt=i(pd),Ca=n(pd,"DIV",{class:!0});var Z$=s(Ca);T(BI.$$.fragment,Z$),$Lt=i(Z$),gNe=n(Z$,"P",{});var ULa=s(gNe);kLt=r(ULa,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),ULa.forEach(t),SLt=i(Z$),qf=n(Z$,"P",{});var ahe=s(qf);RLt=r(ahe,`Note:
Loading a model from its configuration file does `),hNe=n(ahe,"STRONG",{});var HLa=s(hNe);PLt=r(HLa,"not"),HLa.forEach(t),BLt=r(ahe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ace=n(ahe,"A",{href:!0});var JLa=s(Ace);ILt=r(JLa,"from_pretrained()"),JLa.forEach(t),NLt=r(ahe," to load the model weights."),ahe.forEach(t),qLt=i(Z$),T(Qy.$$.fragment,Z$),Z$.forEach(t),DLt=i(pd),gt=n(pd,"DIV",{class:!0});var _d=s(gt);T(II.$$.fragment,_d),jLt=i(_d),uNe=n(_d,"P",{});var YLa=s(uNe);GLt=r(YLa,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),YLa.forEach(t),OLt=i(_d),ms=n(_d,"P",{});var K$=s(ms);VLt=r(K$,"The model class to instantiate is selected based on the "),pNe=n(K$,"CODE",{});var ZLa=s(pNe);XLt=r(ZLa,"model_type"),ZLa.forEach(t),zLt=r(K$,` property of the config object (either
passed as an argument or loaded from `),_Ne=n(K$,"CODE",{});var KLa=s(_Ne);QLt=r(KLa,"pretrained_model_name_or_path"),KLa.forEach(t),WLt=r(K$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bNe=n(K$,"CODE",{});var eya=s(bNe);ULt=r(eya,"pretrained_model_name_or_path"),eya.forEach(t),HLt=r(K$,":"),K$.forEach(t),JLt=i(_d),We=n(_d,"UL",{});var So=s(We);Wy=n(So,"LI",{});var Jso=s(Wy);vNe=n(Jso,"STRONG",{});var oya=s(vNe);YLt=r(oya,"albert"),oya.forEach(t),ZLt=r(Jso," \u2014 "),Lce=n(Jso,"A",{href:!0});var rya=s(Lce);KLt=r(rya,"FlaxAlbertForTokenClassification"),rya.forEach(t),eyt=r(Jso," (ALBERT model)"),Jso.forEach(t),oyt=i(So),Uy=n(So,"LI",{});var Yso=s(Uy);FNe=n(Yso,"STRONG",{});var tya=s(FNe);ryt=r(tya,"bert"),tya.forEach(t),tyt=r(Yso," \u2014 "),yce=n(Yso,"A",{href:!0});var aya=s(yce);ayt=r(aya,"FlaxBertForTokenClassification"),aya.forEach(t),nyt=r(Yso," (BERT model)"),Yso.forEach(t),syt=i(So),Hy=n(So,"LI",{});var Zso=s(Hy);TNe=n(Zso,"STRONG",{});var nya=s(TNe);lyt=r(nya,"big_bird"),nya.forEach(t),iyt=r(Zso," \u2014 "),xce=n(Zso,"A",{href:!0});var sya=s(xce);dyt=r(sya,"FlaxBigBirdForTokenClassification"),sya.forEach(t),myt=r(Zso," (BigBird model)"),Zso.forEach(t),cyt=i(So),Jy=n(So,"LI",{});var Kso=s(Jy);MNe=n(Kso,"STRONG",{});var lya=s(MNe);fyt=r(lya,"distilbert"),lya.forEach(t),gyt=r(Kso," \u2014 "),$ce=n(Kso,"A",{href:!0});var iya=s($ce);hyt=r(iya,"FlaxDistilBertForTokenClassification"),iya.forEach(t),uyt=r(Kso," (DistilBERT model)"),Kso.forEach(t),pyt=i(So),Yy=n(So,"LI",{});var elo=s(Yy);ENe=n(elo,"STRONG",{});var dya=s(ENe);_yt=r(dya,"electra"),dya.forEach(t),byt=r(elo," \u2014 "),kce=n(elo,"A",{href:!0});var mya=s(kce);vyt=r(mya,"FlaxElectraForTokenClassification"),mya.forEach(t),Fyt=r(elo," (ELECTRA model)"),elo.forEach(t),Tyt=i(So),Zy=n(So,"LI",{});var olo=s(Zy);CNe=n(olo,"STRONG",{});var cya=s(CNe);Myt=r(cya,"roberta"),cya.forEach(t),Eyt=r(olo," \u2014 "),Sce=n(olo,"A",{href:!0});var fya=s(Sce);Cyt=r(fya,"FlaxRobertaForTokenClassification"),fya.forEach(t),wyt=r(olo," (RoBERTa model)"),olo.forEach(t),Ayt=i(So),Ky=n(So,"LI",{});var rlo=s(Ky);wNe=n(rlo,"STRONG",{});var gya=s(wNe);Lyt=r(gya,"roformer"),gya.forEach(t),yyt=r(rlo," \u2014 "),Rce=n(rlo,"A",{href:!0});var hya=s(Rce);xyt=r(hya,"FlaxRoFormerForTokenClassification"),hya.forEach(t),$yt=r(rlo," (RoFormer model)"),rlo.forEach(t),kyt=i(So),e9=n(So,"LI",{});var tlo=s(e9);ANe=n(tlo,"STRONG",{});var uya=s(ANe);Syt=r(uya,"xlm-roberta"),uya.forEach(t),Ryt=r(tlo," \u2014 "),Pce=n(tlo,"A",{href:!0});var pya=s(Pce);Pyt=r(pya,"FlaxXLMRobertaForTokenClassification"),pya.forEach(t),Byt=r(tlo," (XLM-RoBERTa model)"),tlo.forEach(t),So.forEach(t),Iyt=i(_d),T(o9.$$.fragment,_d),_d.forEach(t),pd.forEach(t),Ldo=i(c),Df=n(c,"H2",{class:!0});var Zco=s(Df);r9=n(Zco,"A",{id:!0,class:!0,href:!0});var _ya=s(r9);LNe=n(_ya,"SPAN",{});var bya=s(LNe);T(NI.$$.fragment,bya),bya.forEach(t),_ya.forEach(t),Nyt=i(Zco),yNe=n(Zco,"SPAN",{});var vya=s(yNe);qyt=r(vya,"FlaxAutoModelForMultipleChoice"),vya.forEach(t),Zco.forEach(t),ydo=i(c),qr=n(c,"DIV",{class:!0});var bd=s(qr);T(qI.$$.fragment,bd),Dyt=i(bd),jf=n(bd,"P",{});var nhe=s(jf);jyt=r(nhe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Bce=n(nhe,"A",{href:!0});var Fya=s(Bce);Gyt=r(Fya,"from_pretrained()"),Fya.forEach(t),Oyt=r(nhe," class method or the "),Ice=n(nhe,"A",{href:!0});var Tya=s(Ice);Vyt=r(Tya,"from_config()"),Tya.forEach(t),Xyt=r(nhe,` class
method.`),nhe.forEach(t),zyt=i(bd),DI=n(bd,"P",{});var Kco=s(DI);Qyt=r(Kco,"This class cannot be instantiated directly using "),xNe=n(Kco,"CODE",{});var Mya=s(xNe);Wyt=r(Mya,"__init__()"),Mya.forEach(t),Uyt=r(Kco," (throws an error)."),Kco.forEach(t),Hyt=i(bd),wa=n(bd,"DIV",{class:!0});var ek=s(wa);T(jI.$$.fragment,ek),Jyt=i(ek),$Ne=n(ek,"P",{});var Eya=s($Ne);Yyt=r(Eya,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Eya.forEach(t),Zyt=i(ek),Gf=n(ek,"P",{});var she=s(Gf);Kyt=r(she,`Note:
Loading a model from its configuration file does `),kNe=n(she,"STRONG",{});var Cya=s(kNe);e9t=r(Cya,"not"),Cya.forEach(t),o9t=r(she,` load the model weights. It only affects the
model\u2019s configuration. Use `),Nce=n(she,"A",{href:!0});var wya=s(Nce);r9t=r(wya,"from_pretrained()"),wya.forEach(t),t9t=r(she," to load the model weights."),she.forEach(t),a9t=i(ek),T(t9.$$.fragment,ek),ek.forEach(t),n9t=i(bd),ht=n(bd,"DIV",{class:!0});var vd=s(ht);T(GI.$$.fragment,vd),s9t=i(vd),SNe=n(vd,"P",{});var Aya=s(SNe);l9t=r(Aya,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Aya.forEach(t),i9t=i(vd),cs=n(vd,"P",{});var ok=s(cs);d9t=r(ok,"The model class to instantiate is selected based on the "),RNe=n(ok,"CODE",{});var Lya=s(RNe);m9t=r(Lya,"model_type"),Lya.forEach(t),c9t=r(ok,` property of the config object (either
passed as an argument or loaded from `),PNe=n(ok,"CODE",{});var yya=s(PNe);f9t=r(yya,"pretrained_model_name_or_path"),yya.forEach(t),g9t=r(ok,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),BNe=n(ok,"CODE",{});var xya=s(BNe);h9t=r(xya,"pretrained_model_name_or_path"),xya.forEach(t),u9t=r(ok,":"),ok.forEach(t),p9t=i(vd),Ue=n(vd,"UL",{});var Ro=s(Ue);a9=n(Ro,"LI",{});var alo=s(a9);INe=n(alo,"STRONG",{});var $ya=s(INe);_9t=r($ya,"albert"),$ya.forEach(t),b9t=r(alo," \u2014 "),qce=n(alo,"A",{href:!0});var kya=s(qce);v9t=r(kya,"FlaxAlbertForMultipleChoice"),kya.forEach(t),F9t=r(alo," (ALBERT model)"),alo.forEach(t),T9t=i(Ro),n9=n(Ro,"LI",{});var nlo=s(n9);NNe=n(nlo,"STRONG",{});var Sya=s(NNe);M9t=r(Sya,"bert"),Sya.forEach(t),E9t=r(nlo," \u2014 "),Dce=n(nlo,"A",{href:!0});var Rya=s(Dce);C9t=r(Rya,"FlaxBertForMultipleChoice"),Rya.forEach(t),w9t=r(nlo," (BERT model)"),nlo.forEach(t),A9t=i(Ro),s9=n(Ro,"LI",{});var slo=s(s9);qNe=n(slo,"STRONG",{});var Pya=s(qNe);L9t=r(Pya,"big_bird"),Pya.forEach(t),y9t=r(slo," \u2014 "),jce=n(slo,"A",{href:!0});var Bya=s(jce);x9t=r(Bya,"FlaxBigBirdForMultipleChoice"),Bya.forEach(t),$9t=r(slo," (BigBird model)"),slo.forEach(t),k9t=i(Ro),l9=n(Ro,"LI",{});var llo=s(l9);DNe=n(llo,"STRONG",{});var Iya=s(DNe);S9t=r(Iya,"distilbert"),Iya.forEach(t),R9t=r(llo," \u2014 "),Gce=n(llo,"A",{href:!0});var Nya=s(Gce);P9t=r(Nya,"FlaxDistilBertForMultipleChoice"),Nya.forEach(t),B9t=r(llo," (DistilBERT model)"),llo.forEach(t),I9t=i(Ro),i9=n(Ro,"LI",{});var ilo=s(i9);jNe=n(ilo,"STRONG",{});var qya=s(jNe);N9t=r(qya,"electra"),qya.forEach(t),q9t=r(ilo," \u2014 "),Oce=n(ilo,"A",{href:!0});var Dya=s(Oce);D9t=r(Dya,"FlaxElectraForMultipleChoice"),Dya.forEach(t),j9t=r(ilo," (ELECTRA model)"),ilo.forEach(t),G9t=i(Ro),d9=n(Ro,"LI",{});var dlo=s(d9);GNe=n(dlo,"STRONG",{});var jya=s(GNe);O9t=r(jya,"roberta"),jya.forEach(t),V9t=r(dlo," \u2014 "),Vce=n(dlo,"A",{href:!0});var Gya=s(Vce);X9t=r(Gya,"FlaxRobertaForMultipleChoice"),Gya.forEach(t),z9t=r(dlo," (RoBERTa model)"),dlo.forEach(t),Q9t=i(Ro),m9=n(Ro,"LI",{});var mlo=s(m9);ONe=n(mlo,"STRONG",{});var Oya=s(ONe);W9t=r(Oya,"roformer"),Oya.forEach(t),U9t=r(mlo," \u2014 "),Xce=n(mlo,"A",{href:!0});var Vya=s(Xce);H9t=r(Vya,"FlaxRoFormerForMultipleChoice"),Vya.forEach(t),J9t=r(mlo," (RoFormer model)"),mlo.forEach(t),Y9t=i(Ro),c9=n(Ro,"LI",{});var clo=s(c9);VNe=n(clo,"STRONG",{});var Xya=s(VNe);Z9t=r(Xya,"xlm-roberta"),Xya.forEach(t),K9t=r(clo," \u2014 "),zce=n(clo,"A",{href:!0});var zya=s(zce);ext=r(zya,"FlaxXLMRobertaForMultipleChoice"),zya.forEach(t),oxt=r(clo," (XLM-RoBERTa model)"),clo.forEach(t),Ro.forEach(t),rxt=i(vd),T(f9.$$.fragment,vd),vd.forEach(t),bd.forEach(t),xdo=i(c),Of=n(c,"H2",{class:!0});var efo=s(Of);g9=n(efo,"A",{id:!0,class:!0,href:!0});var Qya=s(g9);XNe=n(Qya,"SPAN",{});var Wya=s(XNe);T(OI.$$.fragment,Wya),Wya.forEach(t),Qya.forEach(t),txt=i(efo),zNe=n(efo,"SPAN",{});var Uya=s(zNe);axt=r(Uya,"FlaxAutoModelForNextSentencePrediction"),Uya.forEach(t),efo.forEach(t),$do=i(c),Dr=n(c,"DIV",{class:!0});var Fd=s(Dr);T(VI.$$.fragment,Fd),nxt=i(Fd),Vf=n(Fd,"P",{});var lhe=s(Vf);sxt=r(lhe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Qce=n(lhe,"A",{href:!0});var Hya=s(Qce);lxt=r(Hya,"from_pretrained()"),Hya.forEach(t),ixt=r(lhe," class method or the "),Wce=n(lhe,"A",{href:!0});var Jya=s(Wce);dxt=r(Jya,"from_config()"),Jya.forEach(t),mxt=r(lhe,` class
method.`),lhe.forEach(t),cxt=i(Fd),XI=n(Fd,"P",{});var ofo=s(XI);fxt=r(ofo,"This class cannot be instantiated directly using "),QNe=n(ofo,"CODE",{});var Yya=s(QNe);gxt=r(Yya,"__init__()"),Yya.forEach(t),hxt=r(ofo," (throws an error)."),ofo.forEach(t),uxt=i(Fd),Aa=n(Fd,"DIV",{class:!0});var rk=s(Aa);T(zI.$$.fragment,rk),pxt=i(rk),WNe=n(rk,"P",{});var Zya=s(WNe);_xt=r(Zya,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Zya.forEach(t),bxt=i(rk),Xf=n(rk,"P",{});var ihe=s(Xf);vxt=r(ihe,`Note:
Loading a model from its configuration file does `),UNe=n(ihe,"STRONG",{});var Kya=s(UNe);Fxt=r(Kya,"not"),Kya.forEach(t),Txt=r(ihe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Uce=n(ihe,"A",{href:!0});var e9a=s(Uce);Mxt=r(e9a,"from_pretrained()"),e9a.forEach(t),Ext=r(ihe," to load the model weights."),ihe.forEach(t),Cxt=i(rk),T(h9.$$.fragment,rk),rk.forEach(t),wxt=i(Fd),ut=n(Fd,"DIV",{class:!0});var Td=s(ut);T(QI.$$.fragment,Td),Axt=i(Td),HNe=n(Td,"P",{});var o9a=s(HNe);Lxt=r(o9a,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),o9a.forEach(t),yxt=i(Td),fs=n(Td,"P",{});var tk=s(fs);xxt=r(tk,"The model class to instantiate is selected based on the "),JNe=n(tk,"CODE",{});var r9a=s(JNe);$xt=r(r9a,"model_type"),r9a.forEach(t),kxt=r(tk,` property of the config object (either
passed as an argument or loaded from `),YNe=n(tk,"CODE",{});var t9a=s(YNe);Sxt=r(t9a,"pretrained_model_name_or_path"),t9a.forEach(t),Rxt=r(tk,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ZNe=n(tk,"CODE",{});var a9a=s(ZNe);Pxt=r(a9a,"pretrained_model_name_or_path"),a9a.forEach(t),Bxt=r(tk,":"),tk.forEach(t),Ixt=i(Td),KNe=n(Td,"UL",{});var n9a=s(KNe);u9=n(n9a,"LI",{});var flo=s(u9);eqe=n(flo,"STRONG",{});var s9a=s(eqe);Nxt=r(s9a,"bert"),s9a.forEach(t),qxt=r(flo," \u2014 "),Hce=n(flo,"A",{href:!0});var l9a=s(Hce);Dxt=r(l9a,"FlaxBertForNextSentencePrediction"),l9a.forEach(t),jxt=r(flo," (BERT model)"),flo.forEach(t),n9a.forEach(t),Gxt=i(Td),T(p9.$$.fragment,Td),Td.forEach(t),Fd.forEach(t),kdo=i(c),zf=n(c,"H2",{class:!0});var rfo=s(zf);_9=n(rfo,"A",{id:!0,class:!0,href:!0});var i9a=s(_9);oqe=n(i9a,"SPAN",{});var d9a=s(oqe);T(WI.$$.fragment,d9a),d9a.forEach(t),i9a.forEach(t),Oxt=i(rfo),rqe=n(rfo,"SPAN",{});var m9a=s(rqe);Vxt=r(m9a,"FlaxAutoModelForImageClassification"),m9a.forEach(t),rfo.forEach(t),Sdo=i(c),jr=n(c,"DIV",{class:!0});var Md=s(jr);T(UI.$$.fragment,Md),Xxt=i(Md),Qf=n(Md,"P",{});var dhe=s(Qf);zxt=r(dhe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Jce=n(dhe,"A",{href:!0});var c9a=s(Jce);Qxt=r(c9a,"from_pretrained()"),c9a.forEach(t),Wxt=r(dhe," class method or the "),Yce=n(dhe,"A",{href:!0});var f9a=s(Yce);Uxt=r(f9a,"from_config()"),f9a.forEach(t),Hxt=r(dhe,` class
method.`),dhe.forEach(t),Jxt=i(Md),HI=n(Md,"P",{});var tfo=s(HI);Yxt=r(tfo,"This class cannot be instantiated directly using "),tqe=n(tfo,"CODE",{});var g9a=s(tqe);Zxt=r(g9a,"__init__()"),g9a.forEach(t),Kxt=r(tfo," (throws an error)."),tfo.forEach(t),e$t=i(Md),La=n(Md,"DIV",{class:!0});var ak=s(La);T(JI.$$.fragment,ak),o$t=i(ak),aqe=n(ak,"P",{});var h9a=s(aqe);r$t=r(h9a,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),h9a.forEach(t),t$t=i(ak),Wf=n(ak,"P",{});var mhe=s(Wf);a$t=r(mhe,`Note:
Loading a model from its configuration file does `),nqe=n(mhe,"STRONG",{});var u9a=s(nqe);n$t=r(u9a,"not"),u9a.forEach(t),s$t=r(mhe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Zce=n(mhe,"A",{href:!0});var p9a=s(Zce);l$t=r(p9a,"from_pretrained()"),p9a.forEach(t),i$t=r(mhe," to load the model weights."),mhe.forEach(t),d$t=i(ak),T(b9.$$.fragment,ak),ak.forEach(t),m$t=i(Md),pt=n(Md,"DIV",{class:!0});var Ed=s(pt);T(YI.$$.fragment,Ed),c$t=i(Ed),sqe=n(Ed,"P",{});var _9a=s(sqe);f$t=r(_9a,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),_9a.forEach(t),g$t=i(Ed),gs=n(Ed,"P",{});var nk=s(gs);h$t=r(nk,"The model class to instantiate is selected based on the "),lqe=n(nk,"CODE",{});var b9a=s(lqe);u$t=r(b9a,"model_type"),b9a.forEach(t),p$t=r(nk,` property of the config object (either
passed as an argument or loaded from `),iqe=n(nk,"CODE",{});var v9a=s(iqe);_$t=r(v9a,"pretrained_model_name_or_path"),v9a.forEach(t),b$t=r(nk,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dqe=n(nk,"CODE",{});var F9a=s(dqe);v$t=r(F9a,"pretrained_model_name_or_path"),F9a.forEach(t),F$t=r(nk,":"),nk.forEach(t),T$t=i(Ed),ZI=n(Ed,"UL",{});var afo=s(ZI);v9=n(afo,"LI",{});var glo=s(v9);mqe=n(glo,"STRONG",{});var T9a=s(mqe);M$t=r(T9a,"beit"),T9a.forEach(t),E$t=r(glo," \u2014 "),Kce=n(glo,"A",{href:!0});var M9a=s(Kce);C$t=r(M9a,"FlaxBeitForImageClassification"),M9a.forEach(t),w$t=r(glo," (BEiT model)"),glo.forEach(t),A$t=i(afo),F9=n(afo,"LI",{});var hlo=s(F9);cqe=n(hlo,"STRONG",{});var E9a=s(cqe);L$t=r(E9a,"vit"),E9a.forEach(t),y$t=r(hlo," \u2014 "),efe=n(hlo,"A",{href:!0});var C9a=s(efe);x$t=r(C9a,"FlaxViTForImageClassification"),C9a.forEach(t),$$t=r(hlo," (ViT model)"),hlo.forEach(t),afo.forEach(t),k$t=i(Ed),T(T9.$$.fragment,Ed),Ed.forEach(t),Md.forEach(t),Rdo=i(c),Uf=n(c,"H2",{class:!0});var nfo=s(Uf);M9=n(nfo,"A",{id:!0,class:!0,href:!0});var w9a=s(M9);fqe=n(w9a,"SPAN",{});var A9a=s(fqe);T(KI.$$.fragment,A9a),A9a.forEach(t),w9a.forEach(t),S$t=i(nfo),gqe=n(nfo,"SPAN",{});var L9a=s(gqe);R$t=r(L9a,"FlaxAutoModelForVision2Seq"),L9a.forEach(t),nfo.forEach(t),Pdo=i(c),Gr=n(c,"DIV",{class:!0});var Cd=s(Gr);T(eN.$$.fragment,Cd),P$t=i(Cd),Hf=n(Cd,"P",{});var che=s(Hf);B$t=r(che,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),ofe=n(che,"A",{href:!0});var y9a=s(ofe);I$t=r(y9a,"from_pretrained()"),y9a.forEach(t),N$t=r(che," class method or the "),rfe=n(che,"A",{href:!0});var x9a=s(rfe);q$t=r(x9a,"from_config()"),x9a.forEach(t),D$t=r(che,` class
method.`),che.forEach(t),j$t=i(Cd),oN=n(Cd,"P",{});var sfo=s(oN);G$t=r(sfo,"This class cannot be instantiated directly using "),hqe=n(sfo,"CODE",{});var $9a=s(hqe);O$t=r($9a,"__init__()"),$9a.forEach(t),V$t=r(sfo," (throws an error)."),sfo.forEach(t),X$t=i(Cd),ya=n(Cd,"DIV",{class:!0});var sk=s(ya);T(rN.$$.fragment,sk),z$t=i(sk),uqe=n(sk,"P",{});var k9a=s(uqe);Q$t=r(k9a,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),k9a.forEach(t),W$t=i(sk),Jf=n(sk,"P",{});var fhe=s(Jf);U$t=r(fhe,`Note:
Loading a model from its configuration file does `),pqe=n(fhe,"STRONG",{});var S9a=s(pqe);H$t=r(S9a,"not"),S9a.forEach(t),J$t=r(fhe,` load the model weights. It only affects the
model\u2019s configuration. Use `),tfe=n(fhe,"A",{href:!0});var R9a=s(tfe);Y$t=r(R9a,"from_pretrained()"),R9a.forEach(t),Z$t=r(fhe," to load the model weights."),fhe.forEach(t),K$t=i(sk),T(E9.$$.fragment,sk),sk.forEach(t),ekt=i(Cd),_t=n(Cd,"DIV",{class:!0});var wd=s(_t);T(tN.$$.fragment,wd),okt=i(wd),_qe=n(wd,"P",{});var P9a=s(_qe);rkt=r(P9a,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),P9a.forEach(t),tkt=i(wd),hs=n(wd,"P",{});var lk=s(hs);akt=r(lk,"The model class to instantiate is selected based on the "),bqe=n(lk,"CODE",{});var B9a=s(bqe);nkt=r(B9a,"model_type"),B9a.forEach(t),skt=r(lk,` property of the config object (either
passed as an argument or loaded from `),vqe=n(lk,"CODE",{});var I9a=s(vqe);lkt=r(I9a,"pretrained_model_name_or_path"),I9a.forEach(t),ikt=r(lk,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Fqe=n(lk,"CODE",{});var N9a=s(Fqe);dkt=r(N9a,"pretrained_model_name_or_path"),N9a.forEach(t),mkt=r(lk,":"),lk.forEach(t),ckt=i(wd),Tqe=n(wd,"UL",{});var q9a=s(Tqe);C9=n(q9a,"LI",{});var ulo=s(C9);Mqe=n(ulo,"STRONG",{});var D9a=s(Mqe);fkt=r(D9a,"vision-encoder-decoder"),D9a.forEach(t),gkt=r(ulo," \u2014 "),afe=n(ulo,"A",{href:!0});var j9a=s(afe);hkt=r(j9a,"FlaxVisionEncoderDecoderModel"),j9a.forEach(t),ukt=r(ulo," (Vision Encoder decoder model)"),ulo.forEach(t),q9a.forEach(t),pkt=i(wd),T(w9.$$.fragment,wd),wd.forEach(t),Cd.forEach(t),this.h()},h(){d(g,"name","hf:doc:metadata"),d(g,"content",JSON.stringify(ska)),d(f,"id","auto-classes"),d(f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(f,"href","#auto-classes"),d(u,"class","relative group"),d(ps,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig"),d(bs,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoModel"),d(vs,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer"),d(Sd,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),d(ag,"id","extending-the-auto-classes"),d(ag,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ag,"href","#extending-the-auto-classes"),d(Rd,"class","relative group"),d(sg,"id","transformers.AutoConfig"),d(sg,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(sg,"href","#transformers.AutoConfig"),d(Pd,"class","relative group"),d(qq,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),d(Dq,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig"),d(jq,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartConfig"),d(Gq,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig"),d(Oq,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertConfig"),d(Vq,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig"),d(Xq,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig"),d(zq,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),d(Qq,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig"),d(Wq,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),d(Uq,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig"),d(Hq,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig"),d(Jq,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig"),d(Yq,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig"),d(Zq,"href","/docs/transformers/main/en/model_doc/clipseg#transformers.CLIPSegConfig"),d(Kq,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig"),d(eD,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig"),d(oD,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig"),d(rD,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig"),d(tD,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig"),d(aD,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig"),d(nD,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),d(sD,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig"),d(lD,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),d(iD,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig"),d(dD,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config"),d(mD,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),d(cD,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig"),d(fD,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig"),d(gD,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig"),d(hD,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig"),d(uD,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig"),d(pD,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig"),d(_D,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig"),d(bD,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig"),d(vD,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),d(FD,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig"),d(TD,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig"),d(MD,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig"),d(ED,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig"),d(CD,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig"),d(wD,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig"),d(AD,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig"),d(LD,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig"),d(yD,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config"),d(xD,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),d($D,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),d(kD,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig"),d(SD,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig"),d(RD,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig"),d(PD,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig"),d(BD,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig"),d(ID,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig"),d(ND,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig"),d(qD,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),d(DD,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),d(jD,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDConfig"),d(GD,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig"),d(OD,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig"),d(VD,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig"),d(XD,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config"),d(zD,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig"),d(QD,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig"),d(WD,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config"),d(UD,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig"),d(HD,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig"),d(JD,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig"),d(YD,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig"),d(ZD,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig"),d(KD,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),d(ej,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig"),d(oj,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig"),d(rj,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig"),d(tj,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config"),d(aj,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig"),d(nj,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig"),d(sj,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig"),d(lj,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),d(ij,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig"),d(dj,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig"),d(mj,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig"),d(cj,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig"),d(fj,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig"),d(gj,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig"),d(hj,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig"),d(uj,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig"),d(pj,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig"),d(_j,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagConfig"),d(bj,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmConfig"),d(vj,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig"),d(Fj,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig"),d(Tj,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig"),d(Mj,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig"),d(Ej,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig"),d(Cj,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig"),d(wj,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig"),d(Aj,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig"),d(Lj,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig"),d(yj,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig"),d(xj,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig"),d($j,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),d(kj,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),d(Sj,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),d(Rj,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig"),d(Pj,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),d(Bj,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig"),d(Ij,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config"),d(Nj,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Config"),d(qj,"href","/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerConfig"),d(Dj,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig"),d(jj,"href","/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig"),d(Gj,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),d(Oj,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),d(Vj,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig"),d(Xj,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig"),d(zj,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),d(Qj,"href","/docs/transformers/main/en/model_doc/van#transformers.VanConfig"),d(Wj,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig"),d(Uj,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig"),d(Hj,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),d(Jj,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),d(Yj,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig"),d(Zj,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig"),d(Kj,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig"),d(eG,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig"),d(oG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),d(rG,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),d(tG,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig"),d(aG,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig"),d(nG,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig"),d(sG,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig"),d(lG,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig"),d(iG,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),d(dG,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),d(mG,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),d(cG,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig"),d(fG,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig"),d(gG,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig"),d(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Nu,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(qu,"id","transformers.AutoTokenizer"),d(qu,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(qu,"href","#transformers.AutoTokenizer"),d(Id,"class","relative group"),d(hG,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),d(uG,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),d(pG,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),d(_G,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizer"),d(bG,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizerFast"),d(vG,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizer"),d(FG,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizerFast"),d(TG,"href","/docs/transformers/main/en/model_doc/bartpho#transformers.BartphoTokenizer"),d(MG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(EG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(CG,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),d(wG,"href","/docs/transformers/main/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),d(AG,"href","/docs/transformers/main/en/model_doc/bertweet#transformers.BertweetTokenizer"),d(LG,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizer"),d(yG,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),d(xG,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),d($G,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),d(kG,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),d(SG,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),d(RG,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),d(PG,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomTokenizerFast"),d(BG,"href","/docs/transformers/main/en/model_doc/byt5#transformers.ByT5Tokenizer"),d(IG,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizer"),d(NG,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizerFast"),d(qG,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineTokenizer"),d(DG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),d(jG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),d(GG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),d(OG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),d(VG,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizer"),d(XG,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizerFast"),d(zG,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizer"),d(QG,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),d(WG,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizer"),d(UG,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizerFast"),d(HG,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLTokenizer"),d(JG,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),d(YG,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),d(ZG,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizer"),d(KG,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizerFast"),d(eO,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),d(oO,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),d(rO,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizer"),d(tO,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),d(aO,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),d(nO,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),d(sO,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizer"),d(lO,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizerFast"),d(iO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(dO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(mO,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmTokenizer"),d(cO,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertTokenizer"),d(fO,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizer"),d(gO,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizerFast"),d(hO,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTTokenizer"),d(uO,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizer"),d(pO,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizerFast"),d(_O,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),d(bO,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),d(vO,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),d(FO,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),d(TO,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),d(MO,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseTokenizer"),d(EO,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),d(CO,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),d(wO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),d(AO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),d(LO,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizer"),d(yO,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizerFast"),d(xO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),d($O,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),d(kO,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),d(SO,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),d(RO,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),d(PO,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),d(BO,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),d(IO,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),d(NO,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),d(qO,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),d(DO,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),d(jO,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizer"),d(GO,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizerFast"),d(OO,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),d(VO,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),d(XO,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizer"),d(zO,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizerFast"),d(QO,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),d(WO,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),d(UO,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeTokenizer"),d(HO,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizer"),d(JO,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),d(YO,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),d(ZO,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianTokenizer"),d(KO,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizer"),d(eV,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizerFast"),d(oV,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50Tokenizer"),d(rV,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50TokenizerFast"),d(tV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(aV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(nV,"href","/docs/transformers/main/en/model_doc/mluke#transformers.MLukeTokenizer"),d(sV,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),d(lV,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),d(iV,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizer"),d(dV,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),d(mV,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),d(cV,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),d(fV,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizer"),d(gV,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizerFast"),d(hV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(uV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(pV,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizer"),d(_V,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizerFast"),d(bV,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),d(vV,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),d(FV,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),d(TV,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),d(MV,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),d(EV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),d(CV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),d(wV,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),d(AV,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),d(LV,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),d(yV,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),d(xV,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverTokenizer"),d($V,"href","/docs/transformers/main/en/model_doc/phobert#transformers.PhobertTokenizer"),d(kV,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartTokenizer"),d(SV,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),d(RV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(PV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(BV,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagTokenizer"),d(IV,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizer"),d(NV,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizerFast"),d(qV,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizer"),d(DV,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizerFast"),d(jV,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizer"),d(GV,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizerFast"),d(OV,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizer"),d(VV,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),d(XV,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),d(zV,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),d(QV,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertTokenizer"),d(WV,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizer"),d(UV,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),d(HV,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),d(JV,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),d(YV,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizer"),d(ZV,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizerFast"),d(KV,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),d(eX,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),d(oX,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),d(rX,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),d(tX,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasTokenizer"),d(aX,"href","/docs/transformers/main/en/model_doc/tapex#transformers.TapexTokenizer"),d(nX,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),d(sX,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(lX,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(iX,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(dX,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(mX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),d(cX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),d(fX,"href","/docs/transformers/main/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),d(gX,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperTokenizer"),d(hX,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),d(uX,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),d(pX,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizer"),d(_X,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizerFast"),d(bX,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMTokenizer"),d(vX,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),d(FX,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),d(TX,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),d(MX,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),d(EX,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),d(CX,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizer"),d(wX,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),d(AX,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),d(LX,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),d(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ep,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Cp,"id","transformers.AutoFeatureExtractor"),d(Cp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Cp,"href","#transformers.AutoFeatureExtractor"),d(Nd,"class","relative group"),d(yX,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),d(xX,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitImageProcessor"),d($X,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPImageProcessor"),d(kX,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(SX,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrFeatureExtractor"),d(RX,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(PX,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(BX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),d(IX,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitImageProcessor"),d(NX,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrFeatureExtractor"),d(qX,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTImageProcessor"),d(DX,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrFeatureExtractor"),d(jX,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutFeatureExtractor"),d(GX,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTImageProcessor"),d(OX,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaImageProcessor"),d(VX,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNImageProcessor"),d(XX,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPImageProcessor"),d(zX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),d(QX,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTImageProcessor"),d(WX,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ImageProcessor"),d(UX,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ImageProcessor"),d(HX,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitImageProcessor"),d(JX,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),d(YX,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),d(ZX,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTImageProcessor"),d(KX,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTFeatureExtractor"),d(ez,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverImageProcessor"),d(oz,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerImageProcessor"),d(rz,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(tz,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(az,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerImageProcessor"),d(nz,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),d(sz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(lz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(iz,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrFeatureExtractor"),d(dz,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(mz,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEImageProcessor"),d(cz,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltImageProcessor"),d(fz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(gz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(hz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(uz,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),d(pz,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),d(_z,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperFeatureExtractor"),d(bz,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPImageProcessor"),d(vz,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosFeatureExtractor"),d(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(b_,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(v_,"id","transformers.AutoImageProcessor"),d(v_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(v_,"href","#transformers.AutoImageProcessor"),d(qd,"class","relative group"),d(Fz,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoImageProcessor.from_pretrained"),d(Tz,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitImageProcessor"),d(Mz,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPImageProcessor"),d(Ez,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(Cz,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(wz,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitImageProcessor"),d(Az,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTImageProcessor"),d(Lz,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTImageProcessor"),d(yz,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaImageProcessor"),d(xz,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNImageProcessor"),d($z,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPImageProcessor"),d(kz,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTImageProcessor"),d(Sz,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ImageProcessor"),d(Rz,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ImageProcessor"),d(Pz,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitImageProcessor"),d(Bz,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTImageProcessor"),d(Iz,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverImageProcessor"),d(Nz,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerImageProcessor"),d(qz,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(Dz,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(jz,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerImageProcessor"),d(Gz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(Oz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(Vz,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(Xz,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEImageProcessor"),d(zz,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltImageProcessor"),d(Qz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(Wz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(Uz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(Hz,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPImageProcessor"),d(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Y_,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Z_,"id","transformers.AutoProcessor"),d(Z_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Z_,"href","#transformers.AutoProcessor"),d(Dd,"class","relative group"),d(Jz,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),d(Yz,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),d(Zz,"href","/docs/transformers/main/en/model_doc/clipseg#transformers.CLIPSegProcessor"),d(Kz,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaProcessor"),d(eQ,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),d(oQ,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),d(rQ,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),d(tQ,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),d(aQ,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMProcessor"),d(nQ,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTProcessor"),d(sQ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(lQ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(iQ,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),d(dQ,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),d(mQ,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRProcessor"),d(cQ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(fQ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(gQ,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltProcessor"),d(hQ,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),d(uQ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(pQ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(_Q,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(bQ,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperProcessor"),d(vQ,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPProcessor"),d(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(C1,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(w1,"id","transformers.AutoModel"),d(w1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(w1,"href","#transformers.AutoModel"),d(Gd,"class","relative group"),d(FQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(TQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(MQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(EQ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel"),d(CQ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartModel"),d(wQ,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitModel"),d(AQ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),d(LQ,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),d(yQ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel"),d(xQ,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),d($Q,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel"),d(kQ,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),d(SQ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel"),d(RQ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel"),d(PQ,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineModel"),d(BQ,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel"),d(IQ,"href","/docs/transformers/main/en/model_doc/clipseg#transformers.CLIPSegModel"),d(NQ,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel"),d(qQ,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrModel"),d(DQ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel"),d(jQ,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel"),d(GQ,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel"),d(OQ,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel"),d(VQ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel"),d(XQ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel"),d(zQ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel"),d(QQ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel"),d(WQ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model"),d(UQ,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),d(HQ,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrModel"),d(JQ,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel"),d(YQ,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrModel"),d(ZQ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel"),d(KQ,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel"),d(eW,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder"),d(oW,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel"),d(rW,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel"),d(tW,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel"),d(aW,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmModel"),d(nW,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel"),d(sW,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel"),d(lW,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel"),d(iW,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel"),d(dW,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel"),d(mW,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel"),d(cW,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel"),d(fW,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model"),d(gW,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel"),d(hW,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),d(uW,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel"),d(pW,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel"),d(_W,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel"),d(bW,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel"),d(vW,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel"),d(FW,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel"),d(TW,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel"),d(MW,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),d(EW,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),d(CW,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDModel"),d(wW,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitModel"),d(AW,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltModel"),d(LW,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel"),d(yW,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model"),d(xW,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeModel"),d($W,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel"),d(kW,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),d(SW,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianModel"),d(RW,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMModel"),d(PW,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel"),d(BW,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel"),d(IW,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel"),d(NW,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel"),d(qW,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel"),d(DW,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel"),d(jW,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel"),d(GW,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model"),d(OW,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel"),d(VW,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel"),d(XW,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),d(zW,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel"),d(QW,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),d(WW,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTModel"),d(UW,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel"),d(HW,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel"),d(JW,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel"),d(YW,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel"),d(ZW,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel"),d(KW,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel"),d(eU,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel"),d(oU,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel"),d(rU,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel"),d(tU,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel"),d(aU,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel"),d(nU,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel"),d(sU,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),d(lU,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel"),d(iU,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertModel"),d(dU,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel"),d(mU,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel"),d(cU,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWModel"),d(fU,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel"),d(gU,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel"),d(hU,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel"),d(uU,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel"),d(pU,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinModel"),d(_U,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model"),d(bU,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Model"),d(vU,"href","/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerModel"),d(FU,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel"),d(TU,"href","/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel"),d(MU,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),d(EU,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel"),d(CU,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel"),d(wU,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),d(AU,"href","/docs/transformers/main/en/model_doc/van#transformers.VanModel"),d(LU,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel"),d(yU,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel"),d(xU,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),d($U,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel"),d(kU,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTModel"),d(SU,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel"),d(RU,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNModel"),d(PU,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),d(BU,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),d(IU,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel"),d(NU,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperModel"),d(qU,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel"),d(DU,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel"),d(jU,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel"),d(GU,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),d(OU,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),d(VU,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),d(XU,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel"),d(zU,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel"),d(QU,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel"),d(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Yb,"id","transformers.AutoModelForPreTraining"),d(Yb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Yb,"href","#transformers.AutoModelForPreTraining"),d(Xd,"class","relative group"),d(WU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(UU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(HU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(JU,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining"),d(YU,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),d(ZU,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining"),d(KU,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),d(eH,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),d(oH,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),d(rH,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),d(tH,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),d(aH,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),d(nH,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),d(sH,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),d(lH,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining"),d(iH,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining"),d(dH,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),d(mH,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining"),d(cH,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining"),d(fH,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),d(gH,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining"),d(hH,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),d(uH,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),d(pH,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),d(_H,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),d(bH,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),d(vH,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining"),d(FH,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),d(TH,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),d(MH,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),d(EH,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),d(CH,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining"),d(wH,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),d(AH,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),d(LH,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),d(yH,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForPreTraining"),d(xH,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining"),d($H,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),d(kH,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),d(SH,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),d(RH,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),d(PH,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),d(BH,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),d(IH,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining"),d(NH,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),d(qH,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),d(DH,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),d(jH,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),d(GH,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),d(OH,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),d(VH,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),d(XH,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),d(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Jv,"id","transformers.AutoModelForCausalLM"),d(Jv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Jv,"href","#transformers.AutoModelForCausalLM"),d(Wd,"class","relative group"),d(zH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(QH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(WH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(UH,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM"),d(HH,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel"),d(JH,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),d(YH,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),d(ZH,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),d(KH,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),d(eJ,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),d(oJ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),d(rJ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM"),d(tJ,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM"),d(aJ,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),d(nJ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),d(sJ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM"),d(lJ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM"),d(iJ,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),d(dJ,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),d(mJ,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),d(cJ,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM"),d(fJ,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM"),d(gJ,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM"),d(hJ,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM"),d(uJ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),d(pJ,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM"),d(_J,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),d(bJ,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM"),d(vJ,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM"),d(FJ,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM"),d(TJ,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),d(MJ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),d(EJ,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),d(CJ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM"),d(wJ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM"),d(AJ,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForCausalLM"),d(LJ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM"),d(yJ,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),d(xJ,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),d($J,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM"),d(kJ,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM"),d(SJ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),d(RJ,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),d(PJ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),d(BJ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),d(IJ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),d(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(VF,"id","transformers.AutoModelForDepthEstimation"),d(VF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(VF,"href","#transformers.AutoModelForDepthEstimation"),d(Jd,"class","relative group"),d(NJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(qJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(DJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(jJ,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTForDepthEstimation"),d(GJ,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNForDepthEstimation"),d(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(HF,"id","transformers.AutoModelForMaskedLM"),d(HF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(HF,"href","#transformers.AutoModelForMaskedLM"),d(Kd,"class","relative group"),d(OJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(VJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(XJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(zJ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM"),d(QJ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),d(WJ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM"),d(UJ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),d(HJ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),d(JJ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),d(YJ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),d(ZJ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),d(KJ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),d(eY,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),d(oY,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM"),d(rY,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM"),d(tY,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),d(aY,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM"),d(nY,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM"),d(sY,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),d(lY,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),d(iY,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),d(dY,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),d(mY,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),d(cY,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),d(fY,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),d(gY,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),d(hY,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),d(uY,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM"),d(pY,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),d(_Y,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),d(bY,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),d(vY,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM"),d(FY,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM"),d(TY,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),d(MY,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForMaskedLM"),d(EY,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),d(CY,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),d(wY,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),d(AY,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),d(LY,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),d(yY,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),d(xY,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM"),d(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(DT,"id","transformers.AutoModelForSeq2SeqLM"),d(DT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(DT,"href","#transformers.AutoModelForSeq2SeqLM"),d(rm,"class","relative group"),d($Y,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(kY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(SY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(RY,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),d(PY,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),d(BY,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),d(IY,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),d(NY,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),d(qY,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),d(DY,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration"),d(jY,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),d(GY,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),d(OY,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel"),d(VY,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),d(XY,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),d(zY,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),d(QY,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),d(WY,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),d(UY,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration"),d(HY,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),d(JY,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),d(YY,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),d(ZY,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),d(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(dM,"id","transformers.AutoModelForSequenceClassification"),d(dM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(dM,"href","#transformers.AutoModelForSequenceClassification"),d(nm,"class","relative group"),d(KY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(eZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(oZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(rZ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification"),d(tZ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification"),d(aZ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification"),d(nZ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),d(sZ,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),d(lZ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification"),d(iZ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),d(dZ,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification"),d(mZ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),d(cZ,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),d(fZ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),d(gZ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),d(hZ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),d(uZ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),d(pZ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification"),d(_Z,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification"),d(bZ,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmForSequenceClassification"),d(vZ,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),d(FZ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification"),d(TZ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),d(MZ,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),d(EZ,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),d(CZ,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),d(wZ,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification"),d(AZ,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),d(LZ,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),d(yZ,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),d(xZ,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification"),d($Z,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltForSequenceClassification"),d(kZ,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),d(SZ,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification"),d(RZ,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification"),d(PZ,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification"),d(BZ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),d(IZ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),d(NZ,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),d(qZ,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification"),d(DZ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification"),d(jZ,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),d(GZ,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),d(OZ,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification"),d(VZ,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),d(XZ,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),d(zZ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),d(QZ,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),d(WZ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),d(UZ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),d(HZ,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForSequenceClassification"),d(JZ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),d(YZ,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),d(ZZ,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification"),d(KZ,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),d(eK,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification"),d(oK,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),d(rK,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),d(tK,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),d(aK,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification"),d(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(pE,"id","transformers.AutoModelForMultipleChoice"),d(pE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(pE,"href","#transformers.AutoModelForMultipleChoice"),d(im,"class","relative group"),d(nK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(sK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(lK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(iK,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice"),d(dK,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice"),d(mK,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),d(cK,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),d(fK,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice"),d(gK,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),d(hK,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),d(uK,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),d(pK,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),d(_K,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice"),d(bK,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice"),d(vK,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),d(FK,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice"),d(TK,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),d(MK,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice"),d(EK,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),d(CK,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice"),d(wK,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),d(AK,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),d(LK,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),d(yK,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice"),d(xK,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),d($K,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),d(kK,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),d(SK,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),d(RK,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForMultipleChoice"),d(PK,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),d(BK,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),d(IK,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice"),d(NK,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),d(qK,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),d(DK,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),d(jK,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice"),d(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(KE,"id","transformers.AutoModelForNextSentencePrediction"),d(KE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(KE,"href","#transformers.AutoModelForNextSentencePrediction"),d(cm,"class","relative group"),d(GK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(OK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(VK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(XK,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction"),d(zK,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction"),d(QK,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),d(WK,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),d(UK,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),d(HK,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction"),d(JK,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),d(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(m4,"id","transformers.AutoModelForTokenClassification"),d(m4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(m4,"href","#transformers.AutoModelForTokenClassification"),d(hm,"class","relative group"),d(YK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ZK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(KK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(eee,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification"),d(oee,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification"),d(ree,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),d(tee,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification"),d(aee,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification"),d(nee,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification"),d(see,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),d(lee,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),d(iee,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification"),d(dee,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),d(mee,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),d(cee,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification"),d(fee,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification"),d(gee,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmForTokenClassification"),d(hee,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),d(uee,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification"),d(pee,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification"),d(_ee,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),d(bee,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification"),d(vee,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),d(Fee,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),d(Tee,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),d(Mee,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltForTokenClassification"),d(Eee,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification"),d(Cee,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification"),d(wee,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification"),d(Aee,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),d(Lee,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),d(yee,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),d(xee,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification"),d($ee,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),d(kee,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),d(See,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification"),d(Ree,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification"),d(Pee,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForTokenClassification"),d(Bee,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),d(Iee,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),d(Nee,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification"),d(qee,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),d(Dee,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),d(jee,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),d(Gee,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification"),d(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(rC,"id","transformers.AutoModelForQuestionAnswering"),d(rC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(rC,"href","#transformers.AutoModelForQuestionAnswering"),d(_m,"class","relative group"),d(Oee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Vee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Xee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(zee,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),d(Qee,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering"),d(Wee,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering"),d(Uee,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),d(Hee,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),d(Jee,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForQuestionAnswering"),d(Yee,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),d(Zee,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering"),d(Kee,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),d(eoe,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),d(ooe,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),d(roe,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),d(toe,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),d(aoe,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),d(noe,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering"),d(soe,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),d(loe,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),d(ioe,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),d(doe,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),d(moe,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),d(coe,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),d(foe,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),d(goe,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering"),d(hoe,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltForQuestionAnswering"),d(uoe,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),d(poe,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering"),d(_oe,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),d(boe,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering"),d(voe,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),d(Foe,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),d(Toe,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),d(Moe,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),d(Eoe,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering"),d(Coe,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering"),d(woe,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),d(Aoe,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForQuestionAnswering"),d(Loe,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),d(yoe,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),d(xoe,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),d($oe,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),d(koe,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForQuestionAnswering"),d(Soe,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),d(Roe,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),d(Poe,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),d(Boe,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),d(Ioe,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),d(Noe,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),d(qoe,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),d(Doe,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),d(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(o3,"id","transformers.AutoModelForTableQuestionAnswering"),d(o3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(o3,"href","#transformers.AutoModelForTableQuestionAnswering"),d(Fm,"class","relative group"),d(joe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Goe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Ooe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Voe,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),d(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(s3,"id","transformers.AutoModelForDocumentQuestionAnswering"),d(s3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(s3,"href","#transformers.AutoModelForDocumentQuestionAnswering"),d(Em,"class","relative group"),d(Xoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(zoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Qoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Woe,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering"),d(Uoe,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),d(Hoe,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),d(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(g3,"id","transformers.AutoModelForImageClassification"),d(g3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(g3,"href","#transformers.AutoModelForImageClassification"),d(Lm,"class","relative group"),d(Joe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Yoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Zoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Koe,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification"),d(ere,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification"),d(ore,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification"),d(rre,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),d(tre,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification"),d(are,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),d(nre,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),d(sre,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification"),d(lre,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),d(ire,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification"),d(dre,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),d(mre,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),d(cre,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),d(fre,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),d(gre,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification"),d(hre,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification"),d(ure,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification"),d(pre,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification"),d(_re,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification"),d(bre,"href","/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification"),d(vre,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification"),d(Fre,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification"),d(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(S3,"id","transformers.AutoModelForVideoClassification"),d(S3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(S3,"href","#transformers.AutoModelForVideoClassification"),d($m,"class","relative group"),d(Tre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Mre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Ere,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Cre,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification"),d(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(N3,"id","transformers.AutoModelForVision2Seq"),d(N3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(N3,"href","#transformers.AutoModelForVision2Seq"),d(Rm,"class","relative group"),d(wre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Are,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Lre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(yre,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),d(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(O3,"id","transformers.AutoModelForVisualQuestionAnswering"),d(O3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(O3,"href","#transformers.AutoModelForVisualQuestionAnswering"),d(Im,"class","relative group"),d(xre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d($re,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(kre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Sre,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),d(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(W3,"id","transformers.AutoModelForAudioClassification"),d(W3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(W3,"href","#transformers.AutoModelForAudioClassification"),d(Dm,"class","relative group"),d(Rre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Pre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Bre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ire,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),d(Nre,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification"),d(qre,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification"),d(Dre,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),d(jre,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),d(Gre,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),d(Ore,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),d(Vre,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),d(Xre,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),d(To,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(s5,"id","transformers.AutoModelForAudioFrameClassification"),d(s5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(s5,"href","#transformers.AutoModelForAudioFrameClassification"),d(Om,"class","relative group"),d(zre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Qre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Wre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ure,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),d(Hre,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),d(Jre,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),d(Yre,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),d(Zre,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),d(Mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(u5,"id","transformers.AutoModelForCTC"),d(u5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(u5,"href","#transformers.AutoModelForCTC"),d(zm,"class","relative group"),d(Kre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ete,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(ote,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(rte,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),d(tte,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC"),d(ate,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC"),d(nte,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC"),d(ste,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC"),d(lte,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC"),d(ite,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),d(dte,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),d(mte,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),d(cte,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC"),d(Eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(x5,"id","transformers.AutoModelForSpeechSeq2Seq"),d(x5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(x5,"href","#transformers.AutoModelForSpeechSeq2Seq"),d(Um,"class","relative group"),d(fte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(gte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(hte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ute,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),d(pte,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),d(_te,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperForConditionalGeneration"),d(Co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(I5,"id","transformers.AutoModelForAudioXVector"),d(I5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(I5,"href","#transformers.AutoModelForAudioXVector"),d(Zm,"class","relative group"),d(bte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(vte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Fte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Tte,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),d(Mte,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),d(Ete,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),d(Cte,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),d(wte,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector"),d(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(z5,"id","transformers.AutoModelForMaskedImageModeling"),d(z5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(z5,"href","#transformers.AutoModelForMaskedImageModeling"),d(oc,"class","relative group"),d(Ate,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Lte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(yte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(xte,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),d($te,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),d(kte,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling"),d(Ste,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),d(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(K5,"id","transformers.AutoModelForObjectDetection"),d(K5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(K5,"href","#transformers.AutoModelForObjectDetection"),d(ac,"class","relative group"),d(Rte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Pte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Bte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ite,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection"),d(Nte,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection"),d(qte,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection"),d(Dte,"href","/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerForObjectDetection"),d(jte,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection"),d(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(i0,"id","transformers.AutoModelForImageSegmentation"),d(i0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(i0,"href","#transformers.AutoModelForImageSegmentation"),d(lc,"class","relative group"),d(Gte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ote,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Vte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Xte,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation"),d(yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(g0,"id","transformers.AutoModelForSemanticSegmentation"),d(g0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(g0,"href","#transformers.AutoModelForSemanticSegmentation"),d(mc,"class","relative group"),d(zte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Qte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Wte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ute,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),d(Hte,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),d(Jte,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),d(Yte,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation"),d(Zte,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),d(xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(M0,"id","transformers.AutoModelForInstanceSegmentation"),d(M0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(M0,"href","#transformers.AutoModelForInstanceSegmentation"),d(gc,"class","relative group"),d(Kte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(eae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(oae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(rae,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),d($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(L0,"id","transformers.AutoModelForZeroShotObjectDetection"),d(L0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(L0,"href","#transformers.AutoModelForZeroShotObjectDetection"),d(pc,"class","relative group"),d(tae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(aae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(nae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(sae,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTForObjectDetection"),d(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(S0,"id","transformers.TFAutoModel"),d(S0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(S0,"href","#transformers.TFAutoModel"),d(vc,"class","relative group"),d(lae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(iae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(dae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(mae,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel"),d(cae,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel"),d(fae,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel"),d(gae,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),d(hae,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),d(uae,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel"),d(pae,"href","/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel"),d(_ae,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel"),d(bae,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel"),d(vae,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel"),d(Fae,"href","/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtModel"),d(Tae,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),d(Mae,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel"),d(Eae,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),d(Cae,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel"),d(wae,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel"),d(Aae,"href","/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),d(Lae,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel"),d(yae,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmModel"),d(xae,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel"),d($ae,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel"),d(kae,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel"),d(Sae,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model"),d(Rae,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel"),d(Pae,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.TFGroupViTModel"),d(Bae,"href","/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel"),d(Iae,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),d(Nae,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model"),d(qae,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel"),d(Dae,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel"),d(jae,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel"),d(Gae,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel"),d(Oae,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel"),d(Vae,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel"),d(Xae,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel"),d(zae,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel"),d(Qae,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model"),d(Wae,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),d(Uae,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel"),d(Hae,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel"),d(Jae,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel"),d(Yae,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel"),d(Zae,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel"),d(Kae,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel"),d(ene,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel"),d(one,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel"),d(rne,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),d(tne,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel"),d(ane,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model"),d(nne,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel"),d(sne,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),d(lne,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel"),d(ine,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel"),d(dne,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),d(mne,"href","/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperModel"),d(cne,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel"),d(fne,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel"),d(gne,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),d(hne,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel"),d(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(qw,"id","transformers.TFAutoModelForPreTraining"),d(qw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(qw,"href","#transformers.TFAutoModelForPreTraining"),d(Mc,"class","relative group"),d(une,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(pne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(_ne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ra,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(bne,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining"),d(vne,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),d(Fne,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining"),d(Tne,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),d(Mne,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),d(Ene,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),d(Cne,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining"),d(wne,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),d(Ane,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),d(Lne,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),d(yne,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),d(xne,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),d($ne,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),d(kne,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),d(Sne,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),d(Rne,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),d(Pne,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),d(Bne,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),d(Ine,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),d(Nne,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),d(qne,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),d(Dne,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),d(jne,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),d(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(mA,"id","transformers.TFAutoModelForCausalLM"),d(mA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(mA,"href","#transformers.TFAutoModelForCausalLM"),d(wc,"class","relative group"),d(Gne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(One,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Vne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Xne,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel"),d(zne,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),d(Qne,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),d(Wne,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),d(Une,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),d(Hne,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),d(Jne,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM"),d(Yne,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),d(Zne,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),d(Kne,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),d(ese,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),d(ose,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM"),d(rse,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),d(tse,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),d(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(LA,"id","transformers.TFAutoModelForImageClassification"),d(LA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(LA,"href","#transformers.TFAutoModelForImageClassification"),d(yc,"class","relative group"),d(ase,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(nse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(sse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(aa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(lse,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),d(ise,"href","/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtForImageClassification"),d(dse,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),d(mse,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification"),d(cse,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher"),d(fse,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification"),d(gse,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification"),d(hse,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification"),d(use,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification"),d(pse,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification"),d(_se,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification"),d(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(DA,"id","transformers.TFAutoModelForSemanticSegmentation"),d(DA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(DA,"href","#transformers.TFAutoModelForSemanticSegmentation"),d(kc,"class","relative group"),d(bse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(vse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Fse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(na,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Tse,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation"),d(Mse,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation"),d(Ese,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation"),d(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(zA,"id","transformers.TFAutoModelForMaskedLM"),d(zA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(zA,"href","#transformers.TFAutoModelForMaskedLM"),d(Bc,"class","relative group"),d(Cse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(wse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Ase,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(sa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Lse,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),d(yse,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM"),d(xse,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),d($se,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),d(kse,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),d(Sse,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),d(Rse,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),d(Pse,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM"),d(Bse,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForMaskedLM"),d(Ise,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),d(Nse,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),d(qse,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),d(Dse,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),d(jse,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),d(Gse,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),d(Ose,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),d(Vse,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),d(Xse,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),d(zse,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),d(Qse,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),d(Wse,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),d(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(u6,"id","transformers.TFAutoModelForSeq2SeqLM"),d(u6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(u6,"href","#transformers.TFAutoModelForSeq2SeqLM"),d(qc,"class","relative group"),d(Use,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Hse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Jse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(la,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Yse,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),d(Zse,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),d(Kse,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),d(ele,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),d(ole,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),d(rle,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel"),d(tle,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),d(ale,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),d(nle,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),d(sle,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),d(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(y6,"id","transformers.TFAutoModelForSequenceClassification"),d(y6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(y6,"href","#transformers.TFAutoModelForSequenceClassification"),d(Gc,"class","relative group"),d(lle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ile,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(dle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ia,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(mle,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),d(cle,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification"),d(fle,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),d(gle,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),d(hle,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),d(ule,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),d(ple,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),d(_le,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),d(ble,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),d(vle,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForSequenceClassification"),d(Fle,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),d(Tle,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),d(Mle,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),d(Ele,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),d(Cle,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),d(wle,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification"),d(Ale,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),d(Lle,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),d(yle,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),d(xle,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),d($le,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),d(kle,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),d(Sle,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),d(Rle,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),d(Ple,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),d(Ble,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),d(Ile,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),d(Nle,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),d(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(n7,"id","transformers.TFAutoModelForMultipleChoice"),d(n7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(n7,"href","#transformers.TFAutoModelForMultipleChoice"),d(Xc,"class","relative group"),d(qle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Dle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(jle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(da,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Gle,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),d(Ole,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice"),d(Vle,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),d(Xle,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),d(zle,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),d(Qle,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),d(Wle,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),d(Ule,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),d(Hle,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),d(Jle,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),d(Yle,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),d(Zle,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),d(Kle,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),d(eie,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),d(oie,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),d(rie,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),d(tie,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),d(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(w7,"id","transformers.TFAutoModelForNextSentencePrediction"),d(w7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(w7,"href","#transformers.TFAutoModelForNextSentencePrediction"),d(Wc,"class","relative group"),d(aie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(nie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(sie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ma,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(lie,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),d(iie,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),d(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d($7,"id","transformers.TFAutoModelForTableQuestionAnswering"),d($7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d($7,"href","#transformers.TFAutoModelForTableQuestionAnswering"),d(Jc,"class","relative group"),d(die,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(mie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(cie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ca,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(fie,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),d(et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(P7,"id","transformers.TFAutoModelForDocumentQuestionAnswering"),d(P7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(P7,"href","#transformers.TFAutoModelForDocumentQuestionAnswering"),d(Kc,"class","relative group"),d(gie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(hie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(uie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(fa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(pie,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering"),d(ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(q7,"id","transformers.TFAutoModelForTokenClassification"),d(q7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(q7,"href","#transformers.TFAutoModelForTokenClassification"),d(rf,"class","relative group"),d(_ie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(bie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(vie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ga,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Fie,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),d(Tie,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification"),d(Mie,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),d(Eie,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),d(Cie,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),d(wie,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),d(Aie,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),d(Lie,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification"),d(yie,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForTokenClassification"),d(xie,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),d($ie,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),d(kie,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),d(Sie,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification"),d(Rie,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),d(Pie,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),d(Bie,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),d(Iie,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),d(Nie,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),d(qie,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),d(Die,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),d(jie,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),d(Gie,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),d(rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(d8,"id","transformers.TFAutoModelForQuestionAnswering"),d(d8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(d8,"href","#transformers.TFAutoModelForQuestionAnswering"),d(nf,"class","relative group"),d(Oie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Vie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Xie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ha,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(zie,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),d(Qie,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),d(Wie,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),d(Uie,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),d(Hie,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),d(Jie,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),d(Yie,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),d(Zie,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),d(Kie,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),d(ede,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),d(ode,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),d(rde,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering"),d(tde,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),d(ade,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),d(nde,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),d(sde,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),d(lde,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),d(ide,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),d(dde,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),d(mde,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),d(cde,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),d(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(R8,"id","transformers.TFAutoModelForVision2Seq"),d(R8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(R8,"href","#transformers.TFAutoModelForVision2Seq"),d(df,"class","relative group"),d(fde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(gde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(hde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ua,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ude,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),d(at,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(N8,"id","transformers.TFAutoModelForSpeechSeq2Seq"),d(N8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(N8,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),d(ff,"class","relative group"),d(pde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(_de,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(bde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(pa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(vde,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),d(Fde,"href","/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration"),d(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(O8,"id","transformers.FlaxAutoModel"),d(O8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(O8,"href","#transformers.FlaxAutoModel"),d(uf,"class","relative group"),d(Tde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Mde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Ede,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(_a,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Cde,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel"),d(wde,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel"),d(Ade,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel"),d(Lde,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel"),d(yde,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),d(xde,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),d($de,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),d(kde,"href","/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel"),d(Sde,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),d(Rde,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel"),d(Pde,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model"),d(Bde,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),d(Ide,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel"),d(Nde,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model"),d(qde,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel"),d(Dde,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel"),d(jde,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model"),d(Gde,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel"),d(Ode,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel"),d(Vde,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel"),d(Xde,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel"),d(zde,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model"),d(Qde,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),d(Wde,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel"),d(Ude,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),d(Hde,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel"),d(Jde,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),d(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(bL,"id","transformers.FlaxAutoModelForCausalLM"),d(bL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(bL,"href","#transformers.FlaxAutoModelForCausalLM"),d(bf,"class","relative group"),d(Yde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Zde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Kde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ba,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(eme,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM"),d(ome,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM"),d(rme,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),d(tme,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),d(ame,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),d(nme,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),d(sme,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),d(lme,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),d(ime,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),d(dme,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),d(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(kL,"id","transformers.FlaxAutoModelForPreTraining"),d(kL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(kL,"href","#transformers.FlaxAutoModelForPreTraining"),d(Tf,"class","relative group"),d(mme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(cme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(fme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(va,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(gme,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),d(hme,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),d(ume,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining"),d(pme,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),d(_me,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),d(bme,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),d(vme,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),d(Fme,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),d(Tme,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),d(Mme,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),d(Eme,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),d(Cme,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),d(wme,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),d(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(WL,"id","transformers.FlaxAutoModelForMaskedLM"),d(WL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(WL,"href","#transformers.FlaxAutoModelForMaskedLM"),d(Cf,"class","relative group"),d(Ame,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Lme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(yme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Fa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(xme,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),d($me,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),d(kme,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),d(Sme,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),d(Rme,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),d(Pme,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),d(Bme,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),d(Ime,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),d(Nme,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),d(qme,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),d(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(sy,"id","transformers.FlaxAutoModelForSeq2SeqLM"),d(sy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(sy,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),d(Lf,"class","relative group"),d(Dme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(jme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Gme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ome,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),d(Vme,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),d(Xme,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),d(zme,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),d(Qme,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),d(Wme,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel"),d(Ume,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),d(Hme,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),d(Jme,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),d(Yme,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),d(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(vy,"id","transformers.FlaxAutoModelForSequenceClassification"),d(vy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(vy,"href","#transformers.FlaxAutoModelForSequenceClassification"),d($f,"class","relative group"),d(Zme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Kme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(ece,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ma,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(oce,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),d(rce,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),d(tce,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),d(ace,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),d(nce,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),d(sce,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),d(lce,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),d(ice,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),d(dce,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),d(mce,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),d(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Sy,"id","transformers.FlaxAutoModelForQuestionAnswering"),d(Sy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Sy,"href","#transformers.FlaxAutoModelForQuestionAnswering"),d(Rf,"class","relative group"),d(cce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(fce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(gce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(hce,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),d(uce,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),d(pce,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),d(_ce,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),d(bce,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),d(vce,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),d(Fce,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),d(Tce,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),d(Mce,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),d(Ece,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),d(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(zy,"id","transformers.FlaxAutoModelForTokenClassification"),d(zy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(zy,"href","#transformers.FlaxAutoModelForTokenClassification"),d(If,"class","relative group"),d(Cce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(wce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Ace,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ca,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Lce,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),d(yce,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),d(xce,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),d($ce,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),d(kce,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),d(Sce,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),d(Rce,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),d(Pce,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),d(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(r9,"id","transformers.FlaxAutoModelForMultipleChoice"),d(r9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(r9,"href","#transformers.FlaxAutoModelForMultipleChoice"),d(Df,"class","relative group"),d(Bce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ice,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Nce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(wa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(qce,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),d(Dce,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),d(jce,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),d(Gce,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),d(Oce,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),d(Vce,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),d(Xce,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),d(zce,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),d(ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(g9,"id","transformers.FlaxAutoModelForNextSentencePrediction"),d(g9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(g9,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),d(Of,"class","relative group"),d(Qce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Wce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Uce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Aa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Hce,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),d(ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(_9,"id","transformers.FlaxAutoModelForImageClassification"),d(_9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(_9,"href","#transformers.FlaxAutoModelForImageClassification"),d(zf,"class","relative group"),d(Jce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Yce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Zce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(La,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Kce,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),d(efe,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification"),d(pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(M9,"id","transformers.FlaxAutoModelForVision2Seq"),d(M9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(M9,"href","#transformers.FlaxAutoModelForVision2Seq"),d(Uf,"class","relative group"),d(ofe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(rfe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(tfe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ya,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(afe,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),d(_t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(c,_){e(document.head,g),b(c,v,_),b(c,u,_),e(u,f),e(f,p),M(m,p,null),e(u,h),e(u,He),e(He,Ad),b(c,eg,_),b(c,wt,_),e(wt,Ld),e(wt,yd),e(yd,ik),e(wt,og),b(c,Qe,_),b(c,Ze,_),e(Ze,xd),e(Ze,ps),e(ps,dk),e(Ze,_s),e(Ze,bs),e(bs,mk),e(Ze,$d),e(Ze,vs),e(vs,ck),e(Ze,kd),b(c,rg,_),M(sn,c,_),b(c,Ke,_),b(c,ye,_),e(ye,Sq),e(ye,Sd),e(Sd,Rq),e(ye,Pq),b(c,Po,_),b(c,ln,_),e(ln,Bq),e(ln,tg),e(tg,Iq),e(ln,ifo),b(c,plo,_),b(c,Rd,_),e(Rd,ag),e(ag,ghe),M(fk,ghe,null),e(Rd,dfo),e(Rd,hhe),e(hhe,mfo),b(c,_lo,_),b(c,Fs,_),e(Fs,cfo),e(Fs,uhe),e(uhe,ffo),e(Fs,gfo),e(Fs,phe),e(phe,hfo),e(Fs,ufo),b(c,blo,_),M(gk,c,_),b(c,vlo,_),b(c,Nq,_),e(Nq,pfo),b(c,Flo,_),M(ng,c,_),b(c,Tlo,_),b(c,Pd,_),e(Pd,sg),e(sg,_he),M(hk,_he,null),e(Pd,_fo),e(Pd,bhe),e(bhe,bfo),b(c,Mlo,_),b(c,Bo,_),M(uk,Bo,null),e(Bo,vfo),e(Bo,pk),e(pk,Ffo),e(pk,qq),e(qq,Tfo),e(pk,Mfo),e(Bo,Efo),e(Bo,_k),e(_k,Cfo),e(_k,vhe),e(vhe,wfo),e(_k,Afo),e(Bo,Lfo),e(Bo,Or),M(bk,Or,null),e(Or,yfo),e(Or,Fhe),e(Fhe,xfo),e(Or,$fo),e(Or,Bd),e(Bd,kfo),e(Bd,The),e(The,Sfo),e(Bd,Rfo),e(Bd,Mhe),e(Mhe,Pfo),e(Bd,Bfo),e(Or,Ifo),e(Or,A),e(A,lg),e(lg,Ehe),e(Ehe,Nfo),e(lg,qfo),e(lg,Dq),e(Dq,Dfo),e(lg,jfo),e(A,Gfo),e(A,ig),e(ig,Che),e(Che,Ofo),e(ig,Vfo),e(ig,jq),e(jq,Xfo),e(ig,zfo),e(A,Qfo),e(A,dg),e(dg,whe),e(whe,Wfo),e(dg,Ufo),e(dg,Gq),e(Gq,Hfo),e(dg,Jfo),e(A,Yfo),e(A,mg),e(mg,Ahe),e(Ahe,Zfo),e(mg,Kfo),e(mg,Oq),e(Oq,ego),e(mg,ogo),e(A,rgo),e(A,cg),e(cg,Lhe),e(Lhe,tgo),e(cg,ago),e(cg,Vq),e(Vq,ngo),e(cg,sgo),e(A,lgo),e(A,fg),e(fg,yhe),e(yhe,igo),e(fg,dgo),e(fg,Xq),e(Xq,mgo),e(fg,cgo),e(A,fgo),e(A,gg),e(gg,xhe),e(xhe,ggo),e(gg,hgo),e(gg,zq),e(zq,ugo),e(gg,pgo),e(A,_go),e(A,hg),e(hg,$he),e($he,bgo),e(hg,vgo),e(hg,Qq),e(Qq,Fgo),e(hg,Tgo),e(A,Mgo),e(A,ug),e(ug,khe),e(khe,Ego),e(ug,Cgo),e(ug,Wq),e(Wq,wgo),e(ug,Ago),e(A,Lgo),e(A,pg),e(pg,She),e(She,ygo),e(pg,xgo),e(pg,Uq),e(Uq,$go),e(pg,kgo),e(A,Sgo),e(A,_g),e(_g,Rhe),e(Rhe,Rgo),e(_g,Pgo),e(_g,Hq),e(Hq,Bgo),e(_g,Igo),e(A,Ngo),e(A,bg),e(bg,Phe),e(Phe,qgo),e(bg,Dgo),e(bg,Jq),e(Jq,jgo),e(bg,Ggo),e(A,Ogo),e(A,vg),e(vg,Bhe),e(Bhe,Vgo),e(vg,Xgo),e(vg,Yq),e(Yq,zgo),e(vg,Qgo),e(A,Wgo),e(A,Fg),e(Fg,Ihe),e(Ihe,Ugo),e(Fg,Hgo),e(Fg,Zq),e(Zq,Jgo),e(Fg,Ygo),e(A,Zgo),e(A,Tg),e(Tg,Nhe),e(Nhe,Kgo),e(Tg,eho),e(Tg,Kq),e(Kq,oho),e(Tg,rho),e(A,tho),e(A,Mg),e(Mg,qhe),e(qhe,aho),e(Mg,nho),e(Mg,eD),e(eD,sho),e(Mg,lho),e(A,iho),e(A,Eg),e(Eg,Dhe),e(Dhe,dho),e(Eg,mho),e(Eg,oD),e(oD,cho),e(Eg,fho),e(A,gho),e(A,Cg),e(Cg,jhe),e(jhe,hho),e(Cg,uho),e(Cg,rD),e(rD,pho),e(Cg,_ho),e(A,bho),e(A,wg),e(wg,Ghe),e(Ghe,vho),e(wg,Fho),e(wg,tD),e(tD,Tho),e(wg,Mho),e(A,Eho),e(A,Ag),e(Ag,Ohe),e(Ohe,Cho),e(Ag,who),e(Ag,aD),e(aD,Aho),e(Ag,Lho),e(A,yho),e(A,Lg),e(Lg,Vhe),e(Vhe,xho),e(Lg,$ho),e(Lg,nD),e(nD,kho),e(Lg,Sho),e(A,Rho),e(A,yg),e(yg,Xhe),e(Xhe,Pho),e(yg,Bho),e(yg,sD),e(sD,Iho),e(yg,Nho),e(A,qho),e(A,xg),e(xg,zhe),e(zhe,Dho),e(xg,jho),e(xg,lD),e(lD,Gho),e(xg,Oho),e(A,Vho),e(A,$g),e($g,Qhe),e(Qhe,Xho),e($g,zho),e($g,iD),e(iD,Qho),e($g,Who),e(A,Uho),e(A,kg),e(kg,Whe),e(Whe,Hho),e(kg,Jho),e(kg,dD),e(dD,Yho),e(kg,Zho),e(A,Kho),e(A,Sg),e(Sg,Uhe),e(Uhe,euo),e(Sg,ouo),e(Sg,mD),e(mD,ruo),e(Sg,tuo),e(A,auo),e(A,Rg),e(Rg,Hhe),e(Hhe,nuo),e(Rg,suo),e(Rg,cD),e(cD,luo),e(Rg,iuo),e(A,duo),e(A,Pg),e(Pg,Jhe),e(Jhe,muo),e(Pg,cuo),e(Pg,fD),e(fD,fuo),e(Pg,guo),e(A,huo),e(A,Bg),e(Bg,Yhe),e(Yhe,uuo),e(Bg,puo),e(Bg,gD),e(gD,_uo),e(Bg,buo),e(A,vuo),e(A,Ig),e(Ig,Zhe),e(Zhe,Fuo),e(Ig,Tuo),e(Ig,hD),e(hD,Muo),e(Ig,Euo),e(A,Cuo),e(A,Ng),e(Ng,Khe),e(Khe,wuo),e(Ng,Auo),e(Ng,uD),e(uD,Luo),e(Ng,yuo),e(A,xuo),e(A,qg),e(qg,eue),e(eue,$uo),e(qg,kuo),e(qg,pD),e(pD,Suo),e(qg,Ruo),e(A,Puo),e(A,Dg),e(Dg,oue),e(oue,Buo),e(Dg,Iuo),e(Dg,_D),e(_D,Nuo),e(Dg,quo),e(A,Duo),e(A,jg),e(jg,rue),e(rue,juo),e(jg,Guo),e(jg,bD),e(bD,Ouo),e(jg,Vuo),e(A,Xuo),e(A,Gg),e(Gg,tue),e(tue,zuo),e(Gg,Quo),e(Gg,vD),e(vD,Wuo),e(Gg,Uuo),e(A,Huo),e(A,Og),e(Og,aue),e(aue,Juo),e(Og,Yuo),e(Og,FD),e(FD,Zuo),e(Og,Kuo),e(A,epo),e(A,Vg),e(Vg,nue),e(nue,opo),e(Vg,rpo),e(Vg,TD),e(TD,tpo),e(Vg,apo),e(A,npo),e(A,Xg),e(Xg,sue),e(sue,spo),e(Xg,lpo),e(Xg,MD),e(MD,ipo),e(Xg,dpo),e(A,mpo),e(A,zg),e(zg,lue),e(lue,cpo),e(zg,fpo),e(zg,ED),e(ED,gpo),e(zg,hpo),e(A,upo),e(A,Qg),e(Qg,iue),e(iue,ppo),e(Qg,_po),e(Qg,CD),e(CD,bpo),e(Qg,vpo),e(A,Fpo),e(A,Wg),e(Wg,due),e(due,Tpo),e(Wg,Mpo),e(Wg,wD),e(wD,Epo),e(Wg,Cpo),e(A,wpo),e(A,Ug),e(Ug,mue),e(mue,Apo),e(Ug,Lpo),e(Ug,AD),e(AD,ypo),e(Ug,xpo),e(A,$po),e(A,Hg),e(Hg,cue),e(cue,kpo),e(Hg,Spo),e(Hg,LD),e(LD,Rpo),e(Hg,Ppo),e(A,Bpo),e(A,Jg),e(Jg,fue),e(fue,Ipo),e(Jg,Npo),e(Jg,yD),e(yD,qpo),e(Jg,Dpo),e(A,jpo),e(A,Yg),e(Yg,gue),e(gue,Gpo),e(Yg,Opo),e(Yg,xD),e(xD,Vpo),e(Yg,Xpo),e(A,zpo),e(A,Zg),e(Zg,hue),e(hue,Qpo),e(Zg,Wpo),e(Zg,$D),e($D,Upo),e(Zg,Hpo),e(A,Jpo),e(A,Kg),e(Kg,uue),e(uue,Ypo),e(Kg,Zpo),e(Kg,kD),e(kD,Kpo),e(Kg,e_o),e(A,o_o),e(A,eh),e(eh,pue),e(pue,r_o),e(eh,t_o),e(eh,SD),e(SD,a_o),e(eh,n_o),e(A,s_o),e(A,oh),e(oh,_ue),e(_ue,l_o),e(oh,i_o),e(oh,RD),e(RD,d_o),e(oh,m_o),e(A,c_o),e(A,rh),e(rh,bue),e(bue,f_o),e(rh,g_o),e(rh,PD),e(PD,h_o),e(rh,u_o),e(A,p_o),e(A,th),e(th,vue),e(vue,__o),e(th,b_o),e(th,BD),e(BD,v_o),e(th,F_o),e(A,T_o),e(A,ah),e(ah,Fue),e(Fue,M_o),e(ah,E_o),e(ah,ID),e(ID,C_o),e(ah,w_o),e(A,A_o),e(A,nh),e(nh,Tue),e(Tue,L_o),e(nh,y_o),e(nh,ND),e(ND,x_o),e(nh,$_o),e(A,k_o),e(A,sh),e(sh,Mue),e(Mue,S_o),e(sh,R_o),e(sh,qD),e(qD,P_o),e(sh,B_o),e(A,I_o),e(A,lh),e(lh,Eue),e(Eue,N_o),e(lh,q_o),e(lh,DD),e(DD,D_o),e(lh,j_o),e(A,G_o),e(A,ih),e(ih,Cue),e(Cue,O_o),e(ih,V_o),e(ih,jD),e(jD,X_o),e(ih,z_o),e(A,Q_o),e(A,dh),e(dh,wue),e(wue,W_o),e(dh,U_o),e(dh,GD),e(GD,H_o),e(dh,J_o),e(A,Y_o),e(A,mh),e(mh,Aue),e(Aue,Z_o),e(mh,K_o),e(mh,OD),e(OD,e1o),e(mh,o1o),e(A,r1o),e(A,ch),e(ch,Lue),e(Lue,t1o),e(ch,a1o),e(ch,VD),e(VD,n1o),e(ch,s1o),e(A,l1o),e(A,fh),e(fh,yue),e(yue,i1o),e(fh,d1o),e(fh,XD),e(XD,m1o),e(fh,c1o),e(A,f1o),e(A,gh),e(gh,xue),e(xue,g1o),e(gh,h1o),e(gh,zD),e(zD,u1o),e(gh,p1o),e(A,_1o),e(A,hh),e(hh,$ue),e($ue,b1o),e(hh,v1o),e(hh,QD),e(QD,F1o),e(hh,T1o),e(A,M1o),e(A,uh),e(uh,kue),e(kue,E1o),e(uh,C1o),e(uh,WD),e(WD,w1o),e(uh,A1o),e(A,L1o),e(A,ph),e(ph,Sue),e(Sue,y1o),e(ph,x1o),e(ph,UD),e(UD,$1o),e(ph,k1o),e(A,S1o),e(A,_h),e(_h,Rue),e(Rue,R1o),e(_h,P1o),e(_h,HD),e(HD,B1o),e(_h,I1o),e(A,N1o),e(A,bh),e(bh,Pue),e(Pue,q1o),e(bh,D1o),e(bh,JD),e(JD,j1o),e(bh,G1o),e(A,O1o),e(A,vh),e(vh,Bue),e(Bue,V1o),e(vh,X1o),e(vh,YD),e(YD,z1o),e(vh,Q1o),e(A,W1o),e(A,Fh),e(Fh,Iue),e(Iue,U1o),e(Fh,H1o),e(Fh,ZD),e(ZD,J1o),e(Fh,Y1o),e(A,Z1o),e(A,Th),e(Th,Nue),e(Nue,K1o),e(Th,e2o),e(Th,KD),e(KD,o2o),e(Th,r2o),e(A,t2o),e(A,Mh),e(Mh,que),e(que,a2o),e(Mh,n2o),e(Mh,ej),e(ej,s2o),e(Mh,l2o),e(A,i2o),e(A,Eh),e(Eh,Due),e(Due,d2o),e(Eh,m2o),e(Eh,oj),e(oj,c2o),e(Eh,f2o),e(A,g2o),e(A,Ch),e(Ch,jue),e(jue,h2o),e(Ch,u2o),e(Ch,rj),e(rj,p2o),e(Ch,_2o),e(A,b2o),e(A,wh),e(wh,Gue),e(Gue,v2o),e(wh,F2o),e(wh,tj),e(tj,T2o),e(wh,M2o),e(A,E2o),e(A,Ah),e(Ah,Oue),e(Oue,C2o),e(Ah,w2o),e(Ah,aj),e(aj,A2o),e(Ah,L2o),e(A,y2o),e(A,Lh),e(Lh,Vue),e(Vue,x2o),e(Lh,$2o),e(Lh,nj),e(nj,k2o),e(Lh,S2o),e(A,R2o),e(A,yh),e(yh,Xue),e(Xue,P2o),e(yh,B2o),e(yh,sj),e(sj,I2o),e(yh,N2o),e(A,q2o),e(A,xh),e(xh,zue),e(zue,D2o),e(xh,j2o),e(xh,lj),e(lj,G2o),e(xh,O2o),e(A,V2o),e(A,$h),e($h,Que),e(Que,X2o),e($h,z2o),e($h,ij),e(ij,Q2o),e($h,W2o),e(A,U2o),e(A,kh),e(kh,Wue),e(Wue,H2o),e(kh,J2o),e(kh,dj),e(dj,Y2o),e(kh,Z2o),e(A,K2o),e(A,Sh),e(Sh,Uue),e(Uue,ebo),e(Sh,obo),e(Sh,mj),e(mj,rbo),e(Sh,tbo),e(A,abo),e(A,Rh),e(Rh,Hue),e(Hue,nbo),e(Rh,sbo),e(Rh,cj),e(cj,lbo),e(Rh,ibo),e(A,dbo),e(A,Ph),e(Ph,Jue),e(Jue,mbo),e(Ph,cbo),e(Ph,fj),e(fj,fbo),e(Ph,gbo),e(A,hbo),e(A,Bh),e(Bh,Yue),e(Yue,ubo),e(Bh,pbo),e(Bh,gj),e(gj,_bo),e(Bh,bbo),e(A,vbo),e(A,Ih),e(Ih,Zue),e(Zue,Fbo),e(Ih,Tbo),e(Ih,hj),e(hj,Mbo),e(Ih,Ebo),e(A,Cbo),e(A,Nh),e(Nh,Kue),e(Kue,wbo),e(Nh,Abo),e(Nh,uj),e(uj,Lbo),e(Nh,ybo),e(A,xbo),e(A,qh),e(qh,epe),e(epe,$bo),e(qh,kbo),e(qh,pj),e(pj,Sbo),e(qh,Rbo),e(A,Pbo),e(A,Dh),e(Dh,ope),e(ope,Bbo),e(Dh,Ibo),e(Dh,_j),e(_j,Nbo),e(Dh,qbo),e(A,Dbo),e(A,jh),e(jh,rpe),e(rpe,jbo),e(jh,Gbo),e(jh,bj),e(bj,Obo),e(jh,Vbo),e(A,Xbo),e(A,Gh),e(Gh,tpe),e(tpe,zbo),e(Gh,Qbo),e(Gh,vj),e(vj,Wbo),e(Gh,Ubo),e(A,Hbo),e(A,Oh),e(Oh,ape),e(ape,Jbo),e(Oh,Ybo),e(Oh,Fj),e(Fj,Zbo),e(Oh,Kbo),e(A,evo),e(A,Vh),e(Vh,npe),e(npe,ovo),e(Vh,rvo),e(Vh,Tj),e(Tj,tvo),e(Vh,avo),e(A,nvo),e(A,Xh),e(Xh,spe),e(spe,svo),e(Xh,lvo),e(Xh,Mj),e(Mj,ivo),e(Xh,dvo),e(A,mvo),e(A,zh),e(zh,lpe),e(lpe,cvo),e(zh,fvo),e(zh,Ej),e(Ej,gvo),e(zh,hvo),e(A,uvo),e(A,Qh),e(Qh,ipe),e(ipe,pvo),e(Qh,_vo),e(Qh,Cj),e(Cj,bvo),e(Qh,vvo),e(A,Fvo),e(A,Wh),e(Wh,dpe),e(dpe,Tvo),e(Wh,Mvo),e(Wh,wj),e(wj,Evo),e(Wh,Cvo),e(A,wvo),e(A,Uh),e(Uh,mpe),e(mpe,Avo),e(Uh,Lvo),e(Uh,Aj),e(Aj,yvo),e(Uh,xvo),e(A,$vo),e(A,Hh),e(Hh,cpe),e(cpe,kvo),e(Hh,Svo),e(Hh,Lj),e(Lj,Rvo),e(Hh,Pvo),e(A,Bvo),e(A,Jh),e(Jh,fpe),e(fpe,Ivo),e(Jh,Nvo),e(Jh,yj),e(yj,qvo),e(Jh,Dvo),e(A,jvo),e(A,Yh),e(Yh,gpe),e(gpe,Gvo),e(Yh,Ovo),e(Yh,xj),e(xj,Vvo),e(Yh,Xvo),e(A,zvo),e(A,Zh),e(Zh,hpe),e(hpe,Qvo),e(Zh,Wvo),e(Zh,$j),e($j,Uvo),e(Zh,Hvo),e(A,Jvo),e(A,Kh),e(Kh,upe),e(upe,Yvo),e(Kh,Zvo),e(Kh,kj),e(kj,Kvo),e(Kh,eFo),e(A,oFo),e(A,eu),e(eu,ppe),e(ppe,rFo),e(eu,tFo),e(eu,Sj),e(Sj,aFo),e(eu,nFo),e(A,sFo),e(A,ou),e(ou,_pe),e(_pe,lFo),e(ou,iFo),e(ou,Rj),e(Rj,dFo),e(ou,mFo),e(A,cFo),e(A,ru),e(ru,bpe),e(bpe,fFo),e(ru,gFo),e(ru,Pj),e(Pj,hFo),e(ru,uFo),e(A,pFo),e(A,tu),e(tu,vpe),e(vpe,_Fo),e(tu,bFo),e(tu,Bj),e(Bj,vFo),e(tu,FFo),e(A,TFo),e(A,au),e(au,Fpe),e(Fpe,MFo),e(au,EFo),e(au,Ij),e(Ij,CFo),e(au,wFo),e(A,AFo),e(A,nu),e(nu,Tpe),e(Tpe,LFo),e(nu,yFo),e(nu,Nj),e(Nj,xFo),e(nu,$Fo),e(A,kFo),e(A,su),e(su,Mpe),e(Mpe,SFo),e(su,RFo),e(su,qj),e(qj,PFo),e(su,BFo),e(A,IFo),e(A,lu),e(lu,Epe),e(Epe,NFo),e(lu,qFo),e(lu,Dj),e(Dj,DFo),e(lu,jFo),e(A,GFo),e(A,iu),e(iu,Cpe),e(Cpe,OFo),e(iu,VFo),e(iu,jj),e(jj,XFo),e(iu,zFo),e(A,QFo),e(A,du),e(du,wpe),e(wpe,WFo),e(du,UFo),e(du,Gj),e(Gj,HFo),e(du,JFo),e(A,YFo),e(A,mu),e(mu,Ape),e(Ape,ZFo),e(mu,KFo),e(mu,Oj),e(Oj,eTo),e(mu,oTo),e(A,rTo),e(A,cu),e(cu,Lpe),e(Lpe,tTo),e(cu,aTo),e(cu,Vj),e(Vj,nTo),e(cu,sTo),e(A,lTo),e(A,fu),e(fu,ype),e(ype,iTo),e(fu,dTo),e(fu,Xj),e(Xj,mTo),e(fu,cTo),e(A,fTo),e(A,gu),e(gu,xpe),e(xpe,gTo),e(gu,hTo),e(gu,zj),e(zj,uTo),e(gu,pTo),e(A,_To),e(A,hu),e(hu,$pe),e($pe,bTo),e(hu,vTo),e(hu,Qj),e(Qj,FTo),e(hu,TTo),e(A,MTo),e(A,uu),e(uu,kpe),e(kpe,ETo),e(uu,CTo),e(uu,Wj),e(Wj,wTo),e(uu,ATo),e(A,LTo),e(A,pu),e(pu,Spe),e(Spe,yTo),e(pu,xTo),e(pu,Uj),e(Uj,$To),e(pu,kTo),e(A,STo),e(A,_u),e(_u,Rpe),e(Rpe,RTo),e(_u,PTo),e(_u,Hj),e(Hj,BTo),e(_u,ITo),e(A,NTo),e(A,bu),e(bu,Ppe),e(Ppe,qTo),e(bu,DTo),e(bu,Jj),e(Jj,jTo),e(bu,GTo),e(A,OTo),e(A,vu),e(vu,Bpe),e(Bpe,VTo),e(vu,XTo),e(vu,Yj),e(Yj,zTo),e(vu,QTo),e(A,WTo),e(A,Fu),e(Fu,Ipe),e(Ipe,UTo),e(Fu,HTo),e(Fu,Zj),e(Zj,JTo),e(Fu,YTo),e(A,ZTo),e(A,Tu),e(Tu,Npe),e(Npe,KTo),e(Tu,eMo),e(Tu,Kj),e(Kj,oMo),e(Tu,rMo),e(A,tMo),e(A,Mu),e(Mu,qpe),e(qpe,aMo),e(Mu,nMo),e(Mu,eG),e(eG,sMo),e(Mu,lMo),e(A,iMo),e(A,Eu),e(Eu,Dpe),e(Dpe,dMo),e(Eu,mMo),e(Eu,oG),e(oG,cMo),e(Eu,fMo),e(A,gMo),e(A,Cu),e(Cu,jpe),e(jpe,hMo),e(Cu,uMo),e(Cu,rG),e(rG,pMo),e(Cu,_Mo),e(A,bMo),e(A,wu),e(wu,Gpe),e(Gpe,vMo),e(wu,FMo),e(wu,tG),e(tG,TMo),e(wu,MMo),e(A,EMo),e(A,Au),e(Au,Ope),e(Ope,CMo),e(Au,wMo),e(Au,aG),e(aG,AMo),e(Au,LMo),e(A,yMo),e(A,Lu),e(Lu,Vpe),e(Vpe,xMo),e(Lu,$Mo),e(Lu,nG),e(nG,kMo),e(Lu,SMo),e(A,RMo),e(A,yu),e(yu,Xpe),e(Xpe,PMo),e(yu,BMo),e(yu,sG),e(sG,IMo),e(yu,NMo),e(A,qMo),e(A,xu),e(xu,zpe),e(zpe,DMo),e(xu,jMo),e(xu,lG),e(lG,GMo),e(xu,OMo),e(A,VMo),e(A,$u),e($u,Qpe),e(Qpe,XMo),e($u,zMo),e($u,iG),e(iG,QMo),e($u,WMo),e(A,UMo),e(A,ku),e(ku,Wpe),e(Wpe,HMo),e(ku,JMo),e(ku,dG),e(dG,YMo),e(ku,ZMo),e(A,KMo),e(A,Su),e(Su,Upe),e(Upe,eEo),e(Su,oEo),e(Su,mG),e(mG,rEo),e(Su,tEo),e(A,aEo),e(A,Ru),e(Ru,Hpe),e(Hpe,nEo),e(Ru,sEo),e(Ru,cG),e(cG,lEo),e(Ru,iEo),e(A,dEo),e(A,Pu),e(Pu,Jpe),e(Jpe,mEo),e(Pu,cEo),e(Pu,fG),e(fG,fEo),e(Pu,gEo),e(A,hEo),e(A,Bu),e(Bu,Ype),e(Ype,uEo),e(Bu,pEo),e(Bu,gG),e(gG,_Eo),e(Bu,bEo),e(Or,vEo),M(Iu,Or,null),e(Bo,FEo),e(Bo,Nu),M(vk,Nu,null),e(Nu,TEo),e(Nu,Zpe),e(Zpe,MEo),b(c,Elo,_),b(c,Id,_),e(Id,qu),e(qu,Kpe),M(Fk,Kpe,null),e(Id,EEo),e(Id,e_e),e(e_e,CEo),b(c,Clo,_),b(c,Io,_),M(Tk,Io,null),e(Io,wEo),e(Io,Mk),e(Mk,AEo),e(Mk,hG),e(hG,LEo),e(Mk,yEo),e(Io,xEo),e(Io,Ek),e(Ek,$Eo),e(Ek,o_e),e(o_e,kEo),e(Ek,SEo),e(Io,REo),e(Io,Vr),M(Ck,Vr,null),e(Vr,PEo),e(Vr,r_e),e(r_e,BEo),e(Vr,IEo),e(Vr,dn),e(dn,NEo),e(dn,t_e),e(t_e,qEo),e(dn,DEo),e(dn,a_e),e(a_e,jEo),e(dn,GEo),e(dn,n_e),e(n_e,OEo),e(dn,VEo),e(Vr,XEo),e(Vr,k),e(k,Ts),e(Ts,s_e),e(s_e,zEo),e(Ts,QEo),e(Ts,uG),e(uG,WEo),e(Ts,UEo),e(Ts,pG),e(pG,HEo),e(Ts,JEo),e(k,YEo),e(k,Ms),e(Ms,l_e),e(l_e,ZEo),e(Ms,KEo),e(Ms,_G),e(_G,e4o),e(Ms,o4o),e(Ms,bG),e(bG,r4o),e(Ms,t4o),e(k,a4o),e(k,Es),e(Es,i_e),e(i_e,n4o),e(Es,s4o),e(Es,vG),e(vG,l4o),e(Es,i4o),e(Es,FG),e(FG,d4o),e(Es,m4o),e(k,c4o),e(k,Du),e(Du,d_e),e(d_e,f4o),e(Du,g4o),e(Du,TG),e(TG,h4o),e(Du,u4o),e(k,p4o),e(k,Cs),e(Cs,m_e),e(m_e,_4o),e(Cs,b4o),e(Cs,MG),e(MG,v4o),e(Cs,F4o),e(Cs,EG),e(EG,T4o),e(Cs,M4o),e(k,E4o),e(k,ju),e(ju,c_e),e(c_e,C4o),e(ju,w4o),e(ju,CG),e(CG,A4o),e(ju,L4o),e(k,y4o),e(k,Gu),e(Gu,f_e),e(f_e,x4o),e(Gu,$4o),e(Gu,wG),e(wG,k4o),e(Gu,S4o),e(k,R4o),e(k,Ou),e(Ou,g_e),e(g_e,P4o),e(Ou,B4o),e(Ou,AG),e(AG,I4o),e(Ou,N4o),e(k,q4o),e(k,ws),e(ws,h_e),e(h_e,D4o),e(ws,j4o),e(ws,LG),e(LG,G4o),e(ws,O4o),e(ws,yG),e(yG,V4o),e(ws,X4o),e(k,z4o),e(k,As),e(As,u_e),e(u_e,Q4o),e(As,W4o),e(As,xG),e(xG,U4o),e(As,H4o),e(As,$G),e($G,J4o),e(As,Y4o),e(k,Z4o),e(k,Ls),e(Ls,p_e),e(p_e,K4o),e(Ls,eCo),e(Ls,kG),e(kG,oCo),e(Ls,rCo),e(Ls,SG),e(SG,tCo),e(Ls,aCo),e(k,nCo),e(k,Vu),e(Vu,__e),e(__e,sCo),e(Vu,lCo),e(Vu,RG),e(RG,iCo),e(Vu,dCo),e(k,mCo),e(k,Xu),e(Xu,b_e),e(b_e,cCo),e(Xu,fCo),e(Xu,PG),e(PG,gCo),e(Xu,hCo),e(k,uCo),e(k,zu),e(zu,v_e),e(v_e,pCo),e(zu,_Co),e(zu,BG),e(BG,bCo),e(zu,vCo),e(k,FCo),e(k,ys),e(ys,F_e),e(F_e,TCo),e(ys,MCo),e(ys,IG),e(IG,ECo),e(ys,CCo),e(ys,NG),e(NG,wCo),e(ys,ACo),e(k,LCo),e(k,Qu),e(Qu,T_e),e(T_e,yCo),e(Qu,xCo),e(Qu,qG),e(qG,$Co),e(Qu,kCo),e(k,SCo),e(k,xs),e(xs,M_e),e(M_e,RCo),e(xs,PCo),e(xs,DG),e(DG,BCo),e(xs,ICo),e(xs,jG),e(jG,NCo),e(xs,qCo),e(k,DCo),e(k,$s),e($s,E_e),e(E_e,jCo),e($s,GCo),e($s,GG),e(GG,OCo),e($s,VCo),e($s,OG),e(OG,XCo),e($s,zCo),e(k,QCo),e(k,ks),e(ks,C_e),e(C_e,WCo),e(ks,UCo),e(ks,VG),e(VG,HCo),e(ks,JCo),e(ks,XG),e(XG,YCo),e(ks,ZCo),e(k,KCo),e(k,Ss),e(Ss,w_e),e(w_e,e3o),e(Ss,o3o),e(Ss,zG),e(zG,r3o),e(Ss,t3o),e(Ss,QG),e(QG,a3o),e(Ss,n3o),e(k,s3o),e(k,Rs),e(Rs,A_e),e(A_e,l3o),e(Rs,i3o),e(Rs,WG),e(WG,d3o),e(Rs,m3o),e(Rs,UG),e(UG,c3o),e(Rs,f3o),e(k,g3o),e(k,Wu),e(Wu,L_e),e(L_e,h3o),e(Wu,u3o),e(Wu,HG),e(HG,p3o),e(Wu,_3o),e(k,b3o),e(k,Ps),e(Ps,y_e),e(y_e,v3o),e(Ps,F3o),e(Ps,JG),e(JG,T3o),e(Ps,M3o),e(Ps,YG),e(YG,E3o),e(Ps,C3o),e(k,w3o),e(k,Bs),e(Bs,x_e),e(x_e,A3o),e(Bs,L3o),e(Bs,ZG),e(ZG,y3o),e(Bs,x3o),e(Bs,KG),e(KG,$3o),e(Bs,k3o),e(k,S3o),e(k,Is),e(Is,$_e),e($_e,R3o),e(Is,P3o),e(Is,eO),e(eO,B3o),e(Is,I3o),e(Is,oO),e(oO,N3o),e(Is,q3o),e(k,D3o),e(k,Ns),e(Ns,k_e),e(k_e,j3o),e(Ns,G3o),e(Ns,rO),e(rO,O3o),e(Ns,V3o),e(Ns,tO),e(tO,X3o),e(Ns,z3o),e(k,Q3o),e(k,qs),e(qs,S_e),e(S_e,W3o),e(qs,U3o),e(qs,aO),e(aO,H3o),e(qs,J3o),e(qs,nO),e(nO,Y3o),e(qs,Z3o),e(k,K3o),e(k,Ds),e(Ds,R_e),e(R_e,e5o),e(Ds,o5o),e(Ds,sO),e(sO,r5o),e(Ds,t5o),e(Ds,lO),e(lO,a5o),e(Ds,n5o),e(k,s5o),e(k,js),e(js,P_e),e(P_e,l5o),e(js,i5o),e(js,iO),e(iO,d5o),e(js,m5o),e(js,dO),e(dO,c5o),e(js,f5o),e(k,g5o),e(k,Uu),e(Uu,B_e),e(B_e,h5o),e(Uu,u5o),e(Uu,mO),e(mO,p5o),e(Uu,_5o),e(k,b5o),e(k,Hu),e(Hu,I_e),e(I_e,v5o),e(Hu,F5o),e(Hu,cO),e(cO,T5o),e(Hu,M5o),e(k,E5o),e(k,Gs),e(Gs,N_e),e(N_e,C5o),e(Gs,w5o),e(Gs,fO),e(fO,A5o),e(Gs,L5o),e(Gs,gO),e(gO,y5o),e(Gs,x5o),e(k,$5o),e(k,Ju),e(Ju,q_e),e(q_e,k5o),e(Ju,S5o),e(Ju,hO),e(hO,R5o),e(Ju,P5o),e(k,B5o),e(k,Os),e(Os,D_e),e(D_e,I5o),e(Os,N5o),e(Os,uO),e(uO,q5o),e(Os,D5o),e(Os,pO),e(pO,j5o),e(Os,G5o),e(k,O5o),e(k,Vs),e(Vs,j_e),e(j_e,V5o),e(Vs,X5o),e(Vs,_O),e(_O,z5o),e(Vs,Q5o),e(Vs,bO),e(bO,W5o),e(Vs,U5o),e(k,H5o),e(k,Xs),e(Xs,G_e),e(G_e,J5o),e(Xs,Y5o),e(Xs,vO),e(vO,Z5o),e(Xs,K5o),e(Xs,FO),e(FO,e0o),e(Xs,o0o),e(k,r0o),e(k,Yu),e(Yu,O_e),e(O_e,t0o),e(Yu,a0o),e(Yu,TO),e(TO,n0o),e(Yu,s0o),e(k,l0o),e(k,Zu),e(Zu,V_e),e(V_e,i0o),e(Zu,d0o),e(Zu,MO),e(MO,m0o),e(Zu,c0o),e(k,f0o),e(k,zs),e(zs,X_e),e(X_e,g0o),e(zs,h0o),e(zs,EO),e(EO,u0o),e(zs,p0o),e(zs,CO),e(CO,_0o),e(zs,b0o),e(k,v0o),e(k,Qs),e(Qs,z_e),e(z_e,F0o),e(Qs,T0o),e(Qs,wO),e(wO,M0o),e(Qs,E0o),e(Qs,AO),e(AO,C0o),e(Qs,w0o),e(k,A0o),e(k,Ws),e(Ws,Q_e),e(Q_e,L0o),e(Ws,y0o),e(Ws,LO),e(LO,x0o),e(Ws,$0o),e(Ws,yO),e(yO,k0o),e(Ws,S0o),e(k,R0o),e(k,Ku),e(Ku,W_e),e(W_e,P0o),e(Ku,B0o),e(Ku,xO),e(xO,I0o),e(Ku,N0o),e(k,q0o),e(k,Us),e(Us,U_e),e(U_e,D0o),e(Us,j0o),e(Us,$O),e($O,G0o),e(Us,O0o),e(Us,kO),e(kO,V0o),e(Us,X0o),e(k,z0o),e(k,Hs),e(Hs,H_e),e(H_e,Q0o),e(Hs,W0o),e(Hs,SO),e(SO,U0o),e(Hs,H0o),e(Hs,RO),e(RO,J0o),e(Hs,Y0o),e(k,Z0o),e(k,Js),e(Js,J_e),e(J_e,K0o),e(Js,ewo),e(Js,PO),e(PO,owo),e(Js,rwo),e(Js,BO),e(BO,two),e(Js,awo),e(k,nwo),e(k,Ys),e(Ys,Y_e),e(Y_e,swo),e(Ys,lwo),e(Ys,IO),e(IO,iwo),e(Ys,dwo),e(Ys,NO),e(NO,mwo),e(Ys,cwo),e(k,fwo),e(k,Zs),e(Zs,Z_e),e(Z_e,gwo),e(Zs,hwo),e(Zs,qO),e(qO,uwo),e(Zs,pwo),e(Zs,DO),e(DO,_wo),e(Zs,bwo),e(k,vwo),e(k,Ks),e(Ks,K_e),e(K_e,Fwo),e(Ks,Two),e(Ks,jO),e(jO,Mwo),e(Ks,Ewo),e(Ks,GO),e(GO,Cwo),e(Ks,wwo),e(k,Awo),e(k,el),e(el,e1e),e(e1e,Lwo),e(el,ywo),e(el,OO),e(OO,xwo),e(el,$wo),e(el,VO),e(VO,kwo),e(el,Swo),e(k,Rwo),e(k,ol),e(ol,o1e),e(o1e,Pwo),e(ol,Bwo),e(ol,XO),e(XO,Iwo),e(ol,Nwo),e(ol,zO),e(zO,qwo),e(ol,Dwo),e(k,jwo),e(k,rl),e(rl,r1e),e(r1e,Gwo),e(rl,Owo),e(rl,QO),e(QO,Vwo),e(rl,Xwo),e(rl,WO),e(WO,zwo),e(rl,Qwo),e(k,Wwo),e(k,ep),e(ep,t1e),e(t1e,Uwo),e(ep,Hwo),e(ep,UO),e(UO,Jwo),e(ep,Ywo),e(k,Zwo),e(k,tl),e(tl,a1e),e(a1e,Kwo),e(tl,eAo),e(tl,HO),e(HO,oAo),e(tl,rAo),e(tl,JO),e(JO,tAo),e(tl,aAo),e(k,nAo),e(k,op),e(op,n1e),e(n1e,sAo),e(op,lAo),e(op,YO),e(YO,iAo),e(op,dAo),e(k,mAo),e(k,rp),e(rp,s1e),e(s1e,cAo),e(rp,fAo),e(rp,ZO),e(ZO,gAo),e(rp,hAo),e(k,uAo),e(k,al),e(al,l1e),e(l1e,pAo),e(al,_Ao),e(al,KO),e(KO,bAo),e(al,vAo),e(al,eV),e(eV,FAo),e(al,TAo),e(k,MAo),e(k,nl),e(nl,i1e),e(i1e,EAo),e(nl,CAo),e(nl,oV),e(oV,wAo),e(nl,AAo),e(nl,rV),e(rV,LAo),e(nl,yAo),e(k,xAo),e(k,sl),e(sl,d1e),e(d1e,$Ao),e(sl,kAo),e(sl,tV),e(tV,SAo),e(sl,RAo),e(sl,aV),e(aV,PAo),e(sl,BAo),e(k,IAo),e(k,tp),e(tp,m1e),e(m1e,NAo),e(tp,qAo),e(tp,nV),e(nV,DAo),e(tp,jAo),e(k,GAo),e(k,ll),e(ll,c1e),e(c1e,OAo),e(ll,VAo),e(ll,sV),e(sV,XAo),e(ll,zAo),e(ll,lV),e(lV,QAo),e(ll,WAo),e(k,UAo),e(k,il),e(il,f1e),e(f1e,HAo),e(il,JAo),e(il,iV),e(iV,YAo),e(il,ZAo),e(il,dV),e(dV,KAo),e(il,e6o),e(k,o6o),e(k,dl),e(dl,g1e),e(g1e,r6o),e(dl,t6o),e(dl,mV),e(mV,a6o),e(dl,n6o),e(dl,cV),e(cV,s6o),e(dl,l6o),e(k,i6o),e(k,ml),e(ml,h1e),e(h1e,d6o),e(ml,m6o),e(ml,fV),e(fV,c6o),e(ml,f6o),e(ml,gV),e(gV,g6o),e(ml,h6o),e(k,u6o),e(k,cl),e(cl,u1e),e(u1e,p6o),e(cl,_6o),e(cl,hV),e(hV,b6o),e(cl,v6o),e(cl,uV),e(uV,F6o),e(cl,T6o),e(k,M6o),e(k,fl),e(fl,p1e),e(p1e,E6o),e(fl,C6o),e(fl,pV),e(pV,w6o),e(fl,A6o),e(fl,_V),e(_V,L6o),e(fl,y6o),e(k,x6o),e(k,gl),e(gl,_1e),e(_1e,$6o),e(gl,k6o),e(gl,bV),e(bV,S6o),e(gl,R6o),e(gl,vV),e(vV,P6o),e(gl,B6o),e(k,I6o),e(k,hl),e(hl,b1e),e(b1e,N6o),e(hl,q6o),e(hl,FV),e(FV,D6o),e(hl,j6o),e(hl,TV),e(TV,G6o),e(hl,O6o),e(k,V6o),e(k,ap),e(ap,v1e),e(v1e,X6o),e(ap,z6o),e(ap,MV),e(MV,Q6o),e(ap,W6o),e(k,U6o),e(k,ul),e(ul,F1e),e(F1e,H6o),e(ul,J6o),e(ul,EV),e(EV,Y6o),e(ul,Z6o),e(ul,CV),e(CV,K6o),e(ul,e7o),e(k,o7o),e(k,pl),e(pl,T1e),e(T1e,r7o),e(pl,t7o),e(pl,wV),e(wV,a7o),e(pl,n7o),e(pl,AV),e(AV,s7o),e(pl,l7o),e(k,i7o),e(k,_l),e(_l,M1e),e(M1e,d7o),e(_l,m7o),e(_l,LV),e(LV,c7o),e(_l,f7o),e(_l,yV),e(yV,g7o),e(_l,h7o),e(k,u7o),e(k,np),e(np,E1e),e(E1e,p7o),e(np,_7o),e(np,xV),e(xV,b7o),e(np,v7o),e(k,F7o),e(k,sp),e(sp,C1e),e(C1e,T7o),e(sp,M7o),e(sp,$V),e($V,E7o),e(sp,C7o),e(k,w7o),e(k,lp),e(lp,w1e),e(w1e,A7o),e(lp,L7o),e(lp,kV),e(kV,y7o),e(lp,x7o),e(k,$7o),e(k,ip),e(ip,A1e),e(A1e,k7o),e(ip,S7o),e(ip,SV),e(SV,R7o),e(ip,P7o),e(k,B7o),e(k,bl),e(bl,L1e),e(L1e,I7o),e(bl,N7o),e(bl,RV),e(RV,q7o),e(bl,D7o),e(bl,PV),e(PV,j7o),e(bl,G7o),e(k,O7o),e(k,dp),e(dp,y1e),e(y1e,V7o),e(dp,X7o),e(dp,BV),e(BV,z7o),e(dp,Q7o),e(k,W7o),e(k,vl),e(vl,x1e),e(x1e,U7o),e(vl,H7o),e(vl,IV),e(IV,J7o),e(vl,Y7o),e(vl,NV),e(NV,Z7o),e(vl,K7o),e(k,e8o),e(k,Fl),e(Fl,$1e),e($1e,o8o),e(Fl,r8o),e(Fl,qV),e(qV,t8o),e(Fl,a8o),e(Fl,DV),e(DV,n8o),e(Fl,s8o),e(k,l8o),e(k,Tl),e(Tl,k1e),e(k1e,i8o),e(Tl,d8o),e(Tl,jV),e(jV,m8o),e(Tl,c8o),e(Tl,GV),e(GV,f8o),e(Tl,g8o),e(k,h8o),e(k,Ml),e(Ml,S1e),e(S1e,u8o),e(Ml,p8o),e(Ml,OV),e(OV,_8o),e(Ml,b8o),e(Ml,VV),e(VV,v8o),e(Ml,F8o),e(k,T8o),e(k,El),e(El,R1e),e(R1e,M8o),e(El,E8o),e(El,XV),e(XV,C8o),e(El,w8o),e(El,zV),e(zV,A8o),e(El,L8o),e(k,y8o),e(k,mp),e(mp,P1e),e(P1e,x8o),e(mp,$8o),e(mp,QV),e(QV,k8o),e(mp,S8o),e(k,R8o),e(k,Cl),e(Cl,B1e),e(B1e,P8o),e(Cl,B8o),e(Cl,WV),e(WV,I8o),e(Cl,N8o),e(Cl,UV),e(UV,q8o),e(Cl,D8o),e(k,j8o),e(k,cp),e(cp,I1e),e(I1e,G8o),e(cp,O8o),e(cp,HV),e(HV,V8o),e(cp,X8o),e(k,z8o),e(k,fp),e(fp,N1e),e(N1e,Q8o),e(fp,W8o),e(fp,JV),e(JV,U8o),e(fp,H8o),e(k,J8o),e(k,wl),e(wl,q1e),e(q1e,Y8o),e(wl,Z8o),e(wl,YV),e(YV,K8o),e(wl,eLo),e(wl,ZV),e(ZV,oLo),e(wl,rLo),e(k,tLo),e(k,Al),e(Al,D1e),e(D1e,aLo),e(Al,nLo),e(Al,KV),e(KV,sLo),e(Al,lLo),e(Al,eX),e(eX,iLo),e(Al,dLo),e(k,mLo),e(k,Ll),e(Ll,j1e),e(j1e,cLo),e(Ll,fLo),e(Ll,oX),e(oX,gLo),e(Ll,hLo),e(Ll,rX),e(rX,uLo),e(Ll,pLo),e(k,_Lo),e(k,gp),e(gp,G1e),e(G1e,bLo),e(gp,vLo),e(gp,tX),e(tX,FLo),e(gp,TLo),e(k,MLo),e(k,hp),e(hp,O1e),e(O1e,ELo),e(hp,CLo),e(hp,aX),e(aX,wLo),e(hp,ALo),e(k,LLo),e(k,up),e(up,V1e),e(V1e,yLo),e(up,xLo),e(up,nX),e(nX,$Lo),e(up,kLo),e(k,SLo),e(k,yl),e(yl,X1e),e(X1e,RLo),e(yl,PLo),e(yl,sX),e(sX,BLo),e(yl,ILo),e(yl,lX),e(lX,NLo),e(yl,qLo),e(k,DLo),e(k,xl),e(xl,z1e),e(z1e,jLo),e(xl,GLo),e(xl,iX),e(iX,OLo),e(xl,VLo),e(xl,dX),e(dX,XLo),e(xl,zLo),e(k,QLo),e(k,pp),e(pp,Q1e),e(Q1e,WLo),e(pp,ULo),e(pp,mX),e(mX,HLo),e(pp,JLo),e(k,YLo),e(k,_p),e(_p,W1e),e(W1e,ZLo),e(_p,KLo),e(_p,cX),e(cX,eyo),e(_p,oyo),e(k,ryo),e(k,bp),e(bp,U1e),e(U1e,tyo),e(bp,ayo),e(bp,fX),e(fX,nyo),e(bp,syo),e(k,lyo),e(k,vp),e(vp,H1e),e(H1e,iyo),e(vp,dyo),e(vp,gX),e(gX,myo),e(vp,cyo),e(k,fyo),e(k,$l),e($l,J1e),e(J1e,gyo),e($l,hyo),e($l,hX),e(hX,uyo),e($l,pyo),e($l,uX),e(uX,_yo),e($l,byo),e(k,vyo),e(k,kl),e(kl,Y1e),e(Y1e,Fyo),e(kl,Tyo),e(kl,pX),e(pX,Myo),e(kl,Eyo),e(kl,_X),e(_X,Cyo),e(kl,wyo),e(k,Ayo),e(k,Fp),e(Fp,Z1e),e(Z1e,Lyo),e(Fp,yyo),e(Fp,bX),e(bX,xyo),e(Fp,$yo),e(k,kyo),e(k,Tp),e(Tp,K1e),e(K1e,Syo),e(Tp,Ryo),e(Tp,vX),e(vX,Pyo),e(Tp,Byo),e(k,Iyo),e(k,Sl),e(Sl,e2e),e(e2e,Nyo),e(Sl,qyo),e(Sl,FX),e(FX,Dyo),e(Sl,jyo),e(Sl,TX),e(TX,Gyo),e(Sl,Oyo),e(k,Vyo),e(k,Rl),e(Rl,o2e),e(o2e,Xyo),e(Rl,zyo),e(Rl,MX),e(MX,Qyo),e(Rl,Wyo),e(Rl,EX),e(EX,Uyo),e(Rl,Hyo),e(k,Jyo),e(k,Pl),e(Pl,r2e),e(r2e,Yyo),e(Pl,Zyo),e(Pl,CX),e(CX,Kyo),e(Pl,e9o),e(Pl,wX),e(wX,o9o),e(Pl,r9o),e(k,t9o),e(k,Bl),e(Bl,t2e),e(t2e,a9o),e(Bl,n9o),e(Bl,AX),e(AX,s9o),e(Bl,l9o),e(Bl,LX),e(LX,i9o),e(Bl,d9o),e(Vr,m9o),M(Mp,Vr,null),e(Io,c9o),e(Io,Ep),M(wk,Ep,null),e(Ep,f9o),e(Ep,a2e),e(a2e,g9o),b(c,wlo,_),b(c,Nd,_),e(Nd,Cp),e(Cp,n2e),M(Ak,n2e,null),e(Nd,h9o),e(Nd,s2e),e(s2e,u9o),b(c,Alo,_),b(c,No,_),M(Lk,No,null),e(No,p9o),e(No,yk),e(yk,_9o),e(yk,yX),e(yX,b9o),e(yk,v9o),e(No,F9o),e(No,xk),e(xk,T9o),e(xk,l2e),e(l2e,M9o),e(xk,E9o),e(No,C9o),e(No,eo),M($k,eo,null),e(eo,w9o),e(eo,i2e),e(i2e,A9o),e(eo,L9o),e(eo,mn),e(mn,y9o),e(mn,d2e),e(d2e,x9o),e(mn,$9o),e(mn,m2e),e(m2e,k9o),e(mn,S9o),e(mn,c2e),e(c2e,R9o),e(mn,P9o),e(eo,B9o),e(eo,z),e(z,wp),e(wp,f2e),e(f2e,I9o),e(wp,N9o),e(wp,xX),e(xX,q9o),e(wp,D9o),e(z,j9o),e(z,Ap),e(Ap,g2e),e(g2e,G9o),e(Ap,O9o),e(Ap,$X),e($X,V9o),e(Ap,X9o),e(z,z9o),e(z,Lp),e(Lp,h2e),e(h2e,Q9o),e(Lp,W9o),e(Lp,kX),e(kX,U9o),e(Lp,H9o),e(z,J9o),e(z,yp),e(yp,u2e),e(u2e,Y9o),e(yp,Z9o),e(yp,SX),e(SX,K9o),e(yp,exo),e(z,oxo),e(z,xp),e(xp,p2e),e(p2e,rxo),e(xp,txo),e(xp,RX),e(RX,axo),e(xp,nxo),e(z,sxo),e(z,$p),e($p,_2e),e(_2e,lxo),e($p,ixo),e($p,PX),e(PX,dxo),e($p,mxo),e(z,cxo),e(z,kp),e(kp,b2e),e(b2e,fxo),e(kp,gxo),e(kp,BX),e(BX,hxo),e(kp,uxo),e(z,pxo),e(z,Sp),e(Sp,v2e),e(v2e,_xo),e(Sp,bxo),e(Sp,IX),e(IX,vxo),e(Sp,Fxo),e(z,Txo),e(z,Rp),e(Rp,F2e),e(F2e,Mxo),e(Rp,Exo),e(Rp,NX),e(NX,Cxo),e(Rp,wxo),e(z,Axo),e(z,Pp),e(Pp,T2e),e(T2e,Lxo),e(Pp,yxo),e(Pp,qX),e(qX,xxo),e(Pp,$xo),e(z,kxo),e(z,Bp),e(Bp,M2e),e(M2e,Sxo),e(Bp,Rxo),e(Bp,DX),e(DX,Pxo),e(Bp,Bxo),e(z,Ixo),e(z,Ip),e(Ip,E2e),e(E2e,Nxo),e(Ip,qxo),e(Ip,jX),e(jX,Dxo),e(Ip,jxo),e(z,Gxo),e(z,Np),e(Np,C2e),e(C2e,Oxo),e(Np,Vxo),e(Np,GX),e(GX,Xxo),e(Np,zxo),e(z,Qxo),e(z,qp),e(qp,w2e),e(w2e,Wxo),e(qp,Uxo),e(qp,OX),e(OX,Hxo),e(qp,Jxo),e(z,Yxo),e(z,Dp),e(Dp,A2e),e(A2e,Zxo),e(Dp,Kxo),e(Dp,VX),e(VX,e$o),e(Dp,o$o),e(z,r$o),e(z,jp),e(jp,L2e),e(L2e,t$o),e(jp,a$o),e(jp,XX),e(XX,n$o),e(jp,s$o),e(z,l$o),e(z,Gp),e(Gp,y2e),e(y2e,i$o),e(Gp,d$o),e(Gp,zX),e(zX,m$o),e(Gp,c$o),e(z,f$o),e(z,Op),e(Op,x2e),e(x2e,g$o),e(Op,h$o),e(Op,QX),e(QX,u$o),e(Op,p$o),e(z,_$o),e(z,Vp),e(Vp,$2e),e($2e,b$o),e(Vp,v$o),e(Vp,WX),e(WX,F$o),e(Vp,T$o),e(z,M$o),e(z,Xp),e(Xp,k2e),e(k2e,E$o),e(Xp,C$o),e(Xp,UX),e(UX,w$o),e(Xp,A$o),e(z,L$o),e(z,zp),e(zp,S2e),e(S2e,y$o),e(zp,x$o),e(zp,HX),e(HX,$$o),e(zp,k$o),e(z,S$o),e(z,Qp),e(Qp,R2e),e(R2e,R$o),e(Qp,P$o),e(Qp,JX),e(JX,B$o),e(Qp,I$o),e(z,N$o),e(z,Wp),e(Wp,P2e),e(P2e,q$o),e(Wp,D$o),e(Wp,YX),e(YX,j$o),e(Wp,G$o),e(z,O$o),e(z,Up),e(Up,B2e),e(B2e,V$o),e(Up,X$o),e(Up,ZX),e(ZX,z$o),e(Up,Q$o),e(z,W$o),e(z,Hp),e(Hp,I2e),e(I2e,U$o),e(Hp,H$o),e(Hp,KX),e(KX,J$o),e(Hp,Y$o),e(z,Z$o),e(z,Jp),e(Jp,N2e),e(N2e,K$o),e(Jp,eko),e(Jp,ez),e(ez,oko),e(Jp,rko),e(z,tko),e(z,Yp),e(Yp,q2e),e(q2e,ako),e(Yp,nko),e(Yp,oz),e(oz,sko),e(Yp,lko),e(z,iko),e(z,Zp),e(Zp,D2e),e(D2e,dko),e(Zp,mko),e(Zp,rz),e(rz,cko),e(Zp,fko),e(z,gko),e(z,Kp),e(Kp,j2e),e(j2e,hko),e(Kp,uko),e(Kp,tz),e(tz,pko),e(Kp,_ko),e(z,bko),e(z,e_),e(e_,G2e),e(G2e,vko),e(e_,Fko),e(e_,az),e(az,Tko),e(e_,Mko),e(z,Eko),e(z,o_),e(o_,O2e),e(O2e,Cko),e(o_,wko),e(o_,nz),e(nz,Ako),e(o_,Lko),e(z,yko),e(z,r_),e(r_,V2e),e(V2e,xko),e(r_,$ko),e(r_,sz),e(sz,kko),e(r_,Sko),e(z,Rko),e(z,t_),e(t_,X2e),e(X2e,Pko),e(t_,Bko),e(t_,lz),e(lz,Iko),e(t_,Nko),e(z,qko),e(z,a_),e(a_,z2e),e(z2e,Dko),e(a_,jko),e(a_,iz),e(iz,Gko),e(a_,Oko),e(z,Vko),e(z,n_),e(n_,Q2e),e(Q2e,Xko),e(n_,zko),e(n_,dz),e(dz,Qko),e(n_,Wko),e(z,Uko),e(z,s_),e(s_,W2e),e(W2e,Hko),e(s_,Jko),e(s_,mz),e(mz,Yko),e(s_,Zko),e(z,Kko),e(z,l_),e(l_,U2e),e(U2e,eSo),e(l_,oSo),e(l_,cz),e(cz,rSo),e(l_,tSo),e(z,aSo),e(z,i_),e(i_,H2e),e(H2e,nSo),e(i_,sSo),e(i_,fz),e(fz,lSo),e(i_,iSo),e(z,dSo),e(z,d_),e(d_,J2e),e(J2e,mSo),e(d_,cSo),e(d_,gz),e(gz,fSo),e(d_,gSo),e(z,hSo),e(z,m_),e(m_,Y2e),e(Y2e,uSo),e(m_,pSo),e(m_,hz),e(hz,_So),e(m_,bSo),e(z,vSo),e(z,c_),e(c_,Z2e),e(Z2e,FSo),e(c_,TSo),e(c_,uz),e(uz,MSo),e(c_,ESo),e(z,CSo),e(z,f_),e(f_,K2e),e(K2e,wSo),e(f_,ASo),e(f_,pz),e(pz,LSo),e(f_,ySo),e(z,xSo),e(z,g_),e(g_,ebe),e(ebe,$So),e(g_,kSo),e(g_,_z),e(_z,SSo),e(g_,RSo),e(z,PSo),e(z,h_),e(h_,obe),e(obe,BSo),e(h_,ISo),e(h_,bz),e(bz,NSo),e(h_,qSo),e(z,DSo),e(z,u_),e(u_,rbe),e(rbe,jSo),e(u_,GSo),e(u_,vz),e(vz,OSo),e(u_,VSo),e(eo,XSo),M(p_,eo,null),e(eo,zSo),M(__,eo,null),e(No,QSo),e(No,b_),M(kk,b_,null),e(b_,WSo),e(b_,tbe),e(tbe,USo),b(c,Llo,_),b(c,qd,_),e(qd,v_),e(v_,abe),M(Sk,abe,null),e(qd,HSo),e(qd,nbe),e(nbe,JSo),b(c,ylo,_),b(c,qo,_),M(Rk,qo,null),e(qo,YSo),e(qo,Pk),e(Pk,ZSo),e(Pk,Fz),e(Fz,KSo),e(Pk,eRo),e(qo,oRo),e(qo,Bk),e(Bk,rRo),e(Bk,sbe),e(sbe,tRo),e(Bk,aRo),e(qo,nRo),e(qo,oo),M(Ik,oo,null),e(oo,sRo),e(oo,lbe),e(lbe,lRo),e(oo,iRo),e(oo,cn),e(cn,dRo),e(cn,ibe),e(ibe,mRo),e(cn,cRo),e(cn,dbe),e(dbe,fRo),e(cn,gRo),e(cn,mbe),e(mbe,hRo),e(cn,uRo),e(oo,pRo),e(oo,re),e(re,F_),e(F_,cbe),e(cbe,_Ro),e(F_,bRo),e(F_,Tz),e(Tz,vRo),e(F_,FRo),e(re,TRo),e(re,T_),e(T_,fbe),e(fbe,MRo),e(T_,ERo),e(T_,Mz),e(Mz,CRo),e(T_,wRo),e(re,ARo),e(re,M_),e(M_,gbe),e(gbe,LRo),e(M_,yRo),e(M_,Ez),e(Ez,xRo),e(M_,$Ro),e(re,kRo),e(re,E_),e(E_,hbe),e(hbe,SRo),e(E_,RRo),e(E_,Cz),e(Cz,PRo),e(E_,BRo),e(re,IRo),e(re,C_),e(C_,ube),e(ube,NRo),e(C_,qRo),e(C_,wz),e(wz,DRo),e(C_,jRo),e(re,GRo),e(re,w_),e(w_,pbe),e(pbe,ORo),e(w_,VRo),e(w_,Az),e(Az,XRo),e(w_,zRo),e(re,QRo),e(re,A_),e(A_,_be),e(_be,WRo),e(A_,URo),e(A_,Lz),e(Lz,HRo),e(A_,JRo),e(re,YRo),e(re,L_),e(L_,bbe),e(bbe,ZRo),e(L_,KRo),e(L_,yz),e(yz,ePo),e(L_,oPo),e(re,rPo),e(re,y_),e(y_,vbe),e(vbe,tPo),e(y_,aPo),e(y_,xz),e(xz,nPo),e(y_,sPo),e(re,lPo),e(re,x_),e(x_,Fbe),e(Fbe,iPo),e(x_,dPo),e(x_,$z),e($z,mPo),e(x_,cPo),e(re,fPo),e(re,$_),e($_,Tbe),e(Tbe,gPo),e($_,hPo),e($_,kz),e(kz,uPo),e($_,pPo),e(re,_Po),e(re,k_),e(k_,Mbe),e(Mbe,bPo),e(k_,vPo),e(k_,Sz),e(Sz,FPo),e(k_,TPo),e(re,MPo),e(re,S_),e(S_,Ebe),e(Ebe,EPo),e(S_,CPo),e(S_,Rz),e(Rz,wPo),e(S_,APo),e(re,LPo),e(re,R_),e(R_,Cbe),e(Cbe,yPo),e(R_,xPo),e(R_,Pz),e(Pz,$Po),e(R_,kPo),e(re,SPo),e(re,P_),e(P_,wbe),e(wbe,RPo),e(P_,PPo),e(P_,Bz),e(Bz,BPo),e(P_,IPo),e(re,NPo),e(re,B_),e(B_,Abe),e(Abe,qPo),e(B_,DPo),e(B_,Iz),e(Iz,jPo),e(B_,GPo),e(re,OPo),e(re,I_),e(I_,Lbe),e(Lbe,VPo),e(I_,XPo),e(I_,Nz),e(Nz,zPo),e(I_,QPo),e(re,WPo),e(re,N_),e(N_,ybe),e(ybe,UPo),e(N_,HPo),e(N_,qz),e(qz,JPo),e(N_,YPo),e(re,ZPo),e(re,q_),e(q_,xbe),e(xbe,KPo),e(q_,eBo),e(q_,Dz),e(Dz,oBo),e(q_,rBo),e(re,tBo),e(re,D_),e(D_,$be),e($be,aBo),e(D_,nBo),e(D_,jz),e(jz,sBo),e(D_,lBo),e(re,iBo),e(re,j_),e(j_,kbe),e(kbe,dBo),e(j_,mBo),e(j_,Gz),e(Gz,cBo),e(j_,fBo),e(re,gBo),e(re,G_),e(G_,Sbe),e(Sbe,hBo),e(G_,uBo),e(G_,Oz),e(Oz,pBo),e(G_,_Bo),e(re,bBo),e(re,O_),e(O_,Rbe),e(Rbe,vBo),e(O_,FBo),e(O_,Vz),e(Vz,TBo),e(O_,MBo),e(re,EBo),e(re,V_),e(V_,Pbe),e(Pbe,CBo),e(V_,wBo),e(V_,Xz),e(Xz,ABo),e(V_,LBo),e(re,yBo),e(re,X_),e(X_,Bbe),e(Bbe,xBo),e(X_,$Bo),e(X_,zz),e(zz,kBo),e(X_,SBo),e(re,RBo),e(re,z_),e(z_,Ibe),e(Ibe,PBo),e(z_,BBo),e(z_,Qz),e(Qz,IBo),e(z_,NBo),e(re,qBo),e(re,Q_),e(Q_,Nbe),e(Nbe,DBo),e(Q_,jBo),e(Q_,Wz),e(Wz,GBo),e(Q_,OBo),e(re,VBo),e(re,W_),e(W_,qbe),e(qbe,XBo),e(W_,zBo),e(W_,Uz),e(Uz,QBo),e(W_,WBo),e(re,UBo),e(re,U_),e(U_,Dbe),e(Dbe,HBo),e(U_,JBo),e(U_,Hz),e(Hz,YBo),e(U_,ZBo),e(oo,KBo),M(H_,oo,null),e(oo,eIo),M(J_,oo,null),e(qo,oIo),e(qo,Y_),M(Nk,Y_,null),e(Y_,rIo),e(Y_,jbe),e(jbe,tIo),b(c,xlo,_),b(c,Dd,_),e(Dd,Z_),e(Z_,Gbe),M(qk,Gbe,null),e(Dd,aIo),e(Dd,Obe),e(Obe,nIo),b(c,$lo,_),b(c,Do,_),M(Dk,Do,null),e(Do,sIo),e(Do,jk),e(jk,lIo),e(jk,Jz),e(Jz,iIo),e(jk,dIo),e(Do,mIo),e(Do,Gk),e(Gk,cIo),e(Gk,Vbe),e(Vbe,fIo),e(Gk,gIo),e(Do,hIo),e(Do,ro),M(Ok,ro,null),e(ro,uIo),e(ro,Xbe),e(Xbe,pIo),e(ro,_Io),e(ro,jd),e(jd,bIo),e(jd,zbe),e(zbe,vIo),e(jd,FIo),e(jd,Qbe),e(Qbe,TIo),e(jd,MIo),e(ro,EIo),e(ro,ie),e(ie,K_),e(K_,Wbe),e(Wbe,CIo),e(K_,wIo),e(K_,Yz),e(Yz,AIo),e(K_,LIo),e(ie,yIo),e(ie,e1),e(e1,Ube),e(Ube,xIo),e(e1,$Io),e(e1,Zz),e(Zz,kIo),e(e1,SIo),e(ie,RIo),e(ie,o1),e(o1,Hbe),e(Hbe,PIo),e(o1,BIo),e(o1,Kz),e(Kz,IIo),e(o1,NIo),e(ie,qIo),e(ie,r1),e(r1,Jbe),e(Jbe,DIo),e(r1,jIo),e(r1,eQ),e(eQ,GIo),e(r1,OIo),e(ie,VIo),e(ie,t1),e(t1,Ybe),e(Ybe,XIo),e(t1,zIo),e(t1,oQ),e(oQ,QIo),e(t1,WIo),e(ie,UIo),e(ie,a1),e(a1,Zbe),e(Zbe,HIo),e(a1,JIo),e(a1,rQ),e(rQ,YIo),e(a1,ZIo),e(ie,KIo),e(ie,n1),e(n1,Kbe),e(Kbe,eNo),e(n1,oNo),e(n1,tQ),e(tQ,rNo),e(n1,tNo),e(ie,aNo),e(ie,s1),e(s1,eve),e(eve,nNo),e(s1,sNo),e(s1,aQ),e(aQ,lNo),e(s1,iNo),e(ie,dNo),e(ie,l1),e(l1,ove),e(ove,mNo),e(l1,cNo),e(l1,nQ),e(nQ,fNo),e(l1,gNo),e(ie,hNo),e(ie,i1),e(i1,rve),e(rve,uNo),e(i1,pNo),e(i1,sQ),e(sQ,_No),e(i1,bNo),e(ie,vNo),e(ie,d1),e(d1,tve),e(tve,FNo),e(d1,TNo),e(d1,lQ),e(lQ,MNo),e(d1,ENo),e(ie,CNo),e(ie,m1),e(m1,ave),e(ave,wNo),e(m1,ANo),e(m1,iQ),e(iQ,LNo),e(m1,yNo),e(ie,xNo),e(ie,c1),e(c1,nve),e(nve,$No),e(c1,kNo),e(c1,dQ),e(dQ,SNo),e(c1,RNo),e(ie,PNo),e(ie,f1),e(f1,sve),e(sve,BNo),e(f1,INo),e(f1,mQ),e(mQ,NNo),e(f1,qNo),e(ie,DNo),e(ie,g1),e(g1,lve),e(lve,jNo),e(g1,GNo),e(g1,cQ),e(cQ,ONo),e(g1,VNo),e(ie,XNo),e(ie,h1),e(h1,ive),e(ive,zNo),e(h1,QNo),e(h1,fQ),e(fQ,WNo),e(h1,UNo),e(ie,HNo),e(ie,u1),e(u1,dve),e(dve,JNo),e(u1,YNo),e(u1,gQ),e(gQ,ZNo),e(u1,KNo),e(ie,eqo),e(ie,p1),e(p1,mve),e(mve,oqo),e(p1,rqo),e(p1,hQ),e(hQ,tqo),e(p1,aqo),e(ie,nqo),e(ie,_1),e(_1,cve),e(cve,sqo),e(_1,lqo),e(_1,uQ),e(uQ,iqo),e(_1,dqo),e(ie,mqo),e(ie,b1),e(b1,fve),e(fve,cqo),e(b1,fqo),e(b1,pQ),e(pQ,gqo),e(b1,hqo),e(ie,uqo),e(ie,v1),e(v1,gve),e(gve,pqo),e(v1,_qo),e(v1,_Q),e(_Q,bqo),e(v1,vqo),e(ie,Fqo),e(ie,F1),e(F1,hve),e(hve,Tqo),e(F1,Mqo),e(F1,bQ),e(bQ,Eqo),e(F1,Cqo),e(ie,wqo),e(ie,T1),e(T1,uve),e(uve,Aqo),e(T1,Lqo),e(T1,vQ),e(vQ,yqo),e(T1,xqo),e(ro,$qo),M(M1,ro,null),e(ro,kqo),M(E1,ro,null),e(Do,Sqo),e(Do,C1),M(Vk,C1,null),e(C1,Rqo),e(C1,pve),e(pve,Pqo),b(c,klo,_),b(c,Gd,_),e(Gd,w1),e(w1,_ve),M(Xk,_ve,null),e(Gd,Bqo),e(Gd,bve),e(bve,Iqo),b(c,Slo,_),b(c,jo,_),M(zk,jo,null),e(jo,Nqo),e(jo,Od),e(Od,qqo),e(Od,FQ),e(FQ,Dqo),e(Od,jqo),e(Od,TQ),e(TQ,Gqo),e(Od,Oqo),e(jo,Vqo),e(jo,Qk),e(Qk,Xqo),e(Qk,vve),e(vve,zqo),e(Qk,Qqo),e(jo,Wqo),e(jo,At),M(Wk,At,null),e(At,Uqo),e(At,Fve),e(Fve,Hqo),e(At,Jqo),e(At,Vd),e(Vd,Yqo),e(Vd,Tve),e(Tve,Zqo),e(Vd,Kqo),e(Vd,MQ),e(MQ,eDo),e(Vd,oDo),e(At,rDo),M(A1,At,null),e(jo,tDo),e(jo,to),M(Uk,to,null),e(to,aDo),e(to,Mve),e(Mve,nDo),e(to,sDo),e(to,fn),e(fn,lDo),e(fn,Eve),e(Eve,iDo),e(fn,dDo),e(fn,Cve),e(Cve,mDo),e(fn,cDo),e(fn,wve),e(wve,fDo),e(fn,gDo),e(to,hDo),e(to,y),e(y,L1),e(L1,Ave),e(Ave,uDo),e(L1,pDo),e(L1,EQ),e(EQ,_Do),e(L1,bDo),e(y,vDo),e(y,y1),e(y1,Lve),e(Lve,FDo),e(y1,TDo),e(y1,CQ),e(CQ,MDo),e(y1,EDo),e(y,CDo),e(y,x1),e(x1,yve),e(yve,wDo),e(x1,ADo),e(x1,wQ),e(wQ,LDo),e(x1,yDo),e(y,xDo),e(y,$1),e($1,xve),e(xve,$Do),e($1,kDo),e($1,AQ),e(AQ,SDo),e($1,RDo),e(y,PDo),e(y,k1),e(k1,$ve),e($ve,BDo),e(k1,IDo),e(k1,LQ),e(LQ,NDo),e(k1,qDo),e(y,DDo),e(y,S1),e(S1,kve),e(kve,jDo),e(S1,GDo),e(S1,yQ),e(yQ,ODo),e(S1,VDo),e(y,XDo),e(y,R1),e(R1,Sve),e(Sve,zDo),e(R1,QDo),e(R1,xQ),e(xQ,WDo),e(R1,UDo),e(y,HDo),e(y,P1),e(P1,Rve),e(Rve,JDo),e(P1,YDo),e(P1,$Q),e($Q,ZDo),e(P1,KDo),e(y,ejo),e(y,B1),e(B1,Pve),e(Pve,ojo),e(B1,rjo),e(B1,kQ),e(kQ,tjo),e(B1,ajo),e(y,njo),e(y,I1),e(I1,Bve),e(Bve,sjo),e(I1,ljo),e(I1,SQ),e(SQ,ijo),e(I1,djo),e(y,mjo),e(y,N1),e(N1,Ive),e(Ive,cjo),e(N1,fjo),e(N1,RQ),e(RQ,gjo),e(N1,hjo),e(y,ujo),e(y,q1),e(q1,Nve),e(Nve,pjo),e(q1,_jo),e(q1,PQ),e(PQ,bjo),e(q1,vjo),e(y,Fjo),e(y,D1),e(D1,qve),e(qve,Tjo),e(D1,Mjo),e(D1,BQ),e(BQ,Ejo),e(D1,Cjo),e(y,wjo),e(y,j1),e(j1,Dve),e(Dve,Ajo),e(j1,Ljo),e(j1,IQ),e(IQ,yjo),e(j1,xjo),e(y,$jo),e(y,G1),e(G1,jve),e(jve,kjo),e(G1,Sjo),e(G1,NQ),e(NQ,Rjo),e(G1,Pjo),e(y,Bjo),e(y,O1),e(O1,Gve),e(Gve,Ijo),e(O1,Njo),e(O1,qQ),e(qQ,qjo),e(O1,Djo),e(y,jjo),e(y,V1),e(V1,Ove),e(Ove,Gjo),e(V1,Ojo),e(V1,DQ),e(DQ,Vjo),e(V1,Xjo),e(y,zjo),e(y,X1),e(X1,Vve),e(Vve,Qjo),e(X1,Wjo),e(X1,jQ),e(jQ,Ujo),e(X1,Hjo),e(y,Jjo),e(y,z1),e(z1,Xve),e(Xve,Yjo),e(z1,Zjo),e(z1,GQ),e(GQ,Kjo),e(z1,eGo),e(y,oGo),e(y,Q1),e(Q1,zve),e(zve,rGo),e(Q1,tGo),e(Q1,OQ),e(OQ,aGo),e(Q1,nGo),e(y,sGo),e(y,W1),e(W1,Qve),e(Qve,lGo),e(W1,iGo),e(W1,VQ),e(VQ,dGo),e(W1,mGo),e(y,cGo),e(y,U1),e(U1,Wve),e(Wve,fGo),e(U1,gGo),e(U1,XQ),e(XQ,hGo),e(U1,uGo),e(y,pGo),e(y,H1),e(H1,Uve),e(Uve,_Go),e(H1,bGo),e(H1,zQ),e(zQ,vGo),e(H1,FGo),e(y,TGo),e(y,J1),e(J1,Hve),e(Hve,MGo),e(J1,EGo),e(J1,QQ),e(QQ,CGo),e(J1,wGo),e(y,AGo),e(y,Y1),e(Y1,Jve),e(Jve,LGo),e(Y1,yGo),e(Y1,WQ),e(WQ,xGo),e(Y1,$Go),e(y,kGo),e(y,Z1),e(Z1,Yve),e(Yve,SGo),e(Z1,RGo),e(Z1,UQ),e(UQ,PGo),e(Z1,BGo),e(y,IGo),e(y,K1),e(K1,Zve),e(Zve,NGo),e(K1,qGo),e(K1,HQ),e(HQ,DGo),e(K1,jGo),e(y,GGo),e(y,e2),e(e2,Kve),e(Kve,OGo),e(e2,VGo),e(e2,JQ),e(JQ,XGo),e(e2,zGo),e(y,QGo),e(y,o2),e(o2,eFe),e(eFe,WGo),e(o2,UGo),e(o2,YQ),e(YQ,HGo),e(o2,JGo),e(y,YGo),e(y,r2),e(r2,oFe),e(oFe,ZGo),e(r2,KGo),e(r2,ZQ),e(ZQ,eOo),e(r2,oOo),e(y,rOo),e(y,t2),e(t2,rFe),e(rFe,tOo),e(t2,aOo),e(t2,KQ),e(KQ,nOo),e(t2,sOo),e(y,lOo),e(y,a2),e(a2,tFe),e(tFe,iOo),e(a2,dOo),e(a2,eW),e(eW,mOo),e(a2,cOo),e(y,fOo),e(y,n2),e(n2,aFe),e(aFe,gOo),e(n2,hOo),e(n2,oW),e(oW,uOo),e(n2,pOo),e(y,_Oo),e(y,s2),e(s2,nFe),e(nFe,bOo),e(s2,vOo),e(s2,rW),e(rW,FOo),e(s2,TOo),e(y,MOo),e(y,l2),e(l2,sFe),e(sFe,EOo),e(l2,COo),e(l2,tW),e(tW,wOo),e(l2,AOo),e(y,LOo),e(y,i2),e(i2,lFe),e(lFe,yOo),e(i2,xOo),e(i2,aW),e(aW,$Oo),e(i2,kOo),e(y,SOo),e(y,d2),e(d2,iFe),e(iFe,ROo),e(d2,POo),e(d2,nW),e(nW,BOo),e(d2,IOo),e(y,NOo),e(y,m2),e(m2,dFe),e(dFe,qOo),e(m2,DOo),e(m2,sW),e(sW,jOo),e(m2,GOo),e(y,OOo),e(y,c2),e(c2,mFe),e(mFe,VOo),e(c2,XOo),e(c2,lW),e(lW,zOo),e(c2,QOo),e(y,WOo),e(y,f2),e(f2,cFe),e(cFe,UOo),e(f2,HOo),e(f2,iW),e(iW,JOo),e(f2,YOo),e(y,ZOo),e(y,Il),e(Il,fFe),e(fFe,KOo),e(Il,eVo),e(Il,dW),e(dW,oVo),e(Il,rVo),e(Il,mW),e(mW,tVo),e(Il,aVo),e(y,nVo),e(y,g2),e(g2,gFe),e(gFe,sVo),e(g2,lVo),e(g2,cW),e(cW,iVo),e(g2,dVo),e(y,mVo),e(y,h2),e(h2,hFe),e(hFe,cVo),e(h2,fVo),e(h2,fW),e(fW,gVo),e(h2,hVo),e(y,uVo),e(y,u2),e(u2,uFe),e(uFe,pVo),e(u2,_Vo),e(u2,gW),e(gW,bVo),e(u2,vVo),e(y,FVo),e(y,p2),e(p2,pFe),e(pFe,TVo),e(p2,MVo),e(p2,hW),e(hW,EVo),e(p2,CVo),e(y,wVo),e(y,_2),e(_2,_Fe),e(_Fe,AVo),e(_2,LVo),e(_2,uW),e(uW,yVo),e(_2,xVo),e(y,$Vo),e(y,b2),e(b2,bFe),e(bFe,kVo),e(b2,SVo),e(b2,pW),e(pW,RVo),e(b2,PVo),e(y,BVo),e(y,v2),e(v2,vFe),e(vFe,IVo),e(v2,NVo),e(v2,_W),e(_W,qVo),e(v2,DVo),e(y,jVo),e(y,F2),e(F2,FFe),e(FFe,GVo),e(F2,OVo),e(F2,bW),e(bW,VVo),e(F2,XVo),e(y,zVo),e(y,T2),e(T2,TFe),e(TFe,QVo),e(T2,WVo),e(T2,vW),e(vW,UVo),e(T2,HVo),e(y,JVo),e(y,M2),e(M2,MFe),e(MFe,YVo),e(M2,ZVo),e(M2,FW),e(FW,KVo),e(M2,eXo),e(y,oXo),e(y,E2),e(E2,EFe),e(EFe,rXo),e(E2,tXo),e(E2,TW),e(TW,aXo),e(E2,nXo),e(y,sXo),e(y,C2),e(C2,CFe),e(CFe,lXo),e(C2,iXo),e(C2,MW),e(MW,dXo),e(C2,mXo),e(y,cXo),e(y,w2),e(w2,wFe),e(wFe,fXo),e(w2,gXo),e(w2,EW),e(EW,hXo),e(w2,uXo),e(y,pXo),e(y,A2),e(A2,AFe),e(AFe,_Xo),e(A2,bXo),e(A2,CW),e(CW,vXo),e(A2,FXo),e(y,TXo),e(y,L2),e(L2,LFe),e(LFe,MXo),e(L2,EXo),e(L2,wW),e(wW,CXo),e(L2,wXo),e(y,AXo),e(y,y2),e(y2,yFe),e(yFe,LXo),e(y2,yXo),e(y2,AW),e(AW,xXo),e(y2,$Xo),e(y,kXo),e(y,x2),e(x2,xFe),e(xFe,SXo),e(x2,RXo),e(x2,LW),e(LW,PXo),e(x2,BXo),e(y,IXo),e(y,$2),e($2,$Fe),e($Fe,NXo),e($2,qXo),e($2,yW),e(yW,DXo),e($2,jXo),e(y,GXo),e(y,k2),e(k2,kFe),e(kFe,OXo),e(k2,VXo),e(k2,xW),e(xW,XXo),e(k2,zXo),e(y,QXo),e(y,S2),e(S2,SFe),e(SFe,WXo),e(S2,UXo),e(S2,$W),e($W,HXo),e(S2,JXo),e(y,YXo),e(y,R2),e(R2,RFe),e(RFe,ZXo),e(R2,KXo),e(R2,kW),e(kW,ezo),e(R2,ozo),e(y,rzo),e(y,P2),e(P2,PFe),e(PFe,tzo),e(P2,azo),e(P2,SW),e(SW,nzo),e(P2,szo),e(y,lzo),e(y,B2),e(B2,BFe),e(BFe,izo),e(B2,dzo),e(B2,RW),e(RW,mzo),e(B2,czo),e(y,fzo),e(y,I2),e(I2,IFe),e(IFe,gzo),e(I2,hzo),e(I2,PW),e(PW,uzo),e(I2,pzo),e(y,_zo),e(y,N2),e(N2,NFe),e(NFe,bzo),e(N2,vzo),e(N2,BW),e(BW,Fzo),e(N2,Tzo),e(y,Mzo),e(y,q2),e(q2,qFe),e(qFe,Ezo),e(q2,Czo),e(q2,IW),e(IW,wzo),e(q2,Azo),e(y,Lzo),e(y,D2),e(D2,DFe),e(DFe,yzo),e(D2,xzo),e(D2,NW),e(NW,$zo),e(D2,kzo),e(y,Szo),e(y,j2),e(j2,jFe),e(jFe,Rzo),e(j2,Pzo),e(j2,qW),e(qW,Bzo),e(j2,Izo),e(y,Nzo),e(y,G2),e(G2,GFe),e(GFe,qzo),e(G2,Dzo),e(G2,DW),e(DW,jzo),e(G2,Gzo),e(y,Ozo),e(y,O2),e(O2,OFe),e(OFe,Vzo),e(O2,Xzo),e(O2,jW),e(jW,zzo),e(O2,Qzo),e(y,Wzo),e(y,V2),e(V2,VFe),e(VFe,Uzo),e(V2,Hzo),e(V2,GW),e(GW,Jzo),e(V2,Yzo),e(y,Zzo),e(y,X2),e(X2,XFe),e(XFe,Kzo),e(X2,eQo),e(X2,OW),e(OW,oQo),e(X2,rQo),e(y,tQo),e(y,z2),e(z2,zFe),e(zFe,aQo),e(z2,nQo),e(z2,VW),e(VW,sQo),e(z2,lQo),e(y,iQo),e(y,Q2),e(Q2,QFe),e(QFe,dQo),e(Q2,mQo),e(Q2,XW),e(XW,cQo),e(Q2,fQo),e(y,gQo),e(y,W2),e(W2,WFe),e(WFe,hQo),e(W2,uQo),e(W2,zW),e(zW,pQo),e(W2,_Qo),e(y,bQo),e(y,U2),e(U2,UFe),e(UFe,vQo),e(U2,FQo),e(U2,QW),e(QW,TQo),e(U2,MQo),e(y,EQo),e(y,H2),e(H2,HFe),e(HFe,CQo),e(H2,wQo),e(H2,WW),e(WW,AQo),e(H2,LQo),e(y,yQo),e(y,J2),e(J2,JFe),e(JFe,xQo),e(J2,$Qo),e(J2,UW),e(UW,kQo),e(J2,SQo),e(y,RQo),e(y,Y2),e(Y2,YFe),e(YFe,PQo),e(Y2,BQo),e(Y2,HW),e(HW,IQo),e(Y2,NQo),e(y,qQo),e(y,Z2),e(Z2,ZFe),e(ZFe,DQo),e(Z2,jQo),e(Z2,JW),e(JW,GQo),e(Z2,OQo),e(y,VQo),e(y,K2),e(K2,KFe),e(KFe,XQo),e(K2,zQo),e(K2,YW),e(YW,QQo),e(K2,WQo),e(y,UQo),e(y,eb),e(eb,eTe),e(eTe,HQo),e(eb,JQo),e(eb,ZW),e(ZW,YQo),e(eb,ZQo),e(y,KQo),e(y,ob),e(ob,oTe),e(oTe,eWo),e(ob,oWo),e(ob,KW),e(KW,rWo),e(ob,tWo),e(y,aWo),e(y,rb),e(rb,rTe),e(rTe,nWo),e(rb,sWo),e(rb,eU),e(eU,lWo),e(rb,iWo),e(y,dWo),e(y,tb),e(tb,tTe),e(tTe,mWo),e(tb,cWo),e(tb,oU),e(oU,fWo),e(tb,gWo),e(y,hWo),e(y,ab),e(ab,aTe),e(aTe,uWo),e(ab,pWo),e(ab,rU),e(rU,_Wo),e(ab,bWo),e(y,vWo),e(y,nb),e(nb,nTe),e(nTe,FWo),e(nb,TWo),e(nb,tU),e(tU,MWo),e(nb,EWo),e(y,CWo),e(y,sb),e(sb,sTe),e(sTe,wWo),e(sb,AWo),e(sb,aU),e(aU,LWo),e(sb,yWo),e(y,xWo),e(y,lb),e(lb,lTe),e(lTe,$Wo),e(lb,kWo),e(lb,nU),e(nU,SWo),e(lb,RWo),e(y,PWo),e(y,ib),e(ib,iTe),e(iTe,BWo),e(ib,IWo),e(ib,sU),e(sU,NWo),e(ib,qWo),e(y,DWo),e(y,db),e(db,dTe),e(dTe,jWo),e(db,GWo),e(db,lU),e(lU,OWo),e(db,VWo),e(y,XWo),e(y,mb),e(mb,mTe),e(mTe,zWo),e(mb,QWo),e(mb,iU),e(iU,WWo),e(mb,UWo),e(y,HWo),e(y,cb),e(cb,cTe),e(cTe,JWo),e(cb,YWo),e(cb,dU),e(dU,ZWo),e(cb,KWo),e(y,eUo),e(y,fb),e(fb,fTe),e(fTe,oUo),e(fb,rUo),e(fb,mU),e(mU,tUo),e(fb,aUo),e(y,nUo),e(y,gb),e(gb,gTe),e(gTe,sUo),e(gb,lUo),e(gb,cU),e(cU,iUo),e(gb,dUo),e(y,mUo),e(y,hb),e(hb,hTe),e(hTe,cUo),e(hb,fUo),e(hb,fU),e(fU,gUo),e(hb,hUo),e(y,uUo),e(y,ub),e(ub,uTe),e(uTe,pUo),e(ub,_Uo),e(ub,gU),e(gU,bUo),e(ub,vUo),e(y,FUo),e(y,pb),e(pb,pTe),e(pTe,TUo),e(pb,MUo),e(pb,hU),e(hU,EUo),e(pb,CUo),e(y,wUo),e(y,_b),e(_b,_Te),e(_Te,AUo),e(_b,LUo),e(_b,uU),e(uU,yUo),e(_b,xUo),e(y,$Uo),e(y,bb),e(bb,bTe),e(bTe,kUo),e(bb,SUo),e(bb,pU),e(pU,RUo),e(bb,PUo),e(y,BUo),e(y,vb),e(vb,vTe),e(vTe,IUo),e(vb,NUo),e(vb,_U),e(_U,qUo),e(vb,DUo),e(y,jUo),e(y,Fb),e(Fb,FTe),e(FTe,GUo),e(Fb,OUo),e(Fb,bU),e(bU,VUo),e(Fb,XUo),e(y,zUo),e(y,Tb),e(Tb,TTe),e(TTe,QUo),e(Tb,WUo),e(Tb,vU),e(vU,UUo),e(Tb,HUo),e(y,JUo),e(y,Mb),e(Mb,MTe),e(MTe,YUo),e(Mb,ZUo),e(Mb,FU),e(FU,KUo),e(Mb,eHo),e(y,oHo),e(y,Eb),e(Eb,ETe),e(ETe,rHo),e(Eb,tHo),e(Eb,TU),e(TU,aHo),e(Eb,nHo),e(y,sHo),e(y,Cb),e(Cb,CTe),e(CTe,lHo),e(Cb,iHo),e(Cb,MU),e(MU,dHo),e(Cb,mHo),e(y,cHo),e(y,wb),e(wb,wTe),e(wTe,fHo),e(wb,gHo),e(wb,EU),e(EU,hHo),e(wb,uHo),e(y,pHo),e(y,Ab),e(Ab,ATe),e(ATe,_Ho),e(Ab,bHo),e(Ab,CU),e(CU,vHo),e(Ab,FHo),e(y,THo),e(y,Lb),e(Lb,LTe),e(LTe,MHo),e(Lb,EHo),e(Lb,wU),e(wU,CHo),e(Lb,wHo),e(y,AHo),e(y,yb),e(yb,yTe),e(yTe,LHo),e(yb,yHo),e(yb,AU),e(AU,xHo),e(yb,$Ho),e(y,kHo),e(y,xb),e(xb,xTe),e(xTe,SHo),e(xb,RHo),e(xb,LU),e(LU,PHo),e(xb,BHo),e(y,IHo),e(y,$b),e($b,$Te),e($Te,NHo),e($b,qHo),e($b,yU),e(yU,DHo),e($b,jHo),e(y,GHo),e(y,kb),e(kb,kTe),e(kTe,OHo),e(kb,VHo),e(kb,xU),e(xU,XHo),e(kb,zHo),e(y,QHo),e(y,Sb),e(Sb,STe),e(STe,WHo),e(Sb,UHo),e(Sb,$U),e($U,HHo),e(Sb,JHo),e(y,YHo),e(y,Rb),e(Rb,RTe),e(RTe,ZHo),e(Rb,KHo),e(Rb,kU),e(kU,eJo),e(Rb,oJo),e(y,rJo),e(y,Pb),e(Pb,PTe),e(PTe,tJo),e(Pb,aJo),e(Pb,SU),e(SU,nJo),e(Pb,sJo),e(y,lJo),e(y,Bb),e(Bb,BTe),e(BTe,iJo),e(Bb,dJo),e(Bb,RU),e(RU,mJo),e(Bb,cJo),e(y,fJo),e(y,Ib),e(Ib,ITe),e(ITe,gJo),e(Ib,hJo),e(Ib,PU),e(PU,uJo),e(Ib,pJo),e(y,_Jo),e(y,Nb),e(Nb,NTe),e(NTe,bJo),e(Nb,vJo),e(Nb,BU),e(BU,FJo),e(Nb,TJo),e(y,MJo),e(y,qb),e(qb,qTe),e(qTe,EJo),e(qb,CJo),e(qb,IU),e(IU,wJo),e(qb,AJo),e(y,LJo),e(y,Db),e(Db,DTe),e(DTe,yJo),e(Db,xJo),e(Db,NU),e(NU,$Jo),e(Db,kJo),e(y,SJo),e(y,jb),e(jb,jTe),e(jTe,RJo),e(jb,PJo),e(jb,qU),e(qU,BJo),e(jb,IJo),e(y,NJo),e(y,Gb),e(Gb,GTe),e(GTe,qJo),e(Gb,DJo),e(Gb,DU),e(DU,jJo),e(Gb,GJo),e(y,OJo),e(y,Ob),e(Ob,OTe),e(OTe,VJo),e(Ob,XJo),e(Ob,jU),e(jU,zJo),e(Ob,QJo),e(y,WJo),e(y,Vb),e(Vb,VTe),e(VTe,UJo),e(Vb,HJo),e(Vb,GU),e(GU,JJo),e(Vb,YJo),e(y,ZJo),e(y,Xb),e(Xb,XTe),e(XTe,KJo),e(Xb,eYo),e(Xb,OU),e(OU,oYo),e(Xb,rYo),e(y,tYo),e(y,zb),e(zb,zTe),e(zTe,aYo),e(zb,nYo),e(zb,VU),e(VU,sYo),e(zb,lYo),e(y,iYo),e(y,Qb),e(Qb,QTe),e(QTe,dYo),e(Qb,mYo),e(Qb,XU),e(XU,cYo),e(Qb,fYo),e(y,gYo),e(y,Wb),e(Wb,WTe),e(WTe,hYo),e(Wb,uYo),e(Wb,zU),e(zU,pYo),e(Wb,_Yo),e(y,bYo),e(y,Ub),e(Ub,UTe),e(UTe,vYo),e(Ub,FYo),e(Ub,QU),e(QU,TYo),e(Ub,MYo),e(to,EYo),e(to,Hb),e(Hb,CYo),e(Hb,HTe),e(HTe,wYo),e(Hb,AYo),e(Hb,JTe),e(JTe,LYo),e(to,yYo),M(Jb,to,null),b(c,Rlo,_),b(c,Xd,_),e(Xd,Yb),e(Yb,YTe),M(Hk,YTe,null),e(Xd,xYo),e(Xd,ZTe),e(ZTe,$Yo),b(c,Plo,_),b(c,Go,_),M(Jk,Go,null),e(Go,kYo),e(Go,zd),e(zd,SYo),e(zd,WU),e(WU,RYo),e(zd,PYo),e(zd,UU),e(UU,BYo),e(zd,IYo),e(Go,NYo),e(Go,Yk),e(Yk,qYo),e(Yk,KTe),e(KTe,DYo),e(Yk,jYo),e(Go,GYo),e(Go,Lt),M(Zk,Lt,null),e(Lt,OYo),e(Lt,eMe),e(eMe,VYo),e(Lt,XYo),e(Lt,Qd),e(Qd,zYo),e(Qd,oMe),e(oMe,QYo),e(Qd,WYo),e(Qd,HU),e(HU,UYo),e(Qd,HYo),e(Lt,JYo),M(Zb,Lt,null),e(Go,YYo),e(Go,ao),M(Kk,ao,null),e(ao,ZYo),e(ao,rMe),e(rMe,KYo),e(ao,eZo),e(ao,gn),e(gn,oZo),e(gn,tMe),e(tMe,rZo),e(gn,tZo),e(gn,aMe),e(aMe,aZo),e(gn,nZo),e(gn,nMe),e(nMe,sZo),e(gn,lZo),e(ao,iZo),e(ao,G),e(G,Kb),e(Kb,sMe),e(sMe,dZo),e(Kb,mZo),e(Kb,JU),e(JU,cZo),e(Kb,fZo),e(G,gZo),e(G,ev),e(ev,lMe),e(lMe,hZo),e(ev,uZo),e(ev,YU),e(YU,pZo),e(ev,_Zo),e(G,bZo),e(G,ov),e(ov,iMe),e(iMe,vZo),e(ov,FZo),e(ov,ZU),e(ZU,TZo),e(ov,MZo),e(G,EZo),e(G,rv),e(rv,dMe),e(dMe,CZo),e(rv,wZo),e(rv,KU),e(KU,AZo),e(rv,LZo),e(G,yZo),e(G,tv),e(tv,mMe),e(mMe,xZo),e(tv,$Zo),e(tv,eH),e(eH,kZo),e(tv,SZo),e(G,RZo),e(G,av),e(av,cMe),e(cMe,PZo),e(av,BZo),e(av,oH),e(oH,IZo),e(av,NZo),e(G,qZo),e(G,nv),e(nv,fMe),e(fMe,DZo),e(nv,jZo),e(nv,rH),e(rH,GZo),e(nv,OZo),e(G,VZo),e(G,sv),e(sv,gMe),e(gMe,XZo),e(sv,zZo),e(sv,tH),e(tH,QZo),e(sv,WZo),e(G,UZo),e(G,lv),e(lv,hMe),e(hMe,HZo),e(lv,JZo),e(lv,aH),e(aH,YZo),e(lv,ZZo),e(G,KZo),e(G,iv),e(iv,uMe),e(uMe,eKo),e(iv,oKo),e(iv,nH),e(nH,rKo),e(iv,tKo),e(G,aKo),e(G,dv),e(dv,pMe),e(pMe,nKo),e(dv,sKo),e(dv,sH),e(sH,lKo),e(dv,iKo),e(G,dKo),e(G,mv),e(mv,_Me),e(_Me,mKo),e(mv,cKo),e(mv,lH),e(lH,fKo),e(mv,gKo),e(G,hKo),e(G,cv),e(cv,bMe),e(bMe,uKo),e(cv,pKo),e(cv,iH),e(iH,_Ko),e(cv,bKo),e(G,vKo),e(G,fv),e(fv,vMe),e(vMe,FKo),e(fv,TKo),e(fv,dH),e(dH,MKo),e(fv,EKo),e(G,CKo),e(G,gv),e(gv,FMe),e(FMe,wKo),e(gv,AKo),e(gv,mH),e(mH,LKo),e(gv,yKo),e(G,xKo),e(G,hv),e(hv,TMe),e(TMe,$Ko),e(hv,kKo),e(hv,cH),e(cH,SKo),e(hv,RKo),e(G,PKo),e(G,uv),e(uv,MMe),e(MMe,BKo),e(uv,IKo),e(uv,fH),e(fH,NKo),e(uv,qKo),e(G,DKo),e(G,pv),e(pv,EMe),e(EMe,jKo),e(pv,GKo),e(pv,gH),e(gH,OKo),e(pv,VKo),e(G,XKo),e(G,_v),e(_v,CMe),e(CMe,zKo),e(_v,QKo),e(_v,hH),e(hH,WKo),e(_v,UKo),e(G,HKo),e(G,bv),e(bv,wMe),e(wMe,JKo),e(bv,YKo),e(bv,uH),e(uH,ZKo),e(bv,KKo),e(G,eer),e(G,vv),e(vv,AMe),e(AMe,oer),e(vv,rer),e(vv,pH),e(pH,ter),e(vv,aer),e(G,ner),e(G,Fv),e(Fv,LMe),e(LMe,ser),e(Fv,ler),e(Fv,_H),e(_H,ier),e(Fv,der),e(G,mer),e(G,Tv),e(Tv,yMe),e(yMe,cer),e(Tv,fer),e(Tv,bH),e(bH,ger),e(Tv,her),e(G,uer),e(G,Mv),e(Mv,xMe),e(xMe,per),e(Mv,_er),e(Mv,vH),e(vH,ber),e(Mv,ver),e(G,Fer),e(G,Ev),e(Ev,$Me),e($Me,Ter),e(Ev,Mer),e(Ev,FH),e(FH,Eer),e(Ev,Cer),e(G,wer),e(G,Cv),e(Cv,kMe),e(kMe,Aer),e(Cv,Ler),e(Cv,TH),e(TH,yer),e(Cv,xer),e(G,$er),e(G,wv),e(wv,SMe),e(SMe,ker),e(wv,Ser),e(wv,MH),e(MH,Rer),e(wv,Per),e(G,Ber),e(G,Av),e(Av,RMe),e(RMe,Ier),e(Av,Ner),e(Av,EH),e(EH,qer),e(Av,Der),e(G,jer),e(G,Lv),e(Lv,PMe),e(PMe,Ger),e(Lv,Oer),e(Lv,CH),e(CH,Ver),e(Lv,Xer),e(G,zer),e(G,yv),e(yv,BMe),e(BMe,Qer),e(yv,Wer),e(yv,wH),e(wH,Uer),e(yv,Her),e(G,Jer),e(G,xv),e(xv,IMe),e(IMe,Yer),e(xv,Zer),e(xv,AH),e(AH,Ker),e(xv,eor),e(G,oor),e(G,$v),e($v,NMe),e(NMe,ror),e($v,tor),e($v,LH),e(LH,aor),e($v,nor),e(G,sor),e(G,kv),e(kv,qMe),e(qMe,lor),e(kv,ior),e(kv,yH),e(yH,dor),e(kv,mor),e(G,cor),e(G,Sv),e(Sv,DMe),e(DMe,gor),e(Sv,hor),e(Sv,xH),e(xH,uor),e(Sv,por),e(G,_or),e(G,Rv),e(Rv,jMe),e(jMe,bor),e(Rv,vor),e(Rv,$H),e($H,For),e(Rv,Tor),e(G,Mor),e(G,Pv),e(Pv,GMe),e(GMe,Eor),e(Pv,Cor),e(Pv,kH),e(kH,wor),e(Pv,Aor),e(G,Lor),e(G,Bv),e(Bv,OMe),e(OMe,yor),e(Bv,xor),e(Bv,SH),e(SH,$or),e(Bv,kor),e(G,Sor),e(G,Iv),e(Iv,VMe),e(VMe,Ror),e(Iv,Por),e(Iv,RH),e(RH,Bor),e(Iv,Ior),e(G,Nor),e(G,Nv),e(Nv,XMe),e(XMe,qor),e(Nv,Dor),e(Nv,PH),e(PH,jor),e(Nv,Gor),e(G,Oor),e(G,qv),e(qv,zMe),e(zMe,Vor),e(qv,Xor),e(qv,BH),e(BH,zor),e(qv,Qor),e(G,Wor),e(G,Dv),e(Dv,QMe),e(QMe,Uor),e(Dv,Hor),e(Dv,IH),e(IH,Jor),e(Dv,Yor),e(G,Zor),e(G,jv),e(jv,WMe),e(WMe,Kor),e(jv,err),e(jv,NH),e(NH,orr),e(jv,rrr),e(G,trr),e(G,Gv),e(Gv,UMe),e(UMe,arr),e(Gv,nrr),e(Gv,qH),e(qH,srr),e(Gv,lrr),e(G,irr),e(G,Ov),e(Ov,HMe),e(HMe,drr),e(Ov,mrr),e(Ov,DH),e(DH,crr),e(Ov,frr),e(G,grr),e(G,Vv),e(Vv,JMe),e(JMe,hrr),e(Vv,urr),e(Vv,jH),e(jH,prr),e(Vv,_rr),e(G,brr),e(G,Xv),e(Xv,YMe),e(YMe,vrr),e(Xv,Frr),e(Xv,GH),e(GH,Trr),e(Xv,Mrr),e(G,Err),e(G,zv),e(zv,ZMe),e(ZMe,Crr),e(zv,wrr),e(zv,OH),e(OH,Arr),e(zv,Lrr),e(G,yrr),e(G,Qv),e(Qv,KMe),e(KMe,xrr),e(Qv,$rr),e(Qv,VH),e(VH,krr),e(Qv,Srr),e(G,Rrr),e(G,Wv),e(Wv,eEe),e(eEe,Prr),e(Wv,Brr),e(Wv,XH),e(XH,Irr),e(Wv,Nrr),e(ao,qrr),e(ao,Uv),e(Uv,Drr),e(Uv,oEe),e(oEe,jrr),e(Uv,Grr),e(Uv,rEe),e(rEe,Orr),e(ao,Vrr),M(Hv,ao,null),b(c,Blo,_),b(c,Wd,_),e(Wd,Jv),e(Jv,tEe),M(eS,tEe,null),e(Wd,Xrr),e(Wd,aEe),e(aEe,zrr),b(c,Ilo,_),b(c,Oo,_),M(oS,Oo,null),e(Oo,Qrr),e(Oo,Ud),e(Ud,Wrr),e(Ud,zH),e(zH,Urr),e(Ud,Hrr),e(Ud,QH),e(QH,Jrr),e(Ud,Yrr),e(Oo,Zrr),e(Oo,rS),e(rS,Krr),e(rS,nEe),e(nEe,etr),e(rS,otr),e(Oo,rtr),e(Oo,yt),M(tS,yt,null),e(yt,ttr),e(yt,sEe),e(sEe,atr),e(yt,ntr),e(yt,Hd),e(Hd,str),e(Hd,lEe),e(lEe,ltr),e(Hd,itr),e(Hd,WH),e(WH,dtr),e(Hd,mtr),e(yt,ctr),M(Yv,yt,null),e(Oo,ftr),e(Oo,no),M(aS,no,null),e(no,gtr),e(no,iEe),e(iEe,htr),e(no,utr),e(no,hn),e(hn,ptr),e(hn,dEe),e(dEe,_tr),e(hn,btr),e(hn,mEe),e(mEe,vtr),e(hn,Ftr),e(hn,cEe),e(cEe,Ttr),e(hn,Mtr),e(no,Etr),e(no,W),e(W,Zv),e(Zv,fEe),e(fEe,Ctr),e(Zv,wtr),e(Zv,UH),e(UH,Atr),e(Zv,Ltr),e(W,ytr),e(W,Kv),e(Kv,gEe),e(gEe,xtr),e(Kv,$tr),e(Kv,HH),e(HH,ktr),e(Kv,Str),e(W,Rtr),e(W,eF),e(eF,hEe),e(hEe,Ptr),e(eF,Btr),e(eF,JH),e(JH,Itr),e(eF,Ntr),e(W,qtr),e(W,oF),e(oF,uEe),e(uEe,Dtr),e(oF,jtr),e(oF,YH),e(YH,Gtr),e(oF,Otr),e(W,Vtr),e(W,rF),e(rF,pEe),e(pEe,Xtr),e(rF,ztr),e(rF,ZH),e(ZH,Qtr),e(rF,Wtr),e(W,Utr),e(W,tF),e(tF,_Ee),e(_Ee,Htr),e(tF,Jtr),e(tF,KH),e(KH,Ytr),e(tF,Ztr),e(W,Ktr),e(W,aF),e(aF,bEe),e(bEe,ear),e(aF,oar),e(aF,eJ),e(eJ,rar),e(aF,tar),e(W,aar),e(W,nF),e(nF,vEe),e(vEe,nar),e(nF,sar),e(nF,oJ),e(oJ,lar),e(nF,iar),e(W,dar),e(W,sF),e(sF,FEe),e(FEe,mar),e(sF,car),e(sF,rJ),e(rJ,far),e(sF,gar),e(W,har),e(W,lF),e(lF,TEe),e(TEe,uar),e(lF,par),e(lF,tJ),e(tJ,_ar),e(lF,bar),e(W,Far),e(W,iF),e(iF,MEe),e(MEe,Tar),e(iF,Mar),e(iF,aJ),e(aJ,Ear),e(iF,Car),e(W,war),e(W,dF),e(dF,EEe),e(EEe,Aar),e(dF,Lar),e(dF,nJ),e(nJ,yar),e(dF,xar),e(W,$ar),e(W,mF),e(mF,CEe),e(CEe,kar),e(mF,Sar),e(mF,sJ),e(sJ,Rar),e(mF,Par),e(W,Bar),e(W,cF),e(cF,wEe),e(wEe,Iar),e(cF,Nar),e(cF,lJ),e(lJ,qar),e(cF,Dar),e(W,jar),e(W,fF),e(fF,AEe),e(AEe,Gar),e(fF,Oar),e(fF,iJ),e(iJ,Var),e(fF,Xar),e(W,zar),e(W,gF),e(gF,LEe),e(LEe,Qar),e(gF,War),e(gF,dJ),e(dJ,Uar),e(gF,Har),e(W,Jar),e(W,hF),e(hF,yEe),e(yEe,Yar),e(hF,Zar),e(hF,mJ),e(mJ,Kar),e(hF,enr),e(W,onr),e(W,uF),e(uF,xEe),e(xEe,rnr),e(uF,tnr),e(uF,cJ),e(cJ,anr),e(uF,nnr),e(W,snr),e(W,pF),e(pF,$Ee),e($Ee,lnr),e(pF,inr),e(pF,fJ),e(fJ,dnr),e(pF,mnr),e(W,cnr),e(W,_F),e(_F,kEe),e(kEe,fnr),e(_F,gnr),e(_F,gJ),e(gJ,hnr),e(_F,unr),e(W,pnr),e(W,bF),e(bF,SEe),e(SEe,_nr),e(bF,bnr),e(bF,hJ),e(hJ,vnr),e(bF,Fnr),e(W,Tnr),e(W,vF),e(vF,REe),e(REe,Mnr),e(vF,Enr),e(vF,uJ),e(uJ,Cnr),e(vF,wnr),e(W,Anr),e(W,FF),e(FF,PEe),e(PEe,Lnr),e(FF,ynr),e(FF,pJ),e(pJ,xnr),e(FF,$nr),e(W,knr),e(W,TF),e(TF,BEe),e(BEe,Snr),e(TF,Rnr),e(TF,_J),e(_J,Pnr),e(TF,Bnr),e(W,Inr),e(W,MF),e(MF,IEe),e(IEe,Nnr),e(MF,qnr),e(MF,bJ),e(bJ,Dnr),e(MF,jnr),e(W,Gnr),e(W,EF),e(EF,NEe),e(NEe,Onr),e(EF,Vnr),e(EF,vJ),e(vJ,Xnr),e(EF,znr),e(W,Qnr),e(W,CF),e(CF,qEe),e(qEe,Wnr),e(CF,Unr),e(CF,FJ),e(FJ,Hnr),e(CF,Jnr),e(W,Ynr),e(W,wF),e(wF,DEe),e(DEe,Znr),e(wF,Knr),e(wF,TJ),e(TJ,esr),e(wF,osr),e(W,rsr),e(W,AF),e(AF,jEe),e(jEe,tsr),e(AF,asr),e(AF,MJ),e(MJ,nsr),e(AF,ssr),e(W,lsr),e(W,LF),e(LF,GEe),e(GEe,isr),e(LF,dsr),e(LF,EJ),e(EJ,msr),e(LF,csr),e(W,fsr),e(W,yF),e(yF,OEe),e(OEe,gsr),e(yF,hsr),e(yF,CJ),e(CJ,usr),e(yF,psr),e(W,_sr),e(W,xF),e(xF,VEe),e(VEe,bsr),e(xF,vsr),e(xF,wJ),e(wJ,Fsr),e(xF,Tsr),e(W,Msr),e(W,$F),e($F,XEe),e(XEe,Esr),e($F,Csr),e($F,AJ),e(AJ,wsr),e($F,Asr),e(W,Lsr),e(W,kF),e(kF,zEe),e(zEe,ysr),e(kF,xsr),e(kF,LJ),e(LJ,$sr),e(kF,ksr),e(W,Ssr),e(W,SF),e(SF,QEe),e(QEe,Rsr),e(SF,Psr),e(SF,yJ),e(yJ,Bsr),e(SF,Isr),e(W,Nsr),e(W,RF),e(RF,WEe),e(WEe,qsr),e(RF,Dsr),e(RF,xJ),e(xJ,jsr),e(RF,Gsr),e(W,Osr),e(W,PF),e(PF,UEe),e(UEe,Vsr),e(PF,Xsr),e(PF,$J),e($J,zsr),e(PF,Qsr),e(W,Wsr),e(W,BF),e(BF,HEe),e(HEe,Usr),e(BF,Hsr),e(BF,kJ),e(kJ,Jsr),e(BF,Ysr),e(W,Zsr),e(W,IF),e(IF,JEe),e(JEe,Ksr),e(IF,elr),e(IF,SJ),e(SJ,olr),e(IF,rlr),e(W,tlr),e(W,NF),e(NF,YEe),e(YEe,alr),e(NF,nlr),e(NF,RJ),e(RJ,slr),e(NF,llr),e(W,ilr),e(W,qF),e(qF,ZEe),e(ZEe,dlr),e(qF,mlr),e(qF,PJ),e(PJ,clr),e(qF,flr),e(W,glr),e(W,DF),e(DF,KEe),e(KEe,hlr),e(DF,ulr),e(DF,BJ),e(BJ,plr),e(DF,_lr),e(W,blr),e(W,jF),e(jF,e4e),e(e4e,vlr),e(jF,Flr),e(jF,IJ),e(IJ,Tlr),e(jF,Mlr),e(no,Elr),e(no,GF),e(GF,Clr),e(GF,o4e),e(o4e,wlr),e(GF,Alr),e(GF,r4e),e(r4e,Llr),e(no,ylr),M(OF,no,null),b(c,Nlo,_),b(c,Jd,_),e(Jd,VF),e(VF,t4e),M(nS,t4e,null),e(Jd,xlr),e(Jd,a4e),e(a4e,$lr),b(c,qlo,_),b(c,Vo,_),M(sS,Vo,null),e(Vo,klr),e(Vo,Yd),e(Yd,Slr),e(Yd,NJ),e(NJ,Rlr),e(Yd,Plr),e(Yd,qJ),e(qJ,Blr),e(Yd,Ilr),e(Vo,Nlr),e(Vo,lS),e(lS,qlr),e(lS,n4e),e(n4e,Dlr),e(lS,jlr),e(Vo,Glr),e(Vo,xt),M(iS,xt,null),e(xt,Olr),e(xt,s4e),e(s4e,Vlr),e(xt,Xlr),e(xt,Zd),e(Zd,zlr),e(Zd,l4e),e(l4e,Qlr),e(Zd,Wlr),e(Zd,DJ),e(DJ,Ulr),e(Zd,Hlr),e(xt,Jlr),M(XF,xt,null),e(Vo,Ylr),e(Vo,so),M(dS,so,null),e(so,Zlr),e(so,i4e),e(i4e,Klr),e(so,eir),e(so,un),e(un,oir),e(un,d4e),e(d4e,rir),e(un,tir),e(un,m4e),e(m4e,air),e(un,nir),e(un,c4e),e(c4e,sir),e(un,lir),e(so,iir),e(so,mS),e(mS,zF),e(zF,f4e),e(f4e,dir),e(zF,mir),e(zF,jJ),e(jJ,cir),e(zF,fir),e(mS,gir),e(mS,QF),e(QF,g4e),e(g4e,hir),e(QF,uir),e(QF,GJ),e(GJ,pir),e(QF,_ir),e(so,bir),e(so,WF),e(WF,vir),e(WF,h4e),e(h4e,Fir),e(WF,Tir),e(WF,u4e),e(u4e,Mir),e(so,Eir),M(UF,so,null),b(c,Dlo,_),b(c,Kd,_),e(Kd,HF),e(HF,p4e),M(cS,p4e,null),e(Kd,Cir),e(Kd,_4e),e(_4e,wir),b(c,jlo,_),b(c,Xo,_),M(fS,Xo,null),e(Xo,Air),e(Xo,em),e(em,Lir),e(em,OJ),e(OJ,yir),e(em,xir),e(em,VJ),e(VJ,$ir),e(em,kir),e(Xo,Sir),e(Xo,gS),e(gS,Rir),e(gS,b4e),e(b4e,Pir),e(gS,Bir),e(Xo,Iir),e(Xo,$t),M(hS,$t,null),e($t,Nir),e($t,v4e),e(v4e,qir),e($t,Dir),e($t,om),e(om,jir),e(om,F4e),e(F4e,Gir),e(om,Oir),e(om,XJ),e(XJ,Vir),e(om,Xir),e($t,zir),M(JF,$t,null),e(Xo,Qir),e(Xo,lo),M(uS,lo,null),e(lo,Wir),e(lo,T4e),e(T4e,Uir),e(lo,Hir),e(lo,pn),e(pn,Jir),e(pn,M4e),e(M4e,Yir),e(pn,Zir),e(pn,E4e),e(E4e,Kir),e(pn,edr),e(pn,C4e),e(C4e,odr),e(pn,rdr),e(lo,tdr),e(lo,Y),e(Y,YF),e(YF,w4e),e(w4e,adr),e(YF,ndr),e(YF,zJ),e(zJ,sdr),e(YF,ldr),e(Y,idr),e(Y,ZF),e(ZF,A4e),e(A4e,ddr),e(ZF,mdr),e(ZF,QJ),e(QJ,cdr),e(ZF,fdr),e(Y,gdr),e(Y,KF),e(KF,L4e),e(L4e,hdr),e(KF,udr),e(KF,WJ),e(WJ,pdr),e(KF,_dr),e(Y,bdr),e(Y,eT),e(eT,y4e),e(y4e,vdr),e(eT,Fdr),e(eT,UJ),e(UJ,Tdr),e(eT,Mdr),e(Y,Edr),e(Y,oT),e(oT,x4e),e(x4e,Cdr),e(oT,wdr),e(oT,HJ),e(HJ,Adr),e(oT,Ldr),e(Y,ydr),e(Y,rT),e(rT,$4e),e($4e,xdr),e(rT,$dr),e(rT,JJ),e(JJ,kdr),e(rT,Sdr),e(Y,Rdr),e(Y,tT),e(tT,k4e),e(k4e,Pdr),e(tT,Bdr),e(tT,YJ),e(YJ,Idr),e(tT,Ndr),e(Y,qdr),e(Y,aT),e(aT,S4e),e(S4e,Ddr),e(aT,jdr),e(aT,ZJ),e(ZJ,Gdr),e(aT,Odr),e(Y,Vdr),e(Y,nT),e(nT,R4e),e(R4e,Xdr),e(nT,zdr),e(nT,KJ),e(KJ,Qdr),e(nT,Wdr),e(Y,Udr),e(Y,sT),e(sT,P4e),e(P4e,Hdr),e(sT,Jdr),e(sT,eY),e(eY,Ydr),e(sT,Zdr),e(Y,Kdr),e(Y,lT),e(lT,B4e),e(B4e,emr),e(lT,omr),e(lT,oY),e(oY,rmr),e(lT,tmr),e(Y,amr),e(Y,iT),e(iT,I4e),e(I4e,nmr),e(iT,smr),e(iT,rY),e(rY,lmr),e(iT,imr),e(Y,dmr),e(Y,dT),e(dT,N4e),e(N4e,mmr),e(dT,cmr),e(dT,tY),e(tY,fmr),e(dT,gmr),e(Y,hmr),e(Y,mT),e(mT,q4e),e(q4e,umr),e(mT,pmr),e(mT,aY),e(aY,_mr),e(mT,bmr),e(Y,vmr),e(Y,cT),e(cT,D4e),e(D4e,Fmr),e(cT,Tmr),e(cT,nY),e(nY,Mmr),e(cT,Emr),e(Y,Cmr),e(Y,fT),e(fT,j4e),e(j4e,wmr),e(fT,Amr),e(fT,sY),e(sY,Lmr),e(fT,ymr),e(Y,xmr),e(Y,gT),e(gT,G4e),e(G4e,$mr),e(gT,kmr),e(gT,lY),e(lY,Smr),e(gT,Rmr),e(Y,Pmr),e(Y,hT),e(hT,O4e),e(O4e,Bmr),e(hT,Imr),e(hT,iY),e(iY,Nmr),e(hT,qmr),e(Y,Dmr),e(Y,uT),e(uT,V4e),e(V4e,jmr),e(uT,Gmr),e(uT,dY),e(dY,Omr),e(uT,Vmr),e(Y,Xmr),e(Y,pT),e(pT,X4e),e(X4e,zmr),e(pT,Qmr),e(pT,mY),e(mY,Wmr),e(pT,Umr),e(Y,Hmr),e(Y,_T),e(_T,z4e),e(z4e,Jmr),e(_T,Ymr),e(_T,cY),e(cY,Zmr),e(_T,Kmr),e(Y,ecr),e(Y,bT),e(bT,Q4e),e(Q4e,ocr),e(bT,rcr),e(bT,fY),e(fY,tcr),e(bT,acr),e(Y,ncr),e(Y,vT),e(vT,W4e),e(W4e,scr),e(vT,lcr),e(vT,gY),e(gY,icr),e(vT,dcr),e(Y,mcr),e(Y,FT),e(FT,U4e),e(U4e,ccr),e(FT,fcr),e(FT,hY),e(hY,gcr),e(FT,hcr),e(Y,ucr),e(Y,TT),e(TT,H4e),e(H4e,pcr),e(TT,_cr),e(TT,uY),e(uY,bcr),e(TT,vcr),e(Y,Fcr),e(Y,MT),e(MT,J4e),e(J4e,Tcr),e(MT,Mcr),e(MT,pY),e(pY,Ecr),e(MT,Ccr),e(Y,wcr),e(Y,ET),e(ET,Y4e),e(Y4e,Acr),e(ET,Lcr),e(ET,_Y),e(_Y,ycr),e(ET,xcr),e(Y,$cr),e(Y,CT),e(CT,Z4e),e(Z4e,kcr),e(CT,Scr),e(CT,bY),e(bY,Rcr),e(CT,Pcr),e(Y,Bcr),e(Y,wT),e(wT,K4e),e(K4e,Icr),e(wT,Ncr),e(wT,vY),e(vY,qcr),e(wT,Dcr),e(Y,jcr),e(Y,AT),e(AT,eCe),e(eCe,Gcr),e(AT,Ocr),e(AT,FY),e(FY,Vcr),e(AT,Xcr),e(Y,zcr),e(Y,LT),e(LT,oCe),e(oCe,Qcr),e(LT,Wcr),e(LT,TY),e(TY,Ucr),e(LT,Hcr),e(Y,Jcr),e(Y,yT),e(yT,rCe),e(rCe,Ycr),e(yT,Zcr),e(yT,MY),e(MY,Kcr),e(yT,efr),e(Y,ofr),e(Y,xT),e(xT,tCe),e(tCe,rfr),e(xT,tfr),e(xT,EY),e(EY,afr),e(xT,nfr),e(Y,sfr),e(Y,$T),e($T,aCe),e(aCe,lfr),e($T,ifr),e($T,CY),e(CY,dfr),e($T,mfr),e(Y,cfr),e(Y,kT),e(kT,nCe),e(nCe,ffr),e(kT,gfr),e(kT,wY),e(wY,hfr),e(kT,ufr),e(Y,pfr),e(Y,ST),e(ST,sCe),e(sCe,_fr),e(ST,bfr),e(ST,lCe),e(lCe,vfr),e(ST,Ffr),e(Y,Tfr),e(Y,RT),e(RT,iCe),e(iCe,Mfr),e(RT,Efr),e(RT,AY),e(AY,Cfr),e(RT,wfr),e(Y,Afr),e(Y,PT),e(PT,dCe),e(dCe,Lfr),e(PT,yfr),e(PT,LY),e(LY,xfr),e(PT,$fr),e(Y,kfr),e(Y,BT),e(BT,mCe),e(mCe,Sfr),e(BT,Rfr),e(BT,yY),e(yY,Pfr),e(BT,Bfr),e(Y,Ifr),e(Y,IT),e(IT,cCe),e(cCe,Nfr),e(IT,qfr),e(IT,xY),e(xY,Dfr),e(IT,jfr),e(lo,Gfr),e(lo,NT),e(NT,Ofr),e(NT,fCe),e(fCe,Vfr),e(NT,Xfr),e(NT,gCe),e(gCe,zfr),e(lo,Qfr),M(qT,lo,null),b(c,Glo,_),b(c,rm,_),e(rm,DT),e(DT,hCe),M(pS,hCe,null),e(rm,Wfr),e(rm,uCe),e(uCe,Ufr),b(c,Olo,_),b(c,zo,_),M(_S,zo,null),e(zo,Hfr),e(zo,tm),e(tm,Jfr),e(tm,$Y),e($Y,Yfr),e(tm,Zfr),e(tm,kY),e(kY,Kfr),e(tm,egr),e(zo,ogr),e(zo,bS),e(bS,rgr),e(bS,pCe),e(pCe,tgr),e(bS,agr),e(zo,ngr),e(zo,kt),M(vS,kt,null),e(kt,sgr),e(kt,_Ce),e(_Ce,lgr),e(kt,igr),e(kt,am),e(am,dgr),e(am,bCe),e(bCe,mgr),e(am,cgr),e(am,SY),e(SY,fgr),e(am,ggr),e(kt,hgr),M(jT,kt,null),e(zo,ugr),e(zo,io),M(FS,io,null),e(io,pgr),e(io,vCe),e(vCe,_gr),e(io,bgr),e(io,_n),e(_n,vgr),e(_n,FCe),e(FCe,Fgr),e(_n,Tgr),e(_n,TCe),e(TCe,Mgr),e(_n,Egr),e(_n,MCe),e(MCe,Cgr),e(_n,wgr),e(io,Agr),e(io,pe),e(pe,GT),e(GT,ECe),e(ECe,Lgr),e(GT,ygr),e(GT,RY),e(RY,xgr),e(GT,$gr),e(pe,kgr),e(pe,OT),e(OT,CCe),e(CCe,Sgr),e(OT,Rgr),e(OT,PY),e(PY,Pgr),e(OT,Bgr),e(pe,Igr),e(pe,VT),e(VT,wCe),e(wCe,Ngr),e(VT,qgr),e(VT,BY),e(BY,Dgr),e(VT,jgr),e(pe,Ggr),e(pe,XT),e(XT,ACe),e(ACe,Ogr),e(XT,Vgr),e(XT,IY),e(IY,Xgr),e(XT,zgr),e(pe,Qgr),e(pe,zT),e(zT,LCe),e(LCe,Wgr),e(zT,Ugr),e(zT,NY),e(NY,Hgr),e(zT,Jgr),e(pe,Ygr),e(pe,QT),e(QT,yCe),e(yCe,Zgr),e(QT,Kgr),e(QT,qY),e(qY,ehr),e(QT,ohr),e(pe,rhr),e(pe,WT),e(WT,xCe),e(xCe,thr),e(WT,ahr),e(WT,DY),e(DY,nhr),e(WT,shr),e(pe,lhr),e(pe,UT),e(UT,$Ce),e($Ce,ihr),e(UT,dhr),e(UT,jY),e(jY,mhr),e(UT,chr),e(pe,fhr),e(pe,HT),e(HT,kCe),e(kCe,ghr),e(HT,hhr),e(HT,GY),e(GY,uhr),e(HT,phr),e(pe,_hr),e(pe,JT),e(JT,SCe),e(SCe,bhr),e(JT,vhr),e(JT,OY),e(OY,Fhr),e(JT,Thr),e(pe,Mhr),e(pe,YT),e(YT,RCe),e(RCe,Ehr),e(YT,Chr),e(YT,VY),e(VY,whr),e(YT,Ahr),e(pe,Lhr),e(pe,ZT),e(ZT,PCe),e(PCe,yhr),e(ZT,xhr),e(ZT,XY),e(XY,$hr),e(ZT,khr),e(pe,Shr),e(pe,KT),e(KT,BCe),e(BCe,Rhr),e(KT,Phr),e(KT,zY),e(zY,Bhr),e(KT,Ihr),e(pe,Nhr),e(pe,eM),e(eM,ICe),e(ICe,qhr),e(eM,Dhr),e(eM,QY),e(QY,jhr),e(eM,Ghr),e(pe,Ohr),e(pe,oM),e(oM,NCe),e(NCe,Vhr),e(oM,Xhr),e(oM,WY),e(WY,zhr),e(oM,Qhr),e(pe,Whr),e(pe,rM),e(rM,qCe),e(qCe,Uhr),e(rM,Hhr),e(rM,UY),e(UY,Jhr),e(rM,Yhr),e(pe,Zhr),e(pe,tM),e(tM,DCe),e(DCe,Khr),e(tM,eur),e(tM,HY),e(HY,our),e(tM,rur),e(pe,tur),e(pe,aM),e(aM,jCe),e(jCe,aur),e(aM,nur),e(aM,JY),e(JY,sur),e(aM,lur),e(pe,iur),e(pe,nM),e(nM,GCe),e(GCe,dur),e(nM,mur),e(nM,YY),e(YY,cur),e(nM,fur),e(pe,gur),e(pe,sM),e(sM,OCe),e(OCe,hur),e(sM,uur),e(sM,ZY),e(ZY,pur),e(sM,_ur),e(io,bur),e(io,lM),e(lM,vur),e(lM,VCe),e(VCe,Fur),e(lM,Tur),e(lM,XCe),e(XCe,Mur),e(io,Eur),M(iM,io,null),b(c,Vlo,_),b(c,nm,_),e(nm,dM),e(dM,zCe),M(TS,zCe,null),e(nm,Cur),e(nm,QCe),e(QCe,wur),b(c,Xlo,_),b(c,Qo,_),M(MS,Qo,null),e(Qo,Aur),e(Qo,sm),e(sm,Lur),e(sm,KY),e(KY,yur),e(sm,xur),e(sm,eZ),e(eZ,$ur),e(sm,kur),e(Qo,Sur),e(Qo,ES),e(ES,Rur),e(ES,WCe),e(WCe,Pur),e(ES,Bur),e(Qo,Iur),e(Qo,St),M(CS,St,null),e(St,Nur),e(St,UCe),e(UCe,qur),e(St,Dur),e(St,lm),e(lm,jur),e(lm,HCe),e(HCe,Gur),e(lm,Our),e(lm,oZ),e(oZ,Vur),e(lm,Xur),e(St,zur),M(mM,St,null),e(Qo,Qur),e(Qo,mo),M(wS,mo,null),e(mo,Wur),e(mo,JCe),e(JCe,Uur),e(mo,Hur),e(mo,bn),e(bn,Jur),e(bn,YCe),e(YCe,Yur),e(bn,Zur),e(bn,ZCe),e(ZCe,Kur),e(bn,epr),e(bn,KCe),e(KCe,opr),e(bn,rpr),e(mo,tpr),e(mo,I),e(I,cM),e(cM,e3e),e(e3e,apr),e(cM,npr),e(cM,rZ),e(rZ,spr),e(cM,lpr),e(I,ipr),e(I,fM),e(fM,o3e),e(o3e,dpr),e(fM,mpr),e(fM,tZ),e(tZ,cpr),e(fM,fpr),e(I,gpr),e(I,gM),e(gM,r3e),e(r3e,hpr),e(gM,upr),e(gM,aZ),e(aZ,ppr),e(gM,_pr),e(I,bpr),e(I,hM),e(hM,t3e),e(t3e,vpr),e(hM,Fpr),e(hM,nZ),e(nZ,Tpr),e(hM,Mpr),e(I,Epr),e(I,uM),e(uM,a3e),e(a3e,Cpr),e(uM,wpr),e(uM,sZ),e(sZ,Apr),e(uM,Lpr),e(I,ypr),e(I,pM),e(pM,n3e),e(n3e,xpr),e(pM,$pr),e(pM,lZ),e(lZ,kpr),e(pM,Spr),e(I,Rpr),e(I,_M),e(_M,s3e),e(s3e,Ppr),e(_M,Bpr),e(_M,iZ),e(iZ,Ipr),e(_M,Npr),e(I,qpr),e(I,bM),e(bM,l3e),e(l3e,Dpr),e(bM,jpr),e(bM,dZ),e(dZ,Gpr),e(bM,Opr),e(I,Vpr),e(I,vM),e(vM,i3e),e(i3e,Xpr),e(vM,zpr),e(vM,mZ),e(mZ,Qpr),e(vM,Wpr),e(I,Upr),e(I,FM),e(FM,d3e),e(d3e,Hpr),e(FM,Jpr),e(FM,cZ),e(cZ,Ypr),e(FM,Zpr),e(I,Kpr),e(I,TM),e(TM,m3e),e(m3e,e_r),e(TM,o_r),e(TM,fZ),e(fZ,r_r),e(TM,t_r),e(I,a_r),e(I,MM),e(MM,c3e),e(c3e,n_r),e(MM,s_r),e(MM,gZ),e(gZ,l_r),e(MM,i_r),e(I,d_r),e(I,EM),e(EM,f3e),e(f3e,m_r),e(EM,c_r),e(EM,hZ),e(hZ,f_r),e(EM,g_r),e(I,h_r),e(I,CM),e(CM,g3e),e(g3e,u_r),e(CM,p_r),e(CM,uZ),e(uZ,__r),e(CM,b_r),e(I,v_r),e(I,wM),e(wM,h3e),e(h3e,F_r),e(wM,T_r),e(wM,pZ),e(pZ,M_r),e(wM,E_r),e(I,C_r),e(I,AM),e(AM,u3e),e(u3e,w_r),e(AM,A_r),e(AM,_Z),e(_Z,L_r),e(AM,y_r),e(I,x_r),e(I,LM),e(LM,p3e),e(p3e,$_r),e(LM,k_r),e(LM,bZ),e(bZ,S_r),e(LM,R_r),e(I,P_r),e(I,yM),e(yM,_3e),e(_3e,B_r),e(yM,I_r),e(yM,vZ),e(vZ,N_r),e(yM,q_r),e(I,D_r),e(I,xM),e(xM,b3e),e(b3e,j_r),e(xM,G_r),e(xM,FZ),e(FZ,O_r),e(xM,V_r),e(I,X_r),e(I,$M),e($M,v3e),e(v3e,z_r),e($M,Q_r),e($M,TZ),e(TZ,W_r),e($M,U_r),e(I,H_r),e(I,kM),e(kM,F3e),e(F3e,J_r),e(kM,Y_r),e(kM,MZ),e(MZ,Z_r),e(kM,K_r),e(I,e1r),e(I,SM),e(SM,T3e),e(T3e,o1r),e(SM,r1r),e(SM,EZ),e(EZ,t1r),e(SM,a1r),e(I,n1r),e(I,RM),e(RM,M3e),e(M3e,s1r),e(RM,l1r),e(RM,CZ),e(CZ,i1r),e(RM,d1r),e(I,m1r),e(I,PM),e(PM,E3e),e(E3e,c1r),e(PM,f1r),e(PM,wZ),e(wZ,g1r),e(PM,h1r),e(I,u1r),e(I,BM),e(BM,C3e),e(C3e,p1r),e(BM,_1r),e(BM,AZ),e(AZ,b1r),e(BM,v1r),e(I,F1r),e(I,IM),e(IM,w3e),e(w3e,T1r),e(IM,M1r),e(IM,LZ),e(LZ,E1r),e(IM,C1r),e(I,w1r),e(I,NM),e(NM,A3e),e(A3e,A1r),e(NM,L1r),e(NM,yZ),e(yZ,y1r),e(NM,x1r),e(I,$1r),e(I,qM),e(qM,L3e),e(L3e,k1r),e(qM,S1r),e(qM,xZ),e(xZ,R1r),e(qM,P1r),e(I,B1r),e(I,DM),e(DM,y3e),e(y3e,I1r),e(DM,N1r),e(DM,$Z),e($Z,q1r),e(DM,D1r),e(I,j1r),e(I,jM),e(jM,x3e),e(x3e,G1r),e(jM,O1r),e(jM,kZ),e(kZ,V1r),e(jM,X1r),e(I,z1r),e(I,GM),e(GM,$3e),e($3e,Q1r),e(GM,W1r),e(GM,SZ),e(SZ,U1r),e(GM,H1r),e(I,J1r),e(I,OM),e(OM,k3e),e(k3e,Y1r),e(OM,Z1r),e(OM,RZ),e(RZ,K1r),e(OM,e2r),e(I,o2r),e(I,VM),e(VM,S3e),e(S3e,r2r),e(VM,t2r),e(VM,PZ),e(PZ,a2r),e(VM,n2r),e(I,s2r),e(I,XM),e(XM,R3e),e(R3e,l2r),e(XM,i2r),e(XM,BZ),e(BZ,d2r),e(XM,m2r),e(I,c2r),e(I,zM),e(zM,P3e),e(P3e,f2r),e(zM,g2r),e(zM,IZ),e(IZ,h2r),e(zM,u2r),e(I,p2r),e(I,QM),e(QM,B3e),e(B3e,_2r),e(QM,b2r),e(QM,NZ),e(NZ,v2r),e(QM,F2r),e(I,T2r),e(I,WM),e(WM,I3e),e(I3e,M2r),e(WM,E2r),e(WM,qZ),e(qZ,C2r),e(WM,w2r),e(I,A2r),e(I,UM),e(UM,N3e),e(N3e,L2r),e(UM,y2r),e(UM,DZ),e(DZ,x2r),e(UM,$2r),e(I,k2r),e(I,HM),e(HM,q3e),e(q3e,S2r),e(HM,R2r),e(HM,jZ),e(jZ,P2r),e(HM,B2r),e(I,I2r),e(I,JM),e(JM,D3e),e(D3e,N2r),e(JM,q2r),e(JM,GZ),e(GZ,D2r),e(JM,j2r),e(I,G2r),e(I,YM),e(YM,j3e),e(j3e,O2r),e(YM,V2r),e(YM,OZ),e(OZ,X2r),e(YM,z2r),e(I,Q2r),e(I,ZM),e(ZM,G3e),e(G3e,W2r),e(ZM,U2r),e(ZM,VZ),e(VZ,H2r),e(ZM,J2r),e(I,Y2r),e(I,KM),e(KM,O3e),e(O3e,Z2r),e(KM,K2r),e(KM,XZ),e(XZ,ebr),e(KM,obr),e(I,rbr),e(I,eE),e(eE,V3e),e(V3e,tbr),e(eE,abr),e(eE,zZ),e(zZ,nbr),e(eE,sbr),e(I,lbr),e(I,oE),e(oE,X3e),e(X3e,ibr),e(oE,dbr),e(oE,QZ),e(QZ,mbr),e(oE,cbr),e(I,fbr),e(I,rE),e(rE,z3e),e(z3e,gbr),e(rE,hbr),e(rE,WZ),e(WZ,ubr),e(rE,pbr),e(I,_br),e(I,tE),e(tE,Q3e),e(Q3e,bbr),e(tE,vbr),e(tE,UZ),e(UZ,Fbr),e(tE,Tbr),e(I,Mbr),e(I,aE),e(aE,W3e),e(W3e,Ebr),e(aE,Cbr),e(aE,HZ),e(HZ,wbr),e(aE,Abr),e(I,Lbr),e(I,nE),e(nE,U3e),e(U3e,ybr),e(nE,xbr),e(nE,JZ),e(JZ,$br),e(nE,kbr),e(I,Sbr),e(I,sE),e(sE,H3e),e(H3e,Rbr),e(sE,Pbr),e(sE,YZ),e(YZ,Bbr),e(sE,Ibr),e(I,Nbr),e(I,lE),e(lE,J3e),e(J3e,qbr),e(lE,Dbr),e(lE,ZZ),e(ZZ,jbr),e(lE,Gbr),e(I,Obr),e(I,iE),e(iE,Y3e),e(Y3e,Vbr),e(iE,Xbr),e(iE,KZ),e(KZ,zbr),e(iE,Qbr),e(I,Wbr),e(I,dE),e(dE,Z3e),e(Z3e,Ubr),e(dE,Hbr),e(dE,eK),e(eK,Jbr),e(dE,Ybr),e(I,Zbr),e(I,mE),e(mE,K3e),e(K3e,Kbr),e(mE,evr),e(mE,oK),e(oK,ovr),e(mE,rvr),e(I,tvr),e(I,cE),e(cE,e5e),e(e5e,avr),e(cE,nvr),e(cE,rK),e(rK,svr),e(cE,lvr),e(I,ivr),e(I,fE),e(fE,o5e),e(o5e,dvr),e(fE,mvr),e(fE,tK),e(tK,cvr),e(fE,fvr),e(I,gvr),e(I,gE),e(gE,r5e),e(r5e,hvr),e(gE,uvr),e(gE,aK),e(aK,pvr),e(gE,_vr),e(mo,bvr),e(mo,hE),e(hE,vvr),e(hE,t5e),e(t5e,Fvr),e(hE,Tvr),e(hE,a5e),e(a5e,Mvr),e(mo,Evr),M(uE,mo,null),b(c,zlo,_),b(c,im,_),e(im,pE),e(pE,n5e),M(AS,n5e,null),e(im,Cvr),e(im,s5e),e(s5e,wvr),b(c,Qlo,_),b(c,Wo,_),M(LS,Wo,null),e(Wo,Avr),e(Wo,dm),e(dm,Lvr),e(dm,nK),e(nK,yvr),e(dm,xvr),e(dm,sK),e(sK,$vr),e(dm,kvr),e(Wo,Svr),e(Wo,yS),e(yS,Rvr),e(yS,l5e),e(l5e,Pvr),e(yS,Bvr),e(Wo,Ivr),e(Wo,Rt),M(xS,Rt,null),e(Rt,Nvr),e(Rt,i5e),e(i5e,qvr),e(Rt,Dvr),e(Rt,mm),e(mm,jvr),e(mm,d5e),e(d5e,Gvr),e(mm,Ovr),e(mm,lK),e(lK,Vvr),e(mm,Xvr),e(Rt,zvr),M(_E,Rt,null),e(Wo,Qvr),e(Wo,co),M($S,co,null),e(co,Wvr),e(co,m5e),e(m5e,Uvr),e(co,Hvr),e(co,vn),e(vn,Jvr),e(vn,c5e),e(c5e,Yvr),e(vn,Zvr),e(vn,f5e),e(f5e,Kvr),e(vn,eFr),e(vn,g5e),e(g5e,oFr),e(vn,rFr),e(co,tFr),e(co,K),e(K,bE),e(bE,h5e),e(h5e,aFr),e(bE,nFr),e(bE,iK),e(iK,sFr),e(bE,lFr),e(K,iFr),e(K,vE),e(vE,u5e),e(u5e,dFr),e(vE,mFr),e(vE,dK),e(dK,cFr),e(vE,fFr),e(K,gFr),e(K,FE),e(FE,p5e),e(p5e,hFr),e(FE,uFr),e(FE,mK),e(mK,pFr),e(FE,_Fr),e(K,bFr),e(K,TE),e(TE,_5e),e(_5e,vFr),e(TE,FFr),e(TE,cK),e(cK,TFr),e(TE,MFr),e(K,EFr),e(K,ME),e(ME,b5e),e(b5e,CFr),e(ME,wFr),e(ME,fK),e(fK,AFr),e(ME,LFr),e(K,yFr),e(K,EE),e(EE,v5e),e(v5e,xFr),e(EE,$Fr),e(EE,gK),e(gK,kFr),e(EE,SFr),e(K,RFr),e(K,CE),e(CE,F5e),e(F5e,PFr),e(CE,BFr),e(CE,hK),e(hK,IFr),e(CE,NFr),e(K,qFr),e(K,wE),e(wE,T5e),e(T5e,DFr),e(wE,jFr),e(wE,uK),e(uK,GFr),e(wE,OFr),e(K,VFr),e(K,AE),e(AE,M5e),e(M5e,XFr),e(AE,zFr),e(AE,pK),e(pK,QFr),e(AE,WFr),e(K,UFr),e(K,LE),e(LE,E5e),e(E5e,HFr),e(LE,JFr),e(LE,_K),e(_K,YFr),e(LE,ZFr),e(K,KFr),e(K,yE),e(yE,C5e),e(C5e,eTr),e(yE,oTr),e(yE,bK),e(bK,rTr),e(yE,tTr),e(K,aTr),e(K,xE),e(xE,w5e),e(w5e,nTr),e(xE,sTr),e(xE,vK),e(vK,lTr),e(xE,iTr),e(K,dTr),e(K,$E),e($E,A5e),e(A5e,mTr),e($E,cTr),e($E,FK),e(FK,fTr),e($E,gTr),e(K,hTr),e(K,kE),e(kE,L5e),e(L5e,uTr),e(kE,pTr),e(kE,TK),e(TK,_Tr),e(kE,bTr),e(K,vTr),e(K,SE),e(SE,y5e),e(y5e,FTr),e(SE,TTr),e(SE,MK),e(MK,MTr),e(SE,ETr),e(K,CTr),e(K,RE),e(RE,x5e),e(x5e,wTr),e(RE,ATr),e(RE,EK),e(EK,LTr),e(RE,yTr),e(K,xTr),e(K,PE),e(PE,$5e),e($5e,$Tr),e(PE,kTr),e(PE,CK),e(CK,STr),e(PE,RTr),e(K,PTr),e(K,BE),e(BE,k5e),e(k5e,BTr),e(BE,ITr),e(BE,wK),e(wK,NTr),e(BE,qTr),e(K,DTr),e(K,IE),e(IE,S5e),e(S5e,jTr),e(IE,GTr),e(IE,AK),e(AK,OTr),e(IE,VTr),e(K,XTr),e(K,NE),e(NE,R5e),e(R5e,zTr),e(NE,QTr),e(NE,LK),e(LK,WTr),e(NE,UTr),e(K,HTr),e(K,qE),e(qE,P5e),e(P5e,JTr),e(qE,YTr),e(qE,yK),e(yK,ZTr),e(qE,KTr),e(K,eMr),e(K,DE),e(DE,B5e),e(B5e,oMr),e(DE,rMr),e(DE,xK),e(xK,tMr),e(DE,aMr),e(K,nMr),e(K,jE),e(jE,I5e),e(I5e,sMr),e(jE,lMr),e(jE,$K),e($K,iMr),e(jE,dMr),e(K,mMr),e(K,GE),e(GE,N5e),e(N5e,cMr),e(GE,fMr),e(GE,kK),e(kK,gMr),e(GE,hMr),e(K,uMr),e(K,OE),e(OE,q5e),e(q5e,pMr),e(OE,_Mr),e(OE,SK),e(SK,bMr),e(OE,vMr),e(K,FMr),e(K,VE),e(VE,D5e),e(D5e,TMr),e(VE,MMr),e(VE,RK),e(RK,EMr),e(VE,CMr),e(K,wMr),e(K,XE),e(XE,j5e),e(j5e,AMr),e(XE,LMr),e(XE,PK),e(PK,yMr),e(XE,xMr),e(K,$Mr),e(K,zE),e(zE,G5e),e(G5e,kMr),e(zE,SMr),e(zE,BK),e(BK,RMr),e(zE,PMr),e(K,BMr),e(K,QE),e(QE,O5e),e(O5e,IMr),e(QE,NMr),e(QE,IK),e(IK,qMr),e(QE,DMr),e(K,jMr),e(K,WE),e(WE,V5e),e(V5e,GMr),e(WE,OMr),e(WE,NK),e(NK,VMr),e(WE,XMr),e(K,zMr),e(K,UE),e(UE,X5e),e(X5e,QMr),e(UE,WMr),e(UE,qK),e(qK,UMr),e(UE,HMr),e(K,JMr),e(K,HE),e(HE,z5e),e(z5e,YMr),e(HE,ZMr),e(HE,DK),e(DK,KMr),e(HE,eEr),e(K,oEr),e(K,JE),e(JE,Q5e),e(Q5e,rEr),e(JE,tEr),e(JE,jK),e(jK,aEr),e(JE,nEr),e(co,sEr),e(co,YE),e(YE,lEr),e(YE,W5e),e(W5e,iEr),e(YE,dEr),e(YE,U5e),e(U5e,mEr),e(co,cEr),M(ZE,co,null),b(c,Wlo,_),b(c,cm,_),e(cm,KE),e(KE,H5e),M(kS,H5e,null),e(cm,fEr),e(cm,J5e),e(J5e,gEr),b(c,Ulo,_),b(c,Uo,_),M(SS,Uo,null),e(Uo,hEr),e(Uo,fm),e(fm,uEr),e(fm,GK),e(GK,pEr),e(fm,_Er),e(fm,OK),e(OK,bEr),e(fm,vEr),e(Uo,FEr),e(Uo,RS),e(RS,TEr),e(RS,Y5e),e(Y5e,MEr),e(RS,EEr),e(Uo,CEr),e(Uo,Pt),M(PS,Pt,null),e(Pt,wEr),e(Pt,Z5e),e(Z5e,AEr),e(Pt,LEr),e(Pt,gm),e(gm,yEr),e(gm,K5e),e(K5e,xEr),e(gm,$Er),e(gm,VK),e(VK,kEr),e(gm,SEr),e(Pt,REr),M(e4,Pt,null),e(Uo,PEr),e(Uo,fo),M(BS,fo,null),e(fo,BEr),e(fo,e0e),e(e0e,IEr),e(fo,NEr),e(fo,Fn),e(Fn,qEr),e(Fn,o0e),e(o0e,DEr),e(Fn,jEr),e(Fn,r0e),e(r0e,GEr),e(Fn,OEr),e(Fn,t0e),e(t0e,VEr),e(Fn,XEr),e(fo,zEr),e(fo,Ye),e(Ye,o4),e(o4,a0e),e(a0e,QEr),e(o4,WEr),e(o4,XK),e(XK,UEr),e(o4,HEr),e(Ye,JEr),e(Ye,r4),e(r4,n0e),e(n0e,YEr),e(r4,ZEr),e(r4,zK),e(zK,KEr),e(r4,e4r),e(Ye,o4r),e(Ye,t4),e(t4,s0e),e(s0e,r4r),e(t4,t4r),e(t4,QK),e(QK,a4r),e(t4,n4r),e(Ye,s4r),e(Ye,a4),e(a4,l0e),e(l0e,l4r),e(a4,i4r),e(a4,WK),e(WK,d4r),e(a4,m4r),e(Ye,c4r),e(Ye,n4),e(n4,i0e),e(i0e,f4r),e(n4,g4r),e(n4,UK),e(UK,h4r),e(n4,u4r),e(Ye,p4r),e(Ye,s4),e(s4,d0e),e(d0e,_4r),e(s4,b4r),e(s4,HK),e(HK,v4r),e(s4,F4r),e(Ye,T4r),e(Ye,l4),e(l4,m0e),e(m0e,M4r),e(l4,E4r),e(l4,JK),e(JK,C4r),e(l4,w4r),e(fo,A4r),e(fo,i4),e(i4,L4r),e(i4,c0e),e(c0e,y4r),e(i4,x4r),e(i4,f0e),e(f0e,$4r),e(fo,k4r),M(d4,fo,null),b(c,Hlo,_),b(c,hm,_),e(hm,m4),e(m4,g0e),M(IS,g0e,null),e(hm,S4r),e(hm,h0e),e(h0e,R4r),b(c,Jlo,_),b(c,Ho,_),M(NS,Ho,null),e(Ho,P4r),e(Ho,um),e(um,B4r),e(um,YK),e(YK,I4r),e(um,N4r),e(um,ZK),e(ZK,q4r),e(um,D4r),e(Ho,j4r),e(Ho,qS),e(qS,G4r),e(qS,u0e),e(u0e,O4r),e(qS,V4r),e(Ho,X4r),e(Ho,Bt),M(DS,Bt,null),e(Bt,z4r),e(Bt,p0e),e(p0e,Q4r),e(Bt,W4r),e(Bt,pm),e(pm,U4r),e(pm,_0e),e(_0e,H4r),e(pm,J4r),e(pm,KK),e(KK,Y4r),e(pm,Z4r),e(Bt,K4r),M(c4,Bt,null),e(Ho,eCr),e(Ho,go),M(jS,go,null),e(go,oCr),e(go,b0e),e(b0e,rCr),e(go,tCr),e(go,Tn),e(Tn,aCr),e(Tn,v0e),e(v0e,nCr),e(Tn,sCr),e(Tn,F0e),e(F0e,lCr),e(Tn,iCr),e(Tn,T0e),e(T0e,dCr),e(Tn,mCr),e(go,cCr),e(go,U),e(U,f4),e(f4,M0e),e(M0e,fCr),e(f4,gCr),e(f4,eee),e(eee,hCr),e(f4,uCr),e(U,pCr),e(U,g4),e(g4,E0e),e(E0e,_Cr),e(g4,bCr),e(g4,oee),e(oee,vCr),e(g4,FCr),e(U,TCr),e(U,h4),e(h4,C0e),e(C0e,MCr),e(h4,ECr),e(h4,ree),e(ree,CCr),e(h4,wCr),e(U,ACr),e(U,u4),e(u4,w0e),e(w0e,LCr),e(u4,yCr),e(u4,tee),e(tee,xCr),e(u4,$Cr),e(U,kCr),e(U,p4),e(p4,A0e),e(A0e,SCr),e(p4,RCr),e(p4,aee),e(aee,PCr),e(p4,BCr),e(U,ICr),e(U,_4),e(_4,L0e),e(L0e,NCr),e(_4,qCr),e(_4,nee),e(nee,DCr),e(_4,jCr),e(U,GCr),e(U,b4),e(b4,y0e),e(y0e,OCr),e(b4,VCr),e(b4,see),e(see,XCr),e(b4,zCr),e(U,QCr),e(U,v4),e(v4,x0e),e(x0e,WCr),e(v4,UCr),e(v4,lee),e(lee,HCr),e(v4,JCr),e(U,YCr),e(U,F4),e(F4,$0e),e($0e,ZCr),e(F4,KCr),e(F4,iee),e(iee,e3r),e(F4,o3r),e(U,r3r),e(U,T4),e(T4,k0e),e(k0e,t3r),e(T4,a3r),e(T4,dee),e(dee,n3r),e(T4,s3r),e(U,l3r),e(U,M4),e(M4,S0e),e(S0e,i3r),e(M4,d3r),e(M4,mee),e(mee,m3r),e(M4,c3r),e(U,f3r),e(U,E4),e(E4,R0e),e(R0e,g3r),e(E4,h3r),e(E4,cee),e(cee,u3r),e(E4,p3r),e(U,_3r),e(U,C4),e(C4,P0e),e(P0e,b3r),e(C4,v3r),e(C4,fee),e(fee,F3r),e(C4,T3r),e(U,M3r),e(U,w4),e(w4,B0e),e(B0e,E3r),e(w4,C3r),e(w4,gee),e(gee,w3r),e(w4,A3r),e(U,L3r),e(U,A4),e(A4,I0e),e(I0e,y3r),e(A4,x3r),e(A4,hee),e(hee,$3r),e(A4,k3r),e(U,S3r),e(U,L4),e(L4,N0e),e(N0e,R3r),e(L4,P3r),e(L4,uee),e(uee,B3r),e(L4,I3r),e(U,N3r),e(U,y4),e(y4,q0e),e(q0e,q3r),e(y4,D3r),e(y4,pee),e(pee,j3r),e(y4,G3r),e(U,O3r),e(U,x4),e(x4,D0e),e(D0e,V3r),e(x4,X3r),e(x4,_ee),e(_ee,z3r),e(x4,Q3r),e(U,W3r),e(U,$4),e($4,j0e),e(j0e,U3r),e($4,H3r),e($4,bee),e(bee,J3r),e($4,Y3r),e(U,Z3r),e(U,k4),e(k4,G0e),e(G0e,K3r),e(k4,e5r),e(k4,vee),e(vee,o5r),e(k4,r5r),e(U,t5r),e(U,S4),e(S4,O0e),e(O0e,a5r),e(S4,n5r),e(S4,Fee),e(Fee,s5r),e(S4,l5r),e(U,i5r),e(U,R4),e(R4,V0e),e(V0e,d5r),e(R4,m5r),e(R4,Tee),e(Tee,c5r),e(R4,f5r),e(U,g5r),e(U,P4),e(P4,X0e),e(X0e,h5r),e(P4,u5r),e(P4,Mee),e(Mee,p5r),e(P4,_5r),e(U,b5r),e(U,B4),e(B4,z0e),e(z0e,v5r),e(B4,F5r),e(B4,Eee),e(Eee,T5r),e(B4,M5r),e(U,E5r),e(U,I4),e(I4,Q0e),e(Q0e,C5r),e(I4,w5r),e(I4,Cee),e(Cee,A5r),e(I4,L5r),e(U,y5r),e(U,N4),e(N4,W0e),e(W0e,x5r),e(N4,$5r),e(N4,wee),e(wee,k5r),e(N4,S5r),e(U,R5r),e(U,q4),e(q4,U0e),e(U0e,P5r),e(q4,B5r),e(q4,Aee),e(Aee,I5r),e(q4,N5r),e(U,q5r),e(U,D4),e(D4,H0e),e(H0e,D5r),e(D4,j5r),e(D4,Lee),e(Lee,G5r),e(D4,O5r),e(U,V5r),e(U,j4),e(j4,J0e),e(J0e,X5r),e(j4,z5r),e(j4,yee),e(yee,Q5r),e(j4,W5r),e(U,U5r),e(U,G4),e(G4,Y0e),e(Y0e,H5r),e(G4,J5r),e(G4,xee),e(xee,Y5r),e(G4,Z5r),e(U,K5r),e(U,O4),e(O4,Z0e),e(Z0e,e0r),e(O4,o0r),e(O4,$ee),e($ee,r0r),e(O4,t0r),e(U,a0r),e(U,V4),e(V4,K0e),e(K0e,n0r),e(V4,s0r),e(V4,kee),e(kee,l0r),e(V4,i0r),e(U,d0r),e(U,X4),e(X4,ewe),e(ewe,m0r),e(X4,c0r),e(X4,See),e(See,f0r),e(X4,g0r),e(U,h0r),e(U,z4),e(z4,owe),e(owe,u0r),e(z4,p0r),e(z4,Ree),e(Ree,_0r),e(z4,b0r),e(U,v0r),e(U,Q4),e(Q4,rwe),e(rwe,F0r),e(Q4,T0r),e(Q4,Pee),e(Pee,M0r),e(Q4,E0r),e(U,C0r),e(U,W4),e(W4,twe),e(twe,w0r),e(W4,A0r),e(W4,Bee),e(Bee,L0r),e(W4,y0r),e(U,x0r),e(U,U4),e(U4,awe),e(awe,$0r),e(U4,k0r),e(U4,Iee),e(Iee,S0r),e(U4,R0r),e(U,P0r),e(U,H4),e(H4,nwe),e(nwe,B0r),e(H4,I0r),e(H4,Nee),e(Nee,N0r),e(H4,q0r),e(U,D0r),e(U,J4),e(J4,swe),e(swe,j0r),e(J4,G0r),e(J4,qee),e(qee,O0r),e(J4,V0r),e(U,X0r),e(U,Y4),e(Y4,lwe),e(lwe,z0r),e(Y4,Q0r),e(Y4,Dee),e(Dee,W0r),e(Y4,U0r),e(U,H0r),e(U,Z4),e(Z4,iwe),e(iwe,J0r),e(Z4,Y0r),e(Z4,jee),e(jee,Z0r),e(Z4,K0r),e(U,ewr),e(U,K4),e(K4,dwe),e(dwe,owr),e(K4,rwr),e(K4,Gee),e(Gee,twr),e(K4,awr),e(go,nwr),e(go,eC),e(eC,swr),e(eC,mwe),e(mwe,lwr),e(eC,iwr),e(eC,cwe),e(cwe,dwr),e(go,mwr),M(oC,go,null),b(c,Ylo,_),b(c,_m,_),e(_m,rC),e(rC,fwe),M(GS,fwe,null),e(_m,cwr),e(_m,gwe),e(gwe,fwr),b(c,Zlo,_),b(c,Jo,_),M(OS,Jo,null),e(Jo,gwr),e(Jo,bm),e(bm,hwr),e(bm,Oee),e(Oee,uwr),e(bm,pwr),e(bm,Vee),e(Vee,_wr),e(bm,bwr),e(Jo,vwr),e(Jo,VS),e(VS,Fwr),e(VS,hwe),e(hwe,Twr),e(VS,Mwr),e(Jo,Ewr),e(Jo,It),M(XS,It,null),e(It,Cwr),e(It,uwe),e(uwe,wwr),e(It,Awr),e(It,vm),e(vm,Lwr),e(vm,pwe),e(pwe,ywr),e(vm,xwr),e(vm,Xee),e(Xee,$wr),e(vm,kwr),e(It,Swr),M(tC,It,null),e(Jo,Rwr),e(Jo,ho),M(zS,ho,null),e(ho,Pwr),e(ho,_we),e(_we,Bwr),e(ho,Iwr),e(ho,Mn),e(Mn,Nwr),e(Mn,bwe),e(bwe,qwr),e(Mn,Dwr),e(Mn,vwe),e(vwe,jwr),e(Mn,Gwr),e(Mn,Fwe),e(Fwe,Owr),e(Mn,Vwr),e(ho,Xwr),e(ho,O),e(O,aC),e(aC,Twe),e(Twe,zwr),e(aC,Qwr),e(aC,zee),e(zee,Wwr),e(aC,Uwr),e(O,Hwr),e(O,nC),e(nC,Mwe),e(Mwe,Jwr),e(nC,Ywr),e(nC,Qee),e(Qee,Zwr),e(nC,Kwr),e(O,eAr),e(O,sC),e(sC,Ewe),e(Ewe,oAr),e(sC,rAr),e(sC,Wee),e(Wee,tAr),e(sC,aAr),e(O,nAr),e(O,lC),e(lC,Cwe),e(Cwe,sAr),e(lC,lAr),e(lC,Uee),e(Uee,iAr),e(lC,dAr),e(O,mAr),e(O,iC),e(iC,wwe),e(wwe,cAr),e(iC,fAr),e(iC,Hee),e(Hee,gAr),e(iC,hAr),e(O,uAr),e(O,dC),e(dC,Awe),e(Awe,pAr),e(dC,_Ar),e(dC,Jee),e(Jee,bAr),e(dC,vAr),e(O,FAr),e(O,mC),e(mC,Lwe),e(Lwe,TAr),e(mC,MAr),e(mC,Yee),e(Yee,EAr),e(mC,CAr),e(O,wAr),e(O,cC),e(cC,ywe),e(ywe,AAr),e(cC,LAr),e(cC,Zee),e(Zee,yAr),e(cC,xAr),e(O,$Ar),e(O,fC),e(fC,xwe),e(xwe,kAr),e(fC,SAr),e(fC,Kee),e(Kee,RAr),e(fC,PAr),e(O,BAr),e(O,gC),e(gC,$we),e($we,IAr),e(gC,NAr),e(gC,eoe),e(eoe,qAr),e(gC,DAr),e(O,jAr),e(O,hC),e(hC,kwe),e(kwe,GAr),e(hC,OAr),e(hC,ooe),e(ooe,VAr),e(hC,XAr),e(O,zAr),e(O,uC),e(uC,Swe),e(Swe,QAr),e(uC,WAr),e(uC,roe),e(roe,UAr),e(uC,HAr),e(O,JAr),e(O,pC),e(pC,Rwe),e(Rwe,YAr),e(pC,ZAr),e(pC,toe),e(toe,KAr),e(pC,e6r),e(O,o6r),e(O,_C),e(_C,Pwe),e(Pwe,r6r),e(_C,t6r),e(_C,aoe),e(aoe,a6r),e(_C,n6r),e(O,s6r),e(O,bC),e(bC,Bwe),e(Bwe,l6r),e(bC,i6r),e(bC,noe),e(noe,d6r),e(bC,m6r),e(O,c6r),e(O,vC),e(vC,Iwe),e(Iwe,f6r),e(vC,g6r),e(vC,soe),e(soe,h6r),e(vC,u6r),e(O,p6r),e(O,FC),e(FC,Nwe),e(Nwe,_6r),e(FC,b6r),e(FC,loe),e(loe,v6r),e(FC,F6r),e(O,T6r),e(O,TC),e(TC,qwe),e(qwe,M6r),e(TC,E6r),e(TC,ioe),e(ioe,C6r),e(TC,w6r),e(O,A6r),e(O,MC),e(MC,Dwe),e(Dwe,L6r),e(MC,y6r),e(MC,doe),e(doe,x6r),e(MC,$6r),e(O,k6r),e(O,EC),e(EC,jwe),e(jwe,S6r),e(EC,R6r),e(EC,moe),e(moe,P6r),e(EC,B6r),e(O,I6r),e(O,CC),e(CC,Gwe),e(Gwe,N6r),e(CC,q6r),e(CC,coe),e(coe,D6r),e(CC,j6r),e(O,G6r),e(O,wC),e(wC,Owe),e(Owe,O6r),e(wC,V6r),e(wC,foe),e(foe,X6r),e(wC,z6r),e(O,Q6r),e(O,AC),e(AC,Vwe),e(Vwe,W6r),e(AC,U6r),e(AC,goe),e(goe,H6r),e(AC,J6r),e(O,Y6r),e(O,LC),e(LC,Xwe),e(Xwe,Z6r),e(LC,K6r),e(LC,hoe),e(hoe,e7r),e(LC,o7r),e(O,r7r),e(O,yC),e(yC,zwe),e(zwe,t7r),e(yC,a7r),e(yC,uoe),e(uoe,n7r),e(yC,s7r),e(O,l7r),e(O,xC),e(xC,Qwe),e(Qwe,i7r),e(xC,d7r),e(xC,poe),e(poe,m7r),e(xC,c7r),e(O,f7r),e(O,$C),e($C,Wwe),e(Wwe,g7r),e($C,h7r),e($C,_oe),e(_oe,u7r),e($C,p7r),e(O,_7r),e(O,kC),e(kC,Uwe),e(Uwe,b7r),e(kC,v7r),e(kC,boe),e(boe,F7r),e(kC,T7r),e(O,M7r),e(O,SC),e(SC,Hwe),e(Hwe,E7r),e(SC,C7r),e(SC,voe),e(voe,w7r),e(SC,A7r),e(O,L7r),e(O,RC),e(RC,Jwe),e(Jwe,y7r),e(RC,x7r),e(RC,Foe),e(Foe,$7r),e(RC,k7r),e(O,S7r),e(O,PC),e(PC,Ywe),e(Ywe,R7r),e(PC,P7r),e(PC,Toe),e(Toe,B7r),e(PC,I7r),e(O,N7r),e(O,BC),e(BC,Zwe),e(Zwe,q7r),e(BC,D7r),e(BC,Moe),e(Moe,j7r),e(BC,G7r),e(O,O7r),e(O,IC),e(IC,Kwe),e(Kwe,V7r),e(IC,X7r),e(IC,Eoe),e(Eoe,z7r),e(IC,Q7r),e(O,W7r),e(O,NC),e(NC,eAe),e(eAe,U7r),e(NC,H7r),e(NC,Coe),e(Coe,J7r),e(NC,Y7r),e(O,Z7r),e(O,qC),e(qC,oAe),e(oAe,K7r),e(qC,e8r),e(qC,woe),e(woe,o8r),e(qC,r8r),e(O,t8r),e(O,DC),e(DC,rAe),e(rAe,a8r),e(DC,n8r),e(DC,Aoe),e(Aoe,s8r),e(DC,l8r),e(O,i8r),e(O,jC),e(jC,tAe),e(tAe,d8r),e(jC,m8r),e(jC,Loe),e(Loe,c8r),e(jC,f8r),e(O,g8r),e(O,GC),e(GC,aAe),e(aAe,h8r),e(GC,u8r),e(GC,yoe),e(yoe,p8r),e(GC,_8r),e(O,b8r),e(O,OC),e(OC,nAe),e(nAe,v8r),e(OC,F8r),e(OC,xoe),e(xoe,T8r),e(OC,M8r),e(O,E8r),e(O,VC),e(VC,sAe),e(sAe,C8r),e(VC,w8r),e(VC,$oe),e($oe,A8r),e(VC,L8r),e(O,y8r),e(O,XC),e(XC,lAe),e(lAe,x8r),e(XC,$8r),e(XC,koe),e(koe,k8r),e(XC,S8r),e(O,R8r),e(O,zC),e(zC,iAe),e(iAe,P8r),e(zC,B8r),e(zC,Soe),e(Soe,I8r),e(zC,N8r),e(O,q8r),e(O,QC),e(QC,dAe),e(dAe,D8r),e(QC,j8r),e(QC,Roe),e(Roe,G8r),e(QC,O8r),e(O,V8r),e(O,WC),e(WC,mAe),e(mAe,X8r),e(WC,z8r),e(WC,Poe),e(Poe,Q8r),e(WC,W8r),e(O,U8r),e(O,UC),e(UC,cAe),e(cAe,H8r),e(UC,J8r),e(UC,Boe),e(Boe,Y8r),e(UC,Z8r),e(O,K8r),e(O,HC),e(HC,fAe),e(fAe,eLr),e(HC,oLr),e(HC,Ioe),e(Ioe,rLr),e(HC,tLr),e(O,aLr),e(O,JC),e(JC,gAe),e(gAe,nLr),e(JC,sLr),e(JC,Noe),e(Noe,lLr),e(JC,iLr),e(O,dLr),e(O,YC),e(YC,hAe),e(hAe,mLr),e(YC,cLr),e(YC,qoe),e(qoe,fLr),e(YC,gLr),e(O,hLr),e(O,ZC),e(ZC,uAe),e(uAe,uLr),e(ZC,pLr),e(ZC,Doe),e(Doe,_Lr),e(ZC,bLr),e(ho,vLr),e(ho,KC),e(KC,FLr),e(KC,pAe),e(pAe,TLr),e(KC,MLr),e(KC,_Ae),e(_Ae,ELr),e(ho,CLr),M(e3,ho,null),b(c,Klo,_),b(c,Fm,_),e(Fm,o3),e(o3,bAe),M(QS,bAe,null),e(Fm,wLr),e(Fm,vAe),e(vAe,ALr),b(c,eio,_),b(c,Yo,_),M(WS,Yo,null),e(Yo,LLr),e(Yo,Tm),e(Tm,yLr),e(Tm,joe),e(joe,xLr),e(Tm,$Lr),e(Tm,Goe),e(Goe,kLr),e(Tm,SLr),e(Yo,RLr),e(Yo,US),e(US,PLr),e(US,FAe),e(FAe,BLr),e(US,ILr),e(Yo,NLr),e(Yo,Nt),M(HS,Nt,null),e(Nt,qLr),e(Nt,TAe),e(TAe,DLr),e(Nt,jLr),e(Nt,Mm),e(Mm,GLr),e(Mm,MAe),e(MAe,OLr),e(Mm,VLr),e(Mm,Ooe),e(Ooe,XLr),e(Mm,zLr),e(Nt,QLr),M(r3,Nt,null),e(Yo,WLr),e(Yo,uo),M(JS,uo,null),e(uo,ULr),e(uo,EAe),e(EAe,HLr),e(uo,JLr),e(uo,En),e(En,YLr),e(En,CAe),e(CAe,ZLr),e(En,KLr),e(En,wAe),e(wAe,eyr),e(En,oyr),e(En,AAe),e(AAe,ryr),e(En,tyr),e(uo,ayr),e(uo,LAe),e(LAe,t3),e(t3,yAe),e(yAe,nyr),e(t3,syr),e(t3,Voe),e(Voe,lyr),e(t3,iyr),e(uo,dyr),e(uo,a3),e(a3,myr),e(a3,xAe),e(xAe,cyr),e(a3,fyr),e(a3,$Ae),e($Ae,gyr),e(uo,hyr),M(n3,uo,null),b(c,oio,_),b(c,Em,_),e(Em,s3),e(s3,kAe),M(YS,kAe,null),e(Em,uyr),e(Em,SAe),e(SAe,pyr),b(c,rio,_),b(c,Zo,_),M(ZS,Zo,null),e(Zo,_yr),e(Zo,Cm),e(Cm,byr),e(Cm,Xoe),e(Xoe,vyr),e(Cm,Fyr),e(Cm,zoe),e(zoe,Tyr),e(Cm,Myr),e(Zo,Eyr),e(Zo,KS),e(KS,Cyr),e(KS,RAe),e(RAe,wyr),e(KS,Ayr),e(Zo,Lyr),e(Zo,qt),M(eR,qt,null),e(qt,yyr),e(qt,PAe),e(PAe,xyr),e(qt,$yr),e(qt,wm),e(wm,kyr),e(wm,BAe),e(BAe,Syr),e(wm,Ryr),e(wm,Qoe),e(Qoe,Pyr),e(wm,Byr),e(qt,Iyr),M(l3,qt,null),e(Zo,Nyr),e(Zo,po),M(oR,po,null),e(po,qyr),e(po,IAe),e(IAe,Dyr),e(po,jyr),e(po,Cn),e(Cn,Gyr),e(Cn,NAe),e(NAe,Oyr),e(Cn,Vyr),e(Cn,qAe),e(qAe,Xyr),e(Cn,zyr),e(Cn,DAe),e(DAe,Qyr),e(Cn,Wyr),e(po,Uyr),e(po,Am),e(Am,i3),e(i3,jAe),e(jAe,Hyr),e(i3,Jyr),e(i3,Woe),e(Woe,Yyr),e(i3,Zyr),e(Am,Kyr),e(Am,d3),e(d3,GAe),e(GAe,e9r),e(d3,o9r),e(d3,Uoe),e(Uoe,r9r),e(d3,t9r),e(Am,a9r),e(Am,m3),e(m3,OAe),e(OAe,n9r),e(m3,s9r),e(m3,Hoe),e(Hoe,l9r),e(m3,i9r),e(po,d9r),e(po,c3),e(c3,m9r),e(c3,VAe),e(VAe,c9r),e(c3,f9r),e(c3,XAe),e(XAe,g9r),e(po,h9r),M(f3,po,null),b(c,tio,_),b(c,Lm,_),e(Lm,g3),e(g3,zAe),M(rR,zAe,null),e(Lm,u9r),e(Lm,QAe),e(QAe,p9r),b(c,aio,_),b(c,Ko,_),M(tR,Ko,null),e(Ko,_9r),e(Ko,ym),e(ym,b9r),e(ym,Joe),e(Joe,v9r),e(ym,F9r),e(ym,Yoe),e(Yoe,T9r),e(ym,M9r),e(Ko,E9r),e(Ko,aR),e(aR,C9r),e(aR,WAe),e(WAe,w9r),e(aR,A9r),e(Ko,L9r),e(Ko,Dt),M(nR,Dt,null),e(Dt,y9r),e(Dt,UAe),e(UAe,x9r),e(Dt,$9r),e(Dt,xm),e(xm,k9r),e(xm,HAe),e(HAe,S9r),e(xm,R9r),e(xm,Zoe),e(Zoe,P9r),e(xm,B9r),e(Dt,I9r),M(h3,Dt,null),e(Ko,N9r),e(Ko,_o),M(sR,_o,null),e(_o,q9r),e(_o,JAe),e(JAe,D9r),e(_o,j9r),e(_o,wn),e(wn,G9r),e(wn,YAe),e(YAe,O9r),e(wn,V9r),e(wn,ZAe),e(ZAe,X9r),e(wn,z9r),e(wn,KAe),e(KAe,Q9r),e(wn,W9r),e(_o,U9r),e(_o,Fe),e(Fe,u3),e(u3,e6e),e(e6e,H9r),e(u3,J9r),e(u3,Koe),e(Koe,Y9r),e(u3,Z9r),e(Fe,K9r),e(Fe,p3),e(p3,o6e),e(o6e,exr),e(p3,oxr),e(p3,ere),e(ere,rxr),e(p3,txr),e(Fe,axr),e(Fe,_3),e(_3,r6e),e(r6e,nxr),e(_3,sxr),e(_3,ore),e(ore,lxr),e(_3,ixr),e(Fe,dxr),e(Fe,b3),e(b3,t6e),e(t6e,mxr),e(b3,cxr),e(b3,rre),e(rre,fxr),e(b3,gxr),e(Fe,hxr),e(Fe,Nl),e(Nl,a6e),e(a6e,uxr),e(Nl,pxr),e(Nl,tre),e(tre,_xr),e(Nl,bxr),e(Nl,are),e(are,vxr),e(Nl,Fxr),e(Fe,Txr),e(Fe,v3),e(v3,n6e),e(n6e,Mxr),e(v3,Exr),e(v3,nre),e(nre,Cxr),e(v3,wxr),e(Fe,Axr),e(Fe,ql),e(ql,s6e),e(s6e,Lxr),e(ql,yxr),e(ql,sre),e(sre,xxr),e(ql,$xr),e(ql,lre),e(lre,kxr),e(ql,Sxr),e(Fe,Rxr),e(Fe,F3),e(F3,l6e),e(l6e,Pxr),e(F3,Bxr),e(F3,ire),e(ire,Ixr),e(F3,Nxr),e(Fe,qxr),e(Fe,jt),e(jt,i6e),e(i6e,Dxr),e(jt,jxr),e(jt,dre),e(dre,Gxr),e(jt,Oxr),e(jt,mre),e(mre,Vxr),e(jt,Xxr),e(jt,cre),e(cre,zxr),e(jt,Qxr),e(Fe,Wxr),e(Fe,T3),e(T3,d6e),e(d6e,Uxr),e(T3,Hxr),e(T3,fre),e(fre,Jxr),e(T3,Yxr),e(Fe,Zxr),e(Fe,M3),e(M3,m6e),e(m6e,Kxr),e(M3,e$r),e(M3,gre),e(gre,o$r),e(M3,r$r),e(Fe,t$r),e(Fe,E3),e(E3,c6e),e(c6e,a$r),e(E3,n$r),e(E3,hre),e(hre,s$r),e(E3,l$r),e(Fe,i$r),e(Fe,C3),e(C3,f6e),e(f6e,d$r),e(C3,m$r),e(C3,ure),e(ure,c$r),e(C3,f$r),e(Fe,g$r),e(Fe,w3),e(w3,g6e),e(g6e,h$r),e(w3,u$r),e(w3,pre),e(pre,p$r),e(w3,_$r),e(Fe,b$r),e(Fe,A3),e(A3,h6e),e(h6e,v$r),e(A3,F$r),e(A3,_re),e(_re,T$r),e(A3,M$r),e(Fe,E$r),e(Fe,L3),e(L3,u6e),e(u6e,C$r),e(L3,w$r),e(L3,bre),e(bre,A$r),e(L3,L$r),e(Fe,y$r),e(Fe,y3),e(y3,p6e),e(p6e,x$r),e(y3,$$r),e(y3,vre),e(vre,k$r),e(y3,S$r),e(Fe,R$r),e(Fe,x3),e(x3,_6e),e(_6e,P$r),e(x3,B$r),e(x3,Fre),e(Fre,I$r),e(x3,N$r),e(_o,q$r),e(_o,$3),e($3,D$r),e($3,b6e),e(b6e,j$r),e($3,G$r),e($3,v6e),e(v6e,O$r),e(_o,V$r),M(k3,_o,null),b(c,nio,_),b(c,$m,_),e($m,S3),e(S3,F6e),M(lR,F6e,null),e($m,X$r),e($m,T6e),e(T6e,z$r),b(c,sio,_),b(c,er,_),M(iR,er,null),e(er,Q$r),e(er,km),e(km,W$r),e(km,Tre),e(Tre,U$r),e(km,H$r),e(km,Mre),e(Mre,J$r),e(km,Y$r),e(er,Z$r),e(er,dR),e(dR,K$r),e(dR,M6e),e(M6e,ekr),e(dR,okr),e(er,rkr),e(er,Gt),M(mR,Gt,null),e(Gt,tkr),e(Gt,E6e),e(E6e,akr),e(Gt,nkr),e(Gt,Sm),e(Sm,skr),e(Sm,C6e),e(C6e,lkr),e(Sm,ikr),e(Sm,Ere),e(Ere,dkr),e(Sm,mkr),e(Gt,ckr),M(R3,Gt,null),e(er,fkr),e(er,bo),M(cR,bo,null),e(bo,gkr),e(bo,w6e),e(w6e,hkr),e(bo,ukr),e(bo,An),e(An,pkr),e(An,A6e),e(A6e,_kr),e(An,bkr),e(An,L6e),e(L6e,vkr),e(An,Fkr),e(An,y6e),e(y6e,Tkr),e(An,Mkr),e(bo,Ekr),e(bo,x6e),e(x6e,P3),e(P3,$6e),e($6e,Ckr),e(P3,wkr),e(P3,Cre),e(Cre,Akr),e(P3,Lkr),e(bo,ykr),e(bo,B3),e(B3,xkr),e(B3,k6e),e(k6e,$kr),e(B3,kkr),e(B3,S6e),e(S6e,Skr),e(bo,Rkr),M(I3,bo,null),b(c,lio,_),b(c,Rm,_),e(Rm,N3),e(N3,R6e),M(fR,R6e,null),e(Rm,Pkr),e(Rm,P6e),e(P6e,Bkr),b(c,iio,_),b(c,or,_),M(gR,or,null),e(or,Ikr),e(or,Pm),e(Pm,Nkr),e(Pm,wre),e(wre,qkr),e(Pm,Dkr),e(Pm,Are),e(Are,jkr),e(Pm,Gkr),e(or,Okr),e(or,hR),e(hR,Vkr),e(hR,B6e),e(B6e,Xkr),e(hR,zkr),e(or,Qkr),e(or,Ot),M(uR,Ot,null),e(Ot,Wkr),e(Ot,I6e),e(I6e,Ukr),e(Ot,Hkr),e(Ot,Bm),e(Bm,Jkr),e(Bm,N6e),e(N6e,Ykr),e(Bm,Zkr),e(Bm,Lre),e(Lre,Kkr),e(Bm,eSr),e(Ot,oSr),M(q3,Ot,null),e(or,rSr),e(or,vo),M(pR,vo,null),e(vo,tSr),e(vo,q6e),e(q6e,aSr),e(vo,nSr),e(vo,Ln),e(Ln,sSr),e(Ln,D6e),e(D6e,lSr),e(Ln,iSr),e(Ln,j6e),e(j6e,dSr),e(Ln,mSr),e(Ln,G6e),e(G6e,cSr),e(Ln,fSr),e(vo,gSr),e(vo,O6e),e(O6e,D3),e(D3,V6e),e(V6e,hSr),e(D3,uSr),e(D3,yre),e(yre,pSr),e(D3,_Sr),e(vo,bSr),e(vo,j3),e(j3,vSr),e(j3,X6e),e(X6e,FSr),e(j3,TSr),e(j3,z6e),e(z6e,MSr),e(vo,ESr),M(G3,vo,null),b(c,dio,_),b(c,Im,_),e(Im,O3),e(O3,Q6e),M(_R,Q6e,null),e(Im,CSr),e(Im,W6e),e(W6e,wSr),b(c,mio,_),b(c,rr,_),M(bR,rr,null),e(rr,ASr),e(rr,Nm),e(Nm,LSr),e(Nm,xre),e(xre,ySr),e(Nm,xSr),e(Nm,$re),e($re,$Sr),e(Nm,kSr),e(rr,SSr),e(rr,vR),e(vR,RSr),e(vR,U6e),e(U6e,PSr),e(vR,BSr),e(rr,ISr),e(rr,Vt),M(FR,Vt,null),e(Vt,NSr),e(Vt,H6e),e(H6e,qSr),e(Vt,DSr),e(Vt,qm),e(qm,jSr),e(qm,J6e),e(J6e,GSr),e(qm,OSr),e(qm,kre),e(kre,VSr),e(qm,XSr),e(Vt,zSr),M(V3,Vt,null),e(rr,QSr),e(rr,Fo),M(TR,Fo,null),e(Fo,WSr),e(Fo,Y6e),e(Y6e,USr),e(Fo,HSr),e(Fo,yn),e(yn,JSr),e(yn,Z6e),e(Z6e,YSr),e(yn,ZSr),e(yn,K6e),e(K6e,KSr),e(yn,eRr),e(yn,e7e),e(e7e,oRr),e(yn,rRr),e(Fo,tRr),e(Fo,o7e),e(o7e,X3),e(X3,r7e),e(r7e,aRr),e(X3,nRr),e(X3,Sre),e(Sre,sRr),e(X3,lRr),e(Fo,iRr),e(Fo,z3),e(z3,dRr),e(z3,t7e),e(t7e,mRr),e(z3,cRr),e(z3,a7e),e(a7e,fRr),e(Fo,gRr),M(Q3,Fo,null),b(c,cio,_),b(c,Dm,_),e(Dm,W3),e(W3,n7e),M(MR,n7e,null),e(Dm,hRr),e(Dm,s7e),e(s7e,uRr),b(c,fio,_),b(c,tr,_),M(ER,tr,null),e(tr,pRr),e(tr,jm),e(jm,_Rr),e(jm,Rre),e(Rre,bRr),e(jm,vRr),e(jm,Pre),e(Pre,FRr),e(jm,TRr),e(tr,MRr),e(tr,CR),e(CR,ERr),e(CR,l7e),e(l7e,CRr),e(CR,wRr),e(tr,ARr),e(tr,Xt),M(wR,Xt,null),e(Xt,LRr),e(Xt,i7e),e(i7e,yRr),e(Xt,xRr),e(Xt,Gm),e(Gm,$Rr),e(Gm,d7e),e(d7e,kRr),e(Gm,SRr),e(Gm,Bre),e(Bre,RRr),e(Gm,PRr),e(Xt,BRr),M(U3,Xt,null),e(tr,IRr),e(tr,To),M(AR,To,null),e(To,NRr),e(To,m7e),e(m7e,qRr),e(To,DRr),e(To,xn),e(xn,jRr),e(xn,c7e),e(c7e,GRr),e(xn,ORr),e(xn,f7e),e(f7e,VRr),e(xn,XRr),e(xn,g7e),e(g7e,zRr),e(xn,QRr),e(To,WRr),e(To,Ne),e(Ne,H3),e(H3,h7e),e(h7e,URr),e(H3,HRr),e(H3,Ire),e(Ire,JRr),e(H3,YRr),e(Ne,ZRr),e(Ne,J3),e(J3,u7e),e(u7e,KRr),e(J3,ePr),e(J3,Nre),e(Nre,oPr),e(J3,rPr),e(Ne,tPr),e(Ne,Y3),e(Y3,p7e),e(p7e,aPr),e(Y3,nPr),e(Y3,qre),e(qre,sPr),e(Y3,lPr),e(Ne,iPr),e(Ne,Z3),e(Z3,_7e),e(_7e,dPr),e(Z3,mPr),e(Z3,Dre),e(Dre,cPr),e(Z3,fPr),e(Ne,gPr),e(Ne,K3),e(K3,b7e),e(b7e,hPr),e(K3,uPr),e(K3,jre),e(jre,pPr),e(K3,_Pr),e(Ne,bPr),e(Ne,e5),e(e5,v7e),e(v7e,vPr),e(e5,FPr),e(e5,Gre),e(Gre,TPr),e(e5,MPr),e(Ne,EPr),e(Ne,o5),e(o5,F7e),e(F7e,CPr),e(o5,wPr),e(o5,Ore),e(Ore,APr),e(o5,LPr),e(Ne,yPr),e(Ne,r5),e(r5,T7e),e(T7e,xPr),e(r5,$Pr),e(r5,Vre),e(Vre,kPr),e(r5,SPr),e(Ne,RPr),e(Ne,t5),e(t5,M7e),e(M7e,PPr),e(t5,BPr),e(t5,Xre),e(Xre,IPr),e(t5,NPr),e(To,qPr),e(To,a5),e(a5,DPr),e(a5,E7e),e(E7e,jPr),e(a5,GPr),e(a5,C7e),e(C7e,OPr),e(To,VPr),M(n5,To,null),b(c,gio,_),b(c,Om,_),e(Om,s5),e(s5,w7e),M(LR,w7e,null),e(Om,XPr),e(Om,A7e),e(A7e,zPr),b(c,hio,_),b(c,ar,_),M(yR,ar,null),e(ar,QPr),e(ar,Vm),e(Vm,WPr),e(Vm,zre),e(zre,UPr),e(Vm,HPr),e(Vm,Qre),e(Qre,JPr),e(Vm,YPr),e(ar,ZPr),e(ar,xR),e(xR,KPr),e(xR,L7e),e(L7e,eBr),e(xR,oBr),e(ar,rBr),e(ar,zt),M($R,zt,null),e(zt,tBr),e(zt,y7e),e(y7e,aBr),e(zt,nBr),e(zt,Xm),e(Xm,sBr),e(Xm,x7e),e(x7e,lBr),e(Xm,iBr),e(Xm,Wre),e(Wre,dBr),e(Xm,mBr),e(zt,cBr),M(l5,zt,null),e(ar,fBr),e(ar,Mo),M(kR,Mo,null),e(Mo,gBr),e(Mo,$7e),e($7e,hBr),e(Mo,uBr),e(Mo,$n),e($n,pBr),e($n,k7e),e(k7e,_Br),e($n,bBr),e($n,S7e),e(S7e,vBr),e($n,FBr),e($n,R7e),e(R7e,TBr),e($n,MBr),e(Mo,EBr),e(Mo,vt),e(vt,i5),e(i5,P7e),e(P7e,CBr),e(i5,wBr),e(i5,Ure),e(Ure,ABr),e(i5,LBr),e(vt,yBr),e(vt,d5),e(d5,B7e),e(B7e,xBr),e(d5,$Br),e(d5,Hre),e(Hre,kBr),e(d5,SBr),e(vt,RBr),e(vt,m5),e(m5,I7e),e(I7e,PBr),e(m5,BBr),e(m5,Jre),e(Jre,IBr),e(m5,NBr),e(vt,qBr),e(vt,c5),e(c5,N7e),e(N7e,DBr),e(c5,jBr),e(c5,Yre),e(Yre,GBr),e(c5,OBr),e(vt,VBr),e(vt,f5),e(f5,q7e),e(q7e,XBr),e(f5,zBr),e(f5,Zre),e(Zre,QBr),e(f5,WBr),e(Mo,UBr),e(Mo,g5),e(g5,HBr),e(g5,D7e),e(D7e,JBr),e(g5,YBr),e(g5,j7e),e(j7e,ZBr),e(Mo,KBr),M(h5,Mo,null),b(c,uio,_),b(c,zm,_),e(zm,u5),e(u5,G7e),M(SR,G7e,null),e(zm,eIr),e(zm,O7e),e(O7e,oIr),b(c,pio,_),b(c,nr,_),M(RR,nr,null),e(nr,rIr),e(nr,Qm),e(Qm,tIr),e(Qm,Kre),e(Kre,aIr),e(Qm,nIr),e(Qm,ete),e(ete,sIr),e(Qm,lIr),e(nr,iIr),e(nr,PR),e(PR,dIr),e(PR,V7e),e(V7e,mIr),e(PR,cIr),e(nr,fIr),e(nr,Qt),M(BR,Qt,null),e(Qt,gIr),e(Qt,X7e),e(X7e,hIr),e(Qt,uIr),e(Qt,Wm),e(Wm,pIr),e(Wm,z7e),e(z7e,_Ir),e(Wm,bIr),e(Wm,ote),e(ote,vIr),e(Wm,FIr),e(Qt,TIr),M(p5,Qt,null),e(nr,MIr),e(nr,Eo),M(IR,Eo,null),e(Eo,EIr),e(Eo,Q7e),e(Q7e,CIr),e(Eo,wIr),e(Eo,kn),e(kn,AIr),e(kn,W7e),e(W7e,LIr),e(kn,yIr),e(kn,U7e),e(U7e,xIr),e(kn,$Ir),e(kn,H7e),e(H7e,kIr),e(kn,SIr),e(Eo,RIr),e(Eo,xe),e(xe,_5),e(_5,J7e),e(J7e,PIr),e(_5,BIr),e(_5,rte),e(rte,IIr),e(_5,NIr),e(xe,qIr),e(xe,b5),e(b5,Y7e),e(Y7e,DIr),e(b5,jIr),e(b5,tte),e(tte,GIr),e(b5,OIr),e(xe,VIr),e(xe,v5),e(v5,Z7e),e(Z7e,XIr),e(v5,zIr),e(v5,ate),e(ate,QIr),e(v5,WIr),e(xe,UIr),e(xe,F5),e(F5,K7e),e(K7e,HIr),e(F5,JIr),e(F5,nte),e(nte,YIr),e(F5,ZIr),e(xe,KIr),e(xe,T5),e(T5,e8e),e(e8e,eNr),e(T5,oNr),e(T5,ste),e(ste,rNr),e(T5,tNr),e(xe,aNr),e(xe,M5),e(M5,o8e),e(o8e,nNr),e(M5,sNr),e(M5,lte),e(lte,lNr),e(M5,iNr),e(xe,dNr),e(xe,E5),e(E5,r8e),e(r8e,mNr),e(E5,cNr),e(E5,ite),e(ite,fNr),e(E5,gNr),e(xe,hNr),e(xe,C5),e(C5,t8e),e(t8e,uNr),e(C5,pNr),e(C5,dte),e(dte,_Nr),e(C5,bNr),e(xe,vNr),e(xe,w5),e(w5,a8e),e(a8e,FNr),e(w5,TNr),e(w5,mte),e(mte,MNr),e(w5,ENr),e(xe,CNr),e(xe,A5),e(A5,n8e),e(n8e,wNr),e(A5,ANr),e(A5,cte),e(cte,LNr),e(A5,yNr),e(Eo,xNr),e(Eo,L5),e(L5,$Nr),e(L5,s8e),e(s8e,kNr),e(L5,SNr),e(L5,l8e),e(l8e,RNr),e(Eo,PNr),M(y5,Eo,null),b(c,_io,_),b(c,Um,_),e(Um,x5),e(x5,i8e),M(NR,i8e,null),e(Um,BNr),e(Um,d8e),e(d8e,INr),b(c,bio,_),b(c,sr,_),M(qR,sr,null),e(sr,NNr),e(sr,Hm),e(Hm,qNr),e(Hm,fte),e(fte,DNr),e(Hm,jNr),e(Hm,gte),e(gte,GNr),e(Hm,ONr),e(sr,VNr),e(sr,DR),e(DR,XNr),e(DR,m8e),e(m8e,zNr),e(DR,QNr),e(sr,WNr),e(sr,Wt),M(jR,Wt,null),e(Wt,UNr),e(Wt,c8e),e(c8e,HNr),e(Wt,JNr),e(Wt,Jm),e(Jm,YNr),e(Jm,f8e),e(f8e,ZNr),e(Jm,KNr),e(Jm,hte),e(hte,eqr),e(Jm,oqr),e(Wt,rqr),M($5,Wt,null),e(sr,tqr),e(sr,Co),M(GR,Co,null),e(Co,aqr),e(Co,g8e),e(g8e,nqr),e(Co,sqr),e(Co,Sn),e(Sn,lqr),e(Sn,h8e),e(h8e,iqr),e(Sn,dqr),e(Sn,u8e),e(u8e,mqr),e(Sn,cqr),e(Sn,p8e),e(p8e,fqr),e(Sn,gqr),e(Co,hqr),e(Co,Ym),e(Ym,k5),e(k5,_8e),e(_8e,uqr),e(k5,pqr),e(k5,ute),e(ute,_qr),e(k5,bqr),e(Ym,vqr),e(Ym,S5),e(S5,b8e),e(b8e,Fqr),e(S5,Tqr),e(S5,pte),e(pte,Mqr),e(S5,Eqr),e(Ym,Cqr),e(Ym,R5),e(R5,v8e),e(v8e,wqr),e(R5,Aqr),e(R5,_te),e(_te,Lqr),e(R5,yqr),e(Co,xqr),e(Co,P5),e(P5,$qr),e(P5,F8e),e(F8e,kqr),e(P5,Sqr),e(P5,T8e),e(T8e,Rqr),e(Co,Pqr),M(B5,Co,null),b(c,vio,_),b(c,Zm,_),e(Zm,I5),e(I5,M8e),M(OR,M8e,null),e(Zm,Bqr),e(Zm,E8e),e(E8e,Iqr),b(c,Fio,_),b(c,lr,_),M(VR,lr,null),e(lr,Nqr),e(lr,Km),e(Km,qqr),e(Km,bte),e(bte,Dqr),e(Km,jqr),e(Km,vte),e(vte,Gqr),e(Km,Oqr),e(lr,Vqr),e(lr,XR),e(XR,Xqr),e(XR,C8e),e(C8e,zqr),e(XR,Qqr),e(lr,Wqr),e(lr,Ut),M(zR,Ut,null),e(Ut,Uqr),e(Ut,w8e),e(w8e,Hqr),e(Ut,Jqr),e(Ut,ec),e(ec,Yqr),e(ec,A8e),e(A8e,Zqr),e(ec,Kqr),e(ec,Fte),e(Fte,eDr),e(ec,oDr),e(Ut,rDr),M(N5,Ut,null),e(lr,tDr),e(lr,wo),M(QR,wo,null),e(wo,aDr),e(wo,L8e),e(L8e,nDr),e(wo,sDr),e(wo,Rn),e(Rn,lDr),e(Rn,y8e),e(y8e,iDr),e(Rn,dDr),e(Rn,x8e),e(x8e,mDr),e(Rn,cDr),e(Rn,$8e),e($8e,fDr),e(Rn,gDr),e(wo,hDr),e(wo,Ft),e(Ft,q5),e(q5,k8e),e(k8e,uDr),e(q5,pDr),e(q5,Tte),e(Tte,_Dr),e(q5,bDr),e(Ft,vDr),e(Ft,D5),e(D5,S8e),e(S8e,FDr),e(D5,TDr),e(D5,Mte),e(Mte,MDr),e(D5,EDr),e(Ft,CDr),e(Ft,j5),e(j5,R8e),e(R8e,wDr),e(j5,ADr),e(j5,Ete),e(Ete,LDr),e(j5,yDr),e(Ft,xDr),e(Ft,G5),e(G5,P8e),e(P8e,$Dr),e(G5,kDr),e(G5,Cte),e(Cte,SDr),e(G5,RDr),e(Ft,PDr),e(Ft,O5),e(O5,B8e),e(B8e,BDr),e(O5,IDr),e(O5,wte),e(wte,NDr),e(O5,qDr),e(wo,DDr),e(wo,V5),e(V5,jDr),e(V5,I8e),e(I8e,GDr),e(V5,ODr),e(V5,N8e),e(N8e,VDr),e(wo,XDr),M(X5,wo,null),b(c,Tio,_),b(c,oc,_),e(oc,z5),e(z5,q8e),M(WR,q8e,null),e(oc,zDr),e(oc,D8e),e(D8e,QDr),b(c,Mio,_),b(c,ir,_),M(UR,ir,null),e(ir,WDr),e(ir,rc),e(rc,UDr),e(rc,Ate),e(Ate,HDr),e(rc,JDr),e(rc,Lte),e(Lte,YDr),e(rc,ZDr),e(ir,KDr),e(ir,HR),e(HR,ejr),e(HR,j8e),e(j8e,ojr),e(HR,rjr),e(ir,tjr),e(ir,Ht),M(JR,Ht,null),e(Ht,ajr),e(Ht,G8e),e(G8e,njr),e(Ht,sjr),e(Ht,tc),e(tc,ljr),e(tc,O8e),e(O8e,ijr),e(tc,djr),e(tc,yte),e(yte,mjr),e(tc,cjr),e(Ht,fjr),M(Q5,Ht,null),e(ir,gjr),e(ir,Ao),M(YR,Ao,null),e(Ao,hjr),e(Ao,V8e),e(V8e,ujr),e(Ao,pjr),e(Ao,Pn),e(Pn,_jr),e(Pn,X8e),e(X8e,bjr),e(Pn,vjr),e(Pn,z8e),e(z8e,Fjr),e(Pn,Tjr),e(Pn,Q8e),e(Q8e,Mjr),e(Pn,Ejr),e(Ao,Cjr),e(Ao,Bn),e(Bn,W5),e(W5,W8e),e(W8e,wjr),e(W5,Ajr),e(W5,xte),e(xte,Ljr),e(W5,yjr),e(Bn,xjr),e(Bn,U5),e(U5,U8e),e(U8e,$jr),e(U5,kjr),e(U5,$te),e($te,Sjr),e(U5,Rjr),e(Bn,Pjr),e(Bn,H5),e(H5,H8e),e(H8e,Bjr),e(H5,Ijr),e(H5,kte),e(kte,Njr),e(H5,qjr),e(Bn,Djr),e(Bn,J5),e(J5,J8e),e(J8e,jjr),e(J5,Gjr),e(J5,Ste),e(Ste,Ojr),e(J5,Vjr),e(Ao,Xjr),e(Ao,Y5),e(Y5,zjr),e(Y5,Y8e),e(Y8e,Qjr),e(Y5,Wjr),e(Y5,Z8e),e(Z8e,Ujr),e(Ao,Hjr),M(Z5,Ao,null),b(c,Eio,_),b(c,ac,_),e(ac,K5),e(K5,K8e),M(ZR,K8e,null),e(ac,Jjr),e(ac,eLe),e(eLe,Yjr),b(c,Cio,_),b(c,dr,_),M(KR,dr,null),e(dr,Zjr),e(dr,nc),e(nc,Kjr),e(nc,Rte),e(Rte,eGr),e(nc,oGr),e(nc,Pte),e(Pte,rGr),e(nc,tGr),e(dr,aGr),e(dr,eP),e(eP,nGr),e(eP,oLe),e(oLe,sGr),e(eP,lGr),e(dr,iGr),e(dr,Jt),M(oP,Jt,null),e(Jt,dGr),e(Jt,rLe),e(rLe,mGr),e(Jt,cGr),e(Jt,sc),e(sc,fGr),e(sc,tLe),e(tLe,gGr),e(sc,hGr),e(sc,Bte),e(Bte,uGr),e(sc,pGr),e(Jt,_Gr),M(e0,Jt,null),e(dr,bGr),e(dr,Lo),M(rP,Lo,null),e(Lo,vGr),e(Lo,aLe),e(aLe,FGr),e(Lo,TGr),e(Lo,In),e(In,MGr),e(In,nLe),e(nLe,EGr),e(In,CGr),e(In,sLe),e(sLe,wGr),e(In,AGr),e(In,lLe),e(lLe,LGr),e(In,yGr),e(Lo,xGr),e(Lo,Tt),e(Tt,o0),e(o0,iLe),e(iLe,$Gr),e(o0,kGr),e(o0,Ite),e(Ite,SGr),e(o0,RGr),e(Tt,PGr),e(Tt,r0),e(r0,dLe),e(dLe,BGr),e(r0,IGr),e(r0,Nte),e(Nte,NGr),e(r0,qGr),e(Tt,DGr),e(Tt,t0),e(t0,mLe),e(mLe,jGr),e(t0,GGr),e(t0,qte),e(qte,OGr),e(t0,VGr),e(Tt,XGr),e(Tt,a0),e(a0,cLe),e(cLe,zGr),e(a0,QGr),e(a0,Dte),e(Dte,WGr),e(a0,UGr),e(Tt,HGr),e(Tt,n0),e(n0,fLe),e(fLe,JGr),e(n0,YGr),e(n0,jte),e(jte,ZGr),e(n0,KGr),e(Lo,eOr),e(Lo,s0),e(s0,oOr),e(s0,gLe),e(gLe,rOr),e(s0,tOr),e(s0,hLe),e(hLe,aOr),e(Lo,nOr),M(l0,Lo,null),b(c,wio,_),b(c,lc,_),e(lc,i0),e(i0,uLe),M(tP,uLe,null),e(lc,sOr),e(lc,pLe),e(pLe,lOr),b(c,Aio,_),b(c,mr,_),M(aP,mr,null),e(mr,iOr),e(mr,ic),e(ic,dOr),e(ic,Gte),e(Gte,mOr),e(ic,cOr),e(ic,Ote),e(Ote,fOr),e(ic,gOr),e(mr,hOr),e(mr,nP),e(nP,uOr),e(nP,_Le),e(_Le,pOr),e(nP,_Or),e(mr,bOr),e(mr,Yt),M(sP,Yt,null),e(Yt,vOr),e(Yt,bLe),e(bLe,FOr),e(Yt,TOr),e(Yt,dc),e(dc,MOr),e(dc,vLe),e(vLe,EOr),e(dc,COr),e(dc,Vte),e(Vte,wOr),e(dc,AOr),e(Yt,LOr),M(d0,Yt,null),e(mr,yOr),e(mr,yo),M(lP,yo,null),e(yo,xOr),e(yo,FLe),e(FLe,$Or),e(yo,kOr),e(yo,Nn),e(Nn,SOr),e(Nn,TLe),e(TLe,ROr),e(Nn,POr),e(Nn,MLe),e(MLe,BOr),e(Nn,IOr),e(Nn,ELe),e(ELe,NOr),e(Nn,qOr),e(yo,DOr),e(yo,CLe),e(CLe,m0),e(m0,wLe),e(wLe,jOr),e(m0,GOr),e(m0,Xte),e(Xte,OOr),e(m0,VOr),e(yo,XOr),e(yo,c0),e(c0,zOr),e(c0,ALe),e(ALe,QOr),e(c0,WOr),e(c0,LLe),e(LLe,UOr),e(yo,HOr),M(f0,yo,null),b(c,Lio,_),b(c,mc,_),e(mc,g0),e(g0,yLe),M(iP,yLe,null),e(mc,JOr),e(mc,xLe),e(xLe,YOr),b(c,yio,_),b(c,cr,_),M(dP,cr,null),e(cr,ZOr),e(cr,cc),e(cc,KOr),e(cc,zte),e(zte,eVr),e(cc,oVr),e(cc,Qte),e(Qte,rVr),e(cc,tVr),e(cr,aVr),e(cr,mP),e(mP,nVr),e(mP,$Le),e($Le,sVr),e(mP,lVr),e(cr,iVr),e(cr,Zt),M(cP,Zt,null),e(Zt,dVr),e(Zt,kLe),e(kLe,mVr),e(Zt,cVr),e(Zt,fc),e(fc,fVr),e(fc,SLe),e(SLe,gVr),e(fc,hVr),e(fc,Wte),e(Wte,uVr),e(fc,pVr),e(Zt,_Vr),M(h0,Zt,null),e(cr,bVr),e(cr,xo),M(fP,xo,null),e(xo,vVr),e(xo,RLe),e(RLe,FVr),e(xo,TVr),e(xo,qn),e(qn,MVr),e(qn,PLe),e(PLe,EVr),e(qn,CVr),e(qn,BLe),e(BLe,wVr),e(qn,AVr),e(qn,ILe),e(ILe,LVr),e(qn,yVr),e(xo,xVr),e(xo,Mt),e(Mt,u0),e(u0,NLe),e(NLe,$Vr),e(u0,kVr),e(u0,Ute),e(Ute,SVr),e(u0,RVr),e(Mt,PVr),e(Mt,p0),e(p0,qLe),e(qLe,BVr),e(p0,IVr),e(p0,Hte),e(Hte,NVr),e(p0,qVr),e(Mt,DVr),e(Mt,_0),e(_0,DLe),e(DLe,jVr),e(_0,GVr),e(_0,Jte),e(Jte,OVr),e(_0,VVr),e(Mt,XVr),e(Mt,b0),e(b0,jLe),e(jLe,zVr),e(b0,QVr),e(b0,Yte),e(Yte,WVr),e(b0,UVr),e(Mt,HVr),e(Mt,v0),e(v0,GLe),e(GLe,JVr),e(v0,YVr),e(v0,Zte),e(Zte,ZVr),e(v0,KVr),e(xo,eXr),e(xo,F0),e(F0,oXr),e(F0,OLe),e(OLe,rXr),e(F0,tXr),e(F0,VLe),e(VLe,aXr),e(xo,nXr),M(T0,xo,null),b(c,xio,_),b(c,gc,_),e(gc,M0),e(M0,XLe),M(gP,XLe,null),e(gc,sXr),e(gc,zLe),e(zLe,lXr),b(c,$io,_),b(c,fr,_),M(hP,fr,null),e(fr,iXr),e(fr,hc),e(hc,dXr),e(hc,Kte),e(Kte,mXr),e(hc,cXr),e(hc,eae),e(eae,fXr),e(hc,gXr),e(fr,hXr),e(fr,uP),e(uP,uXr),e(uP,QLe),e(QLe,pXr),e(uP,_Xr),e(fr,bXr),e(fr,Kt),M(pP,Kt,null),e(Kt,vXr),e(Kt,WLe),e(WLe,FXr),e(Kt,TXr),e(Kt,uc),e(uc,MXr),e(uc,ULe),e(ULe,EXr),e(uc,CXr),e(uc,oae),e(oae,wXr),e(uc,AXr),e(Kt,LXr),M(E0,Kt,null),e(fr,yXr),e(fr,$o),M(_P,$o,null),e($o,xXr),e($o,HLe),e(HLe,$Xr),e($o,kXr),e($o,Dn),e(Dn,SXr),e(Dn,JLe),e(JLe,RXr),e(Dn,PXr),e(Dn,YLe),e(YLe,BXr),e(Dn,IXr),e(Dn,ZLe),e(ZLe,NXr),e(Dn,qXr),e($o,DXr),e($o,KLe),e(KLe,C0),e(C0,eye),e(eye,jXr),e(C0,GXr),e(C0,rae),e(rae,OXr),e(C0,VXr),e($o,XXr),e($o,w0),e(w0,zXr),e(w0,oye),e(oye,QXr),e(w0,WXr),e(w0,rye),e(rye,UXr),e($o,HXr),M(A0,$o,null),b(c,kio,_),b(c,pc,_),e(pc,L0),e(L0,tye),M(bP,tye,null),e(pc,JXr),e(pc,aye),e(aye,YXr),b(c,Sio,_),b(c,gr,_),M(vP,gr,null),e(gr,ZXr),e(gr,_c),e(_c,KXr),e(_c,tae),e(tae,ezr),e(_c,ozr),e(_c,aae),e(aae,rzr),e(_c,tzr),e(gr,azr),e(gr,FP),e(FP,nzr),e(FP,nye),e(nye,szr),e(FP,lzr),e(gr,izr),e(gr,ea),M(TP,ea,null),e(ea,dzr),e(ea,sye),e(sye,mzr),e(ea,czr),e(ea,bc),e(bc,fzr),e(bc,lye),e(lye,gzr),e(bc,hzr),e(bc,nae),e(nae,uzr),e(bc,pzr),e(ea,_zr),M(y0,ea,null),e(gr,bzr),e(gr,ko),M(MP,ko,null),e(ko,vzr),e(ko,iye),e(iye,Fzr),e(ko,Tzr),e(ko,jn),e(jn,Mzr),e(jn,dye),e(dye,Ezr),e(jn,Czr),e(jn,mye),e(mye,wzr),e(jn,Azr),e(jn,cye),e(cye,Lzr),e(jn,yzr),e(ko,xzr),e(ko,fye),e(fye,x0),e(x0,gye),e(gye,$zr),e(x0,kzr),e(x0,sae),e(sae,Szr),e(x0,Rzr),e(ko,Pzr),e(ko,$0),e($0,Bzr),e($0,hye),e(hye,Izr),e($0,Nzr),e($0,uye),e(uye,qzr),e(ko,Dzr),M(k0,ko,null),b(c,Rio,_),b(c,vc,_),e(vc,S0),e(S0,pye),M(EP,pye,null),e(vc,jzr),e(vc,_ye),e(_ye,Gzr),b(c,Pio,_),b(c,hr,_),M(CP,hr,null),e(hr,Ozr),e(hr,Fc),e(Fc,Vzr),e(Fc,lae),e(lae,Xzr),e(Fc,zzr),e(Fc,iae),e(iae,Qzr),e(Fc,Wzr),e(hr,Uzr),e(hr,wP),e(wP,Hzr),e(wP,bye),e(bye,Jzr),e(wP,Yzr),e(hr,Zzr),e(hr,oa),M(AP,oa,null),e(oa,Kzr),e(oa,vye),e(vye,eQr),e(oa,oQr),e(oa,Tc),e(Tc,rQr),e(Tc,Fye),e(Fye,tQr),e(Tc,aQr),e(Tc,dae),e(dae,nQr),e(Tc,sQr),e(oa,lQr),M(R0,oa,null),e(hr,iQr),e(hr,Xr),M(LP,Xr,null),e(Xr,dQr),e(Xr,Tye),e(Tye,mQr),e(Xr,cQr),e(Xr,Gn),e(Gn,fQr),e(Gn,Mye),e(Mye,gQr),e(Gn,hQr),e(Gn,Eye),e(Eye,uQr),e(Gn,pQr),e(Gn,Cye),e(Cye,_Qr),e(Gn,bQr),e(Xr,vQr),e(Xr,P),e(P,P0),e(P0,wye),e(wye,FQr),e(P0,TQr),e(P0,mae),e(mae,MQr),e(P0,EQr),e(P,CQr),e(P,B0),e(B0,Aye),e(Aye,wQr),e(B0,AQr),e(B0,cae),e(cae,LQr),e(B0,yQr),e(P,xQr),e(P,I0),e(I0,Lye),e(Lye,$Qr),e(I0,kQr),e(I0,fae),e(fae,SQr),e(I0,RQr),e(P,PQr),e(P,N0),e(N0,yye),e(yye,BQr),e(N0,IQr),e(N0,gae),e(gae,NQr),e(N0,qQr),e(P,DQr),e(P,q0),e(q0,xye),e(xye,jQr),e(q0,GQr),e(q0,hae),e(hae,OQr),e(q0,VQr),e(P,XQr),e(P,D0),e(D0,$ye),e($ye,zQr),e(D0,QQr),e(D0,uae),e(uae,WQr),e(D0,UQr),e(P,HQr),e(P,j0),e(j0,kye),e(kye,JQr),e(j0,YQr),e(j0,pae),e(pae,ZQr),e(j0,KQr),e(P,eWr),e(P,G0),e(G0,Sye),e(Sye,oWr),e(G0,rWr),e(G0,_ae),e(_ae,tWr),e(G0,aWr),e(P,nWr),e(P,O0),e(O0,Rye),e(Rye,sWr),e(O0,lWr),e(O0,bae),e(bae,iWr),e(O0,dWr),e(P,mWr),e(P,V0),e(V0,Pye),e(Pye,cWr),e(V0,fWr),e(V0,vae),e(vae,gWr),e(V0,hWr),e(P,uWr),e(P,X0),e(X0,Bye),e(Bye,pWr),e(X0,_Wr),e(X0,Fae),e(Fae,bWr),e(X0,vWr),e(P,FWr),e(P,z0),e(z0,Iye),e(Iye,TWr),e(z0,MWr),e(z0,Tae),e(Tae,EWr),e(z0,CWr),e(P,wWr),e(P,Q0),e(Q0,Nye),e(Nye,AWr),e(Q0,LWr),e(Q0,Mae),e(Mae,yWr),e(Q0,xWr),e(P,$Wr),e(P,W0),e(W0,qye),e(qye,kWr),e(W0,SWr),e(W0,Eae),e(Eae,RWr),e(W0,PWr),e(P,BWr),e(P,U0),e(U0,Dye),e(Dye,IWr),e(U0,NWr),e(U0,Cae),e(Cae,qWr),e(U0,DWr),e(P,jWr),e(P,H0),e(H0,jye),e(jye,GWr),e(H0,OWr),e(H0,wae),e(wae,VWr),e(H0,XWr),e(P,zWr),e(P,J0),e(J0,Gye),e(Gye,QWr),e(J0,WWr),e(J0,Aae),e(Aae,UWr),e(J0,HWr),e(P,JWr),e(P,Y0),e(Y0,Oye),e(Oye,YWr),e(Y0,ZWr),e(Y0,Lae),e(Lae,KWr),e(Y0,eUr),e(P,oUr),e(P,Z0),e(Z0,Vye),e(Vye,rUr),e(Z0,tUr),e(Z0,yae),e(yae,aUr),e(Z0,nUr),e(P,sUr),e(P,K0),e(K0,Xye),e(Xye,lUr),e(K0,iUr),e(K0,xae),e(xae,dUr),e(K0,mUr),e(P,cUr),e(P,Dl),e(Dl,zye),e(zye,fUr),e(Dl,gUr),e(Dl,$ae),e($ae,hUr),e(Dl,uUr),e(Dl,kae),e(kae,pUr),e(Dl,_Ur),e(P,bUr),e(P,ew),e(ew,Qye),e(Qye,vUr),e(ew,FUr),e(ew,Sae),e(Sae,TUr),e(ew,MUr),e(P,EUr),e(P,ow),e(ow,Wye),e(Wye,CUr),e(ow,wUr),e(ow,Rae),e(Rae,AUr),e(ow,LUr),e(P,yUr),e(P,rw),e(rw,Uye),e(Uye,xUr),e(rw,$Ur),e(rw,Pae),e(Pae,kUr),e(rw,SUr),e(P,RUr),e(P,tw),e(tw,Hye),e(Hye,PUr),e(tw,BUr),e(tw,Bae),e(Bae,IUr),e(tw,NUr),e(P,qUr),e(P,aw),e(aw,Jye),e(Jye,DUr),e(aw,jUr),e(aw,Iae),e(Iae,GUr),e(aw,OUr),e(P,VUr),e(P,nw),e(nw,Yye),e(Yye,XUr),e(nw,zUr),e(nw,Nae),e(Nae,QUr),e(nw,WUr),e(P,UUr),e(P,sw),e(sw,Zye),e(Zye,HUr),e(sw,JUr),e(sw,qae),e(qae,YUr),e(sw,ZUr),e(P,KUr),e(P,lw),e(lw,Kye),e(Kye,eHr),e(lw,oHr),e(lw,Dae),e(Dae,rHr),e(lw,tHr),e(P,aHr),e(P,iw),e(iw,e9e),e(e9e,nHr),e(iw,sHr),e(iw,jae),e(jae,lHr),e(iw,iHr),e(P,dHr),e(P,dw),e(dw,o9e),e(o9e,mHr),e(dw,cHr),e(dw,Gae),e(Gae,fHr),e(dw,gHr),e(P,hHr),e(P,mw),e(mw,r9e),e(r9e,uHr),e(mw,pHr),e(mw,Oae),e(Oae,_Hr),e(mw,bHr),e(P,vHr),e(P,cw),e(cw,t9e),e(t9e,FHr),e(cw,THr),e(cw,Vae),e(Vae,MHr),e(cw,EHr),e(P,CHr),e(P,fw),e(fw,a9e),e(a9e,wHr),e(fw,AHr),e(fw,Xae),e(Xae,LHr),e(fw,yHr),e(P,xHr),e(P,gw),e(gw,n9e),e(n9e,$Hr),e(gw,kHr),e(gw,zae),e(zae,SHr),e(gw,RHr),e(P,PHr),e(P,hw),e(hw,s9e),e(s9e,BHr),e(hw,IHr),e(hw,Qae),e(Qae,NHr),e(hw,qHr),e(P,DHr),e(P,uw),e(uw,l9e),e(l9e,jHr),e(uw,GHr),e(uw,Wae),e(Wae,OHr),e(uw,VHr),e(P,XHr),e(P,pw),e(pw,i9e),e(i9e,zHr),e(pw,QHr),e(pw,Uae),e(Uae,WHr),e(pw,UHr),e(P,HHr),e(P,_w),e(_w,d9e),e(d9e,JHr),e(_w,YHr),e(_w,Hae),e(Hae,ZHr),e(_w,KHr),e(P,eJr),e(P,bw),e(bw,m9e),e(m9e,oJr),e(bw,rJr),e(bw,Jae),e(Jae,tJr),e(bw,aJr),e(P,nJr),e(P,vw),e(vw,c9e),e(c9e,sJr),e(vw,lJr),e(vw,Yae),e(Yae,iJr),e(vw,dJr),e(P,mJr),e(P,Fw),e(Fw,f9e),e(f9e,cJr),e(Fw,fJr),e(Fw,Zae),e(Zae,gJr),e(Fw,hJr),e(P,uJr),e(P,Tw),e(Tw,g9e),e(g9e,pJr),e(Tw,_Jr),e(Tw,Kae),e(Kae,bJr),e(Tw,vJr),e(P,FJr),e(P,Mw),e(Mw,h9e),e(h9e,TJr),e(Mw,MJr),e(Mw,ene),e(ene,EJr),e(Mw,CJr),e(P,wJr),e(P,Ew),e(Ew,u9e),e(u9e,AJr),e(Ew,LJr),e(Ew,one),e(one,yJr),e(Ew,xJr),e(P,$Jr),e(P,Cw),e(Cw,p9e),e(p9e,kJr),e(Cw,SJr),e(Cw,rne),e(rne,RJr),e(Cw,PJr),e(P,BJr),e(P,ww),e(ww,_9e),e(_9e,IJr),e(ww,NJr),e(ww,tne),e(tne,qJr),e(ww,DJr),e(P,jJr),e(P,Aw),e(Aw,b9e),e(b9e,GJr),e(Aw,OJr),e(Aw,ane),e(ane,VJr),e(Aw,XJr),e(P,zJr),e(P,Lw),e(Lw,v9e),e(v9e,QJr),e(Lw,WJr),e(Lw,nne),e(nne,UJr),e(Lw,HJr),e(P,JJr),e(P,yw),e(yw,F9e),e(F9e,YJr),e(yw,ZJr),e(yw,sne),e(sne,KJr),e(yw,eYr),e(P,oYr),e(P,xw),e(xw,T9e),e(T9e,rYr),e(xw,tYr),e(xw,lne),e(lne,aYr),e(xw,nYr),e(P,sYr),e(P,$w),e($w,M9e),e(M9e,lYr),e($w,iYr),e($w,ine),e(ine,dYr),e($w,mYr),e(P,cYr),e(P,kw),e(kw,E9e),e(E9e,fYr),e(kw,gYr),e(kw,dne),e(dne,hYr),e(kw,uYr),e(P,pYr),e(P,Sw),e(Sw,C9e),e(C9e,_Yr),e(Sw,bYr),e(Sw,mne),e(mne,vYr),e(Sw,FYr),e(P,TYr),e(P,Rw),e(Rw,w9e),e(w9e,MYr),e(Rw,EYr),e(Rw,cne),e(cne,CYr),e(Rw,wYr),e(P,AYr),e(P,Pw),e(Pw,A9e),e(A9e,LYr),e(Pw,yYr),e(Pw,fne),e(fne,xYr),e(Pw,$Yr),e(P,kYr),e(P,Bw),e(Bw,L9e),e(L9e,SYr),e(Bw,RYr),e(Bw,gne),e(gne,PYr),e(Bw,BYr),e(P,IYr),e(P,Iw),e(Iw,y9e),e(y9e,NYr),e(Iw,qYr),e(Iw,hne),e(hne,DYr),e(Iw,jYr),e(Xr,GYr),M(Nw,Xr,null),b(c,Bio,_),b(c,Mc,_),e(Mc,qw),e(qw,x9e),M(yP,x9e,null),e(Mc,OYr),e(Mc,$9e),e($9e,VYr),b(c,Iio,_),b(c,ur,_),M(xP,ur,null),e(ur,XYr),e(ur,Ec),e(Ec,zYr),e(Ec,une),e(une,QYr),e(Ec,WYr),e(Ec,pne),e(pne,UYr),e(Ec,HYr),e(ur,JYr),e(ur,$P),e($P,YYr),e($P,k9e),e(k9e,ZYr),e($P,KYr),e(ur,eZr),e(ur,ra),M(kP,ra,null),e(ra,oZr),e(ra,S9e),e(S9e,rZr),e(ra,tZr),e(ra,Cc),e(Cc,aZr),e(Cc,R9e),e(R9e,nZr),e(Cc,sZr),e(Cc,_ne),e(_ne,lZr),e(Cc,iZr),e(ra,dZr),M(Dw,ra,null),e(ur,mZr),e(ur,zr),M(SP,zr,null),e(zr,cZr),e(zr,P9e),e(P9e,fZr),e(zr,gZr),e(zr,On),e(On,hZr),e(On,B9e),e(B9e,uZr),e(On,pZr),e(On,I9e),e(I9e,_Zr),e(On,bZr),e(On,N9e),e(N9e,vZr),e(On,FZr),e(zr,TZr),e(zr,de),e(de,jw),e(jw,q9e),e(q9e,MZr),e(jw,EZr),e(jw,bne),e(bne,CZr),e(jw,wZr),e(de,AZr),e(de,Gw),e(Gw,D9e),e(D9e,LZr),e(Gw,yZr),e(Gw,vne),e(vne,xZr),e(Gw,$Zr),e(de,kZr),e(de,Ow),e(Ow,j9e),e(j9e,SZr),e(Ow,RZr),e(Ow,Fne),e(Fne,PZr),e(Ow,BZr),e(de,IZr),e(de,Vw),e(Vw,G9e),e(G9e,NZr),e(Vw,qZr),e(Vw,Tne),e(Tne,DZr),e(Vw,jZr),e(de,GZr),e(de,Xw),e(Xw,O9e),e(O9e,OZr),e(Xw,VZr),e(Xw,Mne),e(Mne,XZr),e(Xw,zZr),e(de,QZr),e(de,zw),e(zw,V9e),e(V9e,WZr),e(zw,UZr),e(zw,Ene),e(Ene,HZr),e(zw,JZr),e(de,YZr),e(de,Qw),e(Qw,X9e),e(X9e,ZZr),e(Qw,KZr),e(Qw,Cne),e(Cne,eKr),e(Qw,oKr),e(de,rKr),e(de,Ww),e(Ww,z9e),e(z9e,tKr),e(Ww,aKr),e(Ww,wne),e(wne,nKr),e(Ww,sKr),e(de,lKr),e(de,Uw),e(Uw,Q9e),e(Q9e,iKr),e(Uw,dKr),e(Uw,Ane),e(Ane,mKr),e(Uw,cKr),e(de,fKr),e(de,Hw),e(Hw,W9e),e(W9e,gKr),e(Hw,hKr),e(Hw,Lne),e(Lne,uKr),e(Hw,pKr),e(de,_Kr),e(de,Jw),e(Jw,U9e),e(U9e,bKr),e(Jw,vKr),e(Jw,yne),e(yne,FKr),e(Jw,TKr),e(de,MKr),e(de,Yw),e(Yw,H9e),e(H9e,EKr),e(Yw,CKr),e(Yw,xne),e(xne,wKr),e(Yw,AKr),e(de,LKr),e(de,Zw),e(Zw,J9e),e(J9e,yKr),e(Zw,xKr),e(Zw,$ne),e($ne,$Kr),e(Zw,kKr),e(de,SKr),e(de,Kw),e(Kw,Y9e),e(Y9e,RKr),e(Kw,PKr),e(Kw,kne),e(kne,BKr),e(Kw,IKr),e(de,NKr),e(de,eA),e(eA,Z9e),e(Z9e,qKr),e(eA,DKr),e(eA,Sne),e(Sne,jKr),e(eA,GKr),e(de,OKr),e(de,oA),e(oA,K9e),e(K9e,VKr),e(oA,XKr),e(oA,Rne),e(Rne,zKr),e(oA,QKr),e(de,WKr),e(de,rA),e(rA,exe),e(exe,UKr),e(rA,HKr),e(rA,Pne),e(Pne,JKr),e(rA,YKr),e(de,ZKr),e(de,tA),e(tA,oxe),e(oxe,KKr),e(tA,eet),e(tA,Bne),e(Bne,oet),e(tA,ret),e(de,tet),e(de,aA),e(aA,rxe),e(rxe,aet),e(aA,net),e(aA,Ine),e(Ine,set),e(aA,iet),e(de,det),e(de,nA),e(nA,txe),e(txe,met),e(nA,cet),e(nA,Nne),e(Nne,fet),e(nA,get),e(de,het),e(de,sA),e(sA,axe),e(axe,uet),e(sA,pet),e(sA,qne),e(qne,_et),e(sA,bet),e(de,vet),e(de,lA),e(lA,nxe),e(nxe,Fet),e(lA,Tet),e(lA,Dne),e(Dne,Met),e(lA,Eet),e(de,Cet),e(de,iA),e(iA,sxe),e(sxe,wet),e(iA,Aet),e(iA,jne),e(jne,Let),e(iA,yet),e(zr,xet),M(dA,zr,null),b(c,Nio,_),b(c,wc,_),e(wc,mA),e(mA,lxe),M(RP,lxe,null),e(wc,$et),e(wc,ixe),e(ixe,ket),b(c,qio,_),b(c,pr,_),M(PP,pr,null),e(pr,Set),e(pr,Ac),e(Ac,Ret),e(Ac,Gne),e(Gne,Pet),e(Ac,Bet),e(Ac,One),e(One,Iet),e(Ac,Net),e(pr,qet),e(pr,BP),e(BP,Det),e(BP,dxe),e(dxe,jet),e(BP,Get),e(pr,Oet),e(pr,ta),M(IP,ta,null),e(ta,Vet),e(ta,mxe),e(mxe,Xet),e(ta,zet),e(ta,Lc),e(Lc,Qet),e(Lc,cxe),e(cxe,Wet),e(Lc,Uet),e(Lc,Vne),e(Vne,Het),e(Lc,Jet),e(ta,Yet),M(cA,ta,null),e(pr,Zet),e(pr,Qr),M(NP,Qr,null),e(Qr,Ket),e(Qr,fxe),e(fxe,eot),e(Qr,oot),e(Qr,Vn),e(Vn,rot),e(Vn,gxe),e(gxe,tot),e(Vn,aot),e(Vn,hxe),e(hxe,not),e(Vn,sot),e(Vn,uxe),e(uxe,lot),e(Vn,iot),e(Qr,dot),e(Qr,Ce),e(Ce,fA),e(fA,pxe),e(pxe,mot),e(fA,cot),e(fA,Xne),e(Xne,fot),e(fA,got),e(Ce,hot),e(Ce,gA),e(gA,_xe),e(_xe,uot),e(gA,pot),e(gA,zne),e(zne,_ot),e(gA,bot),e(Ce,vot),e(Ce,hA),e(hA,bxe),e(bxe,Fot),e(hA,Tot),e(hA,Qne),e(Qne,Mot),e(hA,Eot),e(Ce,Cot),e(Ce,uA),e(uA,vxe),e(vxe,wot),e(uA,Aot),e(uA,Wne),e(Wne,Lot),e(uA,yot),e(Ce,xot),e(Ce,pA),e(pA,Fxe),e(Fxe,$ot),e(pA,kot),e(pA,Une),e(Une,Sot),e(pA,Rot),e(Ce,Pot),e(Ce,_A),e(_A,Txe),e(Txe,Bot),e(_A,Iot),e(_A,Hne),e(Hne,Not),e(_A,qot),e(Ce,Dot),e(Ce,bA),e(bA,Mxe),e(Mxe,jot),e(bA,Got),e(bA,Jne),e(Jne,Oot),e(bA,Vot),e(Ce,Xot),e(Ce,vA),e(vA,Exe),e(Exe,zot),e(vA,Qot),e(vA,Yne),e(Yne,Wot),e(vA,Uot),e(Ce,Hot),e(Ce,FA),e(FA,Cxe),e(Cxe,Jot),e(FA,Yot),e(FA,Zne),e(Zne,Zot),e(FA,Kot),e(Ce,ert),e(Ce,TA),e(TA,wxe),e(wxe,ort),e(TA,rrt),e(TA,Kne),e(Kne,trt),e(TA,art),e(Ce,nrt),e(Ce,MA),e(MA,Axe),e(Axe,srt),e(MA,lrt),e(MA,ese),e(ese,irt),e(MA,drt),e(Ce,mrt),e(Ce,EA),e(EA,Lxe),e(Lxe,crt),e(EA,frt),e(EA,ose),e(ose,grt),e(EA,hrt),e(Ce,urt),e(Ce,CA),e(CA,yxe),e(yxe,prt),e(CA,_rt),e(CA,rse),e(rse,brt),e(CA,vrt),e(Ce,Frt),e(Ce,wA),e(wA,xxe),e(xxe,Trt),e(wA,Mrt),e(wA,tse),e(tse,Ert),e(wA,Crt),e(Qr,wrt),M(AA,Qr,null),b(c,Dio,_),b(c,yc,_),e(yc,LA),e(LA,$xe),M(qP,$xe,null),e(yc,Art),e(yc,kxe),e(kxe,Lrt),b(c,jio,_),b(c,_r,_),M(DP,_r,null),e(_r,yrt),e(_r,xc),e(xc,xrt),e(xc,ase),e(ase,$rt),e(xc,krt),e(xc,nse),e(nse,Srt),e(xc,Rrt),e(_r,Prt),e(_r,jP),e(jP,Brt),e(jP,Sxe),e(Sxe,Irt),e(jP,Nrt),e(_r,qrt),e(_r,aa),M(GP,aa,null),e(aa,Drt),e(aa,Rxe),e(Rxe,jrt),e(aa,Grt),e(aa,$c),e($c,Ort),e($c,Pxe),e(Pxe,Vrt),e($c,Xrt),e($c,sse),e(sse,zrt),e($c,Qrt),e(aa,Wrt),M(yA,aa,null),e(_r,Urt),e(_r,Wr),M(OP,Wr,null),e(Wr,Hrt),e(Wr,Bxe),e(Bxe,Jrt),e(Wr,Yrt),e(Wr,Xn),e(Xn,Zrt),e(Xn,Ixe),e(Ixe,Krt),e(Xn,ett),e(Xn,Nxe),e(Nxe,ott),e(Xn,rtt),e(Xn,qxe),e(qxe,ttt),e(Xn,att),e(Wr,ntt),e(Wr,$e),e($e,xA),e(xA,Dxe),e(Dxe,stt),e(xA,ltt),e(xA,lse),e(lse,itt),e(xA,dtt),e($e,mtt),e($e,$A),e($A,jxe),e(jxe,ctt),e($A,ftt),e($A,ise),e(ise,gtt),e($A,htt),e($e,utt),e($e,kA),e(kA,Gxe),e(Gxe,ptt),e(kA,_tt),e(kA,dse),e(dse,btt),e(kA,vtt),e($e,Ftt),e($e,jl),e(jl,Oxe),e(Oxe,Ttt),e(jl,Mtt),e(jl,mse),e(mse,Ett),e(jl,Ctt),e(jl,cse),e(cse,wtt),e(jl,Att),e($e,Ltt),e($e,SA),e(SA,Vxe),e(Vxe,ytt),e(SA,xtt),e(SA,fse),e(fse,$tt),e(SA,ktt),e($e,Stt),e($e,RA),e(RA,Xxe),e(Xxe,Rtt),e(RA,Ptt),e(RA,gse),e(gse,Btt),e(RA,Itt),e($e,Ntt),e($e,PA),e(PA,zxe),e(zxe,qtt),e(PA,Dtt),e(PA,hse),e(hse,jtt),e(PA,Gtt),e($e,Ott),e($e,BA),e(BA,Qxe),e(Qxe,Vtt),e(BA,Xtt),e(BA,use),e(use,ztt),e(BA,Qtt),e($e,Wtt),e($e,IA),e(IA,Wxe),e(Wxe,Utt),e(IA,Htt),e(IA,pse),e(pse,Jtt),e(IA,Ytt),e($e,Ztt),e($e,NA),e(NA,Uxe),e(Uxe,Ktt),e(NA,eat),e(NA,_se),e(_se,oat),e(NA,rat),e(Wr,tat),M(qA,Wr,null),b(c,Gio,_),b(c,kc,_),e(kc,DA),e(DA,Hxe),M(VP,Hxe,null),e(kc,aat),e(kc,Jxe),e(Jxe,nat),b(c,Oio,_),b(c,br,_),M(XP,br,null),e(br,sat),e(br,Sc),e(Sc,lat),e(Sc,bse),e(bse,iat),e(Sc,dat),e(Sc,vse),e(vse,mat),e(Sc,cat),e(br,fat),e(br,zP),e(zP,gat),e(zP,Yxe),e(Yxe,hat),e(zP,uat),e(br,pat),e(br,na),M(QP,na,null),e(na,_at),e(na,Zxe),e(Zxe,bat),e(na,vat),e(na,Rc),e(Rc,Fat),e(Rc,Kxe),e(Kxe,Tat),e(Rc,Mat),e(Rc,Fse),e(Fse,Eat),e(Rc,Cat),e(na,wat),M(jA,na,null),e(br,Aat),e(br,Ur),M(WP,Ur,null),e(Ur,Lat),e(Ur,e$e),e(e$e,yat),e(Ur,xat),e(Ur,zn),e(zn,$at),e(zn,o$e),e(o$e,kat),e(zn,Sat),e(zn,r$e),e(r$e,Rat),e(zn,Pat),e(zn,t$e),e(t$e,Bat),e(zn,Iat),e(Ur,Nat),e(Ur,Pc),e(Pc,GA),e(GA,a$e),e(a$e,qat),e(GA,Dat),e(GA,Tse),e(Tse,jat),e(GA,Gat),e(Pc,Oat),e(Pc,OA),e(OA,n$e),e(n$e,Vat),e(OA,Xat),e(OA,Mse),e(Mse,zat),e(OA,Qat),e(Pc,Wat),e(Pc,VA),e(VA,s$e),e(s$e,Uat),e(VA,Hat),e(VA,Ese),e(Ese,Jat),e(VA,Yat),e(Ur,Zat),M(XA,Ur,null),b(c,Vio,_),b(c,Bc,_),e(Bc,zA),e(zA,l$e),M(UP,l$e,null),e(Bc,Kat),e(Bc,i$e),e(i$e,ent),b(c,Xio,_),b(c,vr,_),M(HP,vr,null),e(vr,ont),e(vr,Ic),e(Ic,rnt),e(Ic,Cse),e(Cse,tnt),e(Ic,ant),e(Ic,wse),e(wse,nnt),e(Ic,snt),e(vr,lnt),e(vr,JP),e(JP,int),e(JP,d$e),e(d$e,dnt),e(JP,mnt),e(vr,cnt),e(vr,sa),M(YP,sa,null),e(sa,fnt),e(sa,m$e),e(m$e,gnt),e(sa,hnt),e(sa,Nc),e(Nc,unt),e(Nc,c$e),e(c$e,pnt),e(Nc,_nt),e(Nc,Ase),e(Ase,bnt),e(Nc,vnt),e(sa,Fnt),M(QA,sa,null),e(vr,Tnt),e(vr,Hr),M(ZP,Hr,null),e(Hr,Mnt),e(Hr,f$e),e(f$e,Ent),e(Hr,Cnt),e(Hr,Qn),e(Qn,wnt),e(Qn,g$e),e(g$e,Ant),e(Qn,Lnt),e(Qn,h$e),e(h$e,ynt),e(Qn,xnt),e(Qn,u$e),e(u$e,$nt),e(Qn,knt),e(Hr,Snt),e(Hr,ge),e(ge,WA),e(WA,p$e),e(p$e,Rnt),e(WA,Pnt),e(WA,Lse),e(Lse,Bnt),e(WA,Int),e(ge,Nnt),e(ge,UA),e(UA,_$e),e(_$e,qnt),e(UA,Dnt),e(UA,yse),e(yse,jnt),e(UA,Gnt),e(ge,Ont),e(ge,HA),e(HA,b$e),e(b$e,Vnt),e(HA,Xnt),e(HA,xse),e(xse,znt),e(HA,Qnt),e(ge,Wnt),e(ge,JA),e(JA,v$e),e(v$e,Unt),e(JA,Hnt),e(JA,$se),e($se,Jnt),e(JA,Ynt),e(ge,Znt),e(ge,YA),e(YA,F$e),e(F$e,Knt),e(YA,est),e(YA,kse),e(kse,ost),e(YA,rst),e(ge,tst),e(ge,ZA),e(ZA,T$e),e(T$e,ast),e(ZA,nst),e(ZA,Sse),e(Sse,sst),e(ZA,lst),e(ge,ist),e(ge,KA),e(KA,M$e),e(M$e,dst),e(KA,mst),e(KA,Rse),e(Rse,cst),e(KA,fst),e(ge,gst),e(ge,e6),e(e6,E$e),e(E$e,hst),e(e6,ust),e(e6,Pse),e(Pse,pst),e(e6,_st),e(ge,bst),e(ge,o6),e(o6,C$e),e(C$e,vst),e(o6,Fst),e(o6,Bse),e(Bse,Tst),e(o6,Mst),e(ge,Est),e(ge,r6),e(r6,w$e),e(w$e,Cst),e(r6,wst),e(r6,Ise),e(Ise,Ast),e(r6,Lst),e(ge,yst),e(ge,t6),e(t6,A$e),e(A$e,xst),e(t6,$st),e(t6,Nse),e(Nse,kst),e(t6,Sst),e(ge,Rst),e(ge,a6),e(a6,L$e),e(L$e,Pst),e(a6,Bst),e(a6,qse),e(qse,Ist),e(a6,Nst),e(ge,qst),e(ge,n6),e(n6,y$e),e(y$e,Dst),e(n6,jst),e(n6,Dse),e(Dse,Gst),e(n6,Ost),e(ge,Vst),e(ge,s6),e(s6,x$e),e(x$e,Xst),e(s6,zst),e(s6,jse),e(jse,Qst),e(s6,Wst),e(ge,Ust),e(ge,l6),e(l6,$$e),e($$e,Hst),e(l6,Jst),e(l6,Gse),e(Gse,Yst),e(l6,Zst),e(ge,Kst),e(ge,i6),e(i6,k$e),e(k$e,elt),e(i6,olt),e(i6,Ose),e(Ose,rlt),e(i6,tlt),e(ge,alt),e(ge,d6),e(d6,S$e),e(S$e,nlt),e(d6,slt),e(d6,Vse),e(Vse,llt),e(d6,ilt),e(ge,dlt),e(ge,m6),e(m6,R$e),e(R$e,mlt),e(m6,clt),e(m6,Xse),e(Xse,flt),e(m6,glt),e(ge,hlt),e(ge,c6),e(c6,P$e),e(P$e,ult),e(c6,plt),e(c6,zse),e(zse,_lt),e(c6,blt),e(ge,vlt),e(ge,f6),e(f6,B$e),e(B$e,Flt),e(f6,Tlt),e(f6,Qse),e(Qse,Mlt),e(f6,Elt),e(ge,Clt),e(ge,g6),e(g6,I$e),e(I$e,wlt),e(g6,Alt),e(g6,Wse),e(Wse,Llt),e(g6,ylt),e(Hr,xlt),M(h6,Hr,null),b(c,zio,_),b(c,qc,_),e(qc,u6),e(u6,N$e),M(KP,N$e,null),e(qc,$lt),e(qc,q$e),e(q$e,klt),b(c,Qio,_),b(c,Fr,_),M(eB,Fr,null),e(Fr,Slt),e(Fr,Dc),e(Dc,Rlt),e(Dc,Use),e(Use,Plt),e(Dc,Blt),e(Dc,Hse),e(Hse,Ilt),e(Dc,Nlt),e(Fr,qlt),e(Fr,oB),e(oB,Dlt),e(oB,D$e),e(D$e,jlt),e(oB,Glt),e(Fr,Olt),e(Fr,la),M(rB,la,null),e(la,Vlt),e(la,j$e),e(j$e,Xlt),e(la,zlt),e(la,jc),e(jc,Qlt),e(jc,G$e),e(G$e,Wlt),e(jc,Ult),e(jc,Jse),e(Jse,Hlt),e(jc,Jlt),e(la,Ylt),M(p6,la,null),e(Fr,Zlt),e(Fr,Jr),M(tB,Jr,null),e(Jr,Klt),e(Jr,O$e),e(O$e,eit),e(Jr,oit),e(Jr,Wn),e(Wn,rit),e(Wn,V$e),e(V$e,tit),e(Wn,ait),e(Wn,X$e),e(X$e,nit),e(Wn,sit),e(Wn,z$e),e(z$e,lit),e(Wn,iit),e(Jr,dit),e(Jr,ke),e(ke,_6),e(_6,Q$e),e(Q$e,mit),e(_6,cit),e(_6,Yse),e(Yse,fit),e(_6,git),e(ke,hit),e(ke,b6),e(b6,W$e),e(W$e,uit),e(b6,pit),e(b6,Zse),e(Zse,_it),e(b6,bit),e(ke,vit),e(ke,v6),e(v6,U$e),e(U$e,Fit),e(v6,Tit),e(v6,Kse),e(Kse,Mit),e(v6,Eit),e(ke,Cit),e(ke,F6),e(F6,H$e),e(H$e,wit),e(F6,Ait),e(F6,ele),e(ele,Lit),e(F6,yit),e(ke,xit),e(ke,T6),e(T6,J$e),e(J$e,$it),e(T6,kit),e(T6,ole),e(ole,Sit),e(T6,Rit),e(ke,Pit),e(ke,M6),e(M6,Y$e),e(Y$e,Bit),e(M6,Iit),e(M6,rle),e(rle,Nit),e(M6,qit),e(ke,Dit),e(ke,E6),e(E6,Z$e),e(Z$e,jit),e(E6,Git),e(E6,tle),e(tle,Oit),e(E6,Vit),e(ke,Xit),e(ke,C6),e(C6,K$e),e(K$e,zit),e(C6,Qit),e(C6,ale),e(ale,Wit),e(C6,Uit),e(ke,Hit),e(ke,w6),e(w6,eke),e(eke,Jit),e(w6,Yit),e(w6,nle),e(nle,Zit),e(w6,Kit),e(ke,edt),e(ke,A6),e(A6,oke),e(oke,odt),e(A6,rdt),e(A6,sle),e(sle,tdt),e(A6,adt),e(Jr,ndt),M(L6,Jr,null),b(c,Wio,_),b(c,Gc,_),e(Gc,y6),e(y6,rke),M(aB,rke,null),e(Gc,sdt),e(Gc,tke),e(tke,ldt),b(c,Uio,_),b(c,Tr,_),M(nB,Tr,null),e(Tr,idt),e(Tr,Oc),e(Oc,ddt),e(Oc,lle),e(lle,mdt),e(Oc,cdt),e(Oc,ile),e(ile,fdt),e(Oc,gdt),e(Tr,hdt),e(Tr,sB),e(sB,udt),e(sB,ake),e(ake,pdt),e(sB,_dt),e(Tr,bdt),e(Tr,ia),M(lB,ia,null),e(ia,vdt),e(ia,nke),e(nke,Fdt),e(ia,Tdt),e(ia,Vc),e(Vc,Mdt),e(Vc,ske),e(ske,Edt),e(Vc,Cdt),e(Vc,dle),e(dle,wdt),e(Vc,Adt),e(ia,Ldt),M(x6,ia,null),e(Tr,ydt),e(Tr,Yr),M(iB,Yr,null),e(Yr,xdt),e(Yr,lke),e(lke,$dt),e(Yr,kdt),e(Yr,Un),e(Un,Sdt),e(Un,ike),e(ike,Rdt),e(Un,Pdt),e(Un,dke),e(dke,Bdt),e(Un,Idt),e(Un,mke),e(mke,Ndt),e(Un,qdt),e(Yr,Ddt),e(Yr,te),e(te,$6),e($6,cke),e(cke,jdt),e($6,Gdt),e($6,mle),e(mle,Odt),e($6,Vdt),e(te,Xdt),e(te,k6),e(k6,fke),e(fke,zdt),e(k6,Qdt),e(k6,cle),e(cle,Wdt),e(k6,Udt),e(te,Hdt),e(te,S6),e(S6,gke),e(gke,Jdt),e(S6,Ydt),e(S6,fle),e(fle,Zdt),e(S6,Kdt),e(te,emt),e(te,R6),e(R6,hke),e(hke,omt),e(R6,rmt),e(R6,gle),e(gle,tmt),e(R6,amt),e(te,nmt),e(te,P6),e(P6,uke),e(uke,smt),e(P6,lmt),e(P6,hle),e(hle,imt),e(P6,dmt),e(te,mmt),e(te,B6),e(B6,pke),e(pke,cmt),e(B6,fmt),e(B6,ule),e(ule,gmt),e(B6,hmt),e(te,umt),e(te,I6),e(I6,_ke),e(_ke,pmt),e(I6,_mt),e(I6,ple),e(ple,bmt),e(I6,vmt),e(te,Fmt),e(te,N6),e(N6,bke),e(bke,Tmt),e(N6,Mmt),e(N6,_le),e(_le,Emt),e(N6,Cmt),e(te,wmt),e(te,q6),e(q6,vke),e(vke,Amt),e(q6,Lmt),e(q6,ble),e(ble,ymt),e(q6,xmt),e(te,$mt),e(te,D6),e(D6,Fke),e(Fke,kmt),e(D6,Smt),e(D6,vle),e(vle,Rmt),e(D6,Pmt),e(te,Bmt),e(te,j6),e(j6,Tke),e(Tke,Imt),e(j6,Nmt),e(j6,Fle),e(Fle,qmt),e(j6,Dmt),e(te,jmt),e(te,G6),e(G6,Mke),e(Mke,Gmt),e(G6,Omt),e(G6,Tle),e(Tle,Vmt),e(G6,Xmt),e(te,zmt),e(te,O6),e(O6,Eke),e(Eke,Qmt),e(O6,Wmt),e(O6,Mle),e(Mle,Umt),e(O6,Hmt),e(te,Jmt),e(te,V6),e(V6,Cke),e(Cke,Ymt),e(V6,Zmt),e(V6,Ele),e(Ele,Kmt),e(V6,ect),e(te,oct),e(te,X6),e(X6,wke),e(wke,rct),e(X6,tct),e(X6,Cle),e(Cle,act),e(X6,nct),e(te,sct),e(te,z6),e(z6,Ake),e(Ake,lct),e(z6,ict),e(z6,wle),e(wle,dct),e(z6,mct),e(te,cct),e(te,Q6),e(Q6,Lke),e(Lke,fct),e(Q6,gct),e(Q6,Ale),e(Ale,hct),e(Q6,uct),e(te,pct),e(te,W6),e(W6,yke),e(yke,_ct),e(W6,bct),e(W6,Lle),e(Lle,vct),e(W6,Fct),e(te,Tct),e(te,U6),e(U6,xke),e(xke,Mct),e(U6,Ect),e(U6,yle),e(yle,Cct),e(U6,wct),e(te,Act),e(te,H6),e(H6,$ke),e($ke,Lct),e(H6,yct),e(H6,xle),e(xle,xct),e(H6,$ct),e(te,kct),e(te,J6),e(J6,kke),e(kke,Sct),e(J6,Rct),e(J6,$le),e($le,Pct),e(J6,Bct),e(te,Ict),e(te,Y6),e(Y6,Ske),e(Ske,Nct),e(Y6,qct),e(Y6,kle),e(kle,Dct),e(Y6,jct),e(te,Gct),e(te,Z6),e(Z6,Rke),e(Rke,Oct),e(Z6,Vct),e(Z6,Sle),e(Sle,Xct),e(Z6,zct),e(te,Qct),e(te,K6),e(K6,Pke),e(Pke,Wct),e(K6,Uct),e(K6,Rle),e(Rle,Hct),e(K6,Jct),e(te,Yct),e(te,e7),e(e7,Bke),e(Bke,Zct),e(e7,Kct),e(e7,Ple),e(Ple,eft),e(e7,oft),e(te,rft),e(te,o7),e(o7,Ike),e(Ike,tft),e(o7,aft),e(o7,Ble),e(Ble,nft),e(o7,sft),e(te,lft),e(te,r7),e(r7,Nke),e(Nke,ift),e(r7,dft),e(r7,Ile),e(Ile,mft),e(r7,cft),e(te,fft),e(te,t7),e(t7,qke),e(qke,gft),e(t7,hft),e(t7,Nle),e(Nle,uft),e(t7,pft),e(Yr,_ft),M(a7,Yr,null),b(c,Hio,_),b(c,Xc,_),e(Xc,n7),e(n7,Dke),M(dB,Dke,null),e(Xc,bft),e(Xc,jke),e(jke,vft),b(c,Jio,_),b(c,Mr,_),M(mB,Mr,null),e(Mr,Fft),e(Mr,zc),e(zc,Tft),e(zc,qle),e(qle,Mft),e(zc,Eft),e(zc,Dle),e(Dle,Cft),e(zc,wft),e(Mr,Aft),e(Mr,cB),e(cB,Lft),e(cB,Gke),e(Gke,yft),e(cB,xft),e(Mr,$ft),e(Mr,da),M(fB,da,null),e(da,kft),e(da,Oke),e(Oke,Sft),e(da,Rft),e(da,Qc),e(Qc,Pft),e(Qc,Vke),e(Vke,Bft),e(Qc,Ift),e(Qc,jle),e(jle,Nft),e(Qc,qft),e(da,Dft),M(s7,da,null),e(Mr,jft),e(Mr,Zr),M(gB,Zr,null),e(Zr,Gft),e(Zr,Xke),e(Xke,Oft),e(Zr,Vft),e(Zr,Hn),e(Hn,Xft),e(Hn,zke),e(zke,zft),e(Hn,Qft),e(Hn,Qke),e(Qke,Wft),e(Hn,Uft),e(Hn,Wke),e(Wke,Hft),e(Hn,Jft),e(Zr,Yft),e(Zr,Te),e(Te,l7),e(l7,Uke),e(Uke,Zft),e(l7,Kft),e(l7,Gle),e(Gle,egt),e(l7,ogt),e(Te,rgt),e(Te,i7),e(i7,Hke),e(Hke,tgt),e(i7,agt),e(i7,Ole),e(Ole,ngt),e(i7,sgt),e(Te,lgt),e(Te,d7),e(d7,Jke),e(Jke,igt),e(d7,dgt),e(d7,Vle),e(Vle,mgt),e(d7,cgt),e(Te,fgt),e(Te,m7),e(m7,Yke),e(Yke,ggt),e(m7,hgt),e(m7,Xle),e(Xle,ugt),e(m7,pgt),e(Te,_gt),e(Te,c7),e(c7,Zke),e(Zke,bgt),e(c7,vgt),e(c7,zle),e(zle,Fgt),e(c7,Tgt),e(Te,Mgt),e(Te,f7),e(f7,Kke),e(Kke,Egt),e(f7,Cgt),e(f7,Qle),e(Qle,wgt),e(f7,Agt),e(Te,Lgt),e(Te,g7),e(g7,eSe),e(eSe,ygt),e(g7,xgt),e(g7,Wle),e(Wle,$gt),e(g7,kgt),e(Te,Sgt),e(Te,h7),e(h7,oSe),e(oSe,Rgt),e(h7,Pgt),e(h7,Ule),e(Ule,Bgt),e(h7,Igt),e(Te,Ngt),e(Te,u7),e(u7,rSe),e(rSe,qgt),e(u7,Dgt),e(u7,Hle),e(Hle,jgt),e(u7,Ggt),e(Te,Ogt),e(Te,p7),e(p7,tSe),e(tSe,Vgt),e(p7,Xgt),e(p7,Jle),e(Jle,zgt),e(p7,Qgt),e(Te,Wgt),e(Te,_7),e(_7,aSe),e(aSe,Ugt),e(_7,Hgt),e(_7,Yle),e(Yle,Jgt),e(_7,Ygt),e(Te,Zgt),e(Te,b7),e(b7,nSe),e(nSe,Kgt),e(b7,eht),e(b7,Zle),e(Zle,oht),e(b7,rht),e(Te,tht),e(Te,v7),e(v7,sSe),e(sSe,aht),e(v7,nht),e(v7,Kle),e(Kle,sht),e(v7,lht),e(Te,iht),e(Te,F7),e(F7,lSe),e(lSe,dht),e(F7,mht),e(F7,eie),e(eie,cht),e(F7,fht),e(Te,ght),e(Te,T7),e(T7,iSe),e(iSe,hht),e(T7,uht),e(T7,oie),e(oie,pht),e(T7,_ht),e(Te,bht),e(Te,M7),e(M7,dSe),e(dSe,vht),e(M7,Fht),e(M7,rie),e(rie,Tht),e(M7,Mht),e(Te,Eht),e(Te,E7),e(E7,mSe),e(mSe,Cht),e(E7,wht),e(E7,tie),e(tie,Aht),e(E7,Lht),e(Zr,yht),M(C7,Zr,null),b(c,Yio,_),b(c,Wc,_),e(Wc,w7),e(w7,cSe),M(hB,cSe,null),e(Wc,xht),e(Wc,fSe),e(fSe,$ht),b(c,Zio,_),b(c,Er,_),M(uB,Er,null),e(Er,kht),e(Er,Uc),e(Uc,Sht),e(Uc,aie),e(aie,Rht),e(Uc,Pht),e(Uc,nie),e(nie,Bht),e(Uc,Iht),e(Er,Nht),e(Er,pB),e(pB,qht),e(pB,gSe),e(gSe,Dht),e(pB,jht),e(Er,Ght),e(Er,ma),M(_B,ma,null),e(ma,Oht),e(ma,hSe),e(hSe,Vht),e(ma,Xht),e(ma,Hc),e(Hc,zht),e(Hc,uSe),e(uSe,Qht),e(Hc,Wht),e(Hc,sie),e(sie,Uht),e(Hc,Hht),e(ma,Jht),M(A7,ma,null),e(Er,Yht),e(Er,Kr),M(bB,Kr,null),e(Kr,Zht),e(Kr,pSe),e(pSe,Kht),e(Kr,eut),e(Kr,Jn),e(Jn,out),e(Jn,_Se),e(_Se,rut),e(Jn,tut),e(Jn,bSe),e(bSe,aut),e(Jn,nut),e(Jn,vSe),e(vSe,sut),e(Jn,lut),e(Kr,iut),e(Kr,vB),e(vB,L7),e(L7,FSe),e(FSe,dut),e(L7,mut),e(L7,lie),e(lie,cut),e(L7,fut),e(vB,gut),e(vB,y7),e(y7,TSe),e(TSe,hut),e(y7,uut),e(y7,iie),e(iie,put),e(y7,_ut),e(Kr,but),M(x7,Kr,null),b(c,Kio,_),b(c,Jc,_),e(Jc,$7),e($7,MSe),M(FB,MSe,null),e(Jc,vut),e(Jc,ESe),e(ESe,Fut),b(c,edo,_),b(c,Cr,_),M(TB,Cr,null),e(Cr,Tut),e(Cr,Yc),e(Yc,Mut),e(Yc,die),e(die,Eut),e(Yc,Cut),e(Yc,mie),e(mie,wut),e(Yc,Aut),e(Cr,Lut),e(Cr,MB),e(MB,yut),e(MB,CSe),e(CSe,xut),e(MB,$ut),e(Cr,kut),e(Cr,ca),M(EB,ca,null),e(ca,Sut),e(ca,wSe),e(wSe,Rut),e(ca,Put),e(ca,Zc),e(Zc,But),e(Zc,ASe),e(ASe,Iut),e(Zc,Nut),e(Zc,cie),e(cie,qut),e(Zc,Dut),e(ca,jut),M(k7,ca,null),e(Cr,Gut),e(Cr,et),M(CB,et,null),e(et,Out),e(et,LSe),e(LSe,Vut),e(et,Xut),e(et,Yn),e(Yn,zut),e(Yn,ySe),e(ySe,Qut),e(Yn,Wut),e(Yn,xSe),e(xSe,Uut),e(Yn,Hut),e(Yn,$Se),e($Se,Jut),e(Yn,Yut),e(et,Zut),e(et,kSe),e(kSe,S7),e(S7,SSe),e(SSe,Kut),e(S7,ept),e(S7,fie),e(fie,opt),e(S7,rpt),e(et,tpt),M(R7,et,null),b(c,odo,_),b(c,Kc,_),e(Kc,P7),e(P7,RSe),M(wB,RSe,null),e(Kc,apt),e(Kc,PSe),e(PSe,npt),b(c,rdo,_),b(c,wr,_),M(AB,wr,null),e(wr,spt),e(wr,ef),e(ef,lpt),e(ef,gie),e(gie,ipt),e(ef,dpt),e(ef,hie),e(hie,mpt),e(ef,cpt),e(wr,fpt),e(wr,LB),e(LB,gpt),e(LB,BSe),e(BSe,hpt),e(LB,upt),e(wr,ppt),e(wr,fa),M(yB,fa,null),e(fa,_pt),e(fa,ISe),e(ISe,bpt),e(fa,vpt),e(fa,of),e(of,Fpt),e(of,NSe),e(NSe,Tpt),e(of,Mpt),e(of,uie),e(uie,Ept),e(of,Cpt),e(fa,wpt),M(B7,fa,null),e(wr,Apt),e(wr,ot),M(xB,ot,null),e(ot,Lpt),e(ot,qSe),e(qSe,ypt),e(ot,xpt),e(ot,Zn),e(Zn,$pt),e(Zn,DSe),e(DSe,kpt),e(Zn,Spt),e(Zn,jSe),e(jSe,Rpt),e(Zn,Ppt),e(Zn,GSe),e(GSe,Bpt),e(Zn,Ipt),e(ot,Npt),e(ot,OSe),e(OSe,I7),e(I7,VSe),e(VSe,qpt),e(I7,Dpt),e(I7,pie),e(pie,jpt),e(I7,Gpt),e(ot,Opt),M(N7,ot,null),b(c,tdo,_),b(c,rf,_),e(rf,q7),e(q7,XSe),M($B,XSe,null),e(rf,Vpt),e(rf,zSe),e(zSe,Xpt),b(c,ado,_),b(c,Ar,_),M(kB,Ar,null),e(Ar,zpt),e(Ar,tf),e(tf,Qpt),e(tf,_ie),e(_ie,Wpt),e(tf,Upt),e(tf,bie),e(bie,Hpt),e(tf,Jpt),e(Ar,Ypt),e(Ar,SB),e(SB,Zpt),e(SB,QSe),e(QSe,Kpt),e(SB,e_t),e(Ar,o_t),e(Ar,ga),M(RB,ga,null),e(ga,r_t),e(ga,WSe),e(WSe,t_t),e(ga,a_t),e(ga,af),e(af,n_t),e(af,USe),e(USe,s_t),e(af,l_t),e(af,vie),e(vie,i_t),e(af,d_t),e(ga,m_t),M(D7,ga,null),e(Ar,c_t),e(Ar,rt),M(PB,rt,null),e(rt,f_t),e(rt,HSe),e(HSe,g_t),e(rt,h_t),e(rt,Kn),e(Kn,u_t),e(Kn,JSe),e(JSe,p_t),e(Kn,__t),e(Kn,YSe),e(YSe,b_t),e(Kn,v_t),e(Kn,ZSe),e(ZSe,F_t),e(Kn,T_t),e(rt,M_t),e(rt,me),e(me,j7),e(j7,KSe),e(KSe,E_t),e(j7,C_t),e(j7,Fie),e(Fie,w_t),e(j7,A_t),e(me,L_t),e(me,G7),e(G7,eRe),e(eRe,y_t),e(G7,x_t),e(G7,Tie),e(Tie,$_t),e(G7,k_t),e(me,S_t),e(me,O7),e(O7,oRe),e(oRe,R_t),e(O7,P_t),e(O7,Mie),e(Mie,B_t),e(O7,I_t),e(me,N_t),e(me,V7),e(V7,rRe),e(rRe,q_t),e(V7,D_t),e(V7,Eie),e(Eie,j_t),e(V7,G_t),e(me,O_t),e(me,X7),e(X7,tRe),e(tRe,V_t),e(X7,X_t),e(X7,Cie),e(Cie,z_t),e(X7,Q_t),e(me,W_t),e(me,z7),e(z7,aRe),e(aRe,U_t),e(z7,H_t),e(z7,wie),e(wie,J_t),e(z7,Y_t),e(me,Z_t),e(me,Q7),e(Q7,nRe),e(nRe,K_t),e(Q7,e1t),e(Q7,Aie),e(Aie,o1t),e(Q7,r1t),e(me,t1t),e(me,W7),e(W7,sRe),e(sRe,a1t),e(W7,n1t),e(W7,Lie),e(Lie,s1t),e(W7,l1t),e(me,i1t),e(me,U7),e(U7,lRe),e(lRe,d1t),e(U7,m1t),e(U7,yie),e(yie,c1t),e(U7,f1t),e(me,g1t),e(me,H7),e(H7,iRe),e(iRe,h1t),e(H7,u1t),e(H7,xie),e(xie,p1t),e(H7,_1t),e(me,b1t),e(me,J7),e(J7,dRe),e(dRe,v1t),e(J7,F1t),e(J7,$ie),e($ie,T1t),e(J7,M1t),e(me,E1t),e(me,Y7),e(Y7,mRe),e(mRe,C1t),e(Y7,w1t),e(Y7,kie),e(kie,A1t),e(Y7,L1t),e(me,y1t),e(me,Z7),e(Z7,cRe),e(cRe,x1t),e(Z7,$1t),e(Z7,Sie),e(Sie,k1t),e(Z7,S1t),e(me,R1t),e(me,K7),e(K7,fRe),e(fRe,P1t),e(K7,B1t),e(K7,Rie),e(Rie,I1t),e(K7,N1t),e(me,q1t),e(me,e8),e(e8,gRe),e(gRe,D1t),e(e8,j1t),e(e8,Pie),e(Pie,G1t),e(e8,O1t),e(me,V1t),e(me,o8),e(o8,hRe),e(hRe,X1t),e(o8,z1t),e(o8,Bie),e(Bie,Q1t),e(o8,W1t),e(me,U1t),e(me,r8),e(r8,uRe),e(uRe,H1t),e(r8,J1t),e(r8,Iie),e(Iie,Y1t),e(r8,Z1t),e(me,K1t),e(me,t8),e(t8,pRe),e(pRe,e2t),e(t8,o2t),e(t8,Nie),e(Nie,r2t),e(t8,t2t),e(me,a2t),e(me,a8),e(a8,_Re),e(_Re,n2t),e(a8,s2t),e(a8,qie),e(qie,l2t),e(a8,i2t),e(me,d2t),e(me,n8),e(n8,bRe),e(bRe,m2t),e(n8,c2t),e(n8,Die),e(Die,f2t),e(n8,g2t),e(me,h2t),e(me,s8),e(s8,vRe),e(vRe,u2t),e(s8,p2t),e(s8,jie),e(jie,_2t),e(s8,b2t),e(me,v2t),e(me,l8),e(l8,FRe),e(FRe,F2t),e(l8,T2t),e(l8,Gie),e(Gie,M2t),e(l8,E2t),e(rt,C2t),M(i8,rt,null),b(c,ndo,_),b(c,nf,_),e(nf,d8),e(d8,TRe),M(BB,TRe,null),e(nf,w2t),e(nf,MRe),e(MRe,A2t),b(c,sdo,_),b(c,Lr,_),M(IB,Lr,null),e(Lr,L2t),e(Lr,sf),e(sf,y2t),e(sf,Oie),e(Oie,x2t),e(sf,$2t),e(sf,Vie),e(Vie,k2t),e(sf,S2t),e(Lr,R2t),e(Lr,NB),e(NB,P2t),e(NB,ERe),e(ERe,B2t),e(NB,I2t),e(Lr,N2t),e(Lr,ha),M(qB,ha,null),e(ha,q2t),e(ha,CRe),e(CRe,D2t),e(ha,j2t),e(ha,lf),e(lf,G2t),e(lf,wRe),e(wRe,O2t),e(lf,V2t),e(lf,Xie),e(Xie,X2t),e(lf,z2t),e(ha,Q2t),M(m8,ha,null),e(Lr,W2t),e(Lr,tt),M(DB,tt,null),e(tt,U2t),e(tt,ARe),e(ARe,H2t),e(tt,J2t),e(tt,es),e(es,Y2t),e(es,LRe),e(LRe,Z2t),e(es,K2t),e(es,yRe),e(yRe,ebt),e(es,obt),e(es,xRe),e(xRe,rbt),e(es,tbt),e(tt,abt),e(tt,he),e(he,c8),e(c8,$Re),e($Re,nbt),e(c8,sbt),e(c8,zie),e(zie,lbt),e(c8,ibt),e(he,dbt),e(he,f8),e(f8,kRe),e(kRe,mbt),e(f8,cbt),e(f8,Qie),e(Qie,fbt),e(f8,gbt),e(he,hbt),e(he,g8),e(g8,SRe),e(SRe,ubt),e(g8,pbt),e(g8,Wie),e(Wie,_bt),e(g8,bbt),e(he,vbt),e(he,h8),e(h8,RRe),e(RRe,Fbt),e(h8,Tbt),e(h8,Uie),e(Uie,Mbt),e(h8,Ebt),e(he,Cbt),e(he,u8),e(u8,PRe),e(PRe,wbt),e(u8,Abt),e(u8,Hie),e(Hie,Lbt),e(u8,ybt),e(he,xbt),e(he,p8),e(p8,BRe),e(BRe,$bt),e(p8,kbt),e(p8,Jie),e(Jie,Sbt),e(p8,Rbt),e(he,Pbt),e(he,_8),e(_8,IRe),e(IRe,Bbt),e(_8,Ibt),e(_8,Yie),e(Yie,Nbt),e(_8,qbt),e(he,Dbt),e(he,b8),e(b8,NRe),e(NRe,jbt),e(b8,Gbt),e(b8,Zie),e(Zie,Obt),e(b8,Vbt),e(he,Xbt),e(he,v8),e(v8,qRe),e(qRe,zbt),e(v8,Qbt),e(v8,Kie),e(Kie,Wbt),e(v8,Ubt),e(he,Hbt),e(he,F8),e(F8,DRe),e(DRe,Jbt),e(F8,Ybt),e(F8,ede),e(ede,Zbt),e(F8,Kbt),e(he,evt),e(he,T8),e(T8,jRe),e(jRe,ovt),e(T8,rvt),e(T8,ode),e(ode,tvt),e(T8,avt),e(he,nvt),e(he,M8),e(M8,GRe),e(GRe,svt),e(M8,lvt),e(M8,rde),e(rde,ivt),e(M8,dvt),e(he,mvt),e(he,E8),e(E8,ORe),e(ORe,cvt),e(E8,fvt),e(E8,tde),e(tde,gvt),e(E8,hvt),e(he,uvt),e(he,C8),e(C8,VRe),e(VRe,pvt),e(C8,_vt),e(C8,ade),e(ade,bvt),e(C8,vvt),e(he,Fvt),e(he,w8),e(w8,XRe),e(XRe,Tvt),e(w8,Mvt),e(w8,nde),e(nde,Evt),e(w8,Cvt),e(he,wvt),e(he,A8),e(A8,zRe),e(zRe,Avt),e(A8,Lvt),e(A8,sde),e(sde,yvt),e(A8,xvt),e(he,$vt),e(he,L8),e(L8,QRe),e(QRe,kvt),e(L8,Svt),e(L8,lde),e(lde,Rvt),e(L8,Pvt),e(he,Bvt),e(he,y8),e(y8,WRe),e(WRe,Ivt),e(y8,Nvt),e(y8,ide),e(ide,qvt),e(y8,Dvt),e(he,jvt),e(he,x8),e(x8,URe),e(URe,Gvt),e(x8,Ovt),e(x8,dde),e(dde,Vvt),e(x8,Xvt),e(he,zvt),e(he,$8),e($8,HRe),e(HRe,Qvt),e($8,Wvt),e($8,mde),e(mde,Uvt),e($8,Hvt),e(he,Jvt),e(he,k8),e(k8,JRe),e(JRe,Yvt),e(k8,Zvt),e(k8,cde),e(cde,Kvt),e(k8,eFt),e(tt,oFt),M(S8,tt,null),b(c,ldo,_),b(c,df,_),e(df,R8),e(R8,YRe),M(jB,YRe,null),e(df,rFt),e(df,ZRe),e(ZRe,tFt),b(c,ido,_),b(c,yr,_),M(GB,yr,null),e(yr,aFt),e(yr,mf),e(mf,nFt),e(mf,fde),e(fde,sFt),e(mf,lFt),e(mf,gde),e(gde,iFt),e(mf,dFt),e(yr,mFt),e(yr,OB),e(OB,cFt),e(OB,KRe),e(KRe,fFt),e(OB,gFt),e(yr,hFt),e(yr,ua),M(VB,ua,null),e(ua,uFt),e(ua,ePe),e(ePe,pFt),e(ua,_Ft),e(ua,cf),e(cf,bFt),e(cf,oPe),e(oPe,vFt),e(cf,FFt),e(cf,hde),e(hde,TFt),e(cf,MFt),e(ua,EFt),M(P8,ua,null),e(yr,CFt),e(yr,at),M(XB,at,null),e(at,wFt),e(at,rPe),e(rPe,AFt),e(at,LFt),e(at,os),e(os,yFt),e(os,tPe),e(tPe,xFt),e(os,$Ft),e(os,aPe),e(aPe,kFt),e(os,SFt),e(os,nPe),e(nPe,RFt),e(os,PFt),e(at,BFt),e(at,sPe),e(sPe,B8),e(B8,lPe),e(lPe,IFt),e(B8,NFt),e(B8,ude),e(ude,qFt),e(B8,DFt),e(at,jFt),M(I8,at,null),b(c,ddo,_),b(c,ff,_),e(ff,N8),e(N8,iPe),M(zB,iPe,null),e(ff,GFt),e(ff,dPe),e(dPe,OFt),b(c,mdo,_),b(c,xr,_),M(QB,xr,null),e(xr,VFt),e(xr,gf),e(gf,XFt),e(gf,pde),e(pde,zFt),e(gf,QFt),e(gf,_de),e(_de,WFt),e(gf,UFt),e(xr,HFt),e(xr,WB),e(WB,JFt),e(WB,mPe),e(mPe,YFt),e(WB,ZFt),e(xr,KFt),e(xr,pa),M(UB,pa,null),e(pa,eTt),e(pa,cPe),e(cPe,oTt),e(pa,rTt),e(pa,hf),e(hf,tTt),e(hf,fPe),e(fPe,aTt),e(hf,nTt),e(hf,bde),e(bde,sTt),e(hf,lTt),e(pa,iTt),M(q8,pa,null),e(xr,dTt),e(xr,nt),M(HB,nt,null),e(nt,mTt),e(nt,gPe),e(gPe,cTt),e(nt,fTt),e(nt,rs),e(rs,gTt),e(rs,hPe),e(hPe,hTt),e(rs,uTt),e(rs,uPe),e(uPe,pTt),e(rs,_Tt),e(rs,pPe),e(pPe,bTt),e(rs,vTt),e(nt,FTt),e(nt,JB),e(JB,D8),e(D8,_Pe),e(_Pe,TTt),e(D8,MTt),e(D8,vde),e(vde,ETt),e(D8,CTt),e(JB,wTt),e(JB,j8),e(j8,bPe),e(bPe,ATt),e(j8,LTt),e(j8,Fde),e(Fde,yTt),e(j8,xTt),e(nt,$Tt),M(G8,nt,null),b(c,cdo,_),b(c,uf,_),e(uf,O8),e(O8,vPe),M(YB,vPe,null),e(uf,kTt),e(uf,FPe),e(FPe,STt),b(c,fdo,_),b(c,$r,_),M(ZB,$r,null),e($r,RTt),e($r,pf),e(pf,PTt),e(pf,Tde),e(Tde,BTt),e(pf,ITt),e(pf,Mde),e(Mde,NTt),e(pf,qTt),e($r,DTt),e($r,KB),e(KB,jTt),e(KB,TPe),e(TPe,GTt),e(KB,OTt),e($r,VTt),e($r,_a),M(eI,_a,null),e(_a,XTt),e(_a,MPe),e(MPe,zTt),e(_a,QTt),e(_a,_f),e(_f,WTt),e(_f,EPe),e(EPe,UTt),e(_f,HTt),e(_f,Ede),e(Ede,JTt),e(_f,YTt),e(_a,ZTt),M(V8,_a,null),e($r,KTt),e($r,st),M(oI,st,null),e(st,eMt),e(st,CPe),e(CPe,oMt),e(st,rMt),e(st,ts),e(ts,tMt),e(ts,wPe),e(wPe,aMt),e(ts,nMt),e(ts,APe),e(APe,sMt),e(ts,lMt),e(ts,LPe),e(LPe,iMt),e(ts,dMt),e(st,mMt),e(st,ne),e(ne,X8),e(X8,yPe),e(yPe,cMt),e(X8,fMt),e(X8,Cde),e(Cde,gMt),e(X8,hMt),e(ne,uMt),e(ne,z8),e(z8,xPe),e(xPe,pMt),e(z8,_Mt),e(z8,wde),e(wde,bMt),e(z8,vMt),e(ne,FMt),e(ne,Q8),e(Q8,$Pe),e($Pe,TMt),e(Q8,MMt),e(Q8,Ade),e(Ade,EMt),e(Q8,CMt),e(ne,wMt),e(ne,W8),e(W8,kPe),e(kPe,AMt),e(W8,LMt),e(W8,Lde),e(Lde,yMt),e(W8,xMt),e(ne,$Mt),e(ne,U8),e(U8,SPe),e(SPe,kMt),e(U8,SMt),e(U8,yde),e(yde,RMt),e(U8,PMt),e(ne,BMt),e(ne,H8),e(H8,RPe),e(RPe,IMt),e(H8,NMt),e(H8,xde),e(xde,qMt),e(H8,DMt),e(ne,jMt),e(ne,J8),e(J8,PPe),e(PPe,GMt),e(J8,OMt),e(J8,$de),e($de,VMt),e(J8,XMt),e(ne,zMt),e(ne,Y8),e(Y8,BPe),e(BPe,QMt),e(Y8,WMt),e(Y8,kde),e(kde,UMt),e(Y8,HMt),e(ne,JMt),e(ne,Z8),e(Z8,IPe),e(IPe,YMt),e(Z8,ZMt),e(Z8,Sde),e(Sde,KMt),e(Z8,eEt),e(ne,oEt),e(ne,K8),e(K8,NPe),e(NPe,rEt),e(K8,tEt),e(K8,Rde),e(Rde,aEt),e(K8,nEt),e(ne,sEt),e(ne,eL),e(eL,qPe),e(qPe,lEt),e(eL,iEt),e(eL,Pde),e(Pde,dEt),e(eL,mEt),e(ne,cEt),e(ne,oL),e(oL,DPe),e(DPe,fEt),e(oL,gEt),e(oL,Bde),e(Bde,hEt),e(oL,uEt),e(ne,pEt),e(ne,rL),e(rL,jPe),e(jPe,_Et),e(rL,bEt),e(rL,Ide),e(Ide,vEt),e(rL,FEt),e(ne,TEt),e(ne,tL),e(tL,GPe),e(GPe,MEt),e(tL,EEt),e(tL,Nde),e(Nde,CEt),e(tL,wEt),e(ne,AEt),e(ne,aL),e(aL,OPe),e(OPe,LEt),e(aL,yEt),e(aL,qde),e(qde,xEt),e(aL,$Et),e(ne,kEt),e(ne,nL),e(nL,VPe),e(VPe,SEt),e(nL,REt),e(nL,Dde),e(Dde,PEt),e(nL,BEt),e(ne,IEt),e(ne,sL),e(sL,XPe),e(XPe,NEt),e(sL,qEt),e(sL,jde),e(jde,DEt),e(sL,jEt),e(ne,GEt),e(ne,lL),e(lL,zPe),e(zPe,OEt),e(lL,VEt),e(lL,Gde),e(Gde,XEt),e(lL,zEt),e(ne,QEt),e(ne,iL),e(iL,QPe),e(QPe,WEt),e(iL,UEt),e(iL,Ode),e(Ode,HEt),e(iL,JEt),e(ne,YEt),e(ne,dL),e(dL,WPe),e(WPe,ZEt),e(dL,KEt),e(dL,Vde),e(Vde,e4t),e(dL,o4t),e(ne,r4t),e(ne,mL),e(mL,UPe),e(UPe,t4t),e(mL,a4t),e(mL,Xde),e(Xde,n4t),e(mL,s4t),e(ne,l4t),e(ne,cL),e(cL,HPe),e(HPe,i4t),e(cL,d4t),e(cL,zde),e(zde,m4t),e(cL,c4t),e(ne,f4t),e(ne,fL),e(fL,JPe),e(JPe,g4t),e(fL,h4t),e(fL,Qde),e(Qde,u4t),e(fL,p4t),e(ne,_4t),e(ne,gL),e(gL,YPe),e(YPe,b4t),e(gL,v4t),e(gL,Wde),e(Wde,F4t),e(gL,T4t),e(ne,M4t),e(ne,hL),e(hL,ZPe),e(ZPe,E4t),e(hL,C4t),e(hL,Ude),e(Ude,w4t),e(hL,A4t),e(ne,L4t),e(ne,uL),e(uL,KPe),e(KPe,y4t),e(uL,x4t),e(uL,Hde),e(Hde,$4t),e(uL,k4t),e(ne,S4t),e(ne,pL),e(pL,eBe),e(eBe,R4t),e(pL,P4t),e(pL,Jde),e(Jde,B4t),e(pL,I4t),e(st,N4t),M(_L,st,null),b(c,gdo,_),b(c,bf,_),e(bf,bL),e(bL,oBe),M(rI,oBe,null),e(bf,q4t),e(bf,rBe),e(rBe,D4t),b(c,hdo,_),b(c,kr,_),M(tI,kr,null),e(kr,j4t),e(kr,vf),e(vf,G4t),e(vf,Yde),e(Yde,O4t),e(vf,V4t),e(vf,Zde),e(Zde,X4t),e(vf,z4t),e(kr,Q4t),e(kr,aI),e(aI,W4t),e(aI,tBe),e(tBe,U4t),e(aI,H4t),e(kr,J4t),e(kr,ba),M(nI,ba,null),e(ba,Y4t),e(ba,aBe),e(aBe,Z4t),e(ba,K4t),e(ba,Ff),e(Ff,eCt),e(Ff,nBe),e(nBe,oCt),e(Ff,rCt),e(Ff,Kde),e(Kde,tCt),e(Ff,aCt),e(ba,nCt),M(vL,ba,null),e(kr,sCt),e(kr,lt),M(sI,lt,null),e(lt,lCt),e(lt,sBe),e(sBe,iCt),e(lt,dCt),e(lt,as),e(as,mCt),e(as,lBe),e(lBe,cCt),e(as,fCt),e(as,iBe),e(iBe,gCt),e(as,hCt),e(as,dBe),e(dBe,uCt),e(as,pCt),e(lt,_Ct),e(lt,Se),e(Se,FL),e(FL,mBe),e(mBe,bCt),e(FL,vCt),e(FL,eme),e(eme,FCt),e(FL,TCt),e(Se,MCt),e(Se,TL),e(TL,cBe),e(cBe,ECt),e(TL,CCt),e(TL,ome),e(ome,wCt),e(TL,ACt),e(Se,LCt),e(Se,ML),e(ML,fBe),e(fBe,yCt),e(ML,xCt),e(ML,rme),e(rme,$Ct),e(ML,kCt),e(Se,SCt),e(Se,EL),e(EL,gBe),e(gBe,RCt),e(EL,PCt),e(EL,tme),e(tme,BCt),e(EL,ICt),e(Se,NCt),e(Se,CL),e(CL,hBe),e(hBe,qCt),e(CL,DCt),e(CL,ame),e(ame,jCt),e(CL,GCt),e(Se,OCt),e(Se,wL),e(wL,uBe),e(uBe,VCt),e(wL,XCt),e(wL,nme),e(nme,zCt),e(wL,QCt),e(Se,WCt),e(Se,AL),e(AL,pBe),e(pBe,UCt),e(AL,HCt),e(AL,sme),e(sme,JCt),e(AL,YCt),e(Se,ZCt),e(Se,LL),e(LL,_Be),e(_Be,KCt),e(LL,e3t),e(LL,lme),e(lme,o3t),e(LL,r3t),e(Se,t3t),e(Se,yL),e(yL,bBe),e(bBe,a3t),e(yL,n3t),e(yL,ime),e(ime,s3t),e(yL,l3t),e(Se,i3t),e(Se,xL),e(xL,vBe),e(vBe,d3t),e(xL,m3t),e(xL,dme),e(dme,c3t),e(xL,f3t),e(lt,g3t),M($L,lt,null),b(c,udo,_),b(c,Tf,_),e(Tf,kL),e(kL,FBe),M(lI,FBe,null),e(Tf,h3t),e(Tf,TBe),e(TBe,u3t),b(c,pdo,_),b(c,Sr,_),M(iI,Sr,null),e(Sr,p3t),e(Sr,Mf),e(Mf,_3t),e(Mf,mme),e(mme,b3t),e(Mf,v3t),e(Mf,cme),e(cme,F3t),e(Mf,T3t),e(Sr,M3t),e(Sr,dI),e(dI,E3t),e(dI,MBe),e(MBe,C3t),e(dI,w3t),e(Sr,A3t),e(Sr,va),M(mI,va,null),e(va,L3t),e(va,EBe),e(EBe,y3t),e(va,x3t),e(va,Ef),e(Ef,$3t),e(Ef,CBe),e(CBe,k3t),e(Ef,S3t),e(Ef,fme),e(fme,R3t),e(Ef,P3t),e(va,B3t),M(SL,va,null),e(Sr,I3t),e(Sr,it),M(cI,it,null),e(it,N3t),e(it,wBe),e(wBe,q3t),e(it,D3t),e(it,ns),e(ns,j3t),e(ns,ABe),e(ABe,G3t),e(ns,O3t),e(ns,LBe),e(LBe,V3t),e(ns,X3t),e(ns,yBe),e(yBe,z3t),e(ns,Q3t),e(it,W3t),e(it,we),e(we,RL),e(RL,xBe),e(xBe,U3t),e(RL,H3t),e(RL,gme),e(gme,J3t),e(RL,Y3t),e(we,Z3t),e(we,PL),e(PL,$Be),e($Be,K3t),e(PL,e5t),e(PL,hme),e(hme,o5t),e(PL,r5t),e(we,t5t),e(we,BL),e(BL,kBe),e(kBe,a5t),e(BL,n5t),e(BL,ume),e(ume,s5t),e(BL,l5t),e(we,i5t),e(we,IL),e(IL,SBe),e(SBe,d5t),e(IL,m5t),e(IL,pme),e(pme,c5t),e(IL,f5t),e(we,g5t),e(we,NL),e(NL,RBe),e(RBe,h5t),e(NL,u5t),e(NL,_me),e(_me,p5t),e(NL,_5t),e(we,b5t),e(we,qL),e(qL,PBe),e(PBe,v5t),e(qL,F5t),e(qL,bme),e(bme,T5t),e(qL,M5t),e(we,E5t),e(we,DL),e(DL,BBe),e(BBe,C5t),e(DL,w5t),e(DL,vme),e(vme,A5t),e(DL,L5t),e(we,y5t),e(we,jL),e(jL,IBe),e(IBe,x5t),e(jL,$5t),e(jL,Fme),e(Fme,k5t),e(jL,S5t),e(we,R5t),e(we,GL),e(GL,NBe),e(NBe,P5t),e(GL,B5t),e(GL,Tme),e(Tme,I5t),e(GL,N5t),e(we,q5t),e(we,OL),e(OL,qBe),e(qBe,D5t),e(OL,j5t),e(OL,Mme),e(Mme,G5t),e(OL,O5t),e(we,V5t),e(we,VL),e(VL,DBe),e(DBe,X5t),e(VL,z5t),e(VL,Eme),e(Eme,Q5t),e(VL,W5t),e(we,U5t),e(we,XL),e(XL,jBe),e(jBe,H5t),e(XL,J5t),e(XL,Cme),e(Cme,Y5t),e(XL,Z5t),e(we,K5t),e(we,zL),e(zL,GBe),e(GBe,e0t),e(zL,o0t),e(zL,wme),e(wme,r0t),e(zL,t0t),e(it,a0t),M(QL,it,null),b(c,_do,_),b(c,Cf,_),e(Cf,WL),e(WL,OBe),M(fI,OBe,null),e(Cf,n0t),e(Cf,VBe),e(VBe,s0t),b(c,bdo,_),b(c,Rr,_),M(gI,Rr,null),e(Rr,l0t),e(Rr,wf),e(wf,i0t),e(wf,Ame),e(Ame,d0t),e(wf,m0t),e(wf,Lme),e(Lme,c0t),e(wf,f0t),e(Rr,g0t),e(Rr,hI),e(hI,h0t),e(hI,XBe),e(XBe,u0t),e(hI,p0t),e(Rr,_0t),e(Rr,Fa),M(uI,Fa,null),e(Fa,b0t),e(Fa,zBe),e(zBe,v0t),e(Fa,F0t),e(Fa,Af),e(Af,T0t),e(Af,QBe),e(QBe,M0t),e(Af,E0t),e(Af,yme),e(yme,C0t),e(Af,w0t),e(Fa,A0t),M(UL,Fa,null),e(Rr,L0t),e(Rr,dt),M(pI,dt,null),e(dt,y0t),e(dt,WBe),e(WBe,x0t),e(dt,$0t),e(dt,ss),e(ss,k0t),e(ss,UBe),e(UBe,S0t),e(ss,R0t),e(ss,HBe),e(HBe,P0t),e(ss,B0t),e(ss,JBe),e(JBe,I0t),e(ss,N0t),e(dt,q0t),e(dt,Re),e(Re,HL),e(HL,YBe),e(YBe,D0t),e(HL,j0t),e(HL,xme),e(xme,G0t),e(HL,O0t),e(Re,V0t),e(Re,JL),e(JL,ZBe),e(ZBe,X0t),e(JL,z0t),e(JL,$me),e($me,Q0t),e(JL,W0t),e(Re,U0t),e(Re,YL),e(YL,KBe),e(KBe,H0t),e(YL,J0t),e(YL,kme),e(kme,Y0t),e(YL,Z0t),e(Re,K0t),e(Re,ZL),e(ZL,eIe),e(eIe,ewt),e(ZL,owt),e(ZL,Sme),e(Sme,rwt),e(ZL,twt),e(Re,awt),e(Re,KL),e(KL,oIe),e(oIe,nwt),e(KL,swt),e(KL,Rme),e(Rme,lwt),e(KL,iwt),e(Re,dwt),e(Re,ey),e(ey,rIe),e(rIe,mwt),e(ey,cwt),e(ey,Pme),e(Pme,fwt),e(ey,gwt),e(Re,hwt),e(Re,oy),e(oy,tIe),e(tIe,uwt),e(oy,pwt),e(oy,Bme),e(Bme,_wt),e(oy,bwt),e(Re,vwt),e(Re,ry),e(ry,aIe),e(aIe,Fwt),e(ry,Twt),e(ry,Ime),e(Ime,Mwt),e(ry,Ewt),e(Re,Cwt),e(Re,ty),e(ty,nIe),e(nIe,wwt),e(ty,Awt),e(ty,Nme),e(Nme,Lwt),e(ty,ywt),e(Re,xwt),e(Re,ay),e(ay,sIe),e(sIe,$wt),e(ay,kwt),e(ay,qme),e(qme,Swt),e(ay,Rwt),e(dt,Pwt),M(ny,dt,null),b(c,vdo,_),b(c,Lf,_),e(Lf,sy),e(sy,lIe),M(_I,lIe,null),e(Lf,Bwt),e(Lf,iIe),e(iIe,Iwt),b(c,Fdo,_),b(c,Pr,_),M(bI,Pr,null),e(Pr,Nwt),e(Pr,yf),e(yf,qwt),e(yf,Dme),e(Dme,Dwt),e(yf,jwt),e(yf,jme),e(jme,Gwt),e(yf,Owt),e(Pr,Vwt),e(Pr,vI),e(vI,Xwt),e(vI,dIe),e(dIe,zwt),e(vI,Qwt),e(Pr,Wwt),e(Pr,Ta),M(FI,Ta,null),e(Ta,Uwt),e(Ta,mIe),e(mIe,Hwt),e(Ta,Jwt),e(Ta,xf),e(xf,Ywt),e(xf,cIe),e(cIe,Zwt),e(xf,Kwt),e(xf,Gme),e(Gme,eAt),e(xf,oAt),e(Ta,rAt),M(ly,Ta,null),e(Pr,tAt),e(Pr,mt),M(TI,mt,null),e(mt,aAt),e(mt,fIe),e(fIe,nAt),e(mt,sAt),e(mt,ls),e(ls,lAt),e(ls,gIe),e(gIe,iAt),e(ls,dAt),e(ls,hIe),e(hIe,mAt),e(ls,cAt),e(ls,uIe),e(uIe,fAt),e(ls,gAt),e(mt,hAt),e(mt,Pe),e(Pe,iy),e(iy,pIe),e(pIe,uAt),e(iy,pAt),e(iy,Ome),e(Ome,_At),e(iy,bAt),e(Pe,vAt),e(Pe,dy),e(dy,_Ie),e(_Ie,FAt),e(dy,TAt),e(dy,Vme),e(Vme,MAt),e(dy,EAt),e(Pe,CAt),e(Pe,my),e(my,bIe),e(bIe,wAt),e(my,AAt),e(my,Xme),e(Xme,LAt),e(my,yAt),e(Pe,xAt),e(Pe,cy),e(cy,vIe),e(vIe,$At),e(cy,kAt),e(cy,zme),e(zme,SAt),e(cy,RAt),e(Pe,PAt),e(Pe,fy),e(fy,FIe),e(FIe,BAt),e(fy,IAt),e(fy,Qme),e(Qme,NAt),e(fy,qAt),e(Pe,DAt),e(Pe,gy),e(gy,TIe),e(TIe,jAt),e(gy,GAt),e(gy,Wme),e(Wme,OAt),e(gy,VAt),e(Pe,XAt),e(Pe,hy),e(hy,MIe),e(MIe,zAt),e(hy,QAt),e(hy,Ume),e(Ume,WAt),e(hy,UAt),e(Pe,HAt),e(Pe,uy),e(uy,EIe),e(EIe,JAt),e(uy,YAt),e(uy,Hme),e(Hme,ZAt),e(uy,KAt),e(Pe,e6t),e(Pe,py),e(py,CIe),e(CIe,o6t),e(py,r6t),e(py,Jme),e(Jme,t6t),e(py,a6t),e(Pe,n6t),e(Pe,_y),e(_y,wIe),e(wIe,s6t),e(_y,l6t),e(_y,Yme),e(Yme,i6t),e(_y,d6t),e(mt,m6t),M(by,mt,null),b(c,Tdo,_),b(c,$f,_),e($f,vy),e(vy,AIe),M(MI,AIe,null),e($f,c6t),e($f,LIe),e(LIe,f6t),b(c,Mdo,_),b(c,Br,_),M(EI,Br,null),e(Br,g6t),e(Br,kf),e(kf,h6t),e(kf,Zme),e(Zme,u6t),e(kf,p6t),e(kf,Kme),e(Kme,_6t),e(kf,b6t),e(Br,v6t),e(Br,CI),e(CI,F6t),e(CI,yIe),e(yIe,T6t),e(CI,M6t),e(Br,E6t),e(Br,Ma),M(wI,Ma,null),e(Ma,C6t),e(Ma,xIe),e(xIe,w6t),e(Ma,A6t),e(Ma,Sf),e(Sf,L6t),e(Sf,$Ie),e($Ie,y6t),e(Sf,x6t),e(Sf,ece),e(ece,$6t),e(Sf,k6t),e(Ma,S6t),M(Fy,Ma,null),e(Br,R6t),e(Br,ct),M(AI,ct,null),e(ct,P6t),e(ct,kIe),e(kIe,B6t),e(ct,I6t),e(ct,is),e(is,N6t),e(is,SIe),e(SIe,q6t),e(is,D6t),e(is,RIe),e(RIe,j6t),e(is,G6t),e(is,PIe),e(PIe,O6t),e(is,V6t),e(ct,X6t),e(ct,Be),e(Be,Ty),e(Ty,BIe),e(BIe,z6t),e(Ty,Q6t),e(Ty,oce),e(oce,W6t),e(Ty,U6t),e(Be,H6t),e(Be,My),e(My,IIe),e(IIe,J6t),e(My,Y6t),e(My,rce),e(rce,Z6t),e(My,K6t),e(Be,e7t),e(Be,Ey),e(Ey,NIe),e(NIe,o7t),e(Ey,r7t),e(Ey,tce),e(tce,t7t),e(Ey,a7t),e(Be,n7t),e(Be,Cy),e(Cy,qIe),e(qIe,s7t),e(Cy,l7t),e(Cy,ace),e(ace,i7t),e(Cy,d7t),e(Be,m7t),e(Be,wy),e(wy,DIe),e(DIe,c7t),e(wy,f7t),e(wy,nce),e(nce,g7t),e(wy,h7t),e(Be,u7t),e(Be,Ay),e(Ay,jIe),e(jIe,p7t),e(Ay,_7t),e(Ay,sce),e(sce,b7t),e(Ay,v7t),e(Be,F7t),e(Be,Ly),e(Ly,GIe),e(GIe,T7t),e(Ly,M7t),e(Ly,lce),e(lce,E7t),e(Ly,C7t),e(Be,w7t),e(Be,yy),e(yy,OIe),e(OIe,A7t),e(yy,L7t),e(yy,ice),e(ice,y7t),e(yy,x7t),e(Be,$7t),e(Be,xy),e(xy,VIe),e(VIe,k7t),e(xy,S7t),e(xy,dce),e(dce,R7t),e(xy,P7t),e(Be,B7t),e(Be,$y),e($y,XIe),e(XIe,I7t),e($y,N7t),e($y,mce),e(mce,q7t),e($y,D7t),e(ct,j7t),M(ky,ct,null),b(c,Edo,_),b(c,Rf,_),e(Rf,Sy),e(Sy,zIe),M(LI,zIe,null),e(Rf,G7t),e(Rf,QIe),e(QIe,O7t),b(c,Cdo,_),b(c,Ir,_),M(yI,Ir,null),e(Ir,V7t),e(Ir,Pf),e(Pf,X7t),e(Pf,cce),e(cce,z7t),e(Pf,Q7t),e(Pf,fce),e(fce,W7t),e(Pf,U7t),e(Ir,H7t),e(Ir,xI),e(xI,J7t),e(xI,WIe),e(WIe,Y7t),e(xI,Z7t),e(Ir,K7t),e(Ir,Ea),M($I,Ea,null),e(Ea,e8t),e(Ea,UIe),e(UIe,o8t),e(Ea,r8t),e(Ea,Bf),e(Bf,t8t),e(Bf,HIe),e(HIe,a8t),e(Bf,n8t),e(Bf,gce),e(gce,s8t),e(Bf,l8t),e(Ea,i8t),M(Ry,Ea,null),e(Ir,d8t),e(Ir,ft),M(kI,ft,null),e(ft,m8t),e(ft,JIe),e(JIe,c8t),e(ft,f8t),e(ft,ds),e(ds,g8t),e(ds,YIe),e(YIe,h8t),e(ds,u8t),e(ds,ZIe),e(ZIe,p8t),e(ds,_8t),e(ds,KIe),e(KIe,b8t),e(ds,v8t),e(ft,F8t),e(ft,Ie),e(Ie,Py),e(Py,eNe),e(eNe,T8t),e(Py,M8t),e(Py,hce),e(hce,E8t),e(Py,C8t),e(Ie,w8t),e(Ie,By),e(By,oNe),e(oNe,A8t),e(By,L8t),e(By,uce),e(uce,y8t),e(By,x8t),e(Ie,$8t),e(Ie,Iy),e(Iy,rNe),e(rNe,k8t),e(Iy,S8t),e(Iy,pce),e(pce,R8t),e(Iy,P8t),e(Ie,B8t),e(Ie,Ny),e(Ny,tNe),e(tNe,I8t),e(Ny,N8t),e(Ny,_ce),e(_ce,q8t),e(Ny,D8t),e(Ie,j8t),e(Ie,qy),e(qy,aNe),e(aNe,G8t),e(qy,O8t),e(qy,bce),e(bce,V8t),e(qy,X8t),e(Ie,z8t),e(Ie,Dy),e(Dy,nNe),e(nNe,Q8t),e(Dy,W8t),e(Dy,vce),e(vce,U8t),e(Dy,H8t),e(Ie,J8t),e(Ie,jy),e(jy,sNe),e(sNe,Y8t),e(jy,Z8t),e(jy,Fce),e(Fce,K8t),e(jy,eLt),e(Ie,oLt),e(Ie,Gy),e(Gy,lNe),e(lNe,rLt),e(Gy,tLt),e(Gy,Tce),e(Tce,aLt),e(Gy,nLt),e(Ie,sLt),e(Ie,Oy),e(Oy,iNe),e(iNe,lLt),e(Oy,iLt),e(Oy,Mce),e(Mce,dLt),e(Oy,mLt),e(Ie,cLt),e(Ie,Vy),e(Vy,dNe),e(dNe,fLt),e(Vy,gLt),e(Vy,Ece),e(Ece,hLt),e(Vy,uLt),e(ft,pLt),M(Xy,ft,null),b(c,wdo,_),b(c,If,_),e(If,zy),e(zy,mNe),M(SI,mNe,null),e(If,_Lt),e(If,cNe),e(cNe,bLt),b(c,Ado,_),b(c,Nr,_),M(RI,Nr,null),e(Nr,vLt),e(Nr,Nf),e(Nf,FLt),e(Nf,Cce),e(Cce,TLt),e(Nf,MLt),e(Nf,wce),e(wce,ELt),e(Nf,CLt),e(Nr,wLt),e(Nr,PI),e(PI,ALt),e(PI,fNe),e(fNe,LLt),e(PI,yLt),e(Nr,xLt),e(Nr,Ca),M(BI,Ca,null),e(Ca,$Lt),e(Ca,gNe),e(gNe,kLt),e(Ca,SLt),e(Ca,qf),e(qf,RLt),e(qf,hNe),e(hNe,PLt),e(qf,BLt),e(qf,Ace),e(Ace,ILt),e(qf,NLt),e(Ca,qLt),M(Qy,Ca,null),e(Nr,DLt),e(Nr,gt),M(II,gt,null),e(gt,jLt),e(gt,uNe),e(uNe,GLt),e(gt,OLt),e(gt,ms),e(ms,VLt),e(ms,pNe),e(pNe,XLt),e(ms,zLt),e(ms,_Ne),e(_Ne,QLt),e(ms,WLt),e(ms,bNe),e(bNe,ULt),e(ms,HLt),e(gt,JLt),e(gt,We),e(We,Wy),e(Wy,vNe),e(vNe,YLt),e(Wy,ZLt),e(Wy,Lce),e(Lce,KLt),e(Wy,eyt),e(We,oyt),e(We,Uy),e(Uy,FNe),e(FNe,ryt),e(Uy,tyt),e(Uy,yce),e(yce,ayt),e(Uy,nyt),e(We,syt),e(We,Hy),e(Hy,TNe),e(TNe,lyt),e(Hy,iyt),e(Hy,xce),e(xce,dyt),e(Hy,myt),e(We,cyt),e(We,Jy),e(Jy,MNe),e(MNe,fyt),e(Jy,gyt),e(Jy,$ce),e($ce,hyt),e(Jy,uyt),e(We,pyt),e(We,Yy),e(Yy,ENe),e(ENe,_yt),e(Yy,byt),e(Yy,kce),e(kce,vyt),e(Yy,Fyt),e(We,Tyt),e(We,Zy),e(Zy,CNe),e(CNe,Myt),e(Zy,Eyt),e(Zy,Sce),e(Sce,Cyt),e(Zy,wyt),e(We,Ayt),e(We,Ky),e(Ky,wNe),e(wNe,Lyt),e(Ky,yyt),e(Ky,Rce),e(Rce,xyt),e(Ky,$yt),e(We,kyt),e(We,e9),e(e9,ANe),e(ANe,Syt),e(e9,Ryt),e(e9,Pce),e(Pce,Pyt),e(e9,Byt),e(gt,Iyt),M(o9,gt,null),b(c,Ldo,_),b(c,Df,_),e(Df,r9),e(r9,LNe),M(NI,LNe,null),e(Df,Nyt),e(Df,yNe),e(yNe,qyt),b(c,ydo,_),b(c,qr,_),M(qI,qr,null),e(qr,Dyt),e(qr,jf),e(jf,jyt),e(jf,Bce),e(Bce,Gyt),e(jf,Oyt),e(jf,Ice),e(Ice,Vyt),e(jf,Xyt),e(qr,zyt),e(qr,DI),e(DI,Qyt),e(DI,xNe),e(xNe,Wyt),e(DI,Uyt),e(qr,Hyt),e(qr,wa),M(jI,wa,null),e(wa,Jyt),e(wa,$Ne),e($Ne,Yyt),e(wa,Zyt),e(wa,Gf),e(Gf,Kyt),e(Gf,kNe),e(kNe,e9t),e(Gf,o9t),e(Gf,Nce),e(Nce,r9t),e(Gf,t9t),e(wa,a9t),M(t9,wa,null),e(qr,n9t),e(qr,ht),M(GI,ht,null),e(ht,s9t),e(ht,SNe),e(SNe,l9t),e(ht,i9t),e(ht,cs),e(cs,d9t),e(cs,RNe),e(RNe,m9t),e(cs,c9t),e(cs,PNe),e(PNe,f9t),e(cs,g9t),e(cs,BNe),e(BNe,h9t),e(cs,u9t),e(ht,p9t),e(ht,Ue),e(Ue,a9),e(a9,INe),e(INe,_9t),e(a9,b9t),e(a9,qce),e(qce,v9t),e(a9,F9t),e(Ue,T9t),e(Ue,n9),e(n9,NNe),e(NNe,M9t),e(n9,E9t),e(n9,Dce),e(Dce,C9t),e(n9,w9t),e(Ue,A9t),e(Ue,s9),e(s9,qNe),e(qNe,L9t),e(s9,y9t),e(s9,jce),e(jce,x9t),e(s9,$9t),e(Ue,k9t),e(Ue,l9),e(l9,DNe),e(DNe,S9t),e(l9,R9t),e(l9,Gce),e(Gce,P9t),e(l9,B9t),e(Ue,I9t),e(Ue,i9),e(i9,jNe),e(jNe,N9t),e(i9,q9t),e(i9,Oce),e(Oce,D9t),e(i9,j9t),e(Ue,G9t),e(Ue,d9),e(d9,GNe),e(GNe,O9t),e(d9,V9t),e(d9,Vce),e(Vce,X9t),e(d9,z9t),e(Ue,Q9t),e(Ue,m9),e(m9,ONe),e(ONe,W9t),e(m9,U9t),e(m9,Xce),e(Xce,H9t),e(m9,J9t),e(Ue,Y9t),e(Ue,c9),e(c9,VNe),e(VNe,Z9t),e(c9,K9t),e(c9,zce),e(zce,ext),e(c9,oxt),e(ht,rxt),M(f9,ht,null),b(c,xdo,_),b(c,Of,_),e(Of,g9),e(g9,XNe),M(OI,XNe,null),e(Of,txt),e(Of,zNe),e(zNe,axt),b(c,$do,_),b(c,Dr,_),M(VI,Dr,null),e(Dr,nxt),e(Dr,Vf),e(Vf,sxt),e(Vf,Qce),e(Qce,lxt),e(Vf,ixt),e(Vf,Wce),e(Wce,dxt),e(Vf,mxt),e(Dr,cxt),e(Dr,XI),e(XI,fxt),e(XI,QNe),e(QNe,gxt),e(XI,hxt),e(Dr,uxt),e(Dr,Aa),M(zI,Aa,null),e(Aa,pxt),e(Aa,WNe),e(WNe,_xt),e(Aa,bxt),e(Aa,Xf),e(Xf,vxt),e(Xf,UNe),e(UNe,Fxt),e(Xf,Txt),e(Xf,Uce),e(Uce,Mxt),e(Xf,Ext),e(Aa,Cxt),M(h9,Aa,null),e(Dr,wxt),e(Dr,ut),M(QI,ut,null),e(ut,Axt),e(ut,HNe),e(HNe,Lxt),e(ut,yxt),e(ut,fs),e(fs,xxt),e(fs,JNe),e(JNe,$xt),e(fs,kxt),e(fs,YNe),e(YNe,Sxt),e(fs,Rxt),e(fs,ZNe),e(ZNe,Pxt),e(fs,Bxt),e(ut,Ixt),e(ut,KNe),e(KNe,u9),e(u9,eqe),e(eqe,Nxt),e(u9,qxt),e(u9,Hce),e(Hce,Dxt),e(u9,jxt),e(ut,Gxt),M(p9,ut,null),b(c,kdo,_),b(c,zf,_),e(zf,_9),e(_9,oqe),M(WI,oqe,null),e(zf,Oxt),e(zf,rqe),e(rqe,Vxt),b(c,Sdo,_),b(c,jr,_),M(UI,jr,null),e(jr,Xxt),e(jr,Qf),e(Qf,zxt),e(Qf,Jce),e(Jce,Qxt),e(Qf,Wxt),e(Qf,Yce),e(Yce,Uxt),e(Qf,Hxt),e(jr,Jxt),e(jr,HI),e(HI,Yxt),e(HI,tqe),e(tqe,Zxt),e(HI,Kxt),e(jr,e$t),e(jr,La),M(JI,La,null),e(La,o$t),e(La,aqe),e(aqe,r$t),e(La,t$t),e(La,Wf),e(Wf,a$t),e(Wf,nqe),e(nqe,n$t),e(Wf,s$t),e(Wf,Zce),e(Zce,l$t),e(Wf,i$t),e(La,d$t),M(b9,La,null),e(jr,m$t),e(jr,pt),M(YI,pt,null),e(pt,c$t),e(pt,sqe),e(sqe,f$t),e(pt,g$t),e(pt,gs),e(gs,h$t),e(gs,lqe),e(lqe,u$t),e(gs,p$t),e(gs,iqe),e(iqe,_$t),e(gs,b$t),e(gs,dqe),e(dqe,v$t),e(gs,F$t),e(pt,T$t),e(pt,ZI),e(ZI,v9),e(v9,mqe),e(mqe,M$t),e(v9,E$t),e(v9,Kce),e(Kce,C$t),e(v9,w$t),e(ZI,A$t),e(ZI,F9),e(F9,cqe),e(cqe,L$t),e(F9,y$t),e(F9,efe),e(efe,x$t),e(F9,$$t),e(pt,k$t),M(T9,pt,null),b(c,Rdo,_),b(c,Uf,_),e(Uf,M9),e(M9,fqe),M(KI,fqe,null),e(Uf,S$t),e(Uf,gqe),e(gqe,R$t),b(c,Pdo,_),b(c,Gr,_),M(eN,Gr,null),e(Gr,P$t),e(Gr,Hf),e(Hf,B$t),e(Hf,ofe),e(ofe,I$t),e(Hf,N$t),e(Hf,rfe),e(rfe,q$t),e(Hf,D$t),e(Gr,j$t),e(Gr,oN),e(oN,G$t),e(oN,hqe),e(hqe,O$t),e(oN,V$t),e(Gr,X$t),e(Gr,ya),M(rN,ya,null),e(ya,z$t),e(ya,uqe),e(uqe,Q$t),e(ya,W$t),e(ya,Jf),e(Jf,U$t),e(Jf,pqe),e(pqe,H$t),e(Jf,J$t),e(Jf,tfe),e(tfe,Y$t),e(Jf,Z$t),e(ya,K$t),M(E9,ya,null),e(Gr,ekt),e(Gr,_t),M(tN,_t,null),e(_t,okt),e(_t,_qe),e(_qe,rkt),e(_t,tkt),e(_t,hs),e(hs,akt),e(hs,bqe),e(bqe,nkt),e(hs,skt),e(hs,vqe),e(vqe,lkt),e(hs,ikt),e(hs,Fqe),e(Fqe,dkt),e(hs,mkt),e(_t,ckt),e(_t,Tqe),e(Tqe,C9),e(C9,Mqe),e(Mqe,fkt),e(C9,gkt),e(C9,afe),e(afe,hkt),e(C9,ukt),e(_t,pkt),M(w9,_t,null),Bdo=!0},p(c,[_]){const aN={};_&2&&(aN.$$scope={dirty:_,ctx:c}),ng.$set(aN);const Eqe={};_&2&&(Eqe.$$scope={dirty:_,ctx:c}),Iu.$set(Eqe);const Cqe={};_&2&&(Cqe.$$scope={dirty:_,ctx:c}),Mp.$set(Cqe);const wqe={};_&2&&(wqe.$$scope={dirty:_,ctx:c}),p_.$set(wqe);const nN={};_&2&&(nN.$$scope={dirty:_,ctx:c}),__.$set(nN);const Aqe={};_&2&&(Aqe.$$scope={dirty:_,ctx:c}),H_.$set(Aqe);const us={};_&2&&(us.$$scope={dirty:_,ctx:c}),J_.$set(us);const Lqe={};_&2&&(Lqe.$$scope={dirty:_,ctx:c}),M1.$set(Lqe);const yqe={};_&2&&(yqe.$$scope={dirty:_,ctx:c}),E1.$set(yqe);const xqe={};_&2&&(xqe.$$scope={dirty:_,ctx:c}),A1.$set(xqe);const sN={};_&2&&(sN.$$scope={dirty:_,ctx:c}),Jb.$set(sN);const $qe={};_&2&&($qe.$$scope={dirty:_,ctx:c}),Zb.$set($qe);const lN={};_&2&&(lN.$$scope={dirty:_,ctx:c}),Hv.$set(lN);const kqe={};_&2&&(kqe.$$scope={dirty:_,ctx:c}),Yv.$set(kqe);const iN={};_&2&&(iN.$$scope={dirty:_,ctx:c}),OF.$set(iN);const Sqe={};_&2&&(Sqe.$$scope={dirty:_,ctx:c}),XF.$set(Sqe);const Rqe={};_&2&&(Rqe.$$scope={dirty:_,ctx:c}),UF.$set(Rqe);const Pqe={};_&2&&(Pqe.$$scope={dirty:_,ctx:c}),JF.$set(Pqe);const Yf={};_&2&&(Yf.$$scope={dirty:_,ctx:c}),qT.$set(Yf);const Bqe={};_&2&&(Bqe.$$scope={dirty:_,ctx:c}),jT.$set(Bqe);const Iqe={};_&2&&(Iqe.$$scope={dirty:_,ctx:c}),iM.$set(Iqe);const Nqe={};_&2&&(Nqe.$$scope={dirty:_,ctx:c}),mM.$set(Nqe);const dN={};_&2&&(dN.$$scope={dirty:_,ctx:c}),uE.$set(dN);const qqe={};_&2&&(qqe.$$scope={dirty:_,ctx:c}),_E.$set(qqe);const Dqe={};_&2&&(Dqe.$$scope={dirty:_,ctx:c}),ZE.$set(Dqe);const jqe={};_&2&&(jqe.$$scope={dirty:_,ctx:c}),e4.$set(jqe);const Et={};_&2&&(Et.$$scope={dirty:_,ctx:c}),d4.$set(Et);const mN={};_&2&&(mN.$$scope={dirty:_,ctx:c}),c4.$set(mN);const Gqe={};_&2&&(Gqe.$$scope={dirty:_,ctx:c}),oC.$set(Gqe);const cN={};_&2&&(cN.$$scope={dirty:_,ctx:c}),tC.$set(cN);const Oqe={};_&2&&(Oqe.$$scope={dirty:_,ctx:c}),e3.$set(Oqe);const Ct={};_&2&&(Ct.$$scope={dirty:_,ctx:c}),r3.$set(Ct);const Vqe={};_&2&&(Vqe.$$scope={dirty:_,ctx:c}),n3.$set(Vqe);const Zf={};_&2&&(Zf.$$scope={dirty:_,ctx:c}),l3.$set(Zf);const Xqe={};_&2&&(Xqe.$$scope={dirty:_,ctx:c}),f3.$set(Xqe);const zqe={};_&2&&(zqe.$$scope={dirty:_,ctx:c}),h3.$set(zqe);const L={};_&2&&(L.$$scope={dirty:_,ctx:c}),k3.$set(L);const A9={};_&2&&(A9.$$scope={dirty:_,ctx:c}),R3.$set(A9);const Qqe={};_&2&&(Qqe.$$scope={dirty:_,ctx:c}),I3.$set(Qqe);const Wqe={};_&2&&(Wqe.$$scope={dirty:_,ctx:c}),q3.$set(Wqe);const L9={};_&2&&(L9.$$scope={dirty:_,ctx:c}),G3.$set(L9);const Uqe={};_&2&&(Uqe.$$scope={dirty:_,ctx:c}),V3.$set(Uqe);const Hqe={};_&2&&(Hqe.$$scope={dirty:_,ctx:c}),Q3.$set(Hqe);const y9={};_&2&&(y9.$$scope={dirty:_,ctx:c}),U3.$set(y9);const Jqe={};_&2&&(Jqe.$$scope={dirty:_,ctx:c}),n5.$set(Jqe);const Yqe={};_&2&&(Yqe.$$scope={dirty:_,ctx:c}),l5.$set(Yqe);const x9={};_&2&&(x9.$$scope={dirty:_,ctx:c}),h5.$set(x9);const Zqe={};_&2&&(Zqe.$$scope={dirty:_,ctx:c}),p5.$set(Zqe);const Kqe={};_&2&&(Kqe.$$scope={dirty:_,ctx:c}),y5.$set(Kqe);const $9={};_&2&&($9.$$scope={dirty:_,ctx:c}),$5.$set($9);const eDe={};_&2&&(eDe.$$scope={dirty:_,ctx:c}),B5.$set(eDe);const oDe={};_&2&&(oDe.$$scope={dirty:_,ctx:c}),N5.$set(oDe);const k9={};_&2&&(k9.$$scope={dirty:_,ctx:c}),X5.$set(k9);const rDe={};_&2&&(rDe.$$scope={dirty:_,ctx:c}),Q5.$set(rDe);const tDe={};_&2&&(tDe.$$scope={dirty:_,ctx:c}),Z5.$set(tDe);const S9={};_&2&&(S9.$$scope={dirty:_,ctx:c}),e0.$set(S9);const aDe={};_&2&&(aDe.$$scope={dirty:_,ctx:c}),l0.$set(aDe);const nDe={};_&2&&(nDe.$$scope={dirty:_,ctx:c}),d0.$set(nDe);const R9={};_&2&&(R9.$$scope={dirty:_,ctx:c}),f0.$set(R9);const sDe={};_&2&&(sDe.$$scope={dirty:_,ctx:c}),h0.$set(sDe);const lDe={};_&2&&(lDe.$$scope={dirty:_,ctx:c}),T0.$set(lDe);const P9={};_&2&&(P9.$$scope={dirty:_,ctx:c}),E0.$set(P9);const iDe={};_&2&&(iDe.$$scope={dirty:_,ctx:c}),A0.$set(iDe);const dDe={};_&2&&(dDe.$$scope={dirty:_,ctx:c}),y0.$set(dDe);const B9={};_&2&&(B9.$$scope={dirty:_,ctx:c}),k0.$set(B9);const mDe={};_&2&&(mDe.$$scope={dirty:_,ctx:c}),R0.$set(mDe);const cDe={};_&2&&(cDe.$$scope={dirty:_,ctx:c}),Nw.$set(cDe);const I9={};_&2&&(I9.$$scope={dirty:_,ctx:c}),Dw.$set(I9);const fDe={};_&2&&(fDe.$$scope={dirty:_,ctx:c}),dA.$set(fDe);const gDe={};_&2&&(gDe.$$scope={dirty:_,ctx:c}),cA.$set(gDe);const N9={};_&2&&(N9.$$scope={dirty:_,ctx:c}),AA.$set(N9);const hDe={};_&2&&(hDe.$$scope={dirty:_,ctx:c}),yA.$set(hDe);const uDe={};_&2&&(uDe.$$scope={dirty:_,ctx:c}),qA.$set(uDe);const q9={};_&2&&(q9.$$scope={dirty:_,ctx:c}),jA.$set(q9);const pDe={};_&2&&(pDe.$$scope={dirty:_,ctx:c}),XA.$set(pDe);const _De={};_&2&&(_De.$$scope={dirty:_,ctx:c}),QA.$set(_De);const D9={};_&2&&(D9.$$scope={dirty:_,ctx:c}),h6.$set(D9);const bDe={};_&2&&(bDe.$$scope={dirty:_,ctx:c}),p6.$set(bDe);const vDe={};_&2&&(vDe.$$scope={dirty:_,ctx:c}),L6.$set(vDe);const j9={};_&2&&(j9.$$scope={dirty:_,ctx:c}),x6.$set(j9);const FDe={};_&2&&(FDe.$$scope={dirty:_,ctx:c}),a7.$set(FDe);const TDe={};_&2&&(TDe.$$scope={dirty:_,ctx:c}),s7.$set(TDe);const G9={};_&2&&(G9.$$scope={dirty:_,ctx:c}),C7.$set(G9);const MDe={};_&2&&(MDe.$$scope={dirty:_,ctx:c}),A7.$set(MDe);const EDe={};_&2&&(EDe.$$scope={dirty:_,ctx:c}),x7.$set(EDe);const O9={};_&2&&(O9.$$scope={dirty:_,ctx:c}),k7.$set(O9);const CDe={};_&2&&(CDe.$$scope={dirty:_,ctx:c}),R7.$set(CDe);const wDe={};_&2&&(wDe.$$scope={dirty:_,ctx:c}),B7.$set(wDe);const V9={};_&2&&(V9.$$scope={dirty:_,ctx:c}),N7.$set(V9);const ADe={};_&2&&(ADe.$$scope={dirty:_,ctx:c}),D7.$set(ADe);const LDe={};_&2&&(LDe.$$scope={dirty:_,ctx:c}),i8.$set(LDe);const X9={};_&2&&(X9.$$scope={dirty:_,ctx:c}),m8.$set(X9);const yDe={};_&2&&(yDe.$$scope={dirty:_,ctx:c}),S8.$set(yDe);const xDe={};_&2&&(xDe.$$scope={dirty:_,ctx:c}),P8.$set(xDe);const z9={};_&2&&(z9.$$scope={dirty:_,ctx:c}),I8.$set(z9);const $De={};_&2&&($De.$$scope={dirty:_,ctx:c}),q8.$set($De);const kDe={};_&2&&(kDe.$$scope={dirty:_,ctx:c}),G8.$set(kDe);const Q9={};_&2&&(Q9.$$scope={dirty:_,ctx:c}),V8.$set(Q9);const SDe={};_&2&&(SDe.$$scope={dirty:_,ctx:c}),_L.$set(SDe);const RDe={};_&2&&(RDe.$$scope={dirty:_,ctx:c}),vL.$set(RDe);const W9={};_&2&&(W9.$$scope={dirty:_,ctx:c}),$L.$set(W9);const PDe={};_&2&&(PDe.$$scope={dirty:_,ctx:c}),SL.$set(PDe);const BDe={};_&2&&(BDe.$$scope={dirty:_,ctx:c}),QL.$set(BDe);const U9={};_&2&&(U9.$$scope={dirty:_,ctx:c}),UL.$set(U9);const IDe={};_&2&&(IDe.$$scope={dirty:_,ctx:c}),ny.$set(IDe);const NDe={};_&2&&(NDe.$$scope={dirty:_,ctx:c}),ly.$set(NDe);const H9={};_&2&&(H9.$$scope={dirty:_,ctx:c}),by.$set(H9);const qDe={};_&2&&(qDe.$$scope={dirty:_,ctx:c}),Fy.$set(qDe);const DDe={};_&2&&(DDe.$$scope={dirty:_,ctx:c}),ky.$set(DDe);const J9={};_&2&&(J9.$$scope={dirty:_,ctx:c}),Ry.$set(J9);const jDe={};_&2&&(jDe.$$scope={dirty:_,ctx:c}),Xy.$set(jDe);const GDe={};_&2&&(GDe.$$scope={dirty:_,ctx:c}),Qy.$set(GDe);const Y9={};_&2&&(Y9.$$scope={dirty:_,ctx:c}),o9.$set(Y9);const ODe={};_&2&&(ODe.$$scope={dirty:_,ctx:c}),t9.$set(ODe);const VDe={};_&2&&(VDe.$$scope={dirty:_,ctx:c}),f9.$set(VDe);const Z9={};_&2&&(Z9.$$scope={dirty:_,ctx:c}),h9.$set(Z9);const XDe={};_&2&&(XDe.$$scope={dirty:_,ctx:c}),p9.$set(XDe);const zDe={};_&2&&(zDe.$$scope={dirty:_,ctx:c}),b9.$set(zDe);const K9={};_&2&&(K9.$$scope={dirty:_,ctx:c}),T9.$set(K9);const QDe={};_&2&&(QDe.$$scope={dirty:_,ctx:c}),E9.$set(QDe);const WDe={};_&2&&(WDe.$$scope={dirty:_,ctx:c}),w9.$set(WDe)},i(c){Bdo||(E(m.$$.fragment,c),E(sn.$$.fragment,c),E(fk.$$.fragment,c),E(gk.$$.fragment,c),E(ng.$$.fragment,c),E(hk.$$.fragment,c),E(uk.$$.fragment,c),E(bk.$$.fragment,c),E(Iu.$$.fragment,c),E(vk.$$.fragment,c),E(Fk.$$.fragment,c),E(Tk.$$.fragment,c),E(Ck.$$.fragment,c),E(Mp.$$.fragment,c),E(wk.$$.fragment,c),E(Ak.$$.fragment,c),E(Lk.$$.fragment,c),E($k.$$.fragment,c),E(p_.$$.fragment,c),E(__.$$.fragment,c),E(kk.$$.fragment,c),E(Sk.$$.fragment,c),E(Rk.$$.fragment,c),E(Ik.$$.fragment,c),E(H_.$$.fragment,c),E(J_.$$.fragment,c),E(Nk.$$.fragment,c),E(qk.$$.fragment,c),E(Dk.$$.fragment,c),E(Ok.$$.fragment,c),E(M1.$$.fragment,c),E(E1.$$.fragment,c),E(Vk.$$.fragment,c),E(Xk.$$.fragment,c),E(zk.$$.fragment,c),E(Wk.$$.fragment,c),E(A1.$$.fragment,c),E(Uk.$$.fragment,c),E(Jb.$$.fragment,c),E(Hk.$$.fragment,c),E(Jk.$$.fragment,c),E(Zk.$$.fragment,c),E(Zb.$$.fragment,c),E(Kk.$$.fragment,c),E(Hv.$$.fragment,c),E(eS.$$.fragment,c),E(oS.$$.fragment,c),E(tS.$$.fragment,c),E(Yv.$$.fragment,c),E(aS.$$.fragment,c),E(OF.$$.fragment,c),E(nS.$$.fragment,c),E(sS.$$.fragment,c),E(iS.$$.fragment,c),E(XF.$$.fragment,c),E(dS.$$.fragment,c),E(UF.$$.fragment,c),E(cS.$$.fragment,c),E(fS.$$.fragment,c),E(hS.$$.fragment,c),E(JF.$$.fragment,c),E(uS.$$.fragment,c),E(qT.$$.fragment,c),E(pS.$$.fragment,c),E(_S.$$.fragment,c),E(vS.$$.fragment,c),E(jT.$$.fragment,c),E(FS.$$.fragment,c),E(iM.$$.fragment,c),E(TS.$$.fragment,c),E(MS.$$.fragment,c),E(CS.$$.fragment,c),E(mM.$$.fragment,c),E(wS.$$.fragment,c),E(uE.$$.fragment,c),E(AS.$$.fragment,c),E(LS.$$.fragment,c),E(xS.$$.fragment,c),E(_E.$$.fragment,c),E($S.$$.fragment,c),E(ZE.$$.fragment,c),E(kS.$$.fragment,c),E(SS.$$.fragment,c),E(PS.$$.fragment,c),E(e4.$$.fragment,c),E(BS.$$.fragment,c),E(d4.$$.fragment,c),E(IS.$$.fragment,c),E(NS.$$.fragment,c),E(DS.$$.fragment,c),E(c4.$$.fragment,c),E(jS.$$.fragment,c),E(oC.$$.fragment,c),E(GS.$$.fragment,c),E(OS.$$.fragment,c),E(XS.$$.fragment,c),E(tC.$$.fragment,c),E(zS.$$.fragment,c),E(e3.$$.fragment,c),E(QS.$$.fragment,c),E(WS.$$.fragment,c),E(HS.$$.fragment,c),E(r3.$$.fragment,c),E(JS.$$.fragment,c),E(n3.$$.fragment,c),E(YS.$$.fragment,c),E(ZS.$$.fragment,c),E(eR.$$.fragment,c),E(l3.$$.fragment,c),E(oR.$$.fragment,c),E(f3.$$.fragment,c),E(rR.$$.fragment,c),E(tR.$$.fragment,c),E(nR.$$.fragment,c),E(h3.$$.fragment,c),E(sR.$$.fragment,c),E(k3.$$.fragment,c),E(lR.$$.fragment,c),E(iR.$$.fragment,c),E(mR.$$.fragment,c),E(R3.$$.fragment,c),E(cR.$$.fragment,c),E(I3.$$.fragment,c),E(fR.$$.fragment,c),E(gR.$$.fragment,c),E(uR.$$.fragment,c),E(q3.$$.fragment,c),E(pR.$$.fragment,c),E(G3.$$.fragment,c),E(_R.$$.fragment,c),E(bR.$$.fragment,c),E(FR.$$.fragment,c),E(V3.$$.fragment,c),E(TR.$$.fragment,c),E(Q3.$$.fragment,c),E(MR.$$.fragment,c),E(ER.$$.fragment,c),E(wR.$$.fragment,c),E(U3.$$.fragment,c),E(AR.$$.fragment,c),E(n5.$$.fragment,c),E(LR.$$.fragment,c),E(yR.$$.fragment,c),E($R.$$.fragment,c),E(l5.$$.fragment,c),E(kR.$$.fragment,c),E(h5.$$.fragment,c),E(SR.$$.fragment,c),E(RR.$$.fragment,c),E(BR.$$.fragment,c),E(p5.$$.fragment,c),E(IR.$$.fragment,c),E(y5.$$.fragment,c),E(NR.$$.fragment,c),E(qR.$$.fragment,c),E(jR.$$.fragment,c),E($5.$$.fragment,c),E(GR.$$.fragment,c),E(B5.$$.fragment,c),E(OR.$$.fragment,c),E(VR.$$.fragment,c),E(zR.$$.fragment,c),E(N5.$$.fragment,c),E(QR.$$.fragment,c),E(X5.$$.fragment,c),E(WR.$$.fragment,c),E(UR.$$.fragment,c),E(JR.$$.fragment,c),E(Q5.$$.fragment,c),E(YR.$$.fragment,c),E(Z5.$$.fragment,c),E(ZR.$$.fragment,c),E(KR.$$.fragment,c),E(oP.$$.fragment,c),E(e0.$$.fragment,c),E(rP.$$.fragment,c),E(l0.$$.fragment,c),E(tP.$$.fragment,c),E(aP.$$.fragment,c),E(sP.$$.fragment,c),E(d0.$$.fragment,c),E(lP.$$.fragment,c),E(f0.$$.fragment,c),E(iP.$$.fragment,c),E(dP.$$.fragment,c),E(cP.$$.fragment,c),E(h0.$$.fragment,c),E(fP.$$.fragment,c),E(T0.$$.fragment,c),E(gP.$$.fragment,c),E(hP.$$.fragment,c),E(pP.$$.fragment,c),E(E0.$$.fragment,c),E(_P.$$.fragment,c),E(A0.$$.fragment,c),E(bP.$$.fragment,c),E(vP.$$.fragment,c),E(TP.$$.fragment,c),E(y0.$$.fragment,c),E(MP.$$.fragment,c),E(k0.$$.fragment,c),E(EP.$$.fragment,c),E(CP.$$.fragment,c),E(AP.$$.fragment,c),E(R0.$$.fragment,c),E(LP.$$.fragment,c),E(Nw.$$.fragment,c),E(yP.$$.fragment,c),E(xP.$$.fragment,c),E(kP.$$.fragment,c),E(Dw.$$.fragment,c),E(SP.$$.fragment,c),E(dA.$$.fragment,c),E(RP.$$.fragment,c),E(PP.$$.fragment,c),E(IP.$$.fragment,c),E(cA.$$.fragment,c),E(NP.$$.fragment,c),E(AA.$$.fragment,c),E(qP.$$.fragment,c),E(DP.$$.fragment,c),E(GP.$$.fragment,c),E(yA.$$.fragment,c),E(OP.$$.fragment,c),E(qA.$$.fragment,c),E(VP.$$.fragment,c),E(XP.$$.fragment,c),E(QP.$$.fragment,c),E(jA.$$.fragment,c),E(WP.$$.fragment,c),E(XA.$$.fragment,c),E(UP.$$.fragment,c),E(HP.$$.fragment,c),E(YP.$$.fragment,c),E(QA.$$.fragment,c),E(ZP.$$.fragment,c),E(h6.$$.fragment,c),E(KP.$$.fragment,c),E(eB.$$.fragment,c),E(rB.$$.fragment,c),E(p6.$$.fragment,c),E(tB.$$.fragment,c),E(L6.$$.fragment,c),E(aB.$$.fragment,c),E(nB.$$.fragment,c),E(lB.$$.fragment,c),E(x6.$$.fragment,c),E(iB.$$.fragment,c),E(a7.$$.fragment,c),E(dB.$$.fragment,c),E(mB.$$.fragment,c),E(fB.$$.fragment,c),E(s7.$$.fragment,c),E(gB.$$.fragment,c),E(C7.$$.fragment,c),E(hB.$$.fragment,c),E(uB.$$.fragment,c),E(_B.$$.fragment,c),E(A7.$$.fragment,c),E(bB.$$.fragment,c),E(x7.$$.fragment,c),E(FB.$$.fragment,c),E(TB.$$.fragment,c),E(EB.$$.fragment,c),E(k7.$$.fragment,c),E(CB.$$.fragment,c),E(R7.$$.fragment,c),E(wB.$$.fragment,c),E(AB.$$.fragment,c),E(yB.$$.fragment,c),E(B7.$$.fragment,c),E(xB.$$.fragment,c),E(N7.$$.fragment,c),E($B.$$.fragment,c),E(kB.$$.fragment,c),E(RB.$$.fragment,c),E(D7.$$.fragment,c),E(PB.$$.fragment,c),E(i8.$$.fragment,c),E(BB.$$.fragment,c),E(IB.$$.fragment,c),E(qB.$$.fragment,c),E(m8.$$.fragment,c),E(DB.$$.fragment,c),E(S8.$$.fragment,c),E(jB.$$.fragment,c),E(GB.$$.fragment,c),E(VB.$$.fragment,c),E(P8.$$.fragment,c),E(XB.$$.fragment,c),E(I8.$$.fragment,c),E(zB.$$.fragment,c),E(QB.$$.fragment,c),E(UB.$$.fragment,c),E(q8.$$.fragment,c),E(HB.$$.fragment,c),E(G8.$$.fragment,c),E(YB.$$.fragment,c),E(ZB.$$.fragment,c),E(eI.$$.fragment,c),E(V8.$$.fragment,c),E(oI.$$.fragment,c),E(_L.$$.fragment,c),E(rI.$$.fragment,c),E(tI.$$.fragment,c),E(nI.$$.fragment,c),E(vL.$$.fragment,c),E(sI.$$.fragment,c),E($L.$$.fragment,c),E(lI.$$.fragment,c),E(iI.$$.fragment,c),E(mI.$$.fragment,c),E(SL.$$.fragment,c),E(cI.$$.fragment,c),E(QL.$$.fragment,c),E(fI.$$.fragment,c),E(gI.$$.fragment,c),E(uI.$$.fragment,c),E(UL.$$.fragment,c),E(pI.$$.fragment,c),E(ny.$$.fragment,c),E(_I.$$.fragment,c),E(bI.$$.fragment,c),E(FI.$$.fragment,c),E(ly.$$.fragment,c),E(TI.$$.fragment,c),E(by.$$.fragment,c),E(MI.$$.fragment,c),E(EI.$$.fragment,c),E(wI.$$.fragment,c),E(Fy.$$.fragment,c),E(AI.$$.fragment,c),E(ky.$$.fragment,c),E(LI.$$.fragment,c),E(yI.$$.fragment,c),E($I.$$.fragment,c),E(Ry.$$.fragment,c),E(kI.$$.fragment,c),E(Xy.$$.fragment,c),E(SI.$$.fragment,c),E(RI.$$.fragment,c),E(BI.$$.fragment,c),E(Qy.$$.fragment,c),E(II.$$.fragment,c),E(o9.$$.fragment,c),E(NI.$$.fragment,c),E(qI.$$.fragment,c),E(jI.$$.fragment,c),E(t9.$$.fragment,c),E(GI.$$.fragment,c),E(f9.$$.fragment,c),E(OI.$$.fragment,c),E(VI.$$.fragment,c),E(zI.$$.fragment,c),E(h9.$$.fragment,c),E(QI.$$.fragment,c),E(p9.$$.fragment,c),E(WI.$$.fragment,c),E(UI.$$.fragment,c),E(JI.$$.fragment,c),E(b9.$$.fragment,c),E(YI.$$.fragment,c),E(T9.$$.fragment,c),E(KI.$$.fragment,c),E(eN.$$.fragment,c),E(rN.$$.fragment,c),E(E9.$$.fragment,c),E(tN.$$.fragment,c),E(w9.$$.fragment,c),Bdo=!0)},o(c){C(m.$$.fragment,c),C(sn.$$.fragment,c),C(fk.$$.fragment,c),C(gk.$$.fragment,c),C(ng.$$.fragment,c),C(hk.$$.fragment,c),C(uk.$$.fragment,c),C(bk.$$.fragment,c),C(Iu.$$.fragment,c),C(vk.$$.fragment,c),C(Fk.$$.fragment,c),C(Tk.$$.fragment,c),C(Ck.$$.fragment,c),C(Mp.$$.fragment,c),C(wk.$$.fragment,c),C(Ak.$$.fragment,c),C(Lk.$$.fragment,c),C($k.$$.fragment,c),C(p_.$$.fragment,c),C(__.$$.fragment,c),C(kk.$$.fragment,c),C(Sk.$$.fragment,c),C(Rk.$$.fragment,c),C(Ik.$$.fragment,c),C(H_.$$.fragment,c),C(J_.$$.fragment,c),C(Nk.$$.fragment,c),C(qk.$$.fragment,c),C(Dk.$$.fragment,c),C(Ok.$$.fragment,c),C(M1.$$.fragment,c),C(E1.$$.fragment,c),C(Vk.$$.fragment,c),C(Xk.$$.fragment,c),C(zk.$$.fragment,c),C(Wk.$$.fragment,c),C(A1.$$.fragment,c),C(Uk.$$.fragment,c),C(Jb.$$.fragment,c),C(Hk.$$.fragment,c),C(Jk.$$.fragment,c),C(Zk.$$.fragment,c),C(Zb.$$.fragment,c),C(Kk.$$.fragment,c),C(Hv.$$.fragment,c),C(eS.$$.fragment,c),C(oS.$$.fragment,c),C(tS.$$.fragment,c),C(Yv.$$.fragment,c),C(aS.$$.fragment,c),C(OF.$$.fragment,c),C(nS.$$.fragment,c),C(sS.$$.fragment,c),C(iS.$$.fragment,c),C(XF.$$.fragment,c),C(dS.$$.fragment,c),C(UF.$$.fragment,c),C(cS.$$.fragment,c),C(fS.$$.fragment,c),C(hS.$$.fragment,c),C(JF.$$.fragment,c),C(uS.$$.fragment,c),C(qT.$$.fragment,c),C(pS.$$.fragment,c),C(_S.$$.fragment,c),C(vS.$$.fragment,c),C(jT.$$.fragment,c),C(FS.$$.fragment,c),C(iM.$$.fragment,c),C(TS.$$.fragment,c),C(MS.$$.fragment,c),C(CS.$$.fragment,c),C(mM.$$.fragment,c),C(wS.$$.fragment,c),C(uE.$$.fragment,c),C(AS.$$.fragment,c),C(LS.$$.fragment,c),C(xS.$$.fragment,c),C(_E.$$.fragment,c),C($S.$$.fragment,c),C(ZE.$$.fragment,c),C(kS.$$.fragment,c),C(SS.$$.fragment,c),C(PS.$$.fragment,c),C(e4.$$.fragment,c),C(BS.$$.fragment,c),C(d4.$$.fragment,c),C(IS.$$.fragment,c),C(NS.$$.fragment,c),C(DS.$$.fragment,c),C(c4.$$.fragment,c),C(jS.$$.fragment,c),C(oC.$$.fragment,c),C(GS.$$.fragment,c),C(OS.$$.fragment,c),C(XS.$$.fragment,c),C(tC.$$.fragment,c),C(zS.$$.fragment,c),C(e3.$$.fragment,c),C(QS.$$.fragment,c),C(WS.$$.fragment,c),C(HS.$$.fragment,c),C(r3.$$.fragment,c),C(JS.$$.fragment,c),C(n3.$$.fragment,c),C(YS.$$.fragment,c),C(ZS.$$.fragment,c),C(eR.$$.fragment,c),C(l3.$$.fragment,c),C(oR.$$.fragment,c),C(f3.$$.fragment,c),C(rR.$$.fragment,c),C(tR.$$.fragment,c),C(nR.$$.fragment,c),C(h3.$$.fragment,c),C(sR.$$.fragment,c),C(k3.$$.fragment,c),C(lR.$$.fragment,c),C(iR.$$.fragment,c),C(mR.$$.fragment,c),C(R3.$$.fragment,c),C(cR.$$.fragment,c),C(I3.$$.fragment,c),C(fR.$$.fragment,c),C(gR.$$.fragment,c),C(uR.$$.fragment,c),C(q3.$$.fragment,c),C(pR.$$.fragment,c),C(G3.$$.fragment,c),C(_R.$$.fragment,c),C(bR.$$.fragment,c),C(FR.$$.fragment,c),C(V3.$$.fragment,c),C(TR.$$.fragment,c),C(Q3.$$.fragment,c),C(MR.$$.fragment,c),C(ER.$$.fragment,c),C(wR.$$.fragment,c),C(U3.$$.fragment,c),C(AR.$$.fragment,c),C(n5.$$.fragment,c),C(LR.$$.fragment,c),C(yR.$$.fragment,c),C($R.$$.fragment,c),C(l5.$$.fragment,c),C(kR.$$.fragment,c),C(h5.$$.fragment,c),C(SR.$$.fragment,c),C(RR.$$.fragment,c),C(BR.$$.fragment,c),C(p5.$$.fragment,c),C(IR.$$.fragment,c),C(y5.$$.fragment,c),C(NR.$$.fragment,c),C(qR.$$.fragment,c),C(jR.$$.fragment,c),C($5.$$.fragment,c),C(GR.$$.fragment,c),C(B5.$$.fragment,c),C(OR.$$.fragment,c),C(VR.$$.fragment,c),C(zR.$$.fragment,c),C(N5.$$.fragment,c),C(QR.$$.fragment,c),C(X5.$$.fragment,c),C(WR.$$.fragment,c),C(UR.$$.fragment,c),C(JR.$$.fragment,c),C(Q5.$$.fragment,c),C(YR.$$.fragment,c),C(Z5.$$.fragment,c),C(ZR.$$.fragment,c),C(KR.$$.fragment,c),C(oP.$$.fragment,c),C(e0.$$.fragment,c),C(rP.$$.fragment,c),C(l0.$$.fragment,c),C(tP.$$.fragment,c),C(aP.$$.fragment,c),C(sP.$$.fragment,c),C(d0.$$.fragment,c),C(lP.$$.fragment,c),C(f0.$$.fragment,c),C(iP.$$.fragment,c),C(dP.$$.fragment,c),C(cP.$$.fragment,c),C(h0.$$.fragment,c),C(fP.$$.fragment,c),C(T0.$$.fragment,c),C(gP.$$.fragment,c),C(hP.$$.fragment,c),C(pP.$$.fragment,c),C(E0.$$.fragment,c),C(_P.$$.fragment,c),C(A0.$$.fragment,c),C(bP.$$.fragment,c),C(vP.$$.fragment,c),C(TP.$$.fragment,c),C(y0.$$.fragment,c),C(MP.$$.fragment,c),C(k0.$$.fragment,c),C(EP.$$.fragment,c),C(CP.$$.fragment,c),C(AP.$$.fragment,c),C(R0.$$.fragment,c),C(LP.$$.fragment,c),C(Nw.$$.fragment,c),C(yP.$$.fragment,c),C(xP.$$.fragment,c),C(kP.$$.fragment,c),C(Dw.$$.fragment,c),C(SP.$$.fragment,c),C(dA.$$.fragment,c),C(RP.$$.fragment,c),C(PP.$$.fragment,c),C(IP.$$.fragment,c),C(cA.$$.fragment,c),C(NP.$$.fragment,c),C(AA.$$.fragment,c),C(qP.$$.fragment,c),C(DP.$$.fragment,c),C(GP.$$.fragment,c),C(yA.$$.fragment,c),C(OP.$$.fragment,c),C(qA.$$.fragment,c),C(VP.$$.fragment,c),C(XP.$$.fragment,c),C(QP.$$.fragment,c),C(jA.$$.fragment,c),C(WP.$$.fragment,c),C(XA.$$.fragment,c),C(UP.$$.fragment,c),C(HP.$$.fragment,c),C(YP.$$.fragment,c),C(QA.$$.fragment,c),C(ZP.$$.fragment,c),C(h6.$$.fragment,c),C(KP.$$.fragment,c),C(eB.$$.fragment,c),C(rB.$$.fragment,c),C(p6.$$.fragment,c),C(tB.$$.fragment,c),C(L6.$$.fragment,c),C(aB.$$.fragment,c),C(nB.$$.fragment,c),C(lB.$$.fragment,c),C(x6.$$.fragment,c),C(iB.$$.fragment,c),C(a7.$$.fragment,c),C(dB.$$.fragment,c),C(mB.$$.fragment,c),C(fB.$$.fragment,c),C(s7.$$.fragment,c),C(gB.$$.fragment,c),C(C7.$$.fragment,c),C(hB.$$.fragment,c),C(uB.$$.fragment,c),C(_B.$$.fragment,c),C(A7.$$.fragment,c),C(bB.$$.fragment,c),C(x7.$$.fragment,c),C(FB.$$.fragment,c),C(TB.$$.fragment,c),C(EB.$$.fragment,c),C(k7.$$.fragment,c),C(CB.$$.fragment,c),C(R7.$$.fragment,c),C(wB.$$.fragment,c),C(AB.$$.fragment,c),C(yB.$$.fragment,c),C(B7.$$.fragment,c),C(xB.$$.fragment,c),C(N7.$$.fragment,c),C($B.$$.fragment,c),C(kB.$$.fragment,c),C(RB.$$.fragment,c),C(D7.$$.fragment,c),C(PB.$$.fragment,c),C(i8.$$.fragment,c),C(BB.$$.fragment,c),C(IB.$$.fragment,c),C(qB.$$.fragment,c),C(m8.$$.fragment,c),C(DB.$$.fragment,c),C(S8.$$.fragment,c),C(jB.$$.fragment,c),C(GB.$$.fragment,c),C(VB.$$.fragment,c),C(P8.$$.fragment,c),C(XB.$$.fragment,c),C(I8.$$.fragment,c),C(zB.$$.fragment,c),C(QB.$$.fragment,c),C(UB.$$.fragment,c),C(q8.$$.fragment,c),C(HB.$$.fragment,c),C(G8.$$.fragment,c),C(YB.$$.fragment,c),C(ZB.$$.fragment,c),C(eI.$$.fragment,c),C(V8.$$.fragment,c),C(oI.$$.fragment,c),C(_L.$$.fragment,c),C(rI.$$.fragment,c),C(tI.$$.fragment,c),C(nI.$$.fragment,c),C(vL.$$.fragment,c),C(sI.$$.fragment,c),C($L.$$.fragment,c),C(lI.$$.fragment,c),C(iI.$$.fragment,c),C(mI.$$.fragment,c),C(SL.$$.fragment,c),C(cI.$$.fragment,c),C(QL.$$.fragment,c),C(fI.$$.fragment,c),C(gI.$$.fragment,c),C(uI.$$.fragment,c),C(UL.$$.fragment,c),C(pI.$$.fragment,c),C(ny.$$.fragment,c),C(_I.$$.fragment,c),C(bI.$$.fragment,c),C(FI.$$.fragment,c),C(ly.$$.fragment,c),C(TI.$$.fragment,c),C(by.$$.fragment,c),C(MI.$$.fragment,c),C(EI.$$.fragment,c),C(wI.$$.fragment,c),C(Fy.$$.fragment,c),C(AI.$$.fragment,c),C(ky.$$.fragment,c),C(LI.$$.fragment,c),C(yI.$$.fragment,c),C($I.$$.fragment,c),C(Ry.$$.fragment,c),C(kI.$$.fragment,c),C(Xy.$$.fragment,c),C(SI.$$.fragment,c),C(RI.$$.fragment,c),C(BI.$$.fragment,c),C(Qy.$$.fragment,c),C(II.$$.fragment,c),C(o9.$$.fragment,c),C(NI.$$.fragment,c),C(qI.$$.fragment,c),C(jI.$$.fragment,c),C(t9.$$.fragment,c),C(GI.$$.fragment,c),C(f9.$$.fragment,c),C(OI.$$.fragment,c),C(VI.$$.fragment,c),C(zI.$$.fragment,c),C(h9.$$.fragment,c),C(QI.$$.fragment,c),C(p9.$$.fragment,c),C(WI.$$.fragment,c),C(UI.$$.fragment,c),C(JI.$$.fragment,c),C(b9.$$.fragment,c),C(YI.$$.fragment,c),C(T9.$$.fragment,c),C(KI.$$.fragment,c),C(eN.$$.fragment,c),C(rN.$$.fragment,c),C(E9.$$.fragment,c),C(tN.$$.fragment,c),C(w9.$$.fragment,c),Bdo=!1},d(c){t(g),c&&t(v),c&&t(u),w(m),c&&t(eg),c&&t(wt),c&&t(Qe),c&&t(Ze),c&&t(rg),w(sn,c),c&&t(Ke),c&&t(ye),c&&t(Po),c&&t(ln),c&&t(plo),c&&t(Rd),w(fk),c&&t(_lo),c&&t(Fs),c&&t(blo),w(gk,c),c&&t(vlo),c&&t(Nq),c&&t(Flo),w(ng,c),c&&t(Tlo),c&&t(Pd),w(hk),c&&t(Mlo),c&&t(Bo),w(uk),w(bk),w(Iu),w(vk),c&&t(Elo),c&&t(Id),w(Fk),c&&t(Clo),c&&t(Io),w(Tk),w(Ck),w(Mp),w(wk),c&&t(wlo),c&&t(Nd),w(Ak),c&&t(Alo),c&&t(No),w(Lk),w($k),w(p_),w(__),w(kk),c&&t(Llo),c&&t(qd),w(Sk),c&&t(ylo),c&&t(qo),w(Rk),w(Ik),w(H_),w(J_),w(Nk),c&&t(xlo),c&&t(Dd),w(qk),c&&t($lo),c&&t(Do),w(Dk),w(Ok),w(M1),w(E1),w(Vk),c&&t(klo),c&&t(Gd),w(Xk),c&&t(Slo),c&&t(jo),w(zk),w(Wk),w(A1),w(Uk),w(Jb),c&&t(Rlo),c&&t(Xd),w(Hk),c&&t(Plo),c&&t(Go),w(Jk),w(Zk),w(Zb),w(Kk),w(Hv),c&&t(Blo),c&&t(Wd),w(eS),c&&t(Ilo),c&&t(Oo),w(oS),w(tS),w(Yv),w(aS),w(OF),c&&t(Nlo),c&&t(Jd),w(nS),c&&t(qlo),c&&t(Vo),w(sS),w(iS),w(XF),w(dS),w(UF),c&&t(Dlo),c&&t(Kd),w(cS),c&&t(jlo),c&&t(Xo),w(fS),w(hS),w(JF),w(uS),w(qT),c&&t(Glo),c&&t(rm),w(pS),c&&t(Olo),c&&t(zo),w(_S),w(vS),w(jT),w(FS),w(iM),c&&t(Vlo),c&&t(nm),w(TS),c&&t(Xlo),c&&t(Qo),w(MS),w(CS),w(mM),w(wS),w(uE),c&&t(zlo),c&&t(im),w(AS),c&&t(Qlo),c&&t(Wo),w(LS),w(xS),w(_E),w($S),w(ZE),c&&t(Wlo),c&&t(cm),w(kS),c&&t(Ulo),c&&t(Uo),w(SS),w(PS),w(e4),w(BS),w(d4),c&&t(Hlo),c&&t(hm),w(IS),c&&t(Jlo),c&&t(Ho),w(NS),w(DS),w(c4),w(jS),w(oC),c&&t(Ylo),c&&t(_m),w(GS),c&&t(Zlo),c&&t(Jo),w(OS),w(XS),w(tC),w(zS),w(e3),c&&t(Klo),c&&t(Fm),w(QS),c&&t(eio),c&&t(Yo),w(WS),w(HS),w(r3),w(JS),w(n3),c&&t(oio),c&&t(Em),w(YS),c&&t(rio),c&&t(Zo),w(ZS),w(eR),w(l3),w(oR),w(f3),c&&t(tio),c&&t(Lm),w(rR),c&&t(aio),c&&t(Ko),w(tR),w(nR),w(h3),w(sR),w(k3),c&&t(nio),c&&t($m),w(lR),c&&t(sio),c&&t(er),w(iR),w(mR),w(R3),w(cR),w(I3),c&&t(lio),c&&t(Rm),w(fR),c&&t(iio),c&&t(or),w(gR),w(uR),w(q3),w(pR),w(G3),c&&t(dio),c&&t(Im),w(_R),c&&t(mio),c&&t(rr),w(bR),w(FR),w(V3),w(TR),w(Q3),c&&t(cio),c&&t(Dm),w(MR),c&&t(fio),c&&t(tr),w(ER),w(wR),w(U3),w(AR),w(n5),c&&t(gio),c&&t(Om),w(LR),c&&t(hio),c&&t(ar),w(yR),w($R),w(l5),w(kR),w(h5),c&&t(uio),c&&t(zm),w(SR),c&&t(pio),c&&t(nr),w(RR),w(BR),w(p5),w(IR),w(y5),c&&t(_io),c&&t(Um),w(NR),c&&t(bio),c&&t(sr),w(qR),w(jR),w($5),w(GR),w(B5),c&&t(vio),c&&t(Zm),w(OR),c&&t(Fio),c&&t(lr),w(VR),w(zR),w(N5),w(QR),w(X5),c&&t(Tio),c&&t(oc),w(WR),c&&t(Mio),c&&t(ir),w(UR),w(JR),w(Q5),w(YR),w(Z5),c&&t(Eio),c&&t(ac),w(ZR),c&&t(Cio),c&&t(dr),w(KR),w(oP),w(e0),w(rP),w(l0),c&&t(wio),c&&t(lc),w(tP),c&&t(Aio),c&&t(mr),w(aP),w(sP),w(d0),w(lP),w(f0),c&&t(Lio),c&&t(mc),w(iP),c&&t(yio),c&&t(cr),w(dP),w(cP),w(h0),w(fP),w(T0),c&&t(xio),c&&t(gc),w(gP),c&&t($io),c&&t(fr),w(hP),w(pP),w(E0),w(_P),w(A0),c&&t(kio),c&&t(pc),w(bP),c&&t(Sio),c&&t(gr),w(vP),w(TP),w(y0),w(MP),w(k0),c&&t(Rio),c&&t(vc),w(EP),c&&t(Pio),c&&t(hr),w(CP),w(AP),w(R0),w(LP),w(Nw),c&&t(Bio),c&&t(Mc),w(yP),c&&t(Iio),c&&t(ur),w(xP),w(kP),w(Dw),w(SP),w(dA),c&&t(Nio),c&&t(wc),w(RP),c&&t(qio),c&&t(pr),w(PP),w(IP),w(cA),w(NP),w(AA),c&&t(Dio),c&&t(yc),w(qP),c&&t(jio),c&&t(_r),w(DP),w(GP),w(yA),w(OP),w(qA),c&&t(Gio),c&&t(kc),w(VP),c&&t(Oio),c&&t(br),w(XP),w(QP),w(jA),w(WP),w(XA),c&&t(Vio),c&&t(Bc),w(UP),c&&t(Xio),c&&t(vr),w(HP),w(YP),w(QA),w(ZP),w(h6),c&&t(zio),c&&t(qc),w(KP),c&&t(Qio),c&&t(Fr),w(eB),w(rB),w(p6),w(tB),w(L6),c&&t(Wio),c&&t(Gc),w(aB),c&&t(Uio),c&&t(Tr),w(nB),w(lB),w(x6),w(iB),w(a7),c&&t(Hio),c&&t(Xc),w(dB),c&&t(Jio),c&&t(Mr),w(mB),w(fB),w(s7),w(gB),w(C7),c&&t(Yio),c&&t(Wc),w(hB),c&&t(Zio),c&&t(Er),w(uB),w(_B),w(A7),w(bB),w(x7),c&&t(Kio),c&&t(Jc),w(FB),c&&t(edo),c&&t(Cr),w(TB),w(EB),w(k7),w(CB),w(R7),c&&t(odo),c&&t(Kc),w(wB),c&&t(rdo),c&&t(wr),w(AB),w(yB),w(B7),w(xB),w(N7),c&&t(tdo),c&&t(rf),w($B),c&&t(ado),c&&t(Ar),w(kB),w(RB),w(D7),w(PB),w(i8),c&&t(ndo),c&&t(nf),w(BB),c&&t(sdo),c&&t(Lr),w(IB),w(qB),w(m8),w(DB),w(S8),c&&t(ldo),c&&t(df),w(jB),c&&t(ido),c&&t(yr),w(GB),w(VB),w(P8),w(XB),w(I8),c&&t(ddo),c&&t(ff),w(zB),c&&t(mdo),c&&t(xr),w(QB),w(UB),w(q8),w(HB),w(G8),c&&t(cdo),c&&t(uf),w(YB),c&&t(fdo),c&&t($r),w(ZB),w(eI),w(V8),w(oI),w(_L),c&&t(gdo),c&&t(bf),w(rI),c&&t(hdo),c&&t(kr),w(tI),w(nI),w(vL),w(sI),w($L),c&&t(udo),c&&t(Tf),w(lI),c&&t(pdo),c&&t(Sr),w(iI),w(mI),w(SL),w(cI),w(QL),c&&t(_do),c&&t(Cf),w(fI),c&&t(bdo),c&&t(Rr),w(gI),w(uI),w(UL),w(pI),w(ny),c&&t(vdo),c&&t(Lf),w(_I),c&&t(Fdo),c&&t(Pr),w(bI),w(FI),w(ly),w(TI),w(by),c&&t(Tdo),c&&t($f),w(MI),c&&t(Mdo),c&&t(Br),w(EI),w(wI),w(Fy),w(AI),w(ky),c&&t(Edo),c&&t(Rf),w(LI),c&&t(Cdo),c&&t(Ir),w(yI),w($I),w(Ry),w(kI),w(Xy),c&&t(wdo),c&&t(If),w(SI),c&&t(Ado),c&&t(Nr),w(RI),w(BI),w(Qy),w(II),w(o9),c&&t(Ldo),c&&t(Df),w(NI),c&&t(ydo),c&&t(qr),w(qI),w(jI),w(t9),w(GI),w(f9),c&&t(xdo),c&&t(Of),w(OI),c&&t($do),c&&t(Dr),w(VI),w(zI),w(h9),w(QI),w(p9),c&&t(kdo),c&&t(zf),w(WI),c&&t(Sdo),c&&t(jr),w(UI),w(JI),w(b9),w(YI),w(T9),c&&t(Rdo),c&&t(Uf),w(KI),c&&t(Pdo),c&&t(Gr),w(eN),w(rN),w(E9),w(tN),w(w9)}}}const ska={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoImageProcessor",title:"AutoImageProcessor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForDepthEstimation",title:"AutoModelForDepthEstimation"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForDocumentQuestionAnswering",title:"AutoModelForDocumentQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVideoClassification",title:"AutoModelForVideoClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.AutoModelForZeroShotObjectDetection",title:"AutoModelForZeroShotObjectDetection"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForSemanticSegmentation",title:"TFAutoModelForSemanticSegmentation"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForDocumentQuestionAnswering",title:"TFAutoModelForDocumentQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function lka($){return z9a(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class hka extends G9a{constructor(g){super();O9a(this,g,lka,nka,V9a,{})}}export{hka as default,ska as metadata};
