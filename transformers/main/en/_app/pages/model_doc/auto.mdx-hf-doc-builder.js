import{S as vwa,i as Fwa,s as Twa,e as a,k as l,w as F,t as o,M as Mwa,c as n,d as t,m as i,a as s,x as T,h as r,b as d,G as e,g as b,y as M,q as E,o as C,B as w,v as Ewa,L as j}from"../../chunks/vendor-hf-doc-builder.js";import{T as i8t}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as B}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as oe}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as q}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function Cwa($){let g,v,u,f,p,m,h,$o,vd,Qf,Tt,Fd,Td,v$,Wf,Xe,He,Md,ms,F$,cs,fs,T$,Ed,gs,M$,Cd,Uf,on;return{c(){g=a("p"),v=o("If your "),u=a("code"),f=o("NewModelConfig"),p=o(" is a subclass of "),m=a("code"),h=o("~transformer.PretrainedConfig"),$o=o(`, make sure its
`),vd=a("code"),Qf=o("model_type"),Tt=o(" attribute is set to the same key you use when registering the config (here "),Fd=a("code"),Td=o('"new-model"'),v$=o(")."),Wf=l(),Xe=a("p"),He=o("Likewise, if your "),Md=a("code"),ms=o("NewModel"),F$=o(" is a subclass of "),cs=a("a"),fs=o("PreTrainedModel"),T$=o(`, make sure its
`),Ed=a("code"),gs=o("config_class"),M$=o(` attribute is set to the same class you use when registering the model (here
`),Cd=a("code"),Uf=o("NewModelConfig"),on=o(")."),this.h()},l(Je){g=n(Je,"P",{});var Ae=s(g);v=r(Ae,"If your "),u=n(Ae,"CODE",{});var NN=s(u);f=r(NN,"NewModelConfig"),NN.forEach(t),p=r(Ae," is a subclass of "),m=n(Ae,"CODE",{});var wd=s(m);h=r(wd,"~transformer.PretrainedConfig"),wd.forEach(t),$o=r(Ae,`, make sure its
`),vd=n(Ae,"CODE",{});var qN=s(vd);Qf=r(qN,"model_type"),qN.forEach(t),Tt=r(Ae," attribute is set to the same key you use when registering the config (here "),Fd=n(Ae,"CODE",{});var jN=s(Fd);Td=r(jN,'"new-model"'),jN.forEach(t),v$=r(Ae,")."),Ae.forEach(t),Wf=i(Je),Xe=n(Je,"P",{});var ko=s(Xe);He=r(ko,"Likewise, if your "),Md=n(ko,"CODE",{});var rn=s(Md);ms=r(rn,"NewModel"),rn.forEach(t),F$=r(ko," is a subclass of "),cs=n(ko,"A",{href:!0});var DN=s(cs);fs=r(DN,"PreTrainedModel"),DN.forEach(t),T$=r(ko,`, make sure its
`),Ed=n(ko,"CODE",{});var Hf=s(Ed);gs=r(Hf,"config_class"),Hf.forEach(t),M$=r(ko,` attribute is set to the same class you use when registering the model (here
`),Cd=n(ko,"CODE",{});var GN=s(Cd);Uf=r(GN,"NewModelConfig"),GN.forEach(t),on=r(ko,")."),ko.forEach(t),this.h()},h(){d(cs,"href","/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel")},m(Je,Ae){b(Je,g,Ae),e(g,v),e(g,u),e(u,f),e(g,p),e(g,m),e(m,h),e(g,$o),e(g,vd),e(vd,Qf),e(g,Tt),e(g,Fd),e(Fd,Td),e(g,v$),b(Je,Wf,Ae),b(Je,Xe,Ae),e(Xe,He),e(Xe,Md),e(Md,ms),e(Xe,F$),e(Xe,cs),e(cs,fs),e(Xe,T$),e(Xe,Ed),e(Ed,gs),e(Xe,M$),e(Xe,Cd),e(Cd,Uf),e(Xe,on)},d(Je){Je&&t(g),Je&&t(Wf),Je&&t(Xe)}}}function wwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Awa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Lwa($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var $o=s(u);f=r($o,"use_auth_token=True"),$o.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(m,h){b(m,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(m){m&&t(g)}}}function ywa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function xwa($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var $o=s(u);f=r($o,"use_auth_token=True"),$o.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(m,h){b(m,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(m){m&&t(g)}}}function $wa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function kwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Swa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Rwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Pwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Bwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Iwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Nwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDepthEstimation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForDepthEstimation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDepthEstimation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function qwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDepthEstimation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForDepthEstimation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForDepthEstimation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForDepthEstimation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDepthEstimation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function jwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Dwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Gwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Owa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Vwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Xwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function zwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Qwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Wwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Uwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Hwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Jwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Ywa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Zwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Kwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function eAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function oAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = AutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function rAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/layoutlm_tf_model_config.json")
model = AutoModelForDocumentQuestionAnswering.from_pretrained(
    "./tf_model/layoutlm_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/layoutlm_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/layoutlm_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function tAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function aAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function nAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVideoClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function sAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVideoClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function lAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function iAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function dAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function mAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function cAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function fAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function gAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function hAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function uAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function pAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function _Aa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function bAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function vAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function FAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function TAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function MAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function EAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function CAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function wAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function AAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function LAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function yAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function xAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function $Aa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function kAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForZeroShotObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForZeroShotObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForZeroShotObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function SAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForZeroShotObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForZeroShotObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForZeroShotObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForZeroShotObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForZeroShotObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function RAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function PAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function BAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function IAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function NAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function qAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function jAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function DAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function GAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function OAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSemanticSegmentation.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function VAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function XAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function zAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function QAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function WAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function UAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function HAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function JAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function YAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function ZAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function KAa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function e6a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function o6a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function r6a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/layoutlm_pt_model_config.json")
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
    "./pt_model/layoutlm_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/layoutlm_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/layoutlm_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function t6a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function a6a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function n6a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function s6a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function l6a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function i6a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function d6a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function m6a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function c6a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function f6a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function g6a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function h6a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function u6a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function p6a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function _6a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function b6a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function v6a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function F6a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function T6a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function M6a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function E6a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function C6a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function w6a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function A6a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function L6a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function y6a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function x6a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function $6a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function k6a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function S6a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function R6a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function P6a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:j,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function B6a($){let g,v,u,f,p,m,h,$o,vd,Qf,Tt,Fd,Td,v$,Wf,Xe,He,Md,ms,F$,cs,fs,T$,Ed,gs,M$,Cd,Uf,on,Je,Ae,NN,wd,qN,jN,ko,rn,DN,Hf,GN,gdo,yao,Ad,Jf,Gfe,E$,hdo,Ofe,udo,xao,hs,pdo,Vfe,_do,bdo,Xfe,vdo,Fdo,$ao,C$,kao,ON,Tdo,Sao,Yf,Rao,Ld,Zf,zfe,w$,Mdo,Qfe,Edo,Pao,So,A$,Cdo,L$,wdo,VN,Ado,Ldo,ydo,y$,xdo,Wfe,$do,kdo,Sdo,qr,x$,Rdo,Ufe,Pdo,Bdo,yd,Ido,Hfe,Ndo,qdo,Jfe,jdo,Ddo,Gdo,A,Kf,Yfe,Odo,Vdo,XN,Xdo,zdo,Qdo,eg,Zfe,Wdo,Udo,zN,Hdo,Jdo,Ydo,og,Kfe,Zdo,Kdo,QN,emo,omo,rmo,rg,ege,tmo,amo,WN,nmo,smo,lmo,tg,oge,imo,dmo,UN,mmo,cmo,fmo,ag,rge,gmo,hmo,HN,umo,pmo,_mo,ng,tge,bmo,vmo,JN,Fmo,Tmo,Mmo,sg,age,Emo,Cmo,YN,wmo,Amo,Lmo,lg,nge,ymo,xmo,ZN,$mo,kmo,Smo,ig,sge,Rmo,Pmo,KN,Bmo,Imo,Nmo,dg,lge,qmo,jmo,eq,Dmo,Gmo,Omo,mg,ige,Vmo,Xmo,oq,zmo,Qmo,Wmo,cg,dge,Umo,Hmo,rq,Jmo,Ymo,Zmo,fg,mge,Kmo,eco,tq,oco,rco,tco,gg,cge,aco,nco,aq,sco,lco,ico,hg,fge,dco,mco,nq,cco,fco,gco,ug,gge,hco,uco,sq,pco,_co,bco,pg,hge,vco,Fco,lq,Tco,Mco,Eco,_g,uge,Cco,wco,iq,Aco,Lco,yco,bg,pge,xco,$co,dq,kco,Sco,Rco,vg,_ge,Pco,Bco,mq,Ico,Nco,qco,Fg,bge,jco,Dco,cq,Gco,Oco,Vco,Tg,vge,Xco,zco,fq,Qco,Wco,Uco,Mg,Fge,Hco,Jco,gq,Yco,Zco,Kco,Eg,Tge,efo,ofo,hq,rfo,tfo,afo,Cg,Mge,nfo,sfo,uq,lfo,ifo,dfo,wg,Ege,mfo,cfo,pq,ffo,gfo,hfo,Ag,Cge,ufo,pfo,_q,_fo,bfo,vfo,Lg,wge,Ffo,Tfo,bq,Mfo,Efo,Cfo,yg,Age,wfo,Afo,vq,Lfo,yfo,xfo,xg,Lge,$fo,kfo,Fq,Sfo,Rfo,Pfo,$g,yge,Bfo,Ifo,Tq,Nfo,qfo,jfo,kg,xge,Dfo,Gfo,Mq,Ofo,Vfo,Xfo,Sg,$ge,zfo,Qfo,Eq,Wfo,Ufo,Hfo,Rg,kge,Jfo,Yfo,Cq,Zfo,Kfo,ego,Pg,Sge,ogo,rgo,wq,tgo,ago,ngo,Bg,Rge,sgo,lgo,Aq,igo,dgo,mgo,Ig,Pge,cgo,fgo,Lq,ggo,hgo,ugo,Ng,Bge,pgo,_go,yq,bgo,vgo,Fgo,qg,Ige,Tgo,Mgo,xq,Ego,Cgo,wgo,jg,Nge,Ago,Lgo,$q,ygo,xgo,$go,Dg,qge,kgo,Sgo,kq,Rgo,Pgo,Bgo,Gg,jge,Igo,Ngo,Sq,qgo,jgo,Dgo,Og,Dge,Ggo,Ogo,Rq,Vgo,Xgo,zgo,Vg,Gge,Qgo,Wgo,Pq,Ugo,Hgo,Jgo,Xg,Oge,Ygo,Zgo,Bq,Kgo,eho,oho,zg,Vge,rho,tho,Iq,aho,nho,sho,Qg,Xge,lho,iho,Nq,dho,mho,cho,Wg,zge,fho,gho,qq,hho,uho,pho,Ug,Qge,_ho,bho,jq,vho,Fho,Tho,Hg,Wge,Mho,Eho,Dq,Cho,who,Aho,Jg,Uge,Lho,yho,Gq,xho,$ho,kho,Yg,Hge,Sho,Rho,Oq,Pho,Bho,Iho,Zg,Jge,Nho,qho,Vq,jho,Dho,Gho,Kg,Yge,Oho,Vho,Xq,Xho,zho,Qho,eh,Zge,Who,Uho,zq,Hho,Jho,Yho,oh,Kge,Zho,Kho,Qq,euo,ouo,ruo,rh,ehe,tuo,auo,Wq,nuo,suo,luo,th,ohe,iuo,duo,Uq,muo,cuo,fuo,ah,rhe,guo,huo,Hq,uuo,puo,_uo,nh,the,buo,vuo,Jq,Fuo,Tuo,Muo,sh,ahe,Euo,Cuo,Yq,wuo,Auo,Luo,lh,nhe,yuo,xuo,Zq,$uo,kuo,Suo,ih,she,Ruo,Puo,Kq,Buo,Iuo,Nuo,dh,lhe,quo,juo,ej,Duo,Guo,Ouo,mh,ihe,Vuo,Xuo,oj,zuo,Quo,Wuo,ch,dhe,Uuo,Huo,rj,Juo,Yuo,Zuo,fh,mhe,Kuo,epo,tj,opo,rpo,tpo,gh,che,apo,npo,aj,spo,lpo,ipo,hh,fhe,dpo,mpo,nj,cpo,fpo,gpo,uh,ghe,hpo,upo,sj,ppo,_po,bpo,ph,hhe,vpo,Fpo,lj,Tpo,Mpo,Epo,_h,uhe,Cpo,wpo,ij,Apo,Lpo,ypo,bh,phe,xpo,$po,dj,kpo,Spo,Rpo,vh,_he,Ppo,Bpo,mj,Ipo,Npo,qpo,Fh,bhe,jpo,Dpo,cj,Gpo,Opo,Vpo,Th,vhe,Xpo,zpo,fj,Qpo,Wpo,Upo,Mh,Fhe,Hpo,Jpo,gj,Ypo,Zpo,Kpo,Eh,The,e_o,o_o,hj,r_o,t_o,a_o,Ch,Mhe,n_o,s_o,uj,l_o,i_o,d_o,wh,Ehe,m_o,c_o,pj,f_o,g_o,h_o,Ah,Che,u_o,p_o,_j,__o,b_o,v_o,Lh,whe,F_o,T_o,bj,M_o,E_o,C_o,yh,Ahe,w_o,A_o,vj,L_o,y_o,x_o,xh,Lhe,$_o,k_o,Fj,S_o,R_o,P_o,$h,yhe,B_o,I_o,Tj,N_o,q_o,j_o,kh,xhe,D_o,G_o,Mj,O_o,V_o,X_o,Sh,$he,z_o,Q_o,Ej,W_o,U_o,H_o,Rh,khe,J_o,Y_o,Cj,Z_o,K_o,e1o,Ph,She,o1o,r1o,wj,t1o,a1o,n1o,Bh,Rhe,s1o,l1o,Aj,i1o,d1o,m1o,Ih,Phe,c1o,f1o,Lj,g1o,h1o,u1o,Nh,Bhe,p1o,_1o,yj,b1o,v1o,F1o,qh,Ihe,T1o,M1o,xj,E1o,C1o,w1o,jh,Nhe,A1o,L1o,$j,y1o,x1o,$1o,Dh,qhe,k1o,S1o,kj,R1o,P1o,B1o,Gh,jhe,I1o,N1o,Sj,q1o,j1o,D1o,Oh,Dhe,G1o,O1o,Rj,V1o,X1o,z1o,Vh,Ghe,Q1o,W1o,Pj,U1o,H1o,J1o,Xh,Ohe,Y1o,Z1o,Bj,K1o,e2o,o2o,zh,Vhe,r2o,t2o,Ij,a2o,n2o,s2o,Qh,Xhe,l2o,i2o,Nj,d2o,m2o,c2o,Wh,zhe,f2o,g2o,qj,h2o,u2o,p2o,Uh,Qhe,_2o,b2o,jj,v2o,F2o,T2o,Hh,Whe,M2o,E2o,Dj,C2o,w2o,A2o,Jh,Uhe,L2o,y2o,Gj,x2o,$2o,k2o,Yh,Hhe,S2o,R2o,Oj,P2o,B2o,I2o,Zh,Jhe,N2o,q2o,Vj,j2o,D2o,G2o,Kh,Yhe,O2o,V2o,Xj,X2o,z2o,Q2o,eu,Zhe,W2o,U2o,zj,H2o,J2o,Y2o,ou,Khe,Z2o,K2o,Qj,ebo,obo,rbo,ru,eue,tbo,abo,Wj,nbo,sbo,lbo,tu,oue,ibo,dbo,Uj,mbo,cbo,fbo,au,rue,gbo,hbo,Hj,ubo,pbo,_bo,nu,tue,bbo,vbo,Jj,Fbo,Tbo,Mbo,su,aue,Ebo,Cbo,Yj,wbo,Abo,Lbo,lu,nue,ybo,xbo,Zj,$bo,kbo,Sbo,iu,sue,Rbo,Pbo,Kj,Bbo,Ibo,Nbo,du,lue,qbo,jbo,eD,Dbo,Gbo,Obo,mu,iue,Vbo,Xbo,oD,zbo,Qbo,Wbo,cu,due,Ubo,Hbo,rD,Jbo,Ybo,Zbo,fu,mue,Kbo,evo,tD,ovo,rvo,tvo,gu,cue,avo,nvo,aD,svo,lvo,ivo,hu,fue,dvo,mvo,nD,cvo,fvo,gvo,uu,gue,hvo,uvo,sD,pvo,_vo,bvo,pu,hue,vvo,Fvo,lD,Tvo,Mvo,Evo,_u,uue,Cvo,wvo,iD,Avo,Lvo,yvo,bu,pue,xvo,$vo,dD,kvo,Svo,Rvo,vu,_ue,Pvo,Bvo,mD,Ivo,Nvo,qvo,Fu,bue,jvo,Dvo,cD,Gvo,Ovo,Vvo,Tu,vue,Xvo,zvo,fD,Qvo,Wvo,Uvo,Mu,Fue,Hvo,Jvo,gD,Yvo,Zvo,Kvo,Eu,Tue,eFo,oFo,hD,rFo,tFo,aFo,Cu,Mue,nFo,sFo,uD,lFo,iFo,dFo,wu,Eue,mFo,cFo,pD,fFo,gFo,hFo,Au,Cue,uFo,pFo,_D,_Fo,bFo,vFo,Lu,wue,FFo,TFo,bD,MFo,EFo,CFo,yu,wFo,xu,$$,AFo,Aue,LFo,Bao,xd,$u,Lue,k$,yFo,yue,xFo,Iao,Ro,S$,$Fo,R$,kFo,vD,SFo,RFo,PFo,P$,BFo,xue,IFo,NFo,qFo,jr,B$,jFo,$ue,DFo,GFo,tn,OFo,kue,VFo,XFo,Sue,zFo,QFo,Rue,WFo,UFo,HFo,k,us,Pue,JFo,YFo,FD,ZFo,KFo,TD,eTo,oTo,rTo,ps,Bue,tTo,aTo,MD,nTo,sTo,ED,lTo,iTo,dTo,_s,Iue,mTo,cTo,CD,fTo,gTo,wD,hTo,uTo,pTo,ku,Nue,_To,bTo,AD,vTo,FTo,TTo,bs,que,MTo,ETo,LD,CTo,wTo,yD,ATo,LTo,yTo,Su,jue,xTo,$To,xD,kTo,STo,RTo,Ru,Due,PTo,BTo,$D,ITo,NTo,qTo,Pu,Gue,jTo,DTo,kD,GTo,OTo,VTo,vs,Oue,XTo,zTo,SD,QTo,WTo,RD,UTo,HTo,JTo,Fs,Vue,YTo,ZTo,PD,KTo,eMo,BD,oMo,rMo,tMo,Ts,Xue,aMo,nMo,ID,sMo,lMo,ND,iMo,dMo,mMo,Bu,zue,cMo,fMo,qD,gMo,hMo,uMo,Iu,Que,pMo,_Mo,jD,bMo,vMo,FMo,Nu,Wue,TMo,MMo,DD,EMo,CMo,wMo,Ms,Uue,AMo,LMo,GD,yMo,xMo,OD,$Mo,kMo,SMo,qu,Hue,RMo,PMo,VD,BMo,IMo,NMo,Es,Jue,qMo,jMo,XD,DMo,GMo,zD,OMo,VMo,XMo,Cs,Yue,zMo,QMo,QD,WMo,UMo,WD,HMo,JMo,YMo,ws,Zue,ZMo,KMo,UD,eEo,oEo,HD,rEo,tEo,aEo,As,Kue,nEo,sEo,JD,lEo,iEo,YD,dEo,mEo,cEo,Ls,epe,fEo,gEo,ZD,hEo,uEo,KD,pEo,_Eo,bEo,ju,ope,vEo,FEo,eG,TEo,MEo,EEo,ys,rpe,CEo,wEo,oG,AEo,LEo,rG,yEo,xEo,$Eo,xs,tpe,kEo,SEo,tG,REo,PEo,aG,BEo,IEo,NEo,$s,ape,qEo,jEo,nG,DEo,GEo,sG,OEo,VEo,XEo,ks,npe,zEo,QEo,lG,WEo,UEo,iG,HEo,JEo,YEo,Ss,spe,ZEo,KEo,dG,e4o,o4o,mG,r4o,t4o,a4o,Rs,lpe,n4o,s4o,cG,l4o,i4o,fG,d4o,m4o,c4o,Ps,ipe,f4o,g4o,gG,h4o,u4o,hG,p4o,_4o,b4o,Du,dpe,v4o,F4o,uG,T4o,M4o,E4o,Gu,mpe,C4o,w4o,pG,A4o,L4o,y4o,Bs,cpe,x4o,$4o,_G,k4o,S4o,bG,R4o,P4o,B4o,Ou,fpe,I4o,N4o,vG,q4o,j4o,D4o,Is,gpe,G4o,O4o,FG,V4o,X4o,TG,z4o,Q4o,W4o,Ns,hpe,U4o,H4o,MG,J4o,Y4o,EG,Z4o,K4o,eCo,qs,upe,oCo,rCo,CG,tCo,aCo,wG,nCo,sCo,lCo,Vu,ppe,iCo,dCo,AG,mCo,cCo,fCo,Xu,_pe,gCo,hCo,LG,uCo,pCo,_Co,js,bpe,bCo,vCo,yG,FCo,TCo,xG,MCo,ECo,CCo,Ds,vpe,wCo,ACo,$G,LCo,yCo,kG,xCo,$Co,kCo,Gs,Fpe,SCo,RCo,SG,PCo,BCo,RG,ICo,NCo,qCo,zu,Tpe,jCo,DCo,PG,GCo,OCo,VCo,Os,Mpe,XCo,zCo,BG,QCo,WCo,IG,UCo,HCo,JCo,Vs,Epe,YCo,ZCo,NG,KCo,e3o,qG,o3o,r3o,t3o,Xs,Cpe,a3o,n3o,jG,s3o,l3o,DG,i3o,d3o,m3o,zs,wpe,c3o,f3o,GG,g3o,h3o,OG,u3o,p3o,_3o,Qs,Ape,b3o,v3o,VG,F3o,T3o,XG,M3o,E3o,C3o,Ws,Lpe,w3o,A3o,zG,L3o,y3o,QG,x3o,$3o,k3o,Us,ype,S3o,R3o,WG,P3o,B3o,UG,I3o,N3o,q3o,Hs,xpe,j3o,D3o,HG,G3o,O3o,JG,V3o,X3o,z3o,Js,$pe,Q3o,W3o,YG,U3o,H3o,ZG,J3o,Y3o,Z3o,Qu,kpe,K3o,e5o,KG,o5o,r5o,t5o,Ys,Spe,a5o,n5o,eO,s5o,l5o,oO,i5o,d5o,m5o,Wu,Rpe,c5o,f5o,rO,g5o,h5o,u5o,Uu,Ppe,p5o,_5o,tO,b5o,v5o,F5o,Zs,Bpe,T5o,M5o,aO,E5o,C5o,nO,w5o,A5o,L5o,Ks,Ipe,y5o,x5o,sO,$5o,k5o,lO,S5o,R5o,P5o,el,Npe,B5o,I5o,iO,N5o,q5o,dO,j5o,D5o,G5o,Hu,qpe,O5o,V5o,mO,X5o,z5o,Q5o,ol,jpe,W5o,U5o,cO,H5o,J5o,fO,Y5o,Z5o,K5o,rl,Dpe,e0o,o0o,gO,r0o,t0o,hO,a0o,n0o,s0o,tl,Gpe,l0o,i0o,uO,d0o,m0o,pO,c0o,f0o,g0o,al,Ope,h0o,u0o,_O,p0o,_0o,bO,b0o,v0o,F0o,nl,Vpe,T0o,M0o,vO,E0o,C0o,FO,w0o,A0o,L0o,sl,Xpe,y0o,x0o,TO,$0o,k0o,MO,S0o,R0o,P0o,ll,zpe,B0o,I0o,EO,N0o,q0o,CO,j0o,D0o,G0o,il,Qpe,O0o,V0o,wO,X0o,z0o,AO,Q0o,W0o,U0o,Ju,Wpe,H0o,J0o,LO,Y0o,Z0o,K0o,dl,Upe,ewo,owo,yO,rwo,two,xO,awo,nwo,swo,ml,Hpe,lwo,iwo,$O,dwo,mwo,kO,cwo,fwo,gwo,cl,Jpe,hwo,uwo,SO,pwo,_wo,RO,bwo,vwo,Fwo,Yu,Ype,Two,Mwo,PO,Ewo,Cwo,wwo,Zu,Zpe,Awo,Lwo,BO,ywo,xwo,$wo,Ku,Kpe,kwo,Swo,IO,Rwo,Pwo,Bwo,ep,e_e,Iwo,Nwo,NO,qwo,jwo,Dwo,fl,o_e,Gwo,Owo,qO,Vwo,Xwo,jO,zwo,Qwo,Wwo,op,r_e,Uwo,Hwo,DO,Jwo,Ywo,Zwo,gl,t_e,Kwo,eAo,GO,oAo,rAo,OO,tAo,aAo,nAo,hl,a_e,sAo,lAo,VO,iAo,dAo,XO,mAo,cAo,fAo,ul,n_e,gAo,hAo,zO,uAo,pAo,QO,_Ao,bAo,vAo,pl,s_e,FAo,TAo,WO,MAo,EAo,UO,CAo,wAo,AAo,_l,l_e,LAo,yAo,HO,xAo,$Ao,JO,kAo,SAo,RAo,bl,i_e,PAo,BAo,YO,IAo,NAo,ZO,qAo,jAo,DAo,rp,d_e,GAo,OAo,KO,VAo,XAo,zAo,tp,m_e,QAo,WAo,eV,UAo,HAo,JAo,vl,c_e,YAo,ZAo,oV,KAo,e6o,rV,o6o,r6o,t6o,Fl,f_e,a6o,n6o,tV,s6o,l6o,aV,i6o,d6o,m6o,Tl,g_e,c6o,f6o,nV,g6o,h6o,sV,u6o,p6o,_6o,ap,h_e,b6o,v6o,lV,F6o,T6o,M6o,np,u_e,E6o,C6o,iV,w6o,A6o,L6o,sp,p_e,y6o,x6o,dV,$6o,k6o,S6o,Ml,__e,R6o,P6o,mV,B6o,I6o,cV,N6o,q6o,j6o,El,b_e,D6o,G6o,fV,O6o,V6o,gV,X6o,z6o,Q6o,lp,v_e,W6o,U6o,hV,H6o,J6o,Y6o,ip,F_e,Z6o,K6o,uV,e7o,o7o,r7o,dp,T_e,t7o,a7o,pV,n7o,s7o,l7o,mp,M_e,i7o,d7o,_V,m7o,c7o,f7o,Cl,E_e,g7o,h7o,bV,u7o,p7o,vV,_7o,b7o,v7o,wl,C_e,F7o,T7o,FV,M7o,E7o,TV,C7o,w7o,A7o,cp,w_e,L7o,y7o,MV,x7o,$7o,k7o,fp,A_e,S7o,R7o,EV,P7o,B7o,I7o,Al,L_e,N7o,q7o,CV,j7o,D7o,wV,G7o,O7o,V7o,Ll,y_e,X7o,z7o,AV,Q7o,W7o,LV,U7o,H7o,J7o,yl,x_e,Y7o,Z7o,yV,K7o,e8o,xV,o8o,r8o,t8o,xl,$_e,a8o,n8o,$V,s8o,l8o,kV,i8o,d8o,m8o,gp,c8o,hp,I$,f8o,k_e,g8o,Nao,$d,up,S_e,N$,h8o,R_e,u8o,qao,Po,q$,p8o,j$,_8o,SV,b8o,v8o,F8o,D$,T8o,P_e,M8o,E8o,C8o,Ye,G$,w8o,B_e,A8o,L8o,an,y8o,I_e,x8o,$8o,N_e,k8o,S8o,q_e,R8o,P8o,B8o,z,pp,j_e,I8o,N8o,RV,q8o,j8o,D8o,_p,D_e,G8o,O8o,PV,V8o,X8o,z8o,bp,G_e,Q8o,W8o,BV,U8o,H8o,J8o,vp,O_e,Y8o,Z8o,IV,K8o,eLo,oLo,Fp,V_e,rLo,tLo,NV,aLo,nLo,sLo,Tp,X_e,lLo,iLo,qV,dLo,mLo,cLo,Mp,z_e,fLo,gLo,jV,hLo,uLo,pLo,Ep,Q_e,_Lo,bLo,DV,vLo,FLo,TLo,Cp,W_e,MLo,ELo,GV,CLo,wLo,ALo,wp,U_e,LLo,yLo,OV,xLo,$Lo,kLo,Ap,H_e,SLo,RLo,VV,PLo,BLo,ILo,Lp,J_e,NLo,qLo,XV,jLo,DLo,GLo,yp,Y_e,OLo,VLo,zV,XLo,zLo,QLo,xp,Z_e,WLo,ULo,QV,HLo,JLo,YLo,$p,K_e,ZLo,KLo,WV,eyo,oyo,ryo,kp,e1e,tyo,ayo,UV,nyo,syo,lyo,Sp,o1e,iyo,dyo,HV,myo,cyo,fyo,Rp,r1e,gyo,hyo,JV,uyo,pyo,_yo,Pp,t1e,byo,vyo,YV,Fyo,Tyo,Myo,Bp,a1e,Eyo,Cyo,ZV,wyo,Ayo,Lyo,Ip,n1e,yyo,xyo,KV,$yo,kyo,Syo,Np,s1e,Ryo,Pyo,eX,Byo,Iyo,Nyo,qp,l1e,qyo,jyo,oX,Dyo,Gyo,Oyo,jp,i1e,Vyo,Xyo,rX,zyo,Qyo,Wyo,Dp,d1e,Uyo,Hyo,tX,Jyo,Yyo,Zyo,Gp,m1e,Kyo,e9o,aX,o9o,r9o,t9o,Op,c1e,a9o,n9o,nX,s9o,l9o,i9o,Vp,f1e,d9o,m9o,sX,c9o,f9o,g9o,Xp,g1e,h9o,u9o,lX,p9o,_9o,b9o,zp,h1e,v9o,F9o,iX,T9o,M9o,E9o,Qp,u1e,C9o,w9o,dX,A9o,L9o,y9o,Wp,p1e,x9o,$9o,mX,k9o,S9o,R9o,Up,_1e,P9o,B9o,cX,I9o,N9o,q9o,Hp,b1e,j9o,D9o,fX,G9o,O9o,V9o,Jp,v1e,X9o,z9o,gX,Q9o,W9o,U9o,Yp,F1e,H9o,J9o,hX,Y9o,Z9o,K9o,Zp,T1e,exo,oxo,uX,rxo,txo,axo,Kp,M1e,nxo,sxo,pX,lxo,ixo,dxo,e_,E1e,mxo,cxo,_X,fxo,gxo,hxo,o_,C1e,uxo,pxo,bX,_xo,bxo,vxo,r_,w1e,Fxo,Txo,vX,Mxo,Exo,Cxo,t_,A1e,wxo,Axo,FX,Lxo,yxo,xxo,a_,L1e,$xo,kxo,TX,Sxo,Rxo,Pxo,n_,y1e,Bxo,Ixo,MX,Nxo,qxo,jxo,s_,x1e,Dxo,Gxo,EX,Oxo,Vxo,Xxo,l_,zxo,i_,Qxo,d_,O$,Wxo,$1e,Uxo,jao,kd,m_,k1e,V$,Hxo,S1e,Jxo,Dao,Bo,X$,Yxo,z$,Zxo,CX,Kxo,e$o,o$o,Q$,r$o,R1e,t$o,a$o,n$o,Ze,W$,s$o,P1e,l$o,i$o,Sd,d$o,B1e,m$o,c$o,I1e,f$o,g$o,h$o,se,c_,N1e,u$o,p$o,wX,_$o,b$o,v$o,f_,q1e,F$o,T$o,AX,M$o,E$o,C$o,g_,j1e,w$o,A$o,LX,L$o,y$o,x$o,h_,D1e,$$o,k$o,yX,S$o,R$o,P$o,u_,G1e,B$o,I$o,xX,N$o,q$o,j$o,p_,O1e,D$o,G$o,$X,O$o,V$o,X$o,__,V1e,z$o,Q$o,kX,W$o,U$o,H$o,b_,X1e,J$o,Y$o,SX,Z$o,K$o,eko,v_,z1e,oko,rko,RX,tko,ako,nko,F_,Q1e,sko,lko,PX,iko,dko,mko,T_,W1e,cko,fko,BX,gko,hko,uko,M_,U1e,pko,_ko,IX,bko,vko,Fko,E_,H1e,Tko,Mko,NX,Eko,Cko,wko,C_,J1e,Ako,Lko,qX,yko,xko,$ko,w_,Y1e,kko,Sko,jX,Rko,Pko,Bko,A_,Z1e,Iko,Nko,DX,qko,jko,Dko,L_,K1e,Gko,Oko,GX,Vko,Xko,zko,y_,e2e,Qko,Wko,OX,Uko,Hko,Jko,x_,o2e,Yko,Zko,VX,Kko,eSo,oSo,$_,r2e,rSo,tSo,XX,aSo,nSo,sSo,k_,t2e,lSo,iSo,zX,dSo,mSo,cSo,S_,a2e,fSo,gSo,QX,hSo,uSo,pSo,R_,n2e,_So,bSo,WX,vSo,FSo,TSo,P_,MSo,B_,ESo,I_,U$,CSo,s2e,wSo,Gao,Rd,N_,l2e,H$,ASo,i2e,LSo,Oao,Io,J$,ySo,Pd,xSo,UX,$So,kSo,HX,SSo,RSo,PSo,Y$,BSo,d2e,ISo,NSo,qSo,Mt,Z$,jSo,m2e,DSo,GSo,Bd,OSo,c2e,VSo,XSo,JX,zSo,QSo,WSo,q_,USo,Ke,K$,HSo,f2e,JSo,YSo,nn,ZSo,g2e,KSo,eRo,h2e,oRo,rRo,u2e,tRo,aRo,nRo,y,j_,p2e,sRo,lRo,YX,iRo,dRo,mRo,D_,_2e,cRo,fRo,ZX,gRo,hRo,uRo,G_,b2e,pRo,_Ro,KX,bRo,vRo,FRo,O_,v2e,TRo,MRo,ez,ERo,CRo,wRo,V_,F2e,ARo,LRo,oz,yRo,xRo,$Ro,X_,T2e,kRo,SRo,rz,RRo,PRo,BRo,z_,M2e,IRo,NRo,tz,qRo,jRo,DRo,Q_,E2e,GRo,ORo,az,VRo,XRo,zRo,W_,C2e,QRo,WRo,nz,URo,HRo,JRo,U_,w2e,YRo,ZRo,sz,KRo,ePo,oPo,H_,A2e,rPo,tPo,lz,aPo,nPo,sPo,J_,L2e,lPo,iPo,iz,dPo,mPo,cPo,Y_,y2e,fPo,gPo,dz,hPo,uPo,pPo,Z_,x2e,_Po,bPo,mz,vPo,FPo,TPo,K_,$2e,MPo,EPo,cz,CPo,wPo,APo,e1,k2e,LPo,yPo,fz,xPo,$Po,kPo,o1,S2e,SPo,RPo,gz,PPo,BPo,IPo,r1,R2e,NPo,qPo,hz,jPo,DPo,GPo,t1,P2e,OPo,VPo,uz,XPo,zPo,QPo,a1,B2e,WPo,UPo,pz,HPo,JPo,YPo,n1,I2e,ZPo,KPo,_z,eBo,oBo,rBo,s1,N2e,tBo,aBo,bz,nBo,sBo,lBo,l1,q2e,iBo,dBo,vz,mBo,cBo,fBo,i1,j2e,gBo,hBo,Fz,uBo,pBo,_Bo,d1,D2e,bBo,vBo,Tz,FBo,TBo,MBo,m1,G2e,EBo,CBo,Mz,wBo,ABo,LBo,c1,O2e,yBo,xBo,Ez,$Bo,kBo,SBo,f1,V2e,RBo,PBo,Cz,BBo,IBo,NBo,g1,X2e,qBo,jBo,wz,DBo,GBo,OBo,h1,z2e,VBo,XBo,Az,zBo,QBo,WBo,u1,Q2e,UBo,HBo,Lz,JBo,YBo,ZBo,p1,W2e,KBo,eIo,yz,oIo,rIo,tIo,_1,U2e,aIo,nIo,xz,sIo,lIo,iIo,b1,H2e,dIo,mIo,$z,cIo,fIo,gIo,v1,J2e,hIo,uIo,kz,pIo,_Io,bIo,F1,Y2e,vIo,FIo,Sz,TIo,MIo,EIo,T1,Z2e,CIo,wIo,Rz,AIo,LIo,yIo,M1,K2e,xIo,$Io,Pz,kIo,SIo,RIo,E1,ebe,PIo,BIo,Bz,IIo,NIo,qIo,C1,obe,jIo,DIo,Iz,GIo,OIo,VIo,$l,rbe,XIo,zIo,Nz,QIo,WIo,qz,UIo,HIo,JIo,w1,tbe,YIo,ZIo,jz,KIo,eNo,oNo,A1,abe,rNo,tNo,Dz,aNo,nNo,sNo,L1,nbe,lNo,iNo,Gz,dNo,mNo,cNo,y1,sbe,fNo,gNo,Oz,hNo,uNo,pNo,x1,lbe,_No,bNo,Vz,vNo,FNo,TNo,$1,ibe,MNo,ENo,Xz,CNo,wNo,ANo,k1,dbe,LNo,yNo,zz,xNo,$No,kNo,S1,mbe,SNo,RNo,Qz,PNo,BNo,INo,R1,cbe,NNo,qNo,Wz,jNo,DNo,GNo,P1,fbe,ONo,VNo,Uz,XNo,zNo,QNo,B1,gbe,WNo,UNo,Hz,HNo,JNo,YNo,I1,hbe,ZNo,KNo,Jz,eqo,oqo,rqo,N1,ube,tqo,aqo,Yz,nqo,sqo,lqo,q1,pbe,iqo,dqo,Zz,mqo,cqo,fqo,j1,_be,gqo,hqo,Kz,uqo,pqo,_qo,D1,bbe,bqo,vqo,eQ,Fqo,Tqo,Mqo,G1,vbe,Eqo,Cqo,oQ,wqo,Aqo,Lqo,O1,Fbe,yqo,xqo,rQ,$qo,kqo,Sqo,V1,Tbe,Rqo,Pqo,tQ,Bqo,Iqo,Nqo,X1,Mbe,qqo,jqo,aQ,Dqo,Gqo,Oqo,z1,Ebe,Vqo,Xqo,nQ,zqo,Qqo,Wqo,Q1,Cbe,Uqo,Hqo,sQ,Jqo,Yqo,Zqo,W1,wbe,Kqo,ejo,lQ,ojo,rjo,tjo,U1,Abe,ajo,njo,iQ,sjo,ljo,ijo,H1,Lbe,djo,mjo,dQ,cjo,fjo,gjo,J1,ybe,hjo,ujo,mQ,pjo,_jo,bjo,Y1,xbe,vjo,Fjo,cQ,Tjo,Mjo,Ejo,Z1,$be,Cjo,wjo,fQ,Ajo,Ljo,yjo,K1,kbe,xjo,$jo,gQ,kjo,Sjo,Rjo,e2,Sbe,Pjo,Bjo,hQ,Ijo,Njo,qjo,o2,Rbe,jjo,Djo,uQ,Gjo,Ojo,Vjo,r2,Pbe,Xjo,zjo,pQ,Qjo,Wjo,Ujo,t2,Bbe,Hjo,Jjo,_Q,Yjo,Zjo,Kjo,a2,Ibe,eDo,oDo,bQ,rDo,tDo,aDo,n2,Nbe,nDo,sDo,vQ,lDo,iDo,dDo,s2,qbe,mDo,cDo,FQ,fDo,gDo,hDo,l2,jbe,uDo,pDo,TQ,_Do,bDo,vDo,i2,Dbe,FDo,TDo,MQ,MDo,EDo,CDo,d2,Gbe,wDo,ADo,EQ,LDo,yDo,xDo,m2,Obe,$Do,kDo,CQ,SDo,RDo,PDo,c2,Vbe,BDo,IDo,wQ,NDo,qDo,jDo,f2,Xbe,DDo,GDo,AQ,ODo,VDo,XDo,g2,zbe,zDo,QDo,LQ,WDo,UDo,HDo,h2,Qbe,JDo,YDo,yQ,ZDo,KDo,eGo,u2,Wbe,oGo,rGo,xQ,tGo,aGo,nGo,p2,Ube,sGo,lGo,$Q,iGo,dGo,mGo,_2,Hbe,cGo,fGo,kQ,gGo,hGo,uGo,b2,Jbe,pGo,_Go,SQ,bGo,vGo,FGo,v2,Ybe,TGo,MGo,RQ,EGo,CGo,wGo,F2,Zbe,AGo,LGo,PQ,yGo,xGo,$Go,T2,Kbe,kGo,SGo,BQ,RGo,PGo,BGo,M2,eve,IGo,NGo,IQ,qGo,jGo,DGo,E2,ove,GGo,OGo,NQ,VGo,XGo,zGo,C2,rve,QGo,WGo,qQ,UGo,HGo,JGo,w2,tve,YGo,ZGo,jQ,KGo,eOo,oOo,A2,ave,rOo,tOo,DQ,aOo,nOo,sOo,L2,nve,lOo,iOo,GQ,dOo,mOo,cOo,y2,sve,fOo,gOo,OQ,hOo,uOo,pOo,x2,lve,_Oo,bOo,VQ,vOo,FOo,TOo,$2,ive,MOo,EOo,XQ,COo,wOo,AOo,k2,dve,LOo,yOo,zQ,xOo,$Oo,kOo,S2,mve,SOo,ROo,QQ,POo,BOo,IOo,R2,cve,NOo,qOo,WQ,jOo,DOo,GOo,P2,fve,OOo,VOo,UQ,XOo,zOo,QOo,B2,gve,WOo,UOo,HQ,HOo,JOo,YOo,I2,hve,ZOo,KOo,JQ,eVo,oVo,rVo,N2,uve,tVo,aVo,YQ,nVo,sVo,lVo,q2,pve,iVo,dVo,ZQ,mVo,cVo,fVo,j2,_ve,gVo,hVo,KQ,uVo,pVo,_Vo,D2,bve,bVo,vVo,eW,FVo,TVo,MVo,G2,vve,EVo,CVo,oW,wVo,AVo,LVo,O2,Fve,yVo,xVo,rW,$Vo,kVo,SVo,V2,Tve,RVo,PVo,tW,BVo,IVo,NVo,X2,Mve,qVo,jVo,aW,DVo,GVo,OVo,z2,Eve,VVo,XVo,nW,zVo,QVo,WVo,Q2,Cve,UVo,HVo,sW,JVo,YVo,ZVo,W2,wve,KVo,eXo,lW,oXo,rXo,tXo,U2,Ave,aXo,nXo,iW,sXo,lXo,iXo,H2,Lve,dXo,mXo,dW,cXo,fXo,gXo,J2,yve,hXo,uXo,mW,pXo,_Xo,bXo,Y2,xve,vXo,FXo,cW,TXo,MXo,EXo,Z2,$ve,CXo,wXo,fW,AXo,LXo,yXo,K2,kve,xXo,$Xo,gW,kXo,SXo,RXo,eb,Sve,PXo,BXo,hW,IXo,NXo,qXo,ob,Rve,jXo,DXo,uW,GXo,OXo,VXo,rb,Pve,XXo,zXo,pW,QXo,WXo,UXo,tb,Bve,HXo,JXo,_W,YXo,ZXo,KXo,ab,Ive,ezo,ozo,bW,rzo,tzo,azo,nb,Nve,nzo,szo,vW,lzo,izo,dzo,sb,qve,mzo,czo,FW,fzo,gzo,hzo,lb,uzo,jve,pzo,_zo,Dve,bzo,vzo,ib,Vao,Id,db,Gve,ek,Fzo,Ove,Tzo,Xao,No,ok,Mzo,Nd,Ezo,TW,Czo,wzo,MW,Azo,Lzo,yzo,rk,xzo,Vve,$zo,kzo,Szo,Et,tk,Rzo,Xve,Pzo,Bzo,qd,Izo,zve,Nzo,qzo,EW,jzo,Dzo,Gzo,mb,Ozo,eo,ak,Vzo,Qve,Xzo,zzo,sn,Qzo,Wve,Wzo,Uzo,Uve,Hzo,Jzo,Hve,Yzo,Zzo,Kzo,G,cb,Jve,eQo,oQo,CW,rQo,tQo,aQo,fb,Yve,nQo,sQo,wW,lQo,iQo,dQo,gb,Zve,mQo,cQo,AW,fQo,gQo,hQo,hb,Kve,uQo,pQo,LW,_Qo,bQo,vQo,ub,eFe,FQo,TQo,yW,MQo,EQo,CQo,pb,oFe,wQo,AQo,xW,LQo,yQo,xQo,_b,rFe,$Qo,kQo,$W,SQo,RQo,PQo,bb,tFe,BQo,IQo,kW,NQo,qQo,jQo,vb,aFe,DQo,GQo,SW,OQo,VQo,XQo,Fb,nFe,zQo,QQo,RW,WQo,UQo,HQo,Tb,sFe,JQo,YQo,PW,ZQo,KQo,eWo,Mb,lFe,oWo,rWo,BW,tWo,aWo,nWo,Eb,iFe,sWo,lWo,IW,iWo,dWo,mWo,Cb,dFe,cWo,fWo,NW,gWo,hWo,uWo,wb,mFe,pWo,_Wo,qW,bWo,vWo,FWo,Ab,cFe,TWo,MWo,jW,EWo,CWo,wWo,Lb,fFe,AWo,LWo,DW,yWo,xWo,$Wo,yb,gFe,kWo,SWo,GW,RWo,PWo,BWo,xb,hFe,IWo,NWo,OW,qWo,jWo,DWo,$b,uFe,GWo,OWo,VW,VWo,XWo,zWo,kb,pFe,QWo,WWo,XW,UWo,HWo,JWo,Sb,_Fe,YWo,ZWo,zW,KWo,eUo,oUo,Rb,bFe,rUo,tUo,QW,aUo,nUo,sUo,Pb,vFe,lUo,iUo,WW,dUo,mUo,cUo,Bb,FFe,fUo,gUo,UW,hUo,uUo,pUo,Ib,TFe,_Uo,bUo,HW,vUo,FUo,TUo,Nb,MFe,MUo,EUo,JW,CUo,wUo,AUo,qb,EFe,LUo,yUo,YW,xUo,$Uo,kUo,jb,CFe,SUo,RUo,ZW,PUo,BUo,IUo,Db,wFe,NUo,qUo,KW,jUo,DUo,GUo,Gb,AFe,OUo,VUo,eU,XUo,zUo,QUo,Ob,LFe,WUo,UUo,oU,HUo,JUo,YUo,Vb,yFe,ZUo,KUo,rU,eHo,oHo,rHo,Xb,xFe,tHo,aHo,tU,nHo,sHo,lHo,zb,$Fe,iHo,dHo,aU,mHo,cHo,fHo,Qb,kFe,gHo,hHo,nU,uHo,pHo,_Ho,Wb,SFe,bHo,vHo,sU,FHo,THo,MHo,Ub,RFe,EHo,CHo,lU,wHo,AHo,LHo,Hb,PFe,yHo,xHo,iU,$Ho,kHo,SHo,Jb,BFe,RHo,PHo,dU,BHo,IHo,NHo,Yb,IFe,qHo,jHo,mU,DHo,GHo,OHo,Zb,NFe,VHo,XHo,cU,zHo,QHo,WHo,Kb,qFe,UHo,HHo,fU,JHo,YHo,ZHo,ev,jFe,KHo,eJo,gU,oJo,rJo,tJo,ov,DFe,aJo,nJo,hU,sJo,lJo,iJo,rv,GFe,dJo,mJo,uU,cJo,fJo,gJo,tv,OFe,hJo,uJo,pU,pJo,_Jo,bJo,av,VFe,vJo,FJo,_U,TJo,MJo,EJo,nv,XFe,CJo,wJo,bU,AJo,LJo,yJo,sv,xJo,zFe,$Jo,kJo,QFe,SJo,RJo,lv,zao,jd,iv,WFe,nk,PJo,UFe,BJo,Qao,qo,sk,IJo,Dd,NJo,vU,qJo,jJo,FU,DJo,GJo,OJo,lk,VJo,HFe,XJo,zJo,QJo,Ct,ik,WJo,JFe,UJo,HJo,Gd,JJo,YFe,YJo,ZJo,TU,KJo,eYo,oYo,dv,rYo,oo,dk,tYo,ZFe,aYo,nYo,ln,sYo,KFe,lYo,iYo,eTe,dYo,mYo,oTe,cYo,fYo,gYo,W,mv,rTe,hYo,uYo,MU,pYo,_Yo,bYo,cv,tTe,vYo,FYo,EU,TYo,MYo,EYo,fv,aTe,CYo,wYo,CU,AYo,LYo,yYo,gv,nTe,xYo,$Yo,wU,kYo,SYo,RYo,hv,sTe,PYo,BYo,AU,IYo,NYo,qYo,uv,lTe,jYo,DYo,LU,GYo,OYo,VYo,pv,iTe,XYo,zYo,yU,QYo,WYo,UYo,_v,dTe,HYo,JYo,xU,YYo,ZYo,KYo,bv,mTe,eZo,oZo,$U,rZo,tZo,aZo,vv,cTe,nZo,sZo,kU,lZo,iZo,dZo,Fv,fTe,mZo,cZo,SU,fZo,gZo,hZo,Tv,gTe,uZo,pZo,RU,_Zo,bZo,vZo,Mv,hTe,FZo,TZo,PU,MZo,EZo,CZo,Ev,uTe,wZo,AZo,BU,LZo,yZo,xZo,Cv,pTe,$Zo,kZo,IU,SZo,RZo,PZo,wv,_Te,BZo,IZo,NU,NZo,qZo,jZo,Av,bTe,DZo,GZo,qU,OZo,VZo,XZo,Lv,vTe,zZo,QZo,jU,WZo,UZo,HZo,yv,FTe,JZo,YZo,DU,ZZo,KZo,eKo,xv,TTe,oKo,rKo,GU,tKo,aKo,nKo,$v,MTe,sKo,lKo,OU,iKo,dKo,mKo,kv,ETe,cKo,fKo,VU,gKo,hKo,uKo,Sv,CTe,pKo,_Ko,XU,bKo,vKo,FKo,Rv,wTe,TKo,MKo,zU,EKo,CKo,wKo,Pv,ATe,AKo,LKo,QU,yKo,xKo,$Ko,Bv,LTe,kKo,SKo,WU,RKo,PKo,BKo,Iv,yTe,IKo,NKo,UU,qKo,jKo,DKo,Nv,xTe,GKo,OKo,HU,VKo,XKo,zKo,qv,$Te,QKo,WKo,JU,UKo,HKo,JKo,jv,kTe,YKo,ZKo,YU,KKo,eer,oer,Dv,STe,rer,ter,ZU,aer,ner,ser,Gv,RTe,ler,ier,KU,der,mer,cer,Ov,PTe,fer,ger,eH,her,uer,per,Vv,BTe,_er,ber,oH,ver,Fer,Ter,Xv,ITe,Mer,Eer,rH,Cer,wer,Aer,zv,NTe,Ler,yer,tH,xer,$er,ker,Qv,qTe,Ser,Rer,aH,Per,Ber,Ier,Wv,jTe,Ner,qer,nH,jer,Der,Ger,Uv,DTe,Oer,Ver,sH,Xer,zer,Qer,Hv,GTe,Wer,Uer,lH,Her,Jer,Yer,Jv,OTe,Zer,Ker,iH,eor,oor,ror,Yv,VTe,tor,aor,dH,nor,sor,lor,Zv,XTe,ior,dor,mH,mor,cor,gor,Kv,hor,zTe,uor,por,QTe,_or,bor,eF,Wao,Od,oF,WTe,mk,vor,UTe,For,Uao,jo,ck,Tor,Vd,Mor,cH,Eor,Cor,fH,wor,Aor,Lor,fk,yor,HTe,xor,$or,kor,wt,gk,Sor,JTe,Ror,Por,Xd,Bor,YTe,Ior,Nor,gH,qor,jor,Dor,rF,Gor,ro,hk,Oor,ZTe,Vor,Xor,dn,zor,KTe,Qor,Wor,eMe,Uor,Hor,oMe,Jor,Yor,Zor,uk,tF,rMe,Kor,err,hH,orr,rrr,trr,aF,tMe,arr,nrr,uH,srr,lrr,irr,nF,drr,aMe,mrr,crr,nMe,frr,grr,sF,Hao,zd,lF,sMe,pk,hrr,lMe,urr,Jao,Do,_k,prr,Qd,_rr,pH,brr,vrr,_H,Frr,Trr,Mrr,bk,Err,iMe,Crr,wrr,Arr,At,vk,Lrr,dMe,yrr,xrr,Wd,$rr,mMe,krr,Srr,bH,Rrr,Prr,Brr,iF,Irr,to,Fk,Nrr,cMe,qrr,jrr,mn,Drr,fMe,Grr,Orr,gMe,Vrr,Xrr,hMe,zrr,Qrr,Wrr,Y,dF,uMe,Urr,Hrr,vH,Jrr,Yrr,Zrr,mF,pMe,Krr,etr,FH,otr,rtr,ttr,cF,_Me,atr,ntr,TH,str,ltr,itr,fF,bMe,dtr,mtr,MH,ctr,ftr,gtr,gF,vMe,htr,utr,EH,ptr,_tr,btr,hF,FMe,vtr,Ftr,CH,Ttr,Mtr,Etr,uF,TMe,Ctr,wtr,wH,Atr,Ltr,ytr,pF,MMe,xtr,$tr,AH,ktr,Str,Rtr,_F,EMe,Ptr,Btr,LH,Itr,Ntr,qtr,bF,CMe,jtr,Dtr,yH,Gtr,Otr,Vtr,vF,wMe,Xtr,ztr,xH,Qtr,Wtr,Utr,FF,AMe,Htr,Jtr,$H,Ytr,Ztr,Ktr,TF,LMe,ear,oar,kH,rar,tar,aar,MF,yMe,nar,sar,SH,lar,iar,dar,EF,xMe,mar,car,RH,far,gar,har,CF,$Me,uar,par,PH,_ar,bar,Far,wF,kMe,Tar,Mar,BH,Ear,Car,war,AF,SMe,Aar,Lar,IH,yar,xar,$ar,LF,RMe,kar,Sar,NH,Rar,Par,Bar,yF,PMe,Iar,Nar,qH,qar,jar,Dar,xF,BMe,Gar,Oar,jH,Var,Xar,zar,$F,IMe,Qar,War,DH,Uar,Har,Jar,kF,NMe,Yar,Zar,GH,Kar,enr,onr,SF,qMe,rnr,tnr,OH,anr,nnr,snr,RF,jMe,lnr,inr,VH,dnr,mnr,cnr,PF,DMe,fnr,gnr,XH,hnr,unr,pnr,BF,GMe,_nr,bnr,zH,vnr,Fnr,Tnr,IF,OMe,Mnr,Enr,QH,Cnr,wnr,Anr,NF,VMe,Lnr,ynr,WH,xnr,$nr,knr,qF,XMe,Snr,Rnr,UH,Pnr,Bnr,Inr,jF,zMe,Nnr,qnr,HH,jnr,Dnr,Gnr,DF,QMe,Onr,Vnr,JH,Xnr,znr,Qnr,GF,WMe,Wnr,Unr,YH,Hnr,Jnr,Ynr,OF,UMe,Znr,Knr,ZH,esr,osr,rsr,VF,HMe,tsr,asr,KH,nsr,ssr,lsr,XF,JMe,isr,dsr,YMe,msr,csr,fsr,zF,ZMe,gsr,hsr,eJ,usr,psr,_sr,QF,KMe,bsr,vsr,oJ,Fsr,Tsr,Msr,WF,eEe,Esr,Csr,rJ,wsr,Asr,Lsr,UF,oEe,ysr,xsr,tJ,$sr,ksr,Ssr,HF,Rsr,rEe,Psr,Bsr,tEe,Isr,Nsr,JF,Yao,Ud,YF,aEe,Tk,qsr,nEe,jsr,Zao,Go,Mk,Dsr,Hd,Gsr,aJ,Osr,Vsr,nJ,Xsr,zsr,Qsr,Ek,Wsr,sEe,Usr,Hsr,Jsr,Lt,Ck,Ysr,lEe,Zsr,Ksr,Jd,elr,iEe,olr,rlr,sJ,tlr,alr,nlr,ZF,slr,ao,wk,llr,dEe,ilr,dlr,cn,mlr,mEe,clr,flr,cEe,glr,hlr,fEe,ulr,plr,_lr,he,KF,gEe,blr,vlr,lJ,Flr,Tlr,Mlr,eT,hEe,Elr,Clr,iJ,wlr,Alr,Llr,oT,uEe,ylr,xlr,dJ,$lr,klr,Slr,rT,pEe,Rlr,Plr,mJ,Blr,Ilr,Nlr,tT,_Ee,qlr,jlr,cJ,Dlr,Glr,Olr,aT,bEe,Vlr,Xlr,fJ,zlr,Qlr,Wlr,nT,vEe,Ulr,Hlr,gJ,Jlr,Ylr,Zlr,sT,FEe,Klr,eir,hJ,oir,rir,tir,lT,TEe,air,nir,uJ,sir,lir,iir,iT,MEe,dir,mir,pJ,cir,fir,gir,dT,EEe,hir,uir,_J,pir,_ir,bir,mT,CEe,vir,Fir,bJ,Tir,Mir,Eir,cT,wEe,Cir,wir,vJ,Air,Lir,yir,fT,AEe,xir,$ir,FJ,kir,Sir,Rir,gT,LEe,Pir,Bir,TJ,Iir,Nir,qir,hT,yEe,jir,Dir,MJ,Gir,Oir,Vir,uT,xEe,Xir,zir,EJ,Qir,Wir,Uir,pT,$Ee,Hir,Jir,CJ,Yir,Zir,Kir,_T,kEe,edr,odr,wJ,rdr,tdr,adr,bT,SEe,ndr,sdr,AJ,ldr,idr,ddr,vT,mdr,REe,cdr,fdr,PEe,gdr,hdr,FT,Kao,Yd,TT,BEe,Ak,udr,IEe,pdr,eno,Oo,Lk,_dr,Zd,bdr,LJ,vdr,Fdr,yJ,Tdr,Mdr,Edr,yk,Cdr,NEe,wdr,Adr,Ldr,yt,xk,ydr,qEe,xdr,$dr,Kd,kdr,jEe,Sdr,Rdr,xJ,Pdr,Bdr,Idr,MT,Ndr,no,$k,qdr,DEe,jdr,Ddr,fn,Gdr,GEe,Odr,Vdr,OEe,Xdr,zdr,VEe,Qdr,Wdr,Udr,I,ET,XEe,Hdr,Jdr,$J,Ydr,Zdr,Kdr,CT,zEe,emr,omr,kJ,rmr,tmr,amr,wT,QEe,nmr,smr,SJ,lmr,imr,dmr,AT,WEe,mmr,cmr,RJ,fmr,gmr,hmr,LT,UEe,umr,pmr,PJ,_mr,bmr,vmr,yT,HEe,Fmr,Tmr,BJ,Mmr,Emr,Cmr,xT,JEe,wmr,Amr,IJ,Lmr,ymr,xmr,$T,YEe,$mr,kmr,NJ,Smr,Rmr,Pmr,kT,ZEe,Bmr,Imr,qJ,Nmr,qmr,jmr,ST,KEe,Dmr,Gmr,jJ,Omr,Vmr,Xmr,RT,e4e,zmr,Qmr,DJ,Wmr,Umr,Hmr,PT,o4e,Jmr,Ymr,GJ,Zmr,Kmr,ecr,BT,r4e,ocr,rcr,OJ,tcr,acr,ncr,IT,t4e,scr,lcr,VJ,icr,dcr,mcr,NT,a4e,ccr,fcr,XJ,gcr,hcr,ucr,qT,n4e,pcr,_cr,zJ,bcr,vcr,Fcr,jT,s4e,Tcr,Mcr,QJ,Ecr,Ccr,wcr,DT,l4e,Acr,Lcr,WJ,ycr,xcr,$cr,GT,i4e,kcr,Scr,UJ,Rcr,Pcr,Bcr,OT,d4e,Icr,Ncr,HJ,qcr,jcr,Dcr,VT,m4e,Gcr,Ocr,JJ,Vcr,Xcr,zcr,XT,c4e,Qcr,Wcr,YJ,Ucr,Hcr,Jcr,zT,f4e,Ycr,Zcr,ZJ,Kcr,efr,ofr,QT,g4e,rfr,tfr,KJ,afr,nfr,sfr,WT,h4e,lfr,ifr,eY,dfr,mfr,cfr,UT,u4e,ffr,gfr,oY,hfr,ufr,pfr,HT,p4e,_fr,bfr,rY,vfr,Ffr,Tfr,JT,_4e,Mfr,Efr,tY,Cfr,wfr,Afr,YT,b4e,Lfr,yfr,aY,xfr,$fr,kfr,ZT,v4e,Sfr,Rfr,nY,Pfr,Bfr,Ifr,KT,F4e,Nfr,qfr,sY,jfr,Dfr,Gfr,eM,T4e,Ofr,Vfr,lY,Xfr,zfr,Qfr,oM,M4e,Wfr,Ufr,iY,Hfr,Jfr,Yfr,rM,E4e,Zfr,Kfr,dY,egr,ogr,rgr,tM,C4e,tgr,agr,mY,ngr,sgr,lgr,aM,w4e,igr,dgr,cY,mgr,cgr,fgr,nM,A4e,ggr,hgr,fY,ugr,pgr,_gr,sM,L4e,bgr,vgr,gY,Fgr,Tgr,Mgr,lM,y4e,Egr,Cgr,hY,wgr,Agr,Lgr,iM,x4e,ygr,xgr,uY,$gr,kgr,Sgr,dM,$4e,Rgr,Pgr,pY,Bgr,Igr,Ngr,mM,k4e,qgr,jgr,_Y,Dgr,Ggr,Ogr,cM,S4e,Vgr,Xgr,bY,zgr,Qgr,Wgr,fM,R4e,Ugr,Hgr,vY,Jgr,Ygr,Zgr,gM,P4e,Kgr,ehr,FY,ohr,rhr,thr,hM,B4e,ahr,nhr,TY,shr,lhr,ihr,uM,I4e,dhr,mhr,MY,chr,fhr,ghr,pM,N4e,hhr,uhr,EY,phr,_hr,bhr,_M,q4e,vhr,Fhr,CY,Thr,Mhr,Ehr,bM,j4e,Chr,whr,wY,Ahr,Lhr,yhr,vM,D4e,xhr,$hr,AY,khr,Shr,Rhr,FM,G4e,Phr,Bhr,LY,Ihr,Nhr,qhr,TM,O4e,jhr,Dhr,yY,Ghr,Ohr,Vhr,MM,V4e,Xhr,zhr,xY,Qhr,Whr,Uhr,EM,X4e,Hhr,Jhr,$Y,Yhr,Zhr,Khr,CM,z4e,eur,our,kY,rur,tur,aur,wM,Q4e,nur,sur,SY,lur,iur,dur,AM,mur,W4e,cur,fur,U4e,gur,hur,LM,ono,em,yM,H4e,kk,uur,J4e,pur,rno,Vo,Sk,_ur,om,bur,RY,vur,Fur,PY,Tur,Mur,Eur,Rk,Cur,Y4e,wur,Aur,Lur,xt,Pk,yur,Z4e,xur,$ur,rm,kur,K4e,Sur,Rur,BY,Pur,Bur,Iur,xM,Nur,so,Bk,qur,eCe,jur,Dur,gn,Gur,oCe,Our,Vur,rCe,Xur,zur,tCe,Qur,Wur,Uur,K,$M,aCe,Hur,Jur,IY,Yur,Zur,Kur,kM,nCe,epr,opr,NY,rpr,tpr,apr,SM,sCe,npr,spr,qY,lpr,ipr,dpr,RM,lCe,mpr,cpr,jY,fpr,gpr,hpr,PM,iCe,upr,ppr,DY,_pr,bpr,vpr,BM,dCe,Fpr,Tpr,GY,Mpr,Epr,Cpr,IM,mCe,wpr,Apr,OY,Lpr,ypr,xpr,NM,cCe,$pr,kpr,VY,Spr,Rpr,Ppr,qM,fCe,Bpr,Ipr,XY,Npr,qpr,jpr,jM,gCe,Dpr,Gpr,zY,Opr,Vpr,Xpr,DM,hCe,zpr,Qpr,QY,Wpr,Upr,Hpr,GM,uCe,Jpr,Ypr,WY,Zpr,Kpr,e_r,OM,pCe,o_r,r_r,UY,t_r,a_r,n_r,VM,_Ce,s_r,l_r,HY,i_r,d_r,m_r,XM,bCe,c_r,f_r,JY,g_r,h_r,u_r,zM,vCe,p_r,__r,YY,b_r,v_r,F_r,QM,FCe,T_r,M_r,ZY,E_r,C_r,w_r,WM,TCe,A_r,L_r,KY,y_r,x_r,$_r,UM,MCe,k_r,S_r,eZ,R_r,P_r,B_r,HM,ECe,I_r,N_r,oZ,q_r,j_r,D_r,JM,CCe,G_r,O_r,rZ,V_r,X_r,z_r,YM,wCe,Q_r,W_r,tZ,U_r,H_r,J_r,ZM,ACe,Y_r,Z_r,aZ,K_r,e1r,o1r,KM,LCe,r1r,t1r,nZ,a1r,n1r,s1r,eE,yCe,l1r,i1r,sZ,d1r,m1r,c1r,oE,xCe,f1r,g1r,lZ,h1r,u1r,p1r,rE,$Ce,_1r,b1r,iZ,v1r,F1r,T1r,tE,kCe,M1r,E1r,dZ,C1r,w1r,A1r,aE,SCe,L1r,y1r,mZ,x1r,$1r,k1r,nE,RCe,S1r,R1r,cZ,P1r,B1r,I1r,sE,PCe,N1r,q1r,fZ,j1r,D1r,G1r,lE,BCe,O1r,V1r,gZ,X1r,z1r,Q1r,iE,ICe,W1r,U1r,hZ,H1r,J1r,Y1r,dE,Z1r,NCe,K1r,e2r,qCe,o2r,r2r,mE,tno,tm,cE,jCe,Ik,t2r,DCe,a2r,ano,Xo,Nk,n2r,am,s2r,uZ,l2r,i2r,pZ,d2r,m2r,c2r,qk,f2r,GCe,g2r,h2r,u2r,$t,jk,p2r,OCe,_2r,b2r,nm,v2r,VCe,F2r,T2r,_Z,M2r,E2r,C2r,fE,w2r,lo,Dk,A2r,XCe,L2r,y2r,hn,x2r,zCe,$2r,k2r,QCe,S2r,R2r,WCe,P2r,B2r,I2r,Ue,gE,UCe,N2r,q2r,bZ,j2r,D2r,G2r,hE,HCe,O2r,V2r,vZ,X2r,z2r,Q2r,uE,JCe,W2r,U2r,FZ,H2r,J2r,Y2r,pE,YCe,Z2r,K2r,TZ,ebr,obr,rbr,_E,ZCe,tbr,abr,MZ,nbr,sbr,lbr,bE,KCe,ibr,dbr,EZ,mbr,cbr,fbr,vE,e3e,gbr,hbr,CZ,ubr,pbr,_br,FE,bbr,o3e,vbr,Fbr,r3e,Tbr,Mbr,TE,nno,sm,ME,t3e,Gk,Ebr,a3e,Cbr,sno,zo,Ok,wbr,lm,Abr,wZ,Lbr,ybr,AZ,xbr,$br,kbr,Vk,Sbr,n3e,Rbr,Pbr,Bbr,kt,Xk,Ibr,s3e,Nbr,qbr,im,jbr,l3e,Dbr,Gbr,LZ,Obr,Vbr,Xbr,EE,zbr,io,zk,Qbr,i3e,Wbr,Ubr,un,Hbr,d3e,Jbr,Ybr,m3e,Zbr,Kbr,c3e,evr,ovr,rvr,U,CE,f3e,tvr,avr,yZ,nvr,svr,lvr,wE,g3e,ivr,dvr,xZ,mvr,cvr,fvr,AE,h3e,gvr,hvr,$Z,uvr,pvr,_vr,LE,u3e,bvr,vvr,kZ,Fvr,Tvr,Mvr,yE,p3e,Evr,Cvr,SZ,wvr,Avr,Lvr,xE,_3e,yvr,xvr,RZ,$vr,kvr,Svr,$E,b3e,Rvr,Pvr,PZ,Bvr,Ivr,Nvr,kE,v3e,qvr,jvr,BZ,Dvr,Gvr,Ovr,SE,F3e,Vvr,Xvr,IZ,zvr,Qvr,Wvr,RE,T3e,Uvr,Hvr,NZ,Jvr,Yvr,Zvr,PE,M3e,Kvr,eFr,qZ,oFr,rFr,tFr,BE,E3e,aFr,nFr,jZ,sFr,lFr,iFr,IE,C3e,dFr,mFr,DZ,cFr,fFr,gFr,NE,w3e,hFr,uFr,GZ,pFr,_Fr,bFr,qE,A3e,vFr,FFr,OZ,TFr,MFr,EFr,jE,L3e,CFr,wFr,VZ,AFr,LFr,yFr,DE,y3e,xFr,$Fr,XZ,kFr,SFr,RFr,GE,x3e,PFr,BFr,zZ,IFr,NFr,qFr,OE,$3e,jFr,DFr,QZ,GFr,OFr,VFr,VE,k3e,XFr,zFr,WZ,QFr,WFr,UFr,XE,S3e,HFr,JFr,UZ,YFr,ZFr,KFr,zE,R3e,eTr,oTr,HZ,rTr,tTr,aTr,QE,P3e,nTr,sTr,JZ,lTr,iTr,dTr,WE,B3e,mTr,cTr,YZ,fTr,gTr,hTr,UE,I3e,uTr,pTr,ZZ,_Tr,bTr,vTr,HE,N3e,FTr,TTr,KZ,MTr,ETr,CTr,JE,q3e,wTr,ATr,eK,LTr,yTr,xTr,YE,j3e,$Tr,kTr,oK,STr,RTr,PTr,ZE,D3e,BTr,ITr,rK,NTr,qTr,jTr,KE,G3e,DTr,GTr,tK,OTr,VTr,XTr,e4,O3e,zTr,QTr,aK,WTr,UTr,HTr,o4,V3e,JTr,YTr,nK,ZTr,KTr,eMr,r4,X3e,oMr,rMr,sK,tMr,aMr,nMr,t4,z3e,sMr,lMr,lK,iMr,dMr,mMr,a4,Q3e,cMr,fMr,iK,gMr,hMr,uMr,n4,W3e,pMr,_Mr,dK,bMr,vMr,FMr,s4,U3e,TMr,MMr,mK,EMr,CMr,wMr,l4,H3e,AMr,LMr,cK,yMr,xMr,$Mr,i4,J3e,kMr,SMr,fK,RMr,PMr,BMr,d4,Y3e,IMr,NMr,gK,qMr,jMr,DMr,m4,Z3e,GMr,OMr,hK,VMr,XMr,zMr,c4,K3e,QMr,WMr,uK,UMr,HMr,JMr,f4,YMr,e5e,ZMr,KMr,o5e,eEr,oEr,g4,lno,dm,h4,r5e,Qk,rEr,t5e,tEr,ino,Qo,Wk,aEr,mm,nEr,pK,sEr,lEr,_K,iEr,dEr,mEr,Uk,cEr,a5e,fEr,gEr,hEr,St,Hk,uEr,n5e,pEr,_Er,cm,bEr,s5e,vEr,FEr,bK,TEr,MEr,EEr,u4,CEr,mo,Jk,wEr,l5e,AEr,LEr,pn,yEr,i5e,xEr,$Er,d5e,kEr,SEr,m5e,REr,PEr,BEr,O,p4,c5e,IEr,NEr,vK,qEr,jEr,DEr,_4,f5e,GEr,OEr,FK,VEr,XEr,zEr,b4,g5e,QEr,WEr,TK,UEr,HEr,JEr,v4,h5e,YEr,ZEr,MK,KEr,e4r,o4r,F4,u5e,r4r,t4r,EK,a4r,n4r,s4r,T4,p5e,l4r,i4r,CK,d4r,m4r,c4r,M4,_5e,f4r,g4r,wK,h4r,u4r,p4r,E4,b5e,_4r,b4r,AK,v4r,F4r,T4r,C4,v5e,M4r,E4r,LK,C4r,w4r,A4r,w4,F5e,L4r,y4r,yK,x4r,$4r,k4r,A4,T5e,S4r,R4r,xK,P4r,B4r,I4r,L4,M5e,N4r,q4r,$K,j4r,D4r,G4r,y4,E5e,O4r,V4r,kK,X4r,z4r,Q4r,x4,C5e,W4r,U4r,SK,H4r,J4r,Y4r,$4,w5e,Z4r,K4r,RK,eCr,oCr,rCr,k4,A5e,tCr,aCr,PK,nCr,sCr,lCr,S4,L5e,iCr,dCr,BK,mCr,cCr,fCr,R4,y5e,gCr,hCr,IK,uCr,pCr,_Cr,P4,x5e,bCr,vCr,NK,FCr,TCr,MCr,B4,$5e,ECr,CCr,qK,wCr,ACr,LCr,I4,k5e,yCr,xCr,jK,$Cr,kCr,SCr,N4,S5e,RCr,PCr,DK,BCr,ICr,NCr,q4,R5e,qCr,jCr,GK,DCr,GCr,OCr,j4,P5e,VCr,XCr,OK,zCr,QCr,WCr,D4,B5e,UCr,HCr,VK,JCr,YCr,ZCr,G4,I5e,KCr,e3r,XK,o3r,r3r,t3r,O4,N5e,a3r,n3r,zK,s3r,l3r,i3r,V4,q5e,d3r,m3r,QK,c3r,f3r,g3r,X4,j5e,h3r,u3r,WK,p3r,_3r,b3r,z4,D5e,v3r,F3r,UK,T3r,M3r,E3r,Q4,G5e,C3r,w3r,HK,A3r,L3r,y3r,W4,O5e,x3r,$3r,JK,k3r,S3r,R3r,U4,V5e,P3r,B3r,YK,I3r,N3r,q3r,H4,X5e,j3r,D3r,ZK,G3r,O3r,V3r,J4,z5e,X3r,z3r,KK,Q3r,W3r,U3r,Y4,Q5e,H3r,J3r,eee,Y3r,Z3r,K3r,Z4,W5e,e5r,o5r,oee,r5r,t5r,a5r,K4,U5e,n5r,s5r,ree,l5r,i5r,d5r,eC,H5e,m5r,c5r,tee,f5r,g5r,h5r,oC,J5e,u5r,p5r,aee,_5r,b5r,v5r,rC,Y5e,F5r,T5r,nee,M5r,E5r,C5r,tC,Z5e,w5r,A5r,see,L5r,y5r,x5r,aC,K5e,$5r,k5r,lee,S5r,R5r,P5r,nC,e0e,B5r,I5r,iee,N5r,q5r,j5r,sC,o0e,D5r,G5r,dee,O5r,V5r,X5r,lC,r0e,z5r,Q5r,mee,W5r,U5r,H5r,iC,t0e,J5r,Y5r,cee,Z5r,K5r,e0r,dC,a0e,o0r,r0r,fee,t0r,a0r,n0r,mC,n0e,s0r,l0r,gee,i0r,d0r,m0r,cC,c0r,s0e,f0r,g0r,l0e,h0r,u0r,fC,dno,fm,gC,i0e,Yk,p0r,d0e,_0r,mno,Wo,Zk,b0r,gm,v0r,hee,F0r,T0r,uee,M0r,E0r,C0r,Kk,w0r,m0e,A0r,L0r,y0r,Rt,eS,x0r,c0e,$0r,k0r,hm,S0r,f0e,R0r,P0r,pee,B0r,I0r,N0r,hC,q0r,co,oS,j0r,g0e,D0r,G0r,_n,O0r,h0e,V0r,X0r,u0e,z0r,Q0r,p0e,W0r,U0r,H0r,_0e,uC,b0e,J0r,Y0r,_ee,Z0r,K0r,ewr,pC,owr,v0e,rwr,twr,F0e,awr,nwr,_C,cno,um,bC,T0e,rS,swr,M0e,lwr,fno,Uo,tS,iwr,pm,dwr,bee,mwr,cwr,vee,fwr,gwr,hwr,aS,uwr,E0e,pwr,_wr,bwr,Pt,nS,vwr,C0e,Fwr,Twr,_m,Mwr,w0e,Ewr,Cwr,Fee,wwr,Awr,Lwr,vC,ywr,fo,sS,xwr,A0e,$wr,kwr,bn,Swr,L0e,Rwr,Pwr,y0e,Bwr,Iwr,x0e,Nwr,qwr,jwr,bm,FC,$0e,Dwr,Gwr,Tee,Owr,Vwr,Xwr,TC,k0e,zwr,Qwr,Mee,Wwr,Uwr,Hwr,MC,S0e,Jwr,Ywr,Eee,Zwr,Kwr,eAr,EC,oAr,R0e,rAr,tAr,P0e,aAr,nAr,CC,gno,vm,wC,B0e,lS,sAr,I0e,lAr,hno,Ho,iS,iAr,Fm,dAr,Cee,mAr,cAr,wee,fAr,gAr,hAr,dS,uAr,N0e,pAr,_Ar,bAr,Bt,mS,vAr,q0e,FAr,TAr,Tm,MAr,j0e,EAr,CAr,Aee,wAr,AAr,LAr,AC,yAr,go,cS,xAr,D0e,$Ar,kAr,vn,SAr,G0e,RAr,PAr,O0e,BAr,IAr,V0e,NAr,qAr,jAr,be,LC,X0e,DAr,GAr,Lee,OAr,VAr,XAr,yC,z0e,zAr,QAr,yee,WAr,UAr,HAr,xC,Q0e,JAr,YAr,xee,ZAr,KAr,e6r,$C,W0e,o6r,r6r,$ee,t6r,a6r,n6r,kl,U0e,s6r,l6r,kee,i6r,d6r,See,m6r,c6r,f6r,kC,H0e,g6r,h6r,Ree,u6r,p6r,_6r,Sl,J0e,b6r,v6r,Pee,F6r,T6r,Bee,M6r,E6r,C6r,SC,Y0e,w6r,A6r,Iee,L6r,y6r,x6r,It,Z0e,$6r,k6r,Nee,S6r,R6r,qee,P6r,B6r,jee,I6r,N6r,q6r,RC,K0e,j6r,D6r,Dee,G6r,O6r,V6r,PC,ewe,X6r,z6r,Gee,Q6r,W6r,U6r,BC,owe,H6r,J6r,Oee,Y6r,Z6r,K6r,IC,rwe,e7r,o7r,Vee,r7r,t7r,a7r,NC,twe,n7r,s7r,Xee,l7r,i7r,d7r,qC,awe,m7r,c7r,zee,f7r,g7r,h7r,jC,nwe,u7r,p7r,Qee,_7r,b7r,v7r,DC,swe,F7r,T7r,Wee,M7r,E7r,C7r,GC,lwe,w7r,A7r,Uee,L7r,y7r,x7r,OC,$7r,iwe,k7r,S7r,dwe,R7r,P7r,VC,uno,Mm,XC,mwe,fS,B7r,cwe,I7r,pno,Jo,gS,N7r,Em,q7r,Hee,j7r,D7r,Jee,G7r,O7r,V7r,hS,X7r,fwe,z7r,Q7r,W7r,Nt,uS,U7r,gwe,H7r,J7r,Cm,Y7r,hwe,Z7r,K7r,Yee,e8r,o8r,r8r,zC,t8r,ho,pS,a8r,uwe,n8r,s8r,Fn,l8r,pwe,i8r,d8r,_we,m8r,c8r,bwe,f8r,g8r,h8r,vwe,QC,Fwe,u8r,p8r,Zee,_8r,b8r,v8r,WC,F8r,Twe,T8r,M8r,Mwe,E8r,C8r,UC,_no,wm,HC,Ewe,_S,w8r,Cwe,A8r,bno,Yo,bS,L8r,Am,y8r,Kee,x8r,$8r,eoe,k8r,S8r,R8r,vS,P8r,wwe,B8r,I8r,N8r,qt,FS,q8r,Awe,j8r,D8r,Lm,G8r,Lwe,O8r,V8r,ooe,X8r,z8r,Q8r,JC,W8r,uo,TS,U8r,ywe,H8r,J8r,Tn,Y8r,xwe,Z8r,K8r,$we,eLr,oLr,kwe,rLr,tLr,aLr,Swe,YC,Rwe,nLr,sLr,roe,lLr,iLr,dLr,ZC,mLr,Pwe,cLr,fLr,Bwe,gLr,hLr,KC,vno,ym,e3,Iwe,MS,uLr,Nwe,pLr,Fno,Zo,ES,_Lr,xm,bLr,toe,vLr,FLr,aoe,TLr,MLr,ELr,CS,CLr,qwe,wLr,ALr,LLr,jt,wS,yLr,jwe,xLr,$Lr,$m,kLr,Dwe,SLr,RLr,noe,PLr,BLr,ILr,o3,NLr,po,AS,qLr,Gwe,jLr,DLr,Mn,GLr,Owe,OLr,VLr,Vwe,XLr,zLr,Xwe,QLr,WLr,ULr,zwe,r3,Qwe,HLr,JLr,soe,YLr,ZLr,KLr,t3,eyr,Wwe,oyr,ryr,Uwe,tyr,ayr,a3,Tno,km,n3,Hwe,LS,nyr,Jwe,syr,Mno,Ko,yS,lyr,Sm,iyr,loe,dyr,myr,ioe,cyr,fyr,gyr,xS,hyr,Ywe,uyr,pyr,_yr,Dt,$S,byr,Zwe,vyr,Fyr,Rm,Tyr,Kwe,Myr,Eyr,doe,Cyr,wyr,Ayr,s3,Lyr,_o,kS,yyr,eAe,xyr,$yr,En,kyr,oAe,Syr,Ryr,rAe,Pyr,Byr,tAe,Iyr,Nyr,qyr,Be,l3,aAe,jyr,Dyr,moe,Gyr,Oyr,Vyr,i3,nAe,Xyr,zyr,coe,Qyr,Wyr,Uyr,d3,sAe,Hyr,Jyr,foe,Yyr,Zyr,Kyr,m3,lAe,e9r,o9r,goe,r9r,t9r,a9r,c3,iAe,n9r,s9r,hoe,l9r,i9r,d9r,f3,dAe,m9r,c9r,uoe,f9r,g9r,h9r,g3,mAe,u9r,p9r,poe,_9r,b9r,v9r,h3,cAe,F9r,T9r,_oe,M9r,E9r,C9r,u3,fAe,w9r,A9r,boe,L9r,y9r,x9r,p3,$9r,gAe,k9r,S9r,hAe,R9r,P9r,_3,Eno,Pm,b3,uAe,SS,B9r,pAe,I9r,Cno,er,RS,N9r,Bm,q9r,voe,j9r,D9r,Foe,G9r,O9r,V9r,PS,X9r,_Ae,z9r,Q9r,W9r,Gt,BS,U9r,bAe,H9r,J9r,Im,Y9r,vAe,Z9r,K9r,Toe,exr,oxr,rxr,v3,txr,bo,IS,axr,FAe,nxr,sxr,Cn,lxr,TAe,ixr,dxr,MAe,mxr,cxr,EAe,fxr,gxr,hxr,ut,F3,CAe,uxr,pxr,Moe,_xr,bxr,vxr,T3,wAe,Fxr,Txr,Eoe,Mxr,Exr,Cxr,M3,AAe,wxr,Axr,Coe,Lxr,yxr,xxr,E3,LAe,$xr,kxr,woe,Sxr,Rxr,Pxr,C3,yAe,Bxr,Ixr,Aoe,Nxr,qxr,jxr,w3,Dxr,xAe,Gxr,Oxr,$Ae,Vxr,Xxr,A3,wno,Nm,L3,kAe,NS,zxr,SAe,Qxr,Ano,or,qS,Wxr,qm,Uxr,Loe,Hxr,Jxr,yoe,Yxr,Zxr,Kxr,jS,e$r,RAe,o$r,r$r,t$r,Ot,DS,a$r,PAe,n$r,s$r,jm,l$r,BAe,i$r,d$r,xoe,m$r,c$r,f$r,y3,g$r,vo,GS,h$r,IAe,u$r,p$r,wn,_$r,NAe,b$r,v$r,qAe,F$r,T$r,jAe,M$r,E$r,C$r,Le,x3,DAe,w$r,A$r,$oe,L$r,y$r,x$r,$3,GAe,$$r,k$r,koe,S$r,R$r,P$r,k3,OAe,B$r,I$r,Soe,N$r,q$r,j$r,S3,VAe,D$r,G$r,Roe,O$r,V$r,X$r,R3,XAe,z$r,Q$r,Poe,W$r,U$r,H$r,P3,zAe,J$r,Y$r,Boe,Z$r,K$r,ekr,B3,QAe,okr,rkr,Ioe,tkr,akr,nkr,I3,WAe,skr,lkr,Noe,ikr,dkr,mkr,N3,UAe,ckr,fkr,qoe,gkr,hkr,ukr,q3,HAe,pkr,_kr,joe,bkr,vkr,Fkr,j3,Tkr,JAe,Mkr,Ekr,YAe,Ckr,wkr,D3,Lno,Dm,G3,ZAe,OS,Akr,KAe,Lkr,yno,rr,VS,ykr,Gm,xkr,Doe,$kr,kkr,Goe,Skr,Rkr,Pkr,XS,Bkr,e6e,Ikr,Nkr,qkr,Vt,zS,jkr,o6e,Dkr,Gkr,Om,Okr,r6e,Vkr,Xkr,Ooe,zkr,Qkr,Wkr,O3,Ukr,Fo,QS,Hkr,t6e,Jkr,Ykr,An,Zkr,a6e,Kkr,eSr,n6e,oSr,rSr,s6e,tSr,aSr,nSr,Vm,V3,l6e,sSr,lSr,Voe,iSr,dSr,mSr,X3,i6e,cSr,fSr,Xoe,gSr,hSr,uSr,z3,d6e,pSr,_Sr,zoe,bSr,vSr,FSr,Q3,TSr,m6e,MSr,ESr,c6e,CSr,wSr,W3,xno,Xm,U3,f6e,WS,ASr,g6e,LSr,$no,tr,US,ySr,zm,xSr,Qoe,$Sr,kSr,Woe,SSr,RSr,PSr,HS,BSr,h6e,ISr,NSr,qSr,Xt,JS,jSr,u6e,DSr,GSr,Qm,OSr,p6e,VSr,XSr,Uoe,zSr,QSr,WSr,H3,USr,To,YS,HSr,_6e,JSr,YSr,Ln,ZSr,b6e,KSr,eRr,v6e,oRr,rRr,F6e,tRr,aRr,nRr,pt,J3,T6e,sRr,lRr,Hoe,iRr,dRr,mRr,Y3,M6e,cRr,fRr,Joe,gRr,hRr,uRr,Z3,E6e,pRr,_Rr,Yoe,bRr,vRr,FRr,K3,C6e,TRr,MRr,Zoe,ERr,CRr,wRr,e5,w6e,ARr,LRr,Koe,yRr,xRr,$Rr,o5,kRr,A6e,SRr,RRr,L6e,PRr,BRr,r5,kno,Wm,t5,y6e,ZS,IRr,x6e,NRr,Sno,ar,KS,qRr,Um,jRr,ere,DRr,GRr,ore,ORr,VRr,XRr,eR,zRr,$6e,QRr,WRr,URr,zt,oR,HRr,k6e,JRr,YRr,Hm,ZRr,S6e,KRr,ePr,rre,oPr,rPr,tPr,a5,aPr,Mo,rR,nPr,R6e,sPr,lPr,yn,iPr,P6e,dPr,mPr,B6e,cPr,fPr,I6e,gPr,hPr,uPr,xn,n5,N6e,pPr,_Pr,tre,bPr,vPr,FPr,s5,q6e,TPr,MPr,are,EPr,CPr,wPr,l5,j6e,APr,LPr,nre,yPr,xPr,$Pr,i5,D6e,kPr,SPr,sre,RPr,PPr,BPr,d5,IPr,G6e,NPr,qPr,O6e,jPr,DPr,m5,Rno,Jm,c5,V6e,tR,GPr,X6e,OPr,Pno,nr,aR,VPr,Ym,XPr,lre,zPr,QPr,ire,WPr,UPr,HPr,nR,JPr,z6e,YPr,ZPr,KPr,Qt,sR,eBr,Q6e,oBr,rBr,Zm,tBr,W6e,aBr,nBr,dre,sBr,lBr,iBr,f5,dBr,Eo,lR,mBr,U6e,cBr,fBr,$n,gBr,H6e,hBr,uBr,J6e,pBr,_Br,Y6e,bBr,vBr,FBr,_t,g5,Z6e,TBr,MBr,mre,EBr,CBr,wBr,h5,K6e,ABr,LBr,cre,yBr,xBr,$Br,u5,e7e,kBr,SBr,fre,RBr,PBr,BBr,p5,o7e,IBr,NBr,gre,qBr,jBr,DBr,_5,r7e,GBr,OBr,hre,VBr,XBr,zBr,b5,QBr,t7e,WBr,UBr,a7e,HBr,JBr,v5,Bno,Km,F5,n7e,iR,YBr,s7e,ZBr,Ino,sr,dR,KBr,ec,eIr,ure,oIr,rIr,pre,tIr,aIr,nIr,mR,sIr,l7e,lIr,iIr,dIr,Wt,cR,mIr,i7e,cIr,fIr,oc,gIr,d7e,hIr,uIr,_re,pIr,_Ir,bIr,T5,vIr,Co,fR,FIr,m7e,TIr,MIr,kn,EIr,c7e,CIr,wIr,f7e,AIr,LIr,g7e,yIr,xIr,$Ir,h7e,M5,u7e,kIr,SIr,bre,RIr,PIr,BIr,E5,IIr,p7e,NIr,qIr,_7e,jIr,DIr,C5,Nno,rc,w5,b7e,gR,GIr,v7e,OIr,qno,lr,hR,VIr,tc,XIr,vre,zIr,QIr,Fre,WIr,UIr,HIr,uR,JIr,F7e,YIr,ZIr,KIr,Ut,pR,eNr,T7e,oNr,rNr,ac,tNr,M7e,aNr,nNr,Tre,sNr,lNr,iNr,A5,dNr,wo,_R,mNr,E7e,cNr,fNr,Sn,gNr,C7e,hNr,uNr,w7e,pNr,_Nr,A7e,bNr,vNr,FNr,bt,L5,L7e,TNr,MNr,Mre,ENr,CNr,wNr,y5,y7e,ANr,LNr,Ere,yNr,xNr,$Nr,x5,x7e,kNr,SNr,Cre,RNr,PNr,BNr,$5,$7e,INr,NNr,wre,qNr,jNr,DNr,k5,k7e,GNr,ONr,Are,VNr,XNr,zNr,S5,QNr,S7e,WNr,UNr,R7e,HNr,JNr,R5,jno,nc,P5,P7e,bR,YNr,B7e,ZNr,Dno,ir,vR,KNr,sc,eqr,Lre,oqr,rqr,yre,tqr,aqr,nqr,FR,sqr,I7e,lqr,iqr,dqr,Ht,TR,mqr,N7e,cqr,fqr,lc,gqr,q7e,hqr,uqr,xre,pqr,_qr,bqr,B5,vqr,Ao,MR,Fqr,j7e,Tqr,Mqr,Rn,Eqr,D7e,Cqr,wqr,G7e,Aqr,Lqr,O7e,yqr,xqr,$qr,V7e,I5,X7e,kqr,Sqr,$re,Rqr,Pqr,Bqr,N5,Iqr,z7e,Nqr,qqr,Q7e,jqr,Dqr,q5,Gno,ic,j5,W7e,ER,Gqr,U7e,Oqr,Ono,dr,CR,Vqr,dc,Xqr,kre,zqr,Qqr,Sre,Wqr,Uqr,Hqr,wR,Jqr,H7e,Yqr,Zqr,Kqr,Jt,AR,ejr,J7e,ojr,rjr,mc,tjr,Y7e,ajr,njr,Rre,sjr,ljr,ijr,D5,djr,Lo,LR,mjr,Z7e,cjr,fjr,Pn,gjr,K7e,hjr,ujr,e8e,pjr,_jr,o8e,bjr,vjr,Fjr,r8e,G5,t8e,Tjr,Mjr,Pre,Ejr,Cjr,wjr,O5,Ajr,a8e,Ljr,yjr,n8e,xjr,$jr,V5,Vno,cc,X5,s8e,yR,kjr,l8e,Sjr,Xno,mr,xR,Rjr,fc,Pjr,Bre,Bjr,Ijr,Ire,Njr,qjr,jjr,$R,Djr,i8e,Gjr,Ojr,Vjr,Yt,kR,Xjr,d8e,zjr,Qjr,gc,Wjr,m8e,Ujr,Hjr,Nre,Jjr,Yjr,Zjr,z5,Kjr,Dr,SR,eDr,c8e,oDr,rDr,Bn,tDr,f8e,aDr,nDr,g8e,sDr,lDr,h8e,iDr,dDr,mDr,P,Q5,u8e,cDr,fDr,qre,gDr,hDr,uDr,W5,p8e,pDr,_Dr,jre,bDr,vDr,FDr,U5,_8e,TDr,MDr,Dre,EDr,CDr,wDr,H5,b8e,ADr,LDr,Gre,yDr,xDr,$Dr,J5,v8e,kDr,SDr,Ore,RDr,PDr,BDr,Y5,F8e,IDr,NDr,Vre,qDr,jDr,DDr,Z5,T8e,GDr,ODr,Xre,VDr,XDr,zDr,K5,M8e,QDr,WDr,zre,UDr,HDr,JDr,e0,E8e,YDr,ZDr,Qre,KDr,eGr,oGr,o0,C8e,rGr,tGr,Wre,aGr,nGr,sGr,r0,w8e,lGr,iGr,Ure,dGr,mGr,cGr,t0,A8e,fGr,gGr,Hre,hGr,uGr,pGr,a0,L8e,_Gr,bGr,Jre,vGr,FGr,TGr,n0,y8e,MGr,EGr,Yre,CGr,wGr,AGr,s0,x8e,LGr,yGr,Zre,xGr,$Gr,kGr,l0,$8e,SGr,RGr,Kre,PGr,BGr,IGr,i0,k8e,NGr,qGr,ete,jGr,DGr,GGr,d0,S8e,OGr,VGr,ote,XGr,zGr,QGr,m0,R8e,WGr,UGr,rte,HGr,JGr,YGr,c0,P8e,ZGr,KGr,tte,eOr,oOr,rOr,Rl,B8e,tOr,aOr,ate,nOr,sOr,nte,lOr,iOr,dOr,f0,I8e,mOr,cOr,ste,fOr,gOr,hOr,g0,N8e,uOr,pOr,lte,_Or,bOr,vOr,h0,q8e,FOr,TOr,ite,MOr,EOr,COr,u0,j8e,wOr,AOr,dte,LOr,yOr,xOr,p0,D8e,$Or,kOr,mte,SOr,ROr,POr,_0,G8e,BOr,IOr,cte,NOr,qOr,jOr,b0,O8e,DOr,GOr,fte,OOr,VOr,XOr,v0,V8e,zOr,QOr,gte,WOr,UOr,HOr,F0,X8e,JOr,YOr,hte,ZOr,KOr,eVr,T0,z8e,oVr,rVr,ute,tVr,aVr,nVr,M0,Q8e,sVr,lVr,pte,iVr,dVr,mVr,E0,W8e,cVr,fVr,_te,gVr,hVr,uVr,C0,U8e,pVr,_Vr,bte,bVr,vVr,FVr,w0,H8e,TVr,MVr,vte,EVr,CVr,wVr,A0,J8e,AVr,LVr,Fte,yVr,xVr,$Vr,L0,Y8e,kVr,SVr,Tte,RVr,PVr,BVr,y0,Z8e,IVr,NVr,Mte,qVr,jVr,DVr,x0,K8e,GVr,OVr,Ete,VVr,XVr,zVr,$0,eLe,QVr,WVr,Cte,UVr,HVr,JVr,k0,oLe,YVr,ZVr,wte,KVr,eXr,oXr,S0,rLe,rXr,tXr,Ate,aXr,nXr,sXr,R0,tLe,lXr,iXr,Lte,dXr,mXr,cXr,P0,aLe,fXr,gXr,yte,hXr,uXr,pXr,B0,nLe,_Xr,bXr,xte,vXr,FXr,TXr,I0,sLe,MXr,EXr,$te,CXr,wXr,AXr,N0,lLe,LXr,yXr,kte,xXr,$Xr,kXr,q0,iLe,SXr,RXr,Ste,PXr,BXr,IXr,j0,dLe,NXr,qXr,Rte,jXr,DXr,GXr,D0,mLe,OXr,VXr,Pte,XXr,zXr,QXr,G0,cLe,WXr,UXr,Bte,HXr,JXr,YXr,O0,fLe,ZXr,KXr,Ite,ezr,ozr,rzr,V0,gLe,tzr,azr,Nte,nzr,szr,lzr,X0,hLe,izr,dzr,qte,mzr,czr,fzr,z0,uLe,gzr,hzr,jte,uzr,pzr,_zr,Q0,pLe,bzr,vzr,Dte,Fzr,Tzr,Mzr,W0,_Le,Ezr,Czr,Gte,wzr,Azr,Lzr,U0,bLe,yzr,xzr,Ote,$zr,kzr,Szr,H0,zno,hc,J0,vLe,RR,Rzr,FLe,Pzr,Qno,cr,PR,Bzr,uc,Izr,Vte,Nzr,qzr,Xte,jzr,Dzr,Gzr,BR,Ozr,TLe,Vzr,Xzr,zzr,Zt,IR,Qzr,MLe,Wzr,Uzr,pc,Hzr,ELe,Jzr,Yzr,zte,Zzr,Kzr,eQr,Y0,oQr,Gr,NR,rQr,CLe,tQr,aQr,In,nQr,wLe,sQr,lQr,ALe,iQr,dQr,LLe,mQr,cQr,fQr,le,Z0,yLe,gQr,hQr,Qte,uQr,pQr,_Qr,K0,xLe,bQr,vQr,Wte,FQr,TQr,MQr,ew,$Le,EQr,CQr,Ute,wQr,AQr,LQr,ow,kLe,yQr,xQr,Hte,$Qr,kQr,SQr,rw,SLe,RQr,PQr,Jte,BQr,IQr,NQr,tw,RLe,qQr,jQr,Yte,DQr,GQr,OQr,aw,PLe,VQr,XQr,Zte,zQr,QQr,WQr,nw,BLe,UQr,HQr,Kte,JQr,YQr,ZQr,sw,ILe,KQr,eWr,eae,oWr,rWr,tWr,lw,NLe,aWr,nWr,oae,sWr,lWr,iWr,iw,qLe,dWr,mWr,rae,cWr,fWr,gWr,dw,jLe,hWr,uWr,tae,pWr,_Wr,bWr,mw,DLe,vWr,FWr,aae,TWr,MWr,EWr,cw,GLe,CWr,wWr,nae,AWr,LWr,yWr,fw,OLe,xWr,$Wr,sae,kWr,SWr,RWr,gw,VLe,PWr,BWr,lae,IWr,NWr,qWr,hw,XLe,jWr,DWr,iae,GWr,OWr,VWr,uw,zLe,XWr,zWr,dae,QWr,WWr,UWr,pw,QLe,HWr,JWr,mae,YWr,ZWr,KWr,_w,WLe,eUr,oUr,cae,rUr,tUr,aUr,bw,ULe,nUr,sUr,fae,lUr,iUr,dUr,vw,HLe,mUr,cUr,gae,fUr,gUr,hUr,Fw,JLe,uUr,pUr,hae,_Ur,bUr,vUr,Tw,Wno,_c,Mw,YLe,qR,FUr,ZLe,TUr,Uno,fr,jR,MUr,bc,EUr,uae,CUr,wUr,pae,AUr,LUr,yUr,DR,xUr,KLe,$Ur,kUr,SUr,Kt,GR,RUr,eye,PUr,BUr,vc,IUr,oye,NUr,qUr,_ae,jUr,DUr,GUr,Ew,OUr,Or,OR,VUr,rye,XUr,zUr,Nn,QUr,tye,WUr,UUr,aye,HUr,JUr,nye,YUr,ZUr,KUr,Me,Cw,sye,eHr,oHr,bae,rHr,tHr,aHr,ww,lye,nHr,sHr,vae,lHr,iHr,dHr,Aw,iye,mHr,cHr,Fae,fHr,gHr,hHr,Lw,dye,uHr,pHr,Tae,_Hr,bHr,vHr,yw,mye,FHr,THr,Mae,MHr,EHr,CHr,xw,cye,wHr,AHr,Eae,LHr,yHr,xHr,$w,fye,$Hr,kHr,Cae,SHr,RHr,PHr,kw,gye,BHr,IHr,wae,NHr,qHr,jHr,Sw,hye,DHr,GHr,Aae,OHr,VHr,XHr,Rw,uye,zHr,QHr,Lae,WHr,UHr,HHr,Pw,pye,JHr,YHr,yae,ZHr,KHr,eJr,Bw,_ye,oJr,rJr,xae,tJr,aJr,nJr,Iw,bye,sJr,lJr,$ae,iJr,dJr,mJr,Nw,vye,cJr,fJr,kae,gJr,hJr,uJr,qw,Hno,Fc,jw,Fye,VR,pJr,Tye,_Jr,Jno,gr,XR,bJr,Tc,vJr,Sae,FJr,TJr,Rae,MJr,EJr,CJr,zR,wJr,Mye,AJr,LJr,yJr,ea,QR,xJr,Eye,$Jr,kJr,Mc,SJr,Cye,RJr,PJr,Pae,BJr,IJr,NJr,Dw,qJr,Vr,WR,jJr,wye,DJr,GJr,qn,OJr,Aye,VJr,XJr,Lye,zJr,QJr,yye,WJr,UJr,HJr,ye,Gw,xye,JJr,YJr,Bae,ZJr,KJr,eYr,Ow,$ye,oYr,rYr,Iae,tYr,aYr,nYr,Vw,kye,sYr,lYr,Nae,iYr,dYr,mYr,Pl,Sye,cYr,fYr,qae,gYr,hYr,jae,uYr,pYr,_Yr,Xw,Rye,bYr,vYr,Dae,FYr,TYr,MYr,zw,Pye,EYr,CYr,Gae,wYr,AYr,LYr,Qw,Bye,yYr,xYr,Oae,$Yr,kYr,SYr,Ww,Iye,RYr,PYr,Vae,BYr,IYr,NYr,Uw,Nye,qYr,jYr,Xae,DYr,GYr,OYr,Hw,qye,VYr,XYr,zae,zYr,QYr,WYr,Jw,Yno,Ec,Yw,jye,UR,UYr,Dye,HYr,Zno,hr,HR,JYr,Cc,YYr,Qae,ZYr,KYr,Wae,eZr,oZr,rZr,JR,tZr,Gye,aZr,nZr,sZr,oa,YR,lZr,Oye,iZr,dZr,wc,mZr,Vye,cZr,fZr,Uae,gZr,hZr,uZr,Zw,pZr,Xr,ZR,_Zr,Xye,bZr,vZr,jn,FZr,zye,TZr,MZr,Qye,EZr,CZr,Wye,wZr,AZr,LZr,Ac,Kw,Uye,yZr,xZr,Hae,$Zr,kZr,SZr,eA,Hye,RZr,PZr,Jae,BZr,IZr,NZr,oA,Jye,qZr,jZr,Yae,DZr,GZr,OZr,rA,Kno,Lc,tA,Yye,KR,VZr,Zye,XZr,eso,ur,eP,zZr,yc,QZr,Zae,WZr,UZr,Kae,HZr,JZr,YZr,oP,ZZr,Kye,KZr,eKr,oKr,ra,rP,rKr,e9e,tKr,aKr,xc,nKr,o9e,sKr,lKr,ene,iKr,dKr,mKr,aA,cKr,zr,tP,fKr,r9e,gKr,hKr,Dn,uKr,t9e,pKr,_Kr,a9e,bKr,vKr,n9e,FKr,TKr,MKr,ce,nA,s9e,EKr,CKr,one,wKr,AKr,LKr,sA,l9e,yKr,xKr,rne,$Kr,kKr,SKr,lA,i9e,RKr,PKr,tne,BKr,IKr,NKr,iA,d9e,qKr,jKr,ane,DKr,GKr,OKr,dA,m9e,VKr,XKr,nne,zKr,QKr,WKr,mA,c9e,UKr,HKr,sne,JKr,YKr,ZKr,cA,f9e,KKr,eet,lne,oet,ret,tet,fA,g9e,aet,net,ine,set,iet,det,gA,h9e,met,cet,dne,fet,get,het,hA,u9e,uet,pet,mne,_et,bet,vet,uA,p9e,Fet,Tet,cne,Met,Eet,Cet,pA,_9e,wet,Aet,fne,Let,yet,xet,_A,b9e,$et,ket,gne,Set,Ret,Pet,bA,v9e,Bet,Iet,hne,Net,qet,jet,vA,F9e,Det,Get,une,Oet,Vet,Xet,FA,T9e,zet,Qet,pne,Wet,Uet,Het,TA,M9e,Jet,Yet,_ne,Zet,Ket,eot,MA,E9e,oot,rot,bne,tot,aot,not,EA,C9e,sot,lot,vne,iot,dot,mot,CA,w9e,cot,fot,Fne,got,hot,uot,wA,A9e,pot,_ot,Tne,bot,vot,Fot,AA,oso,$c,LA,L9e,aP,Tot,y9e,Mot,rso,pr,nP,Eot,kc,Cot,Mne,wot,Aot,Ene,Lot,yot,xot,sP,$ot,x9e,kot,Sot,Rot,ta,lP,Pot,$9e,Bot,Iot,Sc,Not,k9e,qot,jot,Cne,Dot,Got,Oot,yA,Vot,Qr,iP,Xot,S9e,zot,Qot,Gn,Wot,R9e,Uot,Hot,P9e,Jot,Yot,B9e,Zot,Kot,ert,xe,xA,I9e,ort,rrt,wne,trt,art,nrt,$A,N9e,srt,lrt,Ane,irt,drt,mrt,kA,q9e,crt,frt,Lne,grt,hrt,urt,SA,j9e,prt,_rt,yne,brt,vrt,Frt,RA,D9e,Trt,Mrt,xne,Ert,Crt,wrt,PA,G9e,Art,Lrt,$ne,yrt,xrt,$rt,BA,O9e,krt,Srt,kne,Rrt,Prt,Brt,IA,V9e,Irt,Nrt,Sne,qrt,jrt,Drt,NA,X9e,Grt,Ort,Rne,Vrt,Xrt,zrt,qA,z9e,Qrt,Wrt,Pne,Urt,Hrt,Jrt,jA,tso,Rc,DA,Q9e,dP,Yrt,W9e,Zrt,aso,_r,mP,Krt,Pc,ett,Bne,ott,rtt,Ine,ttt,att,ntt,cP,stt,U9e,ltt,itt,dtt,aa,fP,mtt,H9e,ctt,ftt,Bc,gtt,J9e,htt,utt,Nne,ptt,_tt,btt,GA,vtt,Wr,gP,Ftt,Y9e,Ttt,Mtt,On,Ett,Z9e,Ctt,wtt,K9e,Att,Ltt,exe,ytt,xtt,$tt,re,OA,oxe,ktt,Stt,qne,Rtt,Ptt,Btt,VA,rxe,Itt,Ntt,jne,qtt,jtt,Dtt,XA,txe,Gtt,Ott,Dne,Vtt,Xtt,ztt,zA,axe,Qtt,Wtt,Gne,Utt,Htt,Jtt,QA,nxe,Ytt,Ztt,One,Ktt,eat,oat,WA,sxe,rat,tat,Vne,aat,nat,sat,UA,lxe,lat,iat,Xne,dat,mat,cat,HA,ixe,fat,gat,zne,hat,uat,pat,JA,dxe,_at,bat,Qne,vat,Fat,Tat,YA,mxe,Mat,Eat,Wne,Cat,wat,Aat,ZA,cxe,Lat,yat,Une,xat,$at,kat,KA,fxe,Sat,Rat,Hne,Pat,Bat,Iat,e6,gxe,Nat,qat,Jne,jat,Dat,Gat,o6,hxe,Oat,Vat,Yne,Xat,zat,Qat,r6,uxe,Wat,Uat,Zne,Hat,Jat,Yat,t6,pxe,Zat,Kat,Kne,ent,ont,rnt,a6,_xe,tnt,ant,ese,nnt,snt,lnt,n6,bxe,int,dnt,ose,mnt,cnt,fnt,s6,vxe,gnt,hnt,rse,unt,pnt,_nt,l6,Fxe,bnt,vnt,tse,Fnt,Tnt,Mnt,i6,Txe,Ent,Cnt,ase,wnt,Ant,Lnt,d6,Mxe,ynt,xnt,nse,$nt,knt,Snt,m6,Exe,Rnt,Pnt,sse,Bnt,Int,Nnt,c6,Cxe,qnt,jnt,lse,Dnt,Gnt,Ont,f6,wxe,Vnt,Xnt,ise,znt,Qnt,Wnt,g6,Axe,Unt,Hnt,dse,Jnt,Ynt,Znt,h6,Lxe,Knt,est,mse,ost,rst,tst,u6,yxe,ast,nst,cse,sst,lst,ist,p6,nso,Ic,_6,xxe,hP,dst,$xe,mst,sso,br,uP,cst,Nc,fst,fse,gst,hst,gse,ust,pst,_st,pP,bst,kxe,vst,Fst,Tst,na,_P,Mst,Sxe,Est,Cst,qc,wst,Rxe,Ast,Lst,hse,yst,xst,$st,b6,kst,Ur,bP,Sst,Pxe,Rst,Pst,Vn,Bst,Bxe,Ist,Nst,Ixe,qst,jst,Nxe,Dst,Gst,Ost,ve,v6,qxe,Vst,Xst,use,zst,Qst,Wst,F6,jxe,Ust,Hst,pse,Jst,Yst,Zst,T6,Dxe,Kst,elt,_se,olt,rlt,tlt,M6,Gxe,alt,nlt,bse,slt,llt,ilt,E6,Oxe,dlt,mlt,vse,clt,flt,glt,C6,Vxe,hlt,ult,Fse,plt,_lt,blt,w6,Xxe,vlt,Flt,Tse,Tlt,Mlt,Elt,A6,zxe,Clt,wlt,Mse,Alt,Llt,ylt,L6,Qxe,xlt,$lt,Ese,klt,Slt,Rlt,y6,Wxe,Plt,Blt,Cse,Ilt,Nlt,qlt,x6,Uxe,jlt,Dlt,wse,Glt,Olt,Vlt,$6,Hxe,Xlt,zlt,Ase,Qlt,Wlt,Ult,k6,Jxe,Hlt,Jlt,Lse,Ylt,Zlt,Klt,S6,Yxe,eit,oit,yse,rit,tit,ait,R6,Zxe,nit,sit,xse,lit,iit,dit,P6,Kxe,mit,cit,$se,fit,git,hit,B6,e$e,uit,pit,kse,_it,bit,vit,I6,lso,jc,N6,o$e,vP,Fit,r$e,Tit,iso,vr,FP,Mit,Dc,Eit,Sse,Cit,wit,Rse,Ait,Lit,yit,TP,xit,t$e,$it,kit,Sit,sa,MP,Rit,a$e,Pit,Bit,Gc,Iit,n$e,Nit,qit,Pse,jit,Dit,Git,q6,Oit,Hr,EP,Vit,s$e,Xit,zit,Xn,Qit,l$e,Wit,Uit,i$e,Hit,Jit,d$e,Yit,Zit,Kit,CP,j6,m$e,edt,odt,Bse,rdt,tdt,adt,D6,c$e,ndt,sdt,Ise,ldt,idt,ddt,G6,dso,Oc,O6,f$e,wP,mdt,g$e,cdt,mso,Fr,AP,fdt,Vc,gdt,Nse,hdt,udt,qse,pdt,_dt,bdt,LP,vdt,h$e,Fdt,Tdt,Mdt,la,yP,Edt,u$e,Cdt,wdt,Xc,Adt,p$e,Ldt,ydt,jse,xdt,$dt,kdt,V6,Sdt,Jr,xP,Rdt,_$e,Pdt,Bdt,zn,Idt,b$e,Ndt,qdt,v$e,jdt,Ddt,F$e,Gdt,Odt,Vdt,T$e,X6,M$e,Xdt,zdt,Dse,Qdt,Wdt,Udt,z6,cso,zc,Q6,E$e,$P,Hdt,C$e,Jdt,fso,Tr,kP,Ydt,Qc,Zdt,Gse,Kdt,emt,Ose,omt,rmt,tmt,SP,amt,w$e,nmt,smt,lmt,ia,RP,imt,A$e,dmt,mmt,Wc,cmt,L$e,fmt,gmt,Vse,hmt,umt,pmt,W6,_mt,Yr,PP,bmt,y$e,vmt,Fmt,Qn,Tmt,x$e,Mmt,Emt,$$e,Cmt,wmt,k$e,Amt,Lmt,ymt,S$e,U6,R$e,xmt,$mt,Xse,kmt,Smt,Rmt,H6,gso,Uc,J6,P$e,BP,Pmt,B$e,Bmt,hso,Mr,IP,Imt,Hc,Nmt,zse,qmt,jmt,Qse,Dmt,Gmt,Omt,NP,Vmt,I$e,Xmt,zmt,Qmt,da,qP,Wmt,N$e,Umt,Hmt,Jc,Jmt,q$e,Ymt,Zmt,Wse,Kmt,ect,oct,Y6,rct,Zr,jP,tct,j$e,act,nct,Wn,sct,D$e,lct,ict,G$e,dct,mct,O$e,cct,fct,gct,ie,Z6,V$e,hct,uct,Use,pct,_ct,bct,K6,X$e,vct,Fct,Hse,Tct,Mct,Ect,e7,z$e,Cct,wct,Jse,Act,Lct,yct,o7,Q$e,xct,$ct,Yse,kct,Sct,Rct,r7,W$e,Pct,Bct,Zse,Ict,Nct,qct,t7,U$e,jct,Dct,Kse,Gct,Oct,Vct,a7,H$e,Xct,zct,ele,Qct,Wct,Uct,n7,J$e,Hct,Jct,ole,Yct,Zct,Kct,s7,Y$e,eft,oft,rle,rft,tft,aft,l7,Z$e,nft,sft,tle,lft,ift,dft,i7,K$e,mft,cft,ale,fft,gft,hft,d7,eke,uft,pft,nle,_ft,bft,vft,m7,oke,Fft,Tft,sle,Mft,Eft,Cft,c7,rke,wft,Aft,lle,Lft,yft,xft,f7,tke,$ft,kft,ile,Sft,Rft,Pft,g7,ake,Bft,Ift,dle,Nft,qft,jft,h7,nke,Dft,Gft,mle,Oft,Vft,Xft,u7,ske,zft,Qft,cle,Wft,Uft,Hft,p7,lke,Jft,Yft,fle,Zft,Kft,egt,_7,ike,ogt,rgt,gle,tgt,agt,ngt,b7,dke,sgt,lgt,hle,igt,dgt,mgt,v7,mke,cgt,fgt,ule,ggt,hgt,ugt,F7,uso,Yc,T7,cke,DP,pgt,fke,_gt,pso,Er,GP,bgt,Zc,vgt,ple,Fgt,Tgt,_le,Mgt,Egt,Cgt,OP,wgt,gke,Agt,Lgt,ygt,ma,VP,xgt,hke,$gt,kgt,Kc,Sgt,uke,Rgt,Pgt,ble,Bgt,Igt,Ngt,M7,qgt,Kr,XP,jgt,pke,Dgt,Ggt,Un,Ogt,_ke,Vgt,Xgt,bke,zgt,Qgt,vke,Wgt,Ugt,Hgt,fe,E7,Fke,Jgt,Ygt,vle,Zgt,Kgt,eht,C7,Tke,oht,rht,Fle,tht,aht,nht,w7,Mke,sht,lht,Tle,iht,dht,mht,A7,Eke,cht,fht,Mle,ght,hht,uht,L7,Cke,pht,_ht,Ele,bht,vht,Fht,y7,wke,Tht,Mht,Cle,Eht,Cht,wht,x7,Ake,Aht,Lht,wle,yht,xht,$ht,$7,Lke,kht,Sht,Ale,Rht,Pht,Bht,k7,yke,Iht,Nht,Lle,qht,jht,Dht,S7,xke,Ght,Oht,yle,Vht,Xht,zht,R7,$ke,Qht,Wht,xle,Uht,Hht,Jht,P7,kke,Yht,Zht,$le,Kht,eut,out,B7,Ske,rut,tut,kle,aut,nut,sut,I7,Rke,lut,iut,Sle,dut,mut,cut,N7,Pke,fut,gut,Rle,hut,uut,put,q7,Bke,_ut,but,Ple,vut,Fut,Tut,j7,Ike,Mut,Eut,Ble,Cut,wut,Aut,D7,Nke,Lut,yut,Ile,xut,$ut,kut,G7,qke,Sut,Rut,Nle,Put,But,Iut,O7,jke,Nut,qut,qle,jut,Dut,Gut,V7,Dke,Out,Vut,jle,Xut,zut,Qut,X7,_so,ef,z7,Gke,zP,Wut,Oke,Uut,bso,Cr,QP,Hut,of,Jut,Dle,Yut,Zut,Gle,Kut,ept,opt,WP,rpt,Vke,tpt,apt,npt,ca,UP,spt,Xke,lpt,ipt,rf,dpt,zke,mpt,cpt,Ole,fpt,gpt,hpt,Q7,upt,et,HP,ppt,Qke,_pt,bpt,Hn,vpt,Wke,Fpt,Tpt,Uke,Mpt,Ept,Hke,Cpt,wpt,Apt,Jke,W7,Yke,Lpt,ypt,Vle,xpt,$pt,kpt,U7,vso,tf,H7,Zke,JP,Spt,Kke,Rpt,Fso,wr,YP,Ppt,af,Bpt,Xle,Ipt,Npt,zle,qpt,jpt,Dpt,ZP,Gpt,eSe,Opt,Vpt,Xpt,fa,KP,zpt,oSe,Qpt,Wpt,nf,Upt,rSe,Hpt,Jpt,Qle,Ypt,Zpt,Kpt,J7,e_t,ot,eB,o_t,tSe,r_t,t_t,Jn,a_t,aSe,n_t,s_t,nSe,l_t,i_t,sSe,d_t,m_t,c_t,oB,Y7,lSe,f_t,g_t,Wle,h_t,u_t,p_t,Z7,iSe,__t,b_t,Ule,v_t,F_t,T_t,K7,Tso,sf,e8,dSe,rB,M_t,mSe,E_t,Mso,Ar,tB,C_t,lf,w_t,Hle,A_t,L_t,Jle,y_t,x_t,$_t,aB,k_t,cSe,S_t,R_t,P_t,ga,nB,B_t,fSe,I_t,N_t,df,q_t,gSe,j_t,D_t,Yle,G_t,O_t,V_t,o8,X_t,rt,sB,z_t,hSe,Q_t,W_t,Yn,U_t,uSe,H_t,J_t,pSe,Y_t,Z_t,_Se,K_t,e1t,o1t,te,r8,bSe,r1t,t1t,Zle,a1t,n1t,s1t,t8,vSe,l1t,i1t,Kle,d1t,m1t,c1t,a8,FSe,f1t,g1t,eie,h1t,u1t,p1t,n8,TSe,_1t,b1t,oie,v1t,F1t,T1t,s8,MSe,M1t,E1t,rie,C1t,w1t,A1t,l8,ESe,L1t,y1t,tie,x1t,$1t,k1t,i8,CSe,S1t,R1t,aie,P1t,B1t,I1t,d8,wSe,N1t,q1t,nie,j1t,D1t,G1t,m8,ASe,O1t,V1t,sie,X1t,z1t,Q1t,c8,LSe,W1t,U1t,lie,H1t,J1t,Y1t,f8,ySe,Z1t,K1t,iie,e2t,o2t,r2t,g8,xSe,t2t,a2t,die,n2t,s2t,l2t,h8,$Se,i2t,d2t,mie,m2t,c2t,f2t,u8,kSe,g2t,h2t,cie,u2t,p2t,_2t,p8,SSe,b2t,v2t,fie,F2t,T2t,M2t,_8,RSe,E2t,C2t,gie,w2t,A2t,L2t,b8,PSe,y2t,x2t,hie,$2t,k2t,S2t,v8,BSe,R2t,P2t,uie,B2t,I2t,N2t,F8,ISe,q2t,j2t,pie,D2t,G2t,O2t,T8,NSe,V2t,X2t,_ie,z2t,Q2t,W2t,M8,qSe,U2t,H2t,bie,J2t,Y2t,Z2t,E8,jSe,K2t,ebt,vie,obt,rbt,tbt,C8,DSe,abt,nbt,Fie,sbt,lbt,ibt,w8,GSe,dbt,mbt,Tie,cbt,fbt,gbt,A8,OSe,hbt,ubt,Mie,pbt,_bt,bbt,L8,VSe,vbt,Fbt,Eie,Tbt,Mbt,Ebt,y8,XSe,Cbt,wbt,Cie,Abt,Lbt,ybt,x8,Eso,mf,$8,zSe,lB,xbt,QSe,$bt,Cso,Lr,iB,kbt,cf,Sbt,wie,Rbt,Pbt,Aie,Bbt,Ibt,Nbt,dB,qbt,WSe,jbt,Dbt,Gbt,ha,mB,Obt,USe,Vbt,Xbt,ff,zbt,HSe,Qbt,Wbt,Lie,Ubt,Hbt,Jbt,k8,Ybt,tt,cB,Zbt,JSe,Kbt,evt,Zn,ovt,YSe,rvt,tvt,ZSe,avt,nvt,KSe,svt,lvt,ivt,$e,S8,eRe,dvt,mvt,yie,cvt,fvt,gvt,R8,oRe,hvt,uvt,xie,pvt,_vt,bvt,P8,rRe,vvt,Fvt,$ie,Tvt,Mvt,Evt,B8,tRe,Cvt,wvt,kie,Avt,Lvt,yvt,I8,aRe,xvt,$vt,Sie,kvt,Svt,Rvt,N8,nRe,Pvt,Bvt,Rie,Ivt,Nvt,qvt,q8,sRe,jvt,Dvt,Pie,Gvt,Ovt,Vvt,j8,lRe,Xvt,zvt,Bie,Qvt,Wvt,Uvt,D8,iRe,Hvt,Jvt,Iie,Yvt,Zvt,Kvt,G8,dRe,eFt,oFt,Nie,rFt,tFt,aFt,O8,wso,gf,V8,mRe,fB,nFt,cRe,sFt,Aso,yr,gB,lFt,hf,iFt,qie,dFt,mFt,jie,cFt,fFt,gFt,hB,hFt,fRe,uFt,pFt,_Ft,ua,uB,bFt,gRe,vFt,FFt,uf,TFt,hRe,MFt,EFt,Die,CFt,wFt,AFt,X8,LFt,at,pB,yFt,uRe,xFt,$Ft,Kn,kFt,pRe,SFt,RFt,_Re,PFt,BFt,bRe,IFt,NFt,qFt,Ee,z8,vRe,jFt,DFt,Gie,GFt,OFt,VFt,Q8,FRe,XFt,zFt,Oie,QFt,WFt,UFt,W8,TRe,HFt,JFt,Vie,YFt,ZFt,KFt,U8,MRe,eTt,oTt,Xie,rTt,tTt,aTt,H8,ERe,nTt,sTt,zie,lTt,iTt,dTt,J8,CRe,mTt,cTt,Qie,fTt,gTt,hTt,Y8,wRe,uTt,pTt,Wie,_Tt,bTt,vTt,Z8,ARe,FTt,TTt,Uie,MTt,ETt,CTt,K8,LRe,wTt,ATt,Hie,LTt,yTt,xTt,eL,yRe,$Tt,kTt,Jie,STt,RTt,PTt,oL,xRe,BTt,ITt,Yie,NTt,qTt,jTt,rL,$Re,DTt,GTt,Zie,OTt,VTt,XTt,tL,kRe,zTt,QTt,Kie,WTt,UTt,HTt,aL,Lso,pf,nL,SRe,_B,JTt,RRe,YTt,yso,xr,bB,ZTt,_f,KTt,ede,eMt,oMt,ode,rMt,tMt,aMt,vB,nMt,PRe,sMt,lMt,iMt,pa,FB,dMt,BRe,mMt,cMt,bf,fMt,IRe,gMt,hMt,rde,uMt,pMt,_Mt,sL,bMt,nt,TB,vMt,NRe,FMt,TMt,es,MMt,qRe,EMt,CMt,jRe,wMt,AMt,DRe,LMt,yMt,xMt,ke,lL,GRe,$Mt,kMt,tde,SMt,RMt,PMt,iL,ORe,BMt,IMt,ade,NMt,qMt,jMt,dL,VRe,DMt,GMt,nde,OMt,VMt,XMt,mL,XRe,zMt,QMt,sde,WMt,UMt,HMt,cL,zRe,JMt,YMt,lde,ZMt,KMt,eEt,fL,QRe,oEt,rEt,ide,tEt,aEt,nEt,gL,WRe,sEt,lEt,dde,iEt,dEt,mEt,hL,URe,cEt,fEt,mde,gEt,hEt,uEt,uL,HRe,pEt,_Et,cde,bEt,vEt,FEt,pL,JRe,TEt,MEt,fde,EEt,CEt,wEt,_L,xso,vf,bL,YRe,MB,AEt,ZRe,LEt,$so,$r,EB,yEt,Ff,xEt,gde,$Et,kEt,hde,SEt,REt,PEt,CB,BEt,KRe,IEt,NEt,qEt,_a,wB,jEt,ePe,DEt,GEt,Tf,OEt,oPe,VEt,XEt,ude,zEt,QEt,WEt,vL,UEt,st,AB,HEt,rPe,JEt,YEt,os,ZEt,tPe,KEt,e4t,aPe,o4t,r4t,nPe,t4t,a4t,n4t,Se,FL,sPe,s4t,l4t,pde,i4t,d4t,m4t,TL,lPe,c4t,f4t,_de,g4t,h4t,u4t,ML,iPe,p4t,_4t,bde,b4t,v4t,F4t,EL,dPe,T4t,M4t,vde,E4t,C4t,w4t,CL,mPe,A4t,L4t,Fde,y4t,x4t,$4t,wL,cPe,k4t,S4t,Tde,R4t,P4t,B4t,AL,fPe,I4t,N4t,Mde,q4t,j4t,D4t,LL,gPe,G4t,O4t,Ede,V4t,X4t,z4t,yL,hPe,Q4t,W4t,Cde,U4t,H4t,J4t,xL,uPe,Y4t,Z4t,wde,K4t,eCt,oCt,$L,kso,Mf,kL,pPe,LB,rCt,_Pe,tCt,Sso,kr,yB,aCt,Ef,nCt,Ade,sCt,lCt,Lde,iCt,dCt,mCt,xB,cCt,bPe,fCt,gCt,hCt,ba,$B,uCt,vPe,pCt,_Ct,Cf,bCt,FPe,vCt,FCt,yde,TCt,MCt,ECt,SL,CCt,lt,kB,wCt,TPe,ACt,LCt,rs,yCt,MPe,xCt,$Ct,EPe,kCt,SCt,CPe,RCt,PCt,BCt,Re,RL,wPe,ICt,NCt,xde,qCt,jCt,DCt,PL,APe,GCt,OCt,$de,VCt,XCt,zCt,BL,LPe,QCt,WCt,kde,UCt,HCt,JCt,IL,yPe,YCt,ZCt,Sde,KCt,e3t,o3t,NL,xPe,r3t,t3t,Rde,a3t,n3t,s3t,qL,$Pe,l3t,i3t,Pde,d3t,m3t,c3t,jL,kPe,f3t,g3t,Bde,h3t,u3t,p3t,DL,SPe,_3t,b3t,Ide,v3t,F3t,T3t,GL,RPe,M3t,E3t,Nde,C3t,w3t,A3t,OL,PPe,L3t,y3t,qde,x3t,$3t,k3t,VL,Rso,wf,XL,BPe,SB,S3t,IPe,R3t,Pso,Sr,RB,P3t,Af,B3t,jde,I3t,N3t,Dde,q3t,j3t,D3t,PB,G3t,NPe,O3t,V3t,X3t,va,BB,z3t,qPe,Q3t,W3t,Lf,U3t,jPe,H3t,J3t,Gde,Y3t,Z3t,K3t,zL,e5t,it,IB,o5t,DPe,r5t,t5t,ts,a5t,GPe,n5t,s5t,OPe,l5t,i5t,VPe,d5t,m5t,c5t,Pe,QL,XPe,f5t,g5t,Ode,h5t,u5t,p5t,WL,zPe,_5t,b5t,Vde,v5t,F5t,T5t,UL,QPe,M5t,E5t,Xde,C5t,w5t,A5t,HL,WPe,L5t,y5t,zde,x5t,$5t,k5t,JL,UPe,S5t,R5t,Qde,P5t,B5t,I5t,YL,HPe,N5t,q5t,Wde,j5t,D5t,G5t,ZL,JPe,O5t,V5t,Ude,X5t,z5t,Q5t,KL,YPe,W5t,U5t,Hde,H5t,J5t,Y5t,ey,ZPe,Z5t,K5t,Jde,e0t,o0t,r0t,oy,KPe,t0t,a0t,Yde,n0t,s0t,l0t,ry,Bso,yf,ty,eBe,NB,i0t,oBe,d0t,Iso,Rr,qB,m0t,xf,c0t,Zde,f0t,g0t,Kde,h0t,u0t,p0t,jB,_0t,rBe,b0t,v0t,F0t,Fa,DB,T0t,tBe,M0t,E0t,$f,C0t,aBe,w0t,A0t,eme,L0t,y0t,x0t,ay,$0t,dt,GB,k0t,nBe,S0t,R0t,as,P0t,sBe,B0t,I0t,lBe,N0t,q0t,iBe,j0t,D0t,G0t,ze,ny,dBe,O0t,V0t,ome,X0t,z0t,Q0t,sy,mBe,W0t,U0t,rme,H0t,J0t,Y0t,ly,cBe,Z0t,K0t,tme,ewt,owt,rwt,iy,fBe,twt,awt,ame,nwt,swt,lwt,dy,gBe,iwt,dwt,nme,mwt,cwt,fwt,my,hBe,gwt,hwt,sme,uwt,pwt,_wt,cy,uBe,bwt,vwt,lme,Fwt,Twt,Mwt,fy,pBe,Ewt,Cwt,ime,wwt,Awt,Lwt,gy,Nso,kf,hy,_Be,OB,ywt,bBe,xwt,qso,Pr,VB,$wt,Sf,kwt,dme,Swt,Rwt,mme,Pwt,Bwt,Iwt,XB,Nwt,vBe,qwt,jwt,Dwt,Ta,zB,Gwt,FBe,Owt,Vwt,Rf,Xwt,TBe,zwt,Qwt,cme,Wwt,Uwt,Hwt,uy,Jwt,mt,QB,Ywt,MBe,Zwt,Kwt,ns,eAt,EBe,oAt,rAt,CBe,tAt,aAt,wBe,nAt,sAt,lAt,Qe,py,ABe,iAt,dAt,fme,mAt,cAt,fAt,_y,LBe,gAt,hAt,gme,uAt,pAt,_At,by,yBe,bAt,vAt,hme,FAt,TAt,MAt,vy,xBe,EAt,CAt,ume,wAt,AAt,LAt,Fy,$Be,yAt,xAt,pme,$At,kAt,SAt,Ty,kBe,RAt,PAt,_me,BAt,IAt,NAt,My,SBe,qAt,jAt,bme,DAt,GAt,OAt,Ey,RBe,VAt,XAt,vme,zAt,QAt,WAt,Cy,jso,Pf,wy,PBe,WB,UAt,BBe,HAt,Dso,Br,UB,JAt,Bf,YAt,Fme,ZAt,KAt,Tme,e6t,o6t,r6t,HB,t6t,IBe,a6t,n6t,s6t,Ma,JB,l6t,NBe,i6t,d6t,If,m6t,qBe,c6t,f6t,Mme,g6t,h6t,u6t,Ay,p6t,ct,YB,_6t,jBe,b6t,v6t,ss,F6t,DBe,T6t,M6t,GBe,E6t,C6t,OBe,w6t,A6t,L6t,VBe,Ly,XBe,y6t,x6t,Eme,$6t,k6t,S6t,yy,Gso,Nf,xy,zBe,ZB,R6t,QBe,P6t,Oso,Ir,KB,B6t,qf,I6t,Cme,N6t,q6t,wme,j6t,D6t,G6t,eI,O6t,WBe,V6t,X6t,z6t,Ea,oI,Q6t,UBe,W6t,U6t,jf,H6t,HBe,J6t,Y6t,Ame,Z6t,K6t,e7t,$y,o7t,ft,rI,r7t,JBe,t7t,a7t,ls,n7t,YBe,s7t,l7t,ZBe,i7t,d7t,KBe,m7t,c7t,f7t,tI,ky,eIe,g7t,h7t,Lme,u7t,p7t,_7t,Sy,oIe,b7t,v7t,yme,F7t,T7t,M7t,Ry,Vso,Df,Py,rIe,aI,E7t,tIe,C7t,Xso,Nr,nI,w7t,Gf,A7t,xme,L7t,y7t,$me,x7t,$7t,k7t,sI,S7t,aIe,R7t,P7t,B7t,Ca,lI,I7t,nIe,N7t,q7t,Of,j7t,sIe,D7t,G7t,kme,O7t,V7t,X7t,By,z7t,gt,iI,Q7t,lIe,W7t,U7t,is,H7t,iIe,J7t,Y7t,dIe,Z7t,K7t,mIe,e8t,o8t,r8t,cIe,Iy,fIe,t8t,a8t,Sme,n8t,s8t,l8t,Ny,zso;return m=new oe({}),on=new B({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),E$=new oe({}),C$=new B({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),Yf=new i8t({props:{warning:!0,$$slots:{default:[Cwa]},$$scope:{ctx:$}}}),w$=new oe({}),A$=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L671"}}),x$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L694"}}),yu=new q({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[wwa]},$$scope:{ctx:$}}}),$$=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L817"}}),k$=new oe({}),S$=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L449"}}),B$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/main/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L463"}}),gp=new q({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[Awa]},$$scope:{ctx:$}}}),I$=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L664"}}),N$=new oe({}),q$=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L205"}}),G$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/main/en/internal/image_processing_utils#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L219"}}),l_=new i8t({props:{$$slots:{default:[Lwa]},$$scope:{ctx:$}}}),i_=new q({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[ywa]},$$scope:{ctx:$}}}),O$=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L346"}}),V$=new oe({}),X$=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L96"}}),W$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L110"}}),P_=new i8t({props:{$$slots:{default:[xwa]},$$scope:{ctx:$}}}),B_=new q({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[$wa]},$$scope:{ctx:$}}}),U$=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L277"}}),H$=new oe({}),J$=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L898"}}),Z$=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clipseg#transformers.CLIPSegConfig">CLIPSegConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clipseg#transformers.CLIPSegModel">CLIPSegModel</a> (CLIPSeg model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel">CodeGenModel</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig">ConditionalDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrModel">ConditionalDetrModel</a> (Conditional DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrModel">DeformableDetrModel</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig">DonutSwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel">DonutSwinModel</a> (DonutSwin model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel">ErnieModel</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmModel">EsmModel</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig">GPTNeoXJapaneseConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel">GPTNeoXJapaneseModel</a> (GPT NeoX Japanese model)</li>
<li><a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel">GroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltModel">LiltModel</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMModel">MarkupLMModel</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel">MobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel">MvpModel</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel">NezhaModel</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel">OwlViTModel</a> (OWL-ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel">PegasusXModel</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertModel">RoCBertModel</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model">Swinv2Model</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerConfig">TableTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerModel">TableTransformerModel</a> (Table Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig">TimeSeriesTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel">TimeSeriesTransformerModel</a> (Time Series Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig">ViTMSNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNModel">ViTMSNModel</a> (ViTMSN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel">VideoMAEModel</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperModel">WhisperModel</a> (Whisper model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig">XCLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel">XCLIPModel</a> (X-CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),q_=new q({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[kwa]},$$scope:{ctx:$}}}),K$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),ib=new q({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[Swa]},$$scope:{ctx:$}}}),ek=new oe({}),ok=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L905"}}),tk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining">ErnieForPreTraining</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining">NezhaForPreTraining</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForPreTraining">RoCBertForPreTraining</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining">VideoMAEForPreTraining</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),mb=new q({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[Rwa]},$$scope:{ctx:$}}}),ak=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),lv=new q({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[Pwa]},$$scope:{ctx:$}}}),nk=new oe({}),sk=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L920"}}),ik=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM">CodeGenForCausalLM</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM">ErnieForCausalLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig">GPTNeoXJapaneseConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM">GPTNeoXJapaneseForCausalLM</a> (GPT NeoX Japanese model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM">MvpForCausalLM</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForCausalLM">RoCBertForCausalLM</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),dv=new q({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[Bwa]},$$scope:{ctx:$}}}),dk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),eF=new q({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[Iwa]},$$scope:{ctx:$}}}),mk=new oe({}),ck=new R({props:{name:"class transformers.AutoModelForDepthEstimation",anchor:"transformers.AutoModelForDepthEstimation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1063"}}),gk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForDepthEstimation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDepthEstimation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTForDepthEstimation">DPTForDepthEstimation</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNForDepthEstimation">GLPNForDepthEstimation</a> (GLPN model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),rF=new q({props:{anchor:"transformers.AutoModelForDepthEstimation.from_config.example",$$slots:{default:[Nwa]},$$scope:{ctx:$}}}),hk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForDepthEstimation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),sF=new q({props:{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.example",$$slots:{default:[qwa]},$$scope:{ctx:$}}}),pk=new oe({}),_k=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L927"}}),vk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM">ErnieForMaskedLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM">NezhaForMaskedLM</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForMaskedLM">RoCBertForMaskedLM</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),iF=new q({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[jwa]},$$scope:{ctx:$}}}),Fk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),JF=new q({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[Dwa]},$$scope:{ctx:$}}}),Tk=new oe({}),Mk=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L934"}}),Ck=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration">PegasusXForConditionalGeneration</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),ZF=new q({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[Gwa]},$$scope:{ctx:$}}}),wk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),FT=new q({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[Owa]},$$scope:{ctx:$}}}),Ak=new oe({}),Lk=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L943"}}),xk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification">ErnieForSequenceClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmForSequenceClassification">EsmForSequenceClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltForSequenceClassification">LiltForSequenceClassification</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification">LukeForSequenceClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification">MarkupLMForSequenceClassification</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification">MvpForSequenceClassification</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification">NezhaForSequenceClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification">OPTForSequenceClassification</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForSequenceClassification">RoCBertForSequenceClassification</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),MT=new q({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[Vwa]},$$scope:{ctx:$}}}),$k=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),LM=new q({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[Xwa]},$$scope:{ctx:$}}}),kk=new oe({}),Sk=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L999"}}),Pk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice">ErnieForMultipleChoice</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice">LukeForMultipleChoice</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice">NezhaForMultipleChoice</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForMultipleChoice">RoCBertForMultipleChoice</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),xM=new q({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[zwa]},$$scope:{ctx:$}}}),Bk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),mE=new q({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[Qwa]},$$scope:{ctx:$}}}),Ik=new oe({}),Nk=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1006"}}),jk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction">ErnieForNextSentencePrediction</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction">NezhaForNextSentencePrediction</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),fE=new q({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[Wwa]},$$scope:{ctx:$}}}),Dk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),TE=new q({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[Uwa]},$$scope:{ctx:$}}}),Gk=new oe({}),Ok=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L992"}}),Xk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification">ErnieForTokenClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmForTokenClassification">EsmForTokenClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltForTokenClassification">LiltForTokenClassification</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification">LukeForTokenClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification">MarkupLMForTokenClassification</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification">NezhaForTokenClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForTokenClassification">RoCBertForTokenClassification</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),EE=new q({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[Hwa]},$$scope:{ctx:$}}}),zk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),g4=new q({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[Jwa]},$$scope:{ctx:$}}}),Qk=new oe({}),Wk=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L952"}}),Hk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForQuestionAnswering">BloomForQuestionAnswering</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering">ErnieForQuestionAnswering</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltForQuestionAnswering">LiltForQuestionAnswering</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering">LukeForQuestionAnswering</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering">MarkupLMForQuestionAnswering</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering">MvpForQuestionAnswering</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering">NezhaForQuestionAnswering</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForQuestionAnswering">OPTForQuestionAnswering</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForQuestionAnswering">RoCBertForQuestionAnswering</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),u4=new q({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[Ywa]},$$scope:{ctx:$}}}),Jk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),fC=new q({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[Zwa]},$$scope:{ctx:$}}}),Yk=new oe({}),Zk=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L959"}}),eS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),hC=new q({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[Kwa]},$$scope:{ctx:$}}}),oS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),_C=new q({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[eAa]},$$scope:{ctx:$}}}),rS=new oe({}),tS=new R({props:{name:"class transformers.AutoModelForDocumentQuestionAnswering",anchor:"transformers.AutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L981"}}),nS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering">LayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),vC=new q({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[oAa]},$$scope:{ctx:$}}}),sS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),CC=new q({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[rAa]},$$scope:{ctx:$}}}),lS=new oe({}),iS=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1015"}}),mS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification">MobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification">Swinv2ForImageClassification</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig">ViTMSNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification">ViTMSNForImageClassification</a> (ViTMSN model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),AC=new q({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[tAa]},$$scope:{ctx:$}}}),cS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),VC=new q({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[aAa]},$$scope:{ctx:$}}}),fS=new oe({}),gS=new R({props:{name:"class transformers.AutoModelForVideoClassification",anchor:"transformers.AutoModelForVideoClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1070"}}),uS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVideoClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification">VideoMAEForVideoClassification</a> (VideoMAE model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),zC=new q({props:{anchor:"transformers.AutoModelForVideoClassification.from_config.example",$$slots:{default:[nAa]},$$scope:{ctx:$}}}),pS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVideoClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),UC=new q({props:{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.example",$$slots:{default:[sAa]},$$scope:{ctx:$}}}),_S=new oe({}),bS=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1077"}}),FS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),JC=new q({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[lAa]},$$scope:{ctx:$}}}),TS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),KC=new q({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[iAa]},$$scope:{ctx:$}}}),MS=new oe({}),ES=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L970"}}),wS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),o3=new q({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[dAa]},$$scope:{ctx:$}}}),AS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),a3=new q({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[mAa]},$$scope:{ctx:$}}}),LS=new oe({}),yS=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1084"}}),$S=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),s3=new q({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[cAa]},$$scope:{ctx:$}}}),kS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),_3=new q({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[fAa]},$$scope:{ctx:$}}}),SS=new oe({}),RS=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1107"}}),BS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),v3=new q({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[gAa]},$$scope:{ctx:$}}}),IS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),A3=new q({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[hAa]},$$scope:{ctx:$}}}),NS=new oe({}),qS=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1091"}}),DS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),y3=new q({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[uAa]},$$scope:{ctx:$}}}),GS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),D3=new q({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[pAa]},$$scope:{ctx:$}}}),OS=new oe({}),VS=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1098"}}),zS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperForConditionalGeneration">WhisperForConditionalGeneration</a> (Whisper model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),O3=new q({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[_Aa]},$$scope:{ctx:$}}}),QS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),W3=new q({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[bAa]},$$scope:{ctx:$}}}),WS=new oe({}),US=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1116"}}),JS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),H3=new q({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[vAa]},$$scope:{ctx:$}}}),YS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),r5=new q({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[FAa]},$$scope:{ctx:$}}}),ZS=new oe({}),KS=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1123"}}),oR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling">Swinv2ForMaskedImageModeling</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),a5=new q({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[TAa]},$$scope:{ctx:$}}}),rR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),m5=new q({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[MAa]},$$scope:{ctx:$}}}),tR=new oe({}),aR=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1047"}}),sR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig">ConditionalDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection">ConditionalDetrForObjectDetection</a> (Conditional DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection">DeformableDetrForObjectDetection</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerConfig">TableTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerForObjectDetection">TableTransformerForObjectDetection</a> (Table Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),f5=new q({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[EAa]},$$scope:{ctx:$}}}),lR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),v5=new q({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[CAa]},$$scope:{ctx:$}}}),iR=new oe({}),dR=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1022"}}),cR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),T5=new q({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[wAa]},$$scope:{ctx:$}}}),fR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),C5=new q({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[AAa]},$$scope:{ctx:$}}}),gR=new oe({}),hR=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1029"}}),pR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation">MobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),A5=new q({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[LAa]},$$scope:{ctx:$}}}),_R=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),R5=new q({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[yAa]},$$scope:{ctx:$}}}),bR=new oe({}),vR=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1038"}}),TR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),B5=new q({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[xAa]},$$scope:{ctx:$}}}),MR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),q5=new q({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[$Aa]},$$scope:{ctx:$}}}),ER=new oe({}),CR=new R({props:{name:"class transformers.AutoModelForZeroShotObjectDetection",anchor:"transformers.AutoModelForZeroShotObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1054"}}),AR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTForObjectDetection">OwlViTForObjectDetection</a> (OWL-ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),D5=new q({props:{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config.example",$$slots:{default:[kAa]},$$scope:{ctx:$}}}),LR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),V5=new q({props:{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.example",$$slots:{default:[SAa]},$$scope:{ctx:$}}}),yR=new oe({}),xR=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L444"}}),kR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtModel">TFCvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel">TFDeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmModel">TFEsmModel</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/groupvit#transformers.TFGroupViTModel">TFGroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model">TFLayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel">TFMobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel">TFRegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel">TFResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel">TFSegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperModel">TFWhisperModel</a> (Whisper model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel">TFXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),z5=new q({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[RAa]},$$scope:{ctx:$}}}),SR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),H0=new q({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[PAa]},$$scope:{ctx:$}}}),RR=new oe({}),PR=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L451"}}),IR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Y0=new q({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[BAa]},$$scope:{ctx:$}}}),NR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Tw=new q({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[IAa]},$$scope:{ctx:$}}}),qR=new oe({}),jR=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L466"}}),GR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM">TFXGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Ew=new q({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[NAa]},$$scope:{ctx:$}}}),OR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),qw=new q({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[qAa]},$$scope:{ctx:$}}}),VR=new oe({}),XR=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L482"}}),QR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtForImageClassification">TFCvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification">TFDeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher">TFDeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification">TFMobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification">TFRegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification">TFResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification">TFSegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Dw=new q({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[jAa]},$$scope:{ctx:$}}}),WR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Jw=new q({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[DAa]},$$scope:{ctx:$}}}),UR=new oe({}),HR=new R({props:{name:"class transformers.TFAutoModelForSemanticSegmentation",anchor:"transformers.TFAutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L491"}}),YR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation">TFData2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation">TFMobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation">TFSegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Zw=new q({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[GAa]},$$scope:{ctx:$}}}),ZR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),rA=new q({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[OAa]},$$scope:{ctx:$}}}),KR=new oe({}),eP=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L507"}}),rP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForMaskedLM">TFEsmForMaskedLM</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),aA=new q({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[VAa]},$$scope:{ctx:$}}}),tP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),AA=new q({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[XAa]},$$scope:{ctx:$}}}),aP=new oe({}),nP=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L514"}}),lP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),yA=new q({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[zAa]},$$scope:{ctx:$}}}),iP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),jA=new q({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[QAa]},$$scope:{ctx:$}}}),dP=new oe({}),mP=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L523"}}),fP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForSequenceClassification">TFEsmForSequenceClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification">TFLayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),GA=new q({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[WAa]},$$scope:{ctx:$}}}),gP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),p6=new q({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[UAa]},$$scope:{ctx:$}}}),hP=new oe({}),uP=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L570"}}),_P=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),b6=new q({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[HAa]},$$scope:{ctx:$}}}),bP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),I6=new q({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[JAa]},$$scope:{ctx:$}}}),vP=new oe({}),FP=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L577"}}),MP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),q6=new q({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[YAa]},$$scope:{ctx:$}}}),EP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),G6=new q({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[ZAa]},$$scope:{ctx:$}}}),wP=new oe({}),AP=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L550"}}),yP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),V6=new q({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[KAa]},$$scope:{ctx:$}}}),xP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),z6=new q({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[e6a]},$$scope:{ctx:$}}}),$P=new oe({}),kP=new R({props:{name:"class transformers.TFAutoModelForDocumentQuestionAnswering",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L539"}}),RP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering">TFLayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),W6=new q({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[o6a]},$$scope:{ctx:$}}}),PP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),H6=new q({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[r6a]},$$scope:{ctx:$}}}),BP=new oe({}),IP=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L561"}}),qP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForTokenClassification">TFEsmForTokenClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification">TFLayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Y6=new q({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[t6a]},$$scope:{ctx:$}}}),jP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),F7=new q({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[a6a]},$$scope:{ctx:$}}}),DP=new oe({}),GP=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L532"}}),VP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering">TFLayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),M7=new q({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[n6a]},$$scope:{ctx:$}}}),XP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),X7=new q({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[s6a]},$$scope:{ctx:$}}}),zP=new oe({}),QP=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L500"}}),UP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Q7=new q({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[l6a]},$$scope:{ctx:$}}}),HP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),U7=new q({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[i6a]},$$scope:{ctx:$}}}),JP=new oe({}),YP=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L586"}}),KP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration">TFWhisperForConditionalGeneration</a> (Whisper model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),J7=new q({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[d6a]},$$scope:{ctx:$}}}),eB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),K7=new q({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[m6a]},$$scope:{ctx:$}}}),rB=new oe({}),tB=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),nB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),o8=new q({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[c6a]},$$scope:{ctx:$}}}),sB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),x8=new q({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[f6a]},$$scope:{ctx:$}}}),lB=new oe({}),iB=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L260"}}),mB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),k8=new q({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[g6a]},$$scope:{ctx:$}}}),cB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),O8=new q({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[h6a]},$$scope:{ctx:$}}}),fB=new oe({}),gB=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L253"}}),uB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),X8=new q({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[u6a]},$$scope:{ctx:$}}}),pB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),aL=new q({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[p6a]},$$scope:{ctx:$}}}),_B=new oe({}),bB=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L267"}}),FB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),sL=new q({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[_6a]},$$scope:{ctx:$}}}),TB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),_L=new q({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[b6a]},$$scope:{ctx:$}}}),MB=new oe({}),EB=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),wB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),vL=new q({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[v6a]},$$scope:{ctx:$}}}),AB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),$L=new q({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[F6a]},$$scope:{ctx:$}}}),LB=new oe({}),yB=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),$B=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),SL=new q({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[T6a]},$$scope:{ctx:$}}}),kB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),VL=new q({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[M6a]},$$scope:{ctx:$}}}),SB=new oe({}),RB=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),BB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),zL=new q({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[E6a]},$$scope:{ctx:$}}}),IB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),ry=new q({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[C6a]},$$scope:{ctx:$}}}),NB=new oe({}),qB=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),DB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),ay=new q({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[w6a]},$$scope:{ctx:$}}}),GB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),gy=new q({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[A6a]},$$scope:{ctx:$}}}),OB=new oe({}),VB=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L308"}}),zB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),uy=new q({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[L6a]},$$scope:{ctx:$}}}),QB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Cy=new q({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[y6a]},$$scope:{ctx:$}}}),WB=new oe({}),UB=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),JB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Ay=new q({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[x6a]},$$scope:{ctx:$}}}),YB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),yy=new q({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[$6a]},$$scope:{ctx:$}}}),ZB=new oe({}),KB=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),oI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),$y=new q({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[k6a]},$$scope:{ctx:$}}}),rI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Ry=new q({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[S6a]},$$scope:{ctx:$}}}),aI=new oe({}),nI=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),lI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),By=new q({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[R6a]},$$scope:{ctx:$}}}),iI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Ny=new q({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[P6a]},$$scope:{ctx:$}}}),{c(){g=a("meta"),v=l(),u=a("h1"),f=a("a"),p=a("span"),F(m.$$.fragment),h=l(),$o=a("span"),vd=o("Auto Classes"),Qf=l(),Tt=a("p"),Fd=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Td=a("code"),v$=o("from_pretrained()"),Wf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Xe=l(),He=a("p"),Md=o("Instantiating one of "),ms=a("a"),F$=o("AutoConfig"),cs=o(", "),fs=a("a"),T$=o("AutoModel"),Ed=o(`, and
`),gs=a("a"),M$=o("AutoTokenizer"),Cd=o(" will directly create a class of the relevant architecture. For instance"),Uf=l(),F(on.$$.fragment),Je=l(),Ae=a("p"),NN=o("will create a model that is an instance of "),wd=a("a"),qN=o("BertModel"),jN=o("."),ko=l(),rn=a("p"),DN=o("There is one class of "),Hf=a("code"),GN=o("AutoModel"),gdo=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),yao=l(),Ad=a("h2"),Jf=a("a"),Gfe=a("span"),F(E$.$$.fragment),hdo=l(),Ofe=a("span"),udo=o("Extending the Auto Classes"),xao=l(),hs=a("p"),pdo=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),Vfe=a("code"),_do=o("NewModel"),bdo=o(", make sure you have a "),Xfe=a("code"),vdo=o("NewModelConfig"),Fdo=o(` then you can add those to the auto
classes like this:`),$ao=l(),F(C$.$$.fragment),kao=l(),ON=a("p"),Tdo=o("You will then be able to use the auto classes like you would usually do!"),Sao=l(),F(Yf.$$.fragment),Rao=l(),Ld=a("h2"),Zf=a("a"),zfe=a("span"),F(w$.$$.fragment),Mdo=l(),Qfe=a("span"),Edo=o("AutoConfig"),Pao=l(),So=a("div"),F(A$.$$.fragment),Cdo=l(),L$=a("p"),wdo=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),VN=a("a"),Ado=o("from_pretrained()"),Ldo=o(" class method."),ydo=l(),y$=a("p"),xdo=o("This class cannot be instantiated directly using "),Wfe=a("code"),$do=o("__init__()"),kdo=o(" (throws an error)."),Sdo=l(),qr=a("div"),F(x$.$$.fragment),Rdo=l(),Ufe=a("p"),Pdo=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),Bdo=l(),yd=a("p"),Ido=o("The configuration class to instantiate is selected based on the "),Hfe=a("code"),Ndo=o("model_type"),qdo=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Jfe=a("code"),jdo=o("pretrained_model_name_or_path"),Ddo=o(":"),Gdo=l(),A=a("ul"),Kf=a("li"),Yfe=a("strong"),Odo=o("albert"),Vdo=o(" \u2014 "),XN=a("a"),Xdo=o("AlbertConfig"),zdo=o(" (ALBERT model)"),Qdo=l(),eg=a("li"),Zfe=a("strong"),Wdo=o("bart"),Udo=o(" \u2014 "),zN=a("a"),Hdo=o("BartConfig"),Jdo=o(" (BART model)"),Ydo=l(),og=a("li"),Kfe=a("strong"),Zdo=o("beit"),Kdo=o(" \u2014 "),QN=a("a"),emo=o("BeitConfig"),omo=o(" (BEiT model)"),rmo=l(),rg=a("li"),ege=a("strong"),tmo=o("bert"),amo=o(" \u2014 "),WN=a("a"),nmo=o("BertConfig"),smo=o(" (BERT model)"),lmo=l(),tg=a("li"),oge=a("strong"),imo=o("bert-generation"),dmo=o(" \u2014 "),UN=a("a"),mmo=o("BertGenerationConfig"),cmo=o(" (Bert Generation model)"),fmo=l(),ag=a("li"),rge=a("strong"),gmo=o("big_bird"),hmo=o(" \u2014 "),HN=a("a"),umo=o("BigBirdConfig"),pmo=o(" (BigBird model)"),_mo=l(),ng=a("li"),tge=a("strong"),bmo=o("bigbird_pegasus"),vmo=o(" \u2014 "),JN=a("a"),Fmo=o("BigBirdPegasusConfig"),Tmo=o(" (BigBird-Pegasus model)"),Mmo=l(),sg=a("li"),age=a("strong"),Emo=o("blenderbot"),Cmo=o(" \u2014 "),YN=a("a"),wmo=o("BlenderbotConfig"),Amo=o(" (Blenderbot model)"),Lmo=l(),lg=a("li"),nge=a("strong"),ymo=o("blenderbot-small"),xmo=o(" \u2014 "),ZN=a("a"),$mo=o("BlenderbotSmallConfig"),kmo=o(" (BlenderbotSmall model)"),Smo=l(),ig=a("li"),sge=a("strong"),Rmo=o("bloom"),Pmo=o(" \u2014 "),KN=a("a"),Bmo=o("BloomConfig"),Imo=o(" (BLOOM model)"),Nmo=l(),dg=a("li"),lge=a("strong"),qmo=o("camembert"),jmo=o(" \u2014 "),eq=a("a"),Dmo=o("CamembertConfig"),Gmo=o(" (CamemBERT model)"),Omo=l(),mg=a("li"),ige=a("strong"),Vmo=o("canine"),Xmo=o(" \u2014 "),oq=a("a"),zmo=o("CanineConfig"),Qmo=o(" (CANINE model)"),Wmo=l(),cg=a("li"),dge=a("strong"),Umo=o("clip"),Hmo=o(" \u2014 "),rq=a("a"),Jmo=o("CLIPConfig"),Ymo=o(" (CLIP model)"),Zmo=l(),fg=a("li"),mge=a("strong"),Kmo=o("clipseg"),eco=o(" \u2014 "),tq=a("a"),oco=o("CLIPSegConfig"),rco=o(" (CLIPSeg model)"),tco=l(),gg=a("li"),cge=a("strong"),aco=o("codegen"),nco=o(" \u2014 "),aq=a("a"),sco=o("CodeGenConfig"),lco=o(" (CodeGen model)"),ico=l(),hg=a("li"),fge=a("strong"),dco=o("conditional_detr"),mco=o(" \u2014 "),nq=a("a"),cco=o("ConditionalDetrConfig"),fco=o(" (Conditional DETR model)"),gco=l(),ug=a("li"),gge=a("strong"),hco=o("convbert"),uco=o(" \u2014 "),sq=a("a"),pco=o("ConvBertConfig"),_co=o(" (ConvBERT model)"),bco=l(),pg=a("li"),hge=a("strong"),vco=o("convnext"),Fco=o(" \u2014 "),lq=a("a"),Tco=o("ConvNextConfig"),Mco=o(" (ConvNeXT model)"),Eco=l(),_g=a("li"),uge=a("strong"),Cco=o("ctrl"),wco=o(" \u2014 "),iq=a("a"),Aco=o("CTRLConfig"),Lco=o(" (CTRL model)"),yco=l(),bg=a("li"),pge=a("strong"),xco=o("cvt"),$co=o(" \u2014 "),dq=a("a"),kco=o("CvtConfig"),Sco=o(" (CvT model)"),Rco=l(),vg=a("li"),_ge=a("strong"),Pco=o("data2vec-audio"),Bco=o(" \u2014 "),mq=a("a"),Ico=o("Data2VecAudioConfig"),Nco=o(" (Data2VecAudio model)"),qco=l(),Fg=a("li"),bge=a("strong"),jco=o("data2vec-text"),Dco=o(" \u2014 "),cq=a("a"),Gco=o("Data2VecTextConfig"),Oco=o(" (Data2VecText model)"),Vco=l(),Tg=a("li"),vge=a("strong"),Xco=o("data2vec-vision"),zco=o(" \u2014 "),fq=a("a"),Qco=o("Data2VecVisionConfig"),Wco=o(" (Data2VecVision model)"),Uco=l(),Mg=a("li"),Fge=a("strong"),Hco=o("deberta"),Jco=o(" \u2014 "),gq=a("a"),Yco=o("DebertaConfig"),Zco=o(" (DeBERTa model)"),Kco=l(),Eg=a("li"),Tge=a("strong"),efo=o("deberta-v2"),ofo=o(" \u2014 "),hq=a("a"),rfo=o("DebertaV2Config"),tfo=o(" (DeBERTa-v2 model)"),afo=l(),Cg=a("li"),Mge=a("strong"),nfo=o("decision_transformer"),sfo=o(" \u2014 "),uq=a("a"),lfo=o("DecisionTransformerConfig"),ifo=o(" (Decision Transformer model)"),dfo=l(),wg=a("li"),Ege=a("strong"),mfo=o("deformable_detr"),cfo=o(" \u2014 "),pq=a("a"),ffo=o("DeformableDetrConfig"),gfo=o(" (Deformable DETR model)"),hfo=l(),Ag=a("li"),Cge=a("strong"),ufo=o("deit"),pfo=o(" \u2014 "),_q=a("a"),_fo=o("DeiTConfig"),bfo=o(" (DeiT model)"),vfo=l(),Lg=a("li"),wge=a("strong"),Ffo=o("detr"),Tfo=o(" \u2014 "),bq=a("a"),Mfo=o("DetrConfig"),Efo=o(" (DETR model)"),Cfo=l(),yg=a("li"),Age=a("strong"),wfo=o("distilbert"),Afo=o(" \u2014 "),vq=a("a"),Lfo=o("DistilBertConfig"),yfo=o(" (DistilBERT model)"),xfo=l(),xg=a("li"),Lge=a("strong"),$fo=o("donut-swin"),kfo=o(" \u2014 "),Fq=a("a"),Sfo=o("DonutSwinConfig"),Rfo=o(" (DonutSwin model)"),Pfo=l(),$g=a("li"),yge=a("strong"),Bfo=o("dpr"),Ifo=o(" \u2014 "),Tq=a("a"),Nfo=o("DPRConfig"),qfo=o(" (DPR model)"),jfo=l(),kg=a("li"),xge=a("strong"),Dfo=o("dpt"),Gfo=o(" \u2014 "),Mq=a("a"),Ofo=o("DPTConfig"),Vfo=o(" (DPT model)"),Xfo=l(),Sg=a("li"),$ge=a("strong"),zfo=o("electra"),Qfo=o(" \u2014 "),Eq=a("a"),Wfo=o("ElectraConfig"),Ufo=o(" (ELECTRA model)"),Hfo=l(),Rg=a("li"),kge=a("strong"),Jfo=o("encoder-decoder"),Yfo=o(" \u2014 "),Cq=a("a"),Zfo=o("EncoderDecoderConfig"),Kfo=o(" (Encoder decoder model)"),ego=l(),Pg=a("li"),Sge=a("strong"),ogo=o("ernie"),rgo=o(" \u2014 "),wq=a("a"),tgo=o("ErnieConfig"),ago=o(" (ERNIE model)"),ngo=l(),Bg=a("li"),Rge=a("strong"),sgo=o("esm"),lgo=o(" \u2014 "),Aq=a("a"),igo=o("EsmConfig"),dgo=o(" (ESM model)"),mgo=l(),Ig=a("li"),Pge=a("strong"),cgo=o("flaubert"),fgo=o(" \u2014 "),Lq=a("a"),ggo=o("FlaubertConfig"),hgo=o(" (FlauBERT model)"),ugo=l(),Ng=a("li"),Bge=a("strong"),pgo=o("flava"),_go=o(" \u2014 "),yq=a("a"),bgo=o("FlavaConfig"),vgo=o(" (FLAVA model)"),Fgo=l(),qg=a("li"),Ige=a("strong"),Tgo=o("fnet"),Mgo=o(" \u2014 "),xq=a("a"),Ego=o("FNetConfig"),Cgo=o(" (FNet model)"),wgo=l(),jg=a("li"),Nge=a("strong"),Ago=o("fsmt"),Lgo=o(" \u2014 "),$q=a("a"),ygo=o("FSMTConfig"),xgo=o(" (FairSeq Machine-Translation model)"),$go=l(),Dg=a("li"),qge=a("strong"),kgo=o("funnel"),Sgo=o(" \u2014 "),kq=a("a"),Rgo=o("FunnelConfig"),Pgo=o(" (Funnel Transformer model)"),Bgo=l(),Gg=a("li"),jge=a("strong"),Igo=o("glpn"),Ngo=o(" \u2014 "),Sq=a("a"),qgo=o("GLPNConfig"),jgo=o(" (GLPN model)"),Dgo=l(),Og=a("li"),Dge=a("strong"),Ggo=o("gpt2"),Ogo=o(" \u2014 "),Rq=a("a"),Vgo=o("GPT2Config"),Xgo=o(" (OpenAI GPT-2 model)"),zgo=l(),Vg=a("li"),Gge=a("strong"),Qgo=o("gpt_neo"),Wgo=o(" \u2014 "),Pq=a("a"),Ugo=o("GPTNeoConfig"),Hgo=o(" (GPT Neo model)"),Jgo=l(),Xg=a("li"),Oge=a("strong"),Ygo=o("gpt_neox"),Zgo=o(" \u2014 "),Bq=a("a"),Kgo=o("GPTNeoXConfig"),eho=o(" (GPT NeoX model)"),oho=l(),zg=a("li"),Vge=a("strong"),rho=o("gpt_neox_japanese"),tho=o(" \u2014 "),Iq=a("a"),aho=o("GPTNeoXJapaneseConfig"),nho=o(" (GPT NeoX Japanese model)"),sho=l(),Qg=a("li"),Xge=a("strong"),lho=o("gptj"),iho=o(" \u2014 "),Nq=a("a"),dho=o("GPTJConfig"),mho=o(" (GPT-J model)"),cho=l(),Wg=a("li"),zge=a("strong"),fho=o("groupvit"),gho=o(" \u2014 "),qq=a("a"),hho=o("GroupViTConfig"),uho=o(" (GroupViT model)"),pho=l(),Ug=a("li"),Qge=a("strong"),_ho=o("hubert"),bho=o(" \u2014 "),jq=a("a"),vho=o("HubertConfig"),Fho=o(" (Hubert model)"),Tho=l(),Hg=a("li"),Wge=a("strong"),Mho=o("ibert"),Eho=o(" \u2014 "),Dq=a("a"),Cho=o("IBertConfig"),who=o(" (I-BERT model)"),Aho=l(),Jg=a("li"),Uge=a("strong"),Lho=o("imagegpt"),yho=o(" \u2014 "),Gq=a("a"),xho=o("ImageGPTConfig"),$ho=o(" (ImageGPT model)"),kho=l(),Yg=a("li"),Hge=a("strong"),Sho=o("layoutlm"),Rho=o(" \u2014 "),Oq=a("a"),Pho=o("LayoutLMConfig"),Bho=o(" (LayoutLM model)"),Iho=l(),Zg=a("li"),Jge=a("strong"),Nho=o("layoutlmv2"),qho=o(" \u2014 "),Vq=a("a"),jho=o("LayoutLMv2Config"),Dho=o(" (LayoutLMv2 model)"),Gho=l(),Kg=a("li"),Yge=a("strong"),Oho=o("layoutlmv3"),Vho=o(" \u2014 "),Xq=a("a"),Xho=o("LayoutLMv3Config"),zho=o(" (LayoutLMv3 model)"),Qho=l(),eh=a("li"),Zge=a("strong"),Who=o("led"),Uho=o(" \u2014 "),zq=a("a"),Hho=o("LEDConfig"),Jho=o(" (LED model)"),Yho=l(),oh=a("li"),Kge=a("strong"),Zho=o("levit"),Kho=o(" \u2014 "),Qq=a("a"),euo=o("LevitConfig"),ouo=o(" (LeViT model)"),ruo=l(),rh=a("li"),ehe=a("strong"),tuo=o("lilt"),auo=o(" \u2014 "),Wq=a("a"),nuo=o("LiltConfig"),suo=o(" (LiLT model)"),luo=l(),th=a("li"),ohe=a("strong"),iuo=o("longformer"),duo=o(" \u2014 "),Uq=a("a"),muo=o("LongformerConfig"),cuo=o(" (Longformer model)"),fuo=l(),ah=a("li"),rhe=a("strong"),guo=o("longt5"),huo=o(" \u2014 "),Hq=a("a"),uuo=o("LongT5Config"),puo=o(" (LongT5 model)"),_uo=l(),nh=a("li"),the=a("strong"),buo=o("luke"),vuo=o(" \u2014 "),Jq=a("a"),Fuo=o("LukeConfig"),Tuo=o(" (LUKE model)"),Muo=l(),sh=a("li"),ahe=a("strong"),Euo=o("lxmert"),Cuo=o(" \u2014 "),Yq=a("a"),wuo=o("LxmertConfig"),Auo=o(" (LXMERT model)"),Luo=l(),lh=a("li"),nhe=a("strong"),yuo=o("m2m_100"),xuo=o(" \u2014 "),Zq=a("a"),$uo=o("M2M100Config"),kuo=o(" (M2M100 model)"),Suo=l(),ih=a("li"),she=a("strong"),Ruo=o("marian"),Puo=o(" \u2014 "),Kq=a("a"),Buo=o("MarianConfig"),Iuo=o(" (Marian model)"),Nuo=l(),dh=a("li"),lhe=a("strong"),quo=o("markuplm"),juo=o(" \u2014 "),ej=a("a"),Duo=o("MarkupLMConfig"),Guo=o(" (MarkupLM model)"),Ouo=l(),mh=a("li"),ihe=a("strong"),Vuo=o("maskformer"),Xuo=o(" \u2014 "),oj=a("a"),zuo=o("MaskFormerConfig"),Quo=o(" (MaskFormer model)"),Wuo=l(),ch=a("li"),dhe=a("strong"),Uuo=o("mbart"),Huo=o(" \u2014 "),rj=a("a"),Juo=o("MBartConfig"),Yuo=o(" (mBART model)"),Zuo=l(),fh=a("li"),mhe=a("strong"),Kuo=o("mctct"),epo=o(" \u2014 "),tj=a("a"),opo=o("MCTCTConfig"),rpo=o(" (M-CTC-T model)"),tpo=l(),gh=a("li"),che=a("strong"),apo=o("megatron-bert"),npo=o(" \u2014 "),aj=a("a"),spo=o("MegatronBertConfig"),lpo=o(" (Megatron-BERT model)"),ipo=l(),hh=a("li"),fhe=a("strong"),dpo=o("mobilebert"),mpo=o(" \u2014 "),nj=a("a"),cpo=o("MobileBertConfig"),fpo=o(" (MobileBERT model)"),gpo=l(),uh=a("li"),ghe=a("strong"),hpo=o("mobilevit"),upo=o(" \u2014 "),sj=a("a"),ppo=o("MobileViTConfig"),_po=o(" (MobileViT model)"),bpo=l(),ph=a("li"),hhe=a("strong"),vpo=o("mpnet"),Fpo=o(" \u2014 "),lj=a("a"),Tpo=o("MPNetConfig"),Mpo=o(" (MPNet model)"),Epo=l(),_h=a("li"),uhe=a("strong"),Cpo=o("mt5"),wpo=o(" \u2014 "),ij=a("a"),Apo=o("MT5Config"),Lpo=o(" (MT5 model)"),ypo=l(),bh=a("li"),phe=a("strong"),xpo=o("mvp"),$po=o(" \u2014 "),dj=a("a"),kpo=o("MvpConfig"),Spo=o(" (MVP model)"),Rpo=l(),vh=a("li"),_he=a("strong"),Ppo=o("nezha"),Bpo=o(" \u2014 "),mj=a("a"),Ipo=o("NezhaConfig"),Npo=o(" (Nezha model)"),qpo=l(),Fh=a("li"),bhe=a("strong"),jpo=o("nystromformer"),Dpo=o(" \u2014 "),cj=a("a"),Gpo=o("NystromformerConfig"),Opo=o(" (Nystr\xF6mformer model)"),Vpo=l(),Th=a("li"),vhe=a("strong"),Xpo=o("openai-gpt"),zpo=o(" \u2014 "),fj=a("a"),Qpo=o("OpenAIGPTConfig"),Wpo=o(" (OpenAI GPT model)"),Upo=l(),Mh=a("li"),Fhe=a("strong"),Hpo=o("opt"),Jpo=o(" \u2014 "),gj=a("a"),Ypo=o("OPTConfig"),Zpo=o(" (OPT model)"),Kpo=l(),Eh=a("li"),The=a("strong"),e_o=o("owlvit"),o_o=o(" \u2014 "),hj=a("a"),r_o=o("OwlViTConfig"),t_o=o(" (OWL-ViT model)"),a_o=l(),Ch=a("li"),Mhe=a("strong"),n_o=o("pegasus"),s_o=o(" \u2014 "),uj=a("a"),l_o=o("PegasusConfig"),i_o=o(" (Pegasus model)"),d_o=l(),wh=a("li"),Ehe=a("strong"),m_o=o("pegasus_x"),c_o=o(" \u2014 "),pj=a("a"),f_o=o("PegasusXConfig"),g_o=o(" (PEGASUS-X model)"),h_o=l(),Ah=a("li"),Che=a("strong"),u_o=o("perceiver"),p_o=o(" \u2014 "),_j=a("a"),__o=o("PerceiverConfig"),b_o=o(" (Perceiver model)"),v_o=l(),Lh=a("li"),whe=a("strong"),F_o=o("plbart"),T_o=o(" \u2014 "),bj=a("a"),M_o=o("PLBartConfig"),E_o=o(" (PLBart model)"),C_o=l(),yh=a("li"),Ahe=a("strong"),w_o=o("poolformer"),A_o=o(" \u2014 "),vj=a("a"),L_o=o("PoolFormerConfig"),y_o=o(" (PoolFormer model)"),x_o=l(),xh=a("li"),Lhe=a("strong"),$_o=o("prophetnet"),k_o=o(" \u2014 "),Fj=a("a"),S_o=o("ProphetNetConfig"),R_o=o(" (ProphetNet model)"),P_o=l(),$h=a("li"),yhe=a("strong"),B_o=o("qdqbert"),I_o=o(" \u2014 "),Tj=a("a"),N_o=o("QDQBertConfig"),q_o=o(" (QDQBert model)"),j_o=l(),kh=a("li"),xhe=a("strong"),D_o=o("rag"),G_o=o(" \u2014 "),Mj=a("a"),O_o=o("RagConfig"),V_o=o(" (RAG model)"),X_o=l(),Sh=a("li"),$he=a("strong"),z_o=o("realm"),Q_o=o(" \u2014 "),Ej=a("a"),W_o=o("RealmConfig"),U_o=o(" (REALM model)"),H_o=l(),Rh=a("li"),khe=a("strong"),J_o=o("reformer"),Y_o=o(" \u2014 "),Cj=a("a"),Z_o=o("ReformerConfig"),K_o=o(" (Reformer model)"),e1o=l(),Ph=a("li"),She=a("strong"),o1o=o("regnet"),r1o=o(" \u2014 "),wj=a("a"),t1o=o("RegNetConfig"),a1o=o(" (RegNet model)"),n1o=l(),Bh=a("li"),Rhe=a("strong"),s1o=o("rembert"),l1o=o(" \u2014 "),Aj=a("a"),i1o=o("RemBertConfig"),d1o=o(" (RemBERT model)"),m1o=l(),Ih=a("li"),Phe=a("strong"),c1o=o("resnet"),f1o=o(" \u2014 "),Lj=a("a"),g1o=o("ResNetConfig"),h1o=o(" (ResNet model)"),u1o=l(),Nh=a("li"),Bhe=a("strong"),p1o=o("retribert"),_1o=o(" \u2014 "),yj=a("a"),b1o=o("RetriBertConfig"),v1o=o(" (RetriBERT model)"),F1o=l(),qh=a("li"),Ihe=a("strong"),T1o=o("roberta"),M1o=o(" \u2014 "),xj=a("a"),E1o=o("RobertaConfig"),C1o=o(" (RoBERTa model)"),w1o=l(),jh=a("li"),Nhe=a("strong"),A1o=o("roc_bert"),L1o=o(" \u2014 "),$j=a("a"),y1o=o("RoCBertConfig"),x1o=o(" (RoCBert model)"),$1o=l(),Dh=a("li"),qhe=a("strong"),k1o=o("roformer"),S1o=o(" \u2014 "),kj=a("a"),R1o=o("RoFormerConfig"),P1o=o(" (RoFormer model)"),B1o=l(),Gh=a("li"),jhe=a("strong"),I1o=o("segformer"),N1o=o(" \u2014 "),Sj=a("a"),q1o=o("SegformerConfig"),j1o=o(" (SegFormer model)"),D1o=l(),Oh=a("li"),Dhe=a("strong"),G1o=o("sew"),O1o=o(" \u2014 "),Rj=a("a"),V1o=o("SEWConfig"),X1o=o(" (SEW model)"),z1o=l(),Vh=a("li"),Ghe=a("strong"),Q1o=o("sew-d"),W1o=o(" \u2014 "),Pj=a("a"),U1o=o("SEWDConfig"),H1o=o(" (SEW-D model)"),J1o=l(),Xh=a("li"),Ohe=a("strong"),Y1o=o("speech-encoder-decoder"),Z1o=o(" \u2014 "),Bj=a("a"),K1o=o("SpeechEncoderDecoderConfig"),e2o=o(" (Speech Encoder decoder model)"),o2o=l(),zh=a("li"),Vhe=a("strong"),r2o=o("speech_to_text"),t2o=o(" \u2014 "),Ij=a("a"),a2o=o("Speech2TextConfig"),n2o=o(" (Speech2Text model)"),s2o=l(),Qh=a("li"),Xhe=a("strong"),l2o=o("speech_to_text_2"),i2o=o(" \u2014 "),Nj=a("a"),d2o=o("Speech2Text2Config"),m2o=o(" (Speech2Text2 model)"),c2o=l(),Wh=a("li"),zhe=a("strong"),f2o=o("splinter"),g2o=o(" \u2014 "),qj=a("a"),h2o=o("SplinterConfig"),u2o=o(" (Splinter model)"),p2o=l(),Uh=a("li"),Qhe=a("strong"),_2o=o("squeezebert"),b2o=o(" \u2014 "),jj=a("a"),v2o=o("SqueezeBertConfig"),F2o=o(" (SqueezeBERT model)"),T2o=l(),Hh=a("li"),Whe=a("strong"),M2o=o("swin"),E2o=o(" \u2014 "),Dj=a("a"),C2o=o("SwinConfig"),w2o=o(" (Swin Transformer model)"),A2o=l(),Jh=a("li"),Uhe=a("strong"),L2o=o("swinv2"),y2o=o(" \u2014 "),Gj=a("a"),x2o=o("Swinv2Config"),$2o=o(" (Swin Transformer V2 model)"),k2o=l(),Yh=a("li"),Hhe=a("strong"),S2o=o("t5"),R2o=o(" \u2014 "),Oj=a("a"),P2o=o("T5Config"),B2o=o(" (T5 model)"),I2o=l(),Zh=a("li"),Jhe=a("strong"),N2o=o("table-transformer"),q2o=o(" \u2014 "),Vj=a("a"),j2o=o("TableTransformerConfig"),D2o=o(" (Table Transformer model)"),G2o=l(),Kh=a("li"),Yhe=a("strong"),O2o=o("tapas"),V2o=o(" \u2014 "),Xj=a("a"),X2o=o("TapasConfig"),z2o=o(" (TAPAS model)"),Q2o=l(),eu=a("li"),Zhe=a("strong"),W2o=o("time_series_transformer"),U2o=o(" \u2014 "),zj=a("a"),H2o=o("TimeSeriesTransformerConfig"),J2o=o(" (Time Series Transformer model)"),Y2o=l(),ou=a("li"),Khe=a("strong"),Z2o=o("trajectory_transformer"),K2o=o(" \u2014 "),Qj=a("a"),ebo=o("TrajectoryTransformerConfig"),obo=o(" (Trajectory Transformer model)"),rbo=l(),ru=a("li"),eue=a("strong"),tbo=o("transfo-xl"),abo=o(" \u2014 "),Wj=a("a"),nbo=o("TransfoXLConfig"),sbo=o(" (Transformer-XL model)"),lbo=l(),tu=a("li"),oue=a("strong"),ibo=o("trocr"),dbo=o(" \u2014 "),Uj=a("a"),mbo=o("TrOCRConfig"),cbo=o(" (TrOCR model)"),fbo=l(),au=a("li"),rue=a("strong"),gbo=o("unispeech"),hbo=o(" \u2014 "),Hj=a("a"),ubo=o("UniSpeechConfig"),pbo=o(" (UniSpeech model)"),_bo=l(),nu=a("li"),tue=a("strong"),bbo=o("unispeech-sat"),vbo=o(" \u2014 "),Jj=a("a"),Fbo=o("UniSpeechSatConfig"),Tbo=o(" (UniSpeechSat model)"),Mbo=l(),su=a("li"),aue=a("strong"),Ebo=o("van"),Cbo=o(" \u2014 "),Yj=a("a"),wbo=o("VanConfig"),Abo=o(" (VAN model)"),Lbo=l(),lu=a("li"),nue=a("strong"),ybo=o("videomae"),xbo=o(" \u2014 "),Zj=a("a"),$bo=o("VideoMAEConfig"),kbo=o(" (VideoMAE model)"),Sbo=l(),iu=a("li"),sue=a("strong"),Rbo=o("vilt"),Pbo=o(" \u2014 "),Kj=a("a"),Bbo=o("ViltConfig"),Ibo=o(" (ViLT model)"),Nbo=l(),du=a("li"),lue=a("strong"),qbo=o("vision-encoder-decoder"),jbo=o(" \u2014 "),eD=a("a"),Dbo=o("VisionEncoderDecoderConfig"),Gbo=o(" (Vision Encoder decoder model)"),Obo=l(),mu=a("li"),iue=a("strong"),Vbo=o("vision-text-dual-encoder"),Xbo=o(" \u2014 "),oD=a("a"),zbo=o("VisionTextDualEncoderConfig"),Qbo=o(" (VisionTextDualEncoder model)"),Wbo=l(),cu=a("li"),due=a("strong"),Ubo=o("visual_bert"),Hbo=o(" \u2014 "),rD=a("a"),Jbo=o("VisualBertConfig"),Ybo=o(" (VisualBERT model)"),Zbo=l(),fu=a("li"),mue=a("strong"),Kbo=o("vit"),evo=o(" \u2014 "),tD=a("a"),ovo=o("ViTConfig"),rvo=o(" (ViT model)"),tvo=l(),gu=a("li"),cue=a("strong"),avo=o("vit_mae"),nvo=o(" \u2014 "),aD=a("a"),svo=o("ViTMAEConfig"),lvo=o(" (ViTMAE model)"),ivo=l(),hu=a("li"),fue=a("strong"),dvo=o("vit_msn"),mvo=o(" \u2014 "),nD=a("a"),cvo=o("ViTMSNConfig"),fvo=o(" (ViTMSN model)"),gvo=l(),uu=a("li"),gue=a("strong"),hvo=o("wav2vec2"),uvo=o(" \u2014 "),sD=a("a"),pvo=o("Wav2Vec2Config"),_vo=o(" (Wav2Vec2 model)"),bvo=l(),pu=a("li"),hue=a("strong"),vvo=o("wav2vec2-conformer"),Fvo=o(" \u2014 "),lD=a("a"),Tvo=o("Wav2Vec2ConformerConfig"),Mvo=o(" (Wav2Vec2-Conformer model)"),Evo=l(),_u=a("li"),uue=a("strong"),Cvo=o("wavlm"),wvo=o(" \u2014 "),iD=a("a"),Avo=o("WavLMConfig"),Lvo=o(" (WavLM model)"),yvo=l(),bu=a("li"),pue=a("strong"),xvo=o("whisper"),$vo=o(" \u2014 "),dD=a("a"),kvo=o("WhisperConfig"),Svo=o(" (Whisper model)"),Rvo=l(),vu=a("li"),_ue=a("strong"),Pvo=o("xclip"),Bvo=o(" \u2014 "),mD=a("a"),Ivo=o("XCLIPConfig"),Nvo=o(" (X-CLIP model)"),qvo=l(),Fu=a("li"),bue=a("strong"),jvo=o("xglm"),Dvo=o(" \u2014 "),cD=a("a"),Gvo=o("XGLMConfig"),Ovo=o(" (XGLM model)"),Vvo=l(),Tu=a("li"),vue=a("strong"),Xvo=o("xlm"),zvo=o(" \u2014 "),fD=a("a"),Qvo=o("XLMConfig"),Wvo=o(" (XLM model)"),Uvo=l(),Mu=a("li"),Fue=a("strong"),Hvo=o("xlm-prophetnet"),Jvo=o(" \u2014 "),gD=a("a"),Yvo=o("XLMProphetNetConfig"),Zvo=o(" (XLM-ProphetNet model)"),Kvo=l(),Eu=a("li"),Tue=a("strong"),eFo=o("xlm-roberta"),oFo=o(" \u2014 "),hD=a("a"),rFo=o("XLMRobertaConfig"),tFo=o(" (XLM-RoBERTa model)"),aFo=l(),Cu=a("li"),Mue=a("strong"),nFo=o("xlm-roberta-xl"),sFo=o(" \u2014 "),uD=a("a"),lFo=o("XLMRobertaXLConfig"),iFo=o(" (XLM-RoBERTa-XL model)"),dFo=l(),wu=a("li"),Eue=a("strong"),mFo=o("xlnet"),cFo=o(" \u2014 "),pD=a("a"),fFo=o("XLNetConfig"),gFo=o(" (XLNet model)"),hFo=l(),Au=a("li"),Cue=a("strong"),uFo=o("yolos"),pFo=o(" \u2014 "),_D=a("a"),_Fo=o("YolosConfig"),bFo=o(" (YOLOS model)"),vFo=l(),Lu=a("li"),wue=a("strong"),FFo=o("yoso"),TFo=o(" \u2014 "),bD=a("a"),MFo=o("YosoConfig"),EFo=o(" (YOSO model)"),CFo=l(),F(yu.$$.fragment),wFo=l(),xu=a("div"),F($$.$$.fragment),AFo=l(),Aue=a("p"),LFo=o("Register a new configuration for this class."),Bao=l(),xd=a("h2"),$u=a("a"),Lue=a("span"),F(k$.$$.fragment),yFo=l(),yue=a("span"),xFo=o("AutoTokenizer"),Iao=l(),Ro=a("div"),F(S$.$$.fragment),$Fo=l(),R$=a("p"),kFo=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),vD=a("a"),SFo=o("AutoTokenizer.from_pretrained()"),RFo=o(" class method."),PFo=l(),P$=a("p"),BFo=o("This class cannot be instantiated directly using "),xue=a("code"),IFo=o("__init__()"),NFo=o(" (throws an error)."),qFo=l(),jr=a("div"),F(B$.$$.fragment),jFo=l(),$ue=a("p"),DFo=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),GFo=l(),tn=a("p"),OFo=o("The tokenizer class to instantiate is selected based on the "),kue=a("code"),VFo=o("model_type"),XFo=o(` property of the config object (either
passed as an argument or loaded from `),Sue=a("code"),zFo=o("pretrained_model_name_or_path"),QFo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rue=a("code"),WFo=o("pretrained_model_name_or_path"),UFo=o(":"),HFo=l(),k=a("ul"),us=a("li"),Pue=a("strong"),JFo=o("albert"),YFo=o(" \u2014 "),FD=a("a"),ZFo=o("AlbertTokenizer"),KFo=o(" or "),TD=a("a"),eTo=o("AlbertTokenizerFast"),oTo=o(" (ALBERT model)"),rTo=l(),ps=a("li"),Bue=a("strong"),tTo=o("bart"),aTo=o(" \u2014 "),MD=a("a"),nTo=o("BartTokenizer"),sTo=o(" or "),ED=a("a"),lTo=o("BartTokenizerFast"),iTo=o(" (BART model)"),dTo=l(),_s=a("li"),Iue=a("strong"),mTo=o("barthez"),cTo=o(" \u2014 "),CD=a("a"),fTo=o("BarthezTokenizer"),gTo=o(" or "),wD=a("a"),hTo=o("BarthezTokenizerFast"),uTo=o(" (BARThez model)"),pTo=l(),ku=a("li"),Nue=a("strong"),_To=o("bartpho"),bTo=o(" \u2014 "),AD=a("a"),vTo=o("BartphoTokenizer"),FTo=o(" (BARTpho model)"),TTo=l(),bs=a("li"),que=a("strong"),MTo=o("bert"),ETo=o(" \u2014 "),LD=a("a"),CTo=o("BertTokenizer"),wTo=o(" or "),yD=a("a"),ATo=o("BertTokenizerFast"),LTo=o(" (BERT model)"),yTo=l(),Su=a("li"),jue=a("strong"),xTo=o("bert-generation"),$To=o(" \u2014 "),xD=a("a"),kTo=o("BertGenerationTokenizer"),STo=o(" (Bert Generation model)"),RTo=l(),Ru=a("li"),Due=a("strong"),PTo=o("bert-japanese"),BTo=o(" \u2014 "),$D=a("a"),ITo=o("BertJapaneseTokenizer"),NTo=o(" (BertJapanese model)"),qTo=l(),Pu=a("li"),Gue=a("strong"),jTo=o("bertweet"),DTo=o(" \u2014 "),kD=a("a"),GTo=o("BertweetTokenizer"),OTo=o(" (BERTweet model)"),VTo=l(),vs=a("li"),Oue=a("strong"),XTo=o("big_bird"),zTo=o(" \u2014 "),SD=a("a"),QTo=o("BigBirdTokenizer"),WTo=o(" or "),RD=a("a"),UTo=o("BigBirdTokenizerFast"),HTo=o(" (BigBird model)"),JTo=l(),Fs=a("li"),Vue=a("strong"),YTo=o("bigbird_pegasus"),ZTo=o(" \u2014 "),PD=a("a"),KTo=o("PegasusTokenizer"),eMo=o(" or "),BD=a("a"),oMo=o("PegasusTokenizerFast"),rMo=o(" (BigBird-Pegasus model)"),tMo=l(),Ts=a("li"),Xue=a("strong"),aMo=o("blenderbot"),nMo=o(" \u2014 "),ID=a("a"),sMo=o("BlenderbotTokenizer"),lMo=o(" or "),ND=a("a"),iMo=o("BlenderbotTokenizerFast"),dMo=o(" (Blenderbot model)"),mMo=l(),Bu=a("li"),zue=a("strong"),cMo=o("blenderbot-small"),fMo=o(" \u2014 "),qD=a("a"),gMo=o("BlenderbotSmallTokenizer"),hMo=o(" (BlenderbotSmall model)"),uMo=l(),Iu=a("li"),Que=a("strong"),pMo=o("bloom"),_Mo=o(" \u2014 "),jD=a("a"),bMo=o("BloomTokenizerFast"),vMo=o(" (BLOOM model)"),FMo=l(),Nu=a("li"),Wue=a("strong"),TMo=o("byt5"),MMo=o(" \u2014 "),DD=a("a"),EMo=o("ByT5Tokenizer"),CMo=o(" (ByT5 model)"),wMo=l(),Ms=a("li"),Uue=a("strong"),AMo=o("camembert"),LMo=o(" \u2014 "),GD=a("a"),yMo=o("CamembertTokenizer"),xMo=o(" or "),OD=a("a"),$Mo=o("CamembertTokenizerFast"),kMo=o(" (CamemBERT model)"),SMo=l(),qu=a("li"),Hue=a("strong"),RMo=o("canine"),PMo=o(" \u2014 "),VD=a("a"),BMo=o("CanineTokenizer"),IMo=o(" (CANINE model)"),NMo=l(),Es=a("li"),Jue=a("strong"),qMo=o("clip"),jMo=o(" \u2014 "),XD=a("a"),DMo=o("CLIPTokenizer"),GMo=o(" or "),zD=a("a"),OMo=o("CLIPTokenizerFast"),VMo=o(" (CLIP model)"),XMo=l(),Cs=a("li"),Yue=a("strong"),zMo=o("clipseg"),QMo=o(" \u2014 "),QD=a("a"),WMo=o("CLIPTokenizer"),UMo=o(" or "),WD=a("a"),HMo=o("CLIPTokenizerFast"),JMo=o(" (CLIPSeg model)"),YMo=l(),ws=a("li"),Zue=a("strong"),ZMo=o("codegen"),KMo=o(" \u2014 "),UD=a("a"),eEo=o("CodeGenTokenizer"),oEo=o(" or "),HD=a("a"),rEo=o("CodeGenTokenizerFast"),tEo=o(" (CodeGen model)"),aEo=l(),As=a("li"),Kue=a("strong"),nEo=o("convbert"),sEo=o(" \u2014 "),JD=a("a"),lEo=o("ConvBertTokenizer"),iEo=o(" or "),YD=a("a"),dEo=o("ConvBertTokenizerFast"),mEo=o(" (ConvBERT model)"),cEo=l(),Ls=a("li"),epe=a("strong"),fEo=o("cpm"),gEo=o(" \u2014 "),ZD=a("a"),hEo=o("CpmTokenizer"),uEo=o(" or "),KD=a("a"),pEo=o("CpmTokenizerFast"),_Eo=o(" (CPM model)"),bEo=l(),ju=a("li"),ope=a("strong"),vEo=o("ctrl"),FEo=o(" \u2014 "),eG=a("a"),TEo=o("CTRLTokenizer"),MEo=o(" (CTRL model)"),EEo=l(),ys=a("li"),rpe=a("strong"),CEo=o("data2vec-text"),wEo=o(" \u2014 "),oG=a("a"),AEo=o("RobertaTokenizer"),LEo=o(" or "),rG=a("a"),yEo=o("RobertaTokenizerFast"),xEo=o(" (Data2VecText model)"),$Eo=l(),xs=a("li"),tpe=a("strong"),kEo=o("deberta"),SEo=o(" \u2014 "),tG=a("a"),REo=o("DebertaTokenizer"),PEo=o(" or "),aG=a("a"),BEo=o("DebertaTokenizerFast"),IEo=o(" (DeBERTa model)"),NEo=l(),$s=a("li"),ape=a("strong"),qEo=o("deberta-v2"),jEo=o(" \u2014 "),nG=a("a"),DEo=o("DebertaV2Tokenizer"),GEo=o(" or "),sG=a("a"),OEo=o("DebertaV2TokenizerFast"),VEo=o(" (DeBERTa-v2 model)"),XEo=l(),ks=a("li"),npe=a("strong"),zEo=o("distilbert"),QEo=o(" \u2014 "),lG=a("a"),WEo=o("DistilBertTokenizer"),UEo=o(" or "),iG=a("a"),HEo=o("DistilBertTokenizerFast"),JEo=o(" (DistilBERT model)"),YEo=l(),Ss=a("li"),spe=a("strong"),ZEo=o("dpr"),KEo=o(" \u2014 "),dG=a("a"),e4o=o("DPRQuestionEncoderTokenizer"),o4o=o(" or "),mG=a("a"),r4o=o("DPRQuestionEncoderTokenizerFast"),t4o=o(" (DPR model)"),a4o=l(),Rs=a("li"),lpe=a("strong"),n4o=o("electra"),s4o=o(" \u2014 "),cG=a("a"),l4o=o("ElectraTokenizer"),i4o=o(" or "),fG=a("a"),d4o=o("ElectraTokenizerFast"),m4o=o(" (ELECTRA model)"),c4o=l(),Ps=a("li"),ipe=a("strong"),f4o=o("ernie"),g4o=o(" \u2014 "),gG=a("a"),h4o=o("BertTokenizer"),u4o=o(" or "),hG=a("a"),p4o=o("BertTokenizerFast"),_4o=o(" (ERNIE model)"),b4o=l(),Du=a("li"),dpe=a("strong"),v4o=o("esm"),F4o=o(" \u2014 "),uG=a("a"),T4o=o("EsmTokenizer"),M4o=o(" (ESM model)"),E4o=l(),Gu=a("li"),mpe=a("strong"),C4o=o("flaubert"),w4o=o(" \u2014 "),pG=a("a"),A4o=o("FlaubertTokenizer"),L4o=o(" (FlauBERT model)"),y4o=l(),Bs=a("li"),cpe=a("strong"),x4o=o("fnet"),$4o=o(" \u2014 "),_G=a("a"),k4o=o("FNetTokenizer"),S4o=o(" or "),bG=a("a"),R4o=o("FNetTokenizerFast"),P4o=o(" (FNet model)"),B4o=l(),Ou=a("li"),fpe=a("strong"),I4o=o("fsmt"),N4o=o(" \u2014 "),vG=a("a"),q4o=o("FSMTTokenizer"),j4o=o(" (FairSeq Machine-Translation model)"),D4o=l(),Is=a("li"),gpe=a("strong"),G4o=o("funnel"),O4o=o(" \u2014 "),FG=a("a"),V4o=o("FunnelTokenizer"),X4o=o(" or "),TG=a("a"),z4o=o("FunnelTokenizerFast"),Q4o=o(" (Funnel Transformer model)"),W4o=l(),Ns=a("li"),hpe=a("strong"),U4o=o("gpt2"),H4o=o(" \u2014 "),MG=a("a"),J4o=o("GPT2Tokenizer"),Y4o=o(" or "),EG=a("a"),Z4o=o("GPT2TokenizerFast"),K4o=o(" (OpenAI GPT-2 model)"),eCo=l(),qs=a("li"),upe=a("strong"),oCo=o("gpt_neo"),rCo=o(" \u2014 "),CG=a("a"),tCo=o("GPT2Tokenizer"),aCo=o(" or "),wG=a("a"),nCo=o("GPT2TokenizerFast"),sCo=o(" (GPT Neo model)"),lCo=l(),Vu=a("li"),ppe=a("strong"),iCo=o("gpt_neox"),dCo=o(" \u2014 "),AG=a("a"),mCo=o("GPTNeoXTokenizerFast"),cCo=o(" (GPT NeoX model)"),fCo=l(),Xu=a("li"),_pe=a("strong"),gCo=o("gpt_neox_japanese"),hCo=o(" \u2014 "),LG=a("a"),uCo=o("GPTNeoXJapaneseTokenizer"),pCo=o(" (GPT NeoX Japanese model)"),_Co=l(),js=a("li"),bpe=a("strong"),bCo=o("gptj"),vCo=o(" \u2014 "),yG=a("a"),FCo=o("GPT2Tokenizer"),TCo=o(" or "),xG=a("a"),MCo=o("GPT2TokenizerFast"),ECo=o(" (GPT-J model)"),CCo=l(),Ds=a("li"),vpe=a("strong"),wCo=o("groupvit"),ACo=o(" \u2014 "),$G=a("a"),LCo=o("CLIPTokenizer"),yCo=o(" or "),kG=a("a"),xCo=o("CLIPTokenizerFast"),$Co=o(" (GroupViT model)"),kCo=l(),Gs=a("li"),Fpe=a("strong"),SCo=o("herbert"),RCo=o(" \u2014 "),SG=a("a"),PCo=o("HerbertTokenizer"),BCo=o(" or "),RG=a("a"),ICo=o("HerbertTokenizerFast"),NCo=o(" (HerBERT model)"),qCo=l(),zu=a("li"),Tpe=a("strong"),jCo=o("hubert"),DCo=o(" \u2014 "),PG=a("a"),GCo=o("Wav2Vec2CTCTokenizer"),OCo=o(" (Hubert model)"),VCo=l(),Os=a("li"),Mpe=a("strong"),XCo=o("ibert"),zCo=o(" \u2014 "),BG=a("a"),QCo=o("RobertaTokenizer"),WCo=o(" or "),IG=a("a"),UCo=o("RobertaTokenizerFast"),HCo=o(" (I-BERT model)"),JCo=l(),Vs=a("li"),Epe=a("strong"),YCo=o("layoutlm"),ZCo=o(" \u2014 "),NG=a("a"),KCo=o("LayoutLMTokenizer"),e3o=o(" or "),qG=a("a"),o3o=o("LayoutLMTokenizerFast"),r3o=o(" (LayoutLM model)"),t3o=l(),Xs=a("li"),Cpe=a("strong"),a3o=o("layoutlmv2"),n3o=o(" \u2014 "),jG=a("a"),s3o=o("LayoutLMv2Tokenizer"),l3o=o(" or "),DG=a("a"),i3o=o("LayoutLMv2TokenizerFast"),d3o=o(" (LayoutLMv2 model)"),m3o=l(),zs=a("li"),wpe=a("strong"),c3o=o("layoutlmv3"),f3o=o(" \u2014 "),GG=a("a"),g3o=o("LayoutLMv3Tokenizer"),h3o=o(" or "),OG=a("a"),u3o=o("LayoutLMv3TokenizerFast"),p3o=o(" (LayoutLMv3 model)"),_3o=l(),Qs=a("li"),Ape=a("strong"),b3o=o("layoutxlm"),v3o=o(" \u2014 "),VG=a("a"),F3o=o("LayoutXLMTokenizer"),T3o=o(" or "),XG=a("a"),M3o=o("LayoutXLMTokenizerFast"),E3o=o(" (LayoutXLM model)"),C3o=l(),Ws=a("li"),Lpe=a("strong"),w3o=o("led"),A3o=o(" \u2014 "),zG=a("a"),L3o=o("LEDTokenizer"),y3o=o(" or "),QG=a("a"),x3o=o("LEDTokenizerFast"),$3o=o(" (LED model)"),k3o=l(),Us=a("li"),ype=a("strong"),S3o=o("lilt"),R3o=o(" \u2014 "),WG=a("a"),P3o=o("LayoutLMv3Tokenizer"),B3o=o(" or "),UG=a("a"),I3o=o("LayoutLMv3TokenizerFast"),N3o=o(" (LiLT model)"),q3o=l(),Hs=a("li"),xpe=a("strong"),j3o=o("longformer"),D3o=o(" \u2014 "),HG=a("a"),G3o=o("LongformerTokenizer"),O3o=o(" or "),JG=a("a"),V3o=o("LongformerTokenizerFast"),X3o=o(" (Longformer model)"),z3o=l(),Js=a("li"),$pe=a("strong"),Q3o=o("longt5"),W3o=o(" \u2014 "),YG=a("a"),U3o=o("T5Tokenizer"),H3o=o(" or "),ZG=a("a"),J3o=o("T5TokenizerFast"),Y3o=o(" (LongT5 model)"),Z3o=l(),Qu=a("li"),kpe=a("strong"),K3o=o("luke"),e5o=o(" \u2014 "),KG=a("a"),o5o=o("LukeTokenizer"),r5o=o(" (LUKE model)"),t5o=l(),Ys=a("li"),Spe=a("strong"),a5o=o("lxmert"),n5o=o(" \u2014 "),eO=a("a"),s5o=o("LxmertTokenizer"),l5o=o(" or "),oO=a("a"),i5o=o("LxmertTokenizerFast"),d5o=o(" (LXMERT model)"),m5o=l(),Wu=a("li"),Rpe=a("strong"),c5o=o("m2m_100"),f5o=o(" \u2014 "),rO=a("a"),g5o=o("M2M100Tokenizer"),h5o=o(" (M2M100 model)"),u5o=l(),Uu=a("li"),Ppe=a("strong"),p5o=o("marian"),_5o=o(" \u2014 "),tO=a("a"),b5o=o("MarianTokenizer"),v5o=o(" (Marian model)"),F5o=l(),Zs=a("li"),Bpe=a("strong"),T5o=o("mbart"),M5o=o(" \u2014 "),aO=a("a"),E5o=o("MBartTokenizer"),C5o=o(" or "),nO=a("a"),w5o=o("MBartTokenizerFast"),A5o=o(" (mBART model)"),L5o=l(),Ks=a("li"),Ipe=a("strong"),y5o=o("mbart50"),x5o=o(" \u2014 "),sO=a("a"),$5o=o("MBart50Tokenizer"),k5o=o(" or "),lO=a("a"),S5o=o("MBart50TokenizerFast"),R5o=o(" (mBART-50 model)"),P5o=l(),el=a("li"),Npe=a("strong"),B5o=o("megatron-bert"),I5o=o(" \u2014 "),iO=a("a"),N5o=o("BertTokenizer"),q5o=o(" or "),dO=a("a"),j5o=o("BertTokenizerFast"),D5o=o(" (Megatron-BERT model)"),G5o=l(),Hu=a("li"),qpe=a("strong"),O5o=o("mluke"),V5o=o(" \u2014 "),mO=a("a"),X5o=o("MLukeTokenizer"),z5o=o(" (mLUKE model)"),Q5o=l(),ol=a("li"),jpe=a("strong"),W5o=o("mobilebert"),U5o=o(" \u2014 "),cO=a("a"),H5o=o("MobileBertTokenizer"),J5o=o(" or "),fO=a("a"),Y5o=o("MobileBertTokenizerFast"),Z5o=o(" (MobileBERT model)"),K5o=l(),rl=a("li"),Dpe=a("strong"),e0o=o("mpnet"),o0o=o(" \u2014 "),gO=a("a"),r0o=o("MPNetTokenizer"),t0o=o(" or "),hO=a("a"),a0o=o("MPNetTokenizerFast"),n0o=o(" (MPNet model)"),s0o=l(),tl=a("li"),Gpe=a("strong"),l0o=o("mt5"),i0o=o(" \u2014 "),uO=a("a"),d0o=o("MT5Tokenizer"),m0o=o(" or "),pO=a("a"),c0o=o("MT5TokenizerFast"),f0o=o(" (MT5 model)"),g0o=l(),al=a("li"),Ope=a("strong"),h0o=o("mvp"),u0o=o(" \u2014 "),_O=a("a"),p0o=o("MvpTokenizer"),_0o=o(" or "),bO=a("a"),b0o=o("MvpTokenizerFast"),v0o=o(" (MVP model)"),F0o=l(),nl=a("li"),Vpe=a("strong"),T0o=o("nezha"),M0o=o(" \u2014 "),vO=a("a"),E0o=o("BertTokenizer"),C0o=o(" or "),FO=a("a"),w0o=o("BertTokenizerFast"),A0o=o(" (Nezha model)"),L0o=l(),sl=a("li"),Xpe=a("strong"),y0o=o("nllb"),x0o=o(" \u2014 "),TO=a("a"),$0o=o("NllbTokenizer"),k0o=o(" or "),MO=a("a"),S0o=o("NllbTokenizerFast"),R0o=o(" (NLLB model)"),P0o=l(),ll=a("li"),zpe=a("strong"),B0o=o("nystromformer"),I0o=o(" \u2014 "),EO=a("a"),N0o=o("AlbertTokenizer"),q0o=o(" or "),CO=a("a"),j0o=o("AlbertTokenizerFast"),D0o=o(" (Nystr\xF6mformer model)"),G0o=l(),il=a("li"),Qpe=a("strong"),O0o=o("openai-gpt"),V0o=o(" \u2014 "),wO=a("a"),X0o=o("OpenAIGPTTokenizer"),z0o=o(" or "),AO=a("a"),Q0o=o("OpenAIGPTTokenizerFast"),W0o=o(" (OpenAI GPT model)"),U0o=l(),Ju=a("li"),Wpe=a("strong"),H0o=o("opt"),J0o=o(" \u2014 "),LO=a("a"),Y0o=o("GPT2Tokenizer"),Z0o=o(" (OPT model)"),K0o=l(),dl=a("li"),Upe=a("strong"),ewo=o("owlvit"),owo=o(" \u2014 "),yO=a("a"),rwo=o("CLIPTokenizer"),two=o(" or "),xO=a("a"),awo=o("CLIPTokenizerFast"),nwo=o(" (OWL-ViT model)"),swo=l(),ml=a("li"),Hpe=a("strong"),lwo=o("pegasus"),iwo=o(" \u2014 "),$O=a("a"),dwo=o("PegasusTokenizer"),mwo=o(" or "),kO=a("a"),cwo=o("PegasusTokenizerFast"),fwo=o(" (Pegasus model)"),gwo=l(),cl=a("li"),Jpe=a("strong"),hwo=o("pegasus_x"),uwo=o(" \u2014 "),SO=a("a"),pwo=o("PegasusTokenizer"),_wo=o(" or "),RO=a("a"),bwo=o("PegasusTokenizerFast"),vwo=o(" (PEGASUS-X model)"),Fwo=l(),Yu=a("li"),Ype=a("strong"),Two=o("perceiver"),Mwo=o(" \u2014 "),PO=a("a"),Ewo=o("PerceiverTokenizer"),Cwo=o(" (Perceiver model)"),wwo=l(),Zu=a("li"),Zpe=a("strong"),Awo=o("phobert"),Lwo=o(" \u2014 "),BO=a("a"),ywo=o("PhobertTokenizer"),xwo=o(" (PhoBERT model)"),$wo=l(),Ku=a("li"),Kpe=a("strong"),kwo=o("plbart"),Swo=o(" \u2014 "),IO=a("a"),Rwo=o("PLBartTokenizer"),Pwo=o(" (PLBart model)"),Bwo=l(),ep=a("li"),e_e=a("strong"),Iwo=o("prophetnet"),Nwo=o(" \u2014 "),NO=a("a"),qwo=o("ProphetNetTokenizer"),jwo=o(" (ProphetNet model)"),Dwo=l(),fl=a("li"),o_e=a("strong"),Gwo=o("qdqbert"),Owo=o(" \u2014 "),qO=a("a"),Vwo=o("BertTokenizer"),Xwo=o(" or "),jO=a("a"),zwo=o("BertTokenizerFast"),Qwo=o(" (QDQBert model)"),Wwo=l(),op=a("li"),r_e=a("strong"),Uwo=o("rag"),Hwo=o(" \u2014 "),DO=a("a"),Jwo=o("RagTokenizer"),Ywo=o(" (RAG model)"),Zwo=l(),gl=a("li"),t_e=a("strong"),Kwo=o("realm"),eAo=o(" \u2014 "),GO=a("a"),oAo=o("RealmTokenizer"),rAo=o(" or "),OO=a("a"),tAo=o("RealmTokenizerFast"),aAo=o(" (REALM model)"),nAo=l(),hl=a("li"),a_e=a("strong"),sAo=o("reformer"),lAo=o(" \u2014 "),VO=a("a"),iAo=o("ReformerTokenizer"),dAo=o(" or "),XO=a("a"),mAo=o("ReformerTokenizerFast"),cAo=o(" (Reformer model)"),fAo=l(),ul=a("li"),n_e=a("strong"),gAo=o("rembert"),hAo=o(" \u2014 "),zO=a("a"),uAo=o("RemBertTokenizer"),pAo=o(" or "),QO=a("a"),_Ao=o("RemBertTokenizerFast"),bAo=o(" (RemBERT model)"),vAo=l(),pl=a("li"),s_e=a("strong"),FAo=o("retribert"),TAo=o(" \u2014 "),WO=a("a"),MAo=o("RetriBertTokenizer"),EAo=o(" or "),UO=a("a"),CAo=o("RetriBertTokenizerFast"),wAo=o(" (RetriBERT model)"),AAo=l(),_l=a("li"),l_e=a("strong"),LAo=o("roberta"),yAo=o(" \u2014 "),HO=a("a"),xAo=o("RobertaTokenizer"),$Ao=o(" or "),JO=a("a"),kAo=o("RobertaTokenizerFast"),SAo=o(" (RoBERTa model)"),RAo=l(),bl=a("li"),i_e=a("strong"),PAo=o("roformer"),BAo=o(" \u2014 "),YO=a("a"),IAo=o("RoFormerTokenizer"),NAo=o(" or "),ZO=a("a"),qAo=o("RoFormerTokenizerFast"),jAo=o(" (RoFormer model)"),DAo=l(),rp=a("li"),d_e=a("strong"),GAo=o("speech_to_text"),OAo=o(" \u2014 "),KO=a("a"),VAo=o("Speech2TextTokenizer"),XAo=o(" (Speech2Text model)"),zAo=l(),tp=a("li"),m_e=a("strong"),QAo=o("speech_to_text_2"),WAo=o(" \u2014 "),eV=a("a"),UAo=o("Speech2Text2Tokenizer"),HAo=o(" (Speech2Text2 model)"),JAo=l(),vl=a("li"),c_e=a("strong"),YAo=o("splinter"),ZAo=o(" \u2014 "),oV=a("a"),KAo=o("SplinterTokenizer"),e6o=o(" or "),rV=a("a"),o6o=o("SplinterTokenizerFast"),r6o=o(" (Splinter model)"),t6o=l(),Fl=a("li"),f_e=a("strong"),a6o=o("squeezebert"),n6o=o(" \u2014 "),tV=a("a"),s6o=o("SqueezeBertTokenizer"),l6o=o(" or "),aV=a("a"),i6o=o("SqueezeBertTokenizerFast"),d6o=o(" (SqueezeBERT model)"),m6o=l(),Tl=a("li"),g_e=a("strong"),c6o=o("t5"),f6o=o(" \u2014 "),nV=a("a"),g6o=o("T5Tokenizer"),h6o=o(" or "),sV=a("a"),u6o=o("T5TokenizerFast"),p6o=o(" (T5 model)"),_6o=l(),ap=a("li"),h_e=a("strong"),b6o=o("tapas"),v6o=o(" \u2014 "),lV=a("a"),F6o=o("TapasTokenizer"),T6o=o(" (TAPAS model)"),M6o=l(),np=a("li"),u_e=a("strong"),E6o=o("tapex"),C6o=o(" \u2014 "),iV=a("a"),w6o=o("TapexTokenizer"),A6o=o(" (TAPEX model)"),L6o=l(),sp=a("li"),p_e=a("strong"),y6o=o("transfo-xl"),x6o=o(" \u2014 "),dV=a("a"),$6o=o("TransfoXLTokenizer"),k6o=o(" (Transformer-XL model)"),S6o=l(),Ml=a("li"),__e=a("strong"),R6o=o("vilt"),P6o=o(" \u2014 "),mV=a("a"),B6o=o("BertTokenizer"),I6o=o(" or "),cV=a("a"),N6o=o("BertTokenizerFast"),q6o=o(" (ViLT model)"),j6o=l(),El=a("li"),b_e=a("strong"),D6o=o("visual_bert"),G6o=o(" \u2014 "),fV=a("a"),O6o=o("BertTokenizer"),V6o=o(" or "),gV=a("a"),X6o=o("BertTokenizerFast"),z6o=o(" (VisualBERT model)"),Q6o=l(),lp=a("li"),v_e=a("strong"),W6o=o("wav2vec2"),U6o=o(" \u2014 "),hV=a("a"),H6o=o("Wav2Vec2CTCTokenizer"),J6o=o(" (Wav2Vec2 model)"),Y6o=l(),ip=a("li"),F_e=a("strong"),Z6o=o("wav2vec2-conformer"),K6o=o(" \u2014 "),uV=a("a"),e7o=o("Wav2Vec2CTCTokenizer"),o7o=o(" (Wav2Vec2-Conformer model)"),r7o=l(),dp=a("li"),T_e=a("strong"),t7o=o("wav2vec2_phoneme"),a7o=o(" \u2014 "),pV=a("a"),n7o=o("Wav2Vec2PhonemeCTCTokenizer"),s7o=o(" (Wav2Vec2Phoneme model)"),l7o=l(),mp=a("li"),M_e=a("strong"),i7o=o("whisper"),d7o=o(" \u2014 "),_V=a("a"),m7o=o("WhisperTokenizer"),c7o=o(" (Whisper model)"),f7o=l(),Cl=a("li"),E_e=a("strong"),g7o=o("xclip"),h7o=o(" \u2014 "),bV=a("a"),u7o=o("CLIPTokenizer"),p7o=o(" or "),vV=a("a"),_7o=o("CLIPTokenizerFast"),b7o=o(" (X-CLIP model)"),v7o=l(),wl=a("li"),C_e=a("strong"),F7o=o("xglm"),T7o=o(" \u2014 "),FV=a("a"),M7o=o("XGLMTokenizer"),E7o=o(" or "),TV=a("a"),C7o=o("XGLMTokenizerFast"),w7o=o(" (XGLM model)"),A7o=l(),cp=a("li"),w_e=a("strong"),L7o=o("xlm"),y7o=o(" \u2014 "),MV=a("a"),x7o=o("XLMTokenizer"),$7o=o(" (XLM model)"),k7o=l(),fp=a("li"),A_e=a("strong"),S7o=o("xlm-prophetnet"),R7o=o(" \u2014 "),EV=a("a"),P7o=o("XLMProphetNetTokenizer"),B7o=o(" (XLM-ProphetNet model)"),I7o=l(),Al=a("li"),L_e=a("strong"),N7o=o("xlm-roberta"),q7o=o(" \u2014 "),CV=a("a"),j7o=o("XLMRobertaTokenizer"),D7o=o(" or "),wV=a("a"),G7o=o("XLMRobertaTokenizerFast"),O7o=o(" (XLM-RoBERTa model)"),V7o=l(),Ll=a("li"),y_e=a("strong"),X7o=o("xlm-roberta-xl"),z7o=o(" \u2014 "),AV=a("a"),Q7o=o("XLMRobertaTokenizer"),W7o=o(" or "),LV=a("a"),U7o=o("XLMRobertaTokenizerFast"),H7o=o(" (XLM-RoBERTa-XL model)"),J7o=l(),yl=a("li"),x_e=a("strong"),Y7o=o("xlnet"),Z7o=o(" \u2014 "),yV=a("a"),K7o=o("XLNetTokenizer"),e8o=o(" or "),xV=a("a"),o8o=o("XLNetTokenizerFast"),r8o=o(" (XLNet model)"),t8o=l(),xl=a("li"),$_e=a("strong"),a8o=o("yoso"),n8o=o(" \u2014 "),$V=a("a"),s8o=o("AlbertTokenizer"),l8o=o(" or "),kV=a("a"),i8o=o("AlbertTokenizerFast"),d8o=o(" (YOSO model)"),m8o=l(),F(gp.$$.fragment),c8o=l(),hp=a("div"),F(I$.$$.fragment),f8o=l(),k_e=a("p"),g8o=o("Register a new tokenizer in this mapping."),Nao=l(),$d=a("h2"),up=a("a"),S_e=a("span"),F(N$.$$.fragment),h8o=l(),R_e=a("span"),u8o=o("AutoFeatureExtractor"),qao=l(),Po=a("div"),F(q$.$$.fragment),p8o=l(),j$=a("p"),_8o=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),SV=a("a"),b8o=o("AutoFeatureExtractor.from_pretrained()"),v8o=o(" class method."),F8o=l(),D$=a("p"),T8o=o("This class cannot be instantiated directly using "),P_e=a("code"),M8o=o("__init__()"),E8o=o(" (throws an error)."),C8o=l(),Ye=a("div"),F(G$.$$.fragment),w8o=l(),B_e=a("p"),A8o=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),L8o=l(),an=a("p"),y8o=o("The feature extractor class to instantiate is selected based on the "),I_e=a("code"),x8o=o("model_type"),$8o=o(` property of the config object
(either passed as an argument or loaded from `),N_e=a("code"),k8o=o("pretrained_model_name_or_path"),S8o=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),q_e=a("code"),R8o=o("pretrained_model_name_or_path"),P8o=o(":"),B8o=l(),z=a("ul"),pp=a("li"),j_e=a("strong"),I8o=o("beit"),N8o=o(" \u2014 "),RV=a("a"),q8o=o("BeitFeatureExtractor"),j8o=o(" (BEiT model)"),D8o=l(),_p=a("li"),D_e=a("strong"),G8o=o("clip"),O8o=o(" \u2014 "),PV=a("a"),V8o=o("CLIPFeatureExtractor"),X8o=o(" (CLIP model)"),z8o=l(),bp=a("li"),G_e=a("strong"),Q8o=o("clipseg"),W8o=o(" \u2014 "),BV=a("a"),U8o=o("ViTFeatureExtractor"),H8o=o(" (CLIPSeg model)"),J8o=l(),vp=a("li"),O_e=a("strong"),Y8o=o("conditional_detr"),Z8o=o(" \u2014 "),IV=a("a"),K8o=o("ConditionalDetrFeatureExtractor"),eLo=o(" (Conditional DETR model)"),oLo=l(),Fp=a("li"),V_e=a("strong"),rLo=o("convnext"),tLo=o(" \u2014 "),NV=a("a"),aLo=o("ConvNextFeatureExtractor"),nLo=o(" (ConvNeXT model)"),sLo=l(),Tp=a("li"),X_e=a("strong"),lLo=o("cvt"),iLo=o(" \u2014 "),qV=a("a"),dLo=o("ConvNextFeatureExtractor"),mLo=o(" (CvT model)"),cLo=l(),Mp=a("li"),z_e=a("strong"),fLo=o("data2vec-audio"),gLo=o(" \u2014 "),jV=a("a"),hLo=o("Wav2Vec2FeatureExtractor"),uLo=o(" (Data2VecAudio model)"),pLo=l(),Ep=a("li"),Q_e=a("strong"),_Lo=o("data2vec-vision"),bLo=o(" \u2014 "),DV=a("a"),vLo=o("BeitFeatureExtractor"),FLo=o(" (Data2VecVision model)"),TLo=l(),Cp=a("li"),W_e=a("strong"),MLo=o("deformable_detr"),ELo=o(" \u2014 "),GV=a("a"),CLo=o("DeformableDetrFeatureExtractor"),wLo=o(" (Deformable DETR model)"),ALo=l(),wp=a("li"),U_e=a("strong"),LLo=o("deit"),yLo=o(" \u2014 "),OV=a("a"),xLo=o("DeiTFeatureExtractor"),$Lo=o(" (DeiT model)"),kLo=l(),Ap=a("li"),H_e=a("strong"),SLo=o("detr"),RLo=o(" \u2014 "),VV=a("a"),PLo=o("DetrFeatureExtractor"),BLo=o(" (DETR model)"),ILo=l(),Lp=a("li"),J_e=a("strong"),NLo=o("donut-swin"),qLo=o(" \u2014 "),XV=a("a"),jLo=o("DonutFeatureExtractor"),DLo=o(" (DonutSwin model)"),GLo=l(),yp=a("li"),Y_e=a("strong"),OLo=o("dpt"),VLo=o(" \u2014 "),zV=a("a"),XLo=o("DPTFeatureExtractor"),zLo=o(" (DPT model)"),QLo=l(),xp=a("li"),Z_e=a("strong"),WLo=o("flava"),ULo=o(" \u2014 "),QV=a("a"),HLo=o("FlavaFeatureExtractor"),JLo=o(" (FLAVA model)"),YLo=l(),$p=a("li"),K_e=a("strong"),ZLo=o("glpn"),KLo=o(" \u2014 "),WV=a("a"),eyo=o("GLPNFeatureExtractor"),oyo=o(" (GLPN model)"),ryo=l(),kp=a("li"),e1e=a("strong"),tyo=o("groupvit"),ayo=o(" \u2014 "),UV=a("a"),nyo=o("CLIPFeatureExtractor"),syo=o(" (GroupViT model)"),lyo=l(),Sp=a("li"),o1e=a("strong"),iyo=o("hubert"),dyo=o(" \u2014 "),HV=a("a"),myo=o("Wav2Vec2FeatureExtractor"),cyo=o(" (Hubert model)"),fyo=l(),Rp=a("li"),r1e=a("strong"),gyo=o("imagegpt"),hyo=o(" \u2014 "),JV=a("a"),uyo=o("ImageGPTFeatureExtractor"),pyo=o(" (ImageGPT model)"),_yo=l(),Pp=a("li"),t1e=a("strong"),byo=o("layoutlmv2"),vyo=o(" \u2014 "),YV=a("a"),Fyo=o("LayoutLMv2FeatureExtractor"),Tyo=o(" (LayoutLMv2 model)"),Myo=l(),Bp=a("li"),a1e=a("strong"),Eyo=o("layoutlmv3"),Cyo=o(" \u2014 "),ZV=a("a"),wyo=o("LayoutLMv3FeatureExtractor"),Ayo=o(" (LayoutLMv3 model)"),Lyo=l(),Ip=a("li"),n1e=a("strong"),yyo=o("levit"),xyo=o(" \u2014 "),KV=a("a"),$yo=o("LevitFeatureExtractor"),kyo=o(" (LeViT model)"),Syo=l(),Np=a("li"),s1e=a("strong"),Ryo=o("maskformer"),Pyo=o(" \u2014 "),eX=a("a"),Byo=o("MaskFormerFeatureExtractor"),Iyo=o(" (MaskFormer model)"),Nyo=l(),qp=a("li"),l1e=a("strong"),qyo=o("mctct"),jyo=o(" \u2014 "),oX=a("a"),Dyo=o("MCTCTFeatureExtractor"),Gyo=o(" (M-CTC-T model)"),Oyo=l(),jp=a("li"),i1e=a("strong"),Vyo=o("mobilevit"),Xyo=o(" \u2014 "),rX=a("a"),zyo=o("MobileViTFeatureExtractor"),Qyo=o(" (MobileViT model)"),Wyo=l(),Dp=a("li"),d1e=a("strong"),Uyo=o("owlvit"),Hyo=o(" \u2014 "),tX=a("a"),Jyo=o("OwlViTFeatureExtractor"),Yyo=o(" (OWL-ViT model)"),Zyo=l(),Gp=a("li"),m1e=a("strong"),Kyo=o("perceiver"),e9o=o(" \u2014 "),aX=a("a"),o9o=o("PerceiverFeatureExtractor"),r9o=o(" (Perceiver model)"),t9o=l(),Op=a("li"),c1e=a("strong"),a9o=o("poolformer"),n9o=o(" \u2014 "),nX=a("a"),s9o=o("PoolFormerFeatureExtractor"),l9o=o(" (PoolFormer model)"),i9o=l(),Vp=a("li"),f1e=a("strong"),d9o=o("regnet"),m9o=o(" \u2014 "),sX=a("a"),c9o=o("ConvNextFeatureExtractor"),f9o=o(" (RegNet model)"),g9o=l(),Xp=a("li"),g1e=a("strong"),h9o=o("resnet"),u9o=o(" \u2014 "),lX=a("a"),p9o=o("ConvNextFeatureExtractor"),_9o=o(" (ResNet model)"),b9o=l(),zp=a("li"),h1e=a("strong"),v9o=o("segformer"),F9o=o(" \u2014 "),iX=a("a"),T9o=o("SegformerFeatureExtractor"),M9o=o(" (SegFormer model)"),E9o=l(),Qp=a("li"),u1e=a("strong"),C9o=o("speech_to_text"),w9o=o(" \u2014 "),dX=a("a"),A9o=o("Speech2TextFeatureExtractor"),L9o=o(" (Speech2Text model)"),y9o=l(),Wp=a("li"),p1e=a("strong"),x9o=o("swin"),$9o=o(" \u2014 "),mX=a("a"),k9o=o("ViTFeatureExtractor"),S9o=o(" (Swin Transformer model)"),R9o=l(),Up=a("li"),_1e=a("strong"),P9o=o("swinv2"),B9o=o(" \u2014 "),cX=a("a"),I9o=o("ViTFeatureExtractor"),N9o=o(" (Swin Transformer V2 model)"),q9o=l(),Hp=a("li"),b1e=a("strong"),j9o=o("table-transformer"),D9o=o(" \u2014 "),fX=a("a"),G9o=o("DetrFeatureExtractor"),O9o=o(" (Table Transformer model)"),V9o=l(),Jp=a("li"),v1e=a("strong"),X9o=o("van"),z9o=o(" \u2014 "),gX=a("a"),Q9o=o("ConvNextFeatureExtractor"),W9o=o(" (VAN model)"),U9o=l(),Yp=a("li"),F1e=a("strong"),H9o=o("videomae"),J9o=o(" \u2014 "),hX=a("a"),Y9o=o("VideoMAEFeatureExtractor"),Z9o=o(" (VideoMAE model)"),K9o=l(),Zp=a("li"),T1e=a("strong"),exo=o("vilt"),oxo=o(" \u2014 "),uX=a("a"),rxo=o("ViltFeatureExtractor"),txo=o(" (ViLT model)"),axo=l(),Kp=a("li"),M1e=a("strong"),nxo=o("vit"),sxo=o(" \u2014 "),pX=a("a"),lxo=o("ViTFeatureExtractor"),ixo=o(" (ViT model)"),dxo=l(),e_=a("li"),E1e=a("strong"),mxo=o("vit_mae"),cxo=o(" \u2014 "),_X=a("a"),fxo=o("ViTFeatureExtractor"),gxo=o(" (ViTMAE model)"),hxo=l(),o_=a("li"),C1e=a("strong"),uxo=o("vit_msn"),pxo=o(" \u2014 "),bX=a("a"),_xo=o("ViTFeatureExtractor"),bxo=o(" (ViTMSN model)"),vxo=l(),r_=a("li"),w1e=a("strong"),Fxo=o("wav2vec2"),Txo=o(" \u2014 "),vX=a("a"),Mxo=o("Wav2Vec2FeatureExtractor"),Exo=o(" (Wav2Vec2 model)"),Cxo=l(),t_=a("li"),A1e=a("strong"),wxo=o("wav2vec2-conformer"),Axo=o(" \u2014 "),FX=a("a"),Lxo=o("Wav2Vec2FeatureExtractor"),yxo=o(" (Wav2Vec2-Conformer model)"),xxo=l(),a_=a("li"),L1e=a("strong"),$xo=o("whisper"),kxo=o(" \u2014 "),TX=a("a"),Sxo=o("WhisperFeatureExtractor"),Rxo=o(" (Whisper model)"),Pxo=l(),n_=a("li"),y1e=a("strong"),Bxo=o("xclip"),Ixo=o(" \u2014 "),MX=a("a"),Nxo=o("CLIPFeatureExtractor"),qxo=o(" (X-CLIP model)"),jxo=l(),s_=a("li"),x1e=a("strong"),Dxo=o("yolos"),Gxo=o(" \u2014 "),EX=a("a"),Oxo=o("YolosFeatureExtractor"),Vxo=o(" (YOLOS model)"),Xxo=l(),F(l_.$$.fragment),zxo=l(),F(i_.$$.fragment),Qxo=l(),d_=a("div"),F(O$.$$.fragment),Wxo=l(),$1e=a("p"),Uxo=o("Register a new feature extractor for this class."),jao=l(),kd=a("h2"),m_=a("a"),k1e=a("span"),F(V$.$$.fragment),Hxo=l(),S1e=a("span"),Jxo=o("AutoProcessor"),Dao=l(),Bo=a("div"),F(X$.$$.fragment),Yxo=l(),z$=a("p"),Zxo=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),CX=a("a"),Kxo=o("AutoProcessor.from_pretrained()"),e$o=o(" class method."),o$o=l(),Q$=a("p"),r$o=o("This class cannot be instantiated directly using "),R1e=a("code"),t$o=o("__init__()"),a$o=o(" (throws an error)."),n$o=l(),Ze=a("div"),F(W$.$$.fragment),s$o=l(),P1e=a("p"),l$o=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),i$o=l(),Sd=a("p"),d$o=o("The processor class to instantiate is selected based on the "),B1e=a("code"),m$o=o("model_type"),c$o=o(` property of the config object (either
passed as an argument or loaded from `),I1e=a("code"),f$o=o("pretrained_model_name_or_path"),g$o=o(" if possible):"),h$o=l(),se=a("ul"),c_=a("li"),N1e=a("strong"),u$o=o("clip"),p$o=o(" \u2014 "),wX=a("a"),_$o=o("CLIPProcessor"),b$o=o(" (CLIP model)"),v$o=l(),f_=a("li"),q1e=a("strong"),F$o=o("clipseg"),T$o=o(" \u2014 "),AX=a("a"),M$o=o("CLIPSegProcessor"),E$o=o(" (CLIPSeg model)"),C$o=l(),g_=a("li"),j1e=a("strong"),w$o=o("flava"),A$o=o(" \u2014 "),LX=a("a"),L$o=o("FlavaProcessor"),y$o=o(" (FLAVA model)"),x$o=l(),h_=a("li"),D1e=a("strong"),$$o=o("groupvit"),k$o=o(" \u2014 "),yX=a("a"),S$o=o("CLIPProcessor"),R$o=o(" (GroupViT model)"),P$o=l(),u_=a("li"),G1e=a("strong"),B$o=o("layoutlmv2"),I$o=o(" \u2014 "),xX=a("a"),N$o=o("LayoutLMv2Processor"),q$o=o(" (LayoutLMv2 model)"),j$o=l(),p_=a("li"),O1e=a("strong"),D$o=o("layoutlmv3"),G$o=o(" \u2014 "),$X=a("a"),O$o=o("LayoutLMv3Processor"),V$o=o(" (LayoutLMv3 model)"),X$o=l(),__=a("li"),V1e=a("strong"),z$o=o("layoutxlm"),Q$o=o(" \u2014 "),kX=a("a"),W$o=o("LayoutXLMProcessor"),U$o=o(" (LayoutXLM model)"),H$o=l(),b_=a("li"),X1e=a("strong"),J$o=o("markuplm"),Y$o=o(" \u2014 "),SX=a("a"),Z$o=o("MarkupLMProcessor"),K$o=o(" (MarkupLM model)"),eko=l(),v_=a("li"),z1e=a("strong"),oko=o("owlvit"),rko=o(" \u2014 "),RX=a("a"),tko=o("OwlViTProcessor"),ako=o(" (OWL-ViT model)"),nko=l(),F_=a("li"),Q1e=a("strong"),sko=o("sew"),lko=o(" \u2014 "),PX=a("a"),iko=o("Wav2Vec2Processor"),dko=o(" (SEW model)"),mko=l(),T_=a("li"),W1e=a("strong"),cko=o("sew-d"),fko=o(" \u2014 "),BX=a("a"),gko=o("Wav2Vec2Processor"),hko=o(" (SEW-D model)"),uko=l(),M_=a("li"),U1e=a("strong"),pko=o("speech_to_text"),_ko=o(" \u2014 "),IX=a("a"),bko=o("Speech2TextProcessor"),vko=o(" (Speech2Text model)"),Fko=l(),E_=a("li"),H1e=a("strong"),Tko=o("speech_to_text_2"),Mko=o(" \u2014 "),NX=a("a"),Eko=o("Speech2Text2Processor"),Cko=o(" (Speech2Text2 model)"),wko=l(),C_=a("li"),J1e=a("strong"),Ako=o("trocr"),Lko=o(" \u2014 "),qX=a("a"),yko=o("TrOCRProcessor"),xko=o(" (TrOCR model)"),$ko=l(),w_=a("li"),Y1e=a("strong"),kko=o("unispeech"),Sko=o(" \u2014 "),jX=a("a"),Rko=o("Wav2Vec2Processor"),Pko=o(" (UniSpeech model)"),Bko=l(),A_=a("li"),Z1e=a("strong"),Iko=o("unispeech-sat"),Nko=o(" \u2014 "),DX=a("a"),qko=o("Wav2Vec2Processor"),jko=o(" (UniSpeechSat model)"),Dko=l(),L_=a("li"),K1e=a("strong"),Gko=o("vilt"),Oko=o(" \u2014 "),GX=a("a"),Vko=o("ViltProcessor"),Xko=o(" (ViLT model)"),zko=l(),y_=a("li"),e2e=a("strong"),Qko=o("vision-text-dual-encoder"),Wko=o(" \u2014 "),OX=a("a"),Uko=o("VisionTextDualEncoderProcessor"),Hko=o(" (VisionTextDualEncoder model)"),Jko=l(),x_=a("li"),o2e=a("strong"),Yko=o("wav2vec2"),Zko=o(" \u2014 "),VX=a("a"),Kko=o("Wav2Vec2Processor"),eSo=o(" (Wav2Vec2 model)"),oSo=l(),$_=a("li"),r2e=a("strong"),rSo=o("wav2vec2-conformer"),tSo=o(" \u2014 "),XX=a("a"),aSo=o("Wav2Vec2Processor"),nSo=o(" (Wav2Vec2-Conformer model)"),sSo=l(),k_=a("li"),t2e=a("strong"),lSo=o("wavlm"),iSo=o(" \u2014 "),zX=a("a"),dSo=o("Wav2Vec2Processor"),mSo=o(" (WavLM model)"),cSo=l(),S_=a("li"),a2e=a("strong"),fSo=o("whisper"),gSo=o(" \u2014 "),QX=a("a"),hSo=o("WhisperProcessor"),uSo=o(" (Whisper model)"),pSo=l(),R_=a("li"),n2e=a("strong"),_So=o("xclip"),bSo=o(" \u2014 "),WX=a("a"),vSo=o("XCLIPProcessor"),FSo=o(" (X-CLIP model)"),TSo=l(),F(P_.$$.fragment),MSo=l(),F(B_.$$.fragment),ESo=l(),I_=a("div"),F(U$.$$.fragment),CSo=l(),s2e=a("p"),wSo=o("Register a new processor for this class."),Gao=l(),Rd=a("h2"),N_=a("a"),l2e=a("span"),F(H$.$$.fragment),ASo=l(),i2e=a("span"),LSo=o("AutoModel"),Oao=l(),Io=a("div"),F(J$.$$.fragment),ySo=l(),Pd=a("p"),xSo=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),UX=a("a"),$So=o("from_pretrained()"),kSo=o(" class method or the "),HX=a("a"),SSo=o("from_config()"),RSo=o(` class
method.`),PSo=l(),Y$=a("p"),BSo=o("This class cannot be instantiated directly using "),d2e=a("code"),ISo=o("__init__()"),NSo=o(" (throws an error)."),qSo=l(),Mt=a("div"),F(Z$.$$.fragment),jSo=l(),m2e=a("p"),DSo=o("Instantiates one of the base model classes of the library from a configuration."),GSo=l(),Bd=a("p"),OSo=o(`Note:
Loading a model from its configuration file does `),c2e=a("strong"),VSo=o("not"),XSo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),JX=a("a"),zSo=o("from_pretrained()"),QSo=o(" to load the model weights."),WSo=l(),F(q_.$$.fragment),USo=l(),Ke=a("div"),F(K$.$$.fragment),HSo=l(),f2e=a("p"),JSo=o("Instantiate one of the base model classes of the library from a pretrained model."),YSo=l(),nn=a("p"),ZSo=o("The model class to instantiate is selected based on the "),g2e=a("code"),KSo=o("model_type"),eRo=o(` property of the config object (either
passed as an argument or loaded from `),h2e=a("code"),oRo=o("pretrained_model_name_or_path"),rRo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u2e=a("code"),tRo=o("pretrained_model_name_or_path"),aRo=o(":"),nRo=l(),y=a("ul"),j_=a("li"),p2e=a("strong"),sRo=o("albert"),lRo=o(" \u2014 "),YX=a("a"),iRo=o("AlbertModel"),dRo=o(" (ALBERT model)"),mRo=l(),D_=a("li"),_2e=a("strong"),cRo=o("bart"),fRo=o(" \u2014 "),ZX=a("a"),gRo=o("BartModel"),hRo=o(" (BART model)"),uRo=l(),G_=a("li"),b2e=a("strong"),pRo=o("beit"),_Ro=o(" \u2014 "),KX=a("a"),bRo=o("BeitModel"),vRo=o(" (BEiT model)"),FRo=l(),O_=a("li"),v2e=a("strong"),TRo=o("bert"),MRo=o(" \u2014 "),ez=a("a"),ERo=o("BertModel"),CRo=o(" (BERT model)"),wRo=l(),V_=a("li"),F2e=a("strong"),ARo=o("bert-generation"),LRo=o(" \u2014 "),oz=a("a"),yRo=o("BertGenerationEncoder"),xRo=o(" (Bert Generation model)"),$Ro=l(),X_=a("li"),T2e=a("strong"),kRo=o("big_bird"),SRo=o(" \u2014 "),rz=a("a"),RRo=o("BigBirdModel"),PRo=o(" (BigBird model)"),BRo=l(),z_=a("li"),M2e=a("strong"),IRo=o("bigbird_pegasus"),NRo=o(" \u2014 "),tz=a("a"),qRo=o("BigBirdPegasusModel"),jRo=o(" (BigBird-Pegasus model)"),DRo=l(),Q_=a("li"),E2e=a("strong"),GRo=o("blenderbot"),ORo=o(" \u2014 "),az=a("a"),VRo=o("BlenderbotModel"),XRo=o(" (Blenderbot model)"),zRo=l(),W_=a("li"),C2e=a("strong"),QRo=o("blenderbot-small"),WRo=o(" \u2014 "),nz=a("a"),URo=o("BlenderbotSmallModel"),HRo=o(" (BlenderbotSmall model)"),JRo=l(),U_=a("li"),w2e=a("strong"),YRo=o("bloom"),ZRo=o(" \u2014 "),sz=a("a"),KRo=o("BloomModel"),ePo=o(" (BLOOM model)"),oPo=l(),H_=a("li"),A2e=a("strong"),rPo=o("camembert"),tPo=o(" \u2014 "),lz=a("a"),aPo=o("CamembertModel"),nPo=o(" (CamemBERT model)"),sPo=l(),J_=a("li"),L2e=a("strong"),lPo=o("canine"),iPo=o(" \u2014 "),iz=a("a"),dPo=o("CanineModel"),mPo=o(" (CANINE model)"),cPo=l(),Y_=a("li"),y2e=a("strong"),fPo=o("clip"),gPo=o(" \u2014 "),dz=a("a"),hPo=o("CLIPModel"),uPo=o(" (CLIP model)"),pPo=l(),Z_=a("li"),x2e=a("strong"),_Po=o("clipseg"),bPo=o(" \u2014 "),mz=a("a"),vPo=o("CLIPSegModel"),FPo=o(" (CLIPSeg model)"),TPo=l(),K_=a("li"),$2e=a("strong"),MPo=o("codegen"),EPo=o(" \u2014 "),cz=a("a"),CPo=o("CodeGenModel"),wPo=o(" (CodeGen model)"),APo=l(),e1=a("li"),k2e=a("strong"),LPo=o("conditional_detr"),yPo=o(" \u2014 "),fz=a("a"),xPo=o("ConditionalDetrModel"),$Po=o(" (Conditional DETR model)"),kPo=l(),o1=a("li"),S2e=a("strong"),SPo=o("convbert"),RPo=o(" \u2014 "),gz=a("a"),PPo=o("ConvBertModel"),BPo=o(" (ConvBERT model)"),IPo=l(),r1=a("li"),R2e=a("strong"),NPo=o("convnext"),qPo=o(" \u2014 "),hz=a("a"),jPo=o("ConvNextModel"),DPo=o(" (ConvNeXT model)"),GPo=l(),t1=a("li"),P2e=a("strong"),OPo=o("ctrl"),VPo=o(" \u2014 "),uz=a("a"),XPo=o("CTRLModel"),zPo=o(" (CTRL model)"),QPo=l(),a1=a("li"),B2e=a("strong"),WPo=o("cvt"),UPo=o(" \u2014 "),pz=a("a"),HPo=o("CvtModel"),JPo=o(" (CvT model)"),YPo=l(),n1=a("li"),I2e=a("strong"),ZPo=o("data2vec-audio"),KPo=o(" \u2014 "),_z=a("a"),eBo=o("Data2VecAudioModel"),oBo=o(" (Data2VecAudio model)"),rBo=l(),s1=a("li"),N2e=a("strong"),tBo=o("data2vec-text"),aBo=o(" \u2014 "),bz=a("a"),nBo=o("Data2VecTextModel"),sBo=o(" (Data2VecText model)"),lBo=l(),l1=a("li"),q2e=a("strong"),iBo=o("data2vec-vision"),dBo=o(" \u2014 "),vz=a("a"),mBo=o("Data2VecVisionModel"),cBo=o(" (Data2VecVision model)"),fBo=l(),i1=a("li"),j2e=a("strong"),gBo=o("deberta"),hBo=o(" \u2014 "),Fz=a("a"),uBo=o("DebertaModel"),pBo=o(" (DeBERTa model)"),_Bo=l(),d1=a("li"),D2e=a("strong"),bBo=o("deberta-v2"),vBo=o(" \u2014 "),Tz=a("a"),FBo=o("DebertaV2Model"),TBo=o(" (DeBERTa-v2 model)"),MBo=l(),m1=a("li"),G2e=a("strong"),EBo=o("decision_transformer"),CBo=o(" \u2014 "),Mz=a("a"),wBo=o("DecisionTransformerModel"),ABo=o(" (Decision Transformer model)"),LBo=l(),c1=a("li"),O2e=a("strong"),yBo=o("deformable_detr"),xBo=o(" \u2014 "),Ez=a("a"),$Bo=o("DeformableDetrModel"),kBo=o(" (Deformable DETR model)"),SBo=l(),f1=a("li"),V2e=a("strong"),RBo=o("deit"),PBo=o(" \u2014 "),Cz=a("a"),BBo=o("DeiTModel"),IBo=o(" (DeiT model)"),NBo=l(),g1=a("li"),X2e=a("strong"),qBo=o("detr"),jBo=o(" \u2014 "),wz=a("a"),DBo=o("DetrModel"),GBo=o(" (DETR model)"),OBo=l(),h1=a("li"),z2e=a("strong"),VBo=o("distilbert"),XBo=o(" \u2014 "),Az=a("a"),zBo=o("DistilBertModel"),QBo=o(" (DistilBERT model)"),WBo=l(),u1=a("li"),Q2e=a("strong"),UBo=o("donut-swin"),HBo=o(" \u2014 "),Lz=a("a"),JBo=o("DonutSwinModel"),YBo=o(" (DonutSwin model)"),ZBo=l(),p1=a("li"),W2e=a("strong"),KBo=o("dpr"),eIo=o(" \u2014 "),yz=a("a"),oIo=o("DPRQuestionEncoder"),rIo=o(" (DPR model)"),tIo=l(),_1=a("li"),U2e=a("strong"),aIo=o("dpt"),nIo=o(" \u2014 "),xz=a("a"),sIo=o("DPTModel"),lIo=o(" (DPT model)"),iIo=l(),b1=a("li"),H2e=a("strong"),dIo=o("electra"),mIo=o(" \u2014 "),$z=a("a"),cIo=o("ElectraModel"),fIo=o(" (ELECTRA model)"),gIo=l(),v1=a("li"),J2e=a("strong"),hIo=o("ernie"),uIo=o(" \u2014 "),kz=a("a"),pIo=o("ErnieModel"),_Io=o(" (ERNIE model)"),bIo=l(),F1=a("li"),Y2e=a("strong"),vIo=o("esm"),FIo=o(" \u2014 "),Sz=a("a"),TIo=o("EsmModel"),MIo=o(" (ESM model)"),EIo=l(),T1=a("li"),Z2e=a("strong"),CIo=o("flaubert"),wIo=o(" \u2014 "),Rz=a("a"),AIo=o("FlaubertModel"),LIo=o(" (FlauBERT model)"),yIo=l(),M1=a("li"),K2e=a("strong"),xIo=o("flava"),$Io=o(" \u2014 "),Pz=a("a"),kIo=o("FlavaModel"),SIo=o(" (FLAVA model)"),RIo=l(),E1=a("li"),ebe=a("strong"),PIo=o("fnet"),BIo=o(" \u2014 "),Bz=a("a"),IIo=o("FNetModel"),NIo=o(" (FNet model)"),qIo=l(),C1=a("li"),obe=a("strong"),jIo=o("fsmt"),DIo=o(" \u2014 "),Iz=a("a"),GIo=o("FSMTModel"),OIo=o(" (FairSeq Machine-Translation model)"),VIo=l(),$l=a("li"),rbe=a("strong"),XIo=o("funnel"),zIo=o(" \u2014 "),Nz=a("a"),QIo=o("FunnelModel"),WIo=o(" or "),qz=a("a"),UIo=o("FunnelBaseModel"),HIo=o(" (Funnel Transformer model)"),JIo=l(),w1=a("li"),tbe=a("strong"),YIo=o("glpn"),ZIo=o(" \u2014 "),jz=a("a"),KIo=o("GLPNModel"),eNo=o(" (GLPN model)"),oNo=l(),A1=a("li"),abe=a("strong"),rNo=o("gpt2"),tNo=o(" \u2014 "),Dz=a("a"),aNo=o("GPT2Model"),nNo=o(" (OpenAI GPT-2 model)"),sNo=l(),L1=a("li"),nbe=a("strong"),lNo=o("gpt_neo"),iNo=o(" \u2014 "),Gz=a("a"),dNo=o("GPTNeoModel"),mNo=o(" (GPT Neo model)"),cNo=l(),y1=a("li"),sbe=a("strong"),fNo=o("gpt_neox"),gNo=o(" \u2014 "),Oz=a("a"),hNo=o("GPTNeoXModel"),uNo=o(" (GPT NeoX model)"),pNo=l(),x1=a("li"),lbe=a("strong"),_No=o("gpt_neox_japanese"),bNo=o(" \u2014 "),Vz=a("a"),vNo=o("GPTNeoXJapaneseModel"),FNo=o(" (GPT NeoX Japanese model)"),TNo=l(),$1=a("li"),ibe=a("strong"),MNo=o("gptj"),ENo=o(" \u2014 "),Xz=a("a"),CNo=o("GPTJModel"),wNo=o(" (GPT-J model)"),ANo=l(),k1=a("li"),dbe=a("strong"),LNo=o("groupvit"),yNo=o(" \u2014 "),zz=a("a"),xNo=o("GroupViTModel"),$No=o(" (GroupViT model)"),kNo=l(),S1=a("li"),mbe=a("strong"),SNo=o("hubert"),RNo=o(" \u2014 "),Qz=a("a"),PNo=o("HubertModel"),BNo=o(" (Hubert model)"),INo=l(),R1=a("li"),cbe=a("strong"),NNo=o("ibert"),qNo=o(" \u2014 "),Wz=a("a"),jNo=o("IBertModel"),DNo=o(" (I-BERT model)"),GNo=l(),P1=a("li"),fbe=a("strong"),ONo=o("imagegpt"),VNo=o(" \u2014 "),Uz=a("a"),XNo=o("ImageGPTModel"),zNo=o(" (ImageGPT model)"),QNo=l(),B1=a("li"),gbe=a("strong"),WNo=o("layoutlm"),UNo=o(" \u2014 "),Hz=a("a"),HNo=o("LayoutLMModel"),JNo=o(" (LayoutLM model)"),YNo=l(),I1=a("li"),hbe=a("strong"),ZNo=o("layoutlmv2"),KNo=o(" \u2014 "),Jz=a("a"),eqo=o("LayoutLMv2Model"),oqo=o(" (LayoutLMv2 model)"),rqo=l(),N1=a("li"),ube=a("strong"),tqo=o("layoutlmv3"),aqo=o(" \u2014 "),Yz=a("a"),nqo=o("LayoutLMv3Model"),sqo=o(" (LayoutLMv3 model)"),lqo=l(),q1=a("li"),pbe=a("strong"),iqo=o("led"),dqo=o(" \u2014 "),Zz=a("a"),mqo=o("LEDModel"),cqo=o(" (LED model)"),fqo=l(),j1=a("li"),_be=a("strong"),gqo=o("levit"),hqo=o(" \u2014 "),Kz=a("a"),uqo=o("LevitModel"),pqo=o(" (LeViT model)"),_qo=l(),D1=a("li"),bbe=a("strong"),bqo=o("lilt"),vqo=o(" \u2014 "),eQ=a("a"),Fqo=o("LiltModel"),Tqo=o(" (LiLT model)"),Mqo=l(),G1=a("li"),vbe=a("strong"),Eqo=o("longformer"),Cqo=o(" \u2014 "),oQ=a("a"),wqo=o("LongformerModel"),Aqo=o(" (Longformer model)"),Lqo=l(),O1=a("li"),Fbe=a("strong"),yqo=o("longt5"),xqo=o(" \u2014 "),rQ=a("a"),$qo=o("LongT5Model"),kqo=o(" (LongT5 model)"),Sqo=l(),V1=a("li"),Tbe=a("strong"),Rqo=o("luke"),Pqo=o(" \u2014 "),tQ=a("a"),Bqo=o("LukeModel"),Iqo=o(" (LUKE model)"),Nqo=l(),X1=a("li"),Mbe=a("strong"),qqo=o("lxmert"),jqo=o(" \u2014 "),aQ=a("a"),Dqo=o("LxmertModel"),Gqo=o(" (LXMERT model)"),Oqo=l(),z1=a("li"),Ebe=a("strong"),Vqo=o("m2m_100"),Xqo=o(" \u2014 "),nQ=a("a"),zqo=o("M2M100Model"),Qqo=o(" (M2M100 model)"),Wqo=l(),Q1=a("li"),Cbe=a("strong"),Uqo=o("marian"),Hqo=o(" \u2014 "),sQ=a("a"),Jqo=o("MarianModel"),Yqo=o(" (Marian model)"),Zqo=l(),W1=a("li"),wbe=a("strong"),Kqo=o("markuplm"),ejo=o(" \u2014 "),lQ=a("a"),ojo=o("MarkupLMModel"),rjo=o(" (MarkupLM model)"),tjo=l(),U1=a("li"),Abe=a("strong"),ajo=o("maskformer"),njo=o(" \u2014 "),iQ=a("a"),sjo=o("MaskFormerModel"),ljo=o(" (MaskFormer model)"),ijo=l(),H1=a("li"),Lbe=a("strong"),djo=o("mbart"),mjo=o(" \u2014 "),dQ=a("a"),cjo=o("MBartModel"),fjo=o(" (mBART model)"),gjo=l(),J1=a("li"),ybe=a("strong"),hjo=o("mctct"),ujo=o(" \u2014 "),mQ=a("a"),pjo=o("MCTCTModel"),_jo=o(" (M-CTC-T model)"),bjo=l(),Y1=a("li"),xbe=a("strong"),vjo=o("megatron-bert"),Fjo=o(" \u2014 "),cQ=a("a"),Tjo=o("MegatronBertModel"),Mjo=o(" (Megatron-BERT model)"),Ejo=l(),Z1=a("li"),$be=a("strong"),Cjo=o("mobilebert"),wjo=o(" \u2014 "),fQ=a("a"),Ajo=o("MobileBertModel"),Ljo=o(" (MobileBERT model)"),yjo=l(),K1=a("li"),kbe=a("strong"),xjo=o("mobilevit"),$jo=o(" \u2014 "),gQ=a("a"),kjo=o("MobileViTModel"),Sjo=o(" (MobileViT model)"),Rjo=l(),e2=a("li"),Sbe=a("strong"),Pjo=o("mpnet"),Bjo=o(" \u2014 "),hQ=a("a"),Ijo=o("MPNetModel"),Njo=o(" (MPNet model)"),qjo=l(),o2=a("li"),Rbe=a("strong"),jjo=o("mt5"),Djo=o(" \u2014 "),uQ=a("a"),Gjo=o("MT5Model"),Ojo=o(" (MT5 model)"),Vjo=l(),r2=a("li"),Pbe=a("strong"),Xjo=o("mvp"),zjo=o(" \u2014 "),pQ=a("a"),Qjo=o("MvpModel"),Wjo=o(" (MVP model)"),Ujo=l(),t2=a("li"),Bbe=a("strong"),Hjo=o("nezha"),Jjo=o(" \u2014 "),_Q=a("a"),Yjo=o("NezhaModel"),Zjo=o(" (Nezha model)"),Kjo=l(),a2=a("li"),Ibe=a("strong"),eDo=o("nllb"),oDo=o(" \u2014 "),bQ=a("a"),rDo=o("M2M100Model"),tDo=o(" (NLLB model)"),aDo=l(),n2=a("li"),Nbe=a("strong"),nDo=o("nystromformer"),sDo=o(" \u2014 "),vQ=a("a"),lDo=o("NystromformerModel"),iDo=o(" (Nystr\xF6mformer model)"),dDo=l(),s2=a("li"),qbe=a("strong"),mDo=o("openai-gpt"),cDo=o(" \u2014 "),FQ=a("a"),fDo=o("OpenAIGPTModel"),gDo=o(" (OpenAI GPT model)"),hDo=l(),l2=a("li"),jbe=a("strong"),uDo=o("opt"),pDo=o(" \u2014 "),TQ=a("a"),_Do=o("OPTModel"),bDo=o(" (OPT model)"),vDo=l(),i2=a("li"),Dbe=a("strong"),FDo=o("owlvit"),TDo=o(" \u2014 "),MQ=a("a"),MDo=o("OwlViTModel"),EDo=o(" (OWL-ViT model)"),CDo=l(),d2=a("li"),Gbe=a("strong"),wDo=o("pegasus"),ADo=o(" \u2014 "),EQ=a("a"),LDo=o("PegasusModel"),yDo=o(" (Pegasus model)"),xDo=l(),m2=a("li"),Obe=a("strong"),$Do=o("pegasus_x"),kDo=o(" \u2014 "),CQ=a("a"),SDo=o("PegasusXModel"),RDo=o(" (PEGASUS-X model)"),PDo=l(),c2=a("li"),Vbe=a("strong"),BDo=o("perceiver"),IDo=o(" \u2014 "),wQ=a("a"),NDo=o("PerceiverModel"),qDo=o(" (Perceiver model)"),jDo=l(),f2=a("li"),Xbe=a("strong"),DDo=o("plbart"),GDo=o(" \u2014 "),AQ=a("a"),ODo=o("PLBartModel"),VDo=o(" (PLBart model)"),XDo=l(),g2=a("li"),zbe=a("strong"),zDo=o("poolformer"),QDo=o(" \u2014 "),LQ=a("a"),WDo=o("PoolFormerModel"),UDo=o(" (PoolFormer model)"),HDo=l(),h2=a("li"),Qbe=a("strong"),JDo=o("prophetnet"),YDo=o(" \u2014 "),yQ=a("a"),ZDo=o("ProphetNetModel"),KDo=o(" (ProphetNet model)"),eGo=l(),u2=a("li"),Wbe=a("strong"),oGo=o("qdqbert"),rGo=o(" \u2014 "),xQ=a("a"),tGo=o("QDQBertModel"),aGo=o(" (QDQBert model)"),nGo=l(),p2=a("li"),Ube=a("strong"),sGo=o("reformer"),lGo=o(" \u2014 "),$Q=a("a"),iGo=o("ReformerModel"),dGo=o(" (Reformer model)"),mGo=l(),_2=a("li"),Hbe=a("strong"),cGo=o("regnet"),fGo=o(" \u2014 "),kQ=a("a"),gGo=o("RegNetModel"),hGo=o(" (RegNet model)"),uGo=l(),b2=a("li"),Jbe=a("strong"),pGo=o("rembert"),_Go=o(" \u2014 "),SQ=a("a"),bGo=o("RemBertModel"),vGo=o(" (RemBERT model)"),FGo=l(),v2=a("li"),Ybe=a("strong"),TGo=o("resnet"),MGo=o(" \u2014 "),RQ=a("a"),EGo=o("ResNetModel"),CGo=o(" (ResNet model)"),wGo=l(),F2=a("li"),Zbe=a("strong"),AGo=o("retribert"),LGo=o(" \u2014 "),PQ=a("a"),yGo=o("RetriBertModel"),xGo=o(" (RetriBERT model)"),$Go=l(),T2=a("li"),Kbe=a("strong"),kGo=o("roberta"),SGo=o(" \u2014 "),BQ=a("a"),RGo=o("RobertaModel"),PGo=o(" (RoBERTa model)"),BGo=l(),M2=a("li"),eve=a("strong"),IGo=o("roc_bert"),NGo=o(" \u2014 "),IQ=a("a"),qGo=o("RoCBertModel"),jGo=o(" (RoCBert model)"),DGo=l(),E2=a("li"),ove=a("strong"),GGo=o("roformer"),OGo=o(" \u2014 "),NQ=a("a"),VGo=o("RoFormerModel"),XGo=o(" (RoFormer model)"),zGo=l(),C2=a("li"),rve=a("strong"),QGo=o("segformer"),WGo=o(" \u2014 "),qQ=a("a"),UGo=o("SegformerModel"),HGo=o(" (SegFormer model)"),JGo=l(),w2=a("li"),tve=a("strong"),YGo=o("sew"),ZGo=o(" \u2014 "),jQ=a("a"),KGo=o("SEWModel"),eOo=o(" (SEW model)"),oOo=l(),A2=a("li"),ave=a("strong"),rOo=o("sew-d"),tOo=o(" \u2014 "),DQ=a("a"),aOo=o("SEWDModel"),nOo=o(" (SEW-D model)"),sOo=l(),L2=a("li"),nve=a("strong"),lOo=o("speech_to_text"),iOo=o(" \u2014 "),GQ=a("a"),dOo=o("Speech2TextModel"),mOo=o(" (Speech2Text model)"),cOo=l(),y2=a("li"),sve=a("strong"),fOo=o("splinter"),gOo=o(" \u2014 "),OQ=a("a"),hOo=o("SplinterModel"),uOo=o(" (Splinter model)"),pOo=l(),x2=a("li"),lve=a("strong"),_Oo=o("squeezebert"),bOo=o(" \u2014 "),VQ=a("a"),vOo=o("SqueezeBertModel"),FOo=o(" (SqueezeBERT model)"),TOo=l(),$2=a("li"),ive=a("strong"),MOo=o("swin"),EOo=o(" \u2014 "),XQ=a("a"),COo=o("SwinModel"),wOo=o(" (Swin Transformer model)"),AOo=l(),k2=a("li"),dve=a("strong"),LOo=o("swinv2"),yOo=o(" \u2014 "),zQ=a("a"),xOo=o("Swinv2Model"),$Oo=o(" (Swin Transformer V2 model)"),kOo=l(),S2=a("li"),mve=a("strong"),SOo=o("t5"),ROo=o(" \u2014 "),QQ=a("a"),POo=o("T5Model"),BOo=o(" (T5 model)"),IOo=l(),R2=a("li"),cve=a("strong"),NOo=o("table-transformer"),qOo=o(" \u2014 "),WQ=a("a"),jOo=o("TableTransformerModel"),DOo=o(" (Table Transformer model)"),GOo=l(),P2=a("li"),fve=a("strong"),OOo=o("tapas"),VOo=o(" \u2014 "),UQ=a("a"),XOo=o("TapasModel"),zOo=o(" (TAPAS model)"),QOo=l(),B2=a("li"),gve=a("strong"),WOo=o("time_series_transformer"),UOo=o(" \u2014 "),HQ=a("a"),HOo=o("TimeSeriesTransformerModel"),JOo=o(" (Time Series Transformer model)"),YOo=l(),I2=a("li"),hve=a("strong"),ZOo=o("trajectory_transformer"),KOo=o(" \u2014 "),JQ=a("a"),eVo=o("TrajectoryTransformerModel"),oVo=o(" (Trajectory Transformer model)"),rVo=l(),N2=a("li"),uve=a("strong"),tVo=o("transfo-xl"),aVo=o(" \u2014 "),YQ=a("a"),nVo=o("TransfoXLModel"),sVo=o(" (Transformer-XL model)"),lVo=l(),q2=a("li"),pve=a("strong"),iVo=o("unispeech"),dVo=o(" \u2014 "),ZQ=a("a"),mVo=o("UniSpeechModel"),cVo=o(" (UniSpeech model)"),fVo=l(),j2=a("li"),_ve=a("strong"),gVo=o("unispeech-sat"),hVo=o(" \u2014 "),KQ=a("a"),uVo=o("UniSpeechSatModel"),pVo=o(" (UniSpeechSat model)"),_Vo=l(),D2=a("li"),bve=a("strong"),bVo=o("van"),vVo=o(" \u2014 "),eW=a("a"),FVo=o("VanModel"),TVo=o(" (VAN model)"),MVo=l(),G2=a("li"),vve=a("strong"),EVo=o("videomae"),CVo=o(" \u2014 "),oW=a("a"),wVo=o("VideoMAEModel"),AVo=o(" (VideoMAE model)"),LVo=l(),O2=a("li"),Fve=a("strong"),yVo=o("vilt"),xVo=o(" \u2014 "),rW=a("a"),$Vo=o("ViltModel"),kVo=o(" (ViLT model)"),SVo=l(),V2=a("li"),Tve=a("strong"),RVo=o("vision-text-dual-encoder"),PVo=o(" \u2014 "),tW=a("a"),BVo=o("VisionTextDualEncoderModel"),IVo=o(" (VisionTextDualEncoder model)"),NVo=l(),X2=a("li"),Mve=a("strong"),qVo=o("visual_bert"),jVo=o(" \u2014 "),aW=a("a"),DVo=o("VisualBertModel"),GVo=o(" (VisualBERT model)"),OVo=l(),z2=a("li"),Eve=a("strong"),VVo=o("vit"),XVo=o(" \u2014 "),nW=a("a"),zVo=o("ViTModel"),QVo=o(" (ViT model)"),WVo=l(),Q2=a("li"),Cve=a("strong"),UVo=o("vit_mae"),HVo=o(" \u2014 "),sW=a("a"),JVo=o("ViTMAEModel"),YVo=o(" (ViTMAE model)"),ZVo=l(),W2=a("li"),wve=a("strong"),KVo=o("vit_msn"),eXo=o(" \u2014 "),lW=a("a"),oXo=o("ViTMSNModel"),rXo=o(" (ViTMSN model)"),tXo=l(),U2=a("li"),Ave=a("strong"),aXo=o("wav2vec2"),nXo=o(" \u2014 "),iW=a("a"),sXo=o("Wav2Vec2Model"),lXo=o(" (Wav2Vec2 model)"),iXo=l(),H2=a("li"),Lve=a("strong"),dXo=o("wav2vec2-conformer"),mXo=o(" \u2014 "),dW=a("a"),cXo=o("Wav2Vec2ConformerModel"),fXo=o(" (Wav2Vec2-Conformer model)"),gXo=l(),J2=a("li"),yve=a("strong"),hXo=o("wavlm"),uXo=o(" \u2014 "),mW=a("a"),pXo=o("WavLMModel"),_Xo=o(" (WavLM model)"),bXo=l(),Y2=a("li"),xve=a("strong"),vXo=o("whisper"),FXo=o(" \u2014 "),cW=a("a"),TXo=o("WhisperModel"),MXo=o(" (Whisper model)"),EXo=l(),Z2=a("li"),$ve=a("strong"),CXo=o("xclip"),wXo=o(" \u2014 "),fW=a("a"),AXo=o("XCLIPModel"),LXo=o(" (X-CLIP model)"),yXo=l(),K2=a("li"),kve=a("strong"),xXo=o("xglm"),$Xo=o(" \u2014 "),gW=a("a"),kXo=o("XGLMModel"),SXo=o(" (XGLM model)"),RXo=l(),eb=a("li"),Sve=a("strong"),PXo=o("xlm"),BXo=o(" \u2014 "),hW=a("a"),IXo=o("XLMModel"),NXo=o(" (XLM model)"),qXo=l(),ob=a("li"),Rve=a("strong"),jXo=o("xlm-prophetnet"),DXo=o(" \u2014 "),uW=a("a"),GXo=o("XLMProphetNetModel"),OXo=o(" (XLM-ProphetNet model)"),VXo=l(),rb=a("li"),Pve=a("strong"),XXo=o("xlm-roberta"),zXo=o(" \u2014 "),pW=a("a"),QXo=o("XLMRobertaModel"),WXo=o(" (XLM-RoBERTa model)"),UXo=l(),tb=a("li"),Bve=a("strong"),HXo=o("xlm-roberta-xl"),JXo=o(" \u2014 "),_W=a("a"),YXo=o("XLMRobertaXLModel"),ZXo=o(" (XLM-RoBERTa-XL model)"),KXo=l(),ab=a("li"),Ive=a("strong"),ezo=o("xlnet"),ozo=o(" \u2014 "),bW=a("a"),rzo=o("XLNetModel"),tzo=o(" (XLNet model)"),azo=l(),nb=a("li"),Nve=a("strong"),nzo=o("yolos"),szo=o(" \u2014 "),vW=a("a"),lzo=o("YolosModel"),izo=o(" (YOLOS model)"),dzo=l(),sb=a("li"),qve=a("strong"),mzo=o("yoso"),czo=o(" \u2014 "),FW=a("a"),fzo=o("YosoModel"),gzo=o(" (YOSO model)"),hzo=l(),lb=a("p"),uzo=o("The model is set in evaluation mode by default using "),jve=a("code"),pzo=o("model.eval()"),_zo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Dve=a("code"),bzo=o("model.train()"),vzo=l(),F(ib.$$.fragment),Vao=l(),Id=a("h2"),db=a("a"),Gve=a("span"),F(ek.$$.fragment),Fzo=l(),Ove=a("span"),Tzo=o("AutoModelForPreTraining"),Xao=l(),No=a("div"),F(ok.$$.fragment),Mzo=l(),Nd=a("p"),Ezo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),TW=a("a"),Czo=o("from_pretrained()"),wzo=o(" class method or the "),MW=a("a"),Azo=o("from_config()"),Lzo=o(` class
method.`),yzo=l(),rk=a("p"),xzo=o("This class cannot be instantiated directly using "),Vve=a("code"),$zo=o("__init__()"),kzo=o(" (throws an error)."),Szo=l(),Et=a("div"),F(tk.$$.fragment),Rzo=l(),Xve=a("p"),Pzo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Bzo=l(),qd=a("p"),Izo=o(`Note:
Loading a model from its configuration file does `),zve=a("strong"),Nzo=o("not"),qzo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),EW=a("a"),jzo=o("from_pretrained()"),Dzo=o(" to load the model weights."),Gzo=l(),F(mb.$$.fragment),Ozo=l(),eo=a("div"),F(ak.$$.fragment),Vzo=l(),Qve=a("p"),Xzo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),zzo=l(),sn=a("p"),Qzo=o("The model class to instantiate is selected based on the "),Wve=a("code"),Wzo=o("model_type"),Uzo=o(` property of the config object (either
passed as an argument or loaded from `),Uve=a("code"),Hzo=o("pretrained_model_name_or_path"),Jzo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Hve=a("code"),Yzo=o("pretrained_model_name_or_path"),Zzo=o(":"),Kzo=l(),G=a("ul"),cb=a("li"),Jve=a("strong"),eQo=o("albert"),oQo=o(" \u2014 "),CW=a("a"),rQo=o("AlbertForPreTraining"),tQo=o(" (ALBERT model)"),aQo=l(),fb=a("li"),Yve=a("strong"),nQo=o("bart"),sQo=o(" \u2014 "),wW=a("a"),lQo=o("BartForConditionalGeneration"),iQo=o(" (BART model)"),dQo=l(),gb=a("li"),Zve=a("strong"),mQo=o("bert"),cQo=o(" \u2014 "),AW=a("a"),fQo=o("BertForPreTraining"),gQo=o(" (BERT model)"),hQo=l(),hb=a("li"),Kve=a("strong"),uQo=o("big_bird"),pQo=o(" \u2014 "),LW=a("a"),_Qo=o("BigBirdForPreTraining"),bQo=o(" (BigBird model)"),vQo=l(),ub=a("li"),eFe=a("strong"),FQo=o("bloom"),TQo=o(" \u2014 "),yW=a("a"),MQo=o("BloomForCausalLM"),EQo=o(" (BLOOM model)"),CQo=l(),pb=a("li"),oFe=a("strong"),wQo=o("camembert"),AQo=o(" \u2014 "),xW=a("a"),LQo=o("CamembertForMaskedLM"),yQo=o(" (CamemBERT model)"),xQo=l(),_b=a("li"),rFe=a("strong"),$Qo=o("ctrl"),kQo=o(" \u2014 "),$W=a("a"),SQo=o("CTRLLMHeadModel"),RQo=o(" (CTRL model)"),PQo=l(),bb=a("li"),tFe=a("strong"),BQo=o("data2vec-text"),IQo=o(" \u2014 "),kW=a("a"),NQo=o("Data2VecTextForMaskedLM"),qQo=o(" (Data2VecText model)"),jQo=l(),vb=a("li"),aFe=a("strong"),DQo=o("deberta"),GQo=o(" \u2014 "),SW=a("a"),OQo=o("DebertaForMaskedLM"),VQo=o(" (DeBERTa model)"),XQo=l(),Fb=a("li"),nFe=a("strong"),zQo=o("deberta-v2"),QQo=o(" \u2014 "),RW=a("a"),WQo=o("DebertaV2ForMaskedLM"),UQo=o(" (DeBERTa-v2 model)"),HQo=l(),Tb=a("li"),sFe=a("strong"),JQo=o("distilbert"),YQo=o(" \u2014 "),PW=a("a"),ZQo=o("DistilBertForMaskedLM"),KQo=o(" (DistilBERT model)"),eWo=l(),Mb=a("li"),lFe=a("strong"),oWo=o("electra"),rWo=o(" \u2014 "),BW=a("a"),tWo=o("ElectraForPreTraining"),aWo=o(" (ELECTRA model)"),nWo=l(),Eb=a("li"),iFe=a("strong"),sWo=o("ernie"),lWo=o(" \u2014 "),IW=a("a"),iWo=o("ErnieForPreTraining"),dWo=o(" (ERNIE model)"),mWo=l(),Cb=a("li"),dFe=a("strong"),cWo=o("flaubert"),fWo=o(" \u2014 "),NW=a("a"),gWo=o("FlaubertWithLMHeadModel"),hWo=o(" (FlauBERT model)"),uWo=l(),wb=a("li"),mFe=a("strong"),pWo=o("flava"),_Wo=o(" \u2014 "),qW=a("a"),bWo=o("FlavaForPreTraining"),vWo=o(" (FLAVA model)"),FWo=l(),Ab=a("li"),cFe=a("strong"),TWo=o("fnet"),MWo=o(" \u2014 "),jW=a("a"),EWo=o("FNetForPreTraining"),CWo=o(" (FNet model)"),wWo=l(),Lb=a("li"),fFe=a("strong"),AWo=o("fsmt"),LWo=o(" \u2014 "),DW=a("a"),yWo=o("FSMTForConditionalGeneration"),xWo=o(" (FairSeq Machine-Translation model)"),$Wo=l(),yb=a("li"),gFe=a("strong"),kWo=o("funnel"),SWo=o(" \u2014 "),GW=a("a"),RWo=o("FunnelForPreTraining"),PWo=o(" (Funnel Transformer model)"),BWo=l(),xb=a("li"),hFe=a("strong"),IWo=o("gpt2"),NWo=o(" \u2014 "),OW=a("a"),qWo=o("GPT2LMHeadModel"),jWo=o(" (OpenAI GPT-2 model)"),DWo=l(),$b=a("li"),uFe=a("strong"),GWo=o("ibert"),OWo=o(" \u2014 "),VW=a("a"),VWo=o("IBertForMaskedLM"),XWo=o(" (I-BERT model)"),zWo=l(),kb=a("li"),pFe=a("strong"),QWo=o("layoutlm"),WWo=o(" \u2014 "),XW=a("a"),UWo=o("LayoutLMForMaskedLM"),HWo=o(" (LayoutLM model)"),JWo=l(),Sb=a("li"),_Fe=a("strong"),YWo=o("longformer"),ZWo=o(" \u2014 "),zW=a("a"),KWo=o("LongformerForMaskedLM"),eUo=o(" (Longformer model)"),oUo=l(),Rb=a("li"),bFe=a("strong"),rUo=o("luke"),tUo=o(" \u2014 "),QW=a("a"),aUo=o("LukeForMaskedLM"),nUo=o(" (LUKE model)"),sUo=l(),Pb=a("li"),vFe=a("strong"),lUo=o("lxmert"),iUo=o(" \u2014 "),WW=a("a"),dUo=o("LxmertForPreTraining"),mUo=o(" (LXMERT model)"),cUo=l(),Bb=a("li"),FFe=a("strong"),fUo=o("megatron-bert"),gUo=o(" \u2014 "),UW=a("a"),hUo=o("MegatronBertForPreTraining"),uUo=o(" (Megatron-BERT model)"),pUo=l(),Ib=a("li"),TFe=a("strong"),_Uo=o("mobilebert"),bUo=o(" \u2014 "),HW=a("a"),vUo=o("MobileBertForPreTraining"),FUo=o(" (MobileBERT model)"),TUo=l(),Nb=a("li"),MFe=a("strong"),MUo=o("mpnet"),EUo=o(" \u2014 "),JW=a("a"),CUo=o("MPNetForMaskedLM"),wUo=o(" (MPNet model)"),AUo=l(),qb=a("li"),EFe=a("strong"),LUo=o("mvp"),yUo=o(" \u2014 "),YW=a("a"),xUo=o("MvpForConditionalGeneration"),$Uo=o(" (MVP model)"),kUo=l(),jb=a("li"),CFe=a("strong"),SUo=o("nezha"),RUo=o(" \u2014 "),ZW=a("a"),PUo=o("NezhaForPreTraining"),BUo=o(" (Nezha model)"),IUo=l(),Db=a("li"),wFe=a("strong"),NUo=o("openai-gpt"),qUo=o(" \u2014 "),KW=a("a"),jUo=o("OpenAIGPTLMHeadModel"),DUo=o(" (OpenAI GPT model)"),GUo=l(),Gb=a("li"),AFe=a("strong"),OUo=o("retribert"),VUo=o(" \u2014 "),eU=a("a"),XUo=o("RetriBertModel"),zUo=o(" (RetriBERT model)"),QUo=l(),Ob=a("li"),LFe=a("strong"),WUo=o("roberta"),UUo=o(" \u2014 "),oU=a("a"),HUo=o("RobertaForMaskedLM"),JUo=o(" (RoBERTa model)"),YUo=l(),Vb=a("li"),yFe=a("strong"),ZUo=o("roc_bert"),KUo=o(" \u2014 "),rU=a("a"),eHo=o("RoCBertForPreTraining"),oHo=o(" (RoCBert model)"),rHo=l(),Xb=a("li"),xFe=a("strong"),tHo=o("splinter"),aHo=o(" \u2014 "),tU=a("a"),nHo=o("SplinterForPreTraining"),sHo=o(" (Splinter model)"),lHo=l(),zb=a("li"),$Fe=a("strong"),iHo=o("squeezebert"),dHo=o(" \u2014 "),aU=a("a"),mHo=o("SqueezeBertForMaskedLM"),cHo=o(" (SqueezeBERT model)"),fHo=l(),Qb=a("li"),kFe=a("strong"),gHo=o("t5"),hHo=o(" \u2014 "),nU=a("a"),uHo=o("T5ForConditionalGeneration"),pHo=o(" (T5 model)"),_Ho=l(),Wb=a("li"),SFe=a("strong"),bHo=o("tapas"),vHo=o(" \u2014 "),sU=a("a"),FHo=o("TapasForMaskedLM"),THo=o(" (TAPAS model)"),MHo=l(),Ub=a("li"),RFe=a("strong"),EHo=o("transfo-xl"),CHo=o(" \u2014 "),lU=a("a"),wHo=o("TransfoXLLMHeadModel"),AHo=o(" (Transformer-XL model)"),LHo=l(),Hb=a("li"),PFe=a("strong"),yHo=o("unispeech"),xHo=o(" \u2014 "),iU=a("a"),$Ho=o("UniSpeechForPreTraining"),kHo=o(" (UniSpeech model)"),SHo=l(),Jb=a("li"),BFe=a("strong"),RHo=o("unispeech-sat"),PHo=o(" \u2014 "),dU=a("a"),BHo=o("UniSpeechSatForPreTraining"),IHo=o(" (UniSpeechSat model)"),NHo=l(),Yb=a("li"),IFe=a("strong"),qHo=o("videomae"),jHo=o(" \u2014 "),mU=a("a"),DHo=o("VideoMAEForPreTraining"),GHo=o(" (VideoMAE model)"),OHo=l(),Zb=a("li"),NFe=a("strong"),VHo=o("visual_bert"),XHo=o(" \u2014 "),cU=a("a"),zHo=o("VisualBertForPreTraining"),QHo=o(" (VisualBERT model)"),WHo=l(),Kb=a("li"),qFe=a("strong"),UHo=o("vit_mae"),HHo=o(" \u2014 "),fU=a("a"),JHo=o("ViTMAEForPreTraining"),YHo=o(" (ViTMAE model)"),ZHo=l(),ev=a("li"),jFe=a("strong"),KHo=o("wav2vec2"),eJo=o(" \u2014 "),gU=a("a"),oJo=o("Wav2Vec2ForPreTraining"),rJo=o(" (Wav2Vec2 model)"),tJo=l(),ov=a("li"),DFe=a("strong"),aJo=o("wav2vec2-conformer"),nJo=o(" \u2014 "),hU=a("a"),sJo=o("Wav2Vec2ConformerForPreTraining"),lJo=o(" (Wav2Vec2-Conformer model)"),iJo=l(),rv=a("li"),GFe=a("strong"),dJo=o("xlm"),mJo=o(" \u2014 "),uU=a("a"),cJo=o("XLMWithLMHeadModel"),fJo=o(" (XLM model)"),gJo=l(),tv=a("li"),OFe=a("strong"),hJo=o("xlm-roberta"),uJo=o(" \u2014 "),pU=a("a"),pJo=o("XLMRobertaForMaskedLM"),_Jo=o(" (XLM-RoBERTa model)"),bJo=l(),av=a("li"),VFe=a("strong"),vJo=o("xlm-roberta-xl"),FJo=o(" \u2014 "),_U=a("a"),TJo=o("XLMRobertaXLForMaskedLM"),MJo=o(" (XLM-RoBERTa-XL model)"),EJo=l(),nv=a("li"),XFe=a("strong"),CJo=o("xlnet"),wJo=o(" \u2014 "),bU=a("a"),AJo=o("XLNetLMHeadModel"),LJo=o(" (XLNet model)"),yJo=l(),sv=a("p"),xJo=o("The model is set in evaluation mode by default using "),zFe=a("code"),$Jo=o("model.eval()"),kJo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),QFe=a("code"),SJo=o("model.train()"),RJo=l(),F(lv.$$.fragment),zao=l(),jd=a("h2"),iv=a("a"),WFe=a("span"),F(nk.$$.fragment),PJo=l(),UFe=a("span"),BJo=o("AutoModelForCausalLM"),Qao=l(),qo=a("div"),F(sk.$$.fragment),IJo=l(),Dd=a("p"),NJo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),vU=a("a"),qJo=o("from_pretrained()"),jJo=o(" class method or the "),FU=a("a"),DJo=o("from_config()"),GJo=o(` class
method.`),OJo=l(),lk=a("p"),VJo=o("This class cannot be instantiated directly using "),HFe=a("code"),XJo=o("__init__()"),zJo=o(" (throws an error)."),QJo=l(),Ct=a("div"),F(ik.$$.fragment),WJo=l(),JFe=a("p"),UJo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),HJo=l(),Gd=a("p"),JJo=o(`Note:
Loading a model from its configuration file does `),YFe=a("strong"),YJo=o("not"),ZJo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),TU=a("a"),KJo=o("from_pretrained()"),eYo=o(" to load the model weights."),oYo=l(),F(dv.$$.fragment),rYo=l(),oo=a("div"),F(dk.$$.fragment),tYo=l(),ZFe=a("p"),aYo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),nYo=l(),ln=a("p"),sYo=o("The model class to instantiate is selected based on the "),KFe=a("code"),lYo=o("model_type"),iYo=o(` property of the config object (either
passed as an argument or loaded from `),eTe=a("code"),dYo=o("pretrained_model_name_or_path"),mYo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oTe=a("code"),cYo=o("pretrained_model_name_or_path"),fYo=o(":"),gYo=l(),W=a("ul"),mv=a("li"),rTe=a("strong"),hYo=o("bart"),uYo=o(" \u2014 "),MU=a("a"),pYo=o("BartForCausalLM"),_Yo=o(" (BART model)"),bYo=l(),cv=a("li"),tTe=a("strong"),vYo=o("bert"),FYo=o(" \u2014 "),EU=a("a"),TYo=o("BertLMHeadModel"),MYo=o(" (BERT model)"),EYo=l(),fv=a("li"),aTe=a("strong"),CYo=o("bert-generation"),wYo=o(" \u2014 "),CU=a("a"),AYo=o("BertGenerationDecoder"),LYo=o(" (Bert Generation model)"),yYo=l(),gv=a("li"),nTe=a("strong"),xYo=o("big_bird"),$Yo=o(" \u2014 "),wU=a("a"),kYo=o("BigBirdForCausalLM"),SYo=o(" (BigBird model)"),RYo=l(),hv=a("li"),sTe=a("strong"),PYo=o("bigbird_pegasus"),BYo=o(" \u2014 "),AU=a("a"),IYo=o("BigBirdPegasusForCausalLM"),NYo=o(" (BigBird-Pegasus model)"),qYo=l(),uv=a("li"),lTe=a("strong"),jYo=o("blenderbot"),DYo=o(" \u2014 "),LU=a("a"),GYo=o("BlenderbotForCausalLM"),OYo=o(" (Blenderbot model)"),VYo=l(),pv=a("li"),iTe=a("strong"),XYo=o("blenderbot-small"),zYo=o(" \u2014 "),yU=a("a"),QYo=o("BlenderbotSmallForCausalLM"),WYo=o(" (BlenderbotSmall model)"),UYo=l(),_v=a("li"),dTe=a("strong"),HYo=o("bloom"),JYo=o(" \u2014 "),xU=a("a"),YYo=o("BloomForCausalLM"),ZYo=o(" (BLOOM model)"),KYo=l(),bv=a("li"),mTe=a("strong"),eZo=o("camembert"),oZo=o(" \u2014 "),$U=a("a"),rZo=o("CamembertForCausalLM"),tZo=o(" (CamemBERT model)"),aZo=l(),vv=a("li"),cTe=a("strong"),nZo=o("codegen"),sZo=o(" \u2014 "),kU=a("a"),lZo=o("CodeGenForCausalLM"),iZo=o(" (CodeGen model)"),dZo=l(),Fv=a("li"),fTe=a("strong"),mZo=o("ctrl"),cZo=o(" \u2014 "),SU=a("a"),fZo=o("CTRLLMHeadModel"),gZo=o(" (CTRL model)"),hZo=l(),Tv=a("li"),gTe=a("strong"),uZo=o("data2vec-text"),pZo=o(" \u2014 "),RU=a("a"),_Zo=o("Data2VecTextForCausalLM"),bZo=o(" (Data2VecText model)"),vZo=l(),Mv=a("li"),hTe=a("strong"),FZo=o("electra"),TZo=o(" \u2014 "),PU=a("a"),MZo=o("ElectraForCausalLM"),EZo=o(" (ELECTRA model)"),CZo=l(),Ev=a("li"),uTe=a("strong"),wZo=o("ernie"),AZo=o(" \u2014 "),BU=a("a"),LZo=o("ErnieForCausalLM"),yZo=o(" (ERNIE model)"),xZo=l(),Cv=a("li"),pTe=a("strong"),$Zo=o("gpt2"),kZo=o(" \u2014 "),IU=a("a"),SZo=o("GPT2LMHeadModel"),RZo=o(" (OpenAI GPT-2 model)"),PZo=l(),wv=a("li"),_Te=a("strong"),BZo=o("gpt_neo"),IZo=o(" \u2014 "),NU=a("a"),NZo=o("GPTNeoForCausalLM"),qZo=o(" (GPT Neo model)"),jZo=l(),Av=a("li"),bTe=a("strong"),DZo=o("gpt_neox"),GZo=o(" \u2014 "),qU=a("a"),OZo=o("GPTNeoXForCausalLM"),VZo=o(" (GPT NeoX model)"),XZo=l(),Lv=a("li"),vTe=a("strong"),zZo=o("gpt_neox_japanese"),QZo=o(" \u2014 "),jU=a("a"),WZo=o("GPTNeoXJapaneseForCausalLM"),UZo=o(" (GPT NeoX Japanese model)"),HZo=l(),yv=a("li"),FTe=a("strong"),JZo=o("gptj"),YZo=o(" \u2014 "),DU=a("a"),ZZo=o("GPTJForCausalLM"),KZo=o(" (GPT-J model)"),eKo=l(),xv=a("li"),TTe=a("strong"),oKo=o("marian"),rKo=o(" \u2014 "),GU=a("a"),tKo=o("MarianForCausalLM"),aKo=o(" (Marian model)"),nKo=l(),$v=a("li"),MTe=a("strong"),sKo=o("mbart"),lKo=o(" \u2014 "),OU=a("a"),iKo=o("MBartForCausalLM"),dKo=o(" (mBART model)"),mKo=l(),kv=a("li"),ETe=a("strong"),cKo=o("megatron-bert"),fKo=o(" \u2014 "),VU=a("a"),gKo=o("MegatronBertForCausalLM"),hKo=o(" (Megatron-BERT model)"),uKo=l(),Sv=a("li"),CTe=a("strong"),pKo=o("mvp"),_Ko=o(" \u2014 "),XU=a("a"),bKo=o("MvpForCausalLM"),vKo=o(" (MVP model)"),FKo=l(),Rv=a("li"),wTe=a("strong"),TKo=o("openai-gpt"),MKo=o(" \u2014 "),zU=a("a"),EKo=o("OpenAIGPTLMHeadModel"),CKo=o(" (OpenAI GPT model)"),wKo=l(),Pv=a("li"),ATe=a("strong"),AKo=o("opt"),LKo=o(" \u2014 "),QU=a("a"),yKo=o("OPTForCausalLM"),xKo=o(" (OPT model)"),$Ko=l(),Bv=a("li"),LTe=a("strong"),kKo=o("pegasus"),SKo=o(" \u2014 "),WU=a("a"),RKo=o("PegasusForCausalLM"),PKo=o(" (Pegasus model)"),BKo=l(),Iv=a("li"),yTe=a("strong"),IKo=o("plbart"),NKo=o(" \u2014 "),UU=a("a"),qKo=o("PLBartForCausalLM"),jKo=o(" (PLBart model)"),DKo=l(),Nv=a("li"),xTe=a("strong"),GKo=o("prophetnet"),OKo=o(" \u2014 "),HU=a("a"),VKo=o("ProphetNetForCausalLM"),XKo=o(" (ProphetNet model)"),zKo=l(),qv=a("li"),$Te=a("strong"),QKo=o("qdqbert"),WKo=o(" \u2014 "),JU=a("a"),UKo=o("QDQBertLMHeadModel"),HKo=o(" (QDQBert model)"),JKo=l(),jv=a("li"),kTe=a("strong"),YKo=o("reformer"),ZKo=o(" \u2014 "),YU=a("a"),KKo=o("ReformerModelWithLMHead"),eer=o(" (Reformer model)"),oer=l(),Dv=a("li"),STe=a("strong"),rer=o("rembert"),ter=o(" \u2014 "),ZU=a("a"),aer=o("RemBertForCausalLM"),ner=o(" (RemBERT model)"),ser=l(),Gv=a("li"),RTe=a("strong"),ler=o("roberta"),ier=o(" \u2014 "),KU=a("a"),der=o("RobertaForCausalLM"),mer=o(" (RoBERTa model)"),cer=l(),Ov=a("li"),PTe=a("strong"),fer=o("roc_bert"),ger=o(" \u2014 "),eH=a("a"),her=o("RoCBertForCausalLM"),uer=o(" (RoCBert model)"),per=l(),Vv=a("li"),BTe=a("strong"),_er=o("roformer"),ber=o(" \u2014 "),oH=a("a"),ver=o("RoFormerForCausalLM"),Fer=o(" (RoFormer model)"),Ter=l(),Xv=a("li"),ITe=a("strong"),Mer=o("speech_to_text_2"),Eer=o(" \u2014 "),rH=a("a"),Cer=o("Speech2Text2ForCausalLM"),wer=o(" (Speech2Text2 model)"),Aer=l(),zv=a("li"),NTe=a("strong"),Ler=o("transfo-xl"),yer=o(" \u2014 "),tH=a("a"),xer=o("TransfoXLLMHeadModel"),$er=o(" (Transformer-XL model)"),ker=l(),Qv=a("li"),qTe=a("strong"),Ser=o("trocr"),Rer=o(" \u2014 "),aH=a("a"),Per=o("TrOCRForCausalLM"),Ber=o(" (TrOCR model)"),Ier=l(),Wv=a("li"),jTe=a("strong"),Ner=o("xglm"),qer=o(" \u2014 "),nH=a("a"),jer=o("XGLMForCausalLM"),Der=o(" (XGLM model)"),Ger=l(),Uv=a("li"),DTe=a("strong"),Oer=o("xlm"),Ver=o(" \u2014 "),sH=a("a"),Xer=o("XLMWithLMHeadModel"),zer=o(" (XLM model)"),Qer=l(),Hv=a("li"),GTe=a("strong"),Wer=o("xlm-prophetnet"),Uer=o(" \u2014 "),lH=a("a"),Her=o("XLMProphetNetForCausalLM"),Jer=o(" (XLM-ProphetNet model)"),Yer=l(),Jv=a("li"),OTe=a("strong"),Zer=o("xlm-roberta"),Ker=o(" \u2014 "),iH=a("a"),eor=o("XLMRobertaForCausalLM"),oor=o(" (XLM-RoBERTa model)"),ror=l(),Yv=a("li"),VTe=a("strong"),tor=o("xlm-roberta-xl"),aor=o(" \u2014 "),dH=a("a"),nor=o("XLMRobertaXLForCausalLM"),sor=o(" (XLM-RoBERTa-XL model)"),lor=l(),Zv=a("li"),XTe=a("strong"),ior=o("xlnet"),dor=o(" \u2014 "),mH=a("a"),mor=o("XLNetLMHeadModel"),cor=o(" (XLNet model)"),gor=l(),Kv=a("p"),hor=o("The model is set in evaluation mode by default using "),zTe=a("code"),uor=o("model.eval()"),por=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),QTe=a("code"),_or=o("model.train()"),bor=l(),F(eF.$$.fragment),Wao=l(),Od=a("h2"),oF=a("a"),WTe=a("span"),F(mk.$$.fragment),vor=l(),UTe=a("span"),For=o("AutoModelForDepthEstimation"),Uao=l(),jo=a("div"),F(ck.$$.fragment),Tor=l(),Vd=a("p"),Mor=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a depth estimation head) when created
with the `),cH=a("a"),Eor=o("from_pretrained()"),Cor=o(" class method or the "),fH=a("a"),wor=o("from_config()"),Aor=o(` class
method.`),Lor=l(),fk=a("p"),yor=o("This class cannot be instantiated directly using "),HTe=a("code"),xor=o("__init__()"),$or=o(" (throws an error)."),kor=l(),wt=a("div"),F(gk.$$.fragment),Sor=l(),JTe=a("p"),Ror=o("Instantiates one of the model classes of the library (with a depth estimation head) from a configuration."),Por=l(),Xd=a("p"),Bor=o(`Note:
Loading a model from its configuration file does `),YTe=a("strong"),Ior=o("not"),Nor=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gH=a("a"),qor=o("from_pretrained()"),jor=o(" to load the model weights."),Dor=l(),F(rF.$$.fragment),Gor=l(),ro=a("div"),F(hk.$$.fragment),Oor=l(),ZTe=a("p"),Vor=o("Instantiate one of the model classes of the library (with a depth estimation head) from a pretrained model."),Xor=l(),dn=a("p"),zor=o("The model class to instantiate is selected based on the "),KTe=a("code"),Qor=o("model_type"),Wor=o(` property of the config object (either
passed as an argument or loaded from `),eMe=a("code"),Uor=o("pretrained_model_name_or_path"),Hor=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oMe=a("code"),Jor=o("pretrained_model_name_or_path"),Yor=o(":"),Zor=l(),uk=a("ul"),tF=a("li"),rMe=a("strong"),Kor=o("dpt"),err=o(" \u2014 "),hH=a("a"),orr=o("DPTForDepthEstimation"),rrr=o(" (DPT model)"),trr=l(),aF=a("li"),tMe=a("strong"),arr=o("glpn"),nrr=o(" \u2014 "),uH=a("a"),srr=o("GLPNForDepthEstimation"),lrr=o(" (GLPN model)"),irr=l(),nF=a("p"),drr=o("The model is set in evaluation mode by default using "),aMe=a("code"),mrr=o("model.eval()"),crr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),nMe=a("code"),frr=o("model.train()"),grr=l(),F(sF.$$.fragment),Hao=l(),zd=a("h2"),lF=a("a"),sMe=a("span"),F(pk.$$.fragment),hrr=l(),lMe=a("span"),urr=o("AutoModelForMaskedLM"),Jao=l(),Do=a("div"),F(_k.$$.fragment),prr=l(),Qd=a("p"),_rr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),pH=a("a"),brr=o("from_pretrained()"),vrr=o(" class method or the "),_H=a("a"),Frr=o("from_config()"),Trr=o(` class
method.`),Mrr=l(),bk=a("p"),Err=o("This class cannot be instantiated directly using "),iMe=a("code"),Crr=o("__init__()"),wrr=o(" (throws an error)."),Arr=l(),At=a("div"),F(vk.$$.fragment),Lrr=l(),dMe=a("p"),yrr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),xrr=l(),Wd=a("p"),$rr=o(`Note:
Loading a model from its configuration file does `),mMe=a("strong"),krr=o("not"),Srr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bH=a("a"),Rrr=o("from_pretrained()"),Prr=o(" to load the model weights."),Brr=l(),F(iF.$$.fragment),Irr=l(),to=a("div"),F(Fk.$$.fragment),Nrr=l(),cMe=a("p"),qrr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),jrr=l(),mn=a("p"),Drr=o("The model class to instantiate is selected based on the "),fMe=a("code"),Grr=o("model_type"),Orr=o(` property of the config object (either
passed as an argument or loaded from `),gMe=a("code"),Vrr=o("pretrained_model_name_or_path"),Xrr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hMe=a("code"),zrr=o("pretrained_model_name_or_path"),Qrr=o(":"),Wrr=l(),Y=a("ul"),dF=a("li"),uMe=a("strong"),Urr=o("albert"),Hrr=o(" \u2014 "),vH=a("a"),Jrr=o("AlbertForMaskedLM"),Yrr=o(" (ALBERT model)"),Zrr=l(),mF=a("li"),pMe=a("strong"),Krr=o("bart"),etr=o(" \u2014 "),FH=a("a"),otr=o("BartForConditionalGeneration"),rtr=o(" (BART model)"),ttr=l(),cF=a("li"),_Me=a("strong"),atr=o("bert"),ntr=o(" \u2014 "),TH=a("a"),str=o("BertForMaskedLM"),ltr=o(" (BERT model)"),itr=l(),fF=a("li"),bMe=a("strong"),dtr=o("big_bird"),mtr=o(" \u2014 "),MH=a("a"),ctr=o("BigBirdForMaskedLM"),ftr=o(" (BigBird model)"),gtr=l(),gF=a("li"),vMe=a("strong"),htr=o("camembert"),utr=o(" \u2014 "),EH=a("a"),ptr=o("CamembertForMaskedLM"),_tr=o(" (CamemBERT model)"),btr=l(),hF=a("li"),FMe=a("strong"),vtr=o("convbert"),Ftr=o(" \u2014 "),CH=a("a"),Ttr=o("ConvBertForMaskedLM"),Mtr=o(" (ConvBERT model)"),Etr=l(),uF=a("li"),TMe=a("strong"),Ctr=o("data2vec-text"),wtr=o(" \u2014 "),wH=a("a"),Atr=o("Data2VecTextForMaskedLM"),Ltr=o(" (Data2VecText model)"),ytr=l(),pF=a("li"),MMe=a("strong"),xtr=o("deberta"),$tr=o(" \u2014 "),AH=a("a"),ktr=o("DebertaForMaskedLM"),Str=o(" (DeBERTa model)"),Rtr=l(),_F=a("li"),EMe=a("strong"),Ptr=o("deberta-v2"),Btr=o(" \u2014 "),LH=a("a"),Itr=o("DebertaV2ForMaskedLM"),Ntr=o(" (DeBERTa-v2 model)"),qtr=l(),bF=a("li"),CMe=a("strong"),jtr=o("distilbert"),Dtr=o(" \u2014 "),yH=a("a"),Gtr=o("DistilBertForMaskedLM"),Otr=o(" (DistilBERT model)"),Vtr=l(),vF=a("li"),wMe=a("strong"),Xtr=o("electra"),ztr=o(" \u2014 "),xH=a("a"),Qtr=o("ElectraForMaskedLM"),Wtr=o(" (ELECTRA model)"),Utr=l(),FF=a("li"),AMe=a("strong"),Htr=o("ernie"),Jtr=o(" \u2014 "),$H=a("a"),Ytr=o("ErnieForMaskedLM"),Ztr=o(" (ERNIE model)"),Ktr=l(),TF=a("li"),LMe=a("strong"),ear=o("flaubert"),oar=o(" \u2014 "),kH=a("a"),rar=o("FlaubertWithLMHeadModel"),tar=o(" (FlauBERT model)"),aar=l(),MF=a("li"),yMe=a("strong"),nar=o("fnet"),sar=o(" \u2014 "),SH=a("a"),lar=o("FNetForMaskedLM"),iar=o(" (FNet model)"),dar=l(),EF=a("li"),xMe=a("strong"),mar=o("funnel"),car=o(" \u2014 "),RH=a("a"),far=o("FunnelForMaskedLM"),gar=o(" (Funnel Transformer model)"),har=l(),CF=a("li"),$Me=a("strong"),uar=o("ibert"),par=o(" \u2014 "),PH=a("a"),_ar=o("IBertForMaskedLM"),bar=o(" (I-BERT model)"),Far=l(),wF=a("li"),kMe=a("strong"),Tar=o("layoutlm"),Mar=o(" \u2014 "),BH=a("a"),Ear=o("LayoutLMForMaskedLM"),Car=o(" (LayoutLM model)"),war=l(),AF=a("li"),SMe=a("strong"),Aar=o("longformer"),Lar=o(" \u2014 "),IH=a("a"),yar=o("LongformerForMaskedLM"),xar=o(" (Longformer model)"),$ar=l(),LF=a("li"),RMe=a("strong"),kar=o("luke"),Sar=o(" \u2014 "),NH=a("a"),Rar=o("LukeForMaskedLM"),Par=o(" (LUKE model)"),Bar=l(),yF=a("li"),PMe=a("strong"),Iar=o("mbart"),Nar=o(" \u2014 "),qH=a("a"),qar=o("MBartForConditionalGeneration"),jar=o(" (mBART model)"),Dar=l(),xF=a("li"),BMe=a("strong"),Gar=o("megatron-bert"),Oar=o(" \u2014 "),jH=a("a"),Var=o("MegatronBertForMaskedLM"),Xar=o(" (Megatron-BERT model)"),zar=l(),$F=a("li"),IMe=a("strong"),Qar=o("mobilebert"),War=o(" \u2014 "),DH=a("a"),Uar=o("MobileBertForMaskedLM"),Har=o(" (MobileBERT model)"),Jar=l(),kF=a("li"),NMe=a("strong"),Yar=o("mpnet"),Zar=o(" \u2014 "),GH=a("a"),Kar=o("MPNetForMaskedLM"),enr=o(" (MPNet model)"),onr=l(),SF=a("li"),qMe=a("strong"),rnr=o("mvp"),tnr=o(" \u2014 "),OH=a("a"),anr=o("MvpForConditionalGeneration"),nnr=o(" (MVP model)"),snr=l(),RF=a("li"),jMe=a("strong"),lnr=o("nezha"),inr=o(" \u2014 "),VH=a("a"),dnr=o("NezhaForMaskedLM"),mnr=o(" (Nezha model)"),cnr=l(),PF=a("li"),DMe=a("strong"),fnr=o("nystromformer"),gnr=o(" \u2014 "),XH=a("a"),hnr=o("NystromformerForMaskedLM"),unr=o(" (Nystr\xF6mformer model)"),pnr=l(),BF=a("li"),GMe=a("strong"),_nr=o("perceiver"),bnr=o(" \u2014 "),zH=a("a"),vnr=o("PerceiverForMaskedLM"),Fnr=o(" (Perceiver model)"),Tnr=l(),IF=a("li"),OMe=a("strong"),Mnr=o("qdqbert"),Enr=o(" \u2014 "),QH=a("a"),Cnr=o("QDQBertForMaskedLM"),wnr=o(" (QDQBert model)"),Anr=l(),NF=a("li"),VMe=a("strong"),Lnr=o("reformer"),ynr=o(" \u2014 "),WH=a("a"),xnr=o("ReformerForMaskedLM"),$nr=o(" (Reformer model)"),knr=l(),qF=a("li"),XMe=a("strong"),Snr=o("rembert"),Rnr=o(" \u2014 "),UH=a("a"),Pnr=o("RemBertForMaskedLM"),Bnr=o(" (RemBERT model)"),Inr=l(),jF=a("li"),zMe=a("strong"),Nnr=o("roberta"),qnr=o(" \u2014 "),HH=a("a"),jnr=o("RobertaForMaskedLM"),Dnr=o(" (RoBERTa model)"),Gnr=l(),DF=a("li"),QMe=a("strong"),Onr=o("roc_bert"),Vnr=o(" \u2014 "),JH=a("a"),Xnr=o("RoCBertForMaskedLM"),znr=o(" (RoCBert model)"),Qnr=l(),GF=a("li"),WMe=a("strong"),Wnr=o("roformer"),Unr=o(" \u2014 "),YH=a("a"),Hnr=o("RoFormerForMaskedLM"),Jnr=o(" (RoFormer model)"),Ynr=l(),OF=a("li"),UMe=a("strong"),Znr=o("squeezebert"),Knr=o(" \u2014 "),ZH=a("a"),esr=o("SqueezeBertForMaskedLM"),osr=o(" (SqueezeBERT model)"),rsr=l(),VF=a("li"),HMe=a("strong"),tsr=o("tapas"),asr=o(" \u2014 "),KH=a("a"),nsr=o("TapasForMaskedLM"),ssr=o(" (TAPAS model)"),lsr=l(),XF=a("li"),JMe=a("strong"),isr=o("wav2vec2"),dsr=o(" \u2014 "),YMe=a("code"),msr=o("Wav2Vec2ForMaskedLM"),csr=o(" (Wav2Vec2 model)"),fsr=l(),zF=a("li"),ZMe=a("strong"),gsr=o("xlm"),hsr=o(" \u2014 "),eJ=a("a"),usr=o("XLMWithLMHeadModel"),psr=o(" (XLM model)"),_sr=l(),QF=a("li"),KMe=a("strong"),bsr=o("xlm-roberta"),vsr=o(" \u2014 "),oJ=a("a"),Fsr=o("XLMRobertaForMaskedLM"),Tsr=o(" (XLM-RoBERTa model)"),Msr=l(),WF=a("li"),eEe=a("strong"),Esr=o("xlm-roberta-xl"),Csr=o(" \u2014 "),rJ=a("a"),wsr=o("XLMRobertaXLForMaskedLM"),Asr=o(" (XLM-RoBERTa-XL model)"),Lsr=l(),UF=a("li"),oEe=a("strong"),ysr=o("yoso"),xsr=o(" \u2014 "),tJ=a("a"),$sr=o("YosoForMaskedLM"),ksr=o(" (YOSO model)"),Ssr=l(),HF=a("p"),Rsr=o("The model is set in evaluation mode by default using "),rEe=a("code"),Psr=o("model.eval()"),Bsr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),tEe=a("code"),Isr=o("model.train()"),Nsr=l(),F(JF.$$.fragment),Yao=l(),Ud=a("h2"),YF=a("a"),aEe=a("span"),F(Tk.$$.fragment),qsr=l(),nEe=a("span"),jsr=o("AutoModelForSeq2SeqLM"),Zao=l(),Go=a("div"),F(Mk.$$.fragment),Dsr=l(),Hd=a("p"),Gsr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),aJ=a("a"),Osr=o("from_pretrained()"),Vsr=o(" class method or the "),nJ=a("a"),Xsr=o("from_config()"),zsr=o(` class
method.`),Qsr=l(),Ek=a("p"),Wsr=o("This class cannot be instantiated directly using "),sEe=a("code"),Usr=o("__init__()"),Hsr=o(" (throws an error)."),Jsr=l(),Lt=a("div"),F(Ck.$$.fragment),Ysr=l(),lEe=a("p"),Zsr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Ksr=l(),Jd=a("p"),elr=o(`Note:
Loading a model from its configuration file does `),iEe=a("strong"),olr=o("not"),rlr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sJ=a("a"),tlr=o("from_pretrained()"),alr=o(" to load the model weights."),nlr=l(),F(ZF.$$.fragment),slr=l(),ao=a("div"),F(wk.$$.fragment),llr=l(),dEe=a("p"),ilr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),dlr=l(),cn=a("p"),mlr=o("The model class to instantiate is selected based on the "),mEe=a("code"),clr=o("model_type"),flr=o(` property of the config object (either
passed as an argument or loaded from `),cEe=a("code"),glr=o("pretrained_model_name_or_path"),hlr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fEe=a("code"),ulr=o("pretrained_model_name_or_path"),plr=o(":"),_lr=l(),he=a("ul"),KF=a("li"),gEe=a("strong"),blr=o("bart"),vlr=o(" \u2014 "),lJ=a("a"),Flr=o("BartForConditionalGeneration"),Tlr=o(" (BART model)"),Mlr=l(),eT=a("li"),hEe=a("strong"),Elr=o("bigbird_pegasus"),Clr=o(" \u2014 "),iJ=a("a"),wlr=o("BigBirdPegasusForConditionalGeneration"),Alr=o(" (BigBird-Pegasus model)"),Llr=l(),oT=a("li"),uEe=a("strong"),ylr=o("blenderbot"),xlr=o(" \u2014 "),dJ=a("a"),$lr=o("BlenderbotForConditionalGeneration"),klr=o(" (Blenderbot model)"),Slr=l(),rT=a("li"),pEe=a("strong"),Rlr=o("blenderbot-small"),Plr=o(" \u2014 "),mJ=a("a"),Blr=o("BlenderbotSmallForConditionalGeneration"),Ilr=o(" (BlenderbotSmall model)"),Nlr=l(),tT=a("li"),_Ee=a("strong"),qlr=o("encoder-decoder"),jlr=o(" \u2014 "),cJ=a("a"),Dlr=o("EncoderDecoderModel"),Glr=o(" (Encoder decoder model)"),Olr=l(),aT=a("li"),bEe=a("strong"),Vlr=o("fsmt"),Xlr=o(" \u2014 "),fJ=a("a"),zlr=o("FSMTForConditionalGeneration"),Qlr=o(" (FairSeq Machine-Translation model)"),Wlr=l(),nT=a("li"),vEe=a("strong"),Ulr=o("led"),Hlr=o(" \u2014 "),gJ=a("a"),Jlr=o("LEDForConditionalGeneration"),Ylr=o(" (LED model)"),Zlr=l(),sT=a("li"),FEe=a("strong"),Klr=o("longt5"),eir=o(" \u2014 "),hJ=a("a"),oir=o("LongT5ForConditionalGeneration"),rir=o(" (LongT5 model)"),tir=l(),lT=a("li"),TEe=a("strong"),air=o("m2m_100"),nir=o(" \u2014 "),uJ=a("a"),sir=o("M2M100ForConditionalGeneration"),lir=o(" (M2M100 model)"),iir=l(),iT=a("li"),MEe=a("strong"),dir=o("marian"),mir=o(" \u2014 "),pJ=a("a"),cir=o("MarianMTModel"),fir=o(" (Marian model)"),gir=l(),dT=a("li"),EEe=a("strong"),hir=o("mbart"),uir=o(" \u2014 "),_J=a("a"),pir=o("MBartForConditionalGeneration"),_ir=o(" (mBART model)"),bir=l(),mT=a("li"),CEe=a("strong"),vir=o("mt5"),Fir=o(" \u2014 "),bJ=a("a"),Tir=o("MT5ForConditionalGeneration"),Mir=o(" (MT5 model)"),Eir=l(),cT=a("li"),wEe=a("strong"),Cir=o("mvp"),wir=o(" \u2014 "),vJ=a("a"),Air=o("MvpForConditionalGeneration"),Lir=o(" (MVP model)"),yir=l(),fT=a("li"),AEe=a("strong"),xir=o("nllb"),$ir=o(" \u2014 "),FJ=a("a"),kir=o("M2M100ForConditionalGeneration"),Sir=o(" (NLLB model)"),Rir=l(),gT=a("li"),LEe=a("strong"),Pir=o("pegasus"),Bir=o(" \u2014 "),TJ=a("a"),Iir=o("PegasusForConditionalGeneration"),Nir=o(" (Pegasus model)"),qir=l(),hT=a("li"),yEe=a("strong"),jir=o("pegasus_x"),Dir=o(" \u2014 "),MJ=a("a"),Gir=o("PegasusXForConditionalGeneration"),Oir=o(" (PEGASUS-X model)"),Vir=l(),uT=a("li"),xEe=a("strong"),Xir=o("plbart"),zir=o(" \u2014 "),EJ=a("a"),Qir=o("PLBartForConditionalGeneration"),Wir=o(" (PLBart model)"),Uir=l(),pT=a("li"),$Ee=a("strong"),Hir=o("prophetnet"),Jir=o(" \u2014 "),CJ=a("a"),Yir=o("ProphetNetForConditionalGeneration"),Zir=o(" (ProphetNet model)"),Kir=l(),_T=a("li"),kEe=a("strong"),edr=o("t5"),odr=o(" \u2014 "),wJ=a("a"),rdr=o("T5ForConditionalGeneration"),tdr=o(" (T5 model)"),adr=l(),bT=a("li"),SEe=a("strong"),ndr=o("xlm-prophetnet"),sdr=o(" \u2014 "),AJ=a("a"),ldr=o("XLMProphetNetForConditionalGeneration"),idr=o(" (XLM-ProphetNet model)"),ddr=l(),vT=a("p"),mdr=o("The model is set in evaluation mode by default using "),REe=a("code"),cdr=o("model.eval()"),fdr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),PEe=a("code"),gdr=o("model.train()"),hdr=l(),F(FT.$$.fragment),Kao=l(),Yd=a("h2"),TT=a("a"),BEe=a("span"),F(Ak.$$.fragment),udr=l(),IEe=a("span"),pdr=o("AutoModelForSequenceClassification"),eno=l(),Oo=a("div"),F(Lk.$$.fragment),_dr=l(),Zd=a("p"),bdr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),LJ=a("a"),vdr=o("from_pretrained()"),Fdr=o(" class method or the "),yJ=a("a"),Tdr=o("from_config()"),Mdr=o(` class
method.`),Edr=l(),yk=a("p"),Cdr=o("This class cannot be instantiated directly using "),NEe=a("code"),wdr=o("__init__()"),Adr=o(" (throws an error)."),Ldr=l(),yt=a("div"),F(xk.$$.fragment),ydr=l(),qEe=a("p"),xdr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),$dr=l(),Kd=a("p"),kdr=o(`Note:
Loading a model from its configuration file does `),jEe=a("strong"),Sdr=o("not"),Rdr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xJ=a("a"),Pdr=o("from_pretrained()"),Bdr=o(" to load the model weights."),Idr=l(),F(MT.$$.fragment),Ndr=l(),no=a("div"),F($k.$$.fragment),qdr=l(),DEe=a("p"),jdr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Ddr=l(),fn=a("p"),Gdr=o("The model class to instantiate is selected based on the "),GEe=a("code"),Odr=o("model_type"),Vdr=o(` property of the config object (either
passed as an argument or loaded from `),OEe=a("code"),Xdr=o("pretrained_model_name_or_path"),zdr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),VEe=a("code"),Qdr=o("pretrained_model_name_or_path"),Wdr=o(":"),Udr=l(),I=a("ul"),ET=a("li"),XEe=a("strong"),Hdr=o("albert"),Jdr=o(" \u2014 "),$J=a("a"),Ydr=o("AlbertForSequenceClassification"),Zdr=o(" (ALBERT model)"),Kdr=l(),CT=a("li"),zEe=a("strong"),emr=o("bart"),omr=o(" \u2014 "),kJ=a("a"),rmr=o("BartForSequenceClassification"),tmr=o(" (BART model)"),amr=l(),wT=a("li"),QEe=a("strong"),nmr=o("bert"),smr=o(" \u2014 "),SJ=a("a"),lmr=o("BertForSequenceClassification"),imr=o(" (BERT model)"),dmr=l(),AT=a("li"),WEe=a("strong"),mmr=o("big_bird"),cmr=o(" \u2014 "),RJ=a("a"),fmr=o("BigBirdForSequenceClassification"),gmr=o(" (BigBird model)"),hmr=l(),LT=a("li"),UEe=a("strong"),umr=o("bigbird_pegasus"),pmr=o(" \u2014 "),PJ=a("a"),_mr=o("BigBirdPegasusForSequenceClassification"),bmr=o(" (BigBird-Pegasus model)"),vmr=l(),yT=a("li"),HEe=a("strong"),Fmr=o("bloom"),Tmr=o(" \u2014 "),BJ=a("a"),Mmr=o("BloomForSequenceClassification"),Emr=o(" (BLOOM model)"),Cmr=l(),xT=a("li"),JEe=a("strong"),wmr=o("camembert"),Amr=o(" \u2014 "),IJ=a("a"),Lmr=o("CamembertForSequenceClassification"),ymr=o(" (CamemBERT model)"),xmr=l(),$T=a("li"),YEe=a("strong"),$mr=o("canine"),kmr=o(" \u2014 "),NJ=a("a"),Smr=o("CanineForSequenceClassification"),Rmr=o(" (CANINE model)"),Pmr=l(),kT=a("li"),ZEe=a("strong"),Bmr=o("convbert"),Imr=o(" \u2014 "),qJ=a("a"),Nmr=o("ConvBertForSequenceClassification"),qmr=o(" (ConvBERT model)"),jmr=l(),ST=a("li"),KEe=a("strong"),Dmr=o("ctrl"),Gmr=o(" \u2014 "),jJ=a("a"),Omr=o("CTRLForSequenceClassification"),Vmr=o(" (CTRL model)"),Xmr=l(),RT=a("li"),e4e=a("strong"),zmr=o("data2vec-text"),Qmr=o(" \u2014 "),DJ=a("a"),Wmr=o("Data2VecTextForSequenceClassification"),Umr=o(" (Data2VecText model)"),Hmr=l(),PT=a("li"),o4e=a("strong"),Jmr=o("deberta"),Ymr=o(" \u2014 "),GJ=a("a"),Zmr=o("DebertaForSequenceClassification"),Kmr=o(" (DeBERTa model)"),ecr=l(),BT=a("li"),r4e=a("strong"),ocr=o("deberta-v2"),rcr=o(" \u2014 "),OJ=a("a"),tcr=o("DebertaV2ForSequenceClassification"),acr=o(" (DeBERTa-v2 model)"),ncr=l(),IT=a("li"),t4e=a("strong"),scr=o("distilbert"),lcr=o(" \u2014 "),VJ=a("a"),icr=o("DistilBertForSequenceClassification"),dcr=o(" (DistilBERT model)"),mcr=l(),NT=a("li"),a4e=a("strong"),ccr=o("electra"),fcr=o(" \u2014 "),XJ=a("a"),gcr=o("ElectraForSequenceClassification"),hcr=o(" (ELECTRA model)"),ucr=l(),qT=a("li"),n4e=a("strong"),pcr=o("ernie"),_cr=o(" \u2014 "),zJ=a("a"),bcr=o("ErnieForSequenceClassification"),vcr=o(" (ERNIE model)"),Fcr=l(),jT=a("li"),s4e=a("strong"),Tcr=o("esm"),Mcr=o(" \u2014 "),QJ=a("a"),Ecr=o("EsmForSequenceClassification"),Ccr=o(" (ESM model)"),wcr=l(),DT=a("li"),l4e=a("strong"),Acr=o("flaubert"),Lcr=o(" \u2014 "),WJ=a("a"),ycr=o("FlaubertForSequenceClassification"),xcr=o(" (FlauBERT model)"),$cr=l(),GT=a("li"),i4e=a("strong"),kcr=o("fnet"),Scr=o(" \u2014 "),UJ=a("a"),Rcr=o("FNetForSequenceClassification"),Pcr=o(" (FNet model)"),Bcr=l(),OT=a("li"),d4e=a("strong"),Icr=o("funnel"),Ncr=o(" \u2014 "),HJ=a("a"),qcr=o("FunnelForSequenceClassification"),jcr=o(" (Funnel Transformer model)"),Dcr=l(),VT=a("li"),m4e=a("strong"),Gcr=o("gpt2"),Ocr=o(" \u2014 "),JJ=a("a"),Vcr=o("GPT2ForSequenceClassification"),Xcr=o(" (OpenAI GPT-2 model)"),zcr=l(),XT=a("li"),c4e=a("strong"),Qcr=o("gpt_neo"),Wcr=o(" \u2014 "),YJ=a("a"),Ucr=o("GPTNeoForSequenceClassification"),Hcr=o(" (GPT Neo model)"),Jcr=l(),zT=a("li"),f4e=a("strong"),Ycr=o("gptj"),Zcr=o(" \u2014 "),ZJ=a("a"),Kcr=o("GPTJForSequenceClassification"),efr=o(" (GPT-J model)"),ofr=l(),QT=a("li"),g4e=a("strong"),rfr=o("ibert"),tfr=o(" \u2014 "),KJ=a("a"),afr=o("IBertForSequenceClassification"),nfr=o(" (I-BERT model)"),sfr=l(),WT=a("li"),h4e=a("strong"),lfr=o("layoutlm"),ifr=o(" \u2014 "),eY=a("a"),dfr=o("LayoutLMForSequenceClassification"),mfr=o(" (LayoutLM model)"),cfr=l(),UT=a("li"),u4e=a("strong"),ffr=o("layoutlmv2"),gfr=o(" \u2014 "),oY=a("a"),hfr=o("LayoutLMv2ForSequenceClassification"),ufr=o(" (LayoutLMv2 model)"),pfr=l(),HT=a("li"),p4e=a("strong"),_fr=o("layoutlmv3"),bfr=o(" \u2014 "),rY=a("a"),vfr=o("LayoutLMv3ForSequenceClassification"),Ffr=o(" (LayoutLMv3 model)"),Tfr=l(),JT=a("li"),_4e=a("strong"),Mfr=o("led"),Efr=o(" \u2014 "),tY=a("a"),Cfr=o("LEDForSequenceClassification"),wfr=o(" (LED model)"),Afr=l(),YT=a("li"),b4e=a("strong"),Lfr=o("lilt"),yfr=o(" \u2014 "),aY=a("a"),xfr=o("LiltForSequenceClassification"),$fr=o(" (LiLT model)"),kfr=l(),ZT=a("li"),v4e=a("strong"),Sfr=o("longformer"),Rfr=o(" \u2014 "),nY=a("a"),Pfr=o("LongformerForSequenceClassification"),Bfr=o(" (Longformer model)"),Ifr=l(),KT=a("li"),F4e=a("strong"),Nfr=o("luke"),qfr=o(" \u2014 "),sY=a("a"),jfr=o("LukeForSequenceClassification"),Dfr=o(" (LUKE model)"),Gfr=l(),eM=a("li"),T4e=a("strong"),Ofr=o("markuplm"),Vfr=o(" \u2014 "),lY=a("a"),Xfr=o("MarkupLMForSequenceClassification"),zfr=o(" (MarkupLM model)"),Qfr=l(),oM=a("li"),M4e=a("strong"),Wfr=o("mbart"),Ufr=o(" \u2014 "),iY=a("a"),Hfr=o("MBartForSequenceClassification"),Jfr=o(" (mBART model)"),Yfr=l(),rM=a("li"),E4e=a("strong"),Zfr=o("megatron-bert"),Kfr=o(" \u2014 "),dY=a("a"),egr=o("MegatronBertForSequenceClassification"),ogr=o(" (Megatron-BERT model)"),rgr=l(),tM=a("li"),C4e=a("strong"),tgr=o("mobilebert"),agr=o(" \u2014 "),mY=a("a"),ngr=o("MobileBertForSequenceClassification"),sgr=o(" (MobileBERT model)"),lgr=l(),aM=a("li"),w4e=a("strong"),igr=o("mpnet"),dgr=o(" \u2014 "),cY=a("a"),mgr=o("MPNetForSequenceClassification"),cgr=o(" (MPNet model)"),fgr=l(),nM=a("li"),A4e=a("strong"),ggr=o("mvp"),hgr=o(" \u2014 "),fY=a("a"),ugr=o("MvpForSequenceClassification"),pgr=o(" (MVP model)"),_gr=l(),sM=a("li"),L4e=a("strong"),bgr=o("nezha"),vgr=o(" \u2014 "),gY=a("a"),Fgr=o("NezhaForSequenceClassification"),Tgr=o(" (Nezha model)"),Mgr=l(),lM=a("li"),y4e=a("strong"),Egr=o("nystromformer"),Cgr=o(" \u2014 "),hY=a("a"),wgr=o("NystromformerForSequenceClassification"),Agr=o(" (Nystr\xF6mformer model)"),Lgr=l(),iM=a("li"),x4e=a("strong"),ygr=o("openai-gpt"),xgr=o(" \u2014 "),uY=a("a"),$gr=o("OpenAIGPTForSequenceClassification"),kgr=o(" (OpenAI GPT model)"),Sgr=l(),dM=a("li"),$4e=a("strong"),Rgr=o("opt"),Pgr=o(" \u2014 "),pY=a("a"),Bgr=o("OPTForSequenceClassification"),Igr=o(" (OPT model)"),Ngr=l(),mM=a("li"),k4e=a("strong"),qgr=o("perceiver"),jgr=o(" \u2014 "),_Y=a("a"),Dgr=o("PerceiverForSequenceClassification"),Ggr=o(" (Perceiver model)"),Ogr=l(),cM=a("li"),S4e=a("strong"),Vgr=o("plbart"),Xgr=o(" \u2014 "),bY=a("a"),zgr=o("PLBartForSequenceClassification"),Qgr=o(" (PLBart model)"),Wgr=l(),fM=a("li"),R4e=a("strong"),Ugr=o("qdqbert"),Hgr=o(" \u2014 "),vY=a("a"),Jgr=o("QDQBertForSequenceClassification"),Ygr=o(" (QDQBert model)"),Zgr=l(),gM=a("li"),P4e=a("strong"),Kgr=o("reformer"),ehr=o(" \u2014 "),FY=a("a"),ohr=o("ReformerForSequenceClassification"),rhr=o(" (Reformer model)"),thr=l(),hM=a("li"),B4e=a("strong"),ahr=o("rembert"),nhr=o(" \u2014 "),TY=a("a"),shr=o("RemBertForSequenceClassification"),lhr=o(" (RemBERT model)"),ihr=l(),uM=a("li"),I4e=a("strong"),dhr=o("roberta"),mhr=o(" \u2014 "),MY=a("a"),chr=o("RobertaForSequenceClassification"),fhr=o(" (RoBERTa model)"),ghr=l(),pM=a("li"),N4e=a("strong"),hhr=o("roc_bert"),uhr=o(" \u2014 "),EY=a("a"),phr=o("RoCBertForSequenceClassification"),_hr=o(" (RoCBert model)"),bhr=l(),_M=a("li"),q4e=a("strong"),vhr=o("roformer"),Fhr=o(" \u2014 "),CY=a("a"),Thr=o("RoFormerForSequenceClassification"),Mhr=o(" (RoFormer model)"),Ehr=l(),bM=a("li"),j4e=a("strong"),Chr=o("squeezebert"),whr=o(" \u2014 "),wY=a("a"),Ahr=o("SqueezeBertForSequenceClassification"),Lhr=o(" (SqueezeBERT model)"),yhr=l(),vM=a("li"),D4e=a("strong"),xhr=o("tapas"),$hr=o(" \u2014 "),AY=a("a"),khr=o("TapasForSequenceClassification"),Shr=o(" (TAPAS model)"),Rhr=l(),FM=a("li"),G4e=a("strong"),Phr=o("transfo-xl"),Bhr=o(" \u2014 "),LY=a("a"),Ihr=o("TransfoXLForSequenceClassification"),Nhr=o(" (Transformer-XL model)"),qhr=l(),TM=a("li"),O4e=a("strong"),jhr=o("xlm"),Dhr=o(" \u2014 "),yY=a("a"),Ghr=o("XLMForSequenceClassification"),Ohr=o(" (XLM model)"),Vhr=l(),MM=a("li"),V4e=a("strong"),Xhr=o("xlm-roberta"),zhr=o(" \u2014 "),xY=a("a"),Qhr=o("XLMRobertaForSequenceClassification"),Whr=o(" (XLM-RoBERTa model)"),Uhr=l(),EM=a("li"),X4e=a("strong"),Hhr=o("xlm-roberta-xl"),Jhr=o(" \u2014 "),$Y=a("a"),Yhr=o("XLMRobertaXLForSequenceClassification"),Zhr=o(" (XLM-RoBERTa-XL model)"),Khr=l(),CM=a("li"),z4e=a("strong"),eur=o("xlnet"),our=o(" \u2014 "),kY=a("a"),rur=o("XLNetForSequenceClassification"),tur=o(" (XLNet model)"),aur=l(),wM=a("li"),Q4e=a("strong"),nur=o("yoso"),sur=o(" \u2014 "),SY=a("a"),lur=o("YosoForSequenceClassification"),iur=o(" (YOSO model)"),dur=l(),AM=a("p"),mur=o("The model is set in evaluation mode by default using "),W4e=a("code"),cur=o("model.eval()"),fur=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),U4e=a("code"),gur=o("model.train()"),hur=l(),F(LM.$$.fragment),ono=l(),em=a("h2"),yM=a("a"),H4e=a("span"),F(kk.$$.fragment),uur=l(),J4e=a("span"),pur=o("AutoModelForMultipleChoice"),rno=l(),Vo=a("div"),F(Sk.$$.fragment),_ur=l(),om=a("p"),bur=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),RY=a("a"),vur=o("from_pretrained()"),Fur=o(" class method or the "),PY=a("a"),Tur=o("from_config()"),Mur=o(` class
method.`),Eur=l(),Rk=a("p"),Cur=o("This class cannot be instantiated directly using "),Y4e=a("code"),wur=o("__init__()"),Aur=o(" (throws an error)."),Lur=l(),xt=a("div"),F(Pk.$$.fragment),yur=l(),Z4e=a("p"),xur=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),$ur=l(),rm=a("p"),kur=o(`Note:
Loading a model from its configuration file does `),K4e=a("strong"),Sur=o("not"),Rur=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),BY=a("a"),Pur=o("from_pretrained()"),Bur=o(" to load the model weights."),Iur=l(),F(xM.$$.fragment),Nur=l(),so=a("div"),F(Bk.$$.fragment),qur=l(),eCe=a("p"),jur=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Dur=l(),gn=a("p"),Gur=o("The model class to instantiate is selected based on the "),oCe=a("code"),Our=o("model_type"),Vur=o(` property of the config object (either
passed as an argument or loaded from `),rCe=a("code"),Xur=o("pretrained_model_name_or_path"),zur=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tCe=a("code"),Qur=o("pretrained_model_name_or_path"),Wur=o(":"),Uur=l(),K=a("ul"),$M=a("li"),aCe=a("strong"),Hur=o("albert"),Jur=o(" \u2014 "),IY=a("a"),Yur=o("AlbertForMultipleChoice"),Zur=o(" (ALBERT model)"),Kur=l(),kM=a("li"),nCe=a("strong"),epr=o("bert"),opr=o(" \u2014 "),NY=a("a"),rpr=o("BertForMultipleChoice"),tpr=o(" (BERT model)"),apr=l(),SM=a("li"),sCe=a("strong"),npr=o("big_bird"),spr=o(" \u2014 "),qY=a("a"),lpr=o("BigBirdForMultipleChoice"),ipr=o(" (BigBird model)"),dpr=l(),RM=a("li"),lCe=a("strong"),mpr=o("camembert"),cpr=o(" \u2014 "),jY=a("a"),fpr=o("CamembertForMultipleChoice"),gpr=o(" (CamemBERT model)"),hpr=l(),PM=a("li"),iCe=a("strong"),upr=o("canine"),ppr=o(" \u2014 "),DY=a("a"),_pr=o("CanineForMultipleChoice"),bpr=o(" (CANINE model)"),vpr=l(),BM=a("li"),dCe=a("strong"),Fpr=o("convbert"),Tpr=o(" \u2014 "),GY=a("a"),Mpr=o("ConvBertForMultipleChoice"),Epr=o(" (ConvBERT model)"),Cpr=l(),IM=a("li"),mCe=a("strong"),wpr=o("data2vec-text"),Apr=o(" \u2014 "),OY=a("a"),Lpr=o("Data2VecTextForMultipleChoice"),ypr=o(" (Data2VecText model)"),xpr=l(),NM=a("li"),cCe=a("strong"),$pr=o("deberta-v2"),kpr=o(" \u2014 "),VY=a("a"),Spr=o("DebertaV2ForMultipleChoice"),Rpr=o(" (DeBERTa-v2 model)"),Ppr=l(),qM=a("li"),fCe=a("strong"),Bpr=o("distilbert"),Ipr=o(" \u2014 "),XY=a("a"),Npr=o("DistilBertForMultipleChoice"),qpr=o(" (DistilBERT model)"),jpr=l(),jM=a("li"),gCe=a("strong"),Dpr=o("electra"),Gpr=o(" \u2014 "),zY=a("a"),Opr=o("ElectraForMultipleChoice"),Vpr=o(" (ELECTRA model)"),Xpr=l(),DM=a("li"),hCe=a("strong"),zpr=o("ernie"),Qpr=o(" \u2014 "),QY=a("a"),Wpr=o("ErnieForMultipleChoice"),Upr=o(" (ERNIE model)"),Hpr=l(),GM=a("li"),uCe=a("strong"),Jpr=o("flaubert"),Ypr=o(" \u2014 "),WY=a("a"),Zpr=o("FlaubertForMultipleChoice"),Kpr=o(" (FlauBERT model)"),e_r=l(),OM=a("li"),pCe=a("strong"),o_r=o("fnet"),r_r=o(" \u2014 "),UY=a("a"),t_r=o("FNetForMultipleChoice"),a_r=o(" (FNet model)"),n_r=l(),VM=a("li"),_Ce=a("strong"),s_r=o("funnel"),l_r=o(" \u2014 "),HY=a("a"),i_r=o("FunnelForMultipleChoice"),d_r=o(" (Funnel Transformer model)"),m_r=l(),XM=a("li"),bCe=a("strong"),c_r=o("ibert"),f_r=o(" \u2014 "),JY=a("a"),g_r=o("IBertForMultipleChoice"),h_r=o(" (I-BERT model)"),u_r=l(),zM=a("li"),vCe=a("strong"),p_r=o("longformer"),__r=o(" \u2014 "),YY=a("a"),b_r=o("LongformerForMultipleChoice"),v_r=o(" (Longformer model)"),F_r=l(),QM=a("li"),FCe=a("strong"),T_r=o("luke"),M_r=o(" \u2014 "),ZY=a("a"),E_r=o("LukeForMultipleChoice"),C_r=o(" (LUKE model)"),w_r=l(),WM=a("li"),TCe=a("strong"),A_r=o("megatron-bert"),L_r=o(" \u2014 "),KY=a("a"),y_r=o("MegatronBertForMultipleChoice"),x_r=o(" (Megatron-BERT model)"),$_r=l(),UM=a("li"),MCe=a("strong"),k_r=o("mobilebert"),S_r=o(" \u2014 "),eZ=a("a"),R_r=o("MobileBertForMultipleChoice"),P_r=o(" (MobileBERT model)"),B_r=l(),HM=a("li"),ECe=a("strong"),I_r=o("mpnet"),N_r=o(" \u2014 "),oZ=a("a"),q_r=o("MPNetForMultipleChoice"),j_r=o(" (MPNet model)"),D_r=l(),JM=a("li"),CCe=a("strong"),G_r=o("nezha"),O_r=o(" \u2014 "),rZ=a("a"),V_r=o("NezhaForMultipleChoice"),X_r=o(" (Nezha model)"),z_r=l(),YM=a("li"),wCe=a("strong"),Q_r=o("nystromformer"),W_r=o(" \u2014 "),tZ=a("a"),U_r=o("NystromformerForMultipleChoice"),H_r=o(" (Nystr\xF6mformer model)"),J_r=l(),ZM=a("li"),ACe=a("strong"),Y_r=o("qdqbert"),Z_r=o(" \u2014 "),aZ=a("a"),K_r=o("QDQBertForMultipleChoice"),e1r=o(" (QDQBert model)"),o1r=l(),KM=a("li"),LCe=a("strong"),r1r=o("rembert"),t1r=o(" \u2014 "),nZ=a("a"),a1r=o("RemBertForMultipleChoice"),n1r=o(" (RemBERT model)"),s1r=l(),eE=a("li"),yCe=a("strong"),l1r=o("roberta"),i1r=o(" \u2014 "),sZ=a("a"),d1r=o("RobertaForMultipleChoice"),m1r=o(" (RoBERTa model)"),c1r=l(),oE=a("li"),xCe=a("strong"),f1r=o("roc_bert"),g1r=o(" \u2014 "),lZ=a("a"),h1r=o("RoCBertForMultipleChoice"),u1r=o(" (RoCBert model)"),p1r=l(),rE=a("li"),$Ce=a("strong"),_1r=o("roformer"),b1r=o(" \u2014 "),iZ=a("a"),v1r=o("RoFormerForMultipleChoice"),F1r=o(" (RoFormer model)"),T1r=l(),tE=a("li"),kCe=a("strong"),M1r=o("squeezebert"),E1r=o(" \u2014 "),dZ=a("a"),C1r=o("SqueezeBertForMultipleChoice"),w1r=o(" (SqueezeBERT model)"),A1r=l(),aE=a("li"),SCe=a("strong"),L1r=o("xlm"),y1r=o(" \u2014 "),mZ=a("a"),x1r=o("XLMForMultipleChoice"),$1r=o(" (XLM model)"),k1r=l(),nE=a("li"),RCe=a("strong"),S1r=o("xlm-roberta"),R1r=o(" \u2014 "),cZ=a("a"),P1r=o("XLMRobertaForMultipleChoice"),B1r=o(" (XLM-RoBERTa model)"),I1r=l(),sE=a("li"),PCe=a("strong"),N1r=o("xlm-roberta-xl"),q1r=o(" \u2014 "),fZ=a("a"),j1r=o("XLMRobertaXLForMultipleChoice"),D1r=o(" (XLM-RoBERTa-XL model)"),G1r=l(),lE=a("li"),BCe=a("strong"),O1r=o("xlnet"),V1r=o(" \u2014 "),gZ=a("a"),X1r=o("XLNetForMultipleChoice"),z1r=o(" (XLNet model)"),Q1r=l(),iE=a("li"),ICe=a("strong"),W1r=o("yoso"),U1r=o(" \u2014 "),hZ=a("a"),H1r=o("YosoForMultipleChoice"),J1r=o(" (YOSO model)"),Y1r=l(),dE=a("p"),Z1r=o("The model is set in evaluation mode by default using "),NCe=a("code"),K1r=o("model.eval()"),e2r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qCe=a("code"),o2r=o("model.train()"),r2r=l(),F(mE.$$.fragment),tno=l(),tm=a("h2"),cE=a("a"),jCe=a("span"),F(Ik.$$.fragment),t2r=l(),DCe=a("span"),a2r=o("AutoModelForNextSentencePrediction"),ano=l(),Xo=a("div"),F(Nk.$$.fragment),n2r=l(),am=a("p"),s2r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),uZ=a("a"),l2r=o("from_pretrained()"),i2r=o(" class method or the "),pZ=a("a"),d2r=o("from_config()"),m2r=o(` class
method.`),c2r=l(),qk=a("p"),f2r=o("This class cannot be instantiated directly using "),GCe=a("code"),g2r=o("__init__()"),h2r=o(" (throws an error)."),u2r=l(),$t=a("div"),F(jk.$$.fragment),p2r=l(),OCe=a("p"),_2r=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),b2r=l(),nm=a("p"),v2r=o(`Note:
Loading a model from its configuration file does `),VCe=a("strong"),F2r=o("not"),T2r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_Z=a("a"),M2r=o("from_pretrained()"),E2r=o(" to load the model weights."),C2r=l(),F(fE.$$.fragment),w2r=l(),lo=a("div"),F(Dk.$$.fragment),A2r=l(),XCe=a("p"),L2r=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),y2r=l(),hn=a("p"),x2r=o("The model class to instantiate is selected based on the "),zCe=a("code"),$2r=o("model_type"),k2r=o(` property of the config object (either
passed as an argument or loaded from `),QCe=a("code"),S2r=o("pretrained_model_name_or_path"),R2r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),WCe=a("code"),P2r=o("pretrained_model_name_or_path"),B2r=o(":"),I2r=l(),Ue=a("ul"),gE=a("li"),UCe=a("strong"),N2r=o("bert"),q2r=o(" \u2014 "),bZ=a("a"),j2r=o("BertForNextSentencePrediction"),D2r=o(" (BERT model)"),G2r=l(),hE=a("li"),HCe=a("strong"),O2r=o("ernie"),V2r=o(" \u2014 "),vZ=a("a"),X2r=o("ErnieForNextSentencePrediction"),z2r=o(" (ERNIE model)"),Q2r=l(),uE=a("li"),JCe=a("strong"),W2r=o("fnet"),U2r=o(" \u2014 "),FZ=a("a"),H2r=o("FNetForNextSentencePrediction"),J2r=o(" (FNet model)"),Y2r=l(),pE=a("li"),YCe=a("strong"),Z2r=o("megatron-bert"),K2r=o(" \u2014 "),TZ=a("a"),ebr=o("MegatronBertForNextSentencePrediction"),obr=o(" (Megatron-BERT model)"),rbr=l(),_E=a("li"),ZCe=a("strong"),tbr=o("mobilebert"),abr=o(" \u2014 "),MZ=a("a"),nbr=o("MobileBertForNextSentencePrediction"),sbr=o(" (MobileBERT model)"),lbr=l(),bE=a("li"),KCe=a("strong"),ibr=o("nezha"),dbr=o(" \u2014 "),EZ=a("a"),mbr=o("NezhaForNextSentencePrediction"),cbr=o(" (Nezha model)"),fbr=l(),vE=a("li"),e3e=a("strong"),gbr=o("qdqbert"),hbr=o(" \u2014 "),CZ=a("a"),ubr=o("QDQBertForNextSentencePrediction"),pbr=o(" (QDQBert model)"),_br=l(),FE=a("p"),bbr=o("The model is set in evaluation mode by default using "),o3e=a("code"),vbr=o("model.eval()"),Fbr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),r3e=a("code"),Tbr=o("model.train()"),Mbr=l(),F(TE.$$.fragment),nno=l(),sm=a("h2"),ME=a("a"),t3e=a("span"),F(Gk.$$.fragment),Ebr=l(),a3e=a("span"),Cbr=o("AutoModelForTokenClassification"),sno=l(),zo=a("div"),F(Ok.$$.fragment),wbr=l(),lm=a("p"),Abr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),wZ=a("a"),Lbr=o("from_pretrained()"),ybr=o(" class method or the "),AZ=a("a"),xbr=o("from_config()"),$br=o(` class
method.`),kbr=l(),Vk=a("p"),Sbr=o("This class cannot be instantiated directly using "),n3e=a("code"),Rbr=o("__init__()"),Pbr=o(" (throws an error)."),Bbr=l(),kt=a("div"),F(Xk.$$.fragment),Ibr=l(),s3e=a("p"),Nbr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),qbr=l(),im=a("p"),jbr=o(`Note:
Loading a model from its configuration file does `),l3e=a("strong"),Dbr=o("not"),Gbr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),LZ=a("a"),Obr=o("from_pretrained()"),Vbr=o(" to load the model weights."),Xbr=l(),F(EE.$$.fragment),zbr=l(),io=a("div"),F(zk.$$.fragment),Qbr=l(),i3e=a("p"),Wbr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Ubr=l(),un=a("p"),Hbr=o("The model class to instantiate is selected based on the "),d3e=a("code"),Jbr=o("model_type"),Ybr=o(` property of the config object (either
passed as an argument or loaded from `),m3e=a("code"),Zbr=o("pretrained_model_name_or_path"),Kbr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c3e=a("code"),evr=o("pretrained_model_name_or_path"),ovr=o(":"),rvr=l(),U=a("ul"),CE=a("li"),f3e=a("strong"),tvr=o("albert"),avr=o(" \u2014 "),yZ=a("a"),nvr=o("AlbertForTokenClassification"),svr=o(" (ALBERT model)"),lvr=l(),wE=a("li"),g3e=a("strong"),ivr=o("bert"),dvr=o(" \u2014 "),xZ=a("a"),mvr=o("BertForTokenClassification"),cvr=o(" (BERT model)"),fvr=l(),AE=a("li"),h3e=a("strong"),gvr=o("big_bird"),hvr=o(" \u2014 "),$Z=a("a"),uvr=o("BigBirdForTokenClassification"),pvr=o(" (BigBird model)"),_vr=l(),LE=a("li"),u3e=a("strong"),bvr=o("bloom"),vvr=o(" \u2014 "),kZ=a("a"),Fvr=o("BloomForTokenClassification"),Tvr=o(" (BLOOM model)"),Mvr=l(),yE=a("li"),p3e=a("strong"),Evr=o("camembert"),Cvr=o(" \u2014 "),SZ=a("a"),wvr=o("CamembertForTokenClassification"),Avr=o(" (CamemBERT model)"),Lvr=l(),xE=a("li"),_3e=a("strong"),yvr=o("canine"),xvr=o(" \u2014 "),RZ=a("a"),$vr=o("CanineForTokenClassification"),kvr=o(" (CANINE model)"),Svr=l(),$E=a("li"),b3e=a("strong"),Rvr=o("convbert"),Pvr=o(" \u2014 "),PZ=a("a"),Bvr=o("ConvBertForTokenClassification"),Ivr=o(" (ConvBERT model)"),Nvr=l(),kE=a("li"),v3e=a("strong"),qvr=o("data2vec-text"),jvr=o(" \u2014 "),BZ=a("a"),Dvr=o("Data2VecTextForTokenClassification"),Gvr=o(" (Data2VecText model)"),Ovr=l(),SE=a("li"),F3e=a("strong"),Vvr=o("deberta"),Xvr=o(" \u2014 "),IZ=a("a"),zvr=o("DebertaForTokenClassification"),Qvr=o(" (DeBERTa model)"),Wvr=l(),RE=a("li"),T3e=a("strong"),Uvr=o("deberta-v2"),Hvr=o(" \u2014 "),NZ=a("a"),Jvr=o("DebertaV2ForTokenClassification"),Yvr=o(" (DeBERTa-v2 model)"),Zvr=l(),PE=a("li"),M3e=a("strong"),Kvr=o("distilbert"),eFr=o(" \u2014 "),qZ=a("a"),oFr=o("DistilBertForTokenClassification"),rFr=o(" (DistilBERT model)"),tFr=l(),BE=a("li"),E3e=a("strong"),aFr=o("electra"),nFr=o(" \u2014 "),jZ=a("a"),sFr=o("ElectraForTokenClassification"),lFr=o(" (ELECTRA model)"),iFr=l(),IE=a("li"),C3e=a("strong"),dFr=o("ernie"),mFr=o(" \u2014 "),DZ=a("a"),cFr=o("ErnieForTokenClassification"),fFr=o(" (ERNIE model)"),gFr=l(),NE=a("li"),w3e=a("strong"),hFr=o("esm"),uFr=o(" \u2014 "),GZ=a("a"),pFr=o("EsmForTokenClassification"),_Fr=o(" (ESM model)"),bFr=l(),qE=a("li"),A3e=a("strong"),vFr=o("flaubert"),FFr=o(" \u2014 "),OZ=a("a"),TFr=o("FlaubertForTokenClassification"),MFr=o(" (FlauBERT model)"),EFr=l(),jE=a("li"),L3e=a("strong"),CFr=o("fnet"),wFr=o(" \u2014 "),VZ=a("a"),AFr=o("FNetForTokenClassification"),LFr=o(" (FNet model)"),yFr=l(),DE=a("li"),y3e=a("strong"),xFr=o("funnel"),$Fr=o(" \u2014 "),XZ=a("a"),kFr=o("FunnelForTokenClassification"),SFr=o(" (Funnel Transformer model)"),RFr=l(),GE=a("li"),x3e=a("strong"),PFr=o("gpt2"),BFr=o(" \u2014 "),zZ=a("a"),IFr=o("GPT2ForTokenClassification"),NFr=o(" (OpenAI GPT-2 model)"),qFr=l(),OE=a("li"),$3e=a("strong"),jFr=o("ibert"),DFr=o(" \u2014 "),QZ=a("a"),GFr=o("IBertForTokenClassification"),OFr=o(" (I-BERT model)"),VFr=l(),VE=a("li"),k3e=a("strong"),XFr=o("layoutlm"),zFr=o(" \u2014 "),WZ=a("a"),QFr=o("LayoutLMForTokenClassification"),WFr=o(" (LayoutLM model)"),UFr=l(),XE=a("li"),S3e=a("strong"),HFr=o("layoutlmv2"),JFr=o(" \u2014 "),UZ=a("a"),YFr=o("LayoutLMv2ForTokenClassification"),ZFr=o(" (LayoutLMv2 model)"),KFr=l(),zE=a("li"),R3e=a("strong"),eTr=o("layoutlmv3"),oTr=o(" \u2014 "),HZ=a("a"),rTr=o("LayoutLMv3ForTokenClassification"),tTr=o(" (LayoutLMv3 model)"),aTr=l(),QE=a("li"),P3e=a("strong"),nTr=o("lilt"),sTr=o(" \u2014 "),JZ=a("a"),lTr=o("LiltForTokenClassification"),iTr=o(" (LiLT model)"),dTr=l(),WE=a("li"),B3e=a("strong"),mTr=o("longformer"),cTr=o(" \u2014 "),YZ=a("a"),fTr=o("LongformerForTokenClassification"),gTr=o(" (Longformer model)"),hTr=l(),UE=a("li"),I3e=a("strong"),uTr=o("luke"),pTr=o(" \u2014 "),ZZ=a("a"),_Tr=o("LukeForTokenClassification"),bTr=o(" (LUKE model)"),vTr=l(),HE=a("li"),N3e=a("strong"),FTr=o("markuplm"),TTr=o(" \u2014 "),KZ=a("a"),MTr=o("MarkupLMForTokenClassification"),ETr=o(" (MarkupLM model)"),CTr=l(),JE=a("li"),q3e=a("strong"),wTr=o("megatron-bert"),ATr=o(" \u2014 "),eK=a("a"),LTr=o("MegatronBertForTokenClassification"),yTr=o(" (Megatron-BERT model)"),xTr=l(),YE=a("li"),j3e=a("strong"),$Tr=o("mobilebert"),kTr=o(" \u2014 "),oK=a("a"),STr=o("MobileBertForTokenClassification"),RTr=o(" (MobileBERT model)"),PTr=l(),ZE=a("li"),D3e=a("strong"),BTr=o("mpnet"),ITr=o(" \u2014 "),rK=a("a"),NTr=o("MPNetForTokenClassification"),qTr=o(" (MPNet model)"),jTr=l(),KE=a("li"),G3e=a("strong"),DTr=o("nezha"),GTr=o(" \u2014 "),tK=a("a"),OTr=o("NezhaForTokenClassification"),VTr=o(" (Nezha model)"),XTr=l(),e4=a("li"),O3e=a("strong"),zTr=o("nystromformer"),QTr=o(" \u2014 "),aK=a("a"),WTr=o("NystromformerForTokenClassification"),UTr=o(" (Nystr\xF6mformer model)"),HTr=l(),o4=a("li"),V3e=a("strong"),JTr=o("qdqbert"),YTr=o(" \u2014 "),nK=a("a"),ZTr=o("QDQBertForTokenClassification"),KTr=o(" (QDQBert model)"),eMr=l(),r4=a("li"),X3e=a("strong"),oMr=o("rembert"),rMr=o(" \u2014 "),sK=a("a"),tMr=o("RemBertForTokenClassification"),aMr=o(" (RemBERT model)"),nMr=l(),t4=a("li"),z3e=a("strong"),sMr=o("roberta"),lMr=o(" \u2014 "),lK=a("a"),iMr=o("RobertaForTokenClassification"),dMr=o(" (RoBERTa model)"),mMr=l(),a4=a("li"),Q3e=a("strong"),cMr=o("roc_bert"),fMr=o(" \u2014 "),iK=a("a"),gMr=o("RoCBertForTokenClassification"),hMr=o(" (RoCBert model)"),uMr=l(),n4=a("li"),W3e=a("strong"),pMr=o("roformer"),_Mr=o(" \u2014 "),dK=a("a"),bMr=o("RoFormerForTokenClassification"),vMr=o(" (RoFormer model)"),FMr=l(),s4=a("li"),U3e=a("strong"),TMr=o("squeezebert"),MMr=o(" \u2014 "),mK=a("a"),EMr=o("SqueezeBertForTokenClassification"),CMr=o(" (SqueezeBERT model)"),wMr=l(),l4=a("li"),H3e=a("strong"),AMr=o("xlm"),LMr=o(" \u2014 "),cK=a("a"),yMr=o("XLMForTokenClassification"),xMr=o(" (XLM model)"),$Mr=l(),i4=a("li"),J3e=a("strong"),kMr=o("xlm-roberta"),SMr=o(" \u2014 "),fK=a("a"),RMr=o("XLMRobertaForTokenClassification"),PMr=o(" (XLM-RoBERTa model)"),BMr=l(),d4=a("li"),Y3e=a("strong"),IMr=o("xlm-roberta-xl"),NMr=o(" \u2014 "),gK=a("a"),qMr=o("XLMRobertaXLForTokenClassification"),jMr=o(" (XLM-RoBERTa-XL model)"),DMr=l(),m4=a("li"),Z3e=a("strong"),GMr=o("xlnet"),OMr=o(" \u2014 "),hK=a("a"),VMr=o("XLNetForTokenClassification"),XMr=o(" (XLNet model)"),zMr=l(),c4=a("li"),K3e=a("strong"),QMr=o("yoso"),WMr=o(" \u2014 "),uK=a("a"),UMr=o("YosoForTokenClassification"),HMr=o(" (YOSO model)"),JMr=l(),f4=a("p"),YMr=o("The model is set in evaluation mode by default using "),e5e=a("code"),ZMr=o("model.eval()"),KMr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),o5e=a("code"),eEr=o("model.train()"),oEr=l(),F(g4.$$.fragment),lno=l(),dm=a("h2"),h4=a("a"),r5e=a("span"),F(Qk.$$.fragment),rEr=l(),t5e=a("span"),tEr=o("AutoModelForQuestionAnswering"),ino=l(),Qo=a("div"),F(Wk.$$.fragment),aEr=l(),mm=a("p"),nEr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),pK=a("a"),sEr=o("from_pretrained()"),lEr=o(" class method or the "),_K=a("a"),iEr=o("from_config()"),dEr=o(` class
method.`),mEr=l(),Uk=a("p"),cEr=o("This class cannot be instantiated directly using "),a5e=a("code"),fEr=o("__init__()"),gEr=o(" (throws an error)."),hEr=l(),St=a("div"),F(Hk.$$.fragment),uEr=l(),n5e=a("p"),pEr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),_Er=l(),cm=a("p"),bEr=o(`Note:
Loading a model from its configuration file does `),s5e=a("strong"),vEr=o("not"),FEr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bK=a("a"),TEr=o("from_pretrained()"),MEr=o(" to load the model weights."),EEr=l(),F(u4.$$.fragment),CEr=l(),mo=a("div"),F(Jk.$$.fragment),wEr=l(),l5e=a("p"),AEr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),LEr=l(),pn=a("p"),yEr=o("The model class to instantiate is selected based on the "),i5e=a("code"),xEr=o("model_type"),$Er=o(` property of the config object (either
passed as an argument or loaded from `),d5e=a("code"),kEr=o("pretrained_model_name_or_path"),SEr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m5e=a("code"),REr=o("pretrained_model_name_or_path"),PEr=o(":"),BEr=l(),O=a("ul"),p4=a("li"),c5e=a("strong"),IEr=o("albert"),NEr=o(" \u2014 "),vK=a("a"),qEr=o("AlbertForQuestionAnswering"),jEr=o(" (ALBERT model)"),DEr=l(),_4=a("li"),f5e=a("strong"),GEr=o("bart"),OEr=o(" \u2014 "),FK=a("a"),VEr=o("BartForQuestionAnswering"),XEr=o(" (BART model)"),zEr=l(),b4=a("li"),g5e=a("strong"),QEr=o("bert"),WEr=o(" \u2014 "),TK=a("a"),UEr=o("BertForQuestionAnswering"),HEr=o(" (BERT model)"),JEr=l(),v4=a("li"),h5e=a("strong"),YEr=o("big_bird"),ZEr=o(" \u2014 "),MK=a("a"),KEr=o("BigBirdForQuestionAnswering"),e4r=o(" (BigBird model)"),o4r=l(),F4=a("li"),u5e=a("strong"),r4r=o("bigbird_pegasus"),t4r=o(" \u2014 "),EK=a("a"),a4r=o("BigBirdPegasusForQuestionAnswering"),n4r=o(" (BigBird-Pegasus model)"),s4r=l(),T4=a("li"),p5e=a("strong"),l4r=o("bloom"),i4r=o(" \u2014 "),CK=a("a"),d4r=o("BloomForQuestionAnswering"),m4r=o(" (BLOOM model)"),c4r=l(),M4=a("li"),_5e=a("strong"),f4r=o("camembert"),g4r=o(" \u2014 "),wK=a("a"),h4r=o("CamembertForQuestionAnswering"),u4r=o(" (CamemBERT model)"),p4r=l(),E4=a("li"),b5e=a("strong"),_4r=o("canine"),b4r=o(" \u2014 "),AK=a("a"),v4r=o("CanineForQuestionAnswering"),F4r=o(" (CANINE model)"),T4r=l(),C4=a("li"),v5e=a("strong"),M4r=o("convbert"),E4r=o(" \u2014 "),LK=a("a"),C4r=o("ConvBertForQuestionAnswering"),w4r=o(" (ConvBERT model)"),A4r=l(),w4=a("li"),F5e=a("strong"),L4r=o("data2vec-text"),y4r=o(" \u2014 "),yK=a("a"),x4r=o("Data2VecTextForQuestionAnswering"),$4r=o(" (Data2VecText model)"),k4r=l(),A4=a("li"),T5e=a("strong"),S4r=o("deberta"),R4r=o(" \u2014 "),xK=a("a"),P4r=o("DebertaForQuestionAnswering"),B4r=o(" (DeBERTa model)"),I4r=l(),L4=a("li"),M5e=a("strong"),N4r=o("deberta-v2"),q4r=o(" \u2014 "),$K=a("a"),j4r=o("DebertaV2ForQuestionAnswering"),D4r=o(" (DeBERTa-v2 model)"),G4r=l(),y4=a("li"),E5e=a("strong"),O4r=o("distilbert"),V4r=o(" \u2014 "),kK=a("a"),X4r=o("DistilBertForQuestionAnswering"),z4r=o(" (DistilBERT model)"),Q4r=l(),x4=a("li"),C5e=a("strong"),W4r=o("electra"),U4r=o(" \u2014 "),SK=a("a"),H4r=o("ElectraForQuestionAnswering"),J4r=o(" (ELECTRA model)"),Y4r=l(),$4=a("li"),w5e=a("strong"),Z4r=o("ernie"),K4r=o(" \u2014 "),RK=a("a"),eCr=o("ErnieForQuestionAnswering"),oCr=o(" (ERNIE model)"),rCr=l(),k4=a("li"),A5e=a("strong"),tCr=o("flaubert"),aCr=o(" \u2014 "),PK=a("a"),nCr=o("FlaubertForQuestionAnsweringSimple"),sCr=o(" (FlauBERT model)"),lCr=l(),S4=a("li"),L5e=a("strong"),iCr=o("fnet"),dCr=o(" \u2014 "),BK=a("a"),mCr=o("FNetForQuestionAnswering"),cCr=o(" (FNet model)"),fCr=l(),R4=a("li"),y5e=a("strong"),gCr=o("funnel"),hCr=o(" \u2014 "),IK=a("a"),uCr=o("FunnelForQuestionAnswering"),pCr=o(" (Funnel Transformer model)"),_Cr=l(),P4=a("li"),x5e=a("strong"),bCr=o("gptj"),vCr=o(" \u2014 "),NK=a("a"),FCr=o("GPTJForQuestionAnswering"),TCr=o(" (GPT-J model)"),MCr=l(),B4=a("li"),$5e=a("strong"),ECr=o("ibert"),CCr=o(" \u2014 "),qK=a("a"),wCr=o("IBertForQuestionAnswering"),ACr=o(" (I-BERT model)"),LCr=l(),I4=a("li"),k5e=a("strong"),yCr=o("layoutlmv2"),xCr=o(" \u2014 "),jK=a("a"),$Cr=o("LayoutLMv2ForQuestionAnswering"),kCr=o(" (LayoutLMv2 model)"),SCr=l(),N4=a("li"),S5e=a("strong"),RCr=o("layoutlmv3"),PCr=o(" \u2014 "),DK=a("a"),BCr=o("LayoutLMv3ForQuestionAnswering"),ICr=o(" (LayoutLMv3 model)"),NCr=l(),q4=a("li"),R5e=a("strong"),qCr=o("led"),jCr=o(" \u2014 "),GK=a("a"),DCr=o("LEDForQuestionAnswering"),GCr=o(" (LED model)"),OCr=l(),j4=a("li"),P5e=a("strong"),VCr=o("lilt"),XCr=o(" \u2014 "),OK=a("a"),zCr=o("LiltForQuestionAnswering"),QCr=o(" (LiLT model)"),WCr=l(),D4=a("li"),B5e=a("strong"),UCr=o("longformer"),HCr=o(" \u2014 "),VK=a("a"),JCr=o("LongformerForQuestionAnswering"),YCr=o(" (Longformer model)"),ZCr=l(),G4=a("li"),I5e=a("strong"),KCr=o("luke"),e3r=o(" \u2014 "),XK=a("a"),o3r=o("LukeForQuestionAnswering"),r3r=o(" (LUKE model)"),t3r=l(),O4=a("li"),N5e=a("strong"),a3r=o("lxmert"),n3r=o(" \u2014 "),zK=a("a"),s3r=o("LxmertForQuestionAnswering"),l3r=o(" (LXMERT model)"),i3r=l(),V4=a("li"),q5e=a("strong"),d3r=o("markuplm"),m3r=o(" \u2014 "),QK=a("a"),c3r=o("MarkupLMForQuestionAnswering"),f3r=o(" (MarkupLM model)"),g3r=l(),X4=a("li"),j5e=a("strong"),h3r=o("mbart"),u3r=o(" \u2014 "),WK=a("a"),p3r=o("MBartForQuestionAnswering"),_3r=o(" (mBART model)"),b3r=l(),z4=a("li"),D5e=a("strong"),v3r=o("megatron-bert"),F3r=o(" \u2014 "),UK=a("a"),T3r=o("MegatronBertForQuestionAnswering"),M3r=o(" (Megatron-BERT model)"),E3r=l(),Q4=a("li"),G5e=a("strong"),C3r=o("mobilebert"),w3r=o(" \u2014 "),HK=a("a"),A3r=o("MobileBertForQuestionAnswering"),L3r=o(" (MobileBERT model)"),y3r=l(),W4=a("li"),O5e=a("strong"),x3r=o("mpnet"),$3r=o(" \u2014 "),JK=a("a"),k3r=o("MPNetForQuestionAnswering"),S3r=o(" (MPNet model)"),R3r=l(),U4=a("li"),V5e=a("strong"),P3r=o("mvp"),B3r=o(" \u2014 "),YK=a("a"),I3r=o("MvpForQuestionAnswering"),N3r=o(" (MVP model)"),q3r=l(),H4=a("li"),X5e=a("strong"),j3r=o("nezha"),D3r=o(" \u2014 "),ZK=a("a"),G3r=o("NezhaForQuestionAnswering"),O3r=o(" (Nezha model)"),V3r=l(),J4=a("li"),z5e=a("strong"),X3r=o("nystromformer"),z3r=o(" \u2014 "),KK=a("a"),Q3r=o("NystromformerForQuestionAnswering"),W3r=o(" (Nystr\xF6mformer model)"),U3r=l(),Y4=a("li"),Q5e=a("strong"),H3r=o("opt"),J3r=o(" \u2014 "),eee=a("a"),Y3r=o("OPTForQuestionAnswering"),Z3r=o(" (OPT model)"),K3r=l(),Z4=a("li"),W5e=a("strong"),e5r=o("qdqbert"),o5r=o(" \u2014 "),oee=a("a"),r5r=o("QDQBertForQuestionAnswering"),t5r=o(" (QDQBert model)"),a5r=l(),K4=a("li"),U5e=a("strong"),n5r=o("reformer"),s5r=o(" \u2014 "),ree=a("a"),l5r=o("ReformerForQuestionAnswering"),i5r=o(" (Reformer model)"),d5r=l(),eC=a("li"),H5e=a("strong"),m5r=o("rembert"),c5r=o(" \u2014 "),tee=a("a"),f5r=o("RemBertForQuestionAnswering"),g5r=o(" (RemBERT model)"),h5r=l(),oC=a("li"),J5e=a("strong"),u5r=o("roberta"),p5r=o(" \u2014 "),aee=a("a"),_5r=o("RobertaForQuestionAnswering"),b5r=o(" (RoBERTa model)"),v5r=l(),rC=a("li"),Y5e=a("strong"),F5r=o("roc_bert"),T5r=o(" \u2014 "),nee=a("a"),M5r=o("RoCBertForQuestionAnswering"),E5r=o(" (RoCBert model)"),C5r=l(),tC=a("li"),Z5e=a("strong"),w5r=o("roformer"),A5r=o(" \u2014 "),see=a("a"),L5r=o("RoFormerForQuestionAnswering"),y5r=o(" (RoFormer model)"),x5r=l(),aC=a("li"),K5e=a("strong"),$5r=o("splinter"),k5r=o(" \u2014 "),lee=a("a"),S5r=o("SplinterForQuestionAnswering"),R5r=o(" (Splinter model)"),P5r=l(),nC=a("li"),e0e=a("strong"),B5r=o("squeezebert"),I5r=o(" \u2014 "),iee=a("a"),N5r=o("SqueezeBertForQuestionAnswering"),q5r=o(" (SqueezeBERT model)"),j5r=l(),sC=a("li"),o0e=a("strong"),D5r=o("xlm"),G5r=o(" \u2014 "),dee=a("a"),O5r=o("XLMForQuestionAnsweringSimple"),V5r=o(" (XLM model)"),X5r=l(),lC=a("li"),r0e=a("strong"),z5r=o("xlm-roberta"),Q5r=o(" \u2014 "),mee=a("a"),W5r=o("XLMRobertaForQuestionAnswering"),U5r=o(" (XLM-RoBERTa model)"),H5r=l(),iC=a("li"),t0e=a("strong"),J5r=o("xlm-roberta-xl"),Y5r=o(" \u2014 "),cee=a("a"),Z5r=o("XLMRobertaXLForQuestionAnswering"),K5r=o(" (XLM-RoBERTa-XL model)"),e0r=l(),dC=a("li"),a0e=a("strong"),o0r=o("xlnet"),r0r=o(" \u2014 "),fee=a("a"),t0r=o("XLNetForQuestionAnsweringSimple"),a0r=o(" (XLNet model)"),n0r=l(),mC=a("li"),n0e=a("strong"),s0r=o("yoso"),l0r=o(" \u2014 "),gee=a("a"),i0r=o("YosoForQuestionAnswering"),d0r=o(" (YOSO model)"),m0r=l(),cC=a("p"),c0r=o("The model is set in evaluation mode by default using "),s0e=a("code"),f0r=o("model.eval()"),g0r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),l0e=a("code"),h0r=o("model.train()"),u0r=l(),F(fC.$$.fragment),dno=l(),fm=a("h2"),gC=a("a"),i0e=a("span"),F(Yk.$$.fragment),p0r=l(),d0e=a("span"),_0r=o("AutoModelForTableQuestionAnswering"),mno=l(),Wo=a("div"),F(Zk.$$.fragment),b0r=l(),gm=a("p"),v0r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),hee=a("a"),F0r=o("from_pretrained()"),T0r=o(" class method or the "),uee=a("a"),M0r=o("from_config()"),E0r=o(` class
method.`),C0r=l(),Kk=a("p"),w0r=o("This class cannot be instantiated directly using "),m0e=a("code"),A0r=o("__init__()"),L0r=o(" (throws an error)."),y0r=l(),Rt=a("div"),F(eS.$$.fragment),x0r=l(),c0e=a("p"),$0r=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),k0r=l(),hm=a("p"),S0r=o(`Note:
Loading a model from its configuration file does `),f0e=a("strong"),R0r=o("not"),P0r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pee=a("a"),B0r=o("from_pretrained()"),I0r=o(" to load the model weights."),N0r=l(),F(hC.$$.fragment),q0r=l(),co=a("div"),F(oS.$$.fragment),j0r=l(),g0e=a("p"),D0r=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),G0r=l(),_n=a("p"),O0r=o("The model class to instantiate is selected based on the "),h0e=a("code"),V0r=o("model_type"),X0r=o(` property of the config object (either
passed as an argument or loaded from `),u0e=a("code"),z0r=o("pretrained_model_name_or_path"),Q0r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p0e=a("code"),W0r=o("pretrained_model_name_or_path"),U0r=o(":"),H0r=l(),_0e=a("ul"),uC=a("li"),b0e=a("strong"),J0r=o("tapas"),Y0r=o(" \u2014 "),_ee=a("a"),Z0r=o("TapasForQuestionAnswering"),K0r=o(" (TAPAS model)"),ewr=l(),pC=a("p"),owr=o("The model is set in evaluation mode by default using "),v0e=a("code"),rwr=o("model.eval()"),twr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),F0e=a("code"),awr=o("model.train()"),nwr=l(),F(_C.$$.fragment),cno=l(),um=a("h2"),bC=a("a"),T0e=a("span"),F(rS.$$.fragment),swr=l(),M0e=a("span"),lwr=o("AutoModelForDocumentQuestionAnswering"),fno=l(),Uo=a("div"),F(tS.$$.fragment),iwr=l(),pm=a("p"),dwr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),bee=a("a"),mwr=o("from_pretrained()"),cwr=o(" class method or the "),vee=a("a"),fwr=o("from_config()"),gwr=o(` class
method.`),hwr=l(),aS=a("p"),uwr=o("This class cannot be instantiated directly using "),E0e=a("code"),pwr=o("__init__()"),_wr=o(" (throws an error)."),bwr=l(),Pt=a("div"),F(nS.$$.fragment),vwr=l(),C0e=a("p"),Fwr=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),Twr=l(),_m=a("p"),Mwr=o(`Note:
Loading a model from its configuration file does `),w0e=a("strong"),Ewr=o("not"),Cwr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Fee=a("a"),wwr=o("from_pretrained()"),Awr=o(" to load the model weights."),Lwr=l(),F(vC.$$.fragment),ywr=l(),fo=a("div"),F(sS.$$.fragment),xwr=l(),A0e=a("p"),$wr=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),kwr=l(),bn=a("p"),Swr=o("The model class to instantiate is selected based on the "),L0e=a("code"),Rwr=o("model_type"),Pwr=o(` property of the config object (either
passed as an argument or loaded from `),y0e=a("code"),Bwr=o("pretrained_model_name_or_path"),Iwr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x0e=a("code"),Nwr=o("pretrained_model_name_or_path"),qwr=o(":"),jwr=l(),bm=a("ul"),FC=a("li"),$0e=a("strong"),Dwr=o("layoutlm"),Gwr=o(" \u2014 "),Tee=a("a"),Owr=o("LayoutLMForQuestionAnswering"),Vwr=o(" (LayoutLM model)"),Xwr=l(),TC=a("li"),k0e=a("strong"),zwr=o("layoutlmv2"),Qwr=o(" \u2014 "),Mee=a("a"),Wwr=o("LayoutLMv2ForQuestionAnswering"),Uwr=o(" (LayoutLMv2 model)"),Hwr=l(),MC=a("li"),S0e=a("strong"),Jwr=o("layoutlmv3"),Ywr=o(" \u2014 "),Eee=a("a"),Zwr=o("LayoutLMv3ForQuestionAnswering"),Kwr=o(" (LayoutLMv3 model)"),eAr=l(),EC=a("p"),oAr=o("The model is set in evaluation mode by default using "),R0e=a("code"),rAr=o("model.eval()"),tAr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),P0e=a("code"),aAr=o("model.train()"),nAr=l(),F(CC.$$.fragment),gno=l(),vm=a("h2"),wC=a("a"),B0e=a("span"),F(lS.$$.fragment),sAr=l(),I0e=a("span"),lAr=o("AutoModelForImageClassification"),hno=l(),Ho=a("div"),F(iS.$$.fragment),iAr=l(),Fm=a("p"),dAr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Cee=a("a"),mAr=o("from_pretrained()"),cAr=o(" class method or the "),wee=a("a"),fAr=o("from_config()"),gAr=o(` class
method.`),hAr=l(),dS=a("p"),uAr=o("This class cannot be instantiated directly using "),N0e=a("code"),pAr=o("__init__()"),_Ar=o(" (throws an error)."),bAr=l(),Bt=a("div"),F(mS.$$.fragment),vAr=l(),q0e=a("p"),FAr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),TAr=l(),Tm=a("p"),MAr=o(`Note:
Loading a model from its configuration file does `),j0e=a("strong"),EAr=o("not"),CAr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Aee=a("a"),wAr=o("from_pretrained()"),AAr=o(" to load the model weights."),LAr=l(),F(AC.$$.fragment),yAr=l(),go=a("div"),F(cS.$$.fragment),xAr=l(),D0e=a("p"),$Ar=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),kAr=l(),vn=a("p"),SAr=o("The model class to instantiate is selected based on the "),G0e=a("code"),RAr=o("model_type"),PAr=o(` property of the config object (either
passed as an argument or loaded from `),O0e=a("code"),BAr=o("pretrained_model_name_or_path"),IAr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V0e=a("code"),NAr=o("pretrained_model_name_or_path"),qAr=o(":"),jAr=l(),be=a("ul"),LC=a("li"),X0e=a("strong"),DAr=o("beit"),GAr=o(" \u2014 "),Lee=a("a"),OAr=o("BeitForImageClassification"),VAr=o(" (BEiT model)"),XAr=l(),yC=a("li"),z0e=a("strong"),zAr=o("convnext"),QAr=o(" \u2014 "),yee=a("a"),WAr=o("ConvNextForImageClassification"),UAr=o(" (ConvNeXT model)"),HAr=l(),xC=a("li"),Q0e=a("strong"),JAr=o("cvt"),YAr=o(" \u2014 "),xee=a("a"),ZAr=o("CvtForImageClassification"),KAr=o(" (CvT model)"),e6r=l(),$C=a("li"),W0e=a("strong"),o6r=o("data2vec-vision"),r6r=o(" \u2014 "),$ee=a("a"),t6r=o("Data2VecVisionForImageClassification"),a6r=o(" (Data2VecVision model)"),n6r=l(),kl=a("li"),U0e=a("strong"),s6r=o("deit"),l6r=o(" \u2014 "),kee=a("a"),i6r=o("DeiTForImageClassification"),d6r=o(" or "),See=a("a"),m6r=o("DeiTForImageClassificationWithTeacher"),c6r=o(" (DeiT model)"),f6r=l(),kC=a("li"),H0e=a("strong"),g6r=o("imagegpt"),h6r=o(" \u2014 "),Ree=a("a"),u6r=o("ImageGPTForImageClassification"),p6r=o(" (ImageGPT model)"),_6r=l(),Sl=a("li"),J0e=a("strong"),b6r=o("levit"),v6r=o(" \u2014 "),Pee=a("a"),F6r=o("LevitForImageClassification"),T6r=o(" or "),Bee=a("a"),M6r=o("LevitForImageClassificationWithTeacher"),E6r=o(" (LeViT model)"),C6r=l(),SC=a("li"),Y0e=a("strong"),w6r=o("mobilevit"),A6r=o(" \u2014 "),Iee=a("a"),L6r=o("MobileViTForImageClassification"),y6r=o(" (MobileViT model)"),x6r=l(),It=a("li"),Z0e=a("strong"),$6r=o("perceiver"),k6r=o(" \u2014 "),Nee=a("a"),S6r=o("PerceiverForImageClassificationLearned"),R6r=o(" or "),qee=a("a"),P6r=o("PerceiverForImageClassificationFourier"),B6r=o(" or "),jee=a("a"),I6r=o("PerceiverForImageClassificationConvProcessing"),N6r=o(" (Perceiver model)"),q6r=l(),RC=a("li"),K0e=a("strong"),j6r=o("poolformer"),D6r=o(" \u2014 "),Dee=a("a"),G6r=o("PoolFormerForImageClassification"),O6r=o(" (PoolFormer model)"),V6r=l(),PC=a("li"),ewe=a("strong"),X6r=o("regnet"),z6r=o(" \u2014 "),Gee=a("a"),Q6r=o("RegNetForImageClassification"),W6r=o(" (RegNet model)"),U6r=l(),BC=a("li"),owe=a("strong"),H6r=o("resnet"),J6r=o(" \u2014 "),Oee=a("a"),Y6r=o("ResNetForImageClassification"),Z6r=o(" (ResNet model)"),K6r=l(),IC=a("li"),rwe=a("strong"),e7r=o("segformer"),o7r=o(" \u2014 "),Vee=a("a"),r7r=o("SegformerForImageClassification"),t7r=o(" (SegFormer model)"),a7r=l(),NC=a("li"),twe=a("strong"),n7r=o("swin"),s7r=o(" \u2014 "),Xee=a("a"),l7r=o("SwinForImageClassification"),i7r=o(" (Swin Transformer model)"),d7r=l(),qC=a("li"),awe=a("strong"),m7r=o("swinv2"),c7r=o(" \u2014 "),zee=a("a"),f7r=o("Swinv2ForImageClassification"),g7r=o(" (Swin Transformer V2 model)"),h7r=l(),jC=a("li"),nwe=a("strong"),u7r=o("van"),p7r=o(" \u2014 "),Qee=a("a"),_7r=o("VanForImageClassification"),b7r=o(" (VAN model)"),v7r=l(),DC=a("li"),swe=a("strong"),F7r=o("vit"),T7r=o(" \u2014 "),Wee=a("a"),M7r=o("ViTForImageClassification"),E7r=o(" (ViT model)"),C7r=l(),GC=a("li"),lwe=a("strong"),w7r=o("vit_msn"),A7r=o(" \u2014 "),Uee=a("a"),L7r=o("ViTMSNForImageClassification"),y7r=o(" (ViTMSN model)"),x7r=l(),OC=a("p"),$7r=o("The model is set in evaluation mode by default using "),iwe=a("code"),k7r=o("model.eval()"),S7r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),dwe=a("code"),R7r=o("model.train()"),P7r=l(),F(VC.$$.fragment),uno=l(),Mm=a("h2"),XC=a("a"),mwe=a("span"),F(fS.$$.fragment),B7r=l(),cwe=a("span"),I7r=o("AutoModelForVideoClassification"),pno=l(),Jo=a("div"),F(gS.$$.fragment),N7r=l(),Em=a("p"),q7r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),Hee=a("a"),j7r=o("from_pretrained()"),D7r=o(" class method or the "),Jee=a("a"),G7r=o("from_config()"),O7r=o(` class
method.`),V7r=l(),hS=a("p"),X7r=o("This class cannot be instantiated directly using "),fwe=a("code"),z7r=o("__init__()"),Q7r=o(" (throws an error)."),W7r=l(),Nt=a("div"),F(uS.$$.fragment),U7r=l(),gwe=a("p"),H7r=o("Instantiates one of the model classes of the library (with a video classification head) from a configuration."),J7r=l(),Cm=a("p"),Y7r=o(`Note:
Loading a model from its configuration file does `),hwe=a("strong"),Z7r=o("not"),K7r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Yee=a("a"),e8r=o("from_pretrained()"),o8r=o(" to load the model weights."),r8r=l(),F(zC.$$.fragment),t8r=l(),ho=a("div"),F(pS.$$.fragment),a8r=l(),uwe=a("p"),n8r=o("Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),s8r=l(),Fn=a("p"),l8r=o("The model class to instantiate is selected based on the "),pwe=a("code"),i8r=o("model_type"),d8r=o(` property of the config object (either
passed as an argument or loaded from `),_we=a("code"),m8r=o("pretrained_model_name_or_path"),c8r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bwe=a("code"),f8r=o("pretrained_model_name_or_path"),g8r=o(":"),h8r=l(),vwe=a("ul"),QC=a("li"),Fwe=a("strong"),u8r=o("videomae"),p8r=o(" \u2014 "),Zee=a("a"),_8r=o("VideoMAEForVideoClassification"),b8r=o(" (VideoMAE model)"),v8r=l(),WC=a("p"),F8r=o("The model is set in evaluation mode by default using "),Twe=a("code"),T8r=o("model.eval()"),M8r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Mwe=a("code"),E8r=o("model.train()"),C8r=l(),F(UC.$$.fragment),_no=l(),wm=a("h2"),HC=a("a"),Ewe=a("span"),F(_S.$$.fragment),w8r=l(),Cwe=a("span"),A8r=o("AutoModelForVision2Seq"),bno=l(),Yo=a("div"),F(bS.$$.fragment),L8r=l(),Am=a("p"),y8r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Kee=a("a"),x8r=o("from_pretrained()"),$8r=o(" class method or the "),eoe=a("a"),k8r=o("from_config()"),S8r=o(` class
method.`),R8r=l(),vS=a("p"),P8r=o("This class cannot be instantiated directly using "),wwe=a("code"),B8r=o("__init__()"),I8r=o(" (throws an error)."),N8r=l(),qt=a("div"),F(FS.$$.fragment),q8r=l(),Awe=a("p"),j8r=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),D8r=l(),Lm=a("p"),G8r=o(`Note:
Loading a model from its configuration file does `),Lwe=a("strong"),O8r=o("not"),V8r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ooe=a("a"),X8r=o("from_pretrained()"),z8r=o(" to load the model weights."),Q8r=l(),F(JC.$$.fragment),W8r=l(),uo=a("div"),F(TS.$$.fragment),U8r=l(),ywe=a("p"),H8r=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),J8r=l(),Tn=a("p"),Y8r=o("The model class to instantiate is selected based on the "),xwe=a("code"),Z8r=o("model_type"),K8r=o(` property of the config object (either
passed as an argument or loaded from `),$we=a("code"),eLr=o("pretrained_model_name_or_path"),oLr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kwe=a("code"),rLr=o("pretrained_model_name_or_path"),tLr=o(":"),aLr=l(),Swe=a("ul"),YC=a("li"),Rwe=a("strong"),nLr=o("vision-encoder-decoder"),sLr=o(" \u2014 "),roe=a("a"),lLr=o("VisionEncoderDecoderModel"),iLr=o(" (Vision Encoder decoder model)"),dLr=l(),ZC=a("p"),mLr=o("The model is set in evaluation mode by default using "),Pwe=a("code"),cLr=o("model.eval()"),fLr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Bwe=a("code"),gLr=o("model.train()"),hLr=l(),F(KC.$$.fragment),vno=l(),ym=a("h2"),e3=a("a"),Iwe=a("span"),F(MS.$$.fragment),uLr=l(),Nwe=a("span"),pLr=o("AutoModelForVisualQuestionAnswering"),Fno=l(),Zo=a("div"),F(ES.$$.fragment),_Lr=l(),xm=a("p"),bLr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),toe=a("a"),vLr=o("from_pretrained()"),FLr=o(" class method or the "),aoe=a("a"),TLr=o("from_config()"),MLr=o(` class
method.`),ELr=l(),CS=a("p"),CLr=o("This class cannot be instantiated directly using "),qwe=a("code"),wLr=o("__init__()"),ALr=o(" (throws an error)."),LLr=l(),jt=a("div"),F(wS.$$.fragment),yLr=l(),jwe=a("p"),xLr=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),$Lr=l(),$m=a("p"),kLr=o(`Note:
Loading a model from its configuration file does `),Dwe=a("strong"),SLr=o("not"),RLr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),noe=a("a"),PLr=o("from_pretrained()"),BLr=o(" to load the model weights."),ILr=l(),F(o3.$$.fragment),NLr=l(),po=a("div"),F(AS.$$.fragment),qLr=l(),Gwe=a("p"),jLr=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),DLr=l(),Mn=a("p"),GLr=o("The model class to instantiate is selected based on the "),Owe=a("code"),OLr=o("model_type"),VLr=o(` property of the config object (either
passed as an argument or loaded from `),Vwe=a("code"),XLr=o("pretrained_model_name_or_path"),zLr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xwe=a("code"),QLr=o("pretrained_model_name_or_path"),WLr=o(":"),ULr=l(),zwe=a("ul"),r3=a("li"),Qwe=a("strong"),HLr=o("vilt"),JLr=o(" \u2014 "),soe=a("a"),YLr=o("ViltForQuestionAnswering"),ZLr=o(" (ViLT model)"),KLr=l(),t3=a("p"),eyr=o("The model is set in evaluation mode by default using "),Wwe=a("code"),oyr=o("model.eval()"),ryr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Uwe=a("code"),tyr=o("model.train()"),ayr=l(),F(a3.$$.fragment),Tno=l(),km=a("h2"),n3=a("a"),Hwe=a("span"),F(LS.$$.fragment),nyr=l(),Jwe=a("span"),syr=o("AutoModelForAudioClassification"),Mno=l(),Ko=a("div"),F(yS.$$.fragment),lyr=l(),Sm=a("p"),iyr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),loe=a("a"),dyr=o("from_pretrained()"),myr=o(" class method or the "),ioe=a("a"),cyr=o("from_config()"),fyr=o(` class
method.`),gyr=l(),xS=a("p"),hyr=o("This class cannot be instantiated directly using "),Ywe=a("code"),uyr=o("__init__()"),pyr=o(" (throws an error)."),_yr=l(),Dt=a("div"),F($S.$$.fragment),byr=l(),Zwe=a("p"),vyr=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),Fyr=l(),Rm=a("p"),Tyr=o(`Note:
Loading a model from its configuration file does `),Kwe=a("strong"),Myr=o("not"),Eyr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),doe=a("a"),Cyr=o("from_pretrained()"),wyr=o(" to load the model weights."),Ayr=l(),F(s3.$$.fragment),Lyr=l(),_o=a("div"),F(kS.$$.fragment),yyr=l(),eAe=a("p"),xyr=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),$yr=l(),En=a("p"),kyr=o("The model class to instantiate is selected based on the "),oAe=a("code"),Syr=o("model_type"),Ryr=o(` property of the config object (either
passed as an argument or loaded from `),rAe=a("code"),Pyr=o("pretrained_model_name_or_path"),Byr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tAe=a("code"),Iyr=o("pretrained_model_name_or_path"),Nyr=o(":"),qyr=l(),Be=a("ul"),l3=a("li"),aAe=a("strong"),jyr=o("data2vec-audio"),Dyr=o(" \u2014 "),moe=a("a"),Gyr=o("Data2VecAudioForSequenceClassification"),Oyr=o(" (Data2VecAudio model)"),Vyr=l(),i3=a("li"),nAe=a("strong"),Xyr=o("hubert"),zyr=o(" \u2014 "),coe=a("a"),Qyr=o("HubertForSequenceClassification"),Wyr=o(" (Hubert model)"),Uyr=l(),d3=a("li"),sAe=a("strong"),Hyr=o("sew"),Jyr=o(" \u2014 "),foe=a("a"),Yyr=o("SEWForSequenceClassification"),Zyr=o(" (SEW model)"),Kyr=l(),m3=a("li"),lAe=a("strong"),e9r=o("sew-d"),o9r=o(" \u2014 "),goe=a("a"),r9r=o("SEWDForSequenceClassification"),t9r=o(" (SEW-D model)"),a9r=l(),c3=a("li"),iAe=a("strong"),n9r=o("unispeech"),s9r=o(" \u2014 "),hoe=a("a"),l9r=o("UniSpeechForSequenceClassification"),i9r=o(" (UniSpeech model)"),d9r=l(),f3=a("li"),dAe=a("strong"),m9r=o("unispeech-sat"),c9r=o(" \u2014 "),uoe=a("a"),f9r=o("UniSpeechSatForSequenceClassification"),g9r=o(" (UniSpeechSat model)"),h9r=l(),g3=a("li"),mAe=a("strong"),u9r=o("wav2vec2"),p9r=o(" \u2014 "),poe=a("a"),_9r=o("Wav2Vec2ForSequenceClassification"),b9r=o(" (Wav2Vec2 model)"),v9r=l(),h3=a("li"),cAe=a("strong"),F9r=o("wav2vec2-conformer"),T9r=o(" \u2014 "),_oe=a("a"),M9r=o("Wav2Vec2ConformerForSequenceClassification"),E9r=o(" (Wav2Vec2-Conformer model)"),C9r=l(),u3=a("li"),fAe=a("strong"),w9r=o("wavlm"),A9r=o(" \u2014 "),boe=a("a"),L9r=o("WavLMForSequenceClassification"),y9r=o(" (WavLM model)"),x9r=l(),p3=a("p"),$9r=o("The model is set in evaluation mode by default using "),gAe=a("code"),k9r=o("model.eval()"),S9r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),hAe=a("code"),R9r=o("model.train()"),P9r=l(),F(_3.$$.fragment),Eno=l(),Pm=a("h2"),b3=a("a"),uAe=a("span"),F(SS.$$.fragment),B9r=l(),pAe=a("span"),I9r=o("AutoModelForAudioFrameClassification"),Cno=l(),er=a("div"),F(RS.$$.fragment),N9r=l(),Bm=a("p"),q9r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),voe=a("a"),j9r=o("from_pretrained()"),D9r=o(" class method or the "),Foe=a("a"),G9r=o("from_config()"),O9r=o(` class
method.`),V9r=l(),PS=a("p"),X9r=o("This class cannot be instantiated directly using "),_Ae=a("code"),z9r=o("__init__()"),Q9r=o(" (throws an error)."),W9r=l(),Gt=a("div"),F(BS.$$.fragment),U9r=l(),bAe=a("p"),H9r=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),J9r=l(),Im=a("p"),Y9r=o(`Note:
Loading a model from its configuration file does `),vAe=a("strong"),Z9r=o("not"),K9r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Toe=a("a"),exr=o("from_pretrained()"),oxr=o(" to load the model weights."),rxr=l(),F(v3.$$.fragment),txr=l(),bo=a("div"),F(IS.$$.fragment),axr=l(),FAe=a("p"),nxr=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),sxr=l(),Cn=a("p"),lxr=o("The model class to instantiate is selected based on the "),TAe=a("code"),ixr=o("model_type"),dxr=o(` property of the config object (either
passed as an argument or loaded from `),MAe=a("code"),mxr=o("pretrained_model_name_or_path"),cxr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),EAe=a("code"),fxr=o("pretrained_model_name_or_path"),gxr=o(":"),hxr=l(),ut=a("ul"),F3=a("li"),CAe=a("strong"),uxr=o("data2vec-audio"),pxr=o(" \u2014 "),Moe=a("a"),_xr=o("Data2VecAudioForAudioFrameClassification"),bxr=o(" (Data2VecAudio model)"),vxr=l(),T3=a("li"),wAe=a("strong"),Fxr=o("unispeech-sat"),Txr=o(" \u2014 "),Eoe=a("a"),Mxr=o("UniSpeechSatForAudioFrameClassification"),Exr=o(" (UniSpeechSat model)"),Cxr=l(),M3=a("li"),AAe=a("strong"),wxr=o("wav2vec2"),Axr=o(" \u2014 "),Coe=a("a"),Lxr=o("Wav2Vec2ForAudioFrameClassification"),yxr=o(" (Wav2Vec2 model)"),xxr=l(),E3=a("li"),LAe=a("strong"),$xr=o("wav2vec2-conformer"),kxr=o(" \u2014 "),woe=a("a"),Sxr=o("Wav2Vec2ConformerForAudioFrameClassification"),Rxr=o(" (Wav2Vec2-Conformer model)"),Pxr=l(),C3=a("li"),yAe=a("strong"),Bxr=o("wavlm"),Ixr=o(" \u2014 "),Aoe=a("a"),Nxr=o("WavLMForAudioFrameClassification"),qxr=o(" (WavLM model)"),jxr=l(),w3=a("p"),Dxr=o("The model is set in evaluation mode by default using "),xAe=a("code"),Gxr=o("model.eval()"),Oxr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$Ae=a("code"),Vxr=o("model.train()"),Xxr=l(),F(A3.$$.fragment),wno=l(),Nm=a("h2"),L3=a("a"),kAe=a("span"),F(NS.$$.fragment),zxr=l(),SAe=a("span"),Qxr=o("AutoModelForCTC"),Ano=l(),or=a("div"),F(qS.$$.fragment),Wxr=l(),qm=a("p"),Uxr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),Loe=a("a"),Hxr=o("from_pretrained()"),Jxr=o(" class method or the "),yoe=a("a"),Yxr=o("from_config()"),Zxr=o(` class
method.`),Kxr=l(),jS=a("p"),e$r=o("This class cannot be instantiated directly using "),RAe=a("code"),o$r=o("__init__()"),r$r=o(" (throws an error)."),t$r=l(),Ot=a("div"),F(DS.$$.fragment),a$r=l(),PAe=a("p"),n$r=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),s$r=l(),jm=a("p"),l$r=o(`Note:
Loading a model from its configuration file does `),BAe=a("strong"),i$r=o("not"),d$r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xoe=a("a"),m$r=o("from_pretrained()"),c$r=o(" to load the model weights."),f$r=l(),F(y3.$$.fragment),g$r=l(),vo=a("div"),F(GS.$$.fragment),h$r=l(),IAe=a("p"),u$r=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),p$r=l(),wn=a("p"),_$r=o("The model class to instantiate is selected based on the "),NAe=a("code"),b$r=o("model_type"),v$r=o(` property of the config object (either
passed as an argument or loaded from `),qAe=a("code"),F$r=o("pretrained_model_name_or_path"),T$r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jAe=a("code"),M$r=o("pretrained_model_name_or_path"),E$r=o(":"),C$r=l(),Le=a("ul"),x3=a("li"),DAe=a("strong"),w$r=o("data2vec-audio"),A$r=o(" \u2014 "),$oe=a("a"),L$r=o("Data2VecAudioForCTC"),y$r=o(" (Data2VecAudio model)"),x$r=l(),$3=a("li"),GAe=a("strong"),$$r=o("hubert"),k$r=o(" \u2014 "),koe=a("a"),S$r=o("HubertForCTC"),R$r=o(" (Hubert model)"),P$r=l(),k3=a("li"),OAe=a("strong"),B$r=o("mctct"),I$r=o(" \u2014 "),Soe=a("a"),N$r=o("MCTCTForCTC"),q$r=o(" (M-CTC-T model)"),j$r=l(),S3=a("li"),VAe=a("strong"),D$r=o("sew"),G$r=o(" \u2014 "),Roe=a("a"),O$r=o("SEWForCTC"),V$r=o(" (SEW model)"),X$r=l(),R3=a("li"),XAe=a("strong"),z$r=o("sew-d"),Q$r=o(" \u2014 "),Poe=a("a"),W$r=o("SEWDForCTC"),U$r=o(" (SEW-D model)"),H$r=l(),P3=a("li"),zAe=a("strong"),J$r=o("unispeech"),Y$r=o(" \u2014 "),Boe=a("a"),Z$r=o("UniSpeechForCTC"),K$r=o(" (UniSpeech model)"),ekr=l(),B3=a("li"),QAe=a("strong"),okr=o("unispeech-sat"),rkr=o(" \u2014 "),Ioe=a("a"),tkr=o("UniSpeechSatForCTC"),akr=o(" (UniSpeechSat model)"),nkr=l(),I3=a("li"),WAe=a("strong"),skr=o("wav2vec2"),lkr=o(" \u2014 "),Noe=a("a"),ikr=o("Wav2Vec2ForCTC"),dkr=o(" (Wav2Vec2 model)"),mkr=l(),N3=a("li"),UAe=a("strong"),ckr=o("wav2vec2-conformer"),fkr=o(" \u2014 "),qoe=a("a"),gkr=o("Wav2Vec2ConformerForCTC"),hkr=o(" (Wav2Vec2-Conformer model)"),ukr=l(),q3=a("li"),HAe=a("strong"),pkr=o("wavlm"),_kr=o(" \u2014 "),joe=a("a"),bkr=o("WavLMForCTC"),vkr=o(" (WavLM model)"),Fkr=l(),j3=a("p"),Tkr=o("The model is set in evaluation mode by default using "),JAe=a("code"),Mkr=o("model.eval()"),Ekr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),YAe=a("code"),Ckr=o("model.train()"),wkr=l(),F(D3.$$.fragment),Lno=l(),Dm=a("h2"),G3=a("a"),ZAe=a("span"),F(OS.$$.fragment),Akr=l(),KAe=a("span"),Lkr=o("AutoModelForSpeechSeq2Seq"),yno=l(),rr=a("div"),F(VS.$$.fragment),ykr=l(),Gm=a("p"),xkr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),Doe=a("a"),$kr=o("from_pretrained()"),kkr=o(" class method or the "),Goe=a("a"),Skr=o("from_config()"),Rkr=o(` class
method.`),Pkr=l(),XS=a("p"),Bkr=o("This class cannot be instantiated directly using "),e6e=a("code"),Ikr=o("__init__()"),Nkr=o(" (throws an error)."),qkr=l(),Vt=a("div"),F(zS.$$.fragment),jkr=l(),o6e=a("p"),Dkr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Gkr=l(),Om=a("p"),Okr=o(`Note:
Loading a model from its configuration file does `),r6e=a("strong"),Vkr=o("not"),Xkr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ooe=a("a"),zkr=o("from_pretrained()"),Qkr=o(" to load the model weights."),Wkr=l(),F(O3.$$.fragment),Ukr=l(),Fo=a("div"),F(QS.$$.fragment),Hkr=l(),t6e=a("p"),Jkr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Ykr=l(),An=a("p"),Zkr=o("The model class to instantiate is selected based on the "),a6e=a("code"),Kkr=o("model_type"),eSr=o(` property of the config object (either
passed as an argument or loaded from `),n6e=a("code"),oSr=o("pretrained_model_name_or_path"),rSr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),s6e=a("code"),tSr=o("pretrained_model_name_or_path"),aSr=o(":"),nSr=l(),Vm=a("ul"),V3=a("li"),l6e=a("strong"),sSr=o("speech-encoder-decoder"),lSr=o(" \u2014 "),Voe=a("a"),iSr=o("SpeechEncoderDecoderModel"),dSr=o(" (Speech Encoder decoder model)"),mSr=l(),X3=a("li"),i6e=a("strong"),cSr=o("speech_to_text"),fSr=o(" \u2014 "),Xoe=a("a"),gSr=o("Speech2TextForConditionalGeneration"),hSr=o(" (Speech2Text model)"),uSr=l(),z3=a("li"),d6e=a("strong"),pSr=o("whisper"),_Sr=o(" \u2014 "),zoe=a("a"),bSr=o("WhisperForConditionalGeneration"),vSr=o(" (Whisper model)"),FSr=l(),Q3=a("p"),TSr=o("The model is set in evaluation mode by default using "),m6e=a("code"),MSr=o("model.eval()"),ESr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),c6e=a("code"),CSr=o("model.train()"),wSr=l(),F(W3.$$.fragment),xno=l(),Xm=a("h2"),U3=a("a"),f6e=a("span"),F(WS.$$.fragment),ASr=l(),g6e=a("span"),LSr=o("AutoModelForAudioXVector"),$no=l(),tr=a("div"),F(US.$$.fragment),ySr=l(),zm=a("p"),xSr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),Qoe=a("a"),$Sr=o("from_pretrained()"),kSr=o(" class method or the "),Woe=a("a"),SSr=o("from_config()"),RSr=o(` class
method.`),PSr=l(),HS=a("p"),BSr=o("This class cannot be instantiated directly using "),h6e=a("code"),ISr=o("__init__()"),NSr=o(" (throws an error)."),qSr=l(),Xt=a("div"),F(JS.$$.fragment),jSr=l(),u6e=a("p"),DSr=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),GSr=l(),Qm=a("p"),OSr=o(`Note:
Loading a model from its configuration file does `),p6e=a("strong"),VSr=o("not"),XSr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Uoe=a("a"),zSr=o("from_pretrained()"),QSr=o(" to load the model weights."),WSr=l(),F(H3.$$.fragment),USr=l(),To=a("div"),F(YS.$$.fragment),HSr=l(),_6e=a("p"),JSr=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),YSr=l(),Ln=a("p"),ZSr=o("The model class to instantiate is selected based on the "),b6e=a("code"),KSr=o("model_type"),eRr=o(` property of the config object (either
passed as an argument or loaded from `),v6e=a("code"),oRr=o("pretrained_model_name_or_path"),rRr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F6e=a("code"),tRr=o("pretrained_model_name_or_path"),aRr=o(":"),nRr=l(),pt=a("ul"),J3=a("li"),T6e=a("strong"),sRr=o("data2vec-audio"),lRr=o(" \u2014 "),Hoe=a("a"),iRr=o("Data2VecAudioForXVector"),dRr=o(" (Data2VecAudio model)"),mRr=l(),Y3=a("li"),M6e=a("strong"),cRr=o("unispeech-sat"),fRr=o(" \u2014 "),Joe=a("a"),gRr=o("UniSpeechSatForXVector"),hRr=o(" (UniSpeechSat model)"),uRr=l(),Z3=a("li"),E6e=a("strong"),pRr=o("wav2vec2"),_Rr=o(" \u2014 "),Yoe=a("a"),bRr=o("Wav2Vec2ForXVector"),vRr=o(" (Wav2Vec2 model)"),FRr=l(),K3=a("li"),C6e=a("strong"),TRr=o("wav2vec2-conformer"),MRr=o(" \u2014 "),Zoe=a("a"),ERr=o("Wav2Vec2ConformerForXVector"),CRr=o(" (Wav2Vec2-Conformer model)"),wRr=l(),e5=a("li"),w6e=a("strong"),ARr=o("wavlm"),LRr=o(" \u2014 "),Koe=a("a"),yRr=o("WavLMForXVector"),xRr=o(" (WavLM model)"),$Rr=l(),o5=a("p"),kRr=o("The model is set in evaluation mode by default using "),A6e=a("code"),SRr=o("model.eval()"),RRr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),L6e=a("code"),PRr=o("model.train()"),BRr=l(),F(r5.$$.fragment),kno=l(),Wm=a("h2"),t5=a("a"),y6e=a("span"),F(ZS.$$.fragment),IRr=l(),x6e=a("span"),NRr=o("AutoModelForMaskedImageModeling"),Sno=l(),ar=a("div"),F(KS.$$.fragment),qRr=l(),Um=a("p"),jRr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),ere=a("a"),DRr=o("from_pretrained()"),GRr=o(" class method or the "),ore=a("a"),ORr=o("from_config()"),VRr=o(` class
method.`),XRr=l(),eR=a("p"),zRr=o("This class cannot be instantiated directly using "),$6e=a("code"),QRr=o("__init__()"),WRr=o(" (throws an error)."),URr=l(),zt=a("div"),F(oR.$$.fragment),HRr=l(),k6e=a("p"),JRr=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),YRr=l(),Hm=a("p"),ZRr=o(`Note:
Loading a model from its configuration file does `),S6e=a("strong"),KRr=o("not"),ePr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rre=a("a"),oPr=o("from_pretrained()"),rPr=o(" to load the model weights."),tPr=l(),F(a5.$$.fragment),aPr=l(),Mo=a("div"),F(rR.$$.fragment),nPr=l(),R6e=a("p"),sPr=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),lPr=l(),yn=a("p"),iPr=o("The model class to instantiate is selected based on the "),P6e=a("code"),dPr=o("model_type"),mPr=o(` property of the config object (either
passed as an argument or loaded from `),B6e=a("code"),cPr=o("pretrained_model_name_or_path"),fPr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I6e=a("code"),gPr=o("pretrained_model_name_or_path"),hPr=o(":"),uPr=l(),xn=a("ul"),n5=a("li"),N6e=a("strong"),pPr=o("deit"),_Pr=o(" \u2014 "),tre=a("a"),bPr=o("DeiTForMaskedImageModeling"),vPr=o(" (DeiT model)"),FPr=l(),s5=a("li"),q6e=a("strong"),TPr=o("swin"),MPr=o(" \u2014 "),are=a("a"),EPr=o("SwinForMaskedImageModeling"),CPr=o(" (Swin Transformer model)"),wPr=l(),l5=a("li"),j6e=a("strong"),APr=o("swinv2"),LPr=o(" \u2014 "),nre=a("a"),yPr=o("Swinv2ForMaskedImageModeling"),xPr=o(" (Swin Transformer V2 model)"),$Pr=l(),i5=a("li"),D6e=a("strong"),kPr=o("vit"),SPr=o(" \u2014 "),sre=a("a"),RPr=o("ViTForMaskedImageModeling"),PPr=o(" (ViT model)"),BPr=l(),d5=a("p"),IPr=o("The model is set in evaluation mode by default using "),G6e=a("code"),NPr=o("model.eval()"),qPr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),O6e=a("code"),jPr=o("model.train()"),DPr=l(),F(m5.$$.fragment),Rno=l(),Jm=a("h2"),c5=a("a"),V6e=a("span"),F(tR.$$.fragment),GPr=l(),X6e=a("span"),OPr=o("AutoModelForObjectDetection"),Pno=l(),nr=a("div"),F(aR.$$.fragment),VPr=l(),Ym=a("p"),XPr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),lre=a("a"),zPr=o("from_pretrained()"),QPr=o(" class method or the "),ire=a("a"),WPr=o("from_config()"),UPr=o(` class
method.`),HPr=l(),nR=a("p"),JPr=o("This class cannot be instantiated directly using "),z6e=a("code"),YPr=o("__init__()"),ZPr=o(" (throws an error)."),KPr=l(),Qt=a("div"),F(sR.$$.fragment),eBr=l(),Q6e=a("p"),oBr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),rBr=l(),Zm=a("p"),tBr=o(`Note:
Loading a model from its configuration file does `),W6e=a("strong"),aBr=o("not"),nBr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dre=a("a"),sBr=o("from_pretrained()"),lBr=o(" to load the model weights."),iBr=l(),F(f5.$$.fragment),dBr=l(),Eo=a("div"),F(lR.$$.fragment),mBr=l(),U6e=a("p"),cBr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),fBr=l(),$n=a("p"),gBr=o("The model class to instantiate is selected based on the "),H6e=a("code"),hBr=o("model_type"),uBr=o(` property of the config object (either
passed as an argument or loaded from `),J6e=a("code"),pBr=o("pretrained_model_name_or_path"),_Br=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Y6e=a("code"),bBr=o("pretrained_model_name_or_path"),vBr=o(":"),FBr=l(),_t=a("ul"),g5=a("li"),Z6e=a("strong"),TBr=o("conditional_detr"),MBr=o(" \u2014 "),mre=a("a"),EBr=o("ConditionalDetrForObjectDetection"),CBr=o(" (Conditional DETR model)"),wBr=l(),h5=a("li"),K6e=a("strong"),ABr=o("deformable_detr"),LBr=o(" \u2014 "),cre=a("a"),yBr=o("DeformableDetrForObjectDetection"),xBr=o(" (Deformable DETR model)"),$Br=l(),u5=a("li"),e7e=a("strong"),kBr=o("detr"),SBr=o(" \u2014 "),fre=a("a"),RBr=o("DetrForObjectDetection"),PBr=o(" (DETR model)"),BBr=l(),p5=a("li"),o7e=a("strong"),IBr=o("table-transformer"),NBr=o(" \u2014 "),gre=a("a"),qBr=o("TableTransformerForObjectDetection"),jBr=o(" (Table Transformer model)"),DBr=l(),_5=a("li"),r7e=a("strong"),GBr=o("yolos"),OBr=o(" \u2014 "),hre=a("a"),VBr=o("YolosForObjectDetection"),XBr=o(" (YOLOS model)"),zBr=l(),b5=a("p"),QBr=o("The model is set in evaluation mode by default using "),t7e=a("code"),WBr=o("model.eval()"),UBr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),a7e=a("code"),HBr=o("model.train()"),JBr=l(),F(v5.$$.fragment),Bno=l(),Km=a("h2"),F5=a("a"),n7e=a("span"),F(iR.$$.fragment),YBr=l(),s7e=a("span"),ZBr=o("AutoModelForImageSegmentation"),Ino=l(),sr=a("div"),F(dR.$$.fragment),KBr=l(),ec=a("p"),eIr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),ure=a("a"),oIr=o("from_pretrained()"),rIr=o(" class method or the "),pre=a("a"),tIr=o("from_config()"),aIr=o(` class
method.`),nIr=l(),mR=a("p"),sIr=o("This class cannot be instantiated directly using "),l7e=a("code"),lIr=o("__init__()"),iIr=o(" (throws an error)."),dIr=l(),Wt=a("div"),F(cR.$$.fragment),mIr=l(),i7e=a("p"),cIr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),fIr=l(),oc=a("p"),gIr=o(`Note:
Loading a model from its configuration file does `),d7e=a("strong"),hIr=o("not"),uIr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_re=a("a"),pIr=o("from_pretrained()"),_Ir=o(" to load the model weights."),bIr=l(),F(T5.$$.fragment),vIr=l(),Co=a("div"),F(fR.$$.fragment),FIr=l(),m7e=a("p"),TIr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),MIr=l(),kn=a("p"),EIr=o("The model class to instantiate is selected based on the "),c7e=a("code"),CIr=o("model_type"),wIr=o(` property of the config object (either
passed as an argument or loaded from `),f7e=a("code"),AIr=o("pretrained_model_name_or_path"),LIr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),g7e=a("code"),yIr=o("pretrained_model_name_or_path"),xIr=o(":"),$Ir=l(),h7e=a("ul"),M5=a("li"),u7e=a("strong"),kIr=o("detr"),SIr=o(" \u2014 "),bre=a("a"),RIr=o("DetrForSegmentation"),PIr=o(" (DETR model)"),BIr=l(),E5=a("p"),IIr=o("The model is set in evaluation mode by default using "),p7e=a("code"),NIr=o("model.eval()"),qIr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_7e=a("code"),jIr=o("model.train()"),DIr=l(),F(C5.$$.fragment),Nno=l(),rc=a("h2"),w5=a("a"),b7e=a("span"),F(gR.$$.fragment),GIr=l(),v7e=a("span"),OIr=o("AutoModelForSemanticSegmentation"),qno=l(),lr=a("div"),F(hR.$$.fragment),VIr=l(),tc=a("p"),XIr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),vre=a("a"),zIr=o("from_pretrained()"),QIr=o(" class method or the "),Fre=a("a"),WIr=o("from_config()"),UIr=o(` class
method.`),HIr=l(),uR=a("p"),JIr=o("This class cannot be instantiated directly using "),F7e=a("code"),YIr=o("__init__()"),ZIr=o(" (throws an error)."),KIr=l(),Ut=a("div"),F(pR.$$.fragment),eNr=l(),T7e=a("p"),oNr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),rNr=l(),ac=a("p"),tNr=o(`Note:
Loading a model from its configuration file does `),M7e=a("strong"),aNr=o("not"),nNr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Tre=a("a"),sNr=o("from_pretrained()"),lNr=o(" to load the model weights."),iNr=l(),F(A5.$$.fragment),dNr=l(),wo=a("div"),F(_R.$$.fragment),mNr=l(),E7e=a("p"),cNr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),fNr=l(),Sn=a("p"),gNr=o("The model class to instantiate is selected based on the "),C7e=a("code"),hNr=o("model_type"),uNr=o(` property of the config object (either
passed as an argument or loaded from `),w7e=a("code"),pNr=o("pretrained_model_name_or_path"),_Nr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),A7e=a("code"),bNr=o("pretrained_model_name_or_path"),vNr=o(":"),FNr=l(),bt=a("ul"),L5=a("li"),L7e=a("strong"),TNr=o("beit"),MNr=o(" \u2014 "),Mre=a("a"),ENr=o("BeitForSemanticSegmentation"),CNr=o(" (BEiT model)"),wNr=l(),y5=a("li"),y7e=a("strong"),ANr=o("data2vec-vision"),LNr=o(" \u2014 "),Ere=a("a"),yNr=o("Data2VecVisionForSemanticSegmentation"),xNr=o(" (Data2VecVision model)"),$Nr=l(),x5=a("li"),x7e=a("strong"),kNr=o("dpt"),SNr=o(" \u2014 "),Cre=a("a"),RNr=o("DPTForSemanticSegmentation"),PNr=o(" (DPT model)"),BNr=l(),$5=a("li"),$7e=a("strong"),INr=o("mobilevit"),NNr=o(" \u2014 "),wre=a("a"),qNr=o("MobileViTForSemanticSegmentation"),jNr=o(" (MobileViT model)"),DNr=l(),k5=a("li"),k7e=a("strong"),GNr=o("segformer"),ONr=o(" \u2014 "),Are=a("a"),VNr=o("SegformerForSemanticSegmentation"),XNr=o(" (SegFormer model)"),zNr=l(),S5=a("p"),QNr=o("The model is set in evaluation mode by default using "),S7e=a("code"),WNr=o("model.eval()"),UNr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),R7e=a("code"),HNr=o("model.train()"),JNr=l(),F(R5.$$.fragment),jno=l(),nc=a("h2"),P5=a("a"),P7e=a("span"),F(bR.$$.fragment),YNr=l(),B7e=a("span"),ZNr=o("AutoModelForInstanceSegmentation"),Dno=l(),ir=a("div"),F(vR.$$.fragment),KNr=l(),sc=a("p"),eqr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),Lre=a("a"),oqr=o("from_pretrained()"),rqr=o(" class method or the "),yre=a("a"),tqr=o("from_config()"),aqr=o(` class
method.`),nqr=l(),FR=a("p"),sqr=o("This class cannot be instantiated directly using "),I7e=a("code"),lqr=o("__init__()"),iqr=o(" (throws an error)."),dqr=l(),Ht=a("div"),F(TR.$$.fragment),mqr=l(),N7e=a("p"),cqr=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),fqr=l(),lc=a("p"),gqr=o(`Note:
Loading a model from its configuration file does `),q7e=a("strong"),hqr=o("not"),uqr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xre=a("a"),pqr=o("from_pretrained()"),_qr=o(" to load the model weights."),bqr=l(),F(B5.$$.fragment),vqr=l(),Ao=a("div"),F(MR.$$.fragment),Fqr=l(),j7e=a("p"),Tqr=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),Mqr=l(),Rn=a("p"),Eqr=o("The model class to instantiate is selected based on the "),D7e=a("code"),Cqr=o("model_type"),wqr=o(` property of the config object (either
passed as an argument or loaded from `),G7e=a("code"),Aqr=o("pretrained_model_name_or_path"),Lqr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O7e=a("code"),yqr=o("pretrained_model_name_or_path"),xqr=o(":"),$qr=l(),V7e=a("ul"),I5=a("li"),X7e=a("strong"),kqr=o("maskformer"),Sqr=o(" \u2014 "),$re=a("a"),Rqr=o("MaskFormerForInstanceSegmentation"),Pqr=o(" (MaskFormer model)"),Bqr=l(),N5=a("p"),Iqr=o("The model is set in evaluation mode by default using "),z7e=a("code"),Nqr=o("model.eval()"),qqr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Q7e=a("code"),jqr=o("model.train()"),Dqr=l(),F(q5.$$.fragment),Gno=l(),ic=a("h2"),j5=a("a"),W7e=a("span"),F(ER.$$.fragment),Gqr=l(),U7e=a("span"),Oqr=o("AutoModelForZeroShotObjectDetection"),Ono=l(),dr=a("div"),F(CR.$$.fragment),Vqr=l(),dc=a("p"),Xqr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a zero-shot object detection head) when created
with the `),kre=a("a"),zqr=o("from_pretrained()"),Qqr=o(" class method or the "),Sre=a("a"),Wqr=o("from_config()"),Uqr=o(` class
method.`),Hqr=l(),wR=a("p"),Jqr=o("This class cannot be instantiated directly using "),H7e=a("code"),Yqr=o("__init__()"),Zqr=o(" (throws an error)."),Kqr=l(),Jt=a("div"),F(AR.$$.fragment),ejr=l(),J7e=a("p"),ojr=o("Instantiates one of the model classes of the library (with a zero-shot object detection head) from a configuration."),rjr=l(),mc=a("p"),tjr=o(`Note:
Loading a model from its configuration file does `),Y7e=a("strong"),ajr=o("not"),njr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Rre=a("a"),sjr=o("from_pretrained()"),ljr=o(" to load the model weights."),ijr=l(),F(D5.$$.fragment),djr=l(),Lo=a("div"),F(LR.$$.fragment),mjr=l(),Z7e=a("p"),cjr=o("Instantiate one of the model classes of the library (with a zero-shot object detection head) from a pretrained model."),fjr=l(),Pn=a("p"),gjr=o("The model class to instantiate is selected based on the "),K7e=a("code"),hjr=o("model_type"),ujr=o(` property of the config object (either
passed as an argument or loaded from `),e8e=a("code"),pjr=o("pretrained_model_name_or_path"),_jr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o8e=a("code"),bjr=o("pretrained_model_name_or_path"),vjr=o(":"),Fjr=l(),r8e=a("ul"),G5=a("li"),t8e=a("strong"),Tjr=o("owlvit"),Mjr=o(" \u2014 "),Pre=a("a"),Ejr=o("OwlViTForObjectDetection"),Cjr=o(" (OWL-ViT model)"),wjr=l(),O5=a("p"),Ajr=o("The model is set in evaluation mode by default using "),a8e=a("code"),Ljr=o("model.eval()"),yjr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),n8e=a("code"),xjr=o("model.train()"),$jr=l(),F(V5.$$.fragment),Vno=l(),cc=a("h2"),X5=a("a"),s8e=a("span"),F(yR.$$.fragment),kjr=l(),l8e=a("span"),Sjr=o("TFAutoModel"),Xno=l(),mr=a("div"),F(xR.$$.fragment),Rjr=l(),fc=a("p"),Pjr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Bre=a("a"),Bjr=o("from_pretrained()"),Ijr=o(" class method or the "),Ire=a("a"),Njr=o("from_config()"),qjr=o(` class
method.`),jjr=l(),$R=a("p"),Djr=o("This class cannot be instantiated directly using "),i8e=a("code"),Gjr=o("__init__()"),Ojr=o(" (throws an error)."),Vjr=l(),Yt=a("div"),F(kR.$$.fragment),Xjr=l(),d8e=a("p"),zjr=o("Instantiates one of the base model classes of the library from a configuration."),Qjr=l(),gc=a("p"),Wjr=o(`Note:
Loading a model from its configuration file does `),m8e=a("strong"),Ujr=o("not"),Hjr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Nre=a("a"),Jjr=o("from_pretrained()"),Yjr=o(" to load the model weights."),Zjr=l(),F(z5.$$.fragment),Kjr=l(),Dr=a("div"),F(SR.$$.fragment),eDr=l(),c8e=a("p"),oDr=o("Instantiate one of the base model classes of the library from a pretrained model."),rDr=l(),Bn=a("p"),tDr=o("The model class to instantiate is selected based on the "),f8e=a("code"),aDr=o("model_type"),nDr=o(` property of the config object (either
passed as an argument or loaded from `),g8e=a("code"),sDr=o("pretrained_model_name_or_path"),lDr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h8e=a("code"),iDr=o("pretrained_model_name_or_path"),dDr=o(":"),mDr=l(),P=a("ul"),Q5=a("li"),u8e=a("strong"),cDr=o("albert"),fDr=o(" \u2014 "),qre=a("a"),gDr=o("TFAlbertModel"),hDr=o(" (ALBERT model)"),uDr=l(),W5=a("li"),p8e=a("strong"),pDr=o("bart"),_Dr=o(" \u2014 "),jre=a("a"),bDr=o("TFBartModel"),vDr=o(" (BART model)"),FDr=l(),U5=a("li"),_8e=a("strong"),TDr=o("bert"),MDr=o(" \u2014 "),Dre=a("a"),EDr=o("TFBertModel"),CDr=o(" (BERT model)"),wDr=l(),H5=a("li"),b8e=a("strong"),ADr=o("blenderbot"),LDr=o(" \u2014 "),Gre=a("a"),yDr=o("TFBlenderbotModel"),xDr=o(" (Blenderbot model)"),$Dr=l(),J5=a("li"),v8e=a("strong"),kDr=o("blenderbot-small"),SDr=o(" \u2014 "),Ore=a("a"),RDr=o("TFBlenderbotSmallModel"),PDr=o(" (BlenderbotSmall model)"),BDr=l(),Y5=a("li"),F8e=a("strong"),IDr=o("camembert"),NDr=o(" \u2014 "),Vre=a("a"),qDr=o("TFCamembertModel"),jDr=o(" (CamemBERT model)"),DDr=l(),Z5=a("li"),T8e=a("strong"),GDr=o("clip"),ODr=o(" \u2014 "),Xre=a("a"),VDr=o("TFCLIPModel"),XDr=o(" (CLIP model)"),zDr=l(),K5=a("li"),M8e=a("strong"),QDr=o("convbert"),WDr=o(" \u2014 "),zre=a("a"),UDr=o("TFConvBertModel"),HDr=o(" (ConvBERT model)"),JDr=l(),e0=a("li"),E8e=a("strong"),YDr=o("convnext"),ZDr=o(" \u2014 "),Qre=a("a"),KDr=o("TFConvNextModel"),eGr=o(" (ConvNeXT model)"),oGr=l(),o0=a("li"),C8e=a("strong"),rGr=o("ctrl"),tGr=o(" \u2014 "),Wre=a("a"),aGr=o("TFCTRLModel"),nGr=o(" (CTRL model)"),sGr=l(),r0=a("li"),w8e=a("strong"),lGr=o("cvt"),iGr=o(" \u2014 "),Ure=a("a"),dGr=o("TFCvtModel"),mGr=o(" (CvT model)"),cGr=l(),t0=a("li"),A8e=a("strong"),fGr=o("data2vec-vision"),gGr=o(" \u2014 "),Hre=a("a"),hGr=o("TFData2VecVisionModel"),uGr=o(" (Data2VecVision model)"),pGr=l(),a0=a("li"),L8e=a("strong"),_Gr=o("deberta"),bGr=o(" \u2014 "),Jre=a("a"),vGr=o("TFDebertaModel"),FGr=o(" (DeBERTa model)"),TGr=l(),n0=a("li"),y8e=a("strong"),MGr=o("deberta-v2"),EGr=o(" \u2014 "),Yre=a("a"),CGr=o("TFDebertaV2Model"),wGr=o(" (DeBERTa-v2 model)"),AGr=l(),s0=a("li"),x8e=a("strong"),LGr=o("deit"),yGr=o(" \u2014 "),Zre=a("a"),xGr=o("TFDeiTModel"),$Gr=o(" (DeiT model)"),kGr=l(),l0=a("li"),$8e=a("strong"),SGr=o("distilbert"),RGr=o(" \u2014 "),Kre=a("a"),PGr=o("TFDistilBertModel"),BGr=o(" (DistilBERT model)"),IGr=l(),i0=a("li"),k8e=a("strong"),NGr=o("dpr"),qGr=o(" \u2014 "),ete=a("a"),jGr=o("TFDPRQuestionEncoder"),DGr=o(" (DPR model)"),GGr=l(),d0=a("li"),S8e=a("strong"),OGr=o("electra"),VGr=o(" \u2014 "),ote=a("a"),XGr=o("TFElectraModel"),zGr=o(" (ELECTRA model)"),QGr=l(),m0=a("li"),R8e=a("strong"),WGr=o("esm"),UGr=o(" \u2014 "),rte=a("a"),HGr=o("TFEsmModel"),JGr=o(" (ESM model)"),YGr=l(),c0=a("li"),P8e=a("strong"),ZGr=o("flaubert"),KGr=o(" \u2014 "),tte=a("a"),eOr=o("TFFlaubertModel"),oOr=o(" (FlauBERT model)"),rOr=l(),Rl=a("li"),B8e=a("strong"),tOr=o("funnel"),aOr=o(" \u2014 "),ate=a("a"),nOr=o("TFFunnelModel"),sOr=o(" or "),nte=a("a"),lOr=o("TFFunnelBaseModel"),iOr=o(" (Funnel Transformer model)"),dOr=l(),f0=a("li"),I8e=a("strong"),mOr=o("gpt2"),cOr=o(" \u2014 "),ste=a("a"),fOr=o("TFGPT2Model"),gOr=o(" (OpenAI GPT-2 model)"),hOr=l(),g0=a("li"),N8e=a("strong"),uOr=o("gptj"),pOr=o(" \u2014 "),lte=a("a"),_Or=o("TFGPTJModel"),bOr=o(" (GPT-J model)"),vOr=l(),h0=a("li"),q8e=a("strong"),FOr=o("groupvit"),TOr=o(" \u2014 "),ite=a("a"),MOr=o("TFGroupViTModel"),EOr=o(" (GroupViT model)"),COr=l(),u0=a("li"),j8e=a("strong"),wOr=o("hubert"),AOr=o(" \u2014 "),dte=a("a"),LOr=o("TFHubertModel"),yOr=o(" (Hubert model)"),xOr=l(),p0=a("li"),D8e=a("strong"),$Or=o("layoutlm"),kOr=o(" \u2014 "),mte=a("a"),SOr=o("TFLayoutLMModel"),ROr=o(" (LayoutLM model)"),POr=l(),_0=a("li"),G8e=a("strong"),BOr=o("layoutlmv3"),IOr=o(" \u2014 "),cte=a("a"),NOr=o("TFLayoutLMv3Model"),qOr=o(" (LayoutLMv3 model)"),jOr=l(),b0=a("li"),O8e=a("strong"),DOr=o("led"),GOr=o(" \u2014 "),fte=a("a"),OOr=o("TFLEDModel"),VOr=o(" (LED model)"),XOr=l(),v0=a("li"),V8e=a("strong"),zOr=o("longformer"),QOr=o(" \u2014 "),gte=a("a"),WOr=o("TFLongformerModel"),UOr=o(" (Longformer model)"),HOr=l(),F0=a("li"),X8e=a("strong"),JOr=o("lxmert"),YOr=o(" \u2014 "),hte=a("a"),ZOr=o("TFLxmertModel"),KOr=o(" (LXMERT model)"),eVr=l(),T0=a("li"),z8e=a("strong"),oVr=o("marian"),rVr=o(" \u2014 "),ute=a("a"),tVr=o("TFMarianModel"),aVr=o(" (Marian model)"),nVr=l(),M0=a("li"),Q8e=a("strong"),sVr=o("mbart"),lVr=o(" \u2014 "),pte=a("a"),iVr=o("TFMBartModel"),dVr=o(" (mBART model)"),mVr=l(),E0=a("li"),W8e=a("strong"),cVr=o("mobilebert"),fVr=o(" \u2014 "),_te=a("a"),gVr=o("TFMobileBertModel"),hVr=o(" (MobileBERT model)"),uVr=l(),C0=a("li"),U8e=a("strong"),pVr=o("mobilevit"),_Vr=o(" \u2014 "),bte=a("a"),bVr=o("TFMobileViTModel"),vVr=o(" (MobileViT model)"),FVr=l(),w0=a("li"),H8e=a("strong"),TVr=o("mpnet"),MVr=o(" \u2014 "),vte=a("a"),EVr=o("TFMPNetModel"),CVr=o(" (MPNet model)"),wVr=l(),A0=a("li"),J8e=a("strong"),AVr=o("mt5"),LVr=o(" \u2014 "),Fte=a("a"),yVr=o("TFMT5Model"),xVr=o(" (MT5 model)"),$Vr=l(),L0=a("li"),Y8e=a("strong"),kVr=o("openai-gpt"),SVr=o(" \u2014 "),Tte=a("a"),RVr=o("TFOpenAIGPTModel"),PVr=o(" (OpenAI GPT model)"),BVr=l(),y0=a("li"),Z8e=a("strong"),IVr=o("opt"),NVr=o(" \u2014 "),Mte=a("a"),qVr=o("TFOPTModel"),jVr=o(" (OPT model)"),DVr=l(),x0=a("li"),K8e=a("strong"),GVr=o("pegasus"),OVr=o(" \u2014 "),Ete=a("a"),VVr=o("TFPegasusModel"),XVr=o(" (Pegasus model)"),zVr=l(),$0=a("li"),eLe=a("strong"),QVr=o("regnet"),WVr=o(" \u2014 "),Cte=a("a"),UVr=o("TFRegNetModel"),HVr=o(" (RegNet model)"),JVr=l(),k0=a("li"),oLe=a("strong"),YVr=o("rembert"),ZVr=o(" \u2014 "),wte=a("a"),KVr=o("TFRemBertModel"),eXr=o(" (RemBERT model)"),oXr=l(),S0=a("li"),rLe=a("strong"),rXr=o("resnet"),tXr=o(" \u2014 "),Ate=a("a"),aXr=o("TFResNetModel"),nXr=o(" (ResNet model)"),sXr=l(),R0=a("li"),tLe=a("strong"),lXr=o("roberta"),iXr=o(" \u2014 "),Lte=a("a"),dXr=o("TFRobertaModel"),mXr=o(" (RoBERTa model)"),cXr=l(),P0=a("li"),aLe=a("strong"),fXr=o("roformer"),gXr=o(" \u2014 "),yte=a("a"),hXr=o("TFRoFormerModel"),uXr=o(" (RoFormer model)"),pXr=l(),B0=a("li"),nLe=a("strong"),_Xr=o("segformer"),bXr=o(" \u2014 "),xte=a("a"),vXr=o("TFSegformerModel"),FXr=o(" (SegFormer model)"),TXr=l(),I0=a("li"),sLe=a("strong"),MXr=o("speech_to_text"),EXr=o(" \u2014 "),$te=a("a"),CXr=o("TFSpeech2TextModel"),wXr=o(" (Speech2Text model)"),AXr=l(),N0=a("li"),lLe=a("strong"),LXr=o("swin"),yXr=o(" \u2014 "),kte=a("a"),xXr=o("TFSwinModel"),$Xr=o(" (Swin Transformer model)"),kXr=l(),q0=a("li"),iLe=a("strong"),SXr=o("t5"),RXr=o(" \u2014 "),Ste=a("a"),PXr=o("TFT5Model"),BXr=o(" (T5 model)"),IXr=l(),j0=a("li"),dLe=a("strong"),NXr=o("tapas"),qXr=o(" \u2014 "),Rte=a("a"),jXr=o("TFTapasModel"),DXr=o(" (TAPAS model)"),GXr=l(),D0=a("li"),mLe=a("strong"),OXr=o("transfo-xl"),VXr=o(" \u2014 "),Pte=a("a"),XXr=o("TFTransfoXLModel"),zXr=o(" (Transformer-XL model)"),QXr=l(),G0=a("li"),cLe=a("strong"),WXr=o("vit"),UXr=o(" \u2014 "),Bte=a("a"),HXr=o("TFViTModel"),JXr=o(" (ViT model)"),YXr=l(),O0=a("li"),fLe=a("strong"),ZXr=o("vit_mae"),KXr=o(" \u2014 "),Ite=a("a"),ezr=o("TFViTMAEModel"),ozr=o(" (ViTMAE model)"),rzr=l(),V0=a("li"),gLe=a("strong"),tzr=o("wav2vec2"),azr=o(" \u2014 "),Nte=a("a"),nzr=o("TFWav2Vec2Model"),szr=o(" (Wav2Vec2 model)"),lzr=l(),X0=a("li"),hLe=a("strong"),izr=o("whisper"),dzr=o(" \u2014 "),qte=a("a"),mzr=o("TFWhisperModel"),czr=o(" (Whisper model)"),fzr=l(),z0=a("li"),uLe=a("strong"),gzr=o("xglm"),hzr=o(" \u2014 "),jte=a("a"),uzr=o("TFXGLMModel"),pzr=o(" (XGLM model)"),_zr=l(),Q0=a("li"),pLe=a("strong"),bzr=o("xlm"),vzr=o(" \u2014 "),Dte=a("a"),Fzr=o("TFXLMModel"),Tzr=o(" (XLM model)"),Mzr=l(),W0=a("li"),_Le=a("strong"),Ezr=o("xlm-roberta"),Czr=o(" \u2014 "),Gte=a("a"),wzr=o("TFXLMRobertaModel"),Azr=o(" (XLM-RoBERTa model)"),Lzr=l(),U0=a("li"),bLe=a("strong"),yzr=o("xlnet"),xzr=o(" \u2014 "),Ote=a("a"),$zr=o("TFXLNetModel"),kzr=o(" (XLNet model)"),Szr=l(),F(H0.$$.fragment),zno=l(),hc=a("h2"),J0=a("a"),vLe=a("span"),F(RR.$$.fragment),Rzr=l(),FLe=a("span"),Pzr=o("TFAutoModelForPreTraining"),Qno=l(),cr=a("div"),F(PR.$$.fragment),Bzr=l(),uc=a("p"),Izr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Vte=a("a"),Nzr=o("from_pretrained()"),qzr=o(" class method or the "),Xte=a("a"),jzr=o("from_config()"),Dzr=o(` class
method.`),Gzr=l(),BR=a("p"),Ozr=o("This class cannot be instantiated directly using "),TLe=a("code"),Vzr=o("__init__()"),Xzr=o(" (throws an error)."),zzr=l(),Zt=a("div"),F(IR.$$.fragment),Qzr=l(),MLe=a("p"),Wzr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Uzr=l(),pc=a("p"),Hzr=o(`Note:
Loading a model from its configuration file does `),ELe=a("strong"),Jzr=o("not"),Yzr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zte=a("a"),Zzr=o("from_pretrained()"),Kzr=o(" to load the model weights."),eQr=l(),F(Y0.$$.fragment),oQr=l(),Gr=a("div"),F(NR.$$.fragment),rQr=l(),CLe=a("p"),tQr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),aQr=l(),In=a("p"),nQr=o("The model class to instantiate is selected based on the "),wLe=a("code"),sQr=o("model_type"),lQr=o(` property of the config object (either
passed as an argument or loaded from `),ALe=a("code"),iQr=o("pretrained_model_name_or_path"),dQr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),LLe=a("code"),mQr=o("pretrained_model_name_or_path"),cQr=o(":"),fQr=l(),le=a("ul"),Z0=a("li"),yLe=a("strong"),gQr=o("albert"),hQr=o(" \u2014 "),Qte=a("a"),uQr=o("TFAlbertForPreTraining"),pQr=o(" (ALBERT model)"),_Qr=l(),K0=a("li"),xLe=a("strong"),bQr=o("bart"),vQr=o(" \u2014 "),Wte=a("a"),FQr=o("TFBartForConditionalGeneration"),TQr=o(" (BART model)"),MQr=l(),ew=a("li"),$Le=a("strong"),EQr=o("bert"),CQr=o(" \u2014 "),Ute=a("a"),wQr=o("TFBertForPreTraining"),AQr=o(" (BERT model)"),LQr=l(),ow=a("li"),kLe=a("strong"),yQr=o("camembert"),xQr=o(" \u2014 "),Hte=a("a"),$Qr=o("TFCamembertForMaskedLM"),kQr=o(" (CamemBERT model)"),SQr=l(),rw=a("li"),SLe=a("strong"),RQr=o("ctrl"),PQr=o(" \u2014 "),Jte=a("a"),BQr=o("TFCTRLLMHeadModel"),IQr=o(" (CTRL model)"),NQr=l(),tw=a("li"),RLe=a("strong"),qQr=o("distilbert"),jQr=o(" \u2014 "),Yte=a("a"),DQr=o("TFDistilBertForMaskedLM"),GQr=o(" (DistilBERT model)"),OQr=l(),aw=a("li"),PLe=a("strong"),VQr=o("electra"),XQr=o(" \u2014 "),Zte=a("a"),zQr=o("TFElectraForPreTraining"),QQr=o(" (ELECTRA model)"),WQr=l(),nw=a("li"),BLe=a("strong"),UQr=o("flaubert"),HQr=o(" \u2014 "),Kte=a("a"),JQr=o("TFFlaubertWithLMHeadModel"),YQr=o(" (FlauBERT model)"),ZQr=l(),sw=a("li"),ILe=a("strong"),KQr=o("funnel"),eWr=o(" \u2014 "),eae=a("a"),oWr=o("TFFunnelForPreTraining"),rWr=o(" (Funnel Transformer model)"),tWr=l(),lw=a("li"),NLe=a("strong"),aWr=o("gpt2"),nWr=o(" \u2014 "),oae=a("a"),sWr=o("TFGPT2LMHeadModel"),lWr=o(" (OpenAI GPT-2 model)"),iWr=l(),iw=a("li"),qLe=a("strong"),dWr=o("layoutlm"),mWr=o(" \u2014 "),rae=a("a"),cWr=o("TFLayoutLMForMaskedLM"),fWr=o(" (LayoutLM model)"),gWr=l(),dw=a("li"),jLe=a("strong"),hWr=o("lxmert"),uWr=o(" \u2014 "),tae=a("a"),pWr=o("TFLxmertForPreTraining"),_Wr=o(" (LXMERT model)"),bWr=l(),mw=a("li"),DLe=a("strong"),vWr=o("mobilebert"),FWr=o(" \u2014 "),aae=a("a"),TWr=o("TFMobileBertForPreTraining"),MWr=o(" (MobileBERT model)"),EWr=l(),cw=a("li"),GLe=a("strong"),CWr=o("mpnet"),wWr=o(" \u2014 "),nae=a("a"),AWr=o("TFMPNetForMaskedLM"),LWr=o(" (MPNet model)"),yWr=l(),fw=a("li"),OLe=a("strong"),xWr=o("openai-gpt"),$Wr=o(" \u2014 "),sae=a("a"),kWr=o("TFOpenAIGPTLMHeadModel"),SWr=o(" (OpenAI GPT model)"),RWr=l(),gw=a("li"),VLe=a("strong"),PWr=o("roberta"),BWr=o(" \u2014 "),lae=a("a"),IWr=o("TFRobertaForMaskedLM"),NWr=o(" (RoBERTa model)"),qWr=l(),hw=a("li"),XLe=a("strong"),jWr=o("t5"),DWr=o(" \u2014 "),iae=a("a"),GWr=o("TFT5ForConditionalGeneration"),OWr=o(" (T5 model)"),VWr=l(),uw=a("li"),zLe=a("strong"),XWr=o("tapas"),zWr=o(" \u2014 "),dae=a("a"),QWr=o("TFTapasForMaskedLM"),WWr=o(" (TAPAS model)"),UWr=l(),pw=a("li"),QLe=a("strong"),HWr=o("transfo-xl"),JWr=o(" \u2014 "),mae=a("a"),YWr=o("TFTransfoXLLMHeadModel"),ZWr=o(" (Transformer-XL model)"),KWr=l(),_w=a("li"),WLe=a("strong"),eUr=o("vit_mae"),oUr=o(" \u2014 "),cae=a("a"),rUr=o("TFViTMAEForPreTraining"),tUr=o(" (ViTMAE model)"),aUr=l(),bw=a("li"),ULe=a("strong"),nUr=o("xlm"),sUr=o(" \u2014 "),fae=a("a"),lUr=o("TFXLMWithLMHeadModel"),iUr=o(" (XLM model)"),dUr=l(),vw=a("li"),HLe=a("strong"),mUr=o("xlm-roberta"),cUr=o(" \u2014 "),gae=a("a"),fUr=o("TFXLMRobertaForMaskedLM"),gUr=o(" (XLM-RoBERTa model)"),hUr=l(),Fw=a("li"),JLe=a("strong"),uUr=o("xlnet"),pUr=o(" \u2014 "),hae=a("a"),_Ur=o("TFXLNetLMHeadModel"),bUr=o(" (XLNet model)"),vUr=l(),F(Tw.$$.fragment),Wno=l(),_c=a("h2"),Mw=a("a"),YLe=a("span"),F(qR.$$.fragment),FUr=l(),ZLe=a("span"),TUr=o("TFAutoModelForCausalLM"),Uno=l(),fr=a("div"),F(jR.$$.fragment),MUr=l(),bc=a("p"),EUr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),uae=a("a"),CUr=o("from_pretrained()"),wUr=o(" class method or the "),pae=a("a"),AUr=o("from_config()"),LUr=o(` class
method.`),yUr=l(),DR=a("p"),xUr=o("This class cannot be instantiated directly using "),KLe=a("code"),$Ur=o("__init__()"),kUr=o(" (throws an error)."),SUr=l(),Kt=a("div"),F(GR.$$.fragment),RUr=l(),eye=a("p"),PUr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),BUr=l(),vc=a("p"),IUr=o(`Note:
Loading a model from its configuration file does `),oye=a("strong"),NUr=o("not"),qUr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_ae=a("a"),jUr=o("from_pretrained()"),DUr=o(" to load the model weights."),GUr=l(),F(Ew.$$.fragment),OUr=l(),Or=a("div"),F(OR.$$.fragment),VUr=l(),rye=a("p"),XUr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),zUr=l(),Nn=a("p"),QUr=o("The model class to instantiate is selected based on the "),tye=a("code"),WUr=o("model_type"),UUr=o(` property of the config object (either
passed as an argument or loaded from `),aye=a("code"),HUr=o("pretrained_model_name_or_path"),JUr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nye=a("code"),YUr=o("pretrained_model_name_or_path"),ZUr=o(":"),KUr=l(),Me=a("ul"),Cw=a("li"),sye=a("strong"),eHr=o("bert"),oHr=o(" \u2014 "),bae=a("a"),rHr=o("TFBertLMHeadModel"),tHr=o(" (BERT model)"),aHr=l(),ww=a("li"),lye=a("strong"),nHr=o("camembert"),sHr=o(" \u2014 "),vae=a("a"),lHr=o("TFCamembertForCausalLM"),iHr=o(" (CamemBERT model)"),dHr=l(),Aw=a("li"),iye=a("strong"),mHr=o("ctrl"),cHr=o(" \u2014 "),Fae=a("a"),fHr=o("TFCTRLLMHeadModel"),gHr=o(" (CTRL model)"),hHr=l(),Lw=a("li"),dye=a("strong"),uHr=o("gpt2"),pHr=o(" \u2014 "),Tae=a("a"),_Hr=o("TFGPT2LMHeadModel"),bHr=o(" (OpenAI GPT-2 model)"),vHr=l(),yw=a("li"),mye=a("strong"),FHr=o("gptj"),THr=o(" \u2014 "),Mae=a("a"),MHr=o("TFGPTJForCausalLM"),EHr=o(" (GPT-J model)"),CHr=l(),xw=a("li"),cye=a("strong"),wHr=o("openai-gpt"),AHr=o(" \u2014 "),Eae=a("a"),LHr=o("TFOpenAIGPTLMHeadModel"),yHr=o(" (OpenAI GPT model)"),xHr=l(),$w=a("li"),fye=a("strong"),$Hr=o("opt"),kHr=o(" \u2014 "),Cae=a("a"),SHr=o("TFOPTForCausalLM"),RHr=o(" (OPT model)"),PHr=l(),kw=a("li"),gye=a("strong"),BHr=o("rembert"),IHr=o(" \u2014 "),wae=a("a"),NHr=o("TFRemBertForCausalLM"),qHr=o(" (RemBERT model)"),jHr=l(),Sw=a("li"),hye=a("strong"),DHr=o("roberta"),GHr=o(" \u2014 "),Aae=a("a"),OHr=o("TFRobertaForCausalLM"),VHr=o(" (RoBERTa model)"),XHr=l(),Rw=a("li"),uye=a("strong"),zHr=o("roformer"),QHr=o(" \u2014 "),Lae=a("a"),WHr=o("TFRoFormerForCausalLM"),UHr=o(" (RoFormer model)"),HHr=l(),Pw=a("li"),pye=a("strong"),JHr=o("transfo-xl"),YHr=o(" \u2014 "),yae=a("a"),ZHr=o("TFTransfoXLLMHeadModel"),KHr=o(" (Transformer-XL model)"),eJr=l(),Bw=a("li"),_ye=a("strong"),oJr=o("xglm"),rJr=o(" \u2014 "),xae=a("a"),tJr=o("TFXGLMForCausalLM"),aJr=o(" (XGLM model)"),nJr=l(),Iw=a("li"),bye=a("strong"),sJr=o("xlm"),lJr=o(" \u2014 "),$ae=a("a"),iJr=o("TFXLMWithLMHeadModel"),dJr=o(" (XLM model)"),mJr=l(),Nw=a("li"),vye=a("strong"),cJr=o("xlnet"),fJr=o(" \u2014 "),kae=a("a"),gJr=o("TFXLNetLMHeadModel"),hJr=o(" (XLNet model)"),uJr=l(),F(qw.$$.fragment),Hno=l(),Fc=a("h2"),jw=a("a"),Fye=a("span"),F(VR.$$.fragment),pJr=l(),Tye=a("span"),_Jr=o("TFAutoModelForImageClassification"),Jno=l(),gr=a("div"),F(XR.$$.fragment),bJr=l(),Tc=a("p"),vJr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Sae=a("a"),FJr=o("from_pretrained()"),TJr=o(" class method or the "),Rae=a("a"),MJr=o("from_config()"),EJr=o(` class
method.`),CJr=l(),zR=a("p"),wJr=o("This class cannot be instantiated directly using "),Mye=a("code"),AJr=o("__init__()"),LJr=o(" (throws an error)."),yJr=l(),ea=a("div"),F(QR.$$.fragment),xJr=l(),Eye=a("p"),$Jr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),kJr=l(),Mc=a("p"),SJr=o(`Note:
Loading a model from its configuration file does `),Cye=a("strong"),RJr=o("not"),PJr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Pae=a("a"),BJr=o("from_pretrained()"),IJr=o(" to load the model weights."),NJr=l(),F(Dw.$$.fragment),qJr=l(),Vr=a("div"),F(WR.$$.fragment),jJr=l(),wye=a("p"),DJr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),GJr=l(),qn=a("p"),OJr=o("The model class to instantiate is selected based on the "),Aye=a("code"),VJr=o("model_type"),XJr=o(` property of the config object (either
passed as an argument or loaded from `),Lye=a("code"),zJr=o("pretrained_model_name_or_path"),QJr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yye=a("code"),WJr=o("pretrained_model_name_or_path"),UJr=o(":"),HJr=l(),ye=a("ul"),Gw=a("li"),xye=a("strong"),JJr=o("convnext"),YJr=o(" \u2014 "),Bae=a("a"),ZJr=o("TFConvNextForImageClassification"),KJr=o(" (ConvNeXT model)"),eYr=l(),Ow=a("li"),$ye=a("strong"),oYr=o("cvt"),rYr=o(" \u2014 "),Iae=a("a"),tYr=o("TFCvtForImageClassification"),aYr=o(" (CvT model)"),nYr=l(),Vw=a("li"),kye=a("strong"),sYr=o("data2vec-vision"),lYr=o(" \u2014 "),Nae=a("a"),iYr=o("TFData2VecVisionForImageClassification"),dYr=o(" (Data2VecVision model)"),mYr=l(),Pl=a("li"),Sye=a("strong"),cYr=o("deit"),fYr=o(" \u2014 "),qae=a("a"),gYr=o("TFDeiTForImageClassification"),hYr=o(" or "),jae=a("a"),uYr=o("TFDeiTForImageClassificationWithTeacher"),pYr=o(" (DeiT model)"),_Yr=l(),Xw=a("li"),Rye=a("strong"),bYr=o("mobilevit"),vYr=o(" \u2014 "),Dae=a("a"),FYr=o("TFMobileViTForImageClassification"),TYr=o(" (MobileViT model)"),MYr=l(),zw=a("li"),Pye=a("strong"),EYr=o("regnet"),CYr=o(" \u2014 "),Gae=a("a"),wYr=o("TFRegNetForImageClassification"),AYr=o(" (RegNet model)"),LYr=l(),Qw=a("li"),Bye=a("strong"),yYr=o("resnet"),xYr=o(" \u2014 "),Oae=a("a"),$Yr=o("TFResNetForImageClassification"),kYr=o(" (ResNet model)"),SYr=l(),Ww=a("li"),Iye=a("strong"),RYr=o("segformer"),PYr=o(" \u2014 "),Vae=a("a"),BYr=o("TFSegformerForImageClassification"),IYr=o(" (SegFormer model)"),NYr=l(),Uw=a("li"),Nye=a("strong"),qYr=o("swin"),jYr=o(" \u2014 "),Xae=a("a"),DYr=o("TFSwinForImageClassification"),GYr=o(" (Swin Transformer model)"),OYr=l(),Hw=a("li"),qye=a("strong"),VYr=o("vit"),XYr=o(" \u2014 "),zae=a("a"),zYr=o("TFViTForImageClassification"),QYr=o(" (ViT model)"),WYr=l(),F(Jw.$$.fragment),Yno=l(),Ec=a("h2"),Yw=a("a"),jye=a("span"),F(UR.$$.fragment),UYr=l(),Dye=a("span"),HYr=o("TFAutoModelForSemanticSegmentation"),Zno=l(),hr=a("div"),F(HR.$$.fragment),JYr=l(),Cc=a("p"),YYr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),Qae=a("a"),ZYr=o("from_pretrained()"),KYr=o(" class method or the "),Wae=a("a"),eZr=o("from_config()"),oZr=o(` class
method.`),rZr=l(),JR=a("p"),tZr=o("This class cannot be instantiated directly using "),Gye=a("code"),aZr=o("__init__()"),nZr=o(" (throws an error)."),sZr=l(),oa=a("div"),F(YR.$$.fragment),lZr=l(),Oye=a("p"),iZr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),dZr=l(),wc=a("p"),mZr=o(`Note:
Loading a model from its configuration file does `),Vye=a("strong"),cZr=o("not"),fZr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Uae=a("a"),gZr=o("from_pretrained()"),hZr=o(" to load the model weights."),uZr=l(),F(Zw.$$.fragment),pZr=l(),Xr=a("div"),F(ZR.$$.fragment),_Zr=l(),Xye=a("p"),bZr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),vZr=l(),jn=a("p"),FZr=o("The model class to instantiate is selected based on the "),zye=a("code"),TZr=o("model_type"),MZr=o(` property of the config object (either
passed as an argument or loaded from `),Qye=a("code"),EZr=o("pretrained_model_name_or_path"),CZr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wye=a("code"),wZr=o("pretrained_model_name_or_path"),AZr=o(":"),LZr=l(),Ac=a("ul"),Kw=a("li"),Uye=a("strong"),yZr=o("data2vec-vision"),xZr=o(" \u2014 "),Hae=a("a"),$Zr=o("TFData2VecVisionForSemanticSegmentation"),kZr=o(" (Data2VecVision model)"),SZr=l(),eA=a("li"),Hye=a("strong"),RZr=o("mobilevit"),PZr=o(" \u2014 "),Jae=a("a"),BZr=o("TFMobileViTForSemanticSegmentation"),IZr=o(" (MobileViT model)"),NZr=l(),oA=a("li"),Jye=a("strong"),qZr=o("segformer"),jZr=o(" \u2014 "),Yae=a("a"),DZr=o("TFSegformerForSemanticSegmentation"),GZr=o(" (SegFormer model)"),OZr=l(),F(rA.$$.fragment),Kno=l(),Lc=a("h2"),tA=a("a"),Yye=a("span"),F(KR.$$.fragment),VZr=l(),Zye=a("span"),XZr=o("TFAutoModelForMaskedLM"),eso=l(),ur=a("div"),F(eP.$$.fragment),zZr=l(),yc=a("p"),QZr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Zae=a("a"),WZr=o("from_pretrained()"),UZr=o(" class method or the "),Kae=a("a"),HZr=o("from_config()"),JZr=o(` class
method.`),YZr=l(),oP=a("p"),ZZr=o("This class cannot be instantiated directly using "),Kye=a("code"),KZr=o("__init__()"),eKr=o(" (throws an error)."),oKr=l(),ra=a("div"),F(rP.$$.fragment),rKr=l(),e9e=a("p"),tKr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),aKr=l(),xc=a("p"),nKr=o(`Note:
Loading a model from its configuration file does `),o9e=a("strong"),sKr=o("not"),lKr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ene=a("a"),iKr=o("from_pretrained()"),dKr=o(" to load the model weights."),mKr=l(),F(aA.$$.fragment),cKr=l(),zr=a("div"),F(tP.$$.fragment),fKr=l(),r9e=a("p"),gKr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),hKr=l(),Dn=a("p"),uKr=o("The model class to instantiate is selected based on the "),t9e=a("code"),pKr=o("model_type"),_Kr=o(` property of the config object (either
passed as an argument or loaded from `),a9e=a("code"),bKr=o("pretrained_model_name_or_path"),vKr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n9e=a("code"),FKr=o("pretrained_model_name_or_path"),TKr=o(":"),MKr=l(),ce=a("ul"),nA=a("li"),s9e=a("strong"),EKr=o("albert"),CKr=o(" \u2014 "),one=a("a"),wKr=o("TFAlbertForMaskedLM"),AKr=o(" (ALBERT model)"),LKr=l(),sA=a("li"),l9e=a("strong"),yKr=o("bert"),xKr=o(" \u2014 "),rne=a("a"),$Kr=o("TFBertForMaskedLM"),kKr=o(" (BERT model)"),SKr=l(),lA=a("li"),i9e=a("strong"),RKr=o("camembert"),PKr=o(" \u2014 "),tne=a("a"),BKr=o("TFCamembertForMaskedLM"),IKr=o(" (CamemBERT model)"),NKr=l(),iA=a("li"),d9e=a("strong"),qKr=o("convbert"),jKr=o(" \u2014 "),ane=a("a"),DKr=o("TFConvBertForMaskedLM"),GKr=o(" (ConvBERT model)"),OKr=l(),dA=a("li"),m9e=a("strong"),VKr=o("deberta"),XKr=o(" \u2014 "),nne=a("a"),zKr=o("TFDebertaForMaskedLM"),QKr=o(" (DeBERTa model)"),WKr=l(),mA=a("li"),c9e=a("strong"),UKr=o("deberta-v2"),HKr=o(" \u2014 "),sne=a("a"),JKr=o("TFDebertaV2ForMaskedLM"),YKr=o(" (DeBERTa-v2 model)"),ZKr=l(),cA=a("li"),f9e=a("strong"),KKr=o("distilbert"),eet=o(" \u2014 "),lne=a("a"),oet=o("TFDistilBertForMaskedLM"),ret=o(" (DistilBERT model)"),tet=l(),fA=a("li"),g9e=a("strong"),aet=o("electra"),net=o(" \u2014 "),ine=a("a"),set=o("TFElectraForMaskedLM"),iet=o(" (ELECTRA model)"),det=l(),gA=a("li"),h9e=a("strong"),met=o("esm"),cet=o(" \u2014 "),dne=a("a"),fet=o("TFEsmForMaskedLM"),get=o(" (ESM model)"),het=l(),hA=a("li"),u9e=a("strong"),uet=o("flaubert"),pet=o(" \u2014 "),mne=a("a"),_et=o("TFFlaubertWithLMHeadModel"),bet=o(" (FlauBERT model)"),vet=l(),uA=a("li"),p9e=a("strong"),Fet=o("funnel"),Tet=o(" \u2014 "),cne=a("a"),Met=o("TFFunnelForMaskedLM"),Eet=o(" (Funnel Transformer model)"),Cet=l(),pA=a("li"),_9e=a("strong"),wet=o("layoutlm"),Aet=o(" \u2014 "),fne=a("a"),Let=o("TFLayoutLMForMaskedLM"),yet=o(" (LayoutLM model)"),xet=l(),_A=a("li"),b9e=a("strong"),$et=o("longformer"),ket=o(" \u2014 "),gne=a("a"),Set=o("TFLongformerForMaskedLM"),Ret=o(" (Longformer model)"),Pet=l(),bA=a("li"),v9e=a("strong"),Bet=o("mobilebert"),Iet=o(" \u2014 "),hne=a("a"),Net=o("TFMobileBertForMaskedLM"),qet=o(" (MobileBERT model)"),jet=l(),vA=a("li"),F9e=a("strong"),Det=o("mpnet"),Get=o(" \u2014 "),une=a("a"),Oet=o("TFMPNetForMaskedLM"),Vet=o(" (MPNet model)"),Xet=l(),FA=a("li"),T9e=a("strong"),zet=o("rembert"),Qet=o(" \u2014 "),pne=a("a"),Wet=o("TFRemBertForMaskedLM"),Uet=o(" (RemBERT model)"),Het=l(),TA=a("li"),M9e=a("strong"),Jet=o("roberta"),Yet=o(" \u2014 "),_ne=a("a"),Zet=o("TFRobertaForMaskedLM"),Ket=o(" (RoBERTa model)"),eot=l(),MA=a("li"),E9e=a("strong"),oot=o("roformer"),rot=o(" \u2014 "),bne=a("a"),tot=o("TFRoFormerForMaskedLM"),aot=o(" (RoFormer model)"),not=l(),EA=a("li"),C9e=a("strong"),sot=o("tapas"),lot=o(" \u2014 "),vne=a("a"),iot=o("TFTapasForMaskedLM"),dot=o(" (TAPAS model)"),mot=l(),CA=a("li"),w9e=a("strong"),cot=o("xlm"),fot=o(" \u2014 "),Fne=a("a"),got=o("TFXLMWithLMHeadModel"),hot=o(" (XLM model)"),uot=l(),wA=a("li"),A9e=a("strong"),pot=o("xlm-roberta"),_ot=o(" \u2014 "),Tne=a("a"),bot=o("TFXLMRobertaForMaskedLM"),vot=o(" (XLM-RoBERTa model)"),Fot=l(),F(AA.$$.fragment),oso=l(),$c=a("h2"),LA=a("a"),L9e=a("span"),F(aP.$$.fragment),Tot=l(),y9e=a("span"),Mot=o("TFAutoModelForSeq2SeqLM"),rso=l(),pr=a("div"),F(nP.$$.fragment),Eot=l(),kc=a("p"),Cot=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Mne=a("a"),wot=o("from_pretrained()"),Aot=o(" class method or the "),Ene=a("a"),Lot=o("from_config()"),yot=o(` class
method.`),xot=l(),sP=a("p"),$ot=o("This class cannot be instantiated directly using "),x9e=a("code"),kot=o("__init__()"),Sot=o(" (throws an error)."),Rot=l(),ta=a("div"),F(lP.$$.fragment),Pot=l(),$9e=a("p"),Bot=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Iot=l(),Sc=a("p"),Not=o(`Note:
Loading a model from its configuration file does `),k9e=a("strong"),qot=o("not"),jot=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Cne=a("a"),Dot=o("from_pretrained()"),Got=o(" to load the model weights."),Oot=l(),F(yA.$$.fragment),Vot=l(),Qr=a("div"),F(iP.$$.fragment),Xot=l(),S9e=a("p"),zot=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Qot=l(),Gn=a("p"),Wot=o("The model class to instantiate is selected based on the "),R9e=a("code"),Uot=o("model_type"),Hot=o(` property of the config object (either
passed as an argument or loaded from `),P9e=a("code"),Jot=o("pretrained_model_name_or_path"),Yot=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),B9e=a("code"),Zot=o("pretrained_model_name_or_path"),Kot=o(":"),ert=l(),xe=a("ul"),xA=a("li"),I9e=a("strong"),ort=o("bart"),rrt=o(" \u2014 "),wne=a("a"),trt=o("TFBartForConditionalGeneration"),art=o(" (BART model)"),nrt=l(),$A=a("li"),N9e=a("strong"),srt=o("blenderbot"),lrt=o(" \u2014 "),Ane=a("a"),irt=o("TFBlenderbotForConditionalGeneration"),drt=o(" (Blenderbot model)"),mrt=l(),kA=a("li"),q9e=a("strong"),crt=o("blenderbot-small"),frt=o(" \u2014 "),Lne=a("a"),grt=o("TFBlenderbotSmallForConditionalGeneration"),hrt=o(" (BlenderbotSmall model)"),urt=l(),SA=a("li"),j9e=a("strong"),prt=o("encoder-decoder"),_rt=o(" \u2014 "),yne=a("a"),brt=o("TFEncoderDecoderModel"),vrt=o(" (Encoder decoder model)"),Frt=l(),RA=a("li"),D9e=a("strong"),Trt=o("led"),Mrt=o(" \u2014 "),xne=a("a"),Ert=o("TFLEDForConditionalGeneration"),Crt=o(" (LED model)"),wrt=l(),PA=a("li"),G9e=a("strong"),Art=o("marian"),Lrt=o(" \u2014 "),$ne=a("a"),yrt=o("TFMarianMTModel"),xrt=o(" (Marian model)"),$rt=l(),BA=a("li"),O9e=a("strong"),krt=o("mbart"),Srt=o(" \u2014 "),kne=a("a"),Rrt=o("TFMBartForConditionalGeneration"),Prt=o(" (mBART model)"),Brt=l(),IA=a("li"),V9e=a("strong"),Irt=o("mt5"),Nrt=o(" \u2014 "),Sne=a("a"),qrt=o("TFMT5ForConditionalGeneration"),jrt=o(" (MT5 model)"),Drt=l(),NA=a("li"),X9e=a("strong"),Grt=o("pegasus"),Ort=o(" \u2014 "),Rne=a("a"),Vrt=o("TFPegasusForConditionalGeneration"),Xrt=o(" (Pegasus model)"),zrt=l(),qA=a("li"),z9e=a("strong"),Qrt=o("t5"),Wrt=o(" \u2014 "),Pne=a("a"),Urt=o("TFT5ForConditionalGeneration"),Hrt=o(" (T5 model)"),Jrt=l(),F(jA.$$.fragment),tso=l(),Rc=a("h2"),DA=a("a"),Q9e=a("span"),F(dP.$$.fragment),Yrt=l(),W9e=a("span"),Zrt=o("TFAutoModelForSequenceClassification"),aso=l(),_r=a("div"),F(mP.$$.fragment),Krt=l(),Pc=a("p"),ett=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Bne=a("a"),ott=o("from_pretrained()"),rtt=o(" class method or the "),Ine=a("a"),ttt=o("from_config()"),att=o(` class
method.`),ntt=l(),cP=a("p"),stt=o("This class cannot be instantiated directly using "),U9e=a("code"),ltt=o("__init__()"),itt=o(" (throws an error)."),dtt=l(),aa=a("div"),F(fP.$$.fragment),mtt=l(),H9e=a("p"),ctt=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),ftt=l(),Bc=a("p"),gtt=o(`Note:
Loading a model from its configuration file does `),J9e=a("strong"),htt=o("not"),utt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Nne=a("a"),ptt=o("from_pretrained()"),_tt=o(" to load the model weights."),btt=l(),F(GA.$$.fragment),vtt=l(),Wr=a("div"),F(gP.$$.fragment),Ftt=l(),Y9e=a("p"),Ttt=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Mtt=l(),On=a("p"),Ett=o("The model class to instantiate is selected based on the "),Z9e=a("code"),Ctt=o("model_type"),wtt=o(` property of the config object (either
passed as an argument or loaded from `),K9e=a("code"),Att=o("pretrained_model_name_or_path"),Ltt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),exe=a("code"),ytt=o("pretrained_model_name_or_path"),xtt=o(":"),$tt=l(),re=a("ul"),OA=a("li"),oxe=a("strong"),ktt=o("albert"),Stt=o(" \u2014 "),qne=a("a"),Rtt=o("TFAlbertForSequenceClassification"),Ptt=o(" (ALBERT model)"),Btt=l(),VA=a("li"),rxe=a("strong"),Itt=o("bert"),Ntt=o(" \u2014 "),jne=a("a"),qtt=o("TFBertForSequenceClassification"),jtt=o(" (BERT model)"),Dtt=l(),XA=a("li"),txe=a("strong"),Gtt=o("camembert"),Ott=o(" \u2014 "),Dne=a("a"),Vtt=o("TFCamembertForSequenceClassification"),Xtt=o(" (CamemBERT model)"),ztt=l(),zA=a("li"),axe=a("strong"),Qtt=o("convbert"),Wtt=o(" \u2014 "),Gne=a("a"),Utt=o("TFConvBertForSequenceClassification"),Htt=o(" (ConvBERT model)"),Jtt=l(),QA=a("li"),nxe=a("strong"),Ytt=o("ctrl"),Ztt=o(" \u2014 "),One=a("a"),Ktt=o("TFCTRLForSequenceClassification"),eat=o(" (CTRL model)"),oat=l(),WA=a("li"),sxe=a("strong"),rat=o("deberta"),tat=o(" \u2014 "),Vne=a("a"),aat=o("TFDebertaForSequenceClassification"),nat=o(" (DeBERTa model)"),sat=l(),UA=a("li"),lxe=a("strong"),lat=o("deberta-v2"),iat=o(" \u2014 "),Xne=a("a"),dat=o("TFDebertaV2ForSequenceClassification"),mat=o(" (DeBERTa-v2 model)"),cat=l(),HA=a("li"),ixe=a("strong"),fat=o("distilbert"),gat=o(" \u2014 "),zne=a("a"),hat=o("TFDistilBertForSequenceClassification"),uat=o(" (DistilBERT model)"),pat=l(),JA=a("li"),dxe=a("strong"),_at=o("electra"),bat=o(" \u2014 "),Qne=a("a"),vat=o("TFElectraForSequenceClassification"),Fat=o(" (ELECTRA model)"),Tat=l(),YA=a("li"),mxe=a("strong"),Mat=o("esm"),Eat=o(" \u2014 "),Wne=a("a"),Cat=o("TFEsmForSequenceClassification"),wat=o(" (ESM model)"),Aat=l(),ZA=a("li"),cxe=a("strong"),Lat=o("flaubert"),yat=o(" \u2014 "),Une=a("a"),xat=o("TFFlaubertForSequenceClassification"),$at=o(" (FlauBERT model)"),kat=l(),KA=a("li"),fxe=a("strong"),Sat=o("funnel"),Rat=o(" \u2014 "),Hne=a("a"),Pat=o("TFFunnelForSequenceClassification"),Bat=o(" (Funnel Transformer model)"),Iat=l(),e6=a("li"),gxe=a("strong"),Nat=o("gpt2"),qat=o(" \u2014 "),Jne=a("a"),jat=o("TFGPT2ForSequenceClassification"),Dat=o(" (OpenAI GPT-2 model)"),Gat=l(),o6=a("li"),hxe=a("strong"),Oat=o("gptj"),Vat=o(" \u2014 "),Yne=a("a"),Xat=o("TFGPTJForSequenceClassification"),zat=o(" (GPT-J model)"),Qat=l(),r6=a("li"),uxe=a("strong"),Wat=o("layoutlm"),Uat=o(" \u2014 "),Zne=a("a"),Hat=o("TFLayoutLMForSequenceClassification"),Jat=o(" (LayoutLM model)"),Yat=l(),t6=a("li"),pxe=a("strong"),Zat=o("layoutlmv3"),Kat=o(" \u2014 "),Kne=a("a"),ent=o("TFLayoutLMv3ForSequenceClassification"),ont=o(" (LayoutLMv3 model)"),rnt=l(),a6=a("li"),_xe=a("strong"),tnt=o("longformer"),ant=o(" \u2014 "),ese=a("a"),nnt=o("TFLongformerForSequenceClassification"),snt=o(" (Longformer model)"),lnt=l(),n6=a("li"),bxe=a("strong"),int=o("mobilebert"),dnt=o(" \u2014 "),ose=a("a"),mnt=o("TFMobileBertForSequenceClassification"),cnt=o(" (MobileBERT model)"),fnt=l(),s6=a("li"),vxe=a("strong"),gnt=o("mpnet"),hnt=o(" \u2014 "),rse=a("a"),unt=o("TFMPNetForSequenceClassification"),pnt=o(" (MPNet model)"),_nt=l(),l6=a("li"),Fxe=a("strong"),bnt=o("openai-gpt"),vnt=o(" \u2014 "),tse=a("a"),Fnt=o("TFOpenAIGPTForSequenceClassification"),Tnt=o(" (OpenAI GPT model)"),Mnt=l(),i6=a("li"),Txe=a("strong"),Ent=o("rembert"),Cnt=o(" \u2014 "),ase=a("a"),wnt=o("TFRemBertForSequenceClassification"),Ant=o(" (RemBERT model)"),Lnt=l(),d6=a("li"),Mxe=a("strong"),ynt=o("roberta"),xnt=o(" \u2014 "),nse=a("a"),$nt=o("TFRobertaForSequenceClassification"),knt=o(" (RoBERTa model)"),Snt=l(),m6=a("li"),Exe=a("strong"),Rnt=o("roformer"),Pnt=o(" \u2014 "),sse=a("a"),Bnt=o("TFRoFormerForSequenceClassification"),Int=o(" (RoFormer model)"),Nnt=l(),c6=a("li"),Cxe=a("strong"),qnt=o("tapas"),jnt=o(" \u2014 "),lse=a("a"),Dnt=o("TFTapasForSequenceClassification"),Gnt=o(" (TAPAS model)"),Ont=l(),f6=a("li"),wxe=a("strong"),Vnt=o("transfo-xl"),Xnt=o(" \u2014 "),ise=a("a"),znt=o("TFTransfoXLForSequenceClassification"),Qnt=o(" (Transformer-XL model)"),Wnt=l(),g6=a("li"),Axe=a("strong"),Unt=o("xlm"),Hnt=o(" \u2014 "),dse=a("a"),Jnt=o("TFXLMForSequenceClassification"),Ynt=o(" (XLM model)"),Znt=l(),h6=a("li"),Lxe=a("strong"),Knt=o("xlm-roberta"),est=o(" \u2014 "),mse=a("a"),ost=o("TFXLMRobertaForSequenceClassification"),rst=o(" (XLM-RoBERTa model)"),tst=l(),u6=a("li"),yxe=a("strong"),ast=o("xlnet"),nst=o(" \u2014 "),cse=a("a"),sst=o("TFXLNetForSequenceClassification"),lst=o(" (XLNet model)"),ist=l(),F(p6.$$.fragment),nso=l(),Ic=a("h2"),_6=a("a"),xxe=a("span"),F(hP.$$.fragment),dst=l(),$xe=a("span"),mst=o("TFAutoModelForMultipleChoice"),sso=l(),br=a("div"),F(uP.$$.fragment),cst=l(),Nc=a("p"),fst=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),fse=a("a"),gst=o("from_pretrained()"),hst=o(" class method or the "),gse=a("a"),ust=o("from_config()"),pst=o(` class
method.`),_st=l(),pP=a("p"),bst=o("This class cannot be instantiated directly using "),kxe=a("code"),vst=o("__init__()"),Fst=o(" (throws an error)."),Tst=l(),na=a("div"),F(_P.$$.fragment),Mst=l(),Sxe=a("p"),Est=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Cst=l(),qc=a("p"),wst=o(`Note:
Loading a model from its configuration file does `),Rxe=a("strong"),Ast=o("not"),Lst=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hse=a("a"),yst=o("from_pretrained()"),xst=o(" to load the model weights."),$st=l(),F(b6.$$.fragment),kst=l(),Ur=a("div"),F(bP.$$.fragment),Sst=l(),Pxe=a("p"),Rst=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Pst=l(),Vn=a("p"),Bst=o("The model class to instantiate is selected based on the "),Bxe=a("code"),Ist=o("model_type"),Nst=o(` property of the config object (either
passed as an argument or loaded from `),Ixe=a("code"),qst=o("pretrained_model_name_or_path"),jst=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nxe=a("code"),Dst=o("pretrained_model_name_or_path"),Gst=o(":"),Ost=l(),ve=a("ul"),v6=a("li"),qxe=a("strong"),Vst=o("albert"),Xst=o(" \u2014 "),use=a("a"),zst=o("TFAlbertForMultipleChoice"),Qst=o(" (ALBERT model)"),Wst=l(),F6=a("li"),jxe=a("strong"),Ust=o("bert"),Hst=o(" \u2014 "),pse=a("a"),Jst=o("TFBertForMultipleChoice"),Yst=o(" (BERT model)"),Zst=l(),T6=a("li"),Dxe=a("strong"),Kst=o("camembert"),elt=o(" \u2014 "),_se=a("a"),olt=o("TFCamembertForMultipleChoice"),rlt=o(" (CamemBERT model)"),tlt=l(),M6=a("li"),Gxe=a("strong"),alt=o("convbert"),nlt=o(" \u2014 "),bse=a("a"),slt=o("TFConvBertForMultipleChoice"),llt=o(" (ConvBERT model)"),ilt=l(),E6=a("li"),Oxe=a("strong"),dlt=o("distilbert"),mlt=o(" \u2014 "),vse=a("a"),clt=o("TFDistilBertForMultipleChoice"),flt=o(" (DistilBERT model)"),glt=l(),C6=a("li"),Vxe=a("strong"),hlt=o("electra"),ult=o(" \u2014 "),Fse=a("a"),plt=o("TFElectraForMultipleChoice"),_lt=o(" (ELECTRA model)"),blt=l(),w6=a("li"),Xxe=a("strong"),vlt=o("flaubert"),Flt=o(" \u2014 "),Tse=a("a"),Tlt=o("TFFlaubertForMultipleChoice"),Mlt=o(" (FlauBERT model)"),Elt=l(),A6=a("li"),zxe=a("strong"),Clt=o("funnel"),wlt=o(" \u2014 "),Mse=a("a"),Alt=o("TFFunnelForMultipleChoice"),Llt=o(" (Funnel Transformer model)"),ylt=l(),L6=a("li"),Qxe=a("strong"),xlt=o("longformer"),$lt=o(" \u2014 "),Ese=a("a"),klt=o("TFLongformerForMultipleChoice"),Slt=o(" (Longformer model)"),Rlt=l(),y6=a("li"),Wxe=a("strong"),Plt=o("mobilebert"),Blt=o(" \u2014 "),Cse=a("a"),Ilt=o("TFMobileBertForMultipleChoice"),Nlt=o(" (MobileBERT model)"),qlt=l(),x6=a("li"),Uxe=a("strong"),jlt=o("mpnet"),Dlt=o(" \u2014 "),wse=a("a"),Glt=o("TFMPNetForMultipleChoice"),Olt=o(" (MPNet model)"),Vlt=l(),$6=a("li"),Hxe=a("strong"),Xlt=o("rembert"),zlt=o(" \u2014 "),Ase=a("a"),Qlt=o("TFRemBertForMultipleChoice"),Wlt=o(" (RemBERT model)"),Ult=l(),k6=a("li"),Jxe=a("strong"),Hlt=o("roberta"),Jlt=o(" \u2014 "),Lse=a("a"),Ylt=o("TFRobertaForMultipleChoice"),Zlt=o(" (RoBERTa model)"),Klt=l(),S6=a("li"),Yxe=a("strong"),eit=o("roformer"),oit=o(" \u2014 "),yse=a("a"),rit=o("TFRoFormerForMultipleChoice"),tit=o(" (RoFormer model)"),ait=l(),R6=a("li"),Zxe=a("strong"),nit=o("xlm"),sit=o(" \u2014 "),xse=a("a"),lit=o("TFXLMForMultipleChoice"),iit=o(" (XLM model)"),dit=l(),P6=a("li"),Kxe=a("strong"),mit=o("xlm-roberta"),cit=o(" \u2014 "),$se=a("a"),fit=o("TFXLMRobertaForMultipleChoice"),git=o(" (XLM-RoBERTa model)"),hit=l(),B6=a("li"),e$e=a("strong"),uit=o("xlnet"),pit=o(" \u2014 "),kse=a("a"),_it=o("TFXLNetForMultipleChoice"),bit=o(" (XLNet model)"),vit=l(),F(I6.$$.fragment),lso=l(),jc=a("h2"),N6=a("a"),o$e=a("span"),F(vP.$$.fragment),Fit=l(),r$e=a("span"),Tit=o("TFAutoModelForNextSentencePrediction"),iso=l(),vr=a("div"),F(FP.$$.fragment),Mit=l(),Dc=a("p"),Eit=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Sse=a("a"),Cit=o("from_pretrained()"),wit=o(" class method or the "),Rse=a("a"),Ait=o("from_config()"),Lit=o(` class
method.`),yit=l(),TP=a("p"),xit=o("This class cannot be instantiated directly using "),t$e=a("code"),$it=o("__init__()"),kit=o(" (throws an error)."),Sit=l(),sa=a("div"),F(MP.$$.fragment),Rit=l(),a$e=a("p"),Pit=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Bit=l(),Gc=a("p"),Iit=o(`Note:
Loading a model from its configuration file does `),n$e=a("strong"),Nit=o("not"),qit=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Pse=a("a"),jit=o("from_pretrained()"),Dit=o(" to load the model weights."),Git=l(),F(q6.$$.fragment),Oit=l(),Hr=a("div"),F(EP.$$.fragment),Vit=l(),s$e=a("p"),Xit=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),zit=l(),Xn=a("p"),Qit=o("The model class to instantiate is selected based on the "),l$e=a("code"),Wit=o("model_type"),Uit=o(` property of the config object (either
passed as an argument or loaded from `),i$e=a("code"),Hit=o("pretrained_model_name_or_path"),Jit=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d$e=a("code"),Yit=o("pretrained_model_name_or_path"),Zit=o(":"),Kit=l(),CP=a("ul"),j6=a("li"),m$e=a("strong"),edt=o("bert"),odt=o(" \u2014 "),Bse=a("a"),rdt=o("TFBertForNextSentencePrediction"),tdt=o(" (BERT model)"),adt=l(),D6=a("li"),c$e=a("strong"),ndt=o("mobilebert"),sdt=o(" \u2014 "),Ise=a("a"),ldt=o("TFMobileBertForNextSentencePrediction"),idt=o(" (MobileBERT model)"),ddt=l(),F(G6.$$.fragment),dso=l(),Oc=a("h2"),O6=a("a"),f$e=a("span"),F(wP.$$.fragment),mdt=l(),g$e=a("span"),cdt=o("TFAutoModelForTableQuestionAnswering"),mso=l(),Fr=a("div"),F(AP.$$.fragment),fdt=l(),Vc=a("p"),gdt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),Nse=a("a"),hdt=o("from_pretrained()"),udt=o(" class method or the "),qse=a("a"),pdt=o("from_config()"),_dt=o(` class
method.`),bdt=l(),LP=a("p"),vdt=o("This class cannot be instantiated directly using "),h$e=a("code"),Fdt=o("__init__()"),Tdt=o(" (throws an error)."),Mdt=l(),la=a("div"),F(yP.$$.fragment),Edt=l(),u$e=a("p"),Cdt=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),wdt=l(),Xc=a("p"),Adt=o(`Note:
Loading a model from its configuration file does `),p$e=a("strong"),Ldt=o("not"),ydt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jse=a("a"),xdt=o("from_pretrained()"),$dt=o(" to load the model weights."),kdt=l(),F(V6.$$.fragment),Sdt=l(),Jr=a("div"),F(xP.$$.fragment),Rdt=l(),_$e=a("p"),Pdt=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Bdt=l(),zn=a("p"),Idt=o("The model class to instantiate is selected based on the "),b$e=a("code"),Ndt=o("model_type"),qdt=o(` property of the config object (either
passed as an argument or loaded from `),v$e=a("code"),jdt=o("pretrained_model_name_or_path"),Ddt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F$e=a("code"),Gdt=o("pretrained_model_name_or_path"),Odt=o(":"),Vdt=l(),T$e=a("ul"),X6=a("li"),M$e=a("strong"),Xdt=o("tapas"),zdt=o(" \u2014 "),Dse=a("a"),Qdt=o("TFTapasForQuestionAnswering"),Wdt=o(" (TAPAS model)"),Udt=l(),F(z6.$$.fragment),cso=l(),zc=a("h2"),Q6=a("a"),E$e=a("span"),F($P.$$.fragment),Hdt=l(),C$e=a("span"),Jdt=o("TFAutoModelForDocumentQuestionAnswering"),fso=l(),Tr=a("div"),F(kP.$$.fragment),Ydt=l(),Qc=a("p"),Zdt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),Gse=a("a"),Kdt=o("from_pretrained()"),emt=o(" class method or the "),Ose=a("a"),omt=o("from_config()"),rmt=o(` class
method.`),tmt=l(),SP=a("p"),amt=o("This class cannot be instantiated directly using "),w$e=a("code"),nmt=o("__init__()"),smt=o(" (throws an error)."),lmt=l(),ia=a("div"),F(RP.$$.fragment),imt=l(),A$e=a("p"),dmt=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),mmt=l(),Wc=a("p"),cmt=o(`Note:
Loading a model from its configuration file does `),L$e=a("strong"),fmt=o("not"),gmt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Vse=a("a"),hmt=o("from_pretrained()"),umt=o(" to load the model weights."),pmt=l(),F(W6.$$.fragment),_mt=l(),Yr=a("div"),F(PP.$$.fragment),bmt=l(),y$e=a("p"),vmt=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),Fmt=l(),Qn=a("p"),Tmt=o("The model class to instantiate is selected based on the "),x$e=a("code"),Mmt=o("model_type"),Emt=o(` property of the config object (either
passed as an argument or loaded from `),$$e=a("code"),Cmt=o("pretrained_model_name_or_path"),wmt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k$e=a("code"),Amt=o("pretrained_model_name_or_path"),Lmt=o(":"),ymt=l(),S$e=a("ul"),U6=a("li"),R$e=a("strong"),xmt=o("layoutlm"),$mt=o(" \u2014 "),Xse=a("a"),kmt=o("TFLayoutLMForQuestionAnswering"),Smt=o(" (LayoutLM model)"),Rmt=l(),F(H6.$$.fragment),gso=l(),Uc=a("h2"),J6=a("a"),P$e=a("span"),F(BP.$$.fragment),Pmt=l(),B$e=a("span"),Bmt=o("TFAutoModelForTokenClassification"),hso=l(),Mr=a("div"),F(IP.$$.fragment),Imt=l(),Hc=a("p"),Nmt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),zse=a("a"),qmt=o("from_pretrained()"),jmt=o(" class method or the "),Qse=a("a"),Dmt=o("from_config()"),Gmt=o(` class
method.`),Omt=l(),NP=a("p"),Vmt=o("This class cannot be instantiated directly using "),I$e=a("code"),Xmt=o("__init__()"),zmt=o(" (throws an error)."),Qmt=l(),da=a("div"),F(qP.$$.fragment),Wmt=l(),N$e=a("p"),Umt=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Hmt=l(),Jc=a("p"),Jmt=o(`Note:
Loading a model from its configuration file does `),q$e=a("strong"),Ymt=o("not"),Zmt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Wse=a("a"),Kmt=o("from_pretrained()"),ect=o(" to load the model weights."),oct=l(),F(Y6.$$.fragment),rct=l(),Zr=a("div"),F(jP.$$.fragment),tct=l(),j$e=a("p"),act=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),nct=l(),Wn=a("p"),sct=o("The model class to instantiate is selected based on the "),D$e=a("code"),lct=o("model_type"),ict=o(` property of the config object (either
passed as an argument or loaded from `),G$e=a("code"),dct=o("pretrained_model_name_or_path"),mct=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O$e=a("code"),cct=o("pretrained_model_name_or_path"),fct=o(":"),gct=l(),ie=a("ul"),Z6=a("li"),V$e=a("strong"),hct=o("albert"),uct=o(" \u2014 "),Use=a("a"),pct=o("TFAlbertForTokenClassification"),_ct=o(" (ALBERT model)"),bct=l(),K6=a("li"),X$e=a("strong"),vct=o("bert"),Fct=o(" \u2014 "),Hse=a("a"),Tct=o("TFBertForTokenClassification"),Mct=o(" (BERT model)"),Ect=l(),e7=a("li"),z$e=a("strong"),Cct=o("camembert"),wct=o(" \u2014 "),Jse=a("a"),Act=o("TFCamembertForTokenClassification"),Lct=o(" (CamemBERT model)"),yct=l(),o7=a("li"),Q$e=a("strong"),xct=o("convbert"),$ct=o(" \u2014 "),Yse=a("a"),kct=o("TFConvBertForTokenClassification"),Sct=o(" (ConvBERT model)"),Rct=l(),r7=a("li"),W$e=a("strong"),Pct=o("deberta"),Bct=o(" \u2014 "),Zse=a("a"),Ict=o("TFDebertaForTokenClassification"),Nct=o(" (DeBERTa model)"),qct=l(),t7=a("li"),U$e=a("strong"),jct=o("deberta-v2"),Dct=o(" \u2014 "),Kse=a("a"),Gct=o("TFDebertaV2ForTokenClassification"),Oct=o(" (DeBERTa-v2 model)"),Vct=l(),a7=a("li"),H$e=a("strong"),Xct=o("distilbert"),zct=o(" \u2014 "),ele=a("a"),Qct=o("TFDistilBertForTokenClassification"),Wct=o(" (DistilBERT model)"),Uct=l(),n7=a("li"),J$e=a("strong"),Hct=o("electra"),Jct=o(" \u2014 "),ole=a("a"),Yct=o("TFElectraForTokenClassification"),Zct=o(" (ELECTRA model)"),Kct=l(),s7=a("li"),Y$e=a("strong"),eft=o("esm"),oft=o(" \u2014 "),rle=a("a"),rft=o("TFEsmForTokenClassification"),tft=o(" (ESM model)"),aft=l(),l7=a("li"),Z$e=a("strong"),nft=o("flaubert"),sft=o(" \u2014 "),tle=a("a"),lft=o("TFFlaubertForTokenClassification"),ift=o(" (FlauBERT model)"),dft=l(),i7=a("li"),K$e=a("strong"),mft=o("funnel"),cft=o(" \u2014 "),ale=a("a"),fft=o("TFFunnelForTokenClassification"),gft=o(" (Funnel Transformer model)"),hft=l(),d7=a("li"),eke=a("strong"),uft=o("layoutlm"),pft=o(" \u2014 "),nle=a("a"),_ft=o("TFLayoutLMForTokenClassification"),bft=o(" (LayoutLM model)"),vft=l(),m7=a("li"),oke=a("strong"),Fft=o("layoutlmv3"),Tft=o(" \u2014 "),sle=a("a"),Mft=o("TFLayoutLMv3ForTokenClassification"),Eft=o(" (LayoutLMv3 model)"),Cft=l(),c7=a("li"),rke=a("strong"),wft=o("longformer"),Aft=o(" \u2014 "),lle=a("a"),Lft=o("TFLongformerForTokenClassification"),yft=o(" (Longformer model)"),xft=l(),f7=a("li"),tke=a("strong"),$ft=o("mobilebert"),kft=o(" \u2014 "),ile=a("a"),Sft=o("TFMobileBertForTokenClassification"),Rft=o(" (MobileBERT model)"),Pft=l(),g7=a("li"),ake=a("strong"),Bft=o("mpnet"),Ift=o(" \u2014 "),dle=a("a"),Nft=o("TFMPNetForTokenClassification"),qft=o(" (MPNet model)"),jft=l(),h7=a("li"),nke=a("strong"),Dft=o("rembert"),Gft=o(" \u2014 "),mle=a("a"),Oft=o("TFRemBertForTokenClassification"),Vft=o(" (RemBERT model)"),Xft=l(),u7=a("li"),ske=a("strong"),zft=o("roberta"),Qft=o(" \u2014 "),cle=a("a"),Wft=o("TFRobertaForTokenClassification"),Uft=o(" (RoBERTa model)"),Hft=l(),p7=a("li"),lke=a("strong"),Jft=o("roformer"),Yft=o(" \u2014 "),fle=a("a"),Zft=o("TFRoFormerForTokenClassification"),Kft=o(" (RoFormer model)"),egt=l(),_7=a("li"),ike=a("strong"),ogt=o("xlm"),rgt=o(" \u2014 "),gle=a("a"),tgt=o("TFXLMForTokenClassification"),agt=o(" (XLM model)"),ngt=l(),b7=a("li"),dke=a("strong"),sgt=o("xlm-roberta"),lgt=o(" \u2014 "),hle=a("a"),igt=o("TFXLMRobertaForTokenClassification"),dgt=o(" (XLM-RoBERTa model)"),mgt=l(),v7=a("li"),mke=a("strong"),cgt=o("xlnet"),fgt=o(" \u2014 "),ule=a("a"),ggt=o("TFXLNetForTokenClassification"),hgt=o(" (XLNet model)"),ugt=l(),F(F7.$$.fragment),uso=l(),Yc=a("h2"),T7=a("a"),cke=a("span"),F(DP.$$.fragment),pgt=l(),fke=a("span"),_gt=o("TFAutoModelForQuestionAnswering"),pso=l(),Er=a("div"),F(GP.$$.fragment),bgt=l(),Zc=a("p"),vgt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),ple=a("a"),Fgt=o("from_pretrained()"),Tgt=o(" class method or the "),_le=a("a"),Mgt=o("from_config()"),Egt=o(` class
method.`),Cgt=l(),OP=a("p"),wgt=o("This class cannot be instantiated directly using "),gke=a("code"),Agt=o("__init__()"),Lgt=o(" (throws an error)."),ygt=l(),ma=a("div"),F(VP.$$.fragment),xgt=l(),hke=a("p"),$gt=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),kgt=l(),Kc=a("p"),Sgt=o(`Note:
Loading a model from its configuration file does `),uke=a("strong"),Rgt=o("not"),Pgt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ble=a("a"),Bgt=o("from_pretrained()"),Igt=o(" to load the model weights."),Ngt=l(),F(M7.$$.fragment),qgt=l(),Kr=a("div"),F(XP.$$.fragment),jgt=l(),pke=a("p"),Dgt=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Ggt=l(),Un=a("p"),Ogt=o("The model class to instantiate is selected based on the "),_ke=a("code"),Vgt=o("model_type"),Xgt=o(` property of the config object (either
passed as an argument or loaded from `),bke=a("code"),zgt=o("pretrained_model_name_or_path"),Qgt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vke=a("code"),Wgt=o("pretrained_model_name_or_path"),Ugt=o(":"),Hgt=l(),fe=a("ul"),E7=a("li"),Fke=a("strong"),Jgt=o("albert"),Ygt=o(" \u2014 "),vle=a("a"),Zgt=o("TFAlbertForQuestionAnswering"),Kgt=o(" (ALBERT model)"),eht=l(),C7=a("li"),Tke=a("strong"),oht=o("bert"),rht=o(" \u2014 "),Fle=a("a"),tht=o("TFBertForQuestionAnswering"),aht=o(" (BERT model)"),nht=l(),w7=a("li"),Mke=a("strong"),sht=o("camembert"),lht=o(" \u2014 "),Tle=a("a"),iht=o("TFCamembertForQuestionAnswering"),dht=o(" (CamemBERT model)"),mht=l(),A7=a("li"),Eke=a("strong"),cht=o("convbert"),fht=o(" \u2014 "),Mle=a("a"),ght=o("TFConvBertForQuestionAnswering"),hht=o(" (ConvBERT model)"),uht=l(),L7=a("li"),Cke=a("strong"),pht=o("deberta"),_ht=o(" \u2014 "),Ele=a("a"),bht=o("TFDebertaForQuestionAnswering"),vht=o(" (DeBERTa model)"),Fht=l(),y7=a("li"),wke=a("strong"),Tht=o("deberta-v2"),Mht=o(" \u2014 "),Cle=a("a"),Eht=o("TFDebertaV2ForQuestionAnswering"),Cht=o(" (DeBERTa-v2 model)"),wht=l(),x7=a("li"),Ake=a("strong"),Aht=o("distilbert"),Lht=o(" \u2014 "),wle=a("a"),yht=o("TFDistilBertForQuestionAnswering"),xht=o(" (DistilBERT model)"),$ht=l(),$7=a("li"),Lke=a("strong"),kht=o("electra"),Sht=o(" \u2014 "),Ale=a("a"),Rht=o("TFElectraForQuestionAnswering"),Pht=o(" (ELECTRA model)"),Bht=l(),k7=a("li"),yke=a("strong"),Iht=o("flaubert"),Nht=o(" \u2014 "),Lle=a("a"),qht=o("TFFlaubertForQuestionAnsweringSimple"),jht=o(" (FlauBERT model)"),Dht=l(),S7=a("li"),xke=a("strong"),Ght=o("funnel"),Oht=o(" \u2014 "),yle=a("a"),Vht=o("TFFunnelForQuestionAnswering"),Xht=o(" (Funnel Transformer model)"),zht=l(),R7=a("li"),$ke=a("strong"),Qht=o("gptj"),Wht=o(" \u2014 "),xle=a("a"),Uht=o("TFGPTJForQuestionAnswering"),Hht=o(" (GPT-J model)"),Jht=l(),P7=a("li"),kke=a("strong"),Yht=o("layoutlmv3"),Zht=o(" \u2014 "),$le=a("a"),Kht=o("TFLayoutLMv3ForQuestionAnswering"),eut=o(" (LayoutLMv3 model)"),out=l(),B7=a("li"),Ske=a("strong"),rut=o("longformer"),tut=o(" \u2014 "),kle=a("a"),aut=o("TFLongformerForQuestionAnswering"),nut=o(" (Longformer model)"),sut=l(),I7=a("li"),Rke=a("strong"),lut=o("mobilebert"),iut=o(" \u2014 "),Sle=a("a"),dut=o("TFMobileBertForQuestionAnswering"),mut=o(" (MobileBERT model)"),cut=l(),N7=a("li"),Pke=a("strong"),fut=o("mpnet"),gut=o(" \u2014 "),Rle=a("a"),hut=o("TFMPNetForQuestionAnswering"),uut=o(" (MPNet model)"),put=l(),q7=a("li"),Bke=a("strong"),_ut=o("rembert"),but=o(" \u2014 "),Ple=a("a"),vut=o("TFRemBertForQuestionAnswering"),Fut=o(" (RemBERT model)"),Tut=l(),j7=a("li"),Ike=a("strong"),Mut=o("roberta"),Eut=o(" \u2014 "),Ble=a("a"),Cut=o("TFRobertaForQuestionAnswering"),wut=o(" (RoBERTa model)"),Aut=l(),D7=a("li"),Nke=a("strong"),Lut=o("roformer"),yut=o(" \u2014 "),Ile=a("a"),xut=o("TFRoFormerForQuestionAnswering"),$ut=o(" (RoFormer model)"),kut=l(),G7=a("li"),qke=a("strong"),Sut=o("xlm"),Rut=o(" \u2014 "),Nle=a("a"),Put=o("TFXLMForQuestionAnsweringSimple"),But=o(" (XLM model)"),Iut=l(),O7=a("li"),jke=a("strong"),Nut=o("xlm-roberta"),qut=o(" \u2014 "),qle=a("a"),jut=o("TFXLMRobertaForQuestionAnswering"),Dut=o(" (XLM-RoBERTa model)"),Gut=l(),V7=a("li"),Dke=a("strong"),Out=o("xlnet"),Vut=o(" \u2014 "),jle=a("a"),Xut=o("TFXLNetForQuestionAnsweringSimple"),zut=o(" (XLNet model)"),Qut=l(),F(X7.$$.fragment),_so=l(),ef=a("h2"),z7=a("a"),Gke=a("span"),F(zP.$$.fragment),Wut=l(),Oke=a("span"),Uut=o("TFAutoModelForVision2Seq"),bso=l(),Cr=a("div"),F(QP.$$.fragment),Hut=l(),of=a("p"),Jut=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Dle=a("a"),Yut=o("from_pretrained()"),Zut=o(" class method or the "),Gle=a("a"),Kut=o("from_config()"),ept=o(` class
method.`),opt=l(),WP=a("p"),rpt=o("This class cannot be instantiated directly using "),Vke=a("code"),tpt=o("__init__()"),apt=o(" (throws an error)."),npt=l(),ca=a("div"),F(UP.$$.fragment),spt=l(),Xke=a("p"),lpt=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),ipt=l(),rf=a("p"),dpt=o(`Note:
Loading a model from its configuration file does `),zke=a("strong"),mpt=o("not"),cpt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ole=a("a"),fpt=o("from_pretrained()"),gpt=o(" to load the model weights."),hpt=l(),F(Q7.$$.fragment),upt=l(),et=a("div"),F(HP.$$.fragment),ppt=l(),Qke=a("p"),_pt=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),bpt=l(),Hn=a("p"),vpt=o("The model class to instantiate is selected based on the "),Wke=a("code"),Fpt=o("model_type"),Tpt=o(` property of the config object (either
passed as an argument or loaded from `),Uke=a("code"),Mpt=o("pretrained_model_name_or_path"),Ept=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Hke=a("code"),Cpt=o("pretrained_model_name_or_path"),wpt=o(":"),Apt=l(),Jke=a("ul"),W7=a("li"),Yke=a("strong"),Lpt=o("vision-encoder-decoder"),ypt=o(" \u2014 "),Vle=a("a"),xpt=o("TFVisionEncoderDecoderModel"),$pt=o(" (Vision Encoder decoder model)"),kpt=l(),F(U7.$$.fragment),vso=l(),tf=a("h2"),H7=a("a"),Zke=a("span"),F(JP.$$.fragment),Spt=l(),Kke=a("span"),Rpt=o("TFAutoModelForSpeechSeq2Seq"),Fso=l(),wr=a("div"),F(YP.$$.fragment),Ppt=l(),af=a("p"),Bpt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),Xle=a("a"),Ipt=o("from_pretrained()"),Npt=o(" class method or the "),zle=a("a"),qpt=o("from_config()"),jpt=o(` class
method.`),Dpt=l(),ZP=a("p"),Gpt=o("This class cannot be instantiated directly using "),eSe=a("code"),Opt=o("__init__()"),Vpt=o(" (throws an error)."),Xpt=l(),fa=a("div"),F(KP.$$.fragment),zpt=l(),oSe=a("p"),Qpt=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Wpt=l(),nf=a("p"),Upt=o(`Note:
Loading a model from its configuration file does `),rSe=a("strong"),Hpt=o("not"),Jpt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Qle=a("a"),Ypt=o("from_pretrained()"),Zpt=o(" to load the model weights."),Kpt=l(),F(J7.$$.fragment),e_t=l(),ot=a("div"),F(eB.$$.fragment),o_t=l(),tSe=a("p"),r_t=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),t_t=l(),Jn=a("p"),a_t=o("The model class to instantiate is selected based on the "),aSe=a("code"),n_t=o("model_type"),s_t=o(` property of the config object (either
passed as an argument or loaded from `),nSe=a("code"),l_t=o("pretrained_model_name_or_path"),i_t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sSe=a("code"),d_t=o("pretrained_model_name_or_path"),m_t=o(":"),c_t=l(),oB=a("ul"),Y7=a("li"),lSe=a("strong"),f_t=o("speech_to_text"),g_t=o(" \u2014 "),Wle=a("a"),h_t=o("TFSpeech2TextForConditionalGeneration"),u_t=o(" (Speech2Text model)"),p_t=l(),Z7=a("li"),iSe=a("strong"),__t=o("whisper"),b_t=o(" \u2014 "),Ule=a("a"),v_t=o("TFWhisperForConditionalGeneration"),F_t=o(" (Whisper model)"),T_t=l(),F(K7.$$.fragment),Tso=l(),sf=a("h2"),e8=a("a"),dSe=a("span"),F(rB.$$.fragment),M_t=l(),mSe=a("span"),E_t=o("FlaxAutoModel"),Mso=l(),Ar=a("div"),F(tB.$$.fragment),C_t=l(),lf=a("p"),w_t=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Hle=a("a"),A_t=o("from_pretrained()"),L_t=o(" class method or the "),Jle=a("a"),y_t=o("from_config()"),x_t=o(` class
method.`),$_t=l(),aB=a("p"),k_t=o("This class cannot be instantiated directly using "),cSe=a("code"),S_t=o("__init__()"),R_t=o(" (throws an error)."),P_t=l(),ga=a("div"),F(nB.$$.fragment),B_t=l(),fSe=a("p"),I_t=o("Instantiates one of the base model classes of the library from a configuration."),N_t=l(),df=a("p"),q_t=o(`Note:
Loading a model from its configuration file does `),gSe=a("strong"),j_t=o("not"),D_t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Yle=a("a"),G_t=o("from_pretrained()"),O_t=o(" to load the model weights."),V_t=l(),F(o8.$$.fragment),X_t=l(),rt=a("div"),F(sB.$$.fragment),z_t=l(),hSe=a("p"),Q_t=o("Instantiate one of the base model classes of the library from a pretrained model."),W_t=l(),Yn=a("p"),U_t=o("The model class to instantiate is selected based on the "),uSe=a("code"),H_t=o("model_type"),J_t=o(` property of the config object (either
passed as an argument or loaded from `),pSe=a("code"),Y_t=o("pretrained_model_name_or_path"),Z_t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_Se=a("code"),K_t=o("pretrained_model_name_or_path"),e1t=o(":"),o1t=l(),te=a("ul"),r8=a("li"),bSe=a("strong"),r1t=o("albert"),t1t=o(" \u2014 "),Zle=a("a"),a1t=o("FlaxAlbertModel"),n1t=o(" (ALBERT model)"),s1t=l(),t8=a("li"),vSe=a("strong"),l1t=o("bart"),i1t=o(" \u2014 "),Kle=a("a"),d1t=o("FlaxBartModel"),m1t=o(" (BART model)"),c1t=l(),a8=a("li"),FSe=a("strong"),f1t=o("beit"),g1t=o(" \u2014 "),eie=a("a"),h1t=o("FlaxBeitModel"),u1t=o(" (BEiT model)"),p1t=l(),n8=a("li"),TSe=a("strong"),_1t=o("bert"),b1t=o(" \u2014 "),oie=a("a"),v1t=o("FlaxBertModel"),F1t=o(" (BERT model)"),T1t=l(),s8=a("li"),MSe=a("strong"),M1t=o("big_bird"),E1t=o(" \u2014 "),rie=a("a"),C1t=o("FlaxBigBirdModel"),w1t=o(" (BigBird model)"),A1t=l(),l8=a("li"),ESe=a("strong"),L1t=o("blenderbot"),y1t=o(" \u2014 "),tie=a("a"),x1t=o("FlaxBlenderbotModel"),$1t=o(" (Blenderbot model)"),k1t=l(),i8=a("li"),CSe=a("strong"),S1t=o("blenderbot-small"),R1t=o(" \u2014 "),aie=a("a"),P1t=o("FlaxBlenderbotSmallModel"),B1t=o(" (BlenderbotSmall model)"),I1t=l(),d8=a("li"),wSe=a("strong"),N1t=o("clip"),q1t=o(" \u2014 "),nie=a("a"),j1t=o("FlaxCLIPModel"),D1t=o(" (CLIP model)"),G1t=l(),m8=a("li"),ASe=a("strong"),O1t=o("distilbert"),V1t=o(" \u2014 "),sie=a("a"),X1t=o("FlaxDistilBertModel"),z1t=o(" (DistilBERT model)"),Q1t=l(),c8=a("li"),LSe=a("strong"),W1t=o("electra"),U1t=o(" \u2014 "),lie=a("a"),H1t=o("FlaxElectraModel"),J1t=o(" (ELECTRA model)"),Y1t=l(),f8=a("li"),ySe=a("strong"),Z1t=o("gpt2"),K1t=o(" \u2014 "),iie=a("a"),e2t=o("FlaxGPT2Model"),o2t=o(" (OpenAI GPT-2 model)"),r2t=l(),g8=a("li"),xSe=a("strong"),t2t=o("gpt_neo"),a2t=o(" \u2014 "),die=a("a"),n2t=o("FlaxGPTNeoModel"),s2t=o(" (GPT Neo model)"),l2t=l(),h8=a("li"),$Se=a("strong"),i2t=o("gptj"),d2t=o(" \u2014 "),mie=a("a"),m2t=o("FlaxGPTJModel"),c2t=o(" (GPT-J model)"),f2t=l(),u8=a("li"),kSe=a("strong"),g2t=o("longt5"),h2t=o(" \u2014 "),cie=a("a"),u2t=o("FlaxLongT5Model"),p2t=o(" (LongT5 model)"),_2t=l(),p8=a("li"),SSe=a("strong"),b2t=o("marian"),v2t=o(" \u2014 "),fie=a("a"),F2t=o("FlaxMarianModel"),T2t=o(" (Marian model)"),M2t=l(),_8=a("li"),RSe=a("strong"),E2t=o("mbart"),C2t=o(" \u2014 "),gie=a("a"),w2t=o("FlaxMBartModel"),A2t=o(" (mBART model)"),L2t=l(),b8=a("li"),PSe=a("strong"),y2t=o("mt5"),x2t=o(" \u2014 "),hie=a("a"),$2t=o("FlaxMT5Model"),k2t=o(" (MT5 model)"),S2t=l(),v8=a("li"),BSe=a("strong"),R2t=o("opt"),P2t=o(" \u2014 "),uie=a("a"),B2t=o("FlaxOPTModel"),I2t=o(" (OPT model)"),N2t=l(),F8=a("li"),ISe=a("strong"),q2t=o("pegasus"),j2t=o(" \u2014 "),pie=a("a"),D2t=o("FlaxPegasusModel"),G2t=o(" (Pegasus model)"),O2t=l(),T8=a("li"),NSe=a("strong"),V2t=o("roberta"),X2t=o(" \u2014 "),_ie=a("a"),z2t=o("FlaxRobertaModel"),Q2t=o(" (RoBERTa model)"),W2t=l(),M8=a("li"),qSe=a("strong"),U2t=o("roformer"),H2t=o(" \u2014 "),bie=a("a"),J2t=o("FlaxRoFormerModel"),Y2t=o(" (RoFormer model)"),Z2t=l(),E8=a("li"),jSe=a("strong"),K2t=o("t5"),ebt=o(" \u2014 "),vie=a("a"),obt=o("FlaxT5Model"),rbt=o(" (T5 model)"),tbt=l(),C8=a("li"),DSe=a("strong"),abt=o("vision-text-dual-encoder"),nbt=o(" \u2014 "),Fie=a("a"),sbt=o("FlaxVisionTextDualEncoderModel"),lbt=o(" (VisionTextDualEncoder model)"),ibt=l(),w8=a("li"),GSe=a("strong"),dbt=o("vit"),mbt=o(" \u2014 "),Tie=a("a"),cbt=o("FlaxViTModel"),fbt=o(" (ViT model)"),gbt=l(),A8=a("li"),OSe=a("strong"),hbt=o("wav2vec2"),ubt=o(" \u2014 "),Mie=a("a"),pbt=o("FlaxWav2Vec2Model"),_bt=o(" (Wav2Vec2 model)"),bbt=l(),L8=a("li"),VSe=a("strong"),vbt=o("xglm"),Fbt=o(" \u2014 "),Eie=a("a"),Tbt=o("FlaxXGLMModel"),Mbt=o(" (XGLM model)"),Ebt=l(),y8=a("li"),XSe=a("strong"),Cbt=o("xlm-roberta"),wbt=o(" \u2014 "),Cie=a("a"),Abt=o("FlaxXLMRobertaModel"),Lbt=o(" (XLM-RoBERTa model)"),ybt=l(),F(x8.$$.fragment),Eso=l(),mf=a("h2"),$8=a("a"),zSe=a("span"),F(lB.$$.fragment),xbt=l(),QSe=a("span"),$bt=o("FlaxAutoModelForCausalLM"),Cso=l(),Lr=a("div"),F(iB.$$.fragment),kbt=l(),cf=a("p"),Sbt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),wie=a("a"),Rbt=o("from_pretrained()"),Pbt=o(" class method or the "),Aie=a("a"),Bbt=o("from_config()"),Ibt=o(` class
method.`),Nbt=l(),dB=a("p"),qbt=o("This class cannot be instantiated directly using "),WSe=a("code"),jbt=o("__init__()"),Dbt=o(" (throws an error)."),Gbt=l(),ha=a("div"),F(mB.$$.fragment),Obt=l(),USe=a("p"),Vbt=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Xbt=l(),ff=a("p"),zbt=o(`Note:
Loading a model from its configuration file does `),HSe=a("strong"),Qbt=o("not"),Wbt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Lie=a("a"),Ubt=o("from_pretrained()"),Hbt=o(" to load the model weights."),Jbt=l(),F(k8.$$.fragment),Ybt=l(),tt=a("div"),F(cB.$$.fragment),Zbt=l(),JSe=a("p"),Kbt=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),evt=l(),Zn=a("p"),ovt=o("The model class to instantiate is selected based on the "),YSe=a("code"),rvt=o("model_type"),tvt=o(` property of the config object (either
passed as an argument or loaded from `),ZSe=a("code"),avt=o("pretrained_model_name_or_path"),nvt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KSe=a("code"),svt=o("pretrained_model_name_or_path"),lvt=o(":"),ivt=l(),$e=a("ul"),S8=a("li"),eRe=a("strong"),dvt=o("bart"),mvt=o(" \u2014 "),yie=a("a"),cvt=o("FlaxBartForCausalLM"),fvt=o(" (BART model)"),gvt=l(),R8=a("li"),oRe=a("strong"),hvt=o("bert"),uvt=o(" \u2014 "),xie=a("a"),pvt=o("FlaxBertForCausalLM"),_vt=o(" (BERT model)"),bvt=l(),P8=a("li"),rRe=a("strong"),vvt=o("big_bird"),Fvt=o(" \u2014 "),$ie=a("a"),Tvt=o("FlaxBigBirdForCausalLM"),Mvt=o(" (BigBird model)"),Evt=l(),B8=a("li"),tRe=a("strong"),Cvt=o("electra"),wvt=o(" \u2014 "),kie=a("a"),Avt=o("FlaxElectraForCausalLM"),Lvt=o(" (ELECTRA model)"),yvt=l(),I8=a("li"),aRe=a("strong"),xvt=o("gpt2"),$vt=o(" \u2014 "),Sie=a("a"),kvt=o("FlaxGPT2LMHeadModel"),Svt=o(" (OpenAI GPT-2 model)"),Rvt=l(),N8=a("li"),nRe=a("strong"),Pvt=o("gpt_neo"),Bvt=o(" \u2014 "),Rie=a("a"),Ivt=o("FlaxGPTNeoForCausalLM"),Nvt=o(" (GPT Neo model)"),qvt=l(),q8=a("li"),sRe=a("strong"),jvt=o("gptj"),Dvt=o(" \u2014 "),Pie=a("a"),Gvt=o("FlaxGPTJForCausalLM"),Ovt=o(" (GPT-J model)"),Vvt=l(),j8=a("li"),lRe=a("strong"),Xvt=o("opt"),zvt=o(" \u2014 "),Bie=a("a"),Qvt=o("FlaxOPTForCausalLM"),Wvt=o(" (OPT model)"),Uvt=l(),D8=a("li"),iRe=a("strong"),Hvt=o("roberta"),Jvt=o(" \u2014 "),Iie=a("a"),Yvt=o("FlaxRobertaForCausalLM"),Zvt=o(" (RoBERTa model)"),Kvt=l(),G8=a("li"),dRe=a("strong"),eFt=o("xglm"),oFt=o(" \u2014 "),Nie=a("a"),rFt=o("FlaxXGLMForCausalLM"),tFt=o(" (XGLM model)"),aFt=l(),F(O8.$$.fragment),wso=l(),gf=a("h2"),V8=a("a"),mRe=a("span"),F(fB.$$.fragment),nFt=l(),cRe=a("span"),sFt=o("FlaxAutoModelForPreTraining"),Aso=l(),yr=a("div"),F(gB.$$.fragment),lFt=l(),hf=a("p"),iFt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),qie=a("a"),dFt=o("from_pretrained()"),mFt=o(" class method or the "),jie=a("a"),cFt=o("from_config()"),fFt=o(` class
method.`),gFt=l(),hB=a("p"),hFt=o("This class cannot be instantiated directly using "),fRe=a("code"),uFt=o("__init__()"),pFt=o(" (throws an error)."),_Ft=l(),ua=a("div"),F(uB.$$.fragment),bFt=l(),gRe=a("p"),vFt=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),FFt=l(),uf=a("p"),TFt=o(`Note:
Loading a model from its configuration file does `),hRe=a("strong"),MFt=o("not"),EFt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Die=a("a"),CFt=o("from_pretrained()"),wFt=o(" to load the model weights."),AFt=l(),F(X8.$$.fragment),LFt=l(),at=a("div"),F(pB.$$.fragment),yFt=l(),uRe=a("p"),xFt=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),$Ft=l(),Kn=a("p"),kFt=o("The model class to instantiate is selected based on the "),pRe=a("code"),SFt=o("model_type"),RFt=o(` property of the config object (either
passed as an argument or loaded from `),_Re=a("code"),PFt=o("pretrained_model_name_or_path"),BFt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bRe=a("code"),IFt=o("pretrained_model_name_or_path"),NFt=o(":"),qFt=l(),Ee=a("ul"),z8=a("li"),vRe=a("strong"),jFt=o("albert"),DFt=o(" \u2014 "),Gie=a("a"),GFt=o("FlaxAlbertForPreTraining"),OFt=o(" (ALBERT model)"),VFt=l(),Q8=a("li"),FRe=a("strong"),XFt=o("bart"),zFt=o(" \u2014 "),Oie=a("a"),QFt=o("FlaxBartForConditionalGeneration"),WFt=o(" (BART model)"),UFt=l(),W8=a("li"),TRe=a("strong"),HFt=o("bert"),JFt=o(" \u2014 "),Vie=a("a"),YFt=o("FlaxBertForPreTraining"),ZFt=o(" (BERT model)"),KFt=l(),U8=a("li"),MRe=a("strong"),eTt=o("big_bird"),oTt=o(" \u2014 "),Xie=a("a"),rTt=o("FlaxBigBirdForPreTraining"),tTt=o(" (BigBird model)"),aTt=l(),H8=a("li"),ERe=a("strong"),nTt=o("electra"),sTt=o(" \u2014 "),zie=a("a"),lTt=o("FlaxElectraForPreTraining"),iTt=o(" (ELECTRA model)"),dTt=l(),J8=a("li"),CRe=a("strong"),mTt=o("longt5"),cTt=o(" \u2014 "),Qie=a("a"),fTt=o("FlaxLongT5ForConditionalGeneration"),gTt=o(" (LongT5 model)"),hTt=l(),Y8=a("li"),wRe=a("strong"),uTt=o("mbart"),pTt=o(" \u2014 "),Wie=a("a"),_Tt=o("FlaxMBartForConditionalGeneration"),bTt=o(" (mBART model)"),vTt=l(),Z8=a("li"),ARe=a("strong"),FTt=o("mt5"),TTt=o(" \u2014 "),Uie=a("a"),MTt=o("FlaxMT5ForConditionalGeneration"),ETt=o(" (MT5 model)"),CTt=l(),K8=a("li"),LRe=a("strong"),wTt=o("roberta"),ATt=o(" \u2014 "),Hie=a("a"),LTt=o("FlaxRobertaForMaskedLM"),yTt=o(" (RoBERTa model)"),xTt=l(),eL=a("li"),yRe=a("strong"),$Tt=o("roformer"),kTt=o(" \u2014 "),Jie=a("a"),STt=o("FlaxRoFormerForMaskedLM"),RTt=o(" (RoFormer model)"),PTt=l(),oL=a("li"),xRe=a("strong"),BTt=o("t5"),ITt=o(" \u2014 "),Yie=a("a"),NTt=o("FlaxT5ForConditionalGeneration"),qTt=o(" (T5 model)"),jTt=l(),rL=a("li"),$Re=a("strong"),DTt=o("wav2vec2"),GTt=o(" \u2014 "),Zie=a("a"),OTt=o("FlaxWav2Vec2ForPreTraining"),VTt=o(" (Wav2Vec2 model)"),XTt=l(),tL=a("li"),kRe=a("strong"),zTt=o("xlm-roberta"),QTt=o(" \u2014 "),Kie=a("a"),WTt=o("FlaxXLMRobertaForMaskedLM"),UTt=o(" (XLM-RoBERTa model)"),HTt=l(),F(aL.$$.fragment),Lso=l(),pf=a("h2"),nL=a("a"),SRe=a("span"),F(_B.$$.fragment),JTt=l(),RRe=a("span"),YTt=o("FlaxAutoModelForMaskedLM"),yso=l(),xr=a("div"),F(bB.$$.fragment),ZTt=l(),_f=a("p"),KTt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),ede=a("a"),eMt=o("from_pretrained()"),oMt=o(" class method or the "),ode=a("a"),rMt=o("from_config()"),tMt=o(` class
method.`),aMt=l(),vB=a("p"),nMt=o("This class cannot be instantiated directly using "),PRe=a("code"),sMt=o("__init__()"),lMt=o(" (throws an error)."),iMt=l(),pa=a("div"),F(FB.$$.fragment),dMt=l(),BRe=a("p"),mMt=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),cMt=l(),bf=a("p"),fMt=o(`Note:
Loading a model from its configuration file does `),IRe=a("strong"),gMt=o("not"),hMt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rde=a("a"),uMt=o("from_pretrained()"),pMt=o(" to load the model weights."),_Mt=l(),F(sL.$$.fragment),bMt=l(),nt=a("div"),F(TB.$$.fragment),vMt=l(),NRe=a("p"),FMt=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),TMt=l(),es=a("p"),MMt=o("The model class to instantiate is selected based on the "),qRe=a("code"),EMt=o("model_type"),CMt=o(` property of the config object (either
passed as an argument or loaded from `),jRe=a("code"),wMt=o("pretrained_model_name_or_path"),AMt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),DRe=a("code"),LMt=o("pretrained_model_name_or_path"),yMt=o(":"),xMt=l(),ke=a("ul"),lL=a("li"),GRe=a("strong"),$Mt=o("albert"),kMt=o(" \u2014 "),tde=a("a"),SMt=o("FlaxAlbertForMaskedLM"),RMt=o(" (ALBERT model)"),PMt=l(),iL=a("li"),ORe=a("strong"),BMt=o("bart"),IMt=o(" \u2014 "),ade=a("a"),NMt=o("FlaxBartForConditionalGeneration"),qMt=o(" (BART model)"),jMt=l(),dL=a("li"),VRe=a("strong"),DMt=o("bert"),GMt=o(" \u2014 "),nde=a("a"),OMt=o("FlaxBertForMaskedLM"),VMt=o(" (BERT model)"),XMt=l(),mL=a("li"),XRe=a("strong"),zMt=o("big_bird"),QMt=o(" \u2014 "),sde=a("a"),WMt=o("FlaxBigBirdForMaskedLM"),UMt=o(" (BigBird model)"),HMt=l(),cL=a("li"),zRe=a("strong"),JMt=o("distilbert"),YMt=o(" \u2014 "),lde=a("a"),ZMt=o("FlaxDistilBertForMaskedLM"),KMt=o(" (DistilBERT model)"),eEt=l(),fL=a("li"),QRe=a("strong"),oEt=o("electra"),rEt=o(" \u2014 "),ide=a("a"),tEt=o("FlaxElectraForMaskedLM"),aEt=o(" (ELECTRA model)"),nEt=l(),gL=a("li"),WRe=a("strong"),sEt=o("mbart"),lEt=o(" \u2014 "),dde=a("a"),iEt=o("FlaxMBartForConditionalGeneration"),dEt=o(" (mBART model)"),mEt=l(),hL=a("li"),URe=a("strong"),cEt=o("roberta"),fEt=o(" \u2014 "),mde=a("a"),gEt=o("FlaxRobertaForMaskedLM"),hEt=o(" (RoBERTa model)"),uEt=l(),uL=a("li"),HRe=a("strong"),pEt=o("roformer"),_Et=o(" \u2014 "),cde=a("a"),bEt=o("FlaxRoFormerForMaskedLM"),vEt=o(" (RoFormer model)"),FEt=l(),pL=a("li"),JRe=a("strong"),TEt=o("xlm-roberta"),MEt=o(" \u2014 "),fde=a("a"),EEt=o("FlaxXLMRobertaForMaskedLM"),CEt=o(" (XLM-RoBERTa model)"),wEt=l(),F(_L.$$.fragment),xso=l(),vf=a("h2"),bL=a("a"),YRe=a("span"),F(MB.$$.fragment),AEt=l(),ZRe=a("span"),LEt=o("FlaxAutoModelForSeq2SeqLM"),$so=l(),$r=a("div"),F(EB.$$.fragment),yEt=l(),Ff=a("p"),xEt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),gde=a("a"),$Et=o("from_pretrained()"),kEt=o(" class method or the "),hde=a("a"),SEt=o("from_config()"),REt=o(` class
method.`),PEt=l(),CB=a("p"),BEt=o("This class cannot be instantiated directly using "),KRe=a("code"),IEt=o("__init__()"),NEt=o(" (throws an error)."),qEt=l(),_a=a("div"),F(wB.$$.fragment),jEt=l(),ePe=a("p"),DEt=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),GEt=l(),Tf=a("p"),OEt=o(`Note:
Loading a model from its configuration file does `),oPe=a("strong"),VEt=o("not"),XEt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ude=a("a"),zEt=o("from_pretrained()"),QEt=o(" to load the model weights."),WEt=l(),F(vL.$$.fragment),UEt=l(),st=a("div"),F(AB.$$.fragment),HEt=l(),rPe=a("p"),JEt=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),YEt=l(),os=a("p"),ZEt=o("The model class to instantiate is selected based on the "),tPe=a("code"),KEt=o("model_type"),e4t=o(` property of the config object (either
passed as an argument or loaded from `),aPe=a("code"),o4t=o("pretrained_model_name_or_path"),r4t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nPe=a("code"),t4t=o("pretrained_model_name_or_path"),a4t=o(":"),n4t=l(),Se=a("ul"),FL=a("li"),sPe=a("strong"),s4t=o("bart"),l4t=o(" \u2014 "),pde=a("a"),i4t=o("FlaxBartForConditionalGeneration"),d4t=o(" (BART model)"),m4t=l(),TL=a("li"),lPe=a("strong"),c4t=o("blenderbot"),f4t=o(" \u2014 "),_de=a("a"),g4t=o("FlaxBlenderbotForConditionalGeneration"),h4t=o(" (Blenderbot model)"),u4t=l(),ML=a("li"),iPe=a("strong"),p4t=o("blenderbot-small"),_4t=o(" \u2014 "),bde=a("a"),b4t=o("FlaxBlenderbotSmallForConditionalGeneration"),v4t=o(" (BlenderbotSmall model)"),F4t=l(),EL=a("li"),dPe=a("strong"),T4t=o("encoder-decoder"),M4t=o(" \u2014 "),vde=a("a"),E4t=o("FlaxEncoderDecoderModel"),C4t=o(" (Encoder decoder model)"),w4t=l(),CL=a("li"),mPe=a("strong"),A4t=o("longt5"),L4t=o(" \u2014 "),Fde=a("a"),y4t=o("FlaxLongT5ForConditionalGeneration"),x4t=o(" (LongT5 model)"),$4t=l(),wL=a("li"),cPe=a("strong"),k4t=o("marian"),S4t=o(" \u2014 "),Tde=a("a"),R4t=o("FlaxMarianMTModel"),P4t=o(" (Marian model)"),B4t=l(),AL=a("li"),fPe=a("strong"),I4t=o("mbart"),N4t=o(" \u2014 "),Mde=a("a"),q4t=o("FlaxMBartForConditionalGeneration"),j4t=o(" (mBART model)"),D4t=l(),LL=a("li"),gPe=a("strong"),G4t=o("mt5"),O4t=o(" \u2014 "),Ede=a("a"),V4t=o("FlaxMT5ForConditionalGeneration"),X4t=o(" (MT5 model)"),z4t=l(),yL=a("li"),hPe=a("strong"),Q4t=o("pegasus"),W4t=o(" \u2014 "),Cde=a("a"),U4t=o("FlaxPegasusForConditionalGeneration"),H4t=o(" (Pegasus model)"),J4t=l(),xL=a("li"),uPe=a("strong"),Y4t=o("t5"),Z4t=o(" \u2014 "),wde=a("a"),K4t=o("FlaxT5ForConditionalGeneration"),eCt=o(" (T5 model)"),oCt=l(),F($L.$$.fragment),kso=l(),Mf=a("h2"),kL=a("a"),pPe=a("span"),F(LB.$$.fragment),rCt=l(),_Pe=a("span"),tCt=o("FlaxAutoModelForSequenceClassification"),Sso=l(),kr=a("div"),F(yB.$$.fragment),aCt=l(),Ef=a("p"),nCt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Ade=a("a"),sCt=o("from_pretrained()"),lCt=o(" class method or the "),Lde=a("a"),iCt=o("from_config()"),dCt=o(` class
method.`),mCt=l(),xB=a("p"),cCt=o("This class cannot be instantiated directly using "),bPe=a("code"),fCt=o("__init__()"),gCt=o(" (throws an error)."),hCt=l(),ba=a("div"),F($B.$$.fragment),uCt=l(),vPe=a("p"),pCt=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),_Ct=l(),Cf=a("p"),bCt=o(`Note:
Loading a model from its configuration file does `),FPe=a("strong"),vCt=o("not"),FCt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yde=a("a"),TCt=o("from_pretrained()"),MCt=o(" to load the model weights."),ECt=l(),F(SL.$$.fragment),CCt=l(),lt=a("div"),F(kB.$$.fragment),wCt=l(),TPe=a("p"),ACt=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),LCt=l(),rs=a("p"),yCt=o("The model class to instantiate is selected based on the "),MPe=a("code"),xCt=o("model_type"),$Ct=o(` property of the config object (either
passed as an argument or loaded from `),EPe=a("code"),kCt=o("pretrained_model_name_or_path"),SCt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),CPe=a("code"),RCt=o("pretrained_model_name_or_path"),PCt=o(":"),BCt=l(),Re=a("ul"),RL=a("li"),wPe=a("strong"),ICt=o("albert"),NCt=o(" \u2014 "),xde=a("a"),qCt=o("FlaxAlbertForSequenceClassification"),jCt=o(" (ALBERT model)"),DCt=l(),PL=a("li"),APe=a("strong"),GCt=o("bart"),OCt=o(" \u2014 "),$de=a("a"),VCt=o("FlaxBartForSequenceClassification"),XCt=o(" (BART model)"),zCt=l(),BL=a("li"),LPe=a("strong"),QCt=o("bert"),WCt=o(" \u2014 "),kde=a("a"),UCt=o("FlaxBertForSequenceClassification"),HCt=o(" (BERT model)"),JCt=l(),IL=a("li"),yPe=a("strong"),YCt=o("big_bird"),ZCt=o(" \u2014 "),Sde=a("a"),KCt=o("FlaxBigBirdForSequenceClassification"),e3t=o(" (BigBird model)"),o3t=l(),NL=a("li"),xPe=a("strong"),r3t=o("distilbert"),t3t=o(" \u2014 "),Rde=a("a"),a3t=o("FlaxDistilBertForSequenceClassification"),n3t=o(" (DistilBERT model)"),s3t=l(),qL=a("li"),$Pe=a("strong"),l3t=o("electra"),i3t=o(" \u2014 "),Pde=a("a"),d3t=o("FlaxElectraForSequenceClassification"),m3t=o(" (ELECTRA model)"),c3t=l(),jL=a("li"),kPe=a("strong"),f3t=o("mbart"),g3t=o(" \u2014 "),Bde=a("a"),h3t=o("FlaxMBartForSequenceClassification"),u3t=o(" (mBART model)"),p3t=l(),DL=a("li"),SPe=a("strong"),_3t=o("roberta"),b3t=o(" \u2014 "),Ide=a("a"),v3t=o("FlaxRobertaForSequenceClassification"),F3t=o(" (RoBERTa model)"),T3t=l(),GL=a("li"),RPe=a("strong"),M3t=o("roformer"),E3t=o(" \u2014 "),Nde=a("a"),C3t=o("FlaxRoFormerForSequenceClassification"),w3t=o(" (RoFormer model)"),A3t=l(),OL=a("li"),PPe=a("strong"),L3t=o("xlm-roberta"),y3t=o(" \u2014 "),qde=a("a"),x3t=o("FlaxXLMRobertaForSequenceClassification"),$3t=o(" (XLM-RoBERTa model)"),k3t=l(),F(VL.$$.fragment),Rso=l(),wf=a("h2"),XL=a("a"),BPe=a("span"),F(SB.$$.fragment),S3t=l(),IPe=a("span"),R3t=o("FlaxAutoModelForQuestionAnswering"),Pso=l(),Sr=a("div"),F(RB.$$.fragment),P3t=l(),Af=a("p"),B3t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),jde=a("a"),I3t=o("from_pretrained()"),N3t=o(" class method or the "),Dde=a("a"),q3t=o("from_config()"),j3t=o(` class
method.`),D3t=l(),PB=a("p"),G3t=o("This class cannot be instantiated directly using "),NPe=a("code"),O3t=o("__init__()"),V3t=o(" (throws an error)."),X3t=l(),va=a("div"),F(BB.$$.fragment),z3t=l(),qPe=a("p"),Q3t=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),W3t=l(),Lf=a("p"),U3t=o(`Note:
Loading a model from its configuration file does `),jPe=a("strong"),H3t=o("not"),J3t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Gde=a("a"),Y3t=o("from_pretrained()"),Z3t=o(" to load the model weights."),K3t=l(),F(zL.$$.fragment),e5t=l(),it=a("div"),F(IB.$$.fragment),o5t=l(),DPe=a("p"),r5t=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),t5t=l(),ts=a("p"),a5t=o("The model class to instantiate is selected based on the "),GPe=a("code"),n5t=o("model_type"),s5t=o(` property of the config object (either
passed as an argument or loaded from `),OPe=a("code"),l5t=o("pretrained_model_name_or_path"),i5t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),VPe=a("code"),d5t=o("pretrained_model_name_or_path"),m5t=o(":"),c5t=l(),Pe=a("ul"),QL=a("li"),XPe=a("strong"),f5t=o("albert"),g5t=o(" \u2014 "),Ode=a("a"),h5t=o("FlaxAlbertForQuestionAnswering"),u5t=o(" (ALBERT model)"),p5t=l(),WL=a("li"),zPe=a("strong"),_5t=o("bart"),b5t=o(" \u2014 "),Vde=a("a"),v5t=o("FlaxBartForQuestionAnswering"),F5t=o(" (BART model)"),T5t=l(),UL=a("li"),QPe=a("strong"),M5t=o("bert"),E5t=o(" \u2014 "),Xde=a("a"),C5t=o("FlaxBertForQuestionAnswering"),w5t=o(" (BERT model)"),A5t=l(),HL=a("li"),WPe=a("strong"),L5t=o("big_bird"),y5t=o(" \u2014 "),zde=a("a"),x5t=o("FlaxBigBirdForQuestionAnswering"),$5t=o(" (BigBird model)"),k5t=l(),JL=a("li"),UPe=a("strong"),S5t=o("distilbert"),R5t=o(" \u2014 "),Qde=a("a"),P5t=o("FlaxDistilBertForQuestionAnswering"),B5t=o(" (DistilBERT model)"),I5t=l(),YL=a("li"),HPe=a("strong"),N5t=o("electra"),q5t=o(" \u2014 "),Wde=a("a"),j5t=o("FlaxElectraForQuestionAnswering"),D5t=o(" (ELECTRA model)"),G5t=l(),ZL=a("li"),JPe=a("strong"),O5t=o("mbart"),V5t=o(" \u2014 "),Ude=a("a"),X5t=o("FlaxMBartForQuestionAnswering"),z5t=o(" (mBART model)"),Q5t=l(),KL=a("li"),YPe=a("strong"),W5t=o("roberta"),U5t=o(" \u2014 "),Hde=a("a"),H5t=o("FlaxRobertaForQuestionAnswering"),J5t=o(" (RoBERTa model)"),Y5t=l(),ey=a("li"),ZPe=a("strong"),Z5t=o("roformer"),K5t=o(" \u2014 "),Jde=a("a"),e0t=o("FlaxRoFormerForQuestionAnswering"),o0t=o(" (RoFormer model)"),r0t=l(),oy=a("li"),KPe=a("strong"),t0t=o("xlm-roberta"),a0t=o(" \u2014 "),Yde=a("a"),n0t=o("FlaxXLMRobertaForQuestionAnswering"),s0t=o(" (XLM-RoBERTa model)"),l0t=l(),F(ry.$$.fragment),Bso=l(),yf=a("h2"),ty=a("a"),eBe=a("span"),F(NB.$$.fragment),i0t=l(),oBe=a("span"),d0t=o("FlaxAutoModelForTokenClassification"),Iso=l(),Rr=a("div"),F(qB.$$.fragment),m0t=l(),xf=a("p"),c0t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Zde=a("a"),f0t=o("from_pretrained()"),g0t=o(" class method or the "),Kde=a("a"),h0t=o("from_config()"),u0t=o(` class
method.`),p0t=l(),jB=a("p"),_0t=o("This class cannot be instantiated directly using "),rBe=a("code"),b0t=o("__init__()"),v0t=o(" (throws an error)."),F0t=l(),Fa=a("div"),F(DB.$$.fragment),T0t=l(),tBe=a("p"),M0t=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),E0t=l(),$f=a("p"),C0t=o(`Note:
Loading a model from its configuration file does `),aBe=a("strong"),w0t=o("not"),A0t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eme=a("a"),L0t=o("from_pretrained()"),y0t=o(" to load the model weights."),x0t=l(),F(ay.$$.fragment),$0t=l(),dt=a("div"),F(GB.$$.fragment),k0t=l(),nBe=a("p"),S0t=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),R0t=l(),as=a("p"),P0t=o("The model class to instantiate is selected based on the "),sBe=a("code"),B0t=o("model_type"),I0t=o(` property of the config object (either
passed as an argument or loaded from `),lBe=a("code"),N0t=o("pretrained_model_name_or_path"),q0t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iBe=a("code"),j0t=o("pretrained_model_name_or_path"),D0t=o(":"),G0t=l(),ze=a("ul"),ny=a("li"),dBe=a("strong"),O0t=o("albert"),V0t=o(" \u2014 "),ome=a("a"),X0t=o("FlaxAlbertForTokenClassification"),z0t=o(" (ALBERT model)"),Q0t=l(),sy=a("li"),mBe=a("strong"),W0t=o("bert"),U0t=o(" \u2014 "),rme=a("a"),H0t=o("FlaxBertForTokenClassification"),J0t=o(" (BERT model)"),Y0t=l(),ly=a("li"),cBe=a("strong"),Z0t=o("big_bird"),K0t=o(" \u2014 "),tme=a("a"),ewt=o("FlaxBigBirdForTokenClassification"),owt=o(" (BigBird model)"),rwt=l(),iy=a("li"),fBe=a("strong"),twt=o("distilbert"),awt=o(" \u2014 "),ame=a("a"),nwt=o("FlaxDistilBertForTokenClassification"),swt=o(" (DistilBERT model)"),lwt=l(),dy=a("li"),gBe=a("strong"),iwt=o("electra"),dwt=o(" \u2014 "),nme=a("a"),mwt=o("FlaxElectraForTokenClassification"),cwt=o(" (ELECTRA model)"),fwt=l(),my=a("li"),hBe=a("strong"),gwt=o("roberta"),hwt=o(" \u2014 "),sme=a("a"),uwt=o("FlaxRobertaForTokenClassification"),pwt=o(" (RoBERTa model)"),_wt=l(),cy=a("li"),uBe=a("strong"),bwt=o("roformer"),vwt=o(" \u2014 "),lme=a("a"),Fwt=o("FlaxRoFormerForTokenClassification"),Twt=o(" (RoFormer model)"),Mwt=l(),fy=a("li"),pBe=a("strong"),Ewt=o("xlm-roberta"),Cwt=o(" \u2014 "),ime=a("a"),wwt=o("FlaxXLMRobertaForTokenClassification"),Awt=o(" (XLM-RoBERTa model)"),Lwt=l(),F(gy.$$.fragment),Nso=l(),kf=a("h2"),hy=a("a"),_Be=a("span"),F(OB.$$.fragment),ywt=l(),bBe=a("span"),xwt=o("FlaxAutoModelForMultipleChoice"),qso=l(),Pr=a("div"),F(VB.$$.fragment),$wt=l(),Sf=a("p"),kwt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),dme=a("a"),Swt=o("from_pretrained()"),Rwt=o(" class method or the "),mme=a("a"),Pwt=o("from_config()"),Bwt=o(` class
method.`),Iwt=l(),XB=a("p"),Nwt=o("This class cannot be instantiated directly using "),vBe=a("code"),qwt=o("__init__()"),jwt=o(" (throws an error)."),Dwt=l(),Ta=a("div"),F(zB.$$.fragment),Gwt=l(),FBe=a("p"),Owt=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Vwt=l(),Rf=a("p"),Xwt=o(`Note:
Loading a model from its configuration file does `),TBe=a("strong"),zwt=o("not"),Qwt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cme=a("a"),Wwt=o("from_pretrained()"),Uwt=o(" to load the model weights."),Hwt=l(),F(uy.$$.fragment),Jwt=l(),mt=a("div"),F(QB.$$.fragment),Ywt=l(),MBe=a("p"),Zwt=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Kwt=l(),ns=a("p"),eAt=o("The model class to instantiate is selected based on the "),EBe=a("code"),oAt=o("model_type"),rAt=o(` property of the config object (either
passed as an argument or loaded from `),CBe=a("code"),tAt=o("pretrained_model_name_or_path"),aAt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wBe=a("code"),nAt=o("pretrained_model_name_or_path"),sAt=o(":"),lAt=l(),Qe=a("ul"),py=a("li"),ABe=a("strong"),iAt=o("albert"),dAt=o(" \u2014 "),fme=a("a"),mAt=o("FlaxAlbertForMultipleChoice"),cAt=o(" (ALBERT model)"),fAt=l(),_y=a("li"),LBe=a("strong"),gAt=o("bert"),hAt=o(" \u2014 "),gme=a("a"),uAt=o("FlaxBertForMultipleChoice"),pAt=o(" (BERT model)"),_At=l(),by=a("li"),yBe=a("strong"),bAt=o("big_bird"),vAt=o(" \u2014 "),hme=a("a"),FAt=o("FlaxBigBirdForMultipleChoice"),TAt=o(" (BigBird model)"),MAt=l(),vy=a("li"),xBe=a("strong"),EAt=o("distilbert"),CAt=o(" \u2014 "),ume=a("a"),wAt=o("FlaxDistilBertForMultipleChoice"),AAt=o(" (DistilBERT model)"),LAt=l(),Fy=a("li"),$Be=a("strong"),yAt=o("electra"),xAt=o(" \u2014 "),pme=a("a"),$At=o("FlaxElectraForMultipleChoice"),kAt=o(" (ELECTRA model)"),SAt=l(),Ty=a("li"),kBe=a("strong"),RAt=o("roberta"),PAt=o(" \u2014 "),_me=a("a"),BAt=o("FlaxRobertaForMultipleChoice"),IAt=o(" (RoBERTa model)"),NAt=l(),My=a("li"),SBe=a("strong"),qAt=o("roformer"),jAt=o(" \u2014 "),bme=a("a"),DAt=o("FlaxRoFormerForMultipleChoice"),GAt=o(" (RoFormer model)"),OAt=l(),Ey=a("li"),RBe=a("strong"),VAt=o("xlm-roberta"),XAt=o(" \u2014 "),vme=a("a"),zAt=o("FlaxXLMRobertaForMultipleChoice"),QAt=o(" (XLM-RoBERTa model)"),WAt=l(),F(Cy.$$.fragment),jso=l(),Pf=a("h2"),wy=a("a"),PBe=a("span"),F(WB.$$.fragment),UAt=l(),BBe=a("span"),HAt=o("FlaxAutoModelForNextSentencePrediction"),Dso=l(),Br=a("div"),F(UB.$$.fragment),JAt=l(),Bf=a("p"),YAt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Fme=a("a"),ZAt=o("from_pretrained()"),KAt=o(" class method or the "),Tme=a("a"),e6t=o("from_config()"),o6t=o(` class
method.`),r6t=l(),HB=a("p"),t6t=o("This class cannot be instantiated directly using "),IBe=a("code"),a6t=o("__init__()"),n6t=o(" (throws an error)."),s6t=l(),Ma=a("div"),F(JB.$$.fragment),l6t=l(),NBe=a("p"),i6t=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),d6t=l(),If=a("p"),m6t=o(`Note:
Loading a model from its configuration file does `),qBe=a("strong"),c6t=o("not"),f6t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Mme=a("a"),g6t=o("from_pretrained()"),h6t=o(" to load the model weights."),u6t=l(),F(Ay.$$.fragment),p6t=l(),ct=a("div"),F(YB.$$.fragment),_6t=l(),jBe=a("p"),b6t=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),v6t=l(),ss=a("p"),F6t=o("The model class to instantiate is selected based on the "),DBe=a("code"),T6t=o("model_type"),M6t=o(` property of the config object (either
passed as an argument or loaded from `),GBe=a("code"),E6t=o("pretrained_model_name_or_path"),C6t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),OBe=a("code"),w6t=o("pretrained_model_name_or_path"),A6t=o(":"),L6t=l(),VBe=a("ul"),Ly=a("li"),XBe=a("strong"),y6t=o("bert"),x6t=o(" \u2014 "),Eme=a("a"),$6t=o("FlaxBertForNextSentencePrediction"),k6t=o(" (BERT model)"),S6t=l(),F(yy.$$.fragment),Gso=l(),Nf=a("h2"),xy=a("a"),zBe=a("span"),F(ZB.$$.fragment),R6t=l(),QBe=a("span"),P6t=o("FlaxAutoModelForImageClassification"),Oso=l(),Ir=a("div"),F(KB.$$.fragment),B6t=l(),qf=a("p"),I6t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Cme=a("a"),N6t=o("from_pretrained()"),q6t=o(" class method or the "),wme=a("a"),j6t=o("from_config()"),D6t=o(` class
method.`),G6t=l(),eI=a("p"),O6t=o("This class cannot be instantiated directly using "),WBe=a("code"),V6t=o("__init__()"),X6t=o(" (throws an error)."),z6t=l(),Ea=a("div"),F(oI.$$.fragment),Q6t=l(),UBe=a("p"),W6t=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),U6t=l(),jf=a("p"),H6t=o(`Note:
Loading a model from its configuration file does `),HBe=a("strong"),J6t=o("not"),Y6t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ame=a("a"),Z6t=o("from_pretrained()"),K6t=o(" to load the model weights."),e7t=l(),F($y.$$.fragment),o7t=l(),ft=a("div"),F(rI.$$.fragment),r7t=l(),JBe=a("p"),t7t=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),a7t=l(),ls=a("p"),n7t=o("The model class to instantiate is selected based on the "),YBe=a("code"),s7t=o("model_type"),l7t=o(` property of the config object (either
passed as an argument or loaded from `),ZBe=a("code"),i7t=o("pretrained_model_name_or_path"),d7t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KBe=a("code"),m7t=o("pretrained_model_name_or_path"),c7t=o(":"),f7t=l(),tI=a("ul"),ky=a("li"),eIe=a("strong"),g7t=o("beit"),h7t=o(" \u2014 "),Lme=a("a"),u7t=o("FlaxBeitForImageClassification"),p7t=o(" (BEiT model)"),_7t=l(),Sy=a("li"),oIe=a("strong"),b7t=o("vit"),v7t=o(" \u2014 "),yme=a("a"),F7t=o("FlaxViTForImageClassification"),T7t=o(" (ViT model)"),M7t=l(),F(Ry.$$.fragment),Vso=l(),Df=a("h2"),Py=a("a"),rIe=a("span"),F(aI.$$.fragment),E7t=l(),tIe=a("span"),C7t=o("FlaxAutoModelForVision2Seq"),Xso=l(),Nr=a("div"),F(nI.$$.fragment),w7t=l(),Gf=a("p"),A7t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),xme=a("a"),L7t=o("from_pretrained()"),y7t=o(" class method or the "),$me=a("a"),x7t=o("from_config()"),$7t=o(` class
method.`),k7t=l(),sI=a("p"),S7t=o("This class cannot be instantiated directly using "),aIe=a("code"),R7t=o("__init__()"),P7t=o(" (throws an error)."),B7t=l(),Ca=a("div"),F(lI.$$.fragment),I7t=l(),nIe=a("p"),N7t=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),q7t=l(),Of=a("p"),j7t=o(`Note:
Loading a model from its configuration file does `),sIe=a("strong"),D7t=o("not"),G7t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kme=a("a"),O7t=o("from_pretrained()"),V7t=o(" to load the model weights."),X7t=l(),F(By.$$.fragment),z7t=l(),gt=a("div"),F(iI.$$.fragment),Q7t=l(),lIe=a("p"),W7t=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),U7t=l(),is=a("p"),H7t=o("The model class to instantiate is selected based on the "),iIe=a("code"),J7t=o("model_type"),Y7t=o(` property of the config object (either
passed as an argument or loaded from `),dIe=a("code"),Z7t=o("pretrained_model_name_or_path"),K7t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mIe=a("code"),e8t=o("pretrained_model_name_or_path"),o8t=o(":"),r8t=l(),cIe=a("ul"),Iy=a("li"),fIe=a("strong"),t8t=o("vision-encoder-decoder"),a8t=o(" \u2014 "),Sme=a("a"),n8t=o("FlaxVisionEncoderDecoderModel"),s8t=o(" (Vision Encoder decoder model)"),l8t=l(),F(Ny.$$.fragment),this.h()},l(c){const _=Mwa('[data-svelte="svelte-1phssyn"]',document.head);g=n(_,"META",{name:!0,content:!0}),_.forEach(t),v=i(c),u=n(c,"H1",{class:!0});var dI=s(u);f=n(dI,"A",{id:!0,class:!0,href:!0});var gIe=s(f);p=n(gIe,"SPAN",{});var hIe=s(p);T(m.$$.fragment,hIe),hIe.forEach(t),gIe.forEach(t),h=i(dI),$o=n(dI,"SPAN",{});var uIe=s($o);vd=r(uIe,"Auto Classes"),uIe.forEach(t),dI.forEach(t),Qf=i(c),Tt=n(c,"P",{});var mI=s(Tt);Fd=r(mI,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Td=n(mI,"CODE",{});var pIe=s(Td);v$=r(pIe,"from_pretrained()"),pIe.forEach(t),Wf=r(mI,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),mI.forEach(t),Xe=i(c),He=n(c,"P",{});var ds=s(He);Md=r(ds,"Instantiating one of "),ms=n(ds,"A",{href:!0});var _Ie=s(ms);F$=r(_Ie,"AutoConfig"),_Ie.forEach(t),cs=r(ds,", "),fs=n(ds,"A",{href:!0});var bIe=s(fs);T$=r(bIe,"AutoModel"),bIe.forEach(t),Ed=r(ds,`, and
`),gs=n(ds,"A",{href:!0});var vIe=s(gs);M$=r(vIe,"AutoTokenizer"),vIe.forEach(t),Cd=r(ds," will directly create a class of the relevant architecture. For instance"),ds.forEach(t),Uf=i(c),T(on.$$.fragment,c),Je=i(c),Ae=n(c,"P",{});var cI=s(Ae);NN=r(cI,"will create a model that is an instance of "),wd=n(cI,"A",{href:!0});var FIe=s(wd);qN=r(FIe,"BertModel"),FIe.forEach(t),jN=r(cI,"."),cI.forEach(t),ko=i(c),rn=n(c,"P",{});var fI=s(rn);DN=r(fI,"There is one class of "),Hf=n(fI,"CODE",{});var TIe=s(Hf);GN=r(TIe,"AutoModel"),TIe.forEach(t),gdo=r(fI," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),fI.forEach(t),yao=i(c),Ad=n(c,"H2",{class:!0});var gI=s(Ad);Jf=n(gI,"A",{id:!0,class:!0,href:!0});var MIe=s(Jf);Gfe=n(MIe,"SPAN",{});var EIe=s(Gfe);T(E$.$$.fragment,EIe),EIe.forEach(t),MIe.forEach(t),hdo=i(gI),Ofe=n(gI,"SPAN",{});var CIe=s(Ofe);udo=r(CIe,"Extending the Auto Classes"),CIe.forEach(t),gI.forEach(t),xao=i(c),hs=n(c,"P",{});var Vf=s(hs);pdo=r(Vf,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),Vfe=n(Vf,"CODE",{});var wIe=s(Vfe);_do=r(wIe,"NewModel"),wIe.forEach(t),bdo=r(Vf,", make sure you have a "),Xfe=n(Vf,"CODE",{});var AIe=s(Xfe);vdo=r(AIe,"NewModelConfig"),AIe.forEach(t),Fdo=r(Vf,` then you can add those to the auto
classes like this:`),Vf.forEach(t),$ao=i(c),T(C$.$$.fragment,c),kao=i(c),ON=n(c,"P",{});var LIe=s(ON);Tdo=r(LIe,"You will then be able to use the auto classes like you would usually do!"),LIe.forEach(t),Sao=i(c),T(Yf.$$.fragment,c),Rao=i(c),Ld=n(c,"H2",{class:!0});var hI=s(Ld);Zf=n(hI,"A",{id:!0,class:!0,href:!0});var yIe=s(Zf);zfe=n(yIe,"SPAN",{});var xIe=s(zfe);T(w$.$$.fragment,xIe),xIe.forEach(t),yIe.forEach(t),Mdo=i(hI),Qfe=n(hI,"SPAN",{});var $Ie=s(Qfe);Edo=r($Ie,"AutoConfig"),$Ie.forEach(t),hI.forEach(t),Pao=i(c),So=n(c,"DIV",{class:!0});var vt=s(So);T(A$.$$.fragment,vt),Cdo=i(vt),L$=n(vt,"P",{});var uI=s(L$);wdo=r(uI,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),VN=n(uI,"A",{href:!0});var kIe=s(VN);Ado=r(kIe,"from_pretrained()"),kIe.forEach(t),Ldo=r(uI," class method."),uI.forEach(t),ydo=i(vt),y$=n(vt,"P",{});var pI=s(y$);xdo=r(pI,"This class cannot be instantiated directly using "),Wfe=n(pI,"CODE",{});var SIe=s(Wfe);$do=r(SIe,"__init__()"),SIe.forEach(t),kdo=r(pI," (throws an error)."),pI.forEach(t),Sdo=i(vt),qr=n(vt,"DIV",{class:!0});var Ft=s(qr);T(x$.$$.fragment,Ft),Rdo=i(Ft),Ufe=n(Ft,"P",{});var RIe=s(Ufe);Pdo=r(RIe,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),RIe.forEach(t),Bdo=i(Ft),yd=n(Ft,"P",{});var Xf=s(yd);Ido=r(Xf,"The configuration class to instantiate is selected based on the "),Hfe=n(Xf,"CODE",{});var PIe=s(Hfe);Ndo=r(PIe,"model_type"),PIe.forEach(t),qdo=r(Xf,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Jfe=n(Xf,"CODE",{});var BIe=s(Jfe);jdo=r(BIe,"pretrained_model_name_or_path"),BIe.forEach(t),Ddo=r(Xf,":"),Xf.forEach(t),Gdo=i(Ft),A=n(Ft,"UL",{});var L=s(A);Kf=n(L,"LI",{});var qy=s(Kf);Yfe=n(qy,"STRONG",{});var IIe=s(Yfe);Odo=r(IIe,"albert"),IIe.forEach(t),Vdo=r(qy," \u2014 "),XN=n(qy,"A",{href:!0});var NIe=s(XN);Xdo=r(NIe,"AlbertConfig"),NIe.forEach(t),zdo=r(qy," (ALBERT model)"),qy.forEach(t),Qdo=i(L),eg=n(L,"LI",{});var jy=s(eg);Zfe=n(jy,"STRONG",{});var qIe=s(Zfe);Wdo=r(qIe,"bart"),qIe.forEach(t),Udo=r(jy," \u2014 "),zN=n(jy,"A",{href:!0});var jIe=s(zN);Hdo=r(jIe,"BartConfig"),jIe.forEach(t),Jdo=r(jy," (BART model)"),jy.forEach(t),Ydo=i(L),og=n(L,"LI",{});var Dy=s(og);Kfe=n(Dy,"STRONG",{});var DIe=s(Kfe);Zdo=r(DIe,"beit"),DIe.forEach(t),Kdo=r(Dy," \u2014 "),QN=n(Dy,"A",{href:!0});var GIe=s(QN);emo=r(GIe,"BeitConfig"),GIe.forEach(t),omo=r(Dy," (BEiT model)"),Dy.forEach(t),rmo=i(L),rg=n(L,"LI",{});var Gy=s(rg);ege=n(Gy,"STRONG",{});var OIe=s(ege);tmo=r(OIe,"bert"),OIe.forEach(t),amo=r(Gy," \u2014 "),WN=n(Gy,"A",{href:!0});var VIe=s(WN);nmo=r(VIe,"BertConfig"),VIe.forEach(t),smo=r(Gy," (BERT model)"),Gy.forEach(t),lmo=i(L),tg=n(L,"LI",{});var Oy=s(tg);oge=n(Oy,"STRONG",{});var XIe=s(oge);imo=r(XIe,"bert-generation"),XIe.forEach(t),dmo=r(Oy," \u2014 "),UN=n(Oy,"A",{href:!0});var zIe=s(UN);mmo=r(zIe,"BertGenerationConfig"),zIe.forEach(t),cmo=r(Oy," (Bert Generation model)"),Oy.forEach(t),fmo=i(L),ag=n(L,"LI",{});var Vy=s(ag);rge=n(Vy,"STRONG",{});var QIe=s(rge);gmo=r(QIe,"big_bird"),QIe.forEach(t),hmo=r(Vy," \u2014 "),HN=n(Vy,"A",{href:!0});var WIe=s(HN);umo=r(WIe,"BigBirdConfig"),WIe.forEach(t),pmo=r(Vy," (BigBird model)"),Vy.forEach(t),_mo=i(L),ng=n(L,"LI",{});var Xy=s(ng);tge=n(Xy,"STRONG",{});var UIe=s(tge);bmo=r(UIe,"bigbird_pegasus"),UIe.forEach(t),vmo=r(Xy," \u2014 "),JN=n(Xy,"A",{href:!0});var HIe=s(JN);Fmo=r(HIe,"BigBirdPegasusConfig"),HIe.forEach(t),Tmo=r(Xy," (BigBird-Pegasus model)"),Xy.forEach(t),Mmo=i(L),sg=n(L,"LI",{});var zy=s(sg);age=n(zy,"STRONG",{});var JIe=s(age);Emo=r(JIe,"blenderbot"),JIe.forEach(t),Cmo=r(zy," \u2014 "),YN=n(zy,"A",{href:!0});var YIe=s(YN);wmo=r(YIe,"BlenderbotConfig"),YIe.forEach(t),Amo=r(zy," (Blenderbot model)"),zy.forEach(t),Lmo=i(L),lg=n(L,"LI",{});var Qy=s(lg);nge=n(Qy,"STRONG",{});var ZIe=s(nge);ymo=r(ZIe,"blenderbot-small"),ZIe.forEach(t),xmo=r(Qy," \u2014 "),ZN=n(Qy,"A",{href:!0});var KIe=s(ZN);$mo=r(KIe,"BlenderbotSmallConfig"),KIe.forEach(t),kmo=r(Qy," (BlenderbotSmall model)"),Qy.forEach(t),Smo=i(L),ig=n(L,"LI",{});var Wy=s(ig);sge=n(Wy,"STRONG",{});var eNe=s(sge);Rmo=r(eNe,"bloom"),eNe.forEach(t),Pmo=r(Wy," \u2014 "),KN=n(Wy,"A",{href:!0});var oNe=s(KN);Bmo=r(oNe,"BloomConfig"),oNe.forEach(t),Imo=r(Wy," (BLOOM model)"),Wy.forEach(t),Nmo=i(L),dg=n(L,"LI",{});var Uy=s(dg);lge=n(Uy,"STRONG",{});var rNe=s(lge);qmo=r(rNe,"camembert"),rNe.forEach(t),jmo=r(Uy," \u2014 "),eq=n(Uy,"A",{href:!0});var tNe=s(eq);Dmo=r(tNe,"CamembertConfig"),tNe.forEach(t),Gmo=r(Uy," (CamemBERT model)"),Uy.forEach(t),Omo=i(L),mg=n(L,"LI",{});var Hy=s(mg);ige=n(Hy,"STRONG",{});var aNe=s(ige);Vmo=r(aNe,"canine"),aNe.forEach(t),Xmo=r(Hy," \u2014 "),oq=n(Hy,"A",{href:!0});var nNe=s(oq);zmo=r(nNe,"CanineConfig"),nNe.forEach(t),Qmo=r(Hy," (CANINE model)"),Hy.forEach(t),Wmo=i(L),cg=n(L,"LI",{});var Jy=s(cg);dge=n(Jy,"STRONG",{});var sNe=s(dge);Umo=r(sNe,"clip"),sNe.forEach(t),Hmo=r(Jy," \u2014 "),rq=n(Jy,"A",{href:!0});var lNe=s(rq);Jmo=r(lNe,"CLIPConfig"),lNe.forEach(t),Ymo=r(Jy," (CLIP model)"),Jy.forEach(t),Zmo=i(L),fg=n(L,"LI",{});var Yy=s(fg);mge=n(Yy,"STRONG",{});var iNe=s(mge);Kmo=r(iNe,"clipseg"),iNe.forEach(t),eco=r(Yy," \u2014 "),tq=n(Yy,"A",{href:!0});var dNe=s(tq);oco=r(dNe,"CLIPSegConfig"),dNe.forEach(t),rco=r(Yy," (CLIPSeg model)"),Yy.forEach(t),tco=i(L),gg=n(L,"LI",{});var Zy=s(gg);cge=n(Zy,"STRONG",{});var mNe=s(cge);aco=r(mNe,"codegen"),mNe.forEach(t),nco=r(Zy," \u2014 "),aq=n(Zy,"A",{href:!0});var cNe=s(aq);sco=r(cNe,"CodeGenConfig"),cNe.forEach(t),lco=r(Zy," (CodeGen model)"),Zy.forEach(t),ico=i(L),hg=n(L,"LI",{});var Ky=s(hg);fge=n(Ky,"STRONG",{});var fNe=s(fge);dco=r(fNe,"conditional_detr"),fNe.forEach(t),mco=r(Ky," \u2014 "),nq=n(Ky,"A",{href:!0});var gNe=s(nq);cco=r(gNe,"ConditionalDetrConfig"),gNe.forEach(t),fco=r(Ky," (Conditional DETR model)"),Ky.forEach(t),gco=i(L),ug=n(L,"LI",{});var e9=s(ug);gge=n(e9,"STRONG",{});var hNe=s(gge);hco=r(hNe,"convbert"),hNe.forEach(t),uco=r(e9," \u2014 "),sq=n(e9,"A",{href:!0});var uNe=s(sq);pco=r(uNe,"ConvBertConfig"),uNe.forEach(t),_co=r(e9," (ConvBERT model)"),e9.forEach(t),bco=i(L),pg=n(L,"LI",{});var o9=s(pg);hge=n(o9,"STRONG",{});var pNe=s(hge);vco=r(pNe,"convnext"),pNe.forEach(t),Fco=r(o9," \u2014 "),lq=n(o9,"A",{href:!0});var _Ne=s(lq);Tco=r(_Ne,"ConvNextConfig"),_Ne.forEach(t),Mco=r(o9," (ConvNeXT model)"),o9.forEach(t),Eco=i(L),_g=n(L,"LI",{});var r9=s(_g);uge=n(r9,"STRONG",{});var bNe=s(uge);Cco=r(bNe,"ctrl"),bNe.forEach(t),wco=r(r9," \u2014 "),iq=n(r9,"A",{href:!0});var vNe=s(iq);Aco=r(vNe,"CTRLConfig"),vNe.forEach(t),Lco=r(r9," (CTRL model)"),r9.forEach(t),yco=i(L),bg=n(L,"LI",{});var t9=s(bg);pge=n(t9,"STRONG",{});var FNe=s(pge);xco=r(FNe,"cvt"),FNe.forEach(t),$co=r(t9," \u2014 "),dq=n(t9,"A",{href:!0});var TNe=s(dq);kco=r(TNe,"CvtConfig"),TNe.forEach(t),Sco=r(t9," (CvT model)"),t9.forEach(t),Rco=i(L),vg=n(L,"LI",{});var a9=s(vg);_ge=n(a9,"STRONG",{});var MNe=s(_ge);Pco=r(MNe,"data2vec-audio"),MNe.forEach(t),Bco=r(a9," \u2014 "),mq=n(a9,"A",{href:!0});var ENe=s(mq);Ico=r(ENe,"Data2VecAudioConfig"),ENe.forEach(t),Nco=r(a9," (Data2VecAudio model)"),a9.forEach(t),qco=i(L),Fg=n(L,"LI",{});var n9=s(Fg);bge=n(n9,"STRONG",{});var CNe=s(bge);jco=r(CNe,"data2vec-text"),CNe.forEach(t),Dco=r(n9," \u2014 "),cq=n(n9,"A",{href:!0});var wNe=s(cq);Gco=r(wNe,"Data2VecTextConfig"),wNe.forEach(t),Oco=r(n9," (Data2VecText model)"),n9.forEach(t),Vco=i(L),Tg=n(L,"LI",{});var s9=s(Tg);vge=n(s9,"STRONG",{});var ANe=s(vge);Xco=r(ANe,"data2vec-vision"),ANe.forEach(t),zco=r(s9," \u2014 "),fq=n(s9,"A",{href:!0});var LNe=s(fq);Qco=r(LNe,"Data2VecVisionConfig"),LNe.forEach(t),Wco=r(s9," (Data2VecVision model)"),s9.forEach(t),Uco=i(L),Mg=n(L,"LI",{});var l9=s(Mg);Fge=n(l9,"STRONG",{});var yNe=s(Fge);Hco=r(yNe,"deberta"),yNe.forEach(t),Jco=r(l9," \u2014 "),gq=n(l9,"A",{href:!0});var xNe=s(gq);Yco=r(xNe,"DebertaConfig"),xNe.forEach(t),Zco=r(l9," (DeBERTa model)"),l9.forEach(t),Kco=i(L),Eg=n(L,"LI",{});var i9=s(Eg);Tge=n(i9,"STRONG",{});var $Ne=s(Tge);efo=r($Ne,"deberta-v2"),$Ne.forEach(t),ofo=r(i9," \u2014 "),hq=n(i9,"A",{href:!0});var kNe=s(hq);rfo=r(kNe,"DebertaV2Config"),kNe.forEach(t),tfo=r(i9," (DeBERTa-v2 model)"),i9.forEach(t),afo=i(L),Cg=n(L,"LI",{});var d9=s(Cg);Mge=n(d9,"STRONG",{});var SNe=s(Mge);nfo=r(SNe,"decision_transformer"),SNe.forEach(t),sfo=r(d9," \u2014 "),uq=n(d9,"A",{href:!0});var RNe=s(uq);lfo=r(RNe,"DecisionTransformerConfig"),RNe.forEach(t),ifo=r(d9," (Decision Transformer model)"),d9.forEach(t),dfo=i(L),wg=n(L,"LI",{});var m9=s(wg);Ege=n(m9,"STRONG",{});var PNe=s(Ege);mfo=r(PNe,"deformable_detr"),PNe.forEach(t),cfo=r(m9," \u2014 "),pq=n(m9,"A",{href:!0});var BNe=s(pq);ffo=r(BNe,"DeformableDetrConfig"),BNe.forEach(t),gfo=r(m9," (Deformable DETR model)"),m9.forEach(t),hfo=i(L),Ag=n(L,"LI",{});var c9=s(Ag);Cge=n(c9,"STRONG",{});var d8t=s(Cge);ufo=r(d8t,"deit"),d8t.forEach(t),pfo=r(c9," \u2014 "),_q=n(c9,"A",{href:!0});var m8t=s(_q);_fo=r(m8t,"DeiTConfig"),m8t.forEach(t),bfo=r(c9," (DeiT model)"),c9.forEach(t),vfo=i(L),Lg=n(L,"LI",{});var INe=s(Lg);wge=n(INe,"STRONG",{});var c8t=s(wge);Ffo=r(c8t,"detr"),c8t.forEach(t),Tfo=r(INe," \u2014 "),bq=n(INe,"A",{href:!0});var f8t=s(bq);Mfo=r(f8t,"DetrConfig"),f8t.forEach(t),Efo=r(INe," (DETR model)"),INe.forEach(t),Cfo=i(L),yg=n(L,"LI",{});var NNe=s(yg);Age=n(NNe,"STRONG",{});var g8t=s(Age);wfo=r(g8t,"distilbert"),g8t.forEach(t),Afo=r(NNe," \u2014 "),vq=n(NNe,"A",{href:!0});var h8t=s(vq);Lfo=r(h8t,"DistilBertConfig"),h8t.forEach(t),yfo=r(NNe," (DistilBERT model)"),NNe.forEach(t),xfo=i(L),xg=n(L,"LI",{});var qNe=s(xg);Lge=n(qNe,"STRONG",{});var u8t=s(Lge);$fo=r(u8t,"donut-swin"),u8t.forEach(t),kfo=r(qNe," \u2014 "),Fq=n(qNe,"A",{href:!0});var p8t=s(Fq);Sfo=r(p8t,"DonutSwinConfig"),p8t.forEach(t),Rfo=r(qNe," (DonutSwin model)"),qNe.forEach(t),Pfo=i(L),$g=n(L,"LI",{});var jNe=s($g);yge=n(jNe,"STRONG",{});var _8t=s(yge);Bfo=r(_8t,"dpr"),_8t.forEach(t),Ifo=r(jNe," \u2014 "),Tq=n(jNe,"A",{href:!0});var b8t=s(Tq);Nfo=r(b8t,"DPRConfig"),b8t.forEach(t),qfo=r(jNe," (DPR model)"),jNe.forEach(t),jfo=i(L),kg=n(L,"LI",{});var DNe=s(kg);xge=n(DNe,"STRONG",{});var v8t=s(xge);Dfo=r(v8t,"dpt"),v8t.forEach(t),Gfo=r(DNe," \u2014 "),Mq=n(DNe,"A",{href:!0});var F8t=s(Mq);Ofo=r(F8t,"DPTConfig"),F8t.forEach(t),Vfo=r(DNe," (DPT model)"),DNe.forEach(t),Xfo=i(L),Sg=n(L,"LI",{});var GNe=s(Sg);$ge=n(GNe,"STRONG",{});var T8t=s($ge);zfo=r(T8t,"electra"),T8t.forEach(t),Qfo=r(GNe," \u2014 "),Eq=n(GNe,"A",{href:!0});var M8t=s(Eq);Wfo=r(M8t,"ElectraConfig"),M8t.forEach(t),Ufo=r(GNe," (ELECTRA model)"),GNe.forEach(t),Hfo=i(L),Rg=n(L,"LI",{});var ONe=s(Rg);kge=n(ONe,"STRONG",{});var E8t=s(kge);Jfo=r(E8t,"encoder-decoder"),E8t.forEach(t),Yfo=r(ONe," \u2014 "),Cq=n(ONe,"A",{href:!0});var C8t=s(Cq);Zfo=r(C8t,"EncoderDecoderConfig"),C8t.forEach(t),Kfo=r(ONe," (Encoder decoder model)"),ONe.forEach(t),ego=i(L),Pg=n(L,"LI",{});var VNe=s(Pg);Sge=n(VNe,"STRONG",{});var w8t=s(Sge);ogo=r(w8t,"ernie"),w8t.forEach(t),rgo=r(VNe," \u2014 "),wq=n(VNe,"A",{href:!0});var A8t=s(wq);tgo=r(A8t,"ErnieConfig"),A8t.forEach(t),ago=r(VNe," (ERNIE model)"),VNe.forEach(t),ngo=i(L),Bg=n(L,"LI",{});var XNe=s(Bg);Rge=n(XNe,"STRONG",{});var L8t=s(Rge);sgo=r(L8t,"esm"),L8t.forEach(t),lgo=r(XNe," \u2014 "),Aq=n(XNe,"A",{href:!0});var y8t=s(Aq);igo=r(y8t,"EsmConfig"),y8t.forEach(t),dgo=r(XNe," (ESM model)"),XNe.forEach(t),mgo=i(L),Ig=n(L,"LI",{});var zNe=s(Ig);Pge=n(zNe,"STRONG",{});var x8t=s(Pge);cgo=r(x8t,"flaubert"),x8t.forEach(t),fgo=r(zNe," \u2014 "),Lq=n(zNe,"A",{href:!0});var $8t=s(Lq);ggo=r($8t,"FlaubertConfig"),$8t.forEach(t),hgo=r(zNe," (FlauBERT model)"),zNe.forEach(t),ugo=i(L),Ng=n(L,"LI",{});var QNe=s(Ng);Bge=n(QNe,"STRONG",{});var k8t=s(Bge);pgo=r(k8t,"flava"),k8t.forEach(t),_go=r(QNe," \u2014 "),yq=n(QNe,"A",{href:!0});var S8t=s(yq);bgo=r(S8t,"FlavaConfig"),S8t.forEach(t),vgo=r(QNe," (FLAVA model)"),QNe.forEach(t),Fgo=i(L),qg=n(L,"LI",{});var WNe=s(qg);Ige=n(WNe,"STRONG",{});var R8t=s(Ige);Tgo=r(R8t,"fnet"),R8t.forEach(t),Mgo=r(WNe," \u2014 "),xq=n(WNe,"A",{href:!0});var P8t=s(xq);Ego=r(P8t,"FNetConfig"),P8t.forEach(t),Cgo=r(WNe," (FNet model)"),WNe.forEach(t),wgo=i(L),jg=n(L,"LI",{});var UNe=s(jg);Nge=n(UNe,"STRONG",{});var B8t=s(Nge);Ago=r(B8t,"fsmt"),B8t.forEach(t),Lgo=r(UNe," \u2014 "),$q=n(UNe,"A",{href:!0});var I8t=s($q);ygo=r(I8t,"FSMTConfig"),I8t.forEach(t),xgo=r(UNe," (FairSeq Machine-Translation model)"),UNe.forEach(t),$go=i(L),Dg=n(L,"LI",{});var HNe=s(Dg);qge=n(HNe,"STRONG",{});var N8t=s(qge);kgo=r(N8t,"funnel"),N8t.forEach(t),Sgo=r(HNe," \u2014 "),kq=n(HNe,"A",{href:!0});var q8t=s(kq);Rgo=r(q8t,"FunnelConfig"),q8t.forEach(t),Pgo=r(HNe," (Funnel Transformer model)"),HNe.forEach(t),Bgo=i(L),Gg=n(L,"LI",{});var JNe=s(Gg);jge=n(JNe,"STRONG",{});var j8t=s(jge);Igo=r(j8t,"glpn"),j8t.forEach(t),Ngo=r(JNe," \u2014 "),Sq=n(JNe,"A",{href:!0});var D8t=s(Sq);qgo=r(D8t,"GLPNConfig"),D8t.forEach(t),jgo=r(JNe," (GLPN model)"),JNe.forEach(t),Dgo=i(L),Og=n(L,"LI",{});var YNe=s(Og);Dge=n(YNe,"STRONG",{});var G8t=s(Dge);Ggo=r(G8t,"gpt2"),G8t.forEach(t),Ogo=r(YNe," \u2014 "),Rq=n(YNe,"A",{href:!0});var O8t=s(Rq);Vgo=r(O8t,"GPT2Config"),O8t.forEach(t),Xgo=r(YNe," (OpenAI GPT-2 model)"),YNe.forEach(t),zgo=i(L),Vg=n(L,"LI",{});var ZNe=s(Vg);Gge=n(ZNe,"STRONG",{});var V8t=s(Gge);Qgo=r(V8t,"gpt_neo"),V8t.forEach(t),Wgo=r(ZNe," \u2014 "),Pq=n(ZNe,"A",{href:!0});var X8t=s(Pq);Ugo=r(X8t,"GPTNeoConfig"),X8t.forEach(t),Hgo=r(ZNe," (GPT Neo model)"),ZNe.forEach(t),Jgo=i(L),Xg=n(L,"LI",{});var KNe=s(Xg);Oge=n(KNe,"STRONG",{});var z8t=s(Oge);Ygo=r(z8t,"gpt_neox"),z8t.forEach(t),Zgo=r(KNe," \u2014 "),Bq=n(KNe,"A",{href:!0});var Q8t=s(Bq);Kgo=r(Q8t,"GPTNeoXConfig"),Q8t.forEach(t),eho=r(KNe," (GPT NeoX model)"),KNe.forEach(t),oho=i(L),zg=n(L,"LI",{});var eqe=s(zg);Vge=n(eqe,"STRONG",{});var W8t=s(Vge);rho=r(W8t,"gpt_neox_japanese"),W8t.forEach(t),tho=r(eqe," \u2014 "),Iq=n(eqe,"A",{href:!0});var U8t=s(Iq);aho=r(U8t,"GPTNeoXJapaneseConfig"),U8t.forEach(t),nho=r(eqe," (GPT NeoX Japanese model)"),eqe.forEach(t),sho=i(L),Qg=n(L,"LI",{});var oqe=s(Qg);Xge=n(oqe,"STRONG",{});var H8t=s(Xge);lho=r(H8t,"gptj"),H8t.forEach(t),iho=r(oqe," \u2014 "),Nq=n(oqe,"A",{href:!0});var J8t=s(Nq);dho=r(J8t,"GPTJConfig"),J8t.forEach(t),mho=r(oqe," (GPT-J model)"),oqe.forEach(t),cho=i(L),Wg=n(L,"LI",{});var rqe=s(Wg);zge=n(rqe,"STRONG",{});var Y8t=s(zge);fho=r(Y8t,"groupvit"),Y8t.forEach(t),gho=r(rqe," \u2014 "),qq=n(rqe,"A",{href:!0});var Z8t=s(qq);hho=r(Z8t,"GroupViTConfig"),Z8t.forEach(t),uho=r(rqe," (GroupViT model)"),rqe.forEach(t),pho=i(L),Ug=n(L,"LI",{});var tqe=s(Ug);Qge=n(tqe,"STRONG",{});var K8t=s(Qge);_ho=r(K8t,"hubert"),K8t.forEach(t),bho=r(tqe," \u2014 "),jq=n(tqe,"A",{href:!0});var eLt=s(jq);vho=r(eLt,"HubertConfig"),eLt.forEach(t),Fho=r(tqe," (Hubert model)"),tqe.forEach(t),Tho=i(L),Hg=n(L,"LI",{});var aqe=s(Hg);Wge=n(aqe,"STRONG",{});var oLt=s(Wge);Mho=r(oLt,"ibert"),oLt.forEach(t),Eho=r(aqe," \u2014 "),Dq=n(aqe,"A",{href:!0});var rLt=s(Dq);Cho=r(rLt,"IBertConfig"),rLt.forEach(t),who=r(aqe," (I-BERT model)"),aqe.forEach(t),Aho=i(L),Jg=n(L,"LI",{});var nqe=s(Jg);Uge=n(nqe,"STRONG",{});var tLt=s(Uge);Lho=r(tLt,"imagegpt"),tLt.forEach(t),yho=r(nqe," \u2014 "),Gq=n(nqe,"A",{href:!0});var aLt=s(Gq);xho=r(aLt,"ImageGPTConfig"),aLt.forEach(t),$ho=r(nqe," (ImageGPT model)"),nqe.forEach(t),kho=i(L),Yg=n(L,"LI",{});var sqe=s(Yg);Hge=n(sqe,"STRONG",{});var nLt=s(Hge);Sho=r(nLt,"layoutlm"),nLt.forEach(t),Rho=r(sqe," \u2014 "),Oq=n(sqe,"A",{href:!0});var sLt=s(Oq);Pho=r(sLt,"LayoutLMConfig"),sLt.forEach(t),Bho=r(sqe," (LayoutLM model)"),sqe.forEach(t),Iho=i(L),Zg=n(L,"LI",{});var lqe=s(Zg);Jge=n(lqe,"STRONG",{});var lLt=s(Jge);Nho=r(lLt,"layoutlmv2"),lLt.forEach(t),qho=r(lqe," \u2014 "),Vq=n(lqe,"A",{href:!0});var iLt=s(Vq);jho=r(iLt,"LayoutLMv2Config"),iLt.forEach(t),Dho=r(lqe," (LayoutLMv2 model)"),lqe.forEach(t),Gho=i(L),Kg=n(L,"LI",{});var iqe=s(Kg);Yge=n(iqe,"STRONG",{});var dLt=s(Yge);Oho=r(dLt,"layoutlmv3"),dLt.forEach(t),Vho=r(iqe," \u2014 "),Xq=n(iqe,"A",{href:!0});var mLt=s(Xq);Xho=r(mLt,"LayoutLMv3Config"),mLt.forEach(t),zho=r(iqe," (LayoutLMv3 model)"),iqe.forEach(t),Qho=i(L),eh=n(L,"LI",{});var dqe=s(eh);Zge=n(dqe,"STRONG",{});var cLt=s(Zge);Who=r(cLt,"led"),cLt.forEach(t),Uho=r(dqe," \u2014 "),zq=n(dqe,"A",{href:!0});var fLt=s(zq);Hho=r(fLt,"LEDConfig"),fLt.forEach(t),Jho=r(dqe," (LED model)"),dqe.forEach(t),Yho=i(L),oh=n(L,"LI",{});var mqe=s(oh);Kge=n(mqe,"STRONG",{});var gLt=s(Kge);Zho=r(gLt,"levit"),gLt.forEach(t),Kho=r(mqe," \u2014 "),Qq=n(mqe,"A",{href:!0});var hLt=s(Qq);euo=r(hLt,"LevitConfig"),hLt.forEach(t),ouo=r(mqe," (LeViT model)"),mqe.forEach(t),ruo=i(L),rh=n(L,"LI",{});var cqe=s(rh);ehe=n(cqe,"STRONG",{});var uLt=s(ehe);tuo=r(uLt,"lilt"),uLt.forEach(t),auo=r(cqe," \u2014 "),Wq=n(cqe,"A",{href:!0});var pLt=s(Wq);nuo=r(pLt,"LiltConfig"),pLt.forEach(t),suo=r(cqe," (LiLT model)"),cqe.forEach(t),luo=i(L),th=n(L,"LI",{});var fqe=s(th);ohe=n(fqe,"STRONG",{});var _Lt=s(ohe);iuo=r(_Lt,"longformer"),_Lt.forEach(t),duo=r(fqe," \u2014 "),Uq=n(fqe,"A",{href:!0});var bLt=s(Uq);muo=r(bLt,"LongformerConfig"),bLt.forEach(t),cuo=r(fqe," (Longformer model)"),fqe.forEach(t),fuo=i(L),ah=n(L,"LI",{});var gqe=s(ah);rhe=n(gqe,"STRONG",{});var vLt=s(rhe);guo=r(vLt,"longt5"),vLt.forEach(t),huo=r(gqe," \u2014 "),Hq=n(gqe,"A",{href:!0});var FLt=s(Hq);uuo=r(FLt,"LongT5Config"),FLt.forEach(t),puo=r(gqe," (LongT5 model)"),gqe.forEach(t),_uo=i(L),nh=n(L,"LI",{});var hqe=s(nh);the=n(hqe,"STRONG",{});var TLt=s(the);buo=r(TLt,"luke"),TLt.forEach(t),vuo=r(hqe," \u2014 "),Jq=n(hqe,"A",{href:!0});var MLt=s(Jq);Fuo=r(MLt,"LukeConfig"),MLt.forEach(t),Tuo=r(hqe," (LUKE model)"),hqe.forEach(t),Muo=i(L),sh=n(L,"LI",{});var uqe=s(sh);ahe=n(uqe,"STRONG",{});var ELt=s(ahe);Euo=r(ELt,"lxmert"),ELt.forEach(t),Cuo=r(uqe," \u2014 "),Yq=n(uqe,"A",{href:!0});var CLt=s(Yq);wuo=r(CLt,"LxmertConfig"),CLt.forEach(t),Auo=r(uqe," (LXMERT model)"),uqe.forEach(t),Luo=i(L),lh=n(L,"LI",{});var pqe=s(lh);nhe=n(pqe,"STRONG",{});var wLt=s(nhe);yuo=r(wLt,"m2m_100"),wLt.forEach(t),xuo=r(pqe," \u2014 "),Zq=n(pqe,"A",{href:!0});var ALt=s(Zq);$uo=r(ALt,"M2M100Config"),ALt.forEach(t),kuo=r(pqe," (M2M100 model)"),pqe.forEach(t),Suo=i(L),ih=n(L,"LI",{});var _qe=s(ih);she=n(_qe,"STRONG",{});var LLt=s(she);Ruo=r(LLt,"marian"),LLt.forEach(t),Puo=r(_qe," \u2014 "),Kq=n(_qe,"A",{href:!0});var yLt=s(Kq);Buo=r(yLt,"MarianConfig"),yLt.forEach(t),Iuo=r(_qe," (Marian model)"),_qe.forEach(t),Nuo=i(L),dh=n(L,"LI",{});var bqe=s(dh);lhe=n(bqe,"STRONG",{});var xLt=s(lhe);quo=r(xLt,"markuplm"),xLt.forEach(t),juo=r(bqe," \u2014 "),ej=n(bqe,"A",{href:!0});var $Lt=s(ej);Duo=r($Lt,"MarkupLMConfig"),$Lt.forEach(t),Guo=r(bqe," (MarkupLM model)"),bqe.forEach(t),Ouo=i(L),mh=n(L,"LI",{});var vqe=s(mh);ihe=n(vqe,"STRONG",{});var kLt=s(ihe);Vuo=r(kLt,"maskformer"),kLt.forEach(t),Xuo=r(vqe," \u2014 "),oj=n(vqe,"A",{href:!0});var SLt=s(oj);zuo=r(SLt,"MaskFormerConfig"),SLt.forEach(t),Quo=r(vqe," (MaskFormer model)"),vqe.forEach(t),Wuo=i(L),ch=n(L,"LI",{});var Fqe=s(ch);dhe=n(Fqe,"STRONG",{});var RLt=s(dhe);Uuo=r(RLt,"mbart"),RLt.forEach(t),Huo=r(Fqe," \u2014 "),rj=n(Fqe,"A",{href:!0});var PLt=s(rj);Juo=r(PLt,"MBartConfig"),PLt.forEach(t),Yuo=r(Fqe," (mBART model)"),Fqe.forEach(t),Zuo=i(L),fh=n(L,"LI",{});var Tqe=s(fh);mhe=n(Tqe,"STRONG",{});var BLt=s(mhe);Kuo=r(BLt,"mctct"),BLt.forEach(t),epo=r(Tqe," \u2014 "),tj=n(Tqe,"A",{href:!0});var ILt=s(tj);opo=r(ILt,"MCTCTConfig"),ILt.forEach(t),rpo=r(Tqe," (M-CTC-T model)"),Tqe.forEach(t),tpo=i(L),gh=n(L,"LI",{});var Mqe=s(gh);che=n(Mqe,"STRONG",{});var NLt=s(che);apo=r(NLt,"megatron-bert"),NLt.forEach(t),npo=r(Mqe," \u2014 "),aj=n(Mqe,"A",{href:!0});var qLt=s(aj);spo=r(qLt,"MegatronBertConfig"),qLt.forEach(t),lpo=r(Mqe," (Megatron-BERT model)"),Mqe.forEach(t),ipo=i(L),hh=n(L,"LI",{});var Eqe=s(hh);fhe=n(Eqe,"STRONG",{});var jLt=s(fhe);dpo=r(jLt,"mobilebert"),jLt.forEach(t),mpo=r(Eqe," \u2014 "),nj=n(Eqe,"A",{href:!0});var DLt=s(nj);cpo=r(DLt,"MobileBertConfig"),DLt.forEach(t),fpo=r(Eqe," (MobileBERT model)"),Eqe.forEach(t),gpo=i(L),uh=n(L,"LI",{});var Cqe=s(uh);ghe=n(Cqe,"STRONG",{});var GLt=s(ghe);hpo=r(GLt,"mobilevit"),GLt.forEach(t),upo=r(Cqe," \u2014 "),sj=n(Cqe,"A",{href:!0});var OLt=s(sj);ppo=r(OLt,"MobileViTConfig"),OLt.forEach(t),_po=r(Cqe," (MobileViT model)"),Cqe.forEach(t),bpo=i(L),ph=n(L,"LI",{});var wqe=s(ph);hhe=n(wqe,"STRONG",{});var VLt=s(hhe);vpo=r(VLt,"mpnet"),VLt.forEach(t),Fpo=r(wqe," \u2014 "),lj=n(wqe,"A",{href:!0});var XLt=s(lj);Tpo=r(XLt,"MPNetConfig"),XLt.forEach(t),Mpo=r(wqe," (MPNet model)"),wqe.forEach(t),Epo=i(L),_h=n(L,"LI",{});var Aqe=s(_h);uhe=n(Aqe,"STRONG",{});var zLt=s(uhe);Cpo=r(zLt,"mt5"),zLt.forEach(t),wpo=r(Aqe," \u2014 "),ij=n(Aqe,"A",{href:!0});var QLt=s(ij);Apo=r(QLt,"MT5Config"),QLt.forEach(t),Lpo=r(Aqe," (MT5 model)"),Aqe.forEach(t),ypo=i(L),bh=n(L,"LI",{});var Lqe=s(bh);phe=n(Lqe,"STRONG",{});var WLt=s(phe);xpo=r(WLt,"mvp"),WLt.forEach(t),$po=r(Lqe," \u2014 "),dj=n(Lqe,"A",{href:!0});var ULt=s(dj);kpo=r(ULt,"MvpConfig"),ULt.forEach(t),Spo=r(Lqe," (MVP model)"),Lqe.forEach(t),Rpo=i(L),vh=n(L,"LI",{});var yqe=s(vh);_he=n(yqe,"STRONG",{});var HLt=s(_he);Ppo=r(HLt,"nezha"),HLt.forEach(t),Bpo=r(yqe," \u2014 "),mj=n(yqe,"A",{href:!0});var JLt=s(mj);Ipo=r(JLt,"NezhaConfig"),JLt.forEach(t),Npo=r(yqe," (Nezha model)"),yqe.forEach(t),qpo=i(L),Fh=n(L,"LI",{});var xqe=s(Fh);bhe=n(xqe,"STRONG",{});var YLt=s(bhe);jpo=r(YLt,"nystromformer"),YLt.forEach(t),Dpo=r(xqe," \u2014 "),cj=n(xqe,"A",{href:!0});var ZLt=s(cj);Gpo=r(ZLt,"NystromformerConfig"),ZLt.forEach(t),Opo=r(xqe," (Nystr\xF6mformer model)"),xqe.forEach(t),Vpo=i(L),Th=n(L,"LI",{});var $qe=s(Th);vhe=n($qe,"STRONG",{});var KLt=s(vhe);Xpo=r(KLt,"openai-gpt"),KLt.forEach(t),zpo=r($qe," \u2014 "),fj=n($qe,"A",{href:!0});var eyt=s(fj);Qpo=r(eyt,"OpenAIGPTConfig"),eyt.forEach(t),Wpo=r($qe," (OpenAI GPT model)"),$qe.forEach(t),Upo=i(L),Mh=n(L,"LI",{});var kqe=s(Mh);Fhe=n(kqe,"STRONG",{});var oyt=s(Fhe);Hpo=r(oyt,"opt"),oyt.forEach(t),Jpo=r(kqe," \u2014 "),gj=n(kqe,"A",{href:!0});var ryt=s(gj);Ypo=r(ryt,"OPTConfig"),ryt.forEach(t),Zpo=r(kqe," (OPT model)"),kqe.forEach(t),Kpo=i(L),Eh=n(L,"LI",{});var Sqe=s(Eh);The=n(Sqe,"STRONG",{});var tyt=s(The);e_o=r(tyt,"owlvit"),tyt.forEach(t),o_o=r(Sqe," \u2014 "),hj=n(Sqe,"A",{href:!0});var ayt=s(hj);r_o=r(ayt,"OwlViTConfig"),ayt.forEach(t),t_o=r(Sqe," (OWL-ViT model)"),Sqe.forEach(t),a_o=i(L),Ch=n(L,"LI",{});var Rqe=s(Ch);Mhe=n(Rqe,"STRONG",{});var nyt=s(Mhe);n_o=r(nyt,"pegasus"),nyt.forEach(t),s_o=r(Rqe," \u2014 "),uj=n(Rqe,"A",{href:!0});var syt=s(uj);l_o=r(syt,"PegasusConfig"),syt.forEach(t),i_o=r(Rqe," (Pegasus model)"),Rqe.forEach(t),d_o=i(L),wh=n(L,"LI",{});var Pqe=s(wh);Ehe=n(Pqe,"STRONG",{});var lyt=s(Ehe);m_o=r(lyt,"pegasus_x"),lyt.forEach(t),c_o=r(Pqe," \u2014 "),pj=n(Pqe,"A",{href:!0});var iyt=s(pj);f_o=r(iyt,"PegasusXConfig"),iyt.forEach(t),g_o=r(Pqe," (PEGASUS-X model)"),Pqe.forEach(t),h_o=i(L),Ah=n(L,"LI",{});var Bqe=s(Ah);Che=n(Bqe,"STRONG",{});var dyt=s(Che);u_o=r(dyt,"perceiver"),dyt.forEach(t),p_o=r(Bqe," \u2014 "),_j=n(Bqe,"A",{href:!0});var myt=s(_j);__o=r(myt,"PerceiverConfig"),myt.forEach(t),b_o=r(Bqe," (Perceiver model)"),Bqe.forEach(t),v_o=i(L),Lh=n(L,"LI",{});var Iqe=s(Lh);whe=n(Iqe,"STRONG",{});var cyt=s(whe);F_o=r(cyt,"plbart"),cyt.forEach(t),T_o=r(Iqe," \u2014 "),bj=n(Iqe,"A",{href:!0});var fyt=s(bj);M_o=r(fyt,"PLBartConfig"),fyt.forEach(t),E_o=r(Iqe," (PLBart model)"),Iqe.forEach(t),C_o=i(L),yh=n(L,"LI",{});var Nqe=s(yh);Ahe=n(Nqe,"STRONG",{});var gyt=s(Ahe);w_o=r(gyt,"poolformer"),gyt.forEach(t),A_o=r(Nqe," \u2014 "),vj=n(Nqe,"A",{href:!0});var hyt=s(vj);L_o=r(hyt,"PoolFormerConfig"),hyt.forEach(t),y_o=r(Nqe," (PoolFormer model)"),Nqe.forEach(t),x_o=i(L),xh=n(L,"LI",{});var qqe=s(xh);Lhe=n(qqe,"STRONG",{});var uyt=s(Lhe);$_o=r(uyt,"prophetnet"),uyt.forEach(t),k_o=r(qqe," \u2014 "),Fj=n(qqe,"A",{href:!0});var pyt=s(Fj);S_o=r(pyt,"ProphetNetConfig"),pyt.forEach(t),R_o=r(qqe," (ProphetNet model)"),qqe.forEach(t),P_o=i(L),$h=n(L,"LI",{});var jqe=s($h);yhe=n(jqe,"STRONG",{});var _yt=s(yhe);B_o=r(_yt,"qdqbert"),_yt.forEach(t),I_o=r(jqe," \u2014 "),Tj=n(jqe,"A",{href:!0});var byt=s(Tj);N_o=r(byt,"QDQBertConfig"),byt.forEach(t),q_o=r(jqe," (QDQBert model)"),jqe.forEach(t),j_o=i(L),kh=n(L,"LI",{});var Dqe=s(kh);xhe=n(Dqe,"STRONG",{});var vyt=s(xhe);D_o=r(vyt,"rag"),vyt.forEach(t),G_o=r(Dqe," \u2014 "),Mj=n(Dqe,"A",{href:!0});var Fyt=s(Mj);O_o=r(Fyt,"RagConfig"),Fyt.forEach(t),V_o=r(Dqe," (RAG model)"),Dqe.forEach(t),X_o=i(L),Sh=n(L,"LI",{});var Gqe=s(Sh);$he=n(Gqe,"STRONG",{});var Tyt=s($he);z_o=r(Tyt,"realm"),Tyt.forEach(t),Q_o=r(Gqe," \u2014 "),Ej=n(Gqe,"A",{href:!0});var Myt=s(Ej);W_o=r(Myt,"RealmConfig"),Myt.forEach(t),U_o=r(Gqe," (REALM model)"),Gqe.forEach(t),H_o=i(L),Rh=n(L,"LI",{});var Oqe=s(Rh);khe=n(Oqe,"STRONG",{});var Eyt=s(khe);J_o=r(Eyt,"reformer"),Eyt.forEach(t),Y_o=r(Oqe," \u2014 "),Cj=n(Oqe,"A",{href:!0});var Cyt=s(Cj);Z_o=r(Cyt,"ReformerConfig"),Cyt.forEach(t),K_o=r(Oqe," (Reformer model)"),Oqe.forEach(t),e1o=i(L),Ph=n(L,"LI",{});var Vqe=s(Ph);She=n(Vqe,"STRONG",{});var wyt=s(She);o1o=r(wyt,"regnet"),wyt.forEach(t),r1o=r(Vqe," \u2014 "),wj=n(Vqe,"A",{href:!0});var Ayt=s(wj);t1o=r(Ayt,"RegNetConfig"),Ayt.forEach(t),a1o=r(Vqe," (RegNet model)"),Vqe.forEach(t),n1o=i(L),Bh=n(L,"LI",{});var Xqe=s(Bh);Rhe=n(Xqe,"STRONG",{});var Lyt=s(Rhe);s1o=r(Lyt,"rembert"),Lyt.forEach(t),l1o=r(Xqe," \u2014 "),Aj=n(Xqe,"A",{href:!0});var yyt=s(Aj);i1o=r(yyt,"RemBertConfig"),yyt.forEach(t),d1o=r(Xqe," (RemBERT model)"),Xqe.forEach(t),m1o=i(L),Ih=n(L,"LI",{});var zqe=s(Ih);Phe=n(zqe,"STRONG",{});var xyt=s(Phe);c1o=r(xyt,"resnet"),xyt.forEach(t),f1o=r(zqe," \u2014 "),Lj=n(zqe,"A",{href:!0});var $yt=s(Lj);g1o=r($yt,"ResNetConfig"),$yt.forEach(t),h1o=r(zqe," (ResNet model)"),zqe.forEach(t),u1o=i(L),Nh=n(L,"LI",{});var Qqe=s(Nh);Bhe=n(Qqe,"STRONG",{});var kyt=s(Bhe);p1o=r(kyt,"retribert"),kyt.forEach(t),_1o=r(Qqe," \u2014 "),yj=n(Qqe,"A",{href:!0});var Syt=s(yj);b1o=r(Syt,"RetriBertConfig"),Syt.forEach(t),v1o=r(Qqe," (RetriBERT model)"),Qqe.forEach(t),F1o=i(L),qh=n(L,"LI",{});var Wqe=s(qh);Ihe=n(Wqe,"STRONG",{});var Ryt=s(Ihe);T1o=r(Ryt,"roberta"),Ryt.forEach(t),M1o=r(Wqe," \u2014 "),xj=n(Wqe,"A",{href:!0});var Pyt=s(xj);E1o=r(Pyt,"RobertaConfig"),Pyt.forEach(t),C1o=r(Wqe," (RoBERTa model)"),Wqe.forEach(t),w1o=i(L),jh=n(L,"LI",{});var Uqe=s(jh);Nhe=n(Uqe,"STRONG",{});var Byt=s(Nhe);A1o=r(Byt,"roc_bert"),Byt.forEach(t),L1o=r(Uqe," \u2014 "),$j=n(Uqe,"A",{href:!0});var Iyt=s($j);y1o=r(Iyt,"RoCBertConfig"),Iyt.forEach(t),x1o=r(Uqe," (RoCBert model)"),Uqe.forEach(t),$1o=i(L),Dh=n(L,"LI",{});var Hqe=s(Dh);qhe=n(Hqe,"STRONG",{});var Nyt=s(qhe);k1o=r(Nyt,"roformer"),Nyt.forEach(t),S1o=r(Hqe," \u2014 "),kj=n(Hqe,"A",{href:!0});var qyt=s(kj);R1o=r(qyt,"RoFormerConfig"),qyt.forEach(t),P1o=r(Hqe," (RoFormer model)"),Hqe.forEach(t),B1o=i(L),Gh=n(L,"LI",{});var Jqe=s(Gh);jhe=n(Jqe,"STRONG",{});var jyt=s(jhe);I1o=r(jyt,"segformer"),jyt.forEach(t),N1o=r(Jqe," \u2014 "),Sj=n(Jqe,"A",{href:!0});var Dyt=s(Sj);q1o=r(Dyt,"SegformerConfig"),Dyt.forEach(t),j1o=r(Jqe," (SegFormer model)"),Jqe.forEach(t),D1o=i(L),Oh=n(L,"LI",{});var Yqe=s(Oh);Dhe=n(Yqe,"STRONG",{});var Gyt=s(Dhe);G1o=r(Gyt,"sew"),Gyt.forEach(t),O1o=r(Yqe," \u2014 "),Rj=n(Yqe,"A",{href:!0});var Oyt=s(Rj);V1o=r(Oyt,"SEWConfig"),Oyt.forEach(t),X1o=r(Yqe," (SEW model)"),Yqe.forEach(t),z1o=i(L),Vh=n(L,"LI",{});var Zqe=s(Vh);Ghe=n(Zqe,"STRONG",{});var Vyt=s(Ghe);Q1o=r(Vyt,"sew-d"),Vyt.forEach(t),W1o=r(Zqe," \u2014 "),Pj=n(Zqe,"A",{href:!0});var Xyt=s(Pj);U1o=r(Xyt,"SEWDConfig"),Xyt.forEach(t),H1o=r(Zqe," (SEW-D model)"),Zqe.forEach(t),J1o=i(L),Xh=n(L,"LI",{});var Kqe=s(Xh);Ohe=n(Kqe,"STRONG",{});var zyt=s(Ohe);Y1o=r(zyt,"speech-encoder-decoder"),zyt.forEach(t),Z1o=r(Kqe," \u2014 "),Bj=n(Kqe,"A",{href:!0});var Qyt=s(Bj);K1o=r(Qyt,"SpeechEncoderDecoderConfig"),Qyt.forEach(t),e2o=r(Kqe," (Speech Encoder decoder model)"),Kqe.forEach(t),o2o=i(L),zh=n(L,"LI",{});var eje=s(zh);Vhe=n(eje,"STRONG",{});var Wyt=s(Vhe);r2o=r(Wyt,"speech_to_text"),Wyt.forEach(t),t2o=r(eje," \u2014 "),Ij=n(eje,"A",{href:!0});var Uyt=s(Ij);a2o=r(Uyt,"Speech2TextConfig"),Uyt.forEach(t),n2o=r(eje," (Speech2Text model)"),eje.forEach(t),s2o=i(L),Qh=n(L,"LI",{});var oje=s(Qh);Xhe=n(oje,"STRONG",{});var Hyt=s(Xhe);l2o=r(Hyt,"speech_to_text_2"),Hyt.forEach(t),i2o=r(oje," \u2014 "),Nj=n(oje,"A",{href:!0});var Jyt=s(Nj);d2o=r(Jyt,"Speech2Text2Config"),Jyt.forEach(t),m2o=r(oje," (Speech2Text2 model)"),oje.forEach(t),c2o=i(L),Wh=n(L,"LI",{});var rje=s(Wh);zhe=n(rje,"STRONG",{});var Yyt=s(zhe);f2o=r(Yyt,"splinter"),Yyt.forEach(t),g2o=r(rje," \u2014 "),qj=n(rje,"A",{href:!0});var Zyt=s(qj);h2o=r(Zyt,"SplinterConfig"),Zyt.forEach(t),u2o=r(rje," (Splinter model)"),rje.forEach(t),p2o=i(L),Uh=n(L,"LI",{});var tje=s(Uh);Qhe=n(tje,"STRONG",{});var Kyt=s(Qhe);_2o=r(Kyt,"squeezebert"),Kyt.forEach(t),b2o=r(tje," \u2014 "),jj=n(tje,"A",{href:!0});var e9t=s(jj);v2o=r(e9t,"SqueezeBertConfig"),e9t.forEach(t),F2o=r(tje," (SqueezeBERT model)"),tje.forEach(t),T2o=i(L),Hh=n(L,"LI",{});var aje=s(Hh);Whe=n(aje,"STRONG",{});var o9t=s(Whe);M2o=r(o9t,"swin"),o9t.forEach(t),E2o=r(aje," \u2014 "),Dj=n(aje,"A",{href:!0});var r9t=s(Dj);C2o=r(r9t,"SwinConfig"),r9t.forEach(t),w2o=r(aje," (Swin Transformer model)"),aje.forEach(t),A2o=i(L),Jh=n(L,"LI",{});var nje=s(Jh);Uhe=n(nje,"STRONG",{});var t9t=s(Uhe);L2o=r(t9t,"swinv2"),t9t.forEach(t),y2o=r(nje," \u2014 "),Gj=n(nje,"A",{href:!0});var a9t=s(Gj);x2o=r(a9t,"Swinv2Config"),a9t.forEach(t),$2o=r(nje," (Swin Transformer V2 model)"),nje.forEach(t),k2o=i(L),Yh=n(L,"LI",{});var sje=s(Yh);Hhe=n(sje,"STRONG",{});var n9t=s(Hhe);S2o=r(n9t,"t5"),n9t.forEach(t),R2o=r(sje," \u2014 "),Oj=n(sje,"A",{href:!0});var s9t=s(Oj);P2o=r(s9t,"T5Config"),s9t.forEach(t),B2o=r(sje," (T5 model)"),sje.forEach(t),I2o=i(L),Zh=n(L,"LI",{});var lje=s(Zh);Jhe=n(lje,"STRONG",{});var l9t=s(Jhe);N2o=r(l9t,"table-transformer"),l9t.forEach(t),q2o=r(lje," \u2014 "),Vj=n(lje,"A",{href:!0});var i9t=s(Vj);j2o=r(i9t,"TableTransformerConfig"),i9t.forEach(t),D2o=r(lje," (Table Transformer model)"),lje.forEach(t),G2o=i(L),Kh=n(L,"LI",{});var ije=s(Kh);Yhe=n(ije,"STRONG",{});var d9t=s(Yhe);O2o=r(d9t,"tapas"),d9t.forEach(t),V2o=r(ije," \u2014 "),Xj=n(ije,"A",{href:!0});var m9t=s(Xj);X2o=r(m9t,"TapasConfig"),m9t.forEach(t),z2o=r(ije," (TAPAS model)"),ije.forEach(t),Q2o=i(L),eu=n(L,"LI",{});var dje=s(eu);Zhe=n(dje,"STRONG",{});var c9t=s(Zhe);W2o=r(c9t,"time_series_transformer"),c9t.forEach(t),U2o=r(dje," \u2014 "),zj=n(dje,"A",{href:!0});var f9t=s(zj);H2o=r(f9t,"TimeSeriesTransformerConfig"),f9t.forEach(t),J2o=r(dje," (Time Series Transformer model)"),dje.forEach(t),Y2o=i(L),ou=n(L,"LI",{});var mje=s(ou);Khe=n(mje,"STRONG",{});var g9t=s(Khe);Z2o=r(g9t,"trajectory_transformer"),g9t.forEach(t),K2o=r(mje," \u2014 "),Qj=n(mje,"A",{href:!0});var h9t=s(Qj);ebo=r(h9t,"TrajectoryTransformerConfig"),h9t.forEach(t),obo=r(mje," (Trajectory Transformer model)"),mje.forEach(t),rbo=i(L),ru=n(L,"LI",{});var cje=s(ru);eue=n(cje,"STRONG",{});var u9t=s(eue);tbo=r(u9t,"transfo-xl"),u9t.forEach(t),abo=r(cje," \u2014 "),Wj=n(cje,"A",{href:!0});var p9t=s(Wj);nbo=r(p9t,"TransfoXLConfig"),p9t.forEach(t),sbo=r(cje," (Transformer-XL model)"),cje.forEach(t),lbo=i(L),tu=n(L,"LI",{});var fje=s(tu);oue=n(fje,"STRONG",{});var _9t=s(oue);ibo=r(_9t,"trocr"),_9t.forEach(t),dbo=r(fje," \u2014 "),Uj=n(fje,"A",{href:!0});var b9t=s(Uj);mbo=r(b9t,"TrOCRConfig"),b9t.forEach(t),cbo=r(fje," (TrOCR model)"),fje.forEach(t),fbo=i(L),au=n(L,"LI",{});var gje=s(au);rue=n(gje,"STRONG",{});var v9t=s(rue);gbo=r(v9t,"unispeech"),v9t.forEach(t),hbo=r(gje," \u2014 "),Hj=n(gje,"A",{href:!0});var F9t=s(Hj);ubo=r(F9t,"UniSpeechConfig"),F9t.forEach(t),pbo=r(gje," (UniSpeech model)"),gje.forEach(t),_bo=i(L),nu=n(L,"LI",{});var hje=s(nu);tue=n(hje,"STRONG",{});var T9t=s(tue);bbo=r(T9t,"unispeech-sat"),T9t.forEach(t),vbo=r(hje," \u2014 "),Jj=n(hje,"A",{href:!0});var M9t=s(Jj);Fbo=r(M9t,"UniSpeechSatConfig"),M9t.forEach(t),Tbo=r(hje," (UniSpeechSat model)"),hje.forEach(t),Mbo=i(L),su=n(L,"LI",{});var uje=s(su);aue=n(uje,"STRONG",{});var E9t=s(aue);Ebo=r(E9t,"van"),E9t.forEach(t),Cbo=r(uje," \u2014 "),Yj=n(uje,"A",{href:!0});var C9t=s(Yj);wbo=r(C9t,"VanConfig"),C9t.forEach(t),Abo=r(uje," (VAN model)"),uje.forEach(t),Lbo=i(L),lu=n(L,"LI",{});var pje=s(lu);nue=n(pje,"STRONG",{});var w9t=s(nue);ybo=r(w9t,"videomae"),w9t.forEach(t),xbo=r(pje," \u2014 "),Zj=n(pje,"A",{href:!0});var A9t=s(Zj);$bo=r(A9t,"VideoMAEConfig"),A9t.forEach(t),kbo=r(pje," (VideoMAE model)"),pje.forEach(t),Sbo=i(L),iu=n(L,"LI",{});var _je=s(iu);sue=n(_je,"STRONG",{});var L9t=s(sue);Rbo=r(L9t,"vilt"),L9t.forEach(t),Pbo=r(_je," \u2014 "),Kj=n(_je,"A",{href:!0});var y9t=s(Kj);Bbo=r(y9t,"ViltConfig"),y9t.forEach(t),Ibo=r(_je," (ViLT model)"),_je.forEach(t),Nbo=i(L),du=n(L,"LI",{});var bje=s(du);lue=n(bje,"STRONG",{});var x9t=s(lue);qbo=r(x9t,"vision-encoder-decoder"),x9t.forEach(t),jbo=r(bje," \u2014 "),eD=n(bje,"A",{href:!0});var $9t=s(eD);Dbo=r($9t,"VisionEncoderDecoderConfig"),$9t.forEach(t),Gbo=r(bje," (Vision Encoder decoder model)"),bje.forEach(t),Obo=i(L),mu=n(L,"LI",{});var vje=s(mu);iue=n(vje,"STRONG",{});var k9t=s(iue);Vbo=r(k9t,"vision-text-dual-encoder"),k9t.forEach(t),Xbo=r(vje," \u2014 "),oD=n(vje,"A",{href:!0});var S9t=s(oD);zbo=r(S9t,"VisionTextDualEncoderConfig"),S9t.forEach(t),Qbo=r(vje," (VisionTextDualEncoder model)"),vje.forEach(t),Wbo=i(L),cu=n(L,"LI",{});var Fje=s(cu);due=n(Fje,"STRONG",{});var R9t=s(due);Ubo=r(R9t,"visual_bert"),R9t.forEach(t),Hbo=r(Fje," \u2014 "),rD=n(Fje,"A",{href:!0});var P9t=s(rD);Jbo=r(P9t,"VisualBertConfig"),P9t.forEach(t),Ybo=r(Fje," (VisualBERT model)"),Fje.forEach(t),Zbo=i(L),fu=n(L,"LI",{});var Tje=s(fu);mue=n(Tje,"STRONG",{});var B9t=s(mue);Kbo=r(B9t,"vit"),B9t.forEach(t),evo=r(Tje," \u2014 "),tD=n(Tje,"A",{href:!0});var I9t=s(tD);ovo=r(I9t,"ViTConfig"),I9t.forEach(t),rvo=r(Tje," (ViT model)"),Tje.forEach(t),tvo=i(L),gu=n(L,"LI",{});var Mje=s(gu);cue=n(Mje,"STRONG",{});var N9t=s(cue);avo=r(N9t,"vit_mae"),N9t.forEach(t),nvo=r(Mje," \u2014 "),aD=n(Mje,"A",{href:!0});var q9t=s(aD);svo=r(q9t,"ViTMAEConfig"),q9t.forEach(t),lvo=r(Mje," (ViTMAE model)"),Mje.forEach(t),ivo=i(L),hu=n(L,"LI",{});var Eje=s(hu);fue=n(Eje,"STRONG",{});var j9t=s(fue);dvo=r(j9t,"vit_msn"),j9t.forEach(t),mvo=r(Eje," \u2014 "),nD=n(Eje,"A",{href:!0});var D9t=s(nD);cvo=r(D9t,"ViTMSNConfig"),D9t.forEach(t),fvo=r(Eje," (ViTMSN model)"),Eje.forEach(t),gvo=i(L),uu=n(L,"LI",{});var Cje=s(uu);gue=n(Cje,"STRONG",{});var G9t=s(gue);hvo=r(G9t,"wav2vec2"),G9t.forEach(t),uvo=r(Cje," \u2014 "),sD=n(Cje,"A",{href:!0});var O9t=s(sD);pvo=r(O9t,"Wav2Vec2Config"),O9t.forEach(t),_vo=r(Cje," (Wav2Vec2 model)"),Cje.forEach(t),bvo=i(L),pu=n(L,"LI",{});var wje=s(pu);hue=n(wje,"STRONG",{});var V9t=s(hue);vvo=r(V9t,"wav2vec2-conformer"),V9t.forEach(t),Fvo=r(wje," \u2014 "),lD=n(wje,"A",{href:!0});var X9t=s(lD);Tvo=r(X9t,"Wav2Vec2ConformerConfig"),X9t.forEach(t),Mvo=r(wje," (Wav2Vec2-Conformer model)"),wje.forEach(t),Evo=i(L),_u=n(L,"LI",{});var Aje=s(_u);uue=n(Aje,"STRONG",{});var z9t=s(uue);Cvo=r(z9t,"wavlm"),z9t.forEach(t),wvo=r(Aje," \u2014 "),iD=n(Aje,"A",{href:!0});var Q9t=s(iD);Avo=r(Q9t,"WavLMConfig"),Q9t.forEach(t),Lvo=r(Aje," (WavLM model)"),Aje.forEach(t),yvo=i(L),bu=n(L,"LI",{});var Lje=s(bu);pue=n(Lje,"STRONG",{});var W9t=s(pue);xvo=r(W9t,"whisper"),W9t.forEach(t),$vo=r(Lje," \u2014 "),dD=n(Lje,"A",{href:!0});var U9t=s(dD);kvo=r(U9t,"WhisperConfig"),U9t.forEach(t),Svo=r(Lje," (Whisper model)"),Lje.forEach(t),Rvo=i(L),vu=n(L,"LI",{});var yje=s(vu);_ue=n(yje,"STRONG",{});var H9t=s(_ue);Pvo=r(H9t,"xclip"),H9t.forEach(t),Bvo=r(yje," \u2014 "),mD=n(yje,"A",{href:!0});var J9t=s(mD);Ivo=r(J9t,"XCLIPConfig"),J9t.forEach(t),Nvo=r(yje," (X-CLIP model)"),yje.forEach(t),qvo=i(L),Fu=n(L,"LI",{});var xje=s(Fu);bue=n(xje,"STRONG",{});var Y9t=s(bue);jvo=r(Y9t,"xglm"),Y9t.forEach(t),Dvo=r(xje," \u2014 "),cD=n(xje,"A",{href:!0});var Z9t=s(cD);Gvo=r(Z9t,"XGLMConfig"),Z9t.forEach(t),Ovo=r(xje," (XGLM model)"),xje.forEach(t),Vvo=i(L),Tu=n(L,"LI",{});var $je=s(Tu);vue=n($je,"STRONG",{});var K9t=s(vue);Xvo=r(K9t,"xlm"),K9t.forEach(t),zvo=r($je," \u2014 "),fD=n($je,"A",{href:!0});var ext=s(fD);Qvo=r(ext,"XLMConfig"),ext.forEach(t),Wvo=r($je," (XLM model)"),$je.forEach(t),Uvo=i(L),Mu=n(L,"LI",{});var kje=s(Mu);Fue=n(kje,"STRONG",{});var oxt=s(Fue);Hvo=r(oxt,"xlm-prophetnet"),oxt.forEach(t),Jvo=r(kje," \u2014 "),gD=n(kje,"A",{href:!0});var rxt=s(gD);Yvo=r(rxt,"XLMProphetNetConfig"),rxt.forEach(t),Zvo=r(kje," (XLM-ProphetNet model)"),kje.forEach(t),Kvo=i(L),Eu=n(L,"LI",{});var Sje=s(Eu);Tue=n(Sje,"STRONG",{});var txt=s(Tue);eFo=r(txt,"xlm-roberta"),txt.forEach(t),oFo=r(Sje," \u2014 "),hD=n(Sje,"A",{href:!0});var axt=s(hD);rFo=r(axt,"XLMRobertaConfig"),axt.forEach(t),tFo=r(Sje," (XLM-RoBERTa model)"),Sje.forEach(t),aFo=i(L),Cu=n(L,"LI",{});var Rje=s(Cu);Mue=n(Rje,"STRONG",{});var nxt=s(Mue);nFo=r(nxt,"xlm-roberta-xl"),nxt.forEach(t),sFo=r(Rje," \u2014 "),uD=n(Rje,"A",{href:!0});var sxt=s(uD);lFo=r(sxt,"XLMRobertaXLConfig"),sxt.forEach(t),iFo=r(Rje," (XLM-RoBERTa-XL model)"),Rje.forEach(t),dFo=i(L),wu=n(L,"LI",{});var Pje=s(wu);Eue=n(Pje,"STRONG",{});var lxt=s(Eue);mFo=r(lxt,"xlnet"),lxt.forEach(t),cFo=r(Pje," \u2014 "),pD=n(Pje,"A",{href:!0});var ixt=s(pD);fFo=r(ixt,"XLNetConfig"),ixt.forEach(t),gFo=r(Pje," (XLNet model)"),Pje.forEach(t),hFo=i(L),Au=n(L,"LI",{});var Bje=s(Au);Cue=n(Bje,"STRONG",{});var dxt=s(Cue);uFo=r(dxt,"yolos"),dxt.forEach(t),pFo=r(Bje," \u2014 "),_D=n(Bje,"A",{href:!0});var mxt=s(_D);_Fo=r(mxt,"YolosConfig"),mxt.forEach(t),bFo=r(Bje," (YOLOS model)"),Bje.forEach(t),vFo=i(L),Lu=n(L,"LI",{});var Ije=s(Lu);wue=n(Ije,"STRONG",{});var cxt=s(wue);FFo=r(cxt,"yoso"),cxt.forEach(t),TFo=r(Ije," \u2014 "),bD=n(Ije,"A",{href:!0});var fxt=s(bD);MFo=r(fxt,"YosoConfig"),fxt.forEach(t),EFo=r(Ije," (YOSO model)"),Ije.forEach(t),L.forEach(t),CFo=i(Ft),T(yu.$$.fragment,Ft),Ft.forEach(t),wFo=i(vt),xu=n(vt,"DIV",{class:!0});var Qso=s(xu);T($$.$$.fragment,Qso),AFo=i(Qso),Aue=n(Qso,"P",{});var gxt=s(Aue);LFo=r(gxt,"Register a new configuration for this class."),gxt.forEach(t),Qso.forEach(t),vt.forEach(t),Bao=i(c),xd=n(c,"H2",{class:!0});var Wso=s(xd);$u=n(Wso,"A",{id:!0,class:!0,href:!0});var hxt=s($u);Lue=n(hxt,"SPAN",{});var uxt=s(Lue);T(k$.$$.fragment,uxt),uxt.forEach(t),hxt.forEach(t),yFo=i(Wso),yue=n(Wso,"SPAN",{});var pxt=s(yue);xFo=r(pxt,"AutoTokenizer"),pxt.forEach(t),Wso.forEach(t),Iao=i(c),Ro=n(c,"DIV",{class:!0});var Bl=s(Ro);T(S$.$$.fragment,Bl),$Fo=i(Bl),R$=n(Bl,"P",{});var Uso=s(R$);kFo=r(Uso,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),vD=n(Uso,"A",{href:!0});var _xt=s(vD);SFo=r(_xt,"AutoTokenizer.from_pretrained()"),_xt.forEach(t),RFo=r(Uso," class method."),Uso.forEach(t),PFo=i(Bl),P$=n(Bl,"P",{});var Hso=s(P$);BFo=r(Hso,"This class cannot be instantiated directly using "),xue=n(Hso,"CODE",{});var bxt=s(xue);IFo=r(bxt,"__init__()"),bxt.forEach(t),NFo=r(Hso," (throws an error)."),Hso.forEach(t),qFo=i(Bl),jr=n(Bl,"DIV",{class:!0});var Il=s(jr);T(B$.$$.fragment,Il),jFo=i(Il),$ue=n(Il,"P",{});var vxt=s($ue);DFo=r(vxt,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),vxt.forEach(t),GFo=i(Il),tn=n(Il,"P",{});var f9=s(tn);OFo=r(f9,"The tokenizer class to instantiate is selected based on the "),kue=n(f9,"CODE",{});var Fxt=s(kue);VFo=r(Fxt,"model_type"),Fxt.forEach(t),XFo=r(f9,` property of the config object (either
passed as an argument or loaded from `),Sue=n(f9,"CODE",{});var Txt=s(Sue);zFo=r(Txt,"pretrained_model_name_or_path"),Txt.forEach(t),QFo=r(f9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rue=n(f9,"CODE",{});var Mxt=s(Rue);WFo=r(Mxt,"pretrained_model_name_or_path"),Mxt.forEach(t),UFo=r(f9,":"),f9.forEach(t),HFo=i(Il),k=n(Il,"UL",{});var S=s(k);us=n(S,"LI",{});var _I=s(us);Pue=n(_I,"STRONG",{});var Ext=s(Pue);JFo=r(Ext,"albert"),Ext.forEach(t),YFo=r(_I," \u2014 "),FD=n(_I,"A",{href:!0});var Cxt=s(FD);ZFo=r(Cxt,"AlbertTokenizer"),Cxt.forEach(t),KFo=r(_I," or "),TD=n(_I,"A",{href:!0});var wxt=s(TD);eTo=r(wxt,"AlbertTokenizerFast"),wxt.forEach(t),oTo=r(_I," (ALBERT model)"),_I.forEach(t),rTo=i(S),ps=n(S,"LI",{});var bI=s(ps);Bue=n(bI,"STRONG",{});var Axt=s(Bue);tTo=r(Axt,"bart"),Axt.forEach(t),aTo=r(bI," \u2014 "),MD=n(bI,"A",{href:!0});var Lxt=s(MD);nTo=r(Lxt,"BartTokenizer"),Lxt.forEach(t),sTo=r(bI," or "),ED=n(bI,"A",{href:!0});var yxt=s(ED);lTo=r(yxt,"BartTokenizerFast"),yxt.forEach(t),iTo=r(bI," (BART model)"),bI.forEach(t),dTo=i(S),_s=n(S,"LI",{});var vI=s(_s);Iue=n(vI,"STRONG",{});var xxt=s(Iue);mTo=r(xxt,"barthez"),xxt.forEach(t),cTo=r(vI," \u2014 "),CD=n(vI,"A",{href:!0});var $xt=s(CD);fTo=r($xt,"BarthezTokenizer"),$xt.forEach(t),gTo=r(vI," or "),wD=n(vI,"A",{href:!0});var kxt=s(wD);hTo=r(kxt,"BarthezTokenizerFast"),kxt.forEach(t),uTo=r(vI," (BARThez model)"),vI.forEach(t),pTo=i(S),ku=n(S,"LI",{});var Nje=s(ku);Nue=n(Nje,"STRONG",{});var Sxt=s(Nue);_To=r(Sxt,"bartpho"),Sxt.forEach(t),bTo=r(Nje," \u2014 "),AD=n(Nje,"A",{href:!0});var Rxt=s(AD);vTo=r(Rxt,"BartphoTokenizer"),Rxt.forEach(t),FTo=r(Nje," (BARTpho model)"),Nje.forEach(t),TTo=i(S),bs=n(S,"LI",{});var FI=s(bs);que=n(FI,"STRONG",{});var Pxt=s(que);MTo=r(Pxt,"bert"),Pxt.forEach(t),ETo=r(FI," \u2014 "),LD=n(FI,"A",{href:!0});var Bxt=s(LD);CTo=r(Bxt,"BertTokenizer"),Bxt.forEach(t),wTo=r(FI," or "),yD=n(FI,"A",{href:!0});var Ixt=s(yD);ATo=r(Ixt,"BertTokenizerFast"),Ixt.forEach(t),LTo=r(FI," (BERT model)"),FI.forEach(t),yTo=i(S),Su=n(S,"LI",{});var qje=s(Su);jue=n(qje,"STRONG",{});var Nxt=s(jue);xTo=r(Nxt,"bert-generation"),Nxt.forEach(t),$To=r(qje," \u2014 "),xD=n(qje,"A",{href:!0});var qxt=s(xD);kTo=r(qxt,"BertGenerationTokenizer"),qxt.forEach(t),STo=r(qje," (Bert Generation model)"),qje.forEach(t),RTo=i(S),Ru=n(S,"LI",{});var jje=s(Ru);Due=n(jje,"STRONG",{});var jxt=s(Due);PTo=r(jxt,"bert-japanese"),jxt.forEach(t),BTo=r(jje," \u2014 "),$D=n(jje,"A",{href:!0});var Dxt=s($D);ITo=r(Dxt,"BertJapaneseTokenizer"),Dxt.forEach(t),NTo=r(jje," (BertJapanese model)"),jje.forEach(t),qTo=i(S),Pu=n(S,"LI",{});var Dje=s(Pu);Gue=n(Dje,"STRONG",{});var Gxt=s(Gue);jTo=r(Gxt,"bertweet"),Gxt.forEach(t),DTo=r(Dje," \u2014 "),kD=n(Dje,"A",{href:!0});var Oxt=s(kD);GTo=r(Oxt,"BertweetTokenizer"),Oxt.forEach(t),OTo=r(Dje," (BERTweet model)"),Dje.forEach(t),VTo=i(S),vs=n(S,"LI",{});var TI=s(vs);Oue=n(TI,"STRONG",{});var Vxt=s(Oue);XTo=r(Vxt,"big_bird"),Vxt.forEach(t),zTo=r(TI," \u2014 "),SD=n(TI,"A",{href:!0});var Xxt=s(SD);QTo=r(Xxt,"BigBirdTokenizer"),Xxt.forEach(t),WTo=r(TI," or "),RD=n(TI,"A",{href:!0});var zxt=s(RD);UTo=r(zxt,"BigBirdTokenizerFast"),zxt.forEach(t),HTo=r(TI," (BigBird model)"),TI.forEach(t),JTo=i(S),Fs=n(S,"LI",{});var MI=s(Fs);Vue=n(MI,"STRONG",{});var Qxt=s(Vue);YTo=r(Qxt,"bigbird_pegasus"),Qxt.forEach(t),ZTo=r(MI," \u2014 "),PD=n(MI,"A",{href:!0});var Wxt=s(PD);KTo=r(Wxt,"PegasusTokenizer"),Wxt.forEach(t),eMo=r(MI," or "),BD=n(MI,"A",{href:!0});var Uxt=s(BD);oMo=r(Uxt,"PegasusTokenizerFast"),Uxt.forEach(t),rMo=r(MI," (BigBird-Pegasus model)"),MI.forEach(t),tMo=i(S),Ts=n(S,"LI",{});var EI=s(Ts);Xue=n(EI,"STRONG",{});var Hxt=s(Xue);aMo=r(Hxt,"blenderbot"),Hxt.forEach(t),nMo=r(EI," \u2014 "),ID=n(EI,"A",{href:!0});var Jxt=s(ID);sMo=r(Jxt,"BlenderbotTokenizer"),Jxt.forEach(t),lMo=r(EI," or "),ND=n(EI,"A",{href:!0});var Yxt=s(ND);iMo=r(Yxt,"BlenderbotTokenizerFast"),Yxt.forEach(t),dMo=r(EI," (Blenderbot model)"),EI.forEach(t),mMo=i(S),Bu=n(S,"LI",{});var Gje=s(Bu);zue=n(Gje,"STRONG",{});var Zxt=s(zue);cMo=r(Zxt,"blenderbot-small"),Zxt.forEach(t),fMo=r(Gje," \u2014 "),qD=n(Gje,"A",{href:!0});var Kxt=s(qD);gMo=r(Kxt,"BlenderbotSmallTokenizer"),Kxt.forEach(t),hMo=r(Gje," (BlenderbotSmall model)"),Gje.forEach(t),uMo=i(S),Iu=n(S,"LI",{});var Oje=s(Iu);Que=n(Oje,"STRONG",{});var e$t=s(Que);pMo=r(e$t,"bloom"),e$t.forEach(t),_Mo=r(Oje," \u2014 "),jD=n(Oje,"A",{href:!0});var o$t=s(jD);bMo=r(o$t,"BloomTokenizerFast"),o$t.forEach(t),vMo=r(Oje," (BLOOM model)"),Oje.forEach(t),FMo=i(S),Nu=n(S,"LI",{});var Vje=s(Nu);Wue=n(Vje,"STRONG",{});var r$t=s(Wue);TMo=r(r$t,"byt5"),r$t.forEach(t),MMo=r(Vje," \u2014 "),DD=n(Vje,"A",{href:!0});var t$t=s(DD);EMo=r(t$t,"ByT5Tokenizer"),t$t.forEach(t),CMo=r(Vje," (ByT5 model)"),Vje.forEach(t),wMo=i(S),Ms=n(S,"LI",{});var CI=s(Ms);Uue=n(CI,"STRONG",{});var a$t=s(Uue);AMo=r(a$t,"camembert"),a$t.forEach(t),LMo=r(CI," \u2014 "),GD=n(CI,"A",{href:!0});var n$t=s(GD);yMo=r(n$t,"CamembertTokenizer"),n$t.forEach(t),xMo=r(CI," or "),OD=n(CI,"A",{href:!0});var s$t=s(OD);$Mo=r(s$t,"CamembertTokenizerFast"),s$t.forEach(t),kMo=r(CI," (CamemBERT model)"),CI.forEach(t),SMo=i(S),qu=n(S,"LI",{});var Xje=s(qu);Hue=n(Xje,"STRONG",{});var l$t=s(Hue);RMo=r(l$t,"canine"),l$t.forEach(t),PMo=r(Xje," \u2014 "),VD=n(Xje,"A",{href:!0});var i$t=s(VD);BMo=r(i$t,"CanineTokenizer"),i$t.forEach(t),IMo=r(Xje," (CANINE model)"),Xje.forEach(t),NMo=i(S),Es=n(S,"LI",{});var wI=s(Es);Jue=n(wI,"STRONG",{});var d$t=s(Jue);qMo=r(d$t,"clip"),d$t.forEach(t),jMo=r(wI," \u2014 "),XD=n(wI,"A",{href:!0});var m$t=s(XD);DMo=r(m$t,"CLIPTokenizer"),m$t.forEach(t),GMo=r(wI," or "),zD=n(wI,"A",{href:!0});var c$t=s(zD);OMo=r(c$t,"CLIPTokenizerFast"),c$t.forEach(t),VMo=r(wI," (CLIP model)"),wI.forEach(t),XMo=i(S),Cs=n(S,"LI",{});var AI=s(Cs);Yue=n(AI,"STRONG",{});var f$t=s(Yue);zMo=r(f$t,"clipseg"),f$t.forEach(t),QMo=r(AI," \u2014 "),QD=n(AI,"A",{href:!0});var g$t=s(QD);WMo=r(g$t,"CLIPTokenizer"),g$t.forEach(t),UMo=r(AI," or "),WD=n(AI,"A",{href:!0});var h$t=s(WD);HMo=r(h$t,"CLIPTokenizerFast"),h$t.forEach(t),JMo=r(AI," (CLIPSeg model)"),AI.forEach(t),YMo=i(S),ws=n(S,"LI",{});var LI=s(ws);Zue=n(LI,"STRONG",{});var u$t=s(Zue);ZMo=r(u$t,"codegen"),u$t.forEach(t),KMo=r(LI," \u2014 "),UD=n(LI,"A",{href:!0});var p$t=s(UD);eEo=r(p$t,"CodeGenTokenizer"),p$t.forEach(t),oEo=r(LI," or "),HD=n(LI,"A",{href:!0});var _$t=s(HD);rEo=r(_$t,"CodeGenTokenizerFast"),_$t.forEach(t),tEo=r(LI," (CodeGen model)"),LI.forEach(t),aEo=i(S),As=n(S,"LI",{});var yI=s(As);Kue=n(yI,"STRONG",{});var b$t=s(Kue);nEo=r(b$t,"convbert"),b$t.forEach(t),sEo=r(yI," \u2014 "),JD=n(yI,"A",{href:!0});var v$t=s(JD);lEo=r(v$t,"ConvBertTokenizer"),v$t.forEach(t),iEo=r(yI," or "),YD=n(yI,"A",{href:!0});var F$t=s(YD);dEo=r(F$t,"ConvBertTokenizerFast"),F$t.forEach(t),mEo=r(yI," (ConvBERT model)"),yI.forEach(t),cEo=i(S),Ls=n(S,"LI",{});var xI=s(Ls);epe=n(xI,"STRONG",{});var T$t=s(epe);fEo=r(T$t,"cpm"),T$t.forEach(t),gEo=r(xI," \u2014 "),ZD=n(xI,"A",{href:!0});var M$t=s(ZD);hEo=r(M$t,"CpmTokenizer"),M$t.forEach(t),uEo=r(xI," or "),KD=n(xI,"A",{href:!0});var E$t=s(KD);pEo=r(E$t,"CpmTokenizerFast"),E$t.forEach(t),_Eo=r(xI," (CPM model)"),xI.forEach(t),bEo=i(S),ju=n(S,"LI",{});var zje=s(ju);ope=n(zje,"STRONG",{});var C$t=s(ope);vEo=r(C$t,"ctrl"),C$t.forEach(t),FEo=r(zje," \u2014 "),eG=n(zje,"A",{href:!0});var w$t=s(eG);TEo=r(w$t,"CTRLTokenizer"),w$t.forEach(t),MEo=r(zje," (CTRL model)"),zje.forEach(t),EEo=i(S),ys=n(S,"LI",{});var $I=s(ys);rpe=n($I,"STRONG",{});var A$t=s(rpe);CEo=r(A$t,"data2vec-text"),A$t.forEach(t),wEo=r($I," \u2014 "),oG=n($I,"A",{href:!0});var L$t=s(oG);AEo=r(L$t,"RobertaTokenizer"),L$t.forEach(t),LEo=r($I," or "),rG=n($I,"A",{href:!0});var y$t=s(rG);yEo=r(y$t,"RobertaTokenizerFast"),y$t.forEach(t),xEo=r($I," (Data2VecText model)"),$I.forEach(t),$Eo=i(S),xs=n(S,"LI",{});var kI=s(xs);tpe=n(kI,"STRONG",{});var x$t=s(tpe);kEo=r(x$t,"deberta"),x$t.forEach(t),SEo=r(kI," \u2014 "),tG=n(kI,"A",{href:!0});var $$t=s(tG);REo=r($$t,"DebertaTokenizer"),$$t.forEach(t),PEo=r(kI," or "),aG=n(kI,"A",{href:!0});var k$t=s(aG);BEo=r(k$t,"DebertaTokenizerFast"),k$t.forEach(t),IEo=r(kI," (DeBERTa model)"),kI.forEach(t),NEo=i(S),$s=n(S,"LI",{});var SI=s($s);ape=n(SI,"STRONG",{});var S$t=s(ape);qEo=r(S$t,"deberta-v2"),S$t.forEach(t),jEo=r(SI," \u2014 "),nG=n(SI,"A",{href:!0});var R$t=s(nG);DEo=r(R$t,"DebertaV2Tokenizer"),R$t.forEach(t),GEo=r(SI," or "),sG=n(SI,"A",{href:!0});var P$t=s(sG);OEo=r(P$t,"DebertaV2TokenizerFast"),P$t.forEach(t),VEo=r(SI," (DeBERTa-v2 model)"),SI.forEach(t),XEo=i(S),ks=n(S,"LI",{});var RI=s(ks);npe=n(RI,"STRONG",{});var B$t=s(npe);zEo=r(B$t,"distilbert"),B$t.forEach(t),QEo=r(RI," \u2014 "),lG=n(RI,"A",{href:!0});var I$t=s(lG);WEo=r(I$t,"DistilBertTokenizer"),I$t.forEach(t),UEo=r(RI," or "),iG=n(RI,"A",{href:!0});var N$t=s(iG);HEo=r(N$t,"DistilBertTokenizerFast"),N$t.forEach(t),JEo=r(RI," (DistilBERT model)"),RI.forEach(t),YEo=i(S),Ss=n(S,"LI",{});var PI=s(Ss);spe=n(PI,"STRONG",{});var q$t=s(spe);ZEo=r(q$t,"dpr"),q$t.forEach(t),KEo=r(PI," \u2014 "),dG=n(PI,"A",{href:!0});var j$t=s(dG);e4o=r(j$t,"DPRQuestionEncoderTokenizer"),j$t.forEach(t),o4o=r(PI," or "),mG=n(PI,"A",{href:!0});var D$t=s(mG);r4o=r(D$t,"DPRQuestionEncoderTokenizerFast"),D$t.forEach(t),t4o=r(PI," (DPR model)"),PI.forEach(t),a4o=i(S),Rs=n(S,"LI",{});var BI=s(Rs);lpe=n(BI,"STRONG",{});var G$t=s(lpe);n4o=r(G$t,"electra"),G$t.forEach(t),s4o=r(BI," \u2014 "),cG=n(BI,"A",{href:!0});var O$t=s(cG);l4o=r(O$t,"ElectraTokenizer"),O$t.forEach(t),i4o=r(BI," or "),fG=n(BI,"A",{href:!0});var V$t=s(fG);d4o=r(V$t,"ElectraTokenizerFast"),V$t.forEach(t),m4o=r(BI," (ELECTRA model)"),BI.forEach(t),c4o=i(S),Ps=n(S,"LI",{});var II=s(Ps);ipe=n(II,"STRONG",{});var X$t=s(ipe);f4o=r(X$t,"ernie"),X$t.forEach(t),g4o=r(II," \u2014 "),gG=n(II,"A",{href:!0});var z$t=s(gG);h4o=r(z$t,"BertTokenizer"),z$t.forEach(t),u4o=r(II," or "),hG=n(II,"A",{href:!0});var Q$t=s(hG);p4o=r(Q$t,"BertTokenizerFast"),Q$t.forEach(t),_4o=r(II," (ERNIE model)"),II.forEach(t),b4o=i(S),Du=n(S,"LI",{});var Qje=s(Du);dpe=n(Qje,"STRONG",{});var W$t=s(dpe);v4o=r(W$t,"esm"),W$t.forEach(t),F4o=r(Qje," \u2014 "),uG=n(Qje,"A",{href:!0});var U$t=s(uG);T4o=r(U$t,"EsmTokenizer"),U$t.forEach(t),M4o=r(Qje," (ESM model)"),Qje.forEach(t),E4o=i(S),Gu=n(S,"LI",{});var Wje=s(Gu);mpe=n(Wje,"STRONG",{});var H$t=s(mpe);C4o=r(H$t,"flaubert"),H$t.forEach(t),w4o=r(Wje," \u2014 "),pG=n(Wje,"A",{href:!0});var J$t=s(pG);A4o=r(J$t,"FlaubertTokenizer"),J$t.forEach(t),L4o=r(Wje," (FlauBERT model)"),Wje.forEach(t),y4o=i(S),Bs=n(S,"LI",{});var NI=s(Bs);cpe=n(NI,"STRONG",{});var Y$t=s(cpe);x4o=r(Y$t,"fnet"),Y$t.forEach(t),$4o=r(NI," \u2014 "),_G=n(NI,"A",{href:!0});var Z$t=s(_G);k4o=r(Z$t,"FNetTokenizer"),Z$t.forEach(t),S4o=r(NI," or "),bG=n(NI,"A",{href:!0});var K$t=s(bG);R4o=r(K$t,"FNetTokenizerFast"),K$t.forEach(t),P4o=r(NI," (FNet model)"),NI.forEach(t),B4o=i(S),Ou=n(S,"LI",{});var Uje=s(Ou);fpe=n(Uje,"STRONG",{});var ekt=s(fpe);I4o=r(ekt,"fsmt"),ekt.forEach(t),N4o=r(Uje," \u2014 "),vG=n(Uje,"A",{href:!0});var okt=s(vG);q4o=r(okt,"FSMTTokenizer"),okt.forEach(t),j4o=r(Uje," (FairSeq Machine-Translation model)"),Uje.forEach(t),D4o=i(S),Is=n(S,"LI",{});var qI=s(Is);gpe=n(qI,"STRONG",{});var rkt=s(gpe);G4o=r(rkt,"funnel"),rkt.forEach(t),O4o=r(qI," \u2014 "),FG=n(qI,"A",{href:!0});var tkt=s(FG);V4o=r(tkt,"FunnelTokenizer"),tkt.forEach(t),X4o=r(qI," or "),TG=n(qI,"A",{href:!0});var akt=s(TG);z4o=r(akt,"FunnelTokenizerFast"),akt.forEach(t),Q4o=r(qI," (Funnel Transformer model)"),qI.forEach(t),W4o=i(S),Ns=n(S,"LI",{});var jI=s(Ns);hpe=n(jI,"STRONG",{});var nkt=s(hpe);U4o=r(nkt,"gpt2"),nkt.forEach(t),H4o=r(jI," \u2014 "),MG=n(jI,"A",{href:!0});var skt=s(MG);J4o=r(skt,"GPT2Tokenizer"),skt.forEach(t),Y4o=r(jI," or "),EG=n(jI,"A",{href:!0});var lkt=s(EG);Z4o=r(lkt,"GPT2TokenizerFast"),lkt.forEach(t),K4o=r(jI," (OpenAI GPT-2 model)"),jI.forEach(t),eCo=i(S),qs=n(S,"LI",{});var DI=s(qs);upe=n(DI,"STRONG",{});var ikt=s(upe);oCo=r(ikt,"gpt_neo"),ikt.forEach(t),rCo=r(DI," \u2014 "),CG=n(DI,"A",{href:!0});var dkt=s(CG);tCo=r(dkt,"GPT2Tokenizer"),dkt.forEach(t),aCo=r(DI," or "),wG=n(DI,"A",{href:!0});var mkt=s(wG);nCo=r(mkt,"GPT2TokenizerFast"),mkt.forEach(t),sCo=r(DI," (GPT Neo model)"),DI.forEach(t),lCo=i(S),Vu=n(S,"LI",{});var Hje=s(Vu);ppe=n(Hje,"STRONG",{});var ckt=s(ppe);iCo=r(ckt,"gpt_neox"),ckt.forEach(t),dCo=r(Hje," \u2014 "),AG=n(Hje,"A",{href:!0});var fkt=s(AG);mCo=r(fkt,"GPTNeoXTokenizerFast"),fkt.forEach(t),cCo=r(Hje," (GPT NeoX model)"),Hje.forEach(t),fCo=i(S),Xu=n(S,"LI",{});var Jje=s(Xu);_pe=n(Jje,"STRONG",{});var gkt=s(_pe);gCo=r(gkt,"gpt_neox_japanese"),gkt.forEach(t),hCo=r(Jje," \u2014 "),LG=n(Jje,"A",{href:!0});var hkt=s(LG);uCo=r(hkt,"GPTNeoXJapaneseTokenizer"),hkt.forEach(t),pCo=r(Jje," (GPT NeoX Japanese model)"),Jje.forEach(t),_Co=i(S),js=n(S,"LI",{});var GI=s(js);bpe=n(GI,"STRONG",{});var ukt=s(bpe);bCo=r(ukt,"gptj"),ukt.forEach(t),vCo=r(GI," \u2014 "),yG=n(GI,"A",{href:!0});var pkt=s(yG);FCo=r(pkt,"GPT2Tokenizer"),pkt.forEach(t),TCo=r(GI," or "),xG=n(GI,"A",{href:!0});var _kt=s(xG);MCo=r(_kt,"GPT2TokenizerFast"),_kt.forEach(t),ECo=r(GI," (GPT-J model)"),GI.forEach(t),CCo=i(S),Ds=n(S,"LI",{});var OI=s(Ds);vpe=n(OI,"STRONG",{});var bkt=s(vpe);wCo=r(bkt,"groupvit"),bkt.forEach(t),ACo=r(OI," \u2014 "),$G=n(OI,"A",{href:!0});var vkt=s($G);LCo=r(vkt,"CLIPTokenizer"),vkt.forEach(t),yCo=r(OI," or "),kG=n(OI,"A",{href:!0});var Fkt=s(kG);xCo=r(Fkt,"CLIPTokenizerFast"),Fkt.forEach(t),$Co=r(OI," (GroupViT model)"),OI.forEach(t),kCo=i(S),Gs=n(S,"LI",{});var VI=s(Gs);Fpe=n(VI,"STRONG",{});var Tkt=s(Fpe);SCo=r(Tkt,"herbert"),Tkt.forEach(t),RCo=r(VI," \u2014 "),SG=n(VI,"A",{href:!0});var Mkt=s(SG);PCo=r(Mkt,"HerbertTokenizer"),Mkt.forEach(t),BCo=r(VI," or "),RG=n(VI,"A",{href:!0});var Ekt=s(RG);ICo=r(Ekt,"HerbertTokenizerFast"),Ekt.forEach(t),NCo=r(VI," (HerBERT model)"),VI.forEach(t),qCo=i(S),zu=n(S,"LI",{});var Yje=s(zu);Tpe=n(Yje,"STRONG",{});var Ckt=s(Tpe);jCo=r(Ckt,"hubert"),Ckt.forEach(t),DCo=r(Yje," \u2014 "),PG=n(Yje,"A",{href:!0});var wkt=s(PG);GCo=r(wkt,"Wav2Vec2CTCTokenizer"),wkt.forEach(t),OCo=r(Yje," (Hubert model)"),Yje.forEach(t),VCo=i(S),Os=n(S,"LI",{});var XI=s(Os);Mpe=n(XI,"STRONG",{});var Akt=s(Mpe);XCo=r(Akt,"ibert"),Akt.forEach(t),zCo=r(XI," \u2014 "),BG=n(XI,"A",{href:!0});var Lkt=s(BG);QCo=r(Lkt,"RobertaTokenizer"),Lkt.forEach(t),WCo=r(XI," or "),IG=n(XI,"A",{href:!0});var ykt=s(IG);UCo=r(ykt,"RobertaTokenizerFast"),ykt.forEach(t),HCo=r(XI," (I-BERT model)"),XI.forEach(t),JCo=i(S),Vs=n(S,"LI",{});var zI=s(Vs);Epe=n(zI,"STRONG",{});var xkt=s(Epe);YCo=r(xkt,"layoutlm"),xkt.forEach(t),ZCo=r(zI," \u2014 "),NG=n(zI,"A",{href:!0});var $kt=s(NG);KCo=r($kt,"LayoutLMTokenizer"),$kt.forEach(t),e3o=r(zI," or "),qG=n(zI,"A",{href:!0});var kkt=s(qG);o3o=r(kkt,"LayoutLMTokenizerFast"),kkt.forEach(t),r3o=r(zI," (LayoutLM model)"),zI.forEach(t),t3o=i(S),Xs=n(S,"LI",{});var QI=s(Xs);Cpe=n(QI,"STRONG",{});var Skt=s(Cpe);a3o=r(Skt,"layoutlmv2"),Skt.forEach(t),n3o=r(QI," \u2014 "),jG=n(QI,"A",{href:!0});var Rkt=s(jG);s3o=r(Rkt,"LayoutLMv2Tokenizer"),Rkt.forEach(t),l3o=r(QI," or "),DG=n(QI,"A",{href:!0});var Pkt=s(DG);i3o=r(Pkt,"LayoutLMv2TokenizerFast"),Pkt.forEach(t),d3o=r(QI," (LayoutLMv2 model)"),QI.forEach(t),m3o=i(S),zs=n(S,"LI",{});var WI=s(zs);wpe=n(WI,"STRONG",{});var Bkt=s(wpe);c3o=r(Bkt,"layoutlmv3"),Bkt.forEach(t),f3o=r(WI," \u2014 "),GG=n(WI,"A",{href:!0});var Ikt=s(GG);g3o=r(Ikt,"LayoutLMv3Tokenizer"),Ikt.forEach(t),h3o=r(WI," or "),OG=n(WI,"A",{href:!0});var Nkt=s(OG);u3o=r(Nkt,"LayoutLMv3TokenizerFast"),Nkt.forEach(t),p3o=r(WI," (LayoutLMv3 model)"),WI.forEach(t),_3o=i(S),Qs=n(S,"LI",{});var UI=s(Qs);Ape=n(UI,"STRONG",{});var qkt=s(Ape);b3o=r(qkt,"layoutxlm"),qkt.forEach(t),v3o=r(UI," \u2014 "),VG=n(UI,"A",{href:!0});var jkt=s(VG);F3o=r(jkt,"LayoutXLMTokenizer"),jkt.forEach(t),T3o=r(UI," or "),XG=n(UI,"A",{href:!0});var Dkt=s(XG);M3o=r(Dkt,"LayoutXLMTokenizerFast"),Dkt.forEach(t),E3o=r(UI," (LayoutXLM model)"),UI.forEach(t),C3o=i(S),Ws=n(S,"LI",{});var HI=s(Ws);Lpe=n(HI,"STRONG",{});var Gkt=s(Lpe);w3o=r(Gkt,"led"),Gkt.forEach(t),A3o=r(HI," \u2014 "),zG=n(HI,"A",{href:!0});var Okt=s(zG);L3o=r(Okt,"LEDTokenizer"),Okt.forEach(t),y3o=r(HI," or "),QG=n(HI,"A",{href:!0});var Vkt=s(QG);x3o=r(Vkt,"LEDTokenizerFast"),Vkt.forEach(t),$3o=r(HI," (LED model)"),HI.forEach(t),k3o=i(S),Us=n(S,"LI",{});var JI=s(Us);ype=n(JI,"STRONG",{});var Xkt=s(ype);S3o=r(Xkt,"lilt"),Xkt.forEach(t),R3o=r(JI," \u2014 "),WG=n(JI,"A",{href:!0});var zkt=s(WG);P3o=r(zkt,"LayoutLMv3Tokenizer"),zkt.forEach(t),B3o=r(JI," or "),UG=n(JI,"A",{href:!0});var Qkt=s(UG);I3o=r(Qkt,"LayoutLMv3TokenizerFast"),Qkt.forEach(t),N3o=r(JI," (LiLT model)"),JI.forEach(t),q3o=i(S),Hs=n(S,"LI",{});var YI=s(Hs);xpe=n(YI,"STRONG",{});var Wkt=s(xpe);j3o=r(Wkt,"longformer"),Wkt.forEach(t),D3o=r(YI," \u2014 "),HG=n(YI,"A",{href:!0});var Ukt=s(HG);G3o=r(Ukt,"LongformerTokenizer"),Ukt.forEach(t),O3o=r(YI," or "),JG=n(YI,"A",{href:!0});var Hkt=s(JG);V3o=r(Hkt,"LongformerTokenizerFast"),Hkt.forEach(t),X3o=r(YI," (Longformer model)"),YI.forEach(t),z3o=i(S),Js=n(S,"LI",{});var ZI=s(Js);$pe=n(ZI,"STRONG",{});var Jkt=s($pe);Q3o=r(Jkt,"longt5"),Jkt.forEach(t),W3o=r(ZI," \u2014 "),YG=n(ZI,"A",{href:!0});var Ykt=s(YG);U3o=r(Ykt,"T5Tokenizer"),Ykt.forEach(t),H3o=r(ZI," or "),ZG=n(ZI,"A",{href:!0});var Zkt=s(ZG);J3o=r(Zkt,"T5TokenizerFast"),Zkt.forEach(t),Y3o=r(ZI," (LongT5 model)"),ZI.forEach(t),Z3o=i(S),Qu=n(S,"LI",{});var Zje=s(Qu);kpe=n(Zje,"STRONG",{});var Kkt=s(kpe);K3o=r(Kkt,"luke"),Kkt.forEach(t),e5o=r(Zje," \u2014 "),KG=n(Zje,"A",{href:!0});var eSt=s(KG);o5o=r(eSt,"LukeTokenizer"),eSt.forEach(t),r5o=r(Zje," (LUKE model)"),Zje.forEach(t),t5o=i(S),Ys=n(S,"LI",{});var KI=s(Ys);Spe=n(KI,"STRONG",{});var oSt=s(Spe);a5o=r(oSt,"lxmert"),oSt.forEach(t),n5o=r(KI," \u2014 "),eO=n(KI,"A",{href:!0});var rSt=s(eO);s5o=r(rSt,"LxmertTokenizer"),rSt.forEach(t),l5o=r(KI," or "),oO=n(KI,"A",{href:!0});var tSt=s(oO);i5o=r(tSt,"LxmertTokenizerFast"),tSt.forEach(t),d5o=r(KI," (LXMERT model)"),KI.forEach(t),m5o=i(S),Wu=n(S,"LI",{});var Kje=s(Wu);Rpe=n(Kje,"STRONG",{});var aSt=s(Rpe);c5o=r(aSt,"m2m_100"),aSt.forEach(t),f5o=r(Kje," \u2014 "),rO=n(Kje,"A",{href:!0});var nSt=s(rO);g5o=r(nSt,"M2M100Tokenizer"),nSt.forEach(t),h5o=r(Kje," (M2M100 model)"),Kje.forEach(t),u5o=i(S),Uu=n(S,"LI",{});var eDe=s(Uu);Ppe=n(eDe,"STRONG",{});var sSt=s(Ppe);p5o=r(sSt,"marian"),sSt.forEach(t),_5o=r(eDe," \u2014 "),tO=n(eDe,"A",{href:!0});var lSt=s(tO);b5o=r(lSt,"MarianTokenizer"),lSt.forEach(t),v5o=r(eDe," (Marian model)"),eDe.forEach(t),F5o=i(S),Zs=n(S,"LI",{});var eN=s(Zs);Bpe=n(eN,"STRONG",{});var iSt=s(Bpe);T5o=r(iSt,"mbart"),iSt.forEach(t),M5o=r(eN," \u2014 "),aO=n(eN,"A",{href:!0});var dSt=s(aO);E5o=r(dSt,"MBartTokenizer"),dSt.forEach(t),C5o=r(eN," or "),nO=n(eN,"A",{href:!0});var mSt=s(nO);w5o=r(mSt,"MBartTokenizerFast"),mSt.forEach(t),A5o=r(eN," (mBART model)"),eN.forEach(t),L5o=i(S),Ks=n(S,"LI",{});var oN=s(Ks);Ipe=n(oN,"STRONG",{});var cSt=s(Ipe);y5o=r(cSt,"mbart50"),cSt.forEach(t),x5o=r(oN," \u2014 "),sO=n(oN,"A",{href:!0});var fSt=s(sO);$5o=r(fSt,"MBart50Tokenizer"),fSt.forEach(t),k5o=r(oN," or "),lO=n(oN,"A",{href:!0});var gSt=s(lO);S5o=r(gSt,"MBart50TokenizerFast"),gSt.forEach(t),R5o=r(oN," (mBART-50 model)"),oN.forEach(t),P5o=i(S),el=n(S,"LI",{});var rN=s(el);Npe=n(rN,"STRONG",{});var hSt=s(Npe);B5o=r(hSt,"megatron-bert"),hSt.forEach(t),I5o=r(rN," \u2014 "),iO=n(rN,"A",{href:!0});var uSt=s(iO);N5o=r(uSt,"BertTokenizer"),uSt.forEach(t),q5o=r(rN," or "),dO=n(rN,"A",{href:!0});var pSt=s(dO);j5o=r(pSt,"BertTokenizerFast"),pSt.forEach(t),D5o=r(rN," (Megatron-BERT model)"),rN.forEach(t),G5o=i(S),Hu=n(S,"LI",{});var oDe=s(Hu);qpe=n(oDe,"STRONG",{});var _St=s(qpe);O5o=r(_St,"mluke"),_St.forEach(t),V5o=r(oDe," \u2014 "),mO=n(oDe,"A",{href:!0});var bSt=s(mO);X5o=r(bSt,"MLukeTokenizer"),bSt.forEach(t),z5o=r(oDe," (mLUKE model)"),oDe.forEach(t),Q5o=i(S),ol=n(S,"LI",{});var tN=s(ol);jpe=n(tN,"STRONG",{});var vSt=s(jpe);W5o=r(vSt,"mobilebert"),vSt.forEach(t),U5o=r(tN," \u2014 "),cO=n(tN,"A",{href:!0});var FSt=s(cO);H5o=r(FSt,"MobileBertTokenizer"),FSt.forEach(t),J5o=r(tN," or "),fO=n(tN,"A",{href:!0});var TSt=s(fO);Y5o=r(TSt,"MobileBertTokenizerFast"),TSt.forEach(t),Z5o=r(tN," (MobileBERT model)"),tN.forEach(t),K5o=i(S),rl=n(S,"LI",{});var aN=s(rl);Dpe=n(aN,"STRONG",{});var MSt=s(Dpe);e0o=r(MSt,"mpnet"),MSt.forEach(t),o0o=r(aN," \u2014 "),gO=n(aN,"A",{href:!0});var ESt=s(gO);r0o=r(ESt,"MPNetTokenizer"),ESt.forEach(t),t0o=r(aN," or "),hO=n(aN,"A",{href:!0});var CSt=s(hO);a0o=r(CSt,"MPNetTokenizerFast"),CSt.forEach(t),n0o=r(aN," (MPNet model)"),aN.forEach(t),s0o=i(S),tl=n(S,"LI",{});var nN=s(tl);Gpe=n(nN,"STRONG",{});var wSt=s(Gpe);l0o=r(wSt,"mt5"),wSt.forEach(t),i0o=r(nN," \u2014 "),uO=n(nN,"A",{href:!0});var ASt=s(uO);d0o=r(ASt,"MT5Tokenizer"),ASt.forEach(t),m0o=r(nN," or "),pO=n(nN,"A",{href:!0});var LSt=s(pO);c0o=r(LSt,"MT5TokenizerFast"),LSt.forEach(t),f0o=r(nN," (MT5 model)"),nN.forEach(t),g0o=i(S),al=n(S,"LI",{});var sN=s(al);Ope=n(sN,"STRONG",{});var ySt=s(Ope);h0o=r(ySt,"mvp"),ySt.forEach(t),u0o=r(sN," \u2014 "),_O=n(sN,"A",{href:!0});var xSt=s(_O);p0o=r(xSt,"MvpTokenizer"),xSt.forEach(t),_0o=r(sN," or "),bO=n(sN,"A",{href:!0});var $St=s(bO);b0o=r($St,"MvpTokenizerFast"),$St.forEach(t),v0o=r(sN," (MVP model)"),sN.forEach(t),F0o=i(S),nl=n(S,"LI",{});var lN=s(nl);Vpe=n(lN,"STRONG",{});var kSt=s(Vpe);T0o=r(kSt,"nezha"),kSt.forEach(t),M0o=r(lN," \u2014 "),vO=n(lN,"A",{href:!0});var SSt=s(vO);E0o=r(SSt,"BertTokenizer"),SSt.forEach(t),C0o=r(lN," or "),FO=n(lN,"A",{href:!0});var RSt=s(FO);w0o=r(RSt,"BertTokenizerFast"),RSt.forEach(t),A0o=r(lN," (Nezha model)"),lN.forEach(t),L0o=i(S),sl=n(S,"LI",{});var iN=s(sl);Xpe=n(iN,"STRONG",{});var PSt=s(Xpe);y0o=r(PSt,"nllb"),PSt.forEach(t),x0o=r(iN," \u2014 "),TO=n(iN,"A",{href:!0});var BSt=s(TO);$0o=r(BSt,"NllbTokenizer"),BSt.forEach(t),k0o=r(iN," or "),MO=n(iN,"A",{href:!0});var ISt=s(MO);S0o=r(ISt,"NllbTokenizerFast"),ISt.forEach(t),R0o=r(iN," (NLLB model)"),iN.forEach(t),P0o=i(S),ll=n(S,"LI",{});var dN=s(ll);zpe=n(dN,"STRONG",{});var NSt=s(zpe);B0o=r(NSt,"nystromformer"),NSt.forEach(t),I0o=r(dN," \u2014 "),EO=n(dN,"A",{href:!0});var qSt=s(EO);N0o=r(qSt,"AlbertTokenizer"),qSt.forEach(t),q0o=r(dN," or "),CO=n(dN,"A",{href:!0});var jSt=s(CO);j0o=r(jSt,"AlbertTokenizerFast"),jSt.forEach(t),D0o=r(dN," (Nystr\xF6mformer model)"),dN.forEach(t),G0o=i(S),il=n(S,"LI",{});var mN=s(il);Qpe=n(mN,"STRONG",{});var DSt=s(Qpe);O0o=r(DSt,"openai-gpt"),DSt.forEach(t),V0o=r(mN," \u2014 "),wO=n(mN,"A",{href:!0});var GSt=s(wO);X0o=r(GSt,"OpenAIGPTTokenizer"),GSt.forEach(t),z0o=r(mN," or "),AO=n(mN,"A",{href:!0});var OSt=s(AO);Q0o=r(OSt,"OpenAIGPTTokenizerFast"),OSt.forEach(t),W0o=r(mN," (OpenAI GPT model)"),mN.forEach(t),U0o=i(S),Ju=n(S,"LI",{});var rDe=s(Ju);Wpe=n(rDe,"STRONG",{});var VSt=s(Wpe);H0o=r(VSt,"opt"),VSt.forEach(t),J0o=r(rDe," \u2014 "),LO=n(rDe,"A",{href:!0});var XSt=s(LO);Y0o=r(XSt,"GPT2Tokenizer"),XSt.forEach(t),Z0o=r(rDe," (OPT model)"),rDe.forEach(t),K0o=i(S),dl=n(S,"LI",{});var cN=s(dl);Upe=n(cN,"STRONG",{});var zSt=s(Upe);ewo=r(zSt,"owlvit"),zSt.forEach(t),owo=r(cN," \u2014 "),yO=n(cN,"A",{href:!0});var QSt=s(yO);rwo=r(QSt,"CLIPTokenizer"),QSt.forEach(t),two=r(cN," or "),xO=n(cN,"A",{href:!0});var WSt=s(xO);awo=r(WSt,"CLIPTokenizerFast"),WSt.forEach(t),nwo=r(cN," (OWL-ViT model)"),cN.forEach(t),swo=i(S),ml=n(S,"LI",{});var fN=s(ml);Hpe=n(fN,"STRONG",{});var USt=s(Hpe);lwo=r(USt,"pegasus"),USt.forEach(t),iwo=r(fN," \u2014 "),$O=n(fN,"A",{href:!0});var HSt=s($O);dwo=r(HSt,"PegasusTokenizer"),HSt.forEach(t),mwo=r(fN," or "),kO=n(fN,"A",{href:!0});var JSt=s(kO);cwo=r(JSt,"PegasusTokenizerFast"),JSt.forEach(t),fwo=r(fN," (Pegasus model)"),fN.forEach(t),gwo=i(S),cl=n(S,"LI",{});var gN=s(cl);Jpe=n(gN,"STRONG",{});var YSt=s(Jpe);hwo=r(YSt,"pegasus_x"),YSt.forEach(t),uwo=r(gN," \u2014 "),SO=n(gN,"A",{href:!0});var ZSt=s(SO);pwo=r(ZSt,"PegasusTokenizer"),ZSt.forEach(t),_wo=r(gN," or "),RO=n(gN,"A",{href:!0});var KSt=s(RO);bwo=r(KSt,"PegasusTokenizerFast"),KSt.forEach(t),vwo=r(gN," (PEGASUS-X model)"),gN.forEach(t),Fwo=i(S),Yu=n(S,"LI",{});var tDe=s(Yu);Ype=n(tDe,"STRONG",{});var eRt=s(Ype);Two=r(eRt,"perceiver"),eRt.forEach(t),Mwo=r(tDe," \u2014 "),PO=n(tDe,"A",{href:!0});var oRt=s(PO);Ewo=r(oRt,"PerceiverTokenizer"),oRt.forEach(t),Cwo=r(tDe," (Perceiver model)"),tDe.forEach(t),wwo=i(S),Zu=n(S,"LI",{});var aDe=s(Zu);Zpe=n(aDe,"STRONG",{});var rRt=s(Zpe);Awo=r(rRt,"phobert"),rRt.forEach(t),Lwo=r(aDe," \u2014 "),BO=n(aDe,"A",{href:!0});var tRt=s(BO);ywo=r(tRt,"PhobertTokenizer"),tRt.forEach(t),xwo=r(aDe," (PhoBERT model)"),aDe.forEach(t),$wo=i(S),Ku=n(S,"LI",{});var nDe=s(Ku);Kpe=n(nDe,"STRONG",{});var aRt=s(Kpe);kwo=r(aRt,"plbart"),aRt.forEach(t),Swo=r(nDe," \u2014 "),IO=n(nDe,"A",{href:!0});var nRt=s(IO);Rwo=r(nRt,"PLBartTokenizer"),nRt.forEach(t),Pwo=r(nDe," (PLBart model)"),nDe.forEach(t),Bwo=i(S),ep=n(S,"LI",{});var sDe=s(ep);e_e=n(sDe,"STRONG",{});var sRt=s(e_e);Iwo=r(sRt,"prophetnet"),sRt.forEach(t),Nwo=r(sDe," \u2014 "),NO=n(sDe,"A",{href:!0});var lRt=s(NO);qwo=r(lRt,"ProphetNetTokenizer"),lRt.forEach(t),jwo=r(sDe," (ProphetNet model)"),sDe.forEach(t),Dwo=i(S),fl=n(S,"LI",{});var hN=s(fl);o_e=n(hN,"STRONG",{});var iRt=s(o_e);Gwo=r(iRt,"qdqbert"),iRt.forEach(t),Owo=r(hN," \u2014 "),qO=n(hN,"A",{href:!0});var dRt=s(qO);Vwo=r(dRt,"BertTokenizer"),dRt.forEach(t),Xwo=r(hN," or "),jO=n(hN,"A",{href:!0});var mRt=s(jO);zwo=r(mRt,"BertTokenizerFast"),mRt.forEach(t),Qwo=r(hN," (QDQBert model)"),hN.forEach(t),Wwo=i(S),op=n(S,"LI",{});var lDe=s(op);r_e=n(lDe,"STRONG",{});var cRt=s(r_e);Uwo=r(cRt,"rag"),cRt.forEach(t),Hwo=r(lDe," \u2014 "),DO=n(lDe,"A",{href:!0});var fRt=s(DO);Jwo=r(fRt,"RagTokenizer"),fRt.forEach(t),Ywo=r(lDe," (RAG model)"),lDe.forEach(t),Zwo=i(S),gl=n(S,"LI",{});var uN=s(gl);t_e=n(uN,"STRONG",{});var gRt=s(t_e);Kwo=r(gRt,"realm"),gRt.forEach(t),eAo=r(uN," \u2014 "),GO=n(uN,"A",{href:!0});var hRt=s(GO);oAo=r(hRt,"RealmTokenizer"),hRt.forEach(t),rAo=r(uN," or "),OO=n(uN,"A",{href:!0});var uRt=s(OO);tAo=r(uRt,"RealmTokenizerFast"),uRt.forEach(t),aAo=r(uN," (REALM model)"),uN.forEach(t),nAo=i(S),hl=n(S,"LI",{});var pN=s(hl);a_e=n(pN,"STRONG",{});var pRt=s(a_e);sAo=r(pRt,"reformer"),pRt.forEach(t),lAo=r(pN," \u2014 "),VO=n(pN,"A",{href:!0});var _Rt=s(VO);iAo=r(_Rt,"ReformerTokenizer"),_Rt.forEach(t),dAo=r(pN," or "),XO=n(pN,"A",{href:!0});var bRt=s(XO);mAo=r(bRt,"ReformerTokenizerFast"),bRt.forEach(t),cAo=r(pN," (Reformer model)"),pN.forEach(t),fAo=i(S),ul=n(S,"LI",{});var _N=s(ul);n_e=n(_N,"STRONG",{});var vRt=s(n_e);gAo=r(vRt,"rembert"),vRt.forEach(t),hAo=r(_N," \u2014 "),zO=n(_N,"A",{href:!0});var FRt=s(zO);uAo=r(FRt,"RemBertTokenizer"),FRt.forEach(t),pAo=r(_N," or "),QO=n(_N,"A",{href:!0});var TRt=s(QO);_Ao=r(TRt,"RemBertTokenizerFast"),TRt.forEach(t),bAo=r(_N," (RemBERT model)"),_N.forEach(t),vAo=i(S),pl=n(S,"LI",{});var bN=s(pl);s_e=n(bN,"STRONG",{});var MRt=s(s_e);FAo=r(MRt,"retribert"),MRt.forEach(t),TAo=r(bN," \u2014 "),WO=n(bN,"A",{href:!0});var ERt=s(WO);MAo=r(ERt,"RetriBertTokenizer"),ERt.forEach(t),EAo=r(bN," or "),UO=n(bN,"A",{href:!0});var CRt=s(UO);CAo=r(CRt,"RetriBertTokenizerFast"),CRt.forEach(t),wAo=r(bN," (RetriBERT model)"),bN.forEach(t),AAo=i(S),_l=n(S,"LI",{});var vN=s(_l);l_e=n(vN,"STRONG",{});var wRt=s(l_e);LAo=r(wRt,"roberta"),wRt.forEach(t),yAo=r(vN," \u2014 "),HO=n(vN,"A",{href:!0});var ARt=s(HO);xAo=r(ARt,"RobertaTokenizer"),ARt.forEach(t),$Ao=r(vN," or "),JO=n(vN,"A",{href:!0});var LRt=s(JO);kAo=r(LRt,"RobertaTokenizerFast"),LRt.forEach(t),SAo=r(vN," (RoBERTa model)"),vN.forEach(t),RAo=i(S),bl=n(S,"LI",{});var FN=s(bl);i_e=n(FN,"STRONG",{});var yRt=s(i_e);PAo=r(yRt,"roformer"),yRt.forEach(t),BAo=r(FN," \u2014 "),YO=n(FN,"A",{href:!0});var xRt=s(YO);IAo=r(xRt,"RoFormerTokenizer"),xRt.forEach(t),NAo=r(FN," or "),ZO=n(FN,"A",{href:!0});var $Rt=s(ZO);qAo=r($Rt,"RoFormerTokenizerFast"),$Rt.forEach(t),jAo=r(FN," (RoFormer model)"),FN.forEach(t),DAo=i(S),rp=n(S,"LI",{});var iDe=s(rp);d_e=n(iDe,"STRONG",{});var kRt=s(d_e);GAo=r(kRt,"speech_to_text"),kRt.forEach(t),OAo=r(iDe," \u2014 "),KO=n(iDe,"A",{href:!0});var SRt=s(KO);VAo=r(SRt,"Speech2TextTokenizer"),SRt.forEach(t),XAo=r(iDe," (Speech2Text model)"),iDe.forEach(t),zAo=i(S),tp=n(S,"LI",{});var dDe=s(tp);m_e=n(dDe,"STRONG",{});var RRt=s(m_e);QAo=r(RRt,"speech_to_text_2"),RRt.forEach(t),WAo=r(dDe," \u2014 "),eV=n(dDe,"A",{href:!0});var PRt=s(eV);UAo=r(PRt,"Speech2Text2Tokenizer"),PRt.forEach(t),HAo=r(dDe," (Speech2Text2 model)"),dDe.forEach(t),JAo=i(S),vl=n(S,"LI",{});var TN=s(vl);c_e=n(TN,"STRONG",{});var BRt=s(c_e);YAo=r(BRt,"splinter"),BRt.forEach(t),ZAo=r(TN," \u2014 "),oV=n(TN,"A",{href:!0});var IRt=s(oV);KAo=r(IRt,"SplinterTokenizer"),IRt.forEach(t),e6o=r(TN," or "),rV=n(TN,"A",{href:!0});var NRt=s(rV);o6o=r(NRt,"SplinterTokenizerFast"),NRt.forEach(t),r6o=r(TN," (Splinter model)"),TN.forEach(t),t6o=i(S),Fl=n(S,"LI",{});var MN=s(Fl);f_e=n(MN,"STRONG",{});var qRt=s(f_e);a6o=r(qRt,"squeezebert"),qRt.forEach(t),n6o=r(MN," \u2014 "),tV=n(MN,"A",{href:!0});var jRt=s(tV);s6o=r(jRt,"SqueezeBertTokenizer"),jRt.forEach(t),l6o=r(MN," or "),aV=n(MN,"A",{href:!0});var DRt=s(aV);i6o=r(DRt,"SqueezeBertTokenizerFast"),DRt.forEach(t),d6o=r(MN," (SqueezeBERT model)"),MN.forEach(t),m6o=i(S),Tl=n(S,"LI",{});var EN=s(Tl);g_e=n(EN,"STRONG",{});var GRt=s(g_e);c6o=r(GRt,"t5"),GRt.forEach(t),f6o=r(EN," \u2014 "),nV=n(EN,"A",{href:!0});var ORt=s(nV);g6o=r(ORt,"T5Tokenizer"),ORt.forEach(t),h6o=r(EN," or "),sV=n(EN,"A",{href:!0});var VRt=s(sV);u6o=r(VRt,"T5TokenizerFast"),VRt.forEach(t),p6o=r(EN," (T5 model)"),EN.forEach(t),_6o=i(S),ap=n(S,"LI",{});var mDe=s(ap);h_e=n(mDe,"STRONG",{});var XRt=s(h_e);b6o=r(XRt,"tapas"),XRt.forEach(t),v6o=r(mDe," \u2014 "),lV=n(mDe,"A",{href:!0});var zRt=s(lV);F6o=r(zRt,"TapasTokenizer"),zRt.forEach(t),T6o=r(mDe," (TAPAS model)"),mDe.forEach(t),M6o=i(S),np=n(S,"LI",{});var cDe=s(np);u_e=n(cDe,"STRONG",{});var QRt=s(u_e);E6o=r(QRt,"tapex"),QRt.forEach(t),C6o=r(cDe," \u2014 "),iV=n(cDe,"A",{href:!0});var WRt=s(iV);w6o=r(WRt,"TapexTokenizer"),WRt.forEach(t),A6o=r(cDe," (TAPEX model)"),cDe.forEach(t),L6o=i(S),sp=n(S,"LI",{});var fDe=s(sp);p_e=n(fDe,"STRONG",{});var URt=s(p_e);y6o=r(URt,"transfo-xl"),URt.forEach(t),x6o=r(fDe," \u2014 "),dV=n(fDe,"A",{href:!0});var HRt=s(dV);$6o=r(HRt,"TransfoXLTokenizer"),HRt.forEach(t),k6o=r(fDe," (Transformer-XL model)"),fDe.forEach(t),S6o=i(S),Ml=n(S,"LI",{});var CN=s(Ml);__e=n(CN,"STRONG",{});var JRt=s(__e);R6o=r(JRt,"vilt"),JRt.forEach(t),P6o=r(CN," \u2014 "),mV=n(CN,"A",{href:!0});var YRt=s(mV);B6o=r(YRt,"BertTokenizer"),YRt.forEach(t),I6o=r(CN," or "),cV=n(CN,"A",{href:!0});var ZRt=s(cV);N6o=r(ZRt,"BertTokenizerFast"),ZRt.forEach(t),q6o=r(CN," (ViLT model)"),CN.forEach(t),j6o=i(S),El=n(S,"LI",{});var wN=s(El);b_e=n(wN,"STRONG",{});var KRt=s(b_e);D6o=r(KRt,"visual_bert"),KRt.forEach(t),G6o=r(wN," \u2014 "),fV=n(wN,"A",{href:!0});var ePt=s(fV);O6o=r(ePt,"BertTokenizer"),ePt.forEach(t),V6o=r(wN," or "),gV=n(wN,"A",{href:!0});var oPt=s(gV);X6o=r(oPt,"BertTokenizerFast"),oPt.forEach(t),z6o=r(wN," (VisualBERT model)"),wN.forEach(t),Q6o=i(S),lp=n(S,"LI",{});var gDe=s(lp);v_e=n(gDe,"STRONG",{});var rPt=s(v_e);W6o=r(rPt,"wav2vec2"),rPt.forEach(t),U6o=r(gDe," \u2014 "),hV=n(gDe,"A",{href:!0});var tPt=s(hV);H6o=r(tPt,"Wav2Vec2CTCTokenizer"),tPt.forEach(t),J6o=r(gDe," (Wav2Vec2 model)"),gDe.forEach(t),Y6o=i(S),ip=n(S,"LI",{});var hDe=s(ip);F_e=n(hDe,"STRONG",{});var aPt=s(F_e);Z6o=r(aPt,"wav2vec2-conformer"),aPt.forEach(t),K6o=r(hDe," \u2014 "),uV=n(hDe,"A",{href:!0});var nPt=s(uV);e7o=r(nPt,"Wav2Vec2CTCTokenizer"),nPt.forEach(t),o7o=r(hDe," (Wav2Vec2-Conformer model)"),hDe.forEach(t),r7o=i(S),dp=n(S,"LI",{});var uDe=s(dp);T_e=n(uDe,"STRONG",{});var sPt=s(T_e);t7o=r(sPt,"wav2vec2_phoneme"),sPt.forEach(t),a7o=r(uDe," \u2014 "),pV=n(uDe,"A",{href:!0});var lPt=s(pV);n7o=r(lPt,"Wav2Vec2PhonemeCTCTokenizer"),lPt.forEach(t),s7o=r(uDe," (Wav2Vec2Phoneme model)"),uDe.forEach(t),l7o=i(S),mp=n(S,"LI",{});var pDe=s(mp);M_e=n(pDe,"STRONG",{});var iPt=s(M_e);i7o=r(iPt,"whisper"),iPt.forEach(t),d7o=r(pDe," \u2014 "),_V=n(pDe,"A",{href:!0});var dPt=s(_V);m7o=r(dPt,"WhisperTokenizer"),dPt.forEach(t),c7o=r(pDe," (Whisper model)"),pDe.forEach(t),f7o=i(S),Cl=n(S,"LI",{});var AN=s(Cl);E_e=n(AN,"STRONG",{});var mPt=s(E_e);g7o=r(mPt,"xclip"),mPt.forEach(t),h7o=r(AN," \u2014 "),bV=n(AN,"A",{href:!0});var cPt=s(bV);u7o=r(cPt,"CLIPTokenizer"),cPt.forEach(t),p7o=r(AN," or "),vV=n(AN,"A",{href:!0});var fPt=s(vV);_7o=r(fPt,"CLIPTokenizerFast"),fPt.forEach(t),b7o=r(AN," (X-CLIP model)"),AN.forEach(t),v7o=i(S),wl=n(S,"LI",{});var LN=s(wl);C_e=n(LN,"STRONG",{});var gPt=s(C_e);F7o=r(gPt,"xglm"),gPt.forEach(t),T7o=r(LN," \u2014 "),FV=n(LN,"A",{href:!0});var hPt=s(FV);M7o=r(hPt,"XGLMTokenizer"),hPt.forEach(t),E7o=r(LN," or "),TV=n(LN,"A",{href:!0});var uPt=s(TV);C7o=r(uPt,"XGLMTokenizerFast"),uPt.forEach(t),w7o=r(LN," (XGLM model)"),LN.forEach(t),A7o=i(S),cp=n(S,"LI",{});var _De=s(cp);w_e=n(_De,"STRONG",{});var pPt=s(w_e);L7o=r(pPt,"xlm"),pPt.forEach(t),y7o=r(_De," \u2014 "),MV=n(_De,"A",{href:!0});var _Pt=s(MV);x7o=r(_Pt,"XLMTokenizer"),_Pt.forEach(t),$7o=r(_De," (XLM model)"),_De.forEach(t),k7o=i(S),fp=n(S,"LI",{});var bDe=s(fp);A_e=n(bDe,"STRONG",{});var bPt=s(A_e);S7o=r(bPt,"xlm-prophetnet"),bPt.forEach(t),R7o=r(bDe," \u2014 "),EV=n(bDe,"A",{href:!0});var vPt=s(EV);P7o=r(vPt,"XLMProphetNetTokenizer"),vPt.forEach(t),B7o=r(bDe," (XLM-ProphetNet model)"),bDe.forEach(t),I7o=i(S),Al=n(S,"LI",{});var yN=s(Al);L_e=n(yN,"STRONG",{});var FPt=s(L_e);N7o=r(FPt,"xlm-roberta"),FPt.forEach(t),q7o=r(yN," \u2014 "),CV=n(yN,"A",{href:!0});var TPt=s(CV);j7o=r(TPt,"XLMRobertaTokenizer"),TPt.forEach(t),D7o=r(yN," or "),wV=n(yN,"A",{href:!0});var MPt=s(wV);G7o=r(MPt,"XLMRobertaTokenizerFast"),MPt.forEach(t),O7o=r(yN," (XLM-RoBERTa model)"),yN.forEach(t),V7o=i(S),Ll=n(S,"LI",{});var xN=s(Ll);y_e=n(xN,"STRONG",{});var EPt=s(y_e);X7o=r(EPt,"xlm-roberta-xl"),EPt.forEach(t),z7o=r(xN," \u2014 "),AV=n(xN,"A",{href:!0});var CPt=s(AV);Q7o=r(CPt,"XLMRobertaTokenizer"),CPt.forEach(t),W7o=r(xN," or "),LV=n(xN,"A",{href:!0});var wPt=s(LV);U7o=r(wPt,"XLMRobertaTokenizerFast"),wPt.forEach(t),H7o=r(xN," (XLM-RoBERTa-XL model)"),xN.forEach(t),J7o=i(S),yl=n(S,"LI",{});var $N=s(yl);x_e=n($N,"STRONG",{});var APt=s(x_e);Y7o=r(APt,"xlnet"),APt.forEach(t),Z7o=r($N," \u2014 "),yV=n($N,"A",{href:!0});var LPt=s(yV);K7o=r(LPt,"XLNetTokenizer"),LPt.forEach(t),e8o=r($N," or "),xV=n($N,"A",{href:!0});var yPt=s(xV);o8o=r(yPt,"XLNetTokenizerFast"),yPt.forEach(t),r8o=r($N," (XLNet model)"),$N.forEach(t),t8o=i(S),xl=n(S,"LI",{});var kN=s(xl);$_e=n(kN,"STRONG",{});var xPt=s($_e);a8o=r(xPt,"yoso"),xPt.forEach(t),n8o=r(kN," \u2014 "),$V=n(kN,"A",{href:!0});var $Pt=s($V);s8o=r($Pt,"AlbertTokenizer"),$Pt.forEach(t),l8o=r(kN," or "),kV=n(kN,"A",{href:!0});var kPt=s(kV);i8o=r(kPt,"AlbertTokenizerFast"),kPt.forEach(t),d8o=r(kN," (YOSO model)"),kN.forEach(t),S.forEach(t),m8o=i(Il),T(gp.$$.fragment,Il),Il.forEach(t),c8o=i(Bl),hp=n(Bl,"DIV",{class:!0});var Jso=s(hp);T(I$.$$.fragment,Jso),f8o=i(Jso),k_e=n(Jso,"P",{});var SPt=s(k_e);g8o=r(SPt,"Register a new tokenizer in this mapping."),SPt.forEach(t),Jso.forEach(t),Bl.forEach(t),Nao=i(c),$d=n(c,"H2",{class:!0});var Yso=s($d);up=n(Yso,"A",{id:!0,class:!0,href:!0});var RPt=s(up);S_e=n(RPt,"SPAN",{});var PPt=s(S_e);T(N$.$$.fragment,PPt),PPt.forEach(t),RPt.forEach(t),h8o=i(Yso),R_e=n(Yso,"SPAN",{});var BPt=s(R_e);u8o=r(BPt,"AutoFeatureExtractor"),BPt.forEach(t),Yso.forEach(t),qao=i(c),Po=n(c,"DIV",{class:!0});var Nl=s(Po);T(q$.$$.fragment,Nl),p8o=i(Nl),j$=n(Nl,"P",{});var Zso=s(j$);_8o=r(Zso,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),SV=n(Zso,"A",{href:!0});var IPt=s(SV);b8o=r(IPt,"AutoFeatureExtractor.from_pretrained()"),IPt.forEach(t),v8o=r(Zso," class method."),Zso.forEach(t),F8o=i(Nl),D$=n(Nl,"P",{});var Kso=s(D$);T8o=r(Kso,"This class cannot be instantiated directly using "),P_e=n(Kso,"CODE",{});var NPt=s(P_e);M8o=r(NPt,"__init__()"),NPt.forEach(t),E8o=r(Kso," (throws an error)."),Kso.forEach(t),C8o=i(Nl),Ye=n(Nl,"DIV",{class:!0});var wa=s(Ye);T(G$.$$.fragment,wa),w8o=i(wa),B_e=n(wa,"P",{});var qPt=s(B_e);A8o=r(qPt,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),qPt.forEach(t),L8o=i(wa),an=n(wa,"P",{});var g9=s(an);y8o=r(g9,"The feature extractor class to instantiate is selected based on the "),I_e=n(g9,"CODE",{});var jPt=s(I_e);x8o=r(jPt,"model_type"),jPt.forEach(t),$8o=r(g9,` property of the config object
(either passed as an argument or loaded from `),N_e=n(g9,"CODE",{});var DPt=s(N_e);k8o=r(DPt,"pretrained_model_name_or_path"),DPt.forEach(t),S8o=r(g9,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),q_e=n(g9,"CODE",{});var GPt=s(q_e);R8o=r(GPt,"pretrained_model_name_or_path"),GPt.forEach(t),P8o=r(g9,":"),g9.forEach(t),B8o=i(wa),z=n(wa,"UL",{});var Q=s(z);pp=n(Q,"LI",{});var vDe=s(pp);j_e=n(vDe,"STRONG",{});var OPt=s(j_e);I8o=r(OPt,"beit"),OPt.forEach(t),N8o=r(vDe," \u2014 "),RV=n(vDe,"A",{href:!0});var VPt=s(RV);q8o=r(VPt,"BeitFeatureExtractor"),VPt.forEach(t),j8o=r(vDe," (BEiT model)"),vDe.forEach(t),D8o=i(Q),_p=n(Q,"LI",{});var FDe=s(_p);D_e=n(FDe,"STRONG",{});var XPt=s(D_e);G8o=r(XPt,"clip"),XPt.forEach(t),O8o=r(FDe," \u2014 "),PV=n(FDe,"A",{href:!0});var zPt=s(PV);V8o=r(zPt,"CLIPFeatureExtractor"),zPt.forEach(t),X8o=r(FDe," (CLIP model)"),FDe.forEach(t),z8o=i(Q),bp=n(Q,"LI",{});var TDe=s(bp);G_e=n(TDe,"STRONG",{});var QPt=s(G_e);Q8o=r(QPt,"clipseg"),QPt.forEach(t),W8o=r(TDe," \u2014 "),BV=n(TDe,"A",{href:!0});var WPt=s(BV);U8o=r(WPt,"ViTFeatureExtractor"),WPt.forEach(t),H8o=r(TDe," (CLIPSeg model)"),TDe.forEach(t),J8o=i(Q),vp=n(Q,"LI",{});var MDe=s(vp);O_e=n(MDe,"STRONG",{});var UPt=s(O_e);Y8o=r(UPt,"conditional_detr"),UPt.forEach(t),Z8o=r(MDe," \u2014 "),IV=n(MDe,"A",{href:!0});var HPt=s(IV);K8o=r(HPt,"ConditionalDetrFeatureExtractor"),HPt.forEach(t),eLo=r(MDe," (Conditional DETR model)"),MDe.forEach(t),oLo=i(Q),Fp=n(Q,"LI",{});var EDe=s(Fp);V_e=n(EDe,"STRONG",{});var JPt=s(V_e);rLo=r(JPt,"convnext"),JPt.forEach(t),tLo=r(EDe," \u2014 "),NV=n(EDe,"A",{href:!0});var YPt=s(NV);aLo=r(YPt,"ConvNextFeatureExtractor"),YPt.forEach(t),nLo=r(EDe," (ConvNeXT model)"),EDe.forEach(t),sLo=i(Q),Tp=n(Q,"LI",{});var CDe=s(Tp);X_e=n(CDe,"STRONG",{});var ZPt=s(X_e);lLo=r(ZPt,"cvt"),ZPt.forEach(t),iLo=r(CDe," \u2014 "),qV=n(CDe,"A",{href:!0});var KPt=s(qV);dLo=r(KPt,"ConvNextFeatureExtractor"),KPt.forEach(t),mLo=r(CDe," (CvT model)"),CDe.forEach(t),cLo=i(Q),Mp=n(Q,"LI",{});var wDe=s(Mp);z_e=n(wDe,"STRONG",{});var eBt=s(z_e);fLo=r(eBt,"data2vec-audio"),eBt.forEach(t),gLo=r(wDe," \u2014 "),jV=n(wDe,"A",{href:!0});var oBt=s(jV);hLo=r(oBt,"Wav2Vec2FeatureExtractor"),oBt.forEach(t),uLo=r(wDe," (Data2VecAudio model)"),wDe.forEach(t),pLo=i(Q),Ep=n(Q,"LI",{});var ADe=s(Ep);Q_e=n(ADe,"STRONG",{});var rBt=s(Q_e);_Lo=r(rBt,"data2vec-vision"),rBt.forEach(t),bLo=r(ADe," \u2014 "),DV=n(ADe,"A",{href:!0});var tBt=s(DV);vLo=r(tBt,"BeitFeatureExtractor"),tBt.forEach(t),FLo=r(ADe," (Data2VecVision model)"),ADe.forEach(t),TLo=i(Q),Cp=n(Q,"LI",{});var LDe=s(Cp);W_e=n(LDe,"STRONG",{});var aBt=s(W_e);MLo=r(aBt,"deformable_detr"),aBt.forEach(t),ELo=r(LDe," \u2014 "),GV=n(LDe,"A",{href:!0});var nBt=s(GV);CLo=r(nBt,"DeformableDetrFeatureExtractor"),nBt.forEach(t),wLo=r(LDe," (Deformable DETR model)"),LDe.forEach(t),ALo=i(Q),wp=n(Q,"LI",{});var yDe=s(wp);U_e=n(yDe,"STRONG",{});var sBt=s(U_e);LLo=r(sBt,"deit"),sBt.forEach(t),yLo=r(yDe," \u2014 "),OV=n(yDe,"A",{href:!0});var lBt=s(OV);xLo=r(lBt,"DeiTFeatureExtractor"),lBt.forEach(t),$Lo=r(yDe," (DeiT model)"),yDe.forEach(t),kLo=i(Q),Ap=n(Q,"LI",{});var xDe=s(Ap);H_e=n(xDe,"STRONG",{});var iBt=s(H_e);SLo=r(iBt,"detr"),iBt.forEach(t),RLo=r(xDe," \u2014 "),VV=n(xDe,"A",{href:!0});var dBt=s(VV);PLo=r(dBt,"DetrFeatureExtractor"),dBt.forEach(t),BLo=r(xDe," (DETR model)"),xDe.forEach(t),ILo=i(Q),Lp=n(Q,"LI",{});var $De=s(Lp);J_e=n($De,"STRONG",{});var mBt=s(J_e);NLo=r(mBt,"donut-swin"),mBt.forEach(t),qLo=r($De," \u2014 "),XV=n($De,"A",{href:!0});var cBt=s(XV);jLo=r(cBt,"DonutFeatureExtractor"),cBt.forEach(t),DLo=r($De," (DonutSwin model)"),$De.forEach(t),GLo=i(Q),yp=n(Q,"LI",{});var kDe=s(yp);Y_e=n(kDe,"STRONG",{});var fBt=s(Y_e);OLo=r(fBt,"dpt"),fBt.forEach(t),VLo=r(kDe," \u2014 "),zV=n(kDe,"A",{href:!0});var gBt=s(zV);XLo=r(gBt,"DPTFeatureExtractor"),gBt.forEach(t),zLo=r(kDe," (DPT model)"),kDe.forEach(t),QLo=i(Q),xp=n(Q,"LI",{});var SDe=s(xp);Z_e=n(SDe,"STRONG",{});var hBt=s(Z_e);WLo=r(hBt,"flava"),hBt.forEach(t),ULo=r(SDe," \u2014 "),QV=n(SDe,"A",{href:!0});var uBt=s(QV);HLo=r(uBt,"FlavaFeatureExtractor"),uBt.forEach(t),JLo=r(SDe," (FLAVA model)"),SDe.forEach(t),YLo=i(Q),$p=n(Q,"LI",{});var RDe=s($p);K_e=n(RDe,"STRONG",{});var pBt=s(K_e);ZLo=r(pBt,"glpn"),pBt.forEach(t),KLo=r(RDe," \u2014 "),WV=n(RDe,"A",{href:!0});var _Bt=s(WV);eyo=r(_Bt,"GLPNFeatureExtractor"),_Bt.forEach(t),oyo=r(RDe," (GLPN model)"),RDe.forEach(t),ryo=i(Q),kp=n(Q,"LI",{});var PDe=s(kp);e1e=n(PDe,"STRONG",{});var bBt=s(e1e);tyo=r(bBt,"groupvit"),bBt.forEach(t),ayo=r(PDe," \u2014 "),UV=n(PDe,"A",{href:!0});var vBt=s(UV);nyo=r(vBt,"CLIPFeatureExtractor"),vBt.forEach(t),syo=r(PDe," (GroupViT model)"),PDe.forEach(t),lyo=i(Q),Sp=n(Q,"LI",{});var BDe=s(Sp);o1e=n(BDe,"STRONG",{});var FBt=s(o1e);iyo=r(FBt,"hubert"),FBt.forEach(t),dyo=r(BDe," \u2014 "),HV=n(BDe,"A",{href:!0});var TBt=s(HV);myo=r(TBt,"Wav2Vec2FeatureExtractor"),TBt.forEach(t),cyo=r(BDe," (Hubert model)"),BDe.forEach(t),fyo=i(Q),Rp=n(Q,"LI",{});var IDe=s(Rp);r1e=n(IDe,"STRONG",{});var MBt=s(r1e);gyo=r(MBt,"imagegpt"),MBt.forEach(t),hyo=r(IDe," \u2014 "),JV=n(IDe,"A",{href:!0});var EBt=s(JV);uyo=r(EBt,"ImageGPTFeatureExtractor"),EBt.forEach(t),pyo=r(IDe," (ImageGPT model)"),IDe.forEach(t),_yo=i(Q),Pp=n(Q,"LI",{});var NDe=s(Pp);t1e=n(NDe,"STRONG",{});var CBt=s(t1e);byo=r(CBt,"layoutlmv2"),CBt.forEach(t),vyo=r(NDe," \u2014 "),YV=n(NDe,"A",{href:!0});var wBt=s(YV);Fyo=r(wBt,"LayoutLMv2FeatureExtractor"),wBt.forEach(t),Tyo=r(NDe," (LayoutLMv2 model)"),NDe.forEach(t),Myo=i(Q),Bp=n(Q,"LI",{});var qDe=s(Bp);a1e=n(qDe,"STRONG",{});var ABt=s(a1e);Eyo=r(ABt,"layoutlmv3"),ABt.forEach(t),Cyo=r(qDe," \u2014 "),ZV=n(qDe,"A",{href:!0});var LBt=s(ZV);wyo=r(LBt,"LayoutLMv3FeatureExtractor"),LBt.forEach(t),Ayo=r(qDe," (LayoutLMv3 model)"),qDe.forEach(t),Lyo=i(Q),Ip=n(Q,"LI",{});var jDe=s(Ip);n1e=n(jDe,"STRONG",{});var yBt=s(n1e);yyo=r(yBt,"levit"),yBt.forEach(t),xyo=r(jDe," \u2014 "),KV=n(jDe,"A",{href:!0});var xBt=s(KV);$yo=r(xBt,"LevitFeatureExtractor"),xBt.forEach(t),kyo=r(jDe," (LeViT model)"),jDe.forEach(t),Syo=i(Q),Np=n(Q,"LI",{});var DDe=s(Np);s1e=n(DDe,"STRONG",{});var $Bt=s(s1e);Ryo=r($Bt,"maskformer"),$Bt.forEach(t),Pyo=r(DDe," \u2014 "),eX=n(DDe,"A",{href:!0});var kBt=s(eX);Byo=r(kBt,"MaskFormerFeatureExtractor"),kBt.forEach(t),Iyo=r(DDe," (MaskFormer model)"),DDe.forEach(t),Nyo=i(Q),qp=n(Q,"LI",{});var GDe=s(qp);l1e=n(GDe,"STRONG",{});var SBt=s(l1e);qyo=r(SBt,"mctct"),SBt.forEach(t),jyo=r(GDe," \u2014 "),oX=n(GDe,"A",{href:!0});var RBt=s(oX);Dyo=r(RBt,"MCTCTFeatureExtractor"),RBt.forEach(t),Gyo=r(GDe," (M-CTC-T model)"),GDe.forEach(t),Oyo=i(Q),jp=n(Q,"LI",{});var ODe=s(jp);i1e=n(ODe,"STRONG",{});var PBt=s(i1e);Vyo=r(PBt,"mobilevit"),PBt.forEach(t),Xyo=r(ODe," \u2014 "),rX=n(ODe,"A",{href:!0});var BBt=s(rX);zyo=r(BBt,"MobileViTFeatureExtractor"),BBt.forEach(t),Qyo=r(ODe," (MobileViT model)"),ODe.forEach(t),Wyo=i(Q),Dp=n(Q,"LI",{});var VDe=s(Dp);d1e=n(VDe,"STRONG",{});var IBt=s(d1e);Uyo=r(IBt,"owlvit"),IBt.forEach(t),Hyo=r(VDe," \u2014 "),tX=n(VDe,"A",{href:!0});var NBt=s(tX);Jyo=r(NBt,"OwlViTFeatureExtractor"),NBt.forEach(t),Yyo=r(VDe," (OWL-ViT model)"),VDe.forEach(t),Zyo=i(Q),Gp=n(Q,"LI",{});var XDe=s(Gp);m1e=n(XDe,"STRONG",{});var qBt=s(m1e);Kyo=r(qBt,"perceiver"),qBt.forEach(t),e9o=r(XDe," \u2014 "),aX=n(XDe,"A",{href:!0});var jBt=s(aX);o9o=r(jBt,"PerceiverFeatureExtractor"),jBt.forEach(t),r9o=r(XDe," (Perceiver model)"),XDe.forEach(t),t9o=i(Q),Op=n(Q,"LI",{});var zDe=s(Op);c1e=n(zDe,"STRONG",{});var DBt=s(c1e);a9o=r(DBt,"poolformer"),DBt.forEach(t),n9o=r(zDe," \u2014 "),nX=n(zDe,"A",{href:!0});var GBt=s(nX);s9o=r(GBt,"PoolFormerFeatureExtractor"),GBt.forEach(t),l9o=r(zDe," (PoolFormer model)"),zDe.forEach(t),i9o=i(Q),Vp=n(Q,"LI",{});var QDe=s(Vp);f1e=n(QDe,"STRONG",{});var OBt=s(f1e);d9o=r(OBt,"regnet"),OBt.forEach(t),m9o=r(QDe," \u2014 "),sX=n(QDe,"A",{href:!0});var VBt=s(sX);c9o=r(VBt,"ConvNextFeatureExtractor"),VBt.forEach(t),f9o=r(QDe," (RegNet model)"),QDe.forEach(t),g9o=i(Q),Xp=n(Q,"LI",{});var WDe=s(Xp);g1e=n(WDe,"STRONG",{});var XBt=s(g1e);h9o=r(XBt,"resnet"),XBt.forEach(t),u9o=r(WDe," \u2014 "),lX=n(WDe,"A",{href:!0});var zBt=s(lX);p9o=r(zBt,"ConvNextFeatureExtractor"),zBt.forEach(t),_9o=r(WDe," (ResNet model)"),WDe.forEach(t),b9o=i(Q),zp=n(Q,"LI",{});var UDe=s(zp);h1e=n(UDe,"STRONG",{});var QBt=s(h1e);v9o=r(QBt,"segformer"),QBt.forEach(t),F9o=r(UDe," \u2014 "),iX=n(UDe,"A",{href:!0});var WBt=s(iX);T9o=r(WBt,"SegformerFeatureExtractor"),WBt.forEach(t),M9o=r(UDe," (SegFormer model)"),UDe.forEach(t),E9o=i(Q),Qp=n(Q,"LI",{});var HDe=s(Qp);u1e=n(HDe,"STRONG",{});var UBt=s(u1e);C9o=r(UBt,"speech_to_text"),UBt.forEach(t),w9o=r(HDe," \u2014 "),dX=n(HDe,"A",{href:!0});var HBt=s(dX);A9o=r(HBt,"Speech2TextFeatureExtractor"),HBt.forEach(t),L9o=r(HDe," (Speech2Text model)"),HDe.forEach(t),y9o=i(Q),Wp=n(Q,"LI",{});var JDe=s(Wp);p1e=n(JDe,"STRONG",{});var JBt=s(p1e);x9o=r(JBt,"swin"),JBt.forEach(t),$9o=r(JDe," \u2014 "),mX=n(JDe,"A",{href:!0});var YBt=s(mX);k9o=r(YBt,"ViTFeatureExtractor"),YBt.forEach(t),S9o=r(JDe," (Swin Transformer model)"),JDe.forEach(t),R9o=i(Q),Up=n(Q,"LI",{});var YDe=s(Up);_1e=n(YDe,"STRONG",{});var ZBt=s(_1e);P9o=r(ZBt,"swinv2"),ZBt.forEach(t),B9o=r(YDe," \u2014 "),cX=n(YDe,"A",{href:!0});var KBt=s(cX);I9o=r(KBt,"ViTFeatureExtractor"),KBt.forEach(t),N9o=r(YDe," (Swin Transformer V2 model)"),YDe.forEach(t),q9o=i(Q),Hp=n(Q,"LI",{});var ZDe=s(Hp);b1e=n(ZDe,"STRONG",{});var eIt=s(b1e);j9o=r(eIt,"table-transformer"),eIt.forEach(t),D9o=r(ZDe," \u2014 "),fX=n(ZDe,"A",{href:!0});var oIt=s(fX);G9o=r(oIt,"DetrFeatureExtractor"),oIt.forEach(t),O9o=r(ZDe," (Table Transformer model)"),ZDe.forEach(t),V9o=i(Q),Jp=n(Q,"LI",{});var KDe=s(Jp);v1e=n(KDe,"STRONG",{});var rIt=s(v1e);X9o=r(rIt,"van"),rIt.forEach(t),z9o=r(KDe," \u2014 "),gX=n(KDe,"A",{href:!0});var tIt=s(gX);Q9o=r(tIt,"ConvNextFeatureExtractor"),tIt.forEach(t),W9o=r(KDe," (VAN model)"),KDe.forEach(t),U9o=i(Q),Yp=n(Q,"LI",{});var eGe=s(Yp);F1e=n(eGe,"STRONG",{});var aIt=s(F1e);H9o=r(aIt,"videomae"),aIt.forEach(t),J9o=r(eGe," \u2014 "),hX=n(eGe,"A",{href:!0});var nIt=s(hX);Y9o=r(nIt,"VideoMAEFeatureExtractor"),nIt.forEach(t),Z9o=r(eGe," (VideoMAE model)"),eGe.forEach(t),K9o=i(Q),Zp=n(Q,"LI",{});var oGe=s(Zp);T1e=n(oGe,"STRONG",{});var sIt=s(T1e);exo=r(sIt,"vilt"),sIt.forEach(t),oxo=r(oGe," \u2014 "),uX=n(oGe,"A",{href:!0});var lIt=s(uX);rxo=r(lIt,"ViltFeatureExtractor"),lIt.forEach(t),txo=r(oGe," (ViLT model)"),oGe.forEach(t),axo=i(Q),Kp=n(Q,"LI",{});var rGe=s(Kp);M1e=n(rGe,"STRONG",{});var iIt=s(M1e);nxo=r(iIt,"vit"),iIt.forEach(t),sxo=r(rGe," \u2014 "),pX=n(rGe,"A",{href:!0});var dIt=s(pX);lxo=r(dIt,"ViTFeatureExtractor"),dIt.forEach(t),ixo=r(rGe," (ViT model)"),rGe.forEach(t),dxo=i(Q),e_=n(Q,"LI",{});var tGe=s(e_);E1e=n(tGe,"STRONG",{});var mIt=s(E1e);mxo=r(mIt,"vit_mae"),mIt.forEach(t),cxo=r(tGe," \u2014 "),_X=n(tGe,"A",{href:!0});var cIt=s(_X);fxo=r(cIt,"ViTFeatureExtractor"),cIt.forEach(t),gxo=r(tGe," (ViTMAE model)"),tGe.forEach(t),hxo=i(Q),o_=n(Q,"LI",{});var aGe=s(o_);C1e=n(aGe,"STRONG",{});var fIt=s(C1e);uxo=r(fIt,"vit_msn"),fIt.forEach(t),pxo=r(aGe," \u2014 "),bX=n(aGe,"A",{href:!0});var gIt=s(bX);_xo=r(gIt,"ViTFeatureExtractor"),gIt.forEach(t),bxo=r(aGe," (ViTMSN model)"),aGe.forEach(t),vxo=i(Q),r_=n(Q,"LI",{});var nGe=s(r_);w1e=n(nGe,"STRONG",{});var hIt=s(w1e);Fxo=r(hIt,"wav2vec2"),hIt.forEach(t),Txo=r(nGe," \u2014 "),vX=n(nGe,"A",{href:!0});var uIt=s(vX);Mxo=r(uIt,"Wav2Vec2FeatureExtractor"),uIt.forEach(t),Exo=r(nGe," (Wav2Vec2 model)"),nGe.forEach(t),Cxo=i(Q),t_=n(Q,"LI",{});var sGe=s(t_);A1e=n(sGe,"STRONG",{});var pIt=s(A1e);wxo=r(pIt,"wav2vec2-conformer"),pIt.forEach(t),Axo=r(sGe," \u2014 "),FX=n(sGe,"A",{href:!0});var _It=s(FX);Lxo=r(_It,"Wav2Vec2FeatureExtractor"),_It.forEach(t),yxo=r(sGe," (Wav2Vec2-Conformer model)"),sGe.forEach(t),xxo=i(Q),a_=n(Q,"LI",{});var lGe=s(a_);L1e=n(lGe,"STRONG",{});var bIt=s(L1e);$xo=r(bIt,"whisper"),bIt.forEach(t),kxo=r(lGe," \u2014 "),TX=n(lGe,"A",{href:!0});var vIt=s(TX);Sxo=r(vIt,"WhisperFeatureExtractor"),vIt.forEach(t),Rxo=r(lGe," (Whisper model)"),lGe.forEach(t),Pxo=i(Q),n_=n(Q,"LI",{});var iGe=s(n_);y1e=n(iGe,"STRONG",{});var FIt=s(y1e);Bxo=r(FIt,"xclip"),FIt.forEach(t),Ixo=r(iGe," \u2014 "),MX=n(iGe,"A",{href:!0});var TIt=s(MX);Nxo=r(TIt,"CLIPFeatureExtractor"),TIt.forEach(t),qxo=r(iGe," (X-CLIP model)"),iGe.forEach(t),jxo=i(Q),s_=n(Q,"LI",{});var dGe=s(s_);x1e=n(dGe,"STRONG",{});var MIt=s(x1e);Dxo=r(MIt,"yolos"),MIt.forEach(t),Gxo=r(dGe," \u2014 "),EX=n(dGe,"A",{href:!0});var EIt=s(EX);Oxo=r(EIt,"YolosFeatureExtractor"),EIt.forEach(t),Vxo=r(dGe," (YOLOS model)"),dGe.forEach(t),Q.forEach(t),Xxo=i(wa),T(l_.$$.fragment,wa),zxo=i(wa),T(i_.$$.fragment,wa),wa.forEach(t),Qxo=i(Nl),d_=n(Nl,"DIV",{class:!0});var elo=s(d_);T(O$.$$.fragment,elo),Wxo=i(elo),$1e=n(elo,"P",{});var CIt=s($1e);Uxo=r(CIt,"Register a new feature extractor for this class."),CIt.forEach(t),elo.forEach(t),Nl.forEach(t),jao=i(c),kd=n(c,"H2",{class:!0});var olo=s(kd);m_=n(olo,"A",{id:!0,class:!0,href:!0});var wIt=s(m_);k1e=n(wIt,"SPAN",{});var AIt=s(k1e);T(V$.$$.fragment,AIt),AIt.forEach(t),wIt.forEach(t),Hxo=i(olo),S1e=n(olo,"SPAN",{});var LIt=s(S1e);Jxo=r(LIt,"AutoProcessor"),LIt.forEach(t),olo.forEach(t),Dao=i(c),Bo=n(c,"DIV",{class:!0});var ql=s(Bo);T(X$.$$.fragment,ql),Yxo=i(ql),z$=n(ql,"P",{});var rlo=s(z$);Zxo=r(rlo,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),CX=n(rlo,"A",{href:!0});var yIt=s(CX);Kxo=r(yIt,"AutoProcessor.from_pretrained()"),yIt.forEach(t),e$o=r(rlo," class method."),rlo.forEach(t),o$o=i(ql),Q$=n(ql,"P",{});var tlo=s(Q$);r$o=r(tlo,"This class cannot be instantiated directly using "),R1e=n(tlo,"CODE",{});var xIt=s(R1e);t$o=r(xIt,"__init__()"),xIt.forEach(t),a$o=r(tlo," (throws an error)."),tlo.forEach(t),n$o=i(ql),Ze=n(ql,"DIV",{class:!0});var Aa=s(Ze);T(W$.$$.fragment,Aa),s$o=i(Aa),P1e=n(Aa,"P",{});var $It=s(P1e);l$o=r($It,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),$It.forEach(t),i$o=i(Aa),Sd=n(Aa,"P",{});var Rme=s(Sd);d$o=r(Rme,"The processor class to instantiate is selected based on the "),B1e=n(Rme,"CODE",{});var kIt=s(B1e);m$o=r(kIt,"model_type"),kIt.forEach(t),c$o=r(Rme,` property of the config object (either
passed as an argument or loaded from `),I1e=n(Rme,"CODE",{});var SIt=s(I1e);f$o=r(SIt,"pretrained_model_name_or_path"),SIt.forEach(t),g$o=r(Rme," if possible):"),Rme.forEach(t),h$o=i(Aa),se=n(Aa,"UL",{});var de=s(se);c_=n(de,"LI",{});var mGe=s(c_);N1e=n(mGe,"STRONG",{});var RIt=s(N1e);u$o=r(RIt,"clip"),RIt.forEach(t),p$o=r(mGe," \u2014 "),wX=n(mGe,"A",{href:!0});var PIt=s(wX);_$o=r(PIt,"CLIPProcessor"),PIt.forEach(t),b$o=r(mGe," (CLIP model)"),mGe.forEach(t),v$o=i(de),f_=n(de,"LI",{});var cGe=s(f_);q1e=n(cGe,"STRONG",{});var BIt=s(q1e);F$o=r(BIt,"clipseg"),BIt.forEach(t),T$o=r(cGe," \u2014 "),AX=n(cGe,"A",{href:!0});var IIt=s(AX);M$o=r(IIt,"CLIPSegProcessor"),IIt.forEach(t),E$o=r(cGe," (CLIPSeg model)"),cGe.forEach(t),C$o=i(de),g_=n(de,"LI",{});var fGe=s(g_);j1e=n(fGe,"STRONG",{});var NIt=s(j1e);w$o=r(NIt,"flava"),NIt.forEach(t),A$o=r(fGe," \u2014 "),LX=n(fGe,"A",{href:!0});var qIt=s(LX);L$o=r(qIt,"FlavaProcessor"),qIt.forEach(t),y$o=r(fGe," (FLAVA model)"),fGe.forEach(t),x$o=i(de),h_=n(de,"LI",{});var gGe=s(h_);D1e=n(gGe,"STRONG",{});var jIt=s(D1e);$$o=r(jIt,"groupvit"),jIt.forEach(t),k$o=r(gGe," \u2014 "),yX=n(gGe,"A",{href:!0});var DIt=s(yX);S$o=r(DIt,"CLIPProcessor"),DIt.forEach(t),R$o=r(gGe," (GroupViT model)"),gGe.forEach(t),P$o=i(de),u_=n(de,"LI",{});var hGe=s(u_);G1e=n(hGe,"STRONG",{});var GIt=s(G1e);B$o=r(GIt,"layoutlmv2"),GIt.forEach(t),I$o=r(hGe," \u2014 "),xX=n(hGe,"A",{href:!0});var OIt=s(xX);N$o=r(OIt,"LayoutLMv2Processor"),OIt.forEach(t),q$o=r(hGe," (LayoutLMv2 model)"),hGe.forEach(t),j$o=i(de),p_=n(de,"LI",{});var uGe=s(p_);O1e=n(uGe,"STRONG",{});var VIt=s(O1e);D$o=r(VIt,"layoutlmv3"),VIt.forEach(t),G$o=r(uGe," \u2014 "),$X=n(uGe,"A",{href:!0});var XIt=s($X);O$o=r(XIt,"LayoutLMv3Processor"),XIt.forEach(t),V$o=r(uGe," (LayoutLMv3 model)"),uGe.forEach(t),X$o=i(de),__=n(de,"LI",{});var pGe=s(__);V1e=n(pGe,"STRONG",{});var zIt=s(V1e);z$o=r(zIt,"layoutxlm"),zIt.forEach(t),Q$o=r(pGe," \u2014 "),kX=n(pGe,"A",{href:!0});var QIt=s(kX);W$o=r(QIt,"LayoutXLMProcessor"),QIt.forEach(t),U$o=r(pGe," (LayoutXLM model)"),pGe.forEach(t),H$o=i(de),b_=n(de,"LI",{});var _Ge=s(b_);X1e=n(_Ge,"STRONG",{});var WIt=s(X1e);J$o=r(WIt,"markuplm"),WIt.forEach(t),Y$o=r(_Ge," \u2014 "),SX=n(_Ge,"A",{href:!0});var UIt=s(SX);Z$o=r(UIt,"MarkupLMProcessor"),UIt.forEach(t),K$o=r(_Ge," (MarkupLM model)"),_Ge.forEach(t),eko=i(de),v_=n(de,"LI",{});var bGe=s(v_);z1e=n(bGe,"STRONG",{});var HIt=s(z1e);oko=r(HIt,"owlvit"),HIt.forEach(t),rko=r(bGe," \u2014 "),RX=n(bGe,"A",{href:!0});var JIt=s(RX);tko=r(JIt,"OwlViTProcessor"),JIt.forEach(t),ako=r(bGe," (OWL-ViT model)"),bGe.forEach(t),nko=i(de),F_=n(de,"LI",{});var vGe=s(F_);Q1e=n(vGe,"STRONG",{});var YIt=s(Q1e);sko=r(YIt,"sew"),YIt.forEach(t),lko=r(vGe," \u2014 "),PX=n(vGe,"A",{href:!0});var ZIt=s(PX);iko=r(ZIt,"Wav2Vec2Processor"),ZIt.forEach(t),dko=r(vGe," (SEW model)"),vGe.forEach(t),mko=i(de),T_=n(de,"LI",{});var FGe=s(T_);W1e=n(FGe,"STRONG",{});var KIt=s(W1e);cko=r(KIt,"sew-d"),KIt.forEach(t),fko=r(FGe," \u2014 "),BX=n(FGe,"A",{href:!0});var eNt=s(BX);gko=r(eNt,"Wav2Vec2Processor"),eNt.forEach(t),hko=r(FGe," (SEW-D model)"),FGe.forEach(t),uko=i(de),M_=n(de,"LI",{});var TGe=s(M_);U1e=n(TGe,"STRONG",{});var oNt=s(U1e);pko=r(oNt,"speech_to_text"),oNt.forEach(t),_ko=r(TGe," \u2014 "),IX=n(TGe,"A",{href:!0});var rNt=s(IX);bko=r(rNt,"Speech2TextProcessor"),rNt.forEach(t),vko=r(TGe," (Speech2Text model)"),TGe.forEach(t),Fko=i(de),E_=n(de,"LI",{});var MGe=s(E_);H1e=n(MGe,"STRONG",{});var tNt=s(H1e);Tko=r(tNt,"speech_to_text_2"),tNt.forEach(t),Mko=r(MGe," \u2014 "),NX=n(MGe,"A",{href:!0});var aNt=s(NX);Eko=r(aNt,"Speech2Text2Processor"),aNt.forEach(t),Cko=r(MGe," (Speech2Text2 model)"),MGe.forEach(t),wko=i(de),C_=n(de,"LI",{});var EGe=s(C_);J1e=n(EGe,"STRONG",{});var nNt=s(J1e);Ako=r(nNt,"trocr"),nNt.forEach(t),Lko=r(EGe," \u2014 "),qX=n(EGe,"A",{href:!0});var sNt=s(qX);yko=r(sNt,"TrOCRProcessor"),sNt.forEach(t),xko=r(EGe," (TrOCR model)"),EGe.forEach(t),$ko=i(de),w_=n(de,"LI",{});var CGe=s(w_);Y1e=n(CGe,"STRONG",{});var lNt=s(Y1e);kko=r(lNt,"unispeech"),lNt.forEach(t),Sko=r(CGe," \u2014 "),jX=n(CGe,"A",{href:!0});var iNt=s(jX);Rko=r(iNt,"Wav2Vec2Processor"),iNt.forEach(t),Pko=r(CGe," (UniSpeech model)"),CGe.forEach(t),Bko=i(de),A_=n(de,"LI",{});var wGe=s(A_);Z1e=n(wGe,"STRONG",{});var dNt=s(Z1e);Iko=r(dNt,"unispeech-sat"),dNt.forEach(t),Nko=r(wGe," \u2014 "),DX=n(wGe,"A",{href:!0});var mNt=s(DX);qko=r(mNt,"Wav2Vec2Processor"),mNt.forEach(t),jko=r(wGe," (UniSpeechSat model)"),wGe.forEach(t),Dko=i(de),L_=n(de,"LI",{});var AGe=s(L_);K1e=n(AGe,"STRONG",{});var cNt=s(K1e);Gko=r(cNt,"vilt"),cNt.forEach(t),Oko=r(AGe," \u2014 "),GX=n(AGe,"A",{href:!0});var fNt=s(GX);Vko=r(fNt,"ViltProcessor"),fNt.forEach(t),Xko=r(AGe," (ViLT model)"),AGe.forEach(t),zko=i(de),y_=n(de,"LI",{});var LGe=s(y_);e2e=n(LGe,"STRONG",{});var gNt=s(e2e);Qko=r(gNt,"vision-text-dual-encoder"),gNt.forEach(t),Wko=r(LGe," \u2014 "),OX=n(LGe,"A",{href:!0});var hNt=s(OX);Uko=r(hNt,"VisionTextDualEncoderProcessor"),hNt.forEach(t),Hko=r(LGe," (VisionTextDualEncoder model)"),LGe.forEach(t),Jko=i(de),x_=n(de,"LI",{});var yGe=s(x_);o2e=n(yGe,"STRONG",{});var uNt=s(o2e);Yko=r(uNt,"wav2vec2"),uNt.forEach(t),Zko=r(yGe," \u2014 "),VX=n(yGe,"A",{href:!0});var pNt=s(VX);Kko=r(pNt,"Wav2Vec2Processor"),pNt.forEach(t),eSo=r(yGe," (Wav2Vec2 model)"),yGe.forEach(t),oSo=i(de),$_=n(de,"LI",{});var xGe=s($_);r2e=n(xGe,"STRONG",{});var _Nt=s(r2e);rSo=r(_Nt,"wav2vec2-conformer"),_Nt.forEach(t),tSo=r(xGe," \u2014 "),XX=n(xGe,"A",{href:!0});var bNt=s(XX);aSo=r(bNt,"Wav2Vec2Processor"),bNt.forEach(t),nSo=r(xGe," (Wav2Vec2-Conformer model)"),xGe.forEach(t),sSo=i(de),k_=n(de,"LI",{});var $Ge=s(k_);t2e=n($Ge,"STRONG",{});var vNt=s(t2e);lSo=r(vNt,"wavlm"),vNt.forEach(t),iSo=r($Ge," \u2014 "),zX=n($Ge,"A",{href:!0});var FNt=s(zX);dSo=r(FNt,"Wav2Vec2Processor"),FNt.forEach(t),mSo=r($Ge," (WavLM model)"),$Ge.forEach(t),cSo=i(de),S_=n(de,"LI",{});var kGe=s(S_);a2e=n(kGe,"STRONG",{});var TNt=s(a2e);fSo=r(TNt,"whisper"),TNt.forEach(t),gSo=r(kGe," \u2014 "),QX=n(kGe,"A",{href:!0});var MNt=s(QX);hSo=r(MNt,"WhisperProcessor"),MNt.forEach(t),uSo=r(kGe," (Whisper model)"),kGe.forEach(t),pSo=i(de),R_=n(de,"LI",{});var SGe=s(R_);n2e=n(SGe,"STRONG",{});var ENt=s(n2e);_So=r(ENt,"xclip"),ENt.forEach(t),bSo=r(SGe," \u2014 "),WX=n(SGe,"A",{href:!0});var CNt=s(WX);vSo=r(CNt,"XCLIPProcessor"),CNt.forEach(t),FSo=r(SGe," (X-CLIP model)"),SGe.forEach(t),de.forEach(t),TSo=i(Aa),T(P_.$$.fragment,Aa),MSo=i(Aa),T(B_.$$.fragment,Aa),Aa.forEach(t),ESo=i(ql),I_=n(ql,"DIV",{class:!0});var alo=s(I_);T(U$.$$.fragment,alo),CSo=i(alo),s2e=n(alo,"P",{});var wNt=s(s2e);wSo=r(wNt,"Register a new processor for this class."),wNt.forEach(t),alo.forEach(t),ql.forEach(t),Gao=i(c),Rd=n(c,"H2",{class:!0});var nlo=s(Rd);N_=n(nlo,"A",{id:!0,class:!0,href:!0});var ANt=s(N_);l2e=n(ANt,"SPAN",{});var LNt=s(l2e);T(H$.$$.fragment,LNt),LNt.forEach(t),ANt.forEach(t),ASo=i(nlo),i2e=n(nlo,"SPAN",{});var yNt=s(i2e);LSo=r(yNt,"AutoModel"),yNt.forEach(t),nlo.forEach(t),Oao=i(c),Io=n(c,"DIV",{class:!0});var jl=s(Io);T(J$.$$.fragment,jl),ySo=i(jl),Pd=n(jl,"P",{});var Pme=s(Pd);xSo=r(Pme,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),UX=n(Pme,"A",{href:!0});var xNt=s(UX);$So=r(xNt,"from_pretrained()"),xNt.forEach(t),kSo=r(Pme," class method or the "),HX=n(Pme,"A",{href:!0});var $Nt=s(HX);SSo=r($Nt,"from_config()"),$Nt.forEach(t),RSo=r(Pme,` class
method.`),Pme.forEach(t),PSo=i(jl),Y$=n(jl,"P",{});var slo=s(Y$);BSo=r(slo,"This class cannot be instantiated directly using "),d2e=n(slo,"CODE",{});var kNt=s(d2e);ISo=r(kNt,"__init__()"),kNt.forEach(t),NSo=r(slo," (throws an error)."),slo.forEach(t),qSo=i(jl),Mt=n(jl,"DIV",{class:!0});var h9=s(Mt);T(Z$.$$.fragment,h9),jSo=i(h9),m2e=n(h9,"P",{});var SNt=s(m2e);DSo=r(SNt,"Instantiates one of the base model classes of the library from a configuration."),SNt.forEach(t),GSo=i(h9),Bd=n(h9,"P",{});var Bme=s(Bd);OSo=r(Bme,`Note:
Loading a model from its configuration file does `),c2e=n(Bme,"STRONG",{});var RNt=s(c2e);VSo=r(RNt,"not"),RNt.forEach(t),XSo=r(Bme,` load the model weights. It only affects the
model\u2019s configuration. Use `),JX=n(Bme,"A",{href:!0});var PNt=s(JX);zSo=r(PNt,"from_pretrained()"),PNt.forEach(t),QSo=r(Bme," to load the model weights."),Bme.forEach(t),WSo=i(h9),T(q_.$$.fragment,h9),h9.forEach(t),USo=i(jl),Ke=n(jl,"DIV",{class:!0});var La=s(Ke);T(K$.$$.fragment,La),HSo=i(La),f2e=n(La,"P",{});var BNt=s(f2e);JSo=r(BNt,"Instantiate one of the base model classes of the library from a pretrained model."),BNt.forEach(t),YSo=i(La),nn=n(La,"P",{});var u9=s(nn);ZSo=r(u9,"The model class to instantiate is selected based on the "),g2e=n(u9,"CODE",{});var INt=s(g2e);KSo=r(INt,"model_type"),INt.forEach(t),eRo=r(u9,` property of the config object (either
passed as an argument or loaded from `),h2e=n(u9,"CODE",{});var NNt=s(h2e);oRo=r(NNt,"pretrained_model_name_or_path"),NNt.forEach(t),rRo=r(u9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u2e=n(u9,"CODE",{});var qNt=s(u2e);tRo=r(qNt,"pretrained_model_name_or_path"),qNt.forEach(t),aRo=r(u9,":"),u9.forEach(t),nRo=i(La),y=n(La,"UL",{});var x=s(y);j_=n(x,"LI",{});var RGe=s(j_);p2e=n(RGe,"STRONG",{});var jNt=s(p2e);sRo=r(jNt,"albert"),jNt.forEach(t),lRo=r(RGe," \u2014 "),YX=n(RGe,"A",{href:!0});var DNt=s(YX);iRo=r(DNt,"AlbertModel"),DNt.forEach(t),dRo=r(RGe," (ALBERT model)"),RGe.forEach(t),mRo=i(x),D_=n(x,"LI",{});var PGe=s(D_);_2e=n(PGe,"STRONG",{});var GNt=s(_2e);cRo=r(GNt,"bart"),GNt.forEach(t),fRo=r(PGe," \u2014 "),ZX=n(PGe,"A",{href:!0});var ONt=s(ZX);gRo=r(ONt,"BartModel"),ONt.forEach(t),hRo=r(PGe," (BART model)"),PGe.forEach(t),uRo=i(x),G_=n(x,"LI",{});var BGe=s(G_);b2e=n(BGe,"STRONG",{});var VNt=s(b2e);pRo=r(VNt,"beit"),VNt.forEach(t),_Ro=r(BGe," \u2014 "),KX=n(BGe,"A",{href:!0});var XNt=s(KX);bRo=r(XNt,"BeitModel"),XNt.forEach(t),vRo=r(BGe," (BEiT model)"),BGe.forEach(t),FRo=i(x),O_=n(x,"LI",{});var IGe=s(O_);v2e=n(IGe,"STRONG",{});var zNt=s(v2e);TRo=r(zNt,"bert"),zNt.forEach(t),MRo=r(IGe," \u2014 "),ez=n(IGe,"A",{href:!0});var QNt=s(ez);ERo=r(QNt,"BertModel"),QNt.forEach(t),CRo=r(IGe," (BERT model)"),IGe.forEach(t),wRo=i(x),V_=n(x,"LI",{});var NGe=s(V_);F2e=n(NGe,"STRONG",{});var WNt=s(F2e);ARo=r(WNt,"bert-generation"),WNt.forEach(t),LRo=r(NGe," \u2014 "),oz=n(NGe,"A",{href:!0});var UNt=s(oz);yRo=r(UNt,"BertGenerationEncoder"),UNt.forEach(t),xRo=r(NGe," (Bert Generation model)"),NGe.forEach(t),$Ro=i(x),X_=n(x,"LI",{});var qGe=s(X_);T2e=n(qGe,"STRONG",{});var HNt=s(T2e);kRo=r(HNt,"big_bird"),HNt.forEach(t),SRo=r(qGe," \u2014 "),rz=n(qGe,"A",{href:!0});var JNt=s(rz);RRo=r(JNt,"BigBirdModel"),JNt.forEach(t),PRo=r(qGe," (BigBird model)"),qGe.forEach(t),BRo=i(x),z_=n(x,"LI",{});var jGe=s(z_);M2e=n(jGe,"STRONG",{});var YNt=s(M2e);IRo=r(YNt,"bigbird_pegasus"),YNt.forEach(t),NRo=r(jGe," \u2014 "),tz=n(jGe,"A",{href:!0});var ZNt=s(tz);qRo=r(ZNt,"BigBirdPegasusModel"),ZNt.forEach(t),jRo=r(jGe," (BigBird-Pegasus model)"),jGe.forEach(t),DRo=i(x),Q_=n(x,"LI",{});var DGe=s(Q_);E2e=n(DGe,"STRONG",{});var KNt=s(E2e);GRo=r(KNt,"blenderbot"),KNt.forEach(t),ORo=r(DGe," \u2014 "),az=n(DGe,"A",{href:!0});var eqt=s(az);VRo=r(eqt,"BlenderbotModel"),eqt.forEach(t),XRo=r(DGe," (Blenderbot model)"),DGe.forEach(t),zRo=i(x),W_=n(x,"LI",{});var GGe=s(W_);C2e=n(GGe,"STRONG",{});var oqt=s(C2e);QRo=r(oqt,"blenderbot-small"),oqt.forEach(t),WRo=r(GGe," \u2014 "),nz=n(GGe,"A",{href:!0});var rqt=s(nz);URo=r(rqt,"BlenderbotSmallModel"),rqt.forEach(t),HRo=r(GGe," (BlenderbotSmall model)"),GGe.forEach(t),JRo=i(x),U_=n(x,"LI",{});var OGe=s(U_);w2e=n(OGe,"STRONG",{});var tqt=s(w2e);YRo=r(tqt,"bloom"),tqt.forEach(t),ZRo=r(OGe," \u2014 "),sz=n(OGe,"A",{href:!0});var aqt=s(sz);KRo=r(aqt,"BloomModel"),aqt.forEach(t),ePo=r(OGe," (BLOOM model)"),OGe.forEach(t),oPo=i(x),H_=n(x,"LI",{});var VGe=s(H_);A2e=n(VGe,"STRONG",{});var nqt=s(A2e);rPo=r(nqt,"camembert"),nqt.forEach(t),tPo=r(VGe," \u2014 "),lz=n(VGe,"A",{href:!0});var sqt=s(lz);aPo=r(sqt,"CamembertModel"),sqt.forEach(t),nPo=r(VGe," (CamemBERT model)"),VGe.forEach(t),sPo=i(x),J_=n(x,"LI",{});var XGe=s(J_);L2e=n(XGe,"STRONG",{});var lqt=s(L2e);lPo=r(lqt,"canine"),lqt.forEach(t),iPo=r(XGe," \u2014 "),iz=n(XGe,"A",{href:!0});var iqt=s(iz);dPo=r(iqt,"CanineModel"),iqt.forEach(t),mPo=r(XGe," (CANINE model)"),XGe.forEach(t),cPo=i(x),Y_=n(x,"LI",{});var zGe=s(Y_);y2e=n(zGe,"STRONG",{});var dqt=s(y2e);fPo=r(dqt,"clip"),dqt.forEach(t),gPo=r(zGe," \u2014 "),dz=n(zGe,"A",{href:!0});var mqt=s(dz);hPo=r(mqt,"CLIPModel"),mqt.forEach(t),uPo=r(zGe," (CLIP model)"),zGe.forEach(t),pPo=i(x),Z_=n(x,"LI",{});var QGe=s(Z_);x2e=n(QGe,"STRONG",{});var cqt=s(x2e);_Po=r(cqt,"clipseg"),cqt.forEach(t),bPo=r(QGe," \u2014 "),mz=n(QGe,"A",{href:!0});var fqt=s(mz);vPo=r(fqt,"CLIPSegModel"),fqt.forEach(t),FPo=r(QGe," (CLIPSeg model)"),QGe.forEach(t),TPo=i(x),K_=n(x,"LI",{});var WGe=s(K_);$2e=n(WGe,"STRONG",{});var gqt=s($2e);MPo=r(gqt,"codegen"),gqt.forEach(t),EPo=r(WGe," \u2014 "),cz=n(WGe,"A",{href:!0});var hqt=s(cz);CPo=r(hqt,"CodeGenModel"),hqt.forEach(t),wPo=r(WGe," (CodeGen model)"),WGe.forEach(t),APo=i(x),e1=n(x,"LI",{});var UGe=s(e1);k2e=n(UGe,"STRONG",{});var uqt=s(k2e);LPo=r(uqt,"conditional_detr"),uqt.forEach(t),yPo=r(UGe," \u2014 "),fz=n(UGe,"A",{href:!0});var pqt=s(fz);xPo=r(pqt,"ConditionalDetrModel"),pqt.forEach(t),$Po=r(UGe," (Conditional DETR model)"),UGe.forEach(t),kPo=i(x),o1=n(x,"LI",{});var HGe=s(o1);S2e=n(HGe,"STRONG",{});var _qt=s(S2e);SPo=r(_qt,"convbert"),_qt.forEach(t),RPo=r(HGe," \u2014 "),gz=n(HGe,"A",{href:!0});var bqt=s(gz);PPo=r(bqt,"ConvBertModel"),bqt.forEach(t),BPo=r(HGe," (ConvBERT model)"),HGe.forEach(t),IPo=i(x),r1=n(x,"LI",{});var JGe=s(r1);R2e=n(JGe,"STRONG",{});var vqt=s(R2e);NPo=r(vqt,"convnext"),vqt.forEach(t),qPo=r(JGe," \u2014 "),hz=n(JGe,"A",{href:!0});var Fqt=s(hz);jPo=r(Fqt,"ConvNextModel"),Fqt.forEach(t),DPo=r(JGe," (ConvNeXT model)"),JGe.forEach(t),GPo=i(x),t1=n(x,"LI",{});var YGe=s(t1);P2e=n(YGe,"STRONG",{});var Tqt=s(P2e);OPo=r(Tqt,"ctrl"),Tqt.forEach(t),VPo=r(YGe," \u2014 "),uz=n(YGe,"A",{href:!0});var Mqt=s(uz);XPo=r(Mqt,"CTRLModel"),Mqt.forEach(t),zPo=r(YGe," (CTRL model)"),YGe.forEach(t),QPo=i(x),a1=n(x,"LI",{});var ZGe=s(a1);B2e=n(ZGe,"STRONG",{});var Eqt=s(B2e);WPo=r(Eqt,"cvt"),Eqt.forEach(t),UPo=r(ZGe," \u2014 "),pz=n(ZGe,"A",{href:!0});var Cqt=s(pz);HPo=r(Cqt,"CvtModel"),Cqt.forEach(t),JPo=r(ZGe," (CvT model)"),ZGe.forEach(t),YPo=i(x),n1=n(x,"LI",{});var KGe=s(n1);I2e=n(KGe,"STRONG",{});var wqt=s(I2e);ZPo=r(wqt,"data2vec-audio"),wqt.forEach(t),KPo=r(KGe," \u2014 "),_z=n(KGe,"A",{href:!0});var Aqt=s(_z);eBo=r(Aqt,"Data2VecAudioModel"),Aqt.forEach(t),oBo=r(KGe," (Data2VecAudio model)"),KGe.forEach(t),rBo=i(x),s1=n(x,"LI",{});var eOe=s(s1);N2e=n(eOe,"STRONG",{});var Lqt=s(N2e);tBo=r(Lqt,"data2vec-text"),Lqt.forEach(t),aBo=r(eOe," \u2014 "),bz=n(eOe,"A",{href:!0});var yqt=s(bz);nBo=r(yqt,"Data2VecTextModel"),yqt.forEach(t),sBo=r(eOe," (Data2VecText model)"),eOe.forEach(t),lBo=i(x),l1=n(x,"LI",{});var oOe=s(l1);q2e=n(oOe,"STRONG",{});var xqt=s(q2e);iBo=r(xqt,"data2vec-vision"),xqt.forEach(t),dBo=r(oOe," \u2014 "),vz=n(oOe,"A",{href:!0});var $qt=s(vz);mBo=r($qt,"Data2VecVisionModel"),$qt.forEach(t),cBo=r(oOe," (Data2VecVision model)"),oOe.forEach(t),fBo=i(x),i1=n(x,"LI",{});var rOe=s(i1);j2e=n(rOe,"STRONG",{});var kqt=s(j2e);gBo=r(kqt,"deberta"),kqt.forEach(t),hBo=r(rOe," \u2014 "),Fz=n(rOe,"A",{href:!0});var Sqt=s(Fz);uBo=r(Sqt,"DebertaModel"),Sqt.forEach(t),pBo=r(rOe," (DeBERTa model)"),rOe.forEach(t),_Bo=i(x),d1=n(x,"LI",{});var tOe=s(d1);D2e=n(tOe,"STRONG",{});var Rqt=s(D2e);bBo=r(Rqt,"deberta-v2"),Rqt.forEach(t),vBo=r(tOe," \u2014 "),Tz=n(tOe,"A",{href:!0});var Pqt=s(Tz);FBo=r(Pqt,"DebertaV2Model"),Pqt.forEach(t),TBo=r(tOe," (DeBERTa-v2 model)"),tOe.forEach(t),MBo=i(x),m1=n(x,"LI",{});var aOe=s(m1);G2e=n(aOe,"STRONG",{});var Bqt=s(G2e);EBo=r(Bqt,"decision_transformer"),Bqt.forEach(t),CBo=r(aOe," \u2014 "),Mz=n(aOe,"A",{href:!0});var Iqt=s(Mz);wBo=r(Iqt,"DecisionTransformerModel"),Iqt.forEach(t),ABo=r(aOe," (Decision Transformer model)"),aOe.forEach(t),LBo=i(x),c1=n(x,"LI",{});var nOe=s(c1);O2e=n(nOe,"STRONG",{});var Nqt=s(O2e);yBo=r(Nqt,"deformable_detr"),Nqt.forEach(t),xBo=r(nOe," \u2014 "),Ez=n(nOe,"A",{href:!0});var qqt=s(Ez);$Bo=r(qqt,"DeformableDetrModel"),qqt.forEach(t),kBo=r(nOe," (Deformable DETR model)"),nOe.forEach(t),SBo=i(x),f1=n(x,"LI",{});var sOe=s(f1);V2e=n(sOe,"STRONG",{});var jqt=s(V2e);RBo=r(jqt,"deit"),jqt.forEach(t),PBo=r(sOe," \u2014 "),Cz=n(sOe,"A",{href:!0});var Dqt=s(Cz);BBo=r(Dqt,"DeiTModel"),Dqt.forEach(t),IBo=r(sOe," (DeiT model)"),sOe.forEach(t),NBo=i(x),g1=n(x,"LI",{});var lOe=s(g1);X2e=n(lOe,"STRONG",{});var Gqt=s(X2e);qBo=r(Gqt,"detr"),Gqt.forEach(t),jBo=r(lOe," \u2014 "),wz=n(lOe,"A",{href:!0});var Oqt=s(wz);DBo=r(Oqt,"DetrModel"),Oqt.forEach(t),GBo=r(lOe," (DETR model)"),lOe.forEach(t),OBo=i(x),h1=n(x,"LI",{});var iOe=s(h1);z2e=n(iOe,"STRONG",{});var Vqt=s(z2e);VBo=r(Vqt,"distilbert"),Vqt.forEach(t),XBo=r(iOe," \u2014 "),Az=n(iOe,"A",{href:!0});var Xqt=s(Az);zBo=r(Xqt,"DistilBertModel"),Xqt.forEach(t),QBo=r(iOe," (DistilBERT model)"),iOe.forEach(t),WBo=i(x),u1=n(x,"LI",{});var dOe=s(u1);Q2e=n(dOe,"STRONG",{});var zqt=s(Q2e);UBo=r(zqt,"donut-swin"),zqt.forEach(t),HBo=r(dOe," \u2014 "),Lz=n(dOe,"A",{href:!0});var Qqt=s(Lz);JBo=r(Qqt,"DonutSwinModel"),Qqt.forEach(t),YBo=r(dOe," (DonutSwin model)"),dOe.forEach(t),ZBo=i(x),p1=n(x,"LI",{});var mOe=s(p1);W2e=n(mOe,"STRONG",{});var Wqt=s(W2e);KBo=r(Wqt,"dpr"),Wqt.forEach(t),eIo=r(mOe," \u2014 "),yz=n(mOe,"A",{href:!0});var Uqt=s(yz);oIo=r(Uqt,"DPRQuestionEncoder"),Uqt.forEach(t),rIo=r(mOe," (DPR model)"),mOe.forEach(t),tIo=i(x),_1=n(x,"LI",{});var cOe=s(_1);U2e=n(cOe,"STRONG",{});var Hqt=s(U2e);aIo=r(Hqt,"dpt"),Hqt.forEach(t),nIo=r(cOe," \u2014 "),xz=n(cOe,"A",{href:!0});var Jqt=s(xz);sIo=r(Jqt,"DPTModel"),Jqt.forEach(t),lIo=r(cOe," (DPT model)"),cOe.forEach(t),iIo=i(x),b1=n(x,"LI",{});var fOe=s(b1);H2e=n(fOe,"STRONG",{});var Yqt=s(H2e);dIo=r(Yqt,"electra"),Yqt.forEach(t),mIo=r(fOe," \u2014 "),$z=n(fOe,"A",{href:!0});var Zqt=s($z);cIo=r(Zqt,"ElectraModel"),Zqt.forEach(t),fIo=r(fOe," (ELECTRA model)"),fOe.forEach(t),gIo=i(x),v1=n(x,"LI",{});var gOe=s(v1);J2e=n(gOe,"STRONG",{});var Kqt=s(J2e);hIo=r(Kqt,"ernie"),Kqt.forEach(t),uIo=r(gOe," \u2014 "),kz=n(gOe,"A",{href:!0});var ejt=s(kz);pIo=r(ejt,"ErnieModel"),ejt.forEach(t),_Io=r(gOe," (ERNIE model)"),gOe.forEach(t),bIo=i(x),F1=n(x,"LI",{});var hOe=s(F1);Y2e=n(hOe,"STRONG",{});var ojt=s(Y2e);vIo=r(ojt,"esm"),ojt.forEach(t),FIo=r(hOe," \u2014 "),Sz=n(hOe,"A",{href:!0});var rjt=s(Sz);TIo=r(rjt,"EsmModel"),rjt.forEach(t),MIo=r(hOe," (ESM model)"),hOe.forEach(t),EIo=i(x),T1=n(x,"LI",{});var uOe=s(T1);Z2e=n(uOe,"STRONG",{});var tjt=s(Z2e);CIo=r(tjt,"flaubert"),tjt.forEach(t),wIo=r(uOe," \u2014 "),Rz=n(uOe,"A",{href:!0});var ajt=s(Rz);AIo=r(ajt,"FlaubertModel"),ajt.forEach(t),LIo=r(uOe," (FlauBERT model)"),uOe.forEach(t),yIo=i(x),M1=n(x,"LI",{});var pOe=s(M1);K2e=n(pOe,"STRONG",{});var njt=s(K2e);xIo=r(njt,"flava"),njt.forEach(t),$Io=r(pOe," \u2014 "),Pz=n(pOe,"A",{href:!0});var sjt=s(Pz);kIo=r(sjt,"FlavaModel"),sjt.forEach(t),SIo=r(pOe," (FLAVA model)"),pOe.forEach(t),RIo=i(x),E1=n(x,"LI",{});var _Oe=s(E1);ebe=n(_Oe,"STRONG",{});var ljt=s(ebe);PIo=r(ljt,"fnet"),ljt.forEach(t),BIo=r(_Oe," \u2014 "),Bz=n(_Oe,"A",{href:!0});var ijt=s(Bz);IIo=r(ijt,"FNetModel"),ijt.forEach(t),NIo=r(_Oe," (FNet model)"),_Oe.forEach(t),qIo=i(x),C1=n(x,"LI",{});var bOe=s(C1);obe=n(bOe,"STRONG",{});var djt=s(obe);jIo=r(djt,"fsmt"),djt.forEach(t),DIo=r(bOe," \u2014 "),Iz=n(bOe,"A",{href:!0});var mjt=s(Iz);GIo=r(mjt,"FSMTModel"),mjt.forEach(t),OIo=r(bOe," (FairSeq Machine-Translation model)"),bOe.forEach(t),VIo=i(x),$l=n(x,"LI",{});var SN=s($l);rbe=n(SN,"STRONG",{});var cjt=s(rbe);XIo=r(cjt,"funnel"),cjt.forEach(t),zIo=r(SN," \u2014 "),Nz=n(SN,"A",{href:!0});var fjt=s(Nz);QIo=r(fjt,"FunnelModel"),fjt.forEach(t),WIo=r(SN," or "),qz=n(SN,"A",{href:!0});var gjt=s(qz);UIo=r(gjt,"FunnelBaseModel"),gjt.forEach(t),HIo=r(SN," (Funnel Transformer model)"),SN.forEach(t),JIo=i(x),w1=n(x,"LI",{});var vOe=s(w1);tbe=n(vOe,"STRONG",{});var hjt=s(tbe);YIo=r(hjt,"glpn"),hjt.forEach(t),ZIo=r(vOe," \u2014 "),jz=n(vOe,"A",{href:!0});var ujt=s(jz);KIo=r(ujt,"GLPNModel"),ujt.forEach(t),eNo=r(vOe," (GLPN model)"),vOe.forEach(t),oNo=i(x),A1=n(x,"LI",{});var FOe=s(A1);abe=n(FOe,"STRONG",{});var pjt=s(abe);rNo=r(pjt,"gpt2"),pjt.forEach(t),tNo=r(FOe," \u2014 "),Dz=n(FOe,"A",{href:!0});var _jt=s(Dz);aNo=r(_jt,"GPT2Model"),_jt.forEach(t),nNo=r(FOe," (OpenAI GPT-2 model)"),FOe.forEach(t),sNo=i(x),L1=n(x,"LI",{});var TOe=s(L1);nbe=n(TOe,"STRONG",{});var bjt=s(nbe);lNo=r(bjt,"gpt_neo"),bjt.forEach(t),iNo=r(TOe," \u2014 "),Gz=n(TOe,"A",{href:!0});var vjt=s(Gz);dNo=r(vjt,"GPTNeoModel"),vjt.forEach(t),mNo=r(TOe," (GPT Neo model)"),TOe.forEach(t),cNo=i(x),y1=n(x,"LI",{});var MOe=s(y1);sbe=n(MOe,"STRONG",{});var Fjt=s(sbe);fNo=r(Fjt,"gpt_neox"),Fjt.forEach(t),gNo=r(MOe," \u2014 "),Oz=n(MOe,"A",{href:!0});var Tjt=s(Oz);hNo=r(Tjt,"GPTNeoXModel"),Tjt.forEach(t),uNo=r(MOe," (GPT NeoX model)"),MOe.forEach(t),pNo=i(x),x1=n(x,"LI",{});var EOe=s(x1);lbe=n(EOe,"STRONG",{});var Mjt=s(lbe);_No=r(Mjt,"gpt_neox_japanese"),Mjt.forEach(t),bNo=r(EOe," \u2014 "),Vz=n(EOe,"A",{href:!0});var Ejt=s(Vz);vNo=r(Ejt,"GPTNeoXJapaneseModel"),Ejt.forEach(t),FNo=r(EOe," (GPT NeoX Japanese model)"),EOe.forEach(t),TNo=i(x),$1=n(x,"LI",{});var COe=s($1);ibe=n(COe,"STRONG",{});var Cjt=s(ibe);MNo=r(Cjt,"gptj"),Cjt.forEach(t),ENo=r(COe," \u2014 "),Xz=n(COe,"A",{href:!0});var wjt=s(Xz);CNo=r(wjt,"GPTJModel"),wjt.forEach(t),wNo=r(COe," (GPT-J model)"),COe.forEach(t),ANo=i(x),k1=n(x,"LI",{});var wOe=s(k1);dbe=n(wOe,"STRONG",{});var Ajt=s(dbe);LNo=r(Ajt,"groupvit"),Ajt.forEach(t),yNo=r(wOe," \u2014 "),zz=n(wOe,"A",{href:!0});var Ljt=s(zz);xNo=r(Ljt,"GroupViTModel"),Ljt.forEach(t),$No=r(wOe," (GroupViT model)"),wOe.forEach(t),kNo=i(x),S1=n(x,"LI",{});var AOe=s(S1);mbe=n(AOe,"STRONG",{});var yjt=s(mbe);SNo=r(yjt,"hubert"),yjt.forEach(t),RNo=r(AOe," \u2014 "),Qz=n(AOe,"A",{href:!0});var xjt=s(Qz);PNo=r(xjt,"HubertModel"),xjt.forEach(t),BNo=r(AOe," (Hubert model)"),AOe.forEach(t),INo=i(x),R1=n(x,"LI",{});var LOe=s(R1);cbe=n(LOe,"STRONG",{});var $jt=s(cbe);NNo=r($jt,"ibert"),$jt.forEach(t),qNo=r(LOe," \u2014 "),Wz=n(LOe,"A",{href:!0});var kjt=s(Wz);jNo=r(kjt,"IBertModel"),kjt.forEach(t),DNo=r(LOe," (I-BERT model)"),LOe.forEach(t),GNo=i(x),P1=n(x,"LI",{});var yOe=s(P1);fbe=n(yOe,"STRONG",{});var Sjt=s(fbe);ONo=r(Sjt,"imagegpt"),Sjt.forEach(t),VNo=r(yOe," \u2014 "),Uz=n(yOe,"A",{href:!0});var Rjt=s(Uz);XNo=r(Rjt,"ImageGPTModel"),Rjt.forEach(t),zNo=r(yOe," (ImageGPT model)"),yOe.forEach(t),QNo=i(x),B1=n(x,"LI",{});var xOe=s(B1);gbe=n(xOe,"STRONG",{});var Pjt=s(gbe);WNo=r(Pjt,"layoutlm"),Pjt.forEach(t),UNo=r(xOe," \u2014 "),Hz=n(xOe,"A",{href:!0});var Bjt=s(Hz);HNo=r(Bjt,"LayoutLMModel"),Bjt.forEach(t),JNo=r(xOe," (LayoutLM model)"),xOe.forEach(t),YNo=i(x),I1=n(x,"LI",{});var $Oe=s(I1);hbe=n($Oe,"STRONG",{});var Ijt=s(hbe);ZNo=r(Ijt,"layoutlmv2"),Ijt.forEach(t),KNo=r($Oe," \u2014 "),Jz=n($Oe,"A",{href:!0});var Njt=s(Jz);eqo=r(Njt,"LayoutLMv2Model"),Njt.forEach(t),oqo=r($Oe," (LayoutLMv2 model)"),$Oe.forEach(t),rqo=i(x),N1=n(x,"LI",{});var kOe=s(N1);ube=n(kOe,"STRONG",{});var qjt=s(ube);tqo=r(qjt,"layoutlmv3"),qjt.forEach(t),aqo=r(kOe," \u2014 "),Yz=n(kOe,"A",{href:!0});var jjt=s(Yz);nqo=r(jjt,"LayoutLMv3Model"),jjt.forEach(t),sqo=r(kOe," (LayoutLMv3 model)"),kOe.forEach(t),lqo=i(x),q1=n(x,"LI",{});var SOe=s(q1);pbe=n(SOe,"STRONG",{});var Djt=s(pbe);iqo=r(Djt,"led"),Djt.forEach(t),dqo=r(SOe," \u2014 "),Zz=n(SOe,"A",{href:!0});var Gjt=s(Zz);mqo=r(Gjt,"LEDModel"),Gjt.forEach(t),cqo=r(SOe," (LED model)"),SOe.forEach(t),fqo=i(x),j1=n(x,"LI",{});var ROe=s(j1);_be=n(ROe,"STRONG",{});var Ojt=s(_be);gqo=r(Ojt,"levit"),Ojt.forEach(t),hqo=r(ROe," \u2014 "),Kz=n(ROe,"A",{href:!0});var Vjt=s(Kz);uqo=r(Vjt,"LevitModel"),Vjt.forEach(t),pqo=r(ROe," (LeViT model)"),ROe.forEach(t),_qo=i(x),D1=n(x,"LI",{});var POe=s(D1);bbe=n(POe,"STRONG",{});var Xjt=s(bbe);bqo=r(Xjt,"lilt"),Xjt.forEach(t),vqo=r(POe," \u2014 "),eQ=n(POe,"A",{href:!0});var zjt=s(eQ);Fqo=r(zjt,"LiltModel"),zjt.forEach(t),Tqo=r(POe," (LiLT model)"),POe.forEach(t),Mqo=i(x),G1=n(x,"LI",{});var BOe=s(G1);vbe=n(BOe,"STRONG",{});var Qjt=s(vbe);Eqo=r(Qjt,"longformer"),Qjt.forEach(t),Cqo=r(BOe," \u2014 "),oQ=n(BOe,"A",{href:!0});var Wjt=s(oQ);wqo=r(Wjt,"LongformerModel"),Wjt.forEach(t),Aqo=r(BOe," (Longformer model)"),BOe.forEach(t),Lqo=i(x),O1=n(x,"LI",{});var IOe=s(O1);Fbe=n(IOe,"STRONG",{});var Ujt=s(Fbe);yqo=r(Ujt,"longt5"),Ujt.forEach(t),xqo=r(IOe," \u2014 "),rQ=n(IOe,"A",{href:!0});var Hjt=s(rQ);$qo=r(Hjt,"LongT5Model"),Hjt.forEach(t),kqo=r(IOe," (LongT5 model)"),IOe.forEach(t),Sqo=i(x),V1=n(x,"LI",{});var NOe=s(V1);Tbe=n(NOe,"STRONG",{});var Jjt=s(Tbe);Rqo=r(Jjt,"luke"),Jjt.forEach(t),Pqo=r(NOe," \u2014 "),tQ=n(NOe,"A",{href:!0});var Yjt=s(tQ);Bqo=r(Yjt,"LukeModel"),Yjt.forEach(t),Iqo=r(NOe," (LUKE model)"),NOe.forEach(t),Nqo=i(x),X1=n(x,"LI",{});var qOe=s(X1);Mbe=n(qOe,"STRONG",{});var Zjt=s(Mbe);qqo=r(Zjt,"lxmert"),Zjt.forEach(t),jqo=r(qOe," \u2014 "),aQ=n(qOe,"A",{href:!0});var Kjt=s(aQ);Dqo=r(Kjt,"LxmertModel"),Kjt.forEach(t),Gqo=r(qOe," (LXMERT model)"),qOe.forEach(t),Oqo=i(x),z1=n(x,"LI",{});var jOe=s(z1);Ebe=n(jOe,"STRONG",{});var eDt=s(Ebe);Vqo=r(eDt,"m2m_100"),eDt.forEach(t),Xqo=r(jOe," \u2014 "),nQ=n(jOe,"A",{href:!0});var oDt=s(nQ);zqo=r(oDt,"M2M100Model"),oDt.forEach(t),Qqo=r(jOe," (M2M100 model)"),jOe.forEach(t),Wqo=i(x),Q1=n(x,"LI",{});var DOe=s(Q1);Cbe=n(DOe,"STRONG",{});var rDt=s(Cbe);Uqo=r(rDt,"marian"),rDt.forEach(t),Hqo=r(DOe," \u2014 "),sQ=n(DOe,"A",{href:!0});var tDt=s(sQ);Jqo=r(tDt,"MarianModel"),tDt.forEach(t),Yqo=r(DOe," (Marian model)"),DOe.forEach(t),Zqo=i(x),W1=n(x,"LI",{});var GOe=s(W1);wbe=n(GOe,"STRONG",{});var aDt=s(wbe);Kqo=r(aDt,"markuplm"),aDt.forEach(t),ejo=r(GOe," \u2014 "),lQ=n(GOe,"A",{href:!0});var nDt=s(lQ);ojo=r(nDt,"MarkupLMModel"),nDt.forEach(t),rjo=r(GOe," (MarkupLM model)"),GOe.forEach(t),tjo=i(x),U1=n(x,"LI",{});var OOe=s(U1);Abe=n(OOe,"STRONG",{});var sDt=s(Abe);ajo=r(sDt,"maskformer"),sDt.forEach(t),njo=r(OOe," \u2014 "),iQ=n(OOe,"A",{href:!0});var lDt=s(iQ);sjo=r(lDt,"MaskFormerModel"),lDt.forEach(t),ljo=r(OOe," (MaskFormer model)"),OOe.forEach(t),ijo=i(x),H1=n(x,"LI",{});var VOe=s(H1);Lbe=n(VOe,"STRONG",{});var iDt=s(Lbe);djo=r(iDt,"mbart"),iDt.forEach(t),mjo=r(VOe," \u2014 "),dQ=n(VOe,"A",{href:!0});var dDt=s(dQ);cjo=r(dDt,"MBartModel"),dDt.forEach(t),fjo=r(VOe," (mBART model)"),VOe.forEach(t),gjo=i(x),J1=n(x,"LI",{});var XOe=s(J1);ybe=n(XOe,"STRONG",{});var mDt=s(ybe);hjo=r(mDt,"mctct"),mDt.forEach(t),ujo=r(XOe," \u2014 "),mQ=n(XOe,"A",{href:!0});var cDt=s(mQ);pjo=r(cDt,"MCTCTModel"),cDt.forEach(t),_jo=r(XOe," (M-CTC-T model)"),XOe.forEach(t),bjo=i(x),Y1=n(x,"LI",{});var zOe=s(Y1);xbe=n(zOe,"STRONG",{});var fDt=s(xbe);vjo=r(fDt,"megatron-bert"),fDt.forEach(t),Fjo=r(zOe," \u2014 "),cQ=n(zOe,"A",{href:!0});var gDt=s(cQ);Tjo=r(gDt,"MegatronBertModel"),gDt.forEach(t),Mjo=r(zOe," (Megatron-BERT model)"),zOe.forEach(t),Ejo=i(x),Z1=n(x,"LI",{});var QOe=s(Z1);$be=n(QOe,"STRONG",{});var hDt=s($be);Cjo=r(hDt,"mobilebert"),hDt.forEach(t),wjo=r(QOe," \u2014 "),fQ=n(QOe,"A",{href:!0});var uDt=s(fQ);Ajo=r(uDt,"MobileBertModel"),uDt.forEach(t),Ljo=r(QOe," (MobileBERT model)"),QOe.forEach(t),yjo=i(x),K1=n(x,"LI",{});var WOe=s(K1);kbe=n(WOe,"STRONG",{});var pDt=s(kbe);xjo=r(pDt,"mobilevit"),pDt.forEach(t),$jo=r(WOe," \u2014 "),gQ=n(WOe,"A",{href:!0});var _Dt=s(gQ);kjo=r(_Dt,"MobileViTModel"),_Dt.forEach(t),Sjo=r(WOe," (MobileViT model)"),WOe.forEach(t),Rjo=i(x),e2=n(x,"LI",{});var UOe=s(e2);Sbe=n(UOe,"STRONG",{});var bDt=s(Sbe);Pjo=r(bDt,"mpnet"),bDt.forEach(t),Bjo=r(UOe," \u2014 "),hQ=n(UOe,"A",{href:!0});var vDt=s(hQ);Ijo=r(vDt,"MPNetModel"),vDt.forEach(t),Njo=r(UOe," (MPNet model)"),UOe.forEach(t),qjo=i(x),o2=n(x,"LI",{});var HOe=s(o2);Rbe=n(HOe,"STRONG",{});var FDt=s(Rbe);jjo=r(FDt,"mt5"),FDt.forEach(t),Djo=r(HOe," \u2014 "),uQ=n(HOe,"A",{href:!0});var TDt=s(uQ);Gjo=r(TDt,"MT5Model"),TDt.forEach(t),Ojo=r(HOe," (MT5 model)"),HOe.forEach(t),Vjo=i(x),r2=n(x,"LI",{});var JOe=s(r2);Pbe=n(JOe,"STRONG",{});var MDt=s(Pbe);Xjo=r(MDt,"mvp"),MDt.forEach(t),zjo=r(JOe," \u2014 "),pQ=n(JOe,"A",{href:!0});var EDt=s(pQ);Qjo=r(EDt,"MvpModel"),EDt.forEach(t),Wjo=r(JOe," (MVP model)"),JOe.forEach(t),Ujo=i(x),t2=n(x,"LI",{});var YOe=s(t2);Bbe=n(YOe,"STRONG",{});var CDt=s(Bbe);Hjo=r(CDt,"nezha"),CDt.forEach(t),Jjo=r(YOe," \u2014 "),_Q=n(YOe,"A",{href:!0});var wDt=s(_Q);Yjo=r(wDt,"NezhaModel"),wDt.forEach(t),Zjo=r(YOe," (Nezha model)"),YOe.forEach(t),Kjo=i(x),a2=n(x,"LI",{});var ZOe=s(a2);Ibe=n(ZOe,"STRONG",{});var ADt=s(Ibe);eDo=r(ADt,"nllb"),ADt.forEach(t),oDo=r(ZOe," \u2014 "),bQ=n(ZOe,"A",{href:!0});var LDt=s(bQ);rDo=r(LDt,"M2M100Model"),LDt.forEach(t),tDo=r(ZOe," (NLLB model)"),ZOe.forEach(t),aDo=i(x),n2=n(x,"LI",{});var KOe=s(n2);Nbe=n(KOe,"STRONG",{});var yDt=s(Nbe);nDo=r(yDt,"nystromformer"),yDt.forEach(t),sDo=r(KOe," \u2014 "),vQ=n(KOe,"A",{href:!0});var xDt=s(vQ);lDo=r(xDt,"NystromformerModel"),xDt.forEach(t),iDo=r(KOe," (Nystr\xF6mformer model)"),KOe.forEach(t),dDo=i(x),s2=n(x,"LI",{});var eVe=s(s2);qbe=n(eVe,"STRONG",{});var $Dt=s(qbe);mDo=r($Dt,"openai-gpt"),$Dt.forEach(t),cDo=r(eVe," \u2014 "),FQ=n(eVe,"A",{href:!0});var kDt=s(FQ);fDo=r(kDt,"OpenAIGPTModel"),kDt.forEach(t),gDo=r(eVe," (OpenAI GPT model)"),eVe.forEach(t),hDo=i(x),l2=n(x,"LI",{});var oVe=s(l2);jbe=n(oVe,"STRONG",{});var SDt=s(jbe);uDo=r(SDt,"opt"),SDt.forEach(t),pDo=r(oVe," \u2014 "),TQ=n(oVe,"A",{href:!0});var RDt=s(TQ);_Do=r(RDt,"OPTModel"),RDt.forEach(t),bDo=r(oVe," (OPT model)"),oVe.forEach(t),vDo=i(x),i2=n(x,"LI",{});var rVe=s(i2);Dbe=n(rVe,"STRONG",{});var PDt=s(Dbe);FDo=r(PDt,"owlvit"),PDt.forEach(t),TDo=r(rVe," \u2014 "),MQ=n(rVe,"A",{href:!0});var BDt=s(MQ);MDo=r(BDt,"OwlViTModel"),BDt.forEach(t),EDo=r(rVe," (OWL-ViT model)"),rVe.forEach(t),CDo=i(x),d2=n(x,"LI",{});var tVe=s(d2);Gbe=n(tVe,"STRONG",{});var IDt=s(Gbe);wDo=r(IDt,"pegasus"),IDt.forEach(t),ADo=r(tVe," \u2014 "),EQ=n(tVe,"A",{href:!0});var NDt=s(EQ);LDo=r(NDt,"PegasusModel"),NDt.forEach(t),yDo=r(tVe," (Pegasus model)"),tVe.forEach(t),xDo=i(x),m2=n(x,"LI",{});var aVe=s(m2);Obe=n(aVe,"STRONG",{});var qDt=s(Obe);$Do=r(qDt,"pegasus_x"),qDt.forEach(t),kDo=r(aVe," \u2014 "),CQ=n(aVe,"A",{href:!0});var jDt=s(CQ);SDo=r(jDt,"PegasusXModel"),jDt.forEach(t),RDo=r(aVe," (PEGASUS-X model)"),aVe.forEach(t),PDo=i(x),c2=n(x,"LI",{});var nVe=s(c2);Vbe=n(nVe,"STRONG",{});var DDt=s(Vbe);BDo=r(DDt,"perceiver"),DDt.forEach(t),IDo=r(nVe," \u2014 "),wQ=n(nVe,"A",{href:!0});var GDt=s(wQ);NDo=r(GDt,"PerceiverModel"),GDt.forEach(t),qDo=r(nVe," (Perceiver model)"),nVe.forEach(t),jDo=i(x),f2=n(x,"LI",{});var sVe=s(f2);Xbe=n(sVe,"STRONG",{});var ODt=s(Xbe);DDo=r(ODt,"plbart"),ODt.forEach(t),GDo=r(sVe," \u2014 "),AQ=n(sVe,"A",{href:!0});var VDt=s(AQ);ODo=r(VDt,"PLBartModel"),VDt.forEach(t),VDo=r(sVe," (PLBart model)"),sVe.forEach(t),XDo=i(x),g2=n(x,"LI",{});var lVe=s(g2);zbe=n(lVe,"STRONG",{});var XDt=s(zbe);zDo=r(XDt,"poolformer"),XDt.forEach(t),QDo=r(lVe," \u2014 "),LQ=n(lVe,"A",{href:!0});var zDt=s(LQ);WDo=r(zDt,"PoolFormerModel"),zDt.forEach(t),UDo=r(lVe," (PoolFormer model)"),lVe.forEach(t),HDo=i(x),h2=n(x,"LI",{});var iVe=s(h2);Qbe=n(iVe,"STRONG",{});var QDt=s(Qbe);JDo=r(QDt,"prophetnet"),QDt.forEach(t),YDo=r(iVe," \u2014 "),yQ=n(iVe,"A",{href:!0});var WDt=s(yQ);ZDo=r(WDt,"ProphetNetModel"),WDt.forEach(t),KDo=r(iVe," (ProphetNet model)"),iVe.forEach(t),eGo=i(x),u2=n(x,"LI",{});var dVe=s(u2);Wbe=n(dVe,"STRONG",{});var UDt=s(Wbe);oGo=r(UDt,"qdqbert"),UDt.forEach(t),rGo=r(dVe," \u2014 "),xQ=n(dVe,"A",{href:!0});var HDt=s(xQ);tGo=r(HDt,"QDQBertModel"),HDt.forEach(t),aGo=r(dVe," (QDQBert model)"),dVe.forEach(t),nGo=i(x),p2=n(x,"LI",{});var mVe=s(p2);Ube=n(mVe,"STRONG",{});var JDt=s(Ube);sGo=r(JDt,"reformer"),JDt.forEach(t),lGo=r(mVe," \u2014 "),$Q=n(mVe,"A",{href:!0});var YDt=s($Q);iGo=r(YDt,"ReformerModel"),YDt.forEach(t),dGo=r(mVe," (Reformer model)"),mVe.forEach(t),mGo=i(x),_2=n(x,"LI",{});var cVe=s(_2);Hbe=n(cVe,"STRONG",{});var ZDt=s(Hbe);cGo=r(ZDt,"regnet"),ZDt.forEach(t),fGo=r(cVe," \u2014 "),kQ=n(cVe,"A",{href:!0});var KDt=s(kQ);gGo=r(KDt,"RegNetModel"),KDt.forEach(t),hGo=r(cVe," (RegNet model)"),cVe.forEach(t),uGo=i(x),b2=n(x,"LI",{});var fVe=s(b2);Jbe=n(fVe,"STRONG",{});var eGt=s(Jbe);pGo=r(eGt,"rembert"),eGt.forEach(t),_Go=r(fVe," \u2014 "),SQ=n(fVe,"A",{href:!0});var oGt=s(SQ);bGo=r(oGt,"RemBertModel"),oGt.forEach(t),vGo=r(fVe," (RemBERT model)"),fVe.forEach(t),FGo=i(x),v2=n(x,"LI",{});var gVe=s(v2);Ybe=n(gVe,"STRONG",{});var rGt=s(Ybe);TGo=r(rGt,"resnet"),rGt.forEach(t),MGo=r(gVe," \u2014 "),RQ=n(gVe,"A",{href:!0});var tGt=s(RQ);EGo=r(tGt,"ResNetModel"),tGt.forEach(t),CGo=r(gVe," (ResNet model)"),gVe.forEach(t),wGo=i(x),F2=n(x,"LI",{});var hVe=s(F2);Zbe=n(hVe,"STRONG",{});var aGt=s(Zbe);AGo=r(aGt,"retribert"),aGt.forEach(t),LGo=r(hVe," \u2014 "),PQ=n(hVe,"A",{href:!0});var nGt=s(PQ);yGo=r(nGt,"RetriBertModel"),nGt.forEach(t),xGo=r(hVe," (RetriBERT model)"),hVe.forEach(t),$Go=i(x),T2=n(x,"LI",{});var uVe=s(T2);Kbe=n(uVe,"STRONG",{});var sGt=s(Kbe);kGo=r(sGt,"roberta"),sGt.forEach(t),SGo=r(uVe," \u2014 "),BQ=n(uVe,"A",{href:!0});var lGt=s(BQ);RGo=r(lGt,"RobertaModel"),lGt.forEach(t),PGo=r(uVe," (RoBERTa model)"),uVe.forEach(t),BGo=i(x),M2=n(x,"LI",{});var pVe=s(M2);eve=n(pVe,"STRONG",{});var iGt=s(eve);IGo=r(iGt,"roc_bert"),iGt.forEach(t),NGo=r(pVe," \u2014 "),IQ=n(pVe,"A",{href:!0});var dGt=s(IQ);qGo=r(dGt,"RoCBertModel"),dGt.forEach(t),jGo=r(pVe," (RoCBert model)"),pVe.forEach(t),DGo=i(x),E2=n(x,"LI",{});var _Ve=s(E2);ove=n(_Ve,"STRONG",{});var mGt=s(ove);GGo=r(mGt,"roformer"),mGt.forEach(t),OGo=r(_Ve," \u2014 "),NQ=n(_Ve,"A",{href:!0});var cGt=s(NQ);VGo=r(cGt,"RoFormerModel"),cGt.forEach(t),XGo=r(_Ve," (RoFormer model)"),_Ve.forEach(t),zGo=i(x),C2=n(x,"LI",{});var bVe=s(C2);rve=n(bVe,"STRONG",{});var fGt=s(rve);QGo=r(fGt,"segformer"),fGt.forEach(t),WGo=r(bVe," \u2014 "),qQ=n(bVe,"A",{href:!0});var gGt=s(qQ);UGo=r(gGt,"SegformerModel"),gGt.forEach(t),HGo=r(bVe," (SegFormer model)"),bVe.forEach(t),JGo=i(x),w2=n(x,"LI",{});var vVe=s(w2);tve=n(vVe,"STRONG",{});var hGt=s(tve);YGo=r(hGt,"sew"),hGt.forEach(t),ZGo=r(vVe," \u2014 "),jQ=n(vVe,"A",{href:!0});var uGt=s(jQ);KGo=r(uGt,"SEWModel"),uGt.forEach(t),eOo=r(vVe," (SEW model)"),vVe.forEach(t),oOo=i(x),A2=n(x,"LI",{});var FVe=s(A2);ave=n(FVe,"STRONG",{});var pGt=s(ave);rOo=r(pGt,"sew-d"),pGt.forEach(t),tOo=r(FVe," \u2014 "),DQ=n(FVe,"A",{href:!0});var _Gt=s(DQ);aOo=r(_Gt,"SEWDModel"),_Gt.forEach(t),nOo=r(FVe," (SEW-D model)"),FVe.forEach(t),sOo=i(x),L2=n(x,"LI",{});var TVe=s(L2);nve=n(TVe,"STRONG",{});var bGt=s(nve);lOo=r(bGt,"speech_to_text"),bGt.forEach(t),iOo=r(TVe," \u2014 "),GQ=n(TVe,"A",{href:!0});var vGt=s(GQ);dOo=r(vGt,"Speech2TextModel"),vGt.forEach(t),mOo=r(TVe," (Speech2Text model)"),TVe.forEach(t),cOo=i(x),y2=n(x,"LI",{});var MVe=s(y2);sve=n(MVe,"STRONG",{});var FGt=s(sve);fOo=r(FGt,"splinter"),FGt.forEach(t),gOo=r(MVe," \u2014 "),OQ=n(MVe,"A",{href:!0});var TGt=s(OQ);hOo=r(TGt,"SplinterModel"),TGt.forEach(t),uOo=r(MVe," (Splinter model)"),MVe.forEach(t),pOo=i(x),x2=n(x,"LI",{});var EVe=s(x2);lve=n(EVe,"STRONG",{});var MGt=s(lve);_Oo=r(MGt,"squeezebert"),MGt.forEach(t),bOo=r(EVe," \u2014 "),VQ=n(EVe,"A",{href:!0});var EGt=s(VQ);vOo=r(EGt,"SqueezeBertModel"),EGt.forEach(t),FOo=r(EVe," (SqueezeBERT model)"),EVe.forEach(t),TOo=i(x),$2=n(x,"LI",{});var CVe=s($2);ive=n(CVe,"STRONG",{});var CGt=s(ive);MOo=r(CGt,"swin"),CGt.forEach(t),EOo=r(CVe," \u2014 "),XQ=n(CVe,"A",{href:!0});var wGt=s(XQ);COo=r(wGt,"SwinModel"),wGt.forEach(t),wOo=r(CVe," (Swin Transformer model)"),CVe.forEach(t),AOo=i(x),k2=n(x,"LI",{});var wVe=s(k2);dve=n(wVe,"STRONG",{});var AGt=s(dve);LOo=r(AGt,"swinv2"),AGt.forEach(t),yOo=r(wVe," \u2014 "),zQ=n(wVe,"A",{href:!0});var LGt=s(zQ);xOo=r(LGt,"Swinv2Model"),LGt.forEach(t),$Oo=r(wVe," (Swin Transformer V2 model)"),wVe.forEach(t),kOo=i(x),S2=n(x,"LI",{});var AVe=s(S2);mve=n(AVe,"STRONG",{});var yGt=s(mve);SOo=r(yGt,"t5"),yGt.forEach(t),ROo=r(AVe," \u2014 "),QQ=n(AVe,"A",{href:!0});var xGt=s(QQ);POo=r(xGt,"T5Model"),xGt.forEach(t),BOo=r(AVe," (T5 model)"),AVe.forEach(t),IOo=i(x),R2=n(x,"LI",{});var LVe=s(R2);cve=n(LVe,"STRONG",{});var $Gt=s(cve);NOo=r($Gt,"table-transformer"),$Gt.forEach(t),qOo=r(LVe," \u2014 "),WQ=n(LVe,"A",{href:!0});var kGt=s(WQ);jOo=r(kGt,"TableTransformerModel"),kGt.forEach(t),DOo=r(LVe," (Table Transformer model)"),LVe.forEach(t),GOo=i(x),P2=n(x,"LI",{});var yVe=s(P2);fve=n(yVe,"STRONG",{});var SGt=s(fve);OOo=r(SGt,"tapas"),SGt.forEach(t),VOo=r(yVe," \u2014 "),UQ=n(yVe,"A",{href:!0});var RGt=s(UQ);XOo=r(RGt,"TapasModel"),RGt.forEach(t),zOo=r(yVe," (TAPAS model)"),yVe.forEach(t),QOo=i(x),B2=n(x,"LI",{});var xVe=s(B2);gve=n(xVe,"STRONG",{});var PGt=s(gve);WOo=r(PGt,"time_series_transformer"),PGt.forEach(t),UOo=r(xVe," \u2014 "),HQ=n(xVe,"A",{href:!0});var BGt=s(HQ);HOo=r(BGt,"TimeSeriesTransformerModel"),BGt.forEach(t),JOo=r(xVe," (Time Series Transformer model)"),xVe.forEach(t),YOo=i(x),I2=n(x,"LI",{});var $Ve=s(I2);hve=n($Ve,"STRONG",{});var IGt=s(hve);ZOo=r(IGt,"trajectory_transformer"),IGt.forEach(t),KOo=r($Ve," \u2014 "),JQ=n($Ve,"A",{href:!0});var NGt=s(JQ);eVo=r(NGt,"TrajectoryTransformerModel"),NGt.forEach(t),oVo=r($Ve," (Trajectory Transformer model)"),$Ve.forEach(t),rVo=i(x),N2=n(x,"LI",{});var kVe=s(N2);uve=n(kVe,"STRONG",{});var qGt=s(uve);tVo=r(qGt,"transfo-xl"),qGt.forEach(t),aVo=r(kVe," \u2014 "),YQ=n(kVe,"A",{href:!0});var jGt=s(YQ);nVo=r(jGt,"TransfoXLModel"),jGt.forEach(t),sVo=r(kVe," (Transformer-XL model)"),kVe.forEach(t),lVo=i(x),q2=n(x,"LI",{});var SVe=s(q2);pve=n(SVe,"STRONG",{});var DGt=s(pve);iVo=r(DGt,"unispeech"),DGt.forEach(t),dVo=r(SVe," \u2014 "),ZQ=n(SVe,"A",{href:!0});var GGt=s(ZQ);mVo=r(GGt,"UniSpeechModel"),GGt.forEach(t),cVo=r(SVe," (UniSpeech model)"),SVe.forEach(t),fVo=i(x),j2=n(x,"LI",{});var RVe=s(j2);_ve=n(RVe,"STRONG",{});var OGt=s(_ve);gVo=r(OGt,"unispeech-sat"),OGt.forEach(t),hVo=r(RVe," \u2014 "),KQ=n(RVe,"A",{href:!0});var VGt=s(KQ);uVo=r(VGt,"UniSpeechSatModel"),VGt.forEach(t),pVo=r(RVe," (UniSpeechSat model)"),RVe.forEach(t),_Vo=i(x),D2=n(x,"LI",{});var PVe=s(D2);bve=n(PVe,"STRONG",{});var XGt=s(bve);bVo=r(XGt,"van"),XGt.forEach(t),vVo=r(PVe," \u2014 "),eW=n(PVe,"A",{href:!0});var zGt=s(eW);FVo=r(zGt,"VanModel"),zGt.forEach(t),TVo=r(PVe," (VAN model)"),PVe.forEach(t),MVo=i(x),G2=n(x,"LI",{});var BVe=s(G2);vve=n(BVe,"STRONG",{});var QGt=s(vve);EVo=r(QGt,"videomae"),QGt.forEach(t),CVo=r(BVe," \u2014 "),oW=n(BVe,"A",{href:!0});var WGt=s(oW);wVo=r(WGt,"VideoMAEModel"),WGt.forEach(t),AVo=r(BVe," (VideoMAE model)"),BVe.forEach(t),LVo=i(x),O2=n(x,"LI",{});var IVe=s(O2);Fve=n(IVe,"STRONG",{});var UGt=s(Fve);yVo=r(UGt,"vilt"),UGt.forEach(t),xVo=r(IVe," \u2014 "),rW=n(IVe,"A",{href:!0});var HGt=s(rW);$Vo=r(HGt,"ViltModel"),HGt.forEach(t),kVo=r(IVe," (ViLT model)"),IVe.forEach(t),SVo=i(x),V2=n(x,"LI",{});var NVe=s(V2);Tve=n(NVe,"STRONG",{});var JGt=s(Tve);RVo=r(JGt,"vision-text-dual-encoder"),JGt.forEach(t),PVo=r(NVe," \u2014 "),tW=n(NVe,"A",{href:!0});var YGt=s(tW);BVo=r(YGt,"VisionTextDualEncoderModel"),YGt.forEach(t),IVo=r(NVe," (VisionTextDualEncoder model)"),NVe.forEach(t),NVo=i(x),X2=n(x,"LI",{});var qVe=s(X2);Mve=n(qVe,"STRONG",{});var ZGt=s(Mve);qVo=r(ZGt,"visual_bert"),ZGt.forEach(t),jVo=r(qVe," \u2014 "),aW=n(qVe,"A",{href:!0});var KGt=s(aW);DVo=r(KGt,"VisualBertModel"),KGt.forEach(t),GVo=r(qVe," (VisualBERT model)"),qVe.forEach(t),OVo=i(x),z2=n(x,"LI",{});var jVe=s(z2);Eve=n(jVe,"STRONG",{});var eOt=s(Eve);VVo=r(eOt,"vit"),eOt.forEach(t),XVo=r(jVe," \u2014 "),nW=n(jVe,"A",{href:!0});var oOt=s(nW);zVo=r(oOt,"ViTModel"),oOt.forEach(t),QVo=r(jVe," (ViT model)"),jVe.forEach(t),WVo=i(x),Q2=n(x,"LI",{});var DVe=s(Q2);Cve=n(DVe,"STRONG",{});var rOt=s(Cve);UVo=r(rOt,"vit_mae"),rOt.forEach(t),HVo=r(DVe," \u2014 "),sW=n(DVe,"A",{href:!0});var tOt=s(sW);JVo=r(tOt,"ViTMAEModel"),tOt.forEach(t),YVo=r(DVe," (ViTMAE model)"),DVe.forEach(t),ZVo=i(x),W2=n(x,"LI",{});var GVe=s(W2);wve=n(GVe,"STRONG",{});var aOt=s(wve);KVo=r(aOt,"vit_msn"),aOt.forEach(t),eXo=r(GVe," \u2014 "),lW=n(GVe,"A",{href:!0});var nOt=s(lW);oXo=r(nOt,"ViTMSNModel"),nOt.forEach(t),rXo=r(GVe," (ViTMSN model)"),GVe.forEach(t),tXo=i(x),U2=n(x,"LI",{});var OVe=s(U2);Ave=n(OVe,"STRONG",{});var sOt=s(Ave);aXo=r(sOt,"wav2vec2"),sOt.forEach(t),nXo=r(OVe," \u2014 "),iW=n(OVe,"A",{href:!0});var lOt=s(iW);sXo=r(lOt,"Wav2Vec2Model"),lOt.forEach(t),lXo=r(OVe," (Wav2Vec2 model)"),OVe.forEach(t),iXo=i(x),H2=n(x,"LI",{});var VVe=s(H2);Lve=n(VVe,"STRONG",{});var iOt=s(Lve);dXo=r(iOt,"wav2vec2-conformer"),iOt.forEach(t),mXo=r(VVe," \u2014 "),dW=n(VVe,"A",{href:!0});var dOt=s(dW);cXo=r(dOt,"Wav2Vec2ConformerModel"),dOt.forEach(t),fXo=r(VVe," (Wav2Vec2-Conformer model)"),VVe.forEach(t),gXo=i(x),J2=n(x,"LI",{});var XVe=s(J2);yve=n(XVe,"STRONG",{});var mOt=s(yve);hXo=r(mOt,"wavlm"),mOt.forEach(t),uXo=r(XVe," \u2014 "),mW=n(XVe,"A",{href:!0});var cOt=s(mW);pXo=r(cOt,"WavLMModel"),cOt.forEach(t),_Xo=r(XVe," (WavLM model)"),XVe.forEach(t),bXo=i(x),Y2=n(x,"LI",{});var zVe=s(Y2);xve=n(zVe,"STRONG",{});var fOt=s(xve);vXo=r(fOt,"whisper"),fOt.forEach(t),FXo=r(zVe," \u2014 "),cW=n(zVe,"A",{href:!0});var gOt=s(cW);TXo=r(gOt,"WhisperModel"),gOt.forEach(t),MXo=r(zVe," (Whisper model)"),zVe.forEach(t),EXo=i(x),Z2=n(x,"LI",{});var QVe=s(Z2);$ve=n(QVe,"STRONG",{});var hOt=s($ve);CXo=r(hOt,"xclip"),hOt.forEach(t),wXo=r(QVe," \u2014 "),fW=n(QVe,"A",{href:!0});var uOt=s(fW);AXo=r(uOt,"XCLIPModel"),uOt.forEach(t),LXo=r(QVe," (X-CLIP model)"),QVe.forEach(t),yXo=i(x),K2=n(x,"LI",{});var WVe=s(K2);kve=n(WVe,"STRONG",{});var pOt=s(kve);xXo=r(pOt,"xglm"),pOt.forEach(t),$Xo=r(WVe," \u2014 "),gW=n(WVe,"A",{href:!0});var _Ot=s(gW);kXo=r(_Ot,"XGLMModel"),_Ot.forEach(t),SXo=r(WVe," (XGLM model)"),WVe.forEach(t),RXo=i(x),eb=n(x,"LI",{});var UVe=s(eb);Sve=n(UVe,"STRONG",{});var bOt=s(Sve);PXo=r(bOt,"xlm"),bOt.forEach(t),BXo=r(UVe," \u2014 "),hW=n(UVe,"A",{href:!0});var vOt=s(hW);IXo=r(vOt,"XLMModel"),vOt.forEach(t),NXo=r(UVe," (XLM model)"),UVe.forEach(t),qXo=i(x),ob=n(x,"LI",{});var HVe=s(ob);Rve=n(HVe,"STRONG",{});var FOt=s(Rve);jXo=r(FOt,"xlm-prophetnet"),FOt.forEach(t),DXo=r(HVe," \u2014 "),uW=n(HVe,"A",{href:!0});var TOt=s(uW);GXo=r(TOt,"XLMProphetNetModel"),TOt.forEach(t),OXo=r(HVe," (XLM-ProphetNet model)"),HVe.forEach(t),VXo=i(x),rb=n(x,"LI",{});var JVe=s(rb);Pve=n(JVe,"STRONG",{});var MOt=s(Pve);XXo=r(MOt,"xlm-roberta"),MOt.forEach(t),zXo=r(JVe," \u2014 "),pW=n(JVe,"A",{href:!0});var EOt=s(pW);QXo=r(EOt,"XLMRobertaModel"),EOt.forEach(t),WXo=r(JVe," (XLM-RoBERTa model)"),JVe.forEach(t),UXo=i(x),tb=n(x,"LI",{});var YVe=s(tb);Bve=n(YVe,"STRONG",{});var COt=s(Bve);HXo=r(COt,"xlm-roberta-xl"),COt.forEach(t),JXo=r(YVe," \u2014 "),_W=n(YVe,"A",{href:!0});var wOt=s(_W);YXo=r(wOt,"XLMRobertaXLModel"),wOt.forEach(t),ZXo=r(YVe," (XLM-RoBERTa-XL model)"),YVe.forEach(t),KXo=i(x),ab=n(x,"LI",{});var ZVe=s(ab);Ive=n(ZVe,"STRONG",{});var AOt=s(Ive);ezo=r(AOt,"xlnet"),AOt.forEach(t),ozo=r(ZVe," \u2014 "),bW=n(ZVe,"A",{href:!0});var LOt=s(bW);rzo=r(LOt,"XLNetModel"),LOt.forEach(t),tzo=r(ZVe," (XLNet model)"),ZVe.forEach(t),azo=i(x),nb=n(x,"LI",{});var KVe=s(nb);Nve=n(KVe,"STRONG",{});var yOt=s(Nve);nzo=r(yOt,"yolos"),yOt.forEach(t),szo=r(KVe," \u2014 "),vW=n(KVe,"A",{href:!0});var xOt=s(vW);lzo=r(xOt,"YolosModel"),xOt.forEach(t),izo=r(KVe," (YOLOS model)"),KVe.forEach(t),dzo=i(x),sb=n(x,"LI",{});var eXe=s(sb);qve=n(eXe,"STRONG",{});var $Ot=s(qve);mzo=r($Ot,"yoso"),$Ot.forEach(t),czo=r(eXe," \u2014 "),FW=n(eXe,"A",{href:!0});var kOt=s(FW);fzo=r(kOt,"YosoModel"),kOt.forEach(t),gzo=r(eXe," (YOSO model)"),eXe.forEach(t),x.forEach(t),hzo=i(La),lb=n(La,"P",{});var oXe=s(lb);uzo=r(oXe,"The model is set in evaluation mode by default using "),jve=n(oXe,"CODE",{});var SOt=s(jve);pzo=r(SOt,"model.eval()"),SOt.forEach(t),_zo=r(oXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Dve=n(oXe,"CODE",{});var ROt=s(Dve);bzo=r(ROt,"model.train()"),ROt.forEach(t),oXe.forEach(t),vzo=i(La),T(ib.$$.fragment,La),La.forEach(t),jl.forEach(t),Vao=i(c),Id=n(c,"H2",{class:!0});var llo=s(Id);db=n(llo,"A",{id:!0,class:!0,href:!0});var POt=s(db);Gve=n(POt,"SPAN",{});var BOt=s(Gve);T(ek.$$.fragment,BOt),BOt.forEach(t),POt.forEach(t),Fzo=i(llo),Ove=n(llo,"SPAN",{});var IOt=s(Ove);Tzo=r(IOt,"AutoModelForPreTraining"),IOt.forEach(t),llo.forEach(t),Xao=i(c),No=n(c,"DIV",{class:!0});var Dl=s(No);T(ok.$$.fragment,Dl),Mzo=i(Dl),Nd=n(Dl,"P",{});var Ime=s(Nd);Ezo=r(Ime,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),TW=n(Ime,"A",{href:!0});var NOt=s(TW);Czo=r(NOt,"from_pretrained()"),NOt.forEach(t),wzo=r(Ime," class method or the "),MW=n(Ime,"A",{href:!0});var qOt=s(MW);Azo=r(qOt,"from_config()"),qOt.forEach(t),Lzo=r(Ime,` class
method.`),Ime.forEach(t),yzo=i(Dl),rk=n(Dl,"P",{});var ilo=s(rk);xzo=r(ilo,"This class cannot be instantiated directly using "),Vve=n(ilo,"CODE",{});var jOt=s(Vve);$zo=r(jOt,"__init__()"),jOt.forEach(t),kzo=r(ilo," (throws an error)."),ilo.forEach(t),Szo=i(Dl),Et=n(Dl,"DIV",{class:!0});var p9=s(Et);T(tk.$$.fragment,p9),Rzo=i(p9),Xve=n(p9,"P",{});var DOt=s(Xve);Pzo=r(DOt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),DOt.forEach(t),Bzo=i(p9),qd=n(p9,"P",{});var Nme=s(qd);Izo=r(Nme,`Note:
Loading a model from its configuration file does `),zve=n(Nme,"STRONG",{});var GOt=s(zve);Nzo=r(GOt,"not"),GOt.forEach(t),qzo=r(Nme,` load the model weights. It only affects the
model\u2019s configuration. Use `),EW=n(Nme,"A",{href:!0});var OOt=s(EW);jzo=r(OOt,"from_pretrained()"),OOt.forEach(t),Dzo=r(Nme," to load the model weights."),Nme.forEach(t),Gzo=i(p9),T(mb.$$.fragment,p9),p9.forEach(t),Ozo=i(Dl),eo=n(Dl,"DIV",{class:!0});var ya=s(eo);T(ak.$$.fragment,ya),Vzo=i(ya),Qve=n(ya,"P",{});var VOt=s(Qve);Xzo=r(VOt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),VOt.forEach(t),zzo=i(ya),sn=n(ya,"P",{});var _9=s(sn);Qzo=r(_9,"The model class to instantiate is selected based on the "),Wve=n(_9,"CODE",{});var XOt=s(Wve);Wzo=r(XOt,"model_type"),XOt.forEach(t),Uzo=r(_9,` property of the config object (either
passed as an argument or loaded from `),Uve=n(_9,"CODE",{});var zOt=s(Uve);Hzo=r(zOt,"pretrained_model_name_or_path"),zOt.forEach(t),Jzo=r(_9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Hve=n(_9,"CODE",{});var QOt=s(Hve);Yzo=r(QOt,"pretrained_model_name_or_path"),QOt.forEach(t),Zzo=r(_9,":"),_9.forEach(t),Kzo=i(ya),G=n(ya,"UL",{});var V=s(G);cb=n(V,"LI",{});var rXe=s(cb);Jve=n(rXe,"STRONG",{});var WOt=s(Jve);eQo=r(WOt,"albert"),WOt.forEach(t),oQo=r(rXe," \u2014 "),CW=n(rXe,"A",{href:!0});var UOt=s(CW);rQo=r(UOt,"AlbertForPreTraining"),UOt.forEach(t),tQo=r(rXe," (ALBERT model)"),rXe.forEach(t),aQo=i(V),fb=n(V,"LI",{});var tXe=s(fb);Yve=n(tXe,"STRONG",{});var HOt=s(Yve);nQo=r(HOt,"bart"),HOt.forEach(t),sQo=r(tXe," \u2014 "),wW=n(tXe,"A",{href:!0});var JOt=s(wW);lQo=r(JOt,"BartForConditionalGeneration"),JOt.forEach(t),iQo=r(tXe," (BART model)"),tXe.forEach(t),dQo=i(V),gb=n(V,"LI",{});var aXe=s(gb);Zve=n(aXe,"STRONG",{});var YOt=s(Zve);mQo=r(YOt,"bert"),YOt.forEach(t),cQo=r(aXe," \u2014 "),AW=n(aXe,"A",{href:!0});var ZOt=s(AW);fQo=r(ZOt,"BertForPreTraining"),ZOt.forEach(t),gQo=r(aXe," (BERT model)"),aXe.forEach(t),hQo=i(V),hb=n(V,"LI",{});var nXe=s(hb);Kve=n(nXe,"STRONG",{});var KOt=s(Kve);uQo=r(KOt,"big_bird"),KOt.forEach(t),pQo=r(nXe," \u2014 "),LW=n(nXe,"A",{href:!0});var eVt=s(LW);_Qo=r(eVt,"BigBirdForPreTraining"),eVt.forEach(t),bQo=r(nXe," (BigBird model)"),nXe.forEach(t),vQo=i(V),ub=n(V,"LI",{});var sXe=s(ub);eFe=n(sXe,"STRONG",{});var oVt=s(eFe);FQo=r(oVt,"bloom"),oVt.forEach(t),TQo=r(sXe," \u2014 "),yW=n(sXe,"A",{href:!0});var rVt=s(yW);MQo=r(rVt,"BloomForCausalLM"),rVt.forEach(t),EQo=r(sXe," (BLOOM model)"),sXe.forEach(t),CQo=i(V),pb=n(V,"LI",{});var lXe=s(pb);oFe=n(lXe,"STRONG",{});var tVt=s(oFe);wQo=r(tVt,"camembert"),tVt.forEach(t),AQo=r(lXe," \u2014 "),xW=n(lXe,"A",{href:!0});var aVt=s(xW);LQo=r(aVt,"CamembertForMaskedLM"),aVt.forEach(t),yQo=r(lXe," (CamemBERT model)"),lXe.forEach(t),xQo=i(V),_b=n(V,"LI",{});var iXe=s(_b);rFe=n(iXe,"STRONG",{});var nVt=s(rFe);$Qo=r(nVt,"ctrl"),nVt.forEach(t),kQo=r(iXe," \u2014 "),$W=n(iXe,"A",{href:!0});var sVt=s($W);SQo=r(sVt,"CTRLLMHeadModel"),sVt.forEach(t),RQo=r(iXe," (CTRL model)"),iXe.forEach(t),PQo=i(V),bb=n(V,"LI",{});var dXe=s(bb);tFe=n(dXe,"STRONG",{});var lVt=s(tFe);BQo=r(lVt,"data2vec-text"),lVt.forEach(t),IQo=r(dXe," \u2014 "),kW=n(dXe,"A",{href:!0});var iVt=s(kW);NQo=r(iVt,"Data2VecTextForMaskedLM"),iVt.forEach(t),qQo=r(dXe," (Data2VecText model)"),dXe.forEach(t),jQo=i(V),vb=n(V,"LI",{});var mXe=s(vb);aFe=n(mXe,"STRONG",{});var dVt=s(aFe);DQo=r(dVt,"deberta"),dVt.forEach(t),GQo=r(mXe," \u2014 "),SW=n(mXe,"A",{href:!0});var mVt=s(SW);OQo=r(mVt,"DebertaForMaskedLM"),mVt.forEach(t),VQo=r(mXe," (DeBERTa model)"),mXe.forEach(t),XQo=i(V),Fb=n(V,"LI",{});var cXe=s(Fb);nFe=n(cXe,"STRONG",{});var cVt=s(nFe);zQo=r(cVt,"deberta-v2"),cVt.forEach(t),QQo=r(cXe," \u2014 "),RW=n(cXe,"A",{href:!0});var fVt=s(RW);WQo=r(fVt,"DebertaV2ForMaskedLM"),fVt.forEach(t),UQo=r(cXe," (DeBERTa-v2 model)"),cXe.forEach(t),HQo=i(V),Tb=n(V,"LI",{});var fXe=s(Tb);sFe=n(fXe,"STRONG",{});var gVt=s(sFe);JQo=r(gVt,"distilbert"),gVt.forEach(t),YQo=r(fXe," \u2014 "),PW=n(fXe,"A",{href:!0});var hVt=s(PW);ZQo=r(hVt,"DistilBertForMaskedLM"),hVt.forEach(t),KQo=r(fXe," (DistilBERT model)"),fXe.forEach(t),eWo=i(V),Mb=n(V,"LI",{});var gXe=s(Mb);lFe=n(gXe,"STRONG",{});var uVt=s(lFe);oWo=r(uVt,"electra"),uVt.forEach(t),rWo=r(gXe," \u2014 "),BW=n(gXe,"A",{href:!0});var pVt=s(BW);tWo=r(pVt,"ElectraForPreTraining"),pVt.forEach(t),aWo=r(gXe," (ELECTRA model)"),gXe.forEach(t),nWo=i(V),Eb=n(V,"LI",{});var hXe=s(Eb);iFe=n(hXe,"STRONG",{});var _Vt=s(iFe);sWo=r(_Vt,"ernie"),_Vt.forEach(t),lWo=r(hXe," \u2014 "),IW=n(hXe,"A",{href:!0});var bVt=s(IW);iWo=r(bVt,"ErnieForPreTraining"),bVt.forEach(t),dWo=r(hXe," (ERNIE model)"),hXe.forEach(t),mWo=i(V),Cb=n(V,"LI",{});var uXe=s(Cb);dFe=n(uXe,"STRONG",{});var vVt=s(dFe);cWo=r(vVt,"flaubert"),vVt.forEach(t),fWo=r(uXe," \u2014 "),NW=n(uXe,"A",{href:!0});var FVt=s(NW);gWo=r(FVt,"FlaubertWithLMHeadModel"),FVt.forEach(t),hWo=r(uXe," (FlauBERT model)"),uXe.forEach(t),uWo=i(V),wb=n(V,"LI",{});var pXe=s(wb);mFe=n(pXe,"STRONG",{});var TVt=s(mFe);pWo=r(TVt,"flava"),TVt.forEach(t),_Wo=r(pXe," \u2014 "),qW=n(pXe,"A",{href:!0});var MVt=s(qW);bWo=r(MVt,"FlavaForPreTraining"),MVt.forEach(t),vWo=r(pXe," (FLAVA model)"),pXe.forEach(t),FWo=i(V),Ab=n(V,"LI",{});var _Xe=s(Ab);cFe=n(_Xe,"STRONG",{});var EVt=s(cFe);TWo=r(EVt,"fnet"),EVt.forEach(t),MWo=r(_Xe," \u2014 "),jW=n(_Xe,"A",{href:!0});var CVt=s(jW);EWo=r(CVt,"FNetForPreTraining"),CVt.forEach(t),CWo=r(_Xe," (FNet model)"),_Xe.forEach(t),wWo=i(V),Lb=n(V,"LI",{});var bXe=s(Lb);fFe=n(bXe,"STRONG",{});var wVt=s(fFe);AWo=r(wVt,"fsmt"),wVt.forEach(t),LWo=r(bXe," \u2014 "),DW=n(bXe,"A",{href:!0});var AVt=s(DW);yWo=r(AVt,"FSMTForConditionalGeneration"),AVt.forEach(t),xWo=r(bXe," (FairSeq Machine-Translation model)"),bXe.forEach(t),$Wo=i(V),yb=n(V,"LI",{});var vXe=s(yb);gFe=n(vXe,"STRONG",{});var LVt=s(gFe);kWo=r(LVt,"funnel"),LVt.forEach(t),SWo=r(vXe," \u2014 "),GW=n(vXe,"A",{href:!0});var yVt=s(GW);RWo=r(yVt,"FunnelForPreTraining"),yVt.forEach(t),PWo=r(vXe," (Funnel Transformer model)"),vXe.forEach(t),BWo=i(V),xb=n(V,"LI",{});var FXe=s(xb);hFe=n(FXe,"STRONG",{});var xVt=s(hFe);IWo=r(xVt,"gpt2"),xVt.forEach(t),NWo=r(FXe," \u2014 "),OW=n(FXe,"A",{href:!0});var $Vt=s(OW);qWo=r($Vt,"GPT2LMHeadModel"),$Vt.forEach(t),jWo=r(FXe," (OpenAI GPT-2 model)"),FXe.forEach(t),DWo=i(V),$b=n(V,"LI",{});var TXe=s($b);uFe=n(TXe,"STRONG",{});var kVt=s(uFe);GWo=r(kVt,"ibert"),kVt.forEach(t),OWo=r(TXe," \u2014 "),VW=n(TXe,"A",{href:!0});var SVt=s(VW);VWo=r(SVt,"IBertForMaskedLM"),SVt.forEach(t),XWo=r(TXe," (I-BERT model)"),TXe.forEach(t),zWo=i(V),kb=n(V,"LI",{});var MXe=s(kb);pFe=n(MXe,"STRONG",{});var RVt=s(pFe);QWo=r(RVt,"layoutlm"),RVt.forEach(t),WWo=r(MXe," \u2014 "),XW=n(MXe,"A",{href:!0});var PVt=s(XW);UWo=r(PVt,"LayoutLMForMaskedLM"),PVt.forEach(t),HWo=r(MXe," (LayoutLM model)"),MXe.forEach(t),JWo=i(V),Sb=n(V,"LI",{});var EXe=s(Sb);_Fe=n(EXe,"STRONG",{});var BVt=s(_Fe);YWo=r(BVt,"longformer"),BVt.forEach(t),ZWo=r(EXe," \u2014 "),zW=n(EXe,"A",{href:!0});var IVt=s(zW);KWo=r(IVt,"LongformerForMaskedLM"),IVt.forEach(t),eUo=r(EXe," (Longformer model)"),EXe.forEach(t),oUo=i(V),Rb=n(V,"LI",{});var CXe=s(Rb);bFe=n(CXe,"STRONG",{});var NVt=s(bFe);rUo=r(NVt,"luke"),NVt.forEach(t),tUo=r(CXe," \u2014 "),QW=n(CXe,"A",{href:!0});var qVt=s(QW);aUo=r(qVt,"LukeForMaskedLM"),qVt.forEach(t),nUo=r(CXe," (LUKE model)"),CXe.forEach(t),sUo=i(V),Pb=n(V,"LI",{});var wXe=s(Pb);vFe=n(wXe,"STRONG",{});var jVt=s(vFe);lUo=r(jVt,"lxmert"),jVt.forEach(t),iUo=r(wXe," \u2014 "),WW=n(wXe,"A",{href:!0});var DVt=s(WW);dUo=r(DVt,"LxmertForPreTraining"),DVt.forEach(t),mUo=r(wXe," (LXMERT model)"),wXe.forEach(t),cUo=i(V),Bb=n(V,"LI",{});var AXe=s(Bb);FFe=n(AXe,"STRONG",{});var GVt=s(FFe);fUo=r(GVt,"megatron-bert"),GVt.forEach(t),gUo=r(AXe," \u2014 "),UW=n(AXe,"A",{href:!0});var OVt=s(UW);hUo=r(OVt,"MegatronBertForPreTraining"),OVt.forEach(t),uUo=r(AXe," (Megatron-BERT model)"),AXe.forEach(t),pUo=i(V),Ib=n(V,"LI",{});var LXe=s(Ib);TFe=n(LXe,"STRONG",{});var VVt=s(TFe);_Uo=r(VVt,"mobilebert"),VVt.forEach(t),bUo=r(LXe," \u2014 "),HW=n(LXe,"A",{href:!0});var XVt=s(HW);vUo=r(XVt,"MobileBertForPreTraining"),XVt.forEach(t),FUo=r(LXe," (MobileBERT model)"),LXe.forEach(t),TUo=i(V),Nb=n(V,"LI",{});var yXe=s(Nb);MFe=n(yXe,"STRONG",{});var zVt=s(MFe);MUo=r(zVt,"mpnet"),zVt.forEach(t),EUo=r(yXe," \u2014 "),JW=n(yXe,"A",{href:!0});var QVt=s(JW);CUo=r(QVt,"MPNetForMaskedLM"),QVt.forEach(t),wUo=r(yXe," (MPNet model)"),yXe.forEach(t),AUo=i(V),qb=n(V,"LI",{});var xXe=s(qb);EFe=n(xXe,"STRONG",{});var WVt=s(EFe);LUo=r(WVt,"mvp"),WVt.forEach(t),yUo=r(xXe," \u2014 "),YW=n(xXe,"A",{href:!0});var UVt=s(YW);xUo=r(UVt,"MvpForConditionalGeneration"),UVt.forEach(t),$Uo=r(xXe," (MVP model)"),xXe.forEach(t),kUo=i(V),jb=n(V,"LI",{});var $Xe=s(jb);CFe=n($Xe,"STRONG",{});var HVt=s(CFe);SUo=r(HVt,"nezha"),HVt.forEach(t),RUo=r($Xe," \u2014 "),ZW=n($Xe,"A",{href:!0});var JVt=s(ZW);PUo=r(JVt,"NezhaForPreTraining"),JVt.forEach(t),BUo=r($Xe," (Nezha model)"),$Xe.forEach(t),IUo=i(V),Db=n(V,"LI",{});var kXe=s(Db);wFe=n(kXe,"STRONG",{});var YVt=s(wFe);NUo=r(YVt,"openai-gpt"),YVt.forEach(t),qUo=r(kXe," \u2014 "),KW=n(kXe,"A",{href:!0});var ZVt=s(KW);jUo=r(ZVt,"OpenAIGPTLMHeadModel"),ZVt.forEach(t),DUo=r(kXe," (OpenAI GPT model)"),kXe.forEach(t),GUo=i(V),Gb=n(V,"LI",{});var SXe=s(Gb);AFe=n(SXe,"STRONG",{});var KVt=s(AFe);OUo=r(KVt,"retribert"),KVt.forEach(t),VUo=r(SXe," \u2014 "),eU=n(SXe,"A",{href:!0});var eXt=s(eU);XUo=r(eXt,"RetriBertModel"),eXt.forEach(t),zUo=r(SXe," (RetriBERT model)"),SXe.forEach(t),QUo=i(V),Ob=n(V,"LI",{});var RXe=s(Ob);LFe=n(RXe,"STRONG",{});var oXt=s(LFe);WUo=r(oXt,"roberta"),oXt.forEach(t),UUo=r(RXe," \u2014 "),oU=n(RXe,"A",{href:!0});var rXt=s(oU);HUo=r(rXt,"RobertaForMaskedLM"),rXt.forEach(t),JUo=r(RXe," (RoBERTa model)"),RXe.forEach(t),YUo=i(V),Vb=n(V,"LI",{});var PXe=s(Vb);yFe=n(PXe,"STRONG",{});var tXt=s(yFe);ZUo=r(tXt,"roc_bert"),tXt.forEach(t),KUo=r(PXe," \u2014 "),rU=n(PXe,"A",{href:!0});var aXt=s(rU);eHo=r(aXt,"RoCBertForPreTraining"),aXt.forEach(t),oHo=r(PXe," (RoCBert model)"),PXe.forEach(t),rHo=i(V),Xb=n(V,"LI",{});var BXe=s(Xb);xFe=n(BXe,"STRONG",{});var nXt=s(xFe);tHo=r(nXt,"splinter"),nXt.forEach(t),aHo=r(BXe," \u2014 "),tU=n(BXe,"A",{href:!0});var sXt=s(tU);nHo=r(sXt,"SplinterForPreTraining"),sXt.forEach(t),sHo=r(BXe," (Splinter model)"),BXe.forEach(t),lHo=i(V),zb=n(V,"LI",{});var IXe=s(zb);$Fe=n(IXe,"STRONG",{});var lXt=s($Fe);iHo=r(lXt,"squeezebert"),lXt.forEach(t),dHo=r(IXe," \u2014 "),aU=n(IXe,"A",{href:!0});var iXt=s(aU);mHo=r(iXt,"SqueezeBertForMaskedLM"),iXt.forEach(t),cHo=r(IXe," (SqueezeBERT model)"),IXe.forEach(t),fHo=i(V),Qb=n(V,"LI",{});var NXe=s(Qb);kFe=n(NXe,"STRONG",{});var dXt=s(kFe);gHo=r(dXt,"t5"),dXt.forEach(t),hHo=r(NXe," \u2014 "),nU=n(NXe,"A",{href:!0});var mXt=s(nU);uHo=r(mXt,"T5ForConditionalGeneration"),mXt.forEach(t),pHo=r(NXe," (T5 model)"),NXe.forEach(t),_Ho=i(V),Wb=n(V,"LI",{});var qXe=s(Wb);SFe=n(qXe,"STRONG",{});var cXt=s(SFe);bHo=r(cXt,"tapas"),cXt.forEach(t),vHo=r(qXe," \u2014 "),sU=n(qXe,"A",{href:!0});var fXt=s(sU);FHo=r(fXt,"TapasForMaskedLM"),fXt.forEach(t),THo=r(qXe," (TAPAS model)"),qXe.forEach(t),MHo=i(V),Ub=n(V,"LI",{});var jXe=s(Ub);RFe=n(jXe,"STRONG",{});var gXt=s(RFe);EHo=r(gXt,"transfo-xl"),gXt.forEach(t),CHo=r(jXe," \u2014 "),lU=n(jXe,"A",{href:!0});var hXt=s(lU);wHo=r(hXt,"TransfoXLLMHeadModel"),hXt.forEach(t),AHo=r(jXe," (Transformer-XL model)"),jXe.forEach(t),LHo=i(V),Hb=n(V,"LI",{});var DXe=s(Hb);PFe=n(DXe,"STRONG",{});var uXt=s(PFe);yHo=r(uXt,"unispeech"),uXt.forEach(t),xHo=r(DXe," \u2014 "),iU=n(DXe,"A",{href:!0});var pXt=s(iU);$Ho=r(pXt,"UniSpeechForPreTraining"),pXt.forEach(t),kHo=r(DXe," (UniSpeech model)"),DXe.forEach(t),SHo=i(V),Jb=n(V,"LI",{});var GXe=s(Jb);BFe=n(GXe,"STRONG",{});var _Xt=s(BFe);RHo=r(_Xt,"unispeech-sat"),_Xt.forEach(t),PHo=r(GXe," \u2014 "),dU=n(GXe,"A",{href:!0});var bXt=s(dU);BHo=r(bXt,"UniSpeechSatForPreTraining"),bXt.forEach(t),IHo=r(GXe," (UniSpeechSat model)"),GXe.forEach(t),NHo=i(V),Yb=n(V,"LI",{});var OXe=s(Yb);IFe=n(OXe,"STRONG",{});var vXt=s(IFe);qHo=r(vXt,"videomae"),vXt.forEach(t),jHo=r(OXe," \u2014 "),mU=n(OXe,"A",{href:!0});var FXt=s(mU);DHo=r(FXt,"VideoMAEForPreTraining"),FXt.forEach(t),GHo=r(OXe," (VideoMAE model)"),OXe.forEach(t),OHo=i(V),Zb=n(V,"LI",{});var VXe=s(Zb);NFe=n(VXe,"STRONG",{});var TXt=s(NFe);VHo=r(TXt,"visual_bert"),TXt.forEach(t),XHo=r(VXe," \u2014 "),cU=n(VXe,"A",{href:!0});var MXt=s(cU);zHo=r(MXt,"VisualBertForPreTraining"),MXt.forEach(t),QHo=r(VXe," (VisualBERT model)"),VXe.forEach(t),WHo=i(V),Kb=n(V,"LI",{});var XXe=s(Kb);qFe=n(XXe,"STRONG",{});var EXt=s(qFe);UHo=r(EXt,"vit_mae"),EXt.forEach(t),HHo=r(XXe," \u2014 "),fU=n(XXe,"A",{href:!0});var CXt=s(fU);JHo=r(CXt,"ViTMAEForPreTraining"),CXt.forEach(t),YHo=r(XXe," (ViTMAE model)"),XXe.forEach(t),ZHo=i(V),ev=n(V,"LI",{});var zXe=s(ev);jFe=n(zXe,"STRONG",{});var wXt=s(jFe);KHo=r(wXt,"wav2vec2"),wXt.forEach(t),eJo=r(zXe," \u2014 "),gU=n(zXe,"A",{href:!0});var AXt=s(gU);oJo=r(AXt,"Wav2Vec2ForPreTraining"),AXt.forEach(t),rJo=r(zXe," (Wav2Vec2 model)"),zXe.forEach(t),tJo=i(V),ov=n(V,"LI",{});var QXe=s(ov);DFe=n(QXe,"STRONG",{});var LXt=s(DFe);aJo=r(LXt,"wav2vec2-conformer"),LXt.forEach(t),nJo=r(QXe," \u2014 "),hU=n(QXe,"A",{href:!0});var yXt=s(hU);sJo=r(yXt,"Wav2Vec2ConformerForPreTraining"),yXt.forEach(t),lJo=r(QXe," (Wav2Vec2-Conformer model)"),QXe.forEach(t),iJo=i(V),rv=n(V,"LI",{});var WXe=s(rv);GFe=n(WXe,"STRONG",{});var xXt=s(GFe);dJo=r(xXt,"xlm"),xXt.forEach(t),mJo=r(WXe," \u2014 "),uU=n(WXe,"A",{href:!0});var $Xt=s(uU);cJo=r($Xt,"XLMWithLMHeadModel"),$Xt.forEach(t),fJo=r(WXe," (XLM model)"),WXe.forEach(t),gJo=i(V),tv=n(V,"LI",{});var UXe=s(tv);OFe=n(UXe,"STRONG",{});var kXt=s(OFe);hJo=r(kXt,"xlm-roberta"),kXt.forEach(t),uJo=r(UXe," \u2014 "),pU=n(UXe,"A",{href:!0});var SXt=s(pU);pJo=r(SXt,"XLMRobertaForMaskedLM"),SXt.forEach(t),_Jo=r(UXe," (XLM-RoBERTa model)"),UXe.forEach(t),bJo=i(V),av=n(V,"LI",{});var HXe=s(av);VFe=n(HXe,"STRONG",{});var RXt=s(VFe);vJo=r(RXt,"xlm-roberta-xl"),RXt.forEach(t),FJo=r(HXe," \u2014 "),_U=n(HXe,"A",{href:!0});var PXt=s(_U);TJo=r(PXt,"XLMRobertaXLForMaskedLM"),PXt.forEach(t),MJo=r(HXe," (XLM-RoBERTa-XL model)"),HXe.forEach(t),EJo=i(V),nv=n(V,"LI",{});var JXe=s(nv);XFe=n(JXe,"STRONG",{});var BXt=s(XFe);CJo=r(BXt,"xlnet"),BXt.forEach(t),wJo=r(JXe," \u2014 "),bU=n(JXe,"A",{href:!0});var IXt=s(bU);AJo=r(IXt,"XLNetLMHeadModel"),IXt.forEach(t),LJo=r(JXe," (XLNet model)"),JXe.forEach(t),V.forEach(t),yJo=i(ya),sv=n(ya,"P",{});var YXe=s(sv);xJo=r(YXe,"The model is set in evaluation mode by default using "),zFe=n(YXe,"CODE",{});var NXt=s(zFe);$Jo=r(NXt,"model.eval()"),NXt.forEach(t),kJo=r(YXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),QFe=n(YXe,"CODE",{});var qXt=s(QFe);SJo=r(qXt,"model.train()"),qXt.forEach(t),YXe.forEach(t),RJo=i(ya),T(lv.$$.fragment,ya),ya.forEach(t),Dl.forEach(t),zao=i(c),jd=n(c,"H2",{class:!0});var dlo=s(jd);iv=n(dlo,"A",{id:!0,class:!0,href:!0});var jXt=s(iv);WFe=n(jXt,"SPAN",{});var DXt=s(WFe);T(nk.$$.fragment,DXt),DXt.forEach(t),jXt.forEach(t),PJo=i(dlo),UFe=n(dlo,"SPAN",{});var GXt=s(UFe);BJo=r(GXt,"AutoModelForCausalLM"),GXt.forEach(t),dlo.forEach(t),Qao=i(c),qo=n(c,"DIV",{class:!0});var Gl=s(qo);T(sk.$$.fragment,Gl),IJo=i(Gl),Dd=n(Gl,"P",{});var qme=s(Dd);NJo=r(qme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),vU=n(qme,"A",{href:!0});var OXt=s(vU);qJo=r(OXt,"from_pretrained()"),OXt.forEach(t),jJo=r(qme," class method or the "),FU=n(qme,"A",{href:!0});var VXt=s(FU);DJo=r(VXt,"from_config()"),VXt.forEach(t),GJo=r(qme,` class
method.`),qme.forEach(t),OJo=i(Gl),lk=n(Gl,"P",{});var mlo=s(lk);VJo=r(mlo,"This class cannot be instantiated directly using "),HFe=n(mlo,"CODE",{});var XXt=s(HFe);XJo=r(XXt,"__init__()"),XXt.forEach(t),zJo=r(mlo," (throws an error)."),mlo.forEach(t),QJo=i(Gl),Ct=n(Gl,"DIV",{class:!0});var b9=s(Ct);T(ik.$$.fragment,b9),WJo=i(b9),JFe=n(b9,"P",{});var zXt=s(JFe);UJo=r(zXt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),zXt.forEach(t),HJo=i(b9),Gd=n(b9,"P",{});var jme=s(Gd);JJo=r(jme,`Note:
Loading a model from its configuration file does `),YFe=n(jme,"STRONG",{});var QXt=s(YFe);YJo=r(QXt,"not"),QXt.forEach(t),ZJo=r(jme,` load the model weights. It only affects the
model\u2019s configuration. Use `),TU=n(jme,"A",{href:!0});var WXt=s(TU);KJo=r(WXt,"from_pretrained()"),WXt.forEach(t),eYo=r(jme," to load the model weights."),jme.forEach(t),oYo=i(b9),T(dv.$$.fragment,b9),b9.forEach(t),rYo=i(Gl),oo=n(Gl,"DIV",{class:!0});var xa=s(oo);T(dk.$$.fragment,xa),tYo=i(xa),ZFe=n(xa,"P",{});var UXt=s(ZFe);aYo=r(UXt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),UXt.forEach(t),nYo=i(xa),ln=n(xa,"P",{});var v9=s(ln);sYo=r(v9,"The model class to instantiate is selected based on the "),KFe=n(v9,"CODE",{});var HXt=s(KFe);lYo=r(HXt,"model_type"),HXt.forEach(t),iYo=r(v9,` property of the config object (either
passed as an argument or loaded from `),eTe=n(v9,"CODE",{});var JXt=s(eTe);dYo=r(JXt,"pretrained_model_name_or_path"),JXt.forEach(t),mYo=r(v9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oTe=n(v9,"CODE",{});var YXt=s(oTe);cYo=r(YXt,"pretrained_model_name_or_path"),YXt.forEach(t),fYo=r(v9,":"),v9.forEach(t),gYo=i(xa),W=n(xa,"UL",{});var H=s(W);mv=n(H,"LI",{});var ZXe=s(mv);rTe=n(ZXe,"STRONG",{});var ZXt=s(rTe);hYo=r(ZXt,"bart"),ZXt.forEach(t),uYo=r(ZXe," \u2014 "),MU=n(ZXe,"A",{href:!0});var KXt=s(MU);pYo=r(KXt,"BartForCausalLM"),KXt.forEach(t),_Yo=r(ZXe," (BART model)"),ZXe.forEach(t),bYo=i(H),cv=n(H,"LI",{});var KXe=s(cv);tTe=n(KXe,"STRONG",{});var ezt=s(tTe);vYo=r(ezt,"bert"),ezt.forEach(t),FYo=r(KXe," \u2014 "),EU=n(KXe,"A",{href:!0});var ozt=s(EU);TYo=r(ozt,"BertLMHeadModel"),ozt.forEach(t),MYo=r(KXe," (BERT model)"),KXe.forEach(t),EYo=i(H),fv=n(H,"LI",{});var eze=s(fv);aTe=n(eze,"STRONG",{});var rzt=s(aTe);CYo=r(rzt,"bert-generation"),rzt.forEach(t),wYo=r(eze," \u2014 "),CU=n(eze,"A",{href:!0});var tzt=s(CU);AYo=r(tzt,"BertGenerationDecoder"),tzt.forEach(t),LYo=r(eze," (Bert Generation model)"),eze.forEach(t),yYo=i(H),gv=n(H,"LI",{});var oze=s(gv);nTe=n(oze,"STRONG",{});var azt=s(nTe);xYo=r(azt,"big_bird"),azt.forEach(t),$Yo=r(oze," \u2014 "),wU=n(oze,"A",{href:!0});var nzt=s(wU);kYo=r(nzt,"BigBirdForCausalLM"),nzt.forEach(t),SYo=r(oze," (BigBird model)"),oze.forEach(t),RYo=i(H),hv=n(H,"LI",{});var rze=s(hv);sTe=n(rze,"STRONG",{});var szt=s(sTe);PYo=r(szt,"bigbird_pegasus"),szt.forEach(t),BYo=r(rze," \u2014 "),AU=n(rze,"A",{href:!0});var lzt=s(AU);IYo=r(lzt,"BigBirdPegasusForCausalLM"),lzt.forEach(t),NYo=r(rze," (BigBird-Pegasus model)"),rze.forEach(t),qYo=i(H),uv=n(H,"LI",{});var tze=s(uv);lTe=n(tze,"STRONG",{});var izt=s(lTe);jYo=r(izt,"blenderbot"),izt.forEach(t),DYo=r(tze," \u2014 "),LU=n(tze,"A",{href:!0});var dzt=s(LU);GYo=r(dzt,"BlenderbotForCausalLM"),dzt.forEach(t),OYo=r(tze," (Blenderbot model)"),tze.forEach(t),VYo=i(H),pv=n(H,"LI",{});var aze=s(pv);iTe=n(aze,"STRONG",{});var mzt=s(iTe);XYo=r(mzt,"blenderbot-small"),mzt.forEach(t),zYo=r(aze," \u2014 "),yU=n(aze,"A",{href:!0});var czt=s(yU);QYo=r(czt,"BlenderbotSmallForCausalLM"),czt.forEach(t),WYo=r(aze," (BlenderbotSmall model)"),aze.forEach(t),UYo=i(H),_v=n(H,"LI",{});var nze=s(_v);dTe=n(nze,"STRONG",{});var fzt=s(dTe);HYo=r(fzt,"bloom"),fzt.forEach(t),JYo=r(nze," \u2014 "),xU=n(nze,"A",{href:!0});var gzt=s(xU);YYo=r(gzt,"BloomForCausalLM"),gzt.forEach(t),ZYo=r(nze," (BLOOM model)"),nze.forEach(t),KYo=i(H),bv=n(H,"LI",{});var sze=s(bv);mTe=n(sze,"STRONG",{});var hzt=s(mTe);eZo=r(hzt,"camembert"),hzt.forEach(t),oZo=r(sze," \u2014 "),$U=n(sze,"A",{href:!0});var uzt=s($U);rZo=r(uzt,"CamembertForCausalLM"),uzt.forEach(t),tZo=r(sze," (CamemBERT model)"),sze.forEach(t),aZo=i(H),vv=n(H,"LI",{});var lze=s(vv);cTe=n(lze,"STRONG",{});var pzt=s(cTe);nZo=r(pzt,"codegen"),pzt.forEach(t),sZo=r(lze," \u2014 "),kU=n(lze,"A",{href:!0});var _zt=s(kU);lZo=r(_zt,"CodeGenForCausalLM"),_zt.forEach(t),iZo=r(lze," (CodeGen model)"),lze.forEach(t),dZo=i(H),Fv=n(H,"LI",{});var ize=s(Fv);fTe=n(ize,"STRONG",{});var bzt=s(fTe);mZo=r(bzt,"ctrl"),bzt.forEach(t),cZo=r(ize," \u2014 "),SU=n(ize,"A",{href:!0});var vzt=s(SU);fZo=r(vzt,"CTRLLMHeadModel"),vzt.forEach(t),gZo=r(ize," (CTRL model)"),ize.forEach(t),hZo=i(H),Tv=n(H,"LI",{});var dze=s(Tv);gTe=n(dze,"STRONG",{});var Fzt=s(gTe);uZo=r(Fzt,"data2vec-text"),Fzt.forEach(t),pZo=r(dze," \u2014 "),RU=n(dze,"A",{href:!0});var Tzt=s(RU);_Zo=r(Tzt,"Data2VecTextForCausalLM"),Tzt.forEach(t),bZo=r(dze," (Data2VecText model)"),dze.forEach(t),vZo=i(H),Mv=n(H,"LI",{});var mze=s(Mv);hTe=n(mze,"STRONG",{});var Mzt=s(hTe);FZo=r(Mzt,"electra"),Mzt.forEach(t),TZo=r(mze," \u2014 "),PU=n(mze,"A",{href:!0});var Ezt=s(PU);MZo=r(Ezt,"ElectraForCausalLM"),Ezt.forEach(t),EZo=r(mze," (ELECTRA model)"),mze.forEach(t),CZo=i(H),Ev=n(H,"LI",{});var cze=s(Ev);uTe=n(cze,"STRONG",{});var Czt=s(uTe);wZo=r(Czt,"ernie"),Czt.forEach(t),AZo=r(cze," \u2014 "),BU=n(cze,"A",{href:!0});var wzt=s(BU);LZo=r(wzt,"ErnieForCausalLM"),wzt.forEach(t),yZo=r(cze," (ERNIE model)"),cze.forEach(t),xZo=i(H),Cv=n(H,"LI",{});var fze=s(Cv);pTe=n(fze,"STRONG",{});var Azt=s(pTe);$Zo=r(Azt,"gpt2"),Azt.forEach(t),kZo=r(fze," \u2014 "),IU=n(fze,"A",{href:!0});var Lzt=s(IU);SZo=r(Lzt,"GPT2LMHeadModel"),Lzt.forEach(t),RZo=r(fze," (OpenAI GPT-2 model)"),fze.forEach(t),PZo=i(H),wv=n(H,"LI",{});var gze=s(wv);_Te=n(gze,"STRONG",{});var yzt=s(_Te);BZo=r(yzt,"gpt_neo"),yzt.forEach(t),IZo=r(gze," \u2014 "),NU=n(gze,"A",{href:!0});var xzt=s(NU);NZo=r(xzt,"GPTNeoForCausalLM"),xzt.forEach(t),qZo=r(gze," (GPT Neo model)"),gze.forEach(t),jZo=i(H),Av=n(H,"LI",{});var hze=s(Av);bTe=n(hze,"STRONG",{});var $zt=s(bTe);DZo=r($zt,"gpt_neox"),$zt.forEach(t),GZo=r(hze," \u2014 "),qU=n(hze,"A",{href:!0});var kzt=s(qU);OZo=r(kzt,"GPTNeoXForCausalLM"),kzt.forEach(t),VZo=r(hze," (GPT NeoX model)"),hze.forEach(t),XZo=i(H),Lv=n(H,"LI",{});var uze=s(Lv);vTe=n(uze,"STRONG",{});var Szt=s(vTe);zZo=r(Szt,"gpt_neox_japanese"),Szt.forEach(t),QZo=r(uze," \u2014 "),jU=n(uze,"A",{href:!0});var Rzt=s(jU);WZo=r(Rzt,"GPTNeoXJapaneseForCausalLM"),Rzt.forEach(t),UZo=r(uze," (GPT NeoX Japanese model)"),uze.forEach(t),HZo=i(H),yv=n(H,"LI",{});var pze=s(yv);FTe=n(pze,"STRONG",{});var Pzt=s(FTe);JZo=r(Pzt,"gptj"),Pzt.forEach(t),YZo=r(pze," \u2014 "),DU=n(pze,"A",{href:!0});var Bzt=s(DU);ZZo=r(Bzt,"GPTJForCausalLM"),Bzt.forEach(t),KZo=r(pze," (GPT-J model)"),pze.forEach(t),eKo=i(H),xv=n(H,"LI",{});var _ze=s(xv);TTe=n(_ze,"STRONG",{});var Izt=s(TTe);oKo=r(Izt,"marian"),Izt.forEach(t),rKo=r(_ze," \u2014 "),GU=n(_ze,"A",{href:!0});var Nzt=s(GU);tKo=r(Nzt,"MarianForCausalLM"),Nzt.forEach(t),aKo=r(_ze," (Marian model)"),_ze.forEach(t),nKo=i(H),$v=n(H,"LI",{});var bze=s($v);MTe=n(bze,"STRONG",{});var qzt=s(MTe);sKo=r(qzt,"mbart"),qzt.forEach(t),lKo=r(bze," \u2014 "),OU=n(bze,"A",{href:!0});var jzt=s(OU);iKo=r(jzt,"MBartForCausalLM"),jzt.forEach(t),dKo=r(bze," (mBART model)"),bze.forEach(t),mKo=i(H),kv=n(H,"LI",{});var vze=s(kv);ETe=n(vze,"STRONG",{});var Dzt=s(ETe);cKo=r(Dzt,"megatron-bert"),Dzt.forEach(t),fKo=r(vze," \u2014 "),VU=n(vze,"A",{href:!0});var Gzt=s(VU);gKo=r(Gzt,"MegatronBertForCausalLM"),Gzt.forEach(t),hKo=r(vze," (Megatron-BERT model)"),vze.forEach(t),uKo=i(H),Sv=n(H,"LI",{});var Fze=s(Sv);CTe=n(Fze,"STRONG",{});var Ozt=s(CTe);pKo=r(Ozt,"mvp"),Ozt.forEach(t),_Ko=r(Fze," \u2014 "),XU=n(Fze,"A",{href:!0});var Vzt=s(XU);bKo=r(Vzt,"MvpForCausalLM"),Vzt.forEach(t),vKo=r(Fze," (MVP model)"),Fze.forEach(t),FKo=i(H),Rv=n(H,"LI",{});var Tze=s(Rv);wTe=n(Tze,"STRONG",{});var Xzt=s(wTe);TKo=r(Xzt,"openai-gpt"),Xzt.forEach(t),MKo=r(Tze," \u2014 "),zU=n(Tze,"A",{href:!0});var zzt=s(zU);EKo=r(zzt,"OpenAIGPTLMHeadModel"),zzt.forEach(t),CKo=r(Tze," (OpenAI GPT model)"),Tze.forEach(t),wKo=i(H),Pv=n(H,"LI",{});var Mze=s(Pv);ATe=n(Mze,"STRONG",{});var Qzt=s(ATe);AKo=r(Qzt,"opt"),Qzt.forEach(t),LKo=r(Mze," \u2014 "),QU=n(Mze,"A",{href:!0});var Wzt=s(QU);yKo=r(Wzt,"OPTForCausalLM"),Wzt.forEach(t),xKo=r(Mze," (OPT model)"),Mze.forEach(t),$Ko=i(H),Bv=n(H,"LI",{});var Eze=s(Bv);LTe=n(Eze,"STRONG",{});var Uzt=s(LTe);kKo=r(Uzt,"pegasus"),Uzt.forEach(t),SKo=r(Eze," \u2014 "),WU=n(Eze,"A",{href:!0});var Hzt=s(WU);RKo=r(Hzt,"PegasusForCausalLM"),Hzt.forEach(t),PKo=r(Eze," (Pegasus model)"),Eze.forEach(t),BKo=i(H),Iv=n(H,"LI",{});var Cze=s(Iv);yTe=n(Cze,"STRONG",{});var Jzt=s(yTe);IKo=r(Jzt,"plbart"),Jzt.forEach(t),NKo=r(Cze," \u2014 "),UU=n(Cze,"A",{href:!0});var Yzt=s(UU);qKo=r(Yzt,"PLBartForCausalLM"),Yzt.forEach(t),jKo=r(Cze," (PLBart model)"),Cze.forEach(t),DKo=i(H),Nv=n(H,"LI",{});var wze=s(Nv);xTe=n(wze,"STRONG",{});var Zzt=s(xTe);GKo=r(Zzt,"prophetnet"),Zzt.forEach(t),OKo=r(wze," \u2014 "),HU=n(wze,"A",{href:!0});var Kzt=s(HU);VKo=r(Kzt,"ProphetNetForCausalLM"),Kzt.forEach(t),XKo=r(wze," (ProphetNet model)"),wze.forEach(t),zKo=i(H),qv=n(H,"LI",{});var Aze=s(qv);$Te=n(Aze,"STRONG",{});var eQt=s($Te);QKo=r(eQt,"qdqbert"),eQt.forEach(t),WKo=r(Aze," \u2014 "),JU=n(Aze,"A",{href:!0});var oQt=s(JU);UKo=r(oQt,"QDQBertLMHeadModel"),oQt.forEach(t),HKo=r(Aze," (QDQBert model)"),Aze.forEach(t),JKo=i(H),jv=n(H,"LI",{});var Lze=s(jv);kTe=n(Lze,"STRONG",{});var rQt=s(kTe);YKo=r(rQt,"reformer"),rQt.forEach(t),ZKo=r(Lze," \u2014 "),YU=n(Lze,"A",{href:!0});var tQt=s(YU);KKo=r(tQt,"ReformerModelWithLMHead"),tQt.forEach(t),eer=r(Lze," (Reformer model)"),Lze.forEach(t),oer=i(H),Dv=n(H,"LI",{});var yze=s(Dv);STe=n(yze,"STRONG",{});var aQt=s(STe);rer=r(aQt,"rembert"),aQt.forEach(t),ter=r(yze," \u2014 "),ZU=n(yze,"A",{href:!0});var nQt=s(ZU);aer=r(nQt,"RemBertForCausalLM"),nQt.forEach(t),ner=r(yze," (RemBERT model)"),yze.forEach(t),ser=i(H),Gv=n(H,"LI",{});var xze=s(Gv);RTe=n(xze,"STRONG",{});var sQt=s(RTe);ler=r(sQt,"roberta"),sQt.forEach(t),ier=r(xze," \u2014 "),KU=n(xze,"A",{href:!0});var lQt=s(KU);der=r(lQt,"RobertaForCausalLM"),lQt.forEach(t),mer=r(xze," (RoBERTa model)"),xze.forEach(t),cer=i(H),Ov=n(H,"LI",{});var $ze=s(Ov);PTe=n($ze,"STRONG",{});var iQt=s(PTe);fer=r(iQt,"roc_bert"),iQt.forEach(t),ger=r($ze," \u2014 "),eH=n($ze,"A",{href:!0});var dQt=s(eH);her=r(dQt,"RoCBertForCausalLM"),dQt.forEach(t),uer=r($ze," (RoCBert model)"),$ze.forEach(t),per=i(H),Vv=n(H,"LI",{});var kze=s(Vv);BTe=n(kze,"STRONG",{});var mQt=s(BTe);_er=r(mQt,"roformer"),mQt.forEach(t),ber=r(kze," \u2014 "),oH=n(kze,"A",{href:!0});var cQt=s(oH);ver=r(cQt,"RoFormerForCausalLM"),cQt.forEach(t),Fer=r(kze," (RoFormer model)"),kze.forEach(t),Ter=i(H),Xv=n(H,"LI",{});var Sze=s(Xv);ITe=n(Sze,"STRONG",{});var fQt=s(ITe);Mer=r(fQt,"speech_to_text_2"),fQt.forEach(t),Eer=r(Sze," \u2014 "),rH=n(Sze,"A",{href:!0});var gQt=s(rH);Cer=r(gQt,"Speech2Text2ForCausalLM"),gQt.forEach(t),wer=r(Sze," (Speech2Text2 model)"),Sze.forEach(t),Aer=i(H),zv=n(H,"LI",{});var Rze=s(zv);NTe=n(Rze,"STRONG",{});var hQt=s(NTe);Ler=r(hQt,"transfo-xl"),hQt.forEach(t),yer=r(Rze," \u2014 "),tH=n(Rze,"A",{href:!0});var uQt=s(tH);xer=r(uQt,"TransfoXLLMHeadModel"),uQt.forEach(t),$er=r(Rze," (Transformer-XL model)"),Rze.forEach(t),ker=i(H),Qv=n(H,"LI",{});var Pze=s(Qv);qTe=n(Pze,"STRONG",{});var pQt=s(qTe);Ser=r(pQt,"trocr"),pQt.forEach(t),Rer=r(Pze," \u2014 "),aH=n(Pze,"A",{href:!0});var _Qt=s(aH);Per=r(_Qt,"TrOCRForCausalLM"),_Qt.forEach(t),Ber=r(Pze," (TrOCR model)"),Pze.forEach(t),Ier=i(H),Wv=n(H,"LI",{});var Bze=s(Wv);jTe=n(Bze,"STRONG",{});var bQt=s(jTe);Ner=r(bQt,"xglm"),bQt.forEach(t),qer=r(Bze," \u2014 "),nH=n(Bze,"A",{href:!0});var vQt=s(nH);jer=r(vQt,"XGLMForCausalLM"),vQt.forEach(t),Der=r(Bze," (XGLM model)"),Bze.forEach(t),Ger=i(H),Uv=n(H,"LI",{});var Ize=s(Uv);DTe=n(Ize,"STRONG",{});var FQt=s(DTe);Oer=r(FQt,"xlm"),FQt.forEach(t),Ver=r(Ize," \u2014 "),sH=n(Ize,"A",{href:!0});var TQt=s(sH);Xer=r(TQt,"XLMWithLMHeadModel"),TQt.forEach(t),zer=r(Ize," (XLM model)"),Ize.forEach(t),Qer=i(H),Hv=n(H,"LI",{});var Nze=s(Hv);GTe=n(Nze,"STRONG",{});var MQt=s(GTe);Wer=r(MQt,"xlm-prophetnet"),MQt.forEach(t),Uer=r(Nze," \u2014 "),lH=n(Nze,"A",{href:!0});var EQt=s(lH);Her=r(EQt,"XLMProphetNetForCausalLM"),EQt.forEach(t),Jer=r(Nze," (XLM-ProphetNet model)"),Nze.forEach(t),Yer=i(H),Jv=n(H,"LI",{});var qze=s(Jv);OTe=n(qze,"STRONG",{});var CQt=s(OTe);Zer=r(CQt,"xlm-roberta"),CQt.forEach(t),Ker=r(qze," \u2014 "),iH=n(qze,"A",{href:!0});var wQt=s(iH);eor=r(wQt,"XLMRobertaForCausalLM"),wQt.forEach(t),oor=r(qze," (XLM-RoBERTa model)"),qze.forEach(t),ror=i(H),Yv=n(H,"LI",{});var jze=s(Yv);VTe=n(jze,"STRONG",{});var AQt=s(VTe);tor=r(AQt,"xlm-roberta-xl"),AQt.forEach(t),aor=r(jze," \u2014 "),dH=n(jze,"A",{href:!0});var LQt=s(dH);nor=r(LQt,"XLMRobertaXLForCausalLM"),LQt.forEach(t),sor=r(jze," (XLM-RoBERTa-XL model)"),jze.forEach(t),lor=i(H),Zv=n(H,"LI",{});var Dze=s(Zv);XTe=n(Dze,"STRONG",{});var yQt=s(XTe);ior=r(yQt,"xlnet"),yQt.forEach(t),dor=r(Dze," \u2014 "),mH=n(Dze,"A",{href:!0});var xQt=s(mH);mor=r(xQt,"XLNetLMHeadModel"),xQt.forEach(t),cor=r(Dze," (XLNet model)"),Dze.forEach(t),H.forEach(t),gor=i(xa),Kv=n(xa,"P",{});var Gze=s(Kv);hor=r(Gze,"The model is set in evaluation mode by default using "),zTe=n(Gze,"CODE",{});var $Qt=s(zTe);uor=r($Qt,"model.eval()"),$Qt.forEach(t),por=r(Gze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),QTe=n(Gze,"CODE",{});var kQt=s(QTe);_or=r(kQt,"model.train()"),kQt.forEach(t),Gze.forEach(t),bor=i(xa),T(eF.$$.fragment,xa),xa.forEach(t),Gl.forEach(t),Wao=i(c),Od=n(c,"H2",{class:!0});var clo=s(Od);oF=n(clo,"A",{id:!0,class:!0,href:!0});var SQt=s(oF);WTe=n(SQt,"SPAN",{});var RQt=s(WTe);T(mk.$$.fragment,RQt),RQt.forEach(t),SQt.forEach(t),vor=i(clo),UTe=n(clo,"SPAN",{});var PQt=s(UTe);For=r(PQt,"AutoModelForDepthEstimation"),PQt.forEach(t),clo.forEach(t),Uao=i(c),jo=n(c,"DIV",{class:!0});var Ol=s(jo);T(ck.$$.fragment,Ol),Tor=i(Ol),Vd=n(Ol,"P",{});var Dme=s(Vd);Mor=r(Dme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a depth estimation head) when created
with the `),cH=n(Dme,"A",{href:!0});var BQt=s(cH);Eor=r(BQt,"from_pretrained()"),BQt.forEach(t),Cor=r(Dme," class method or the "),fH=n(Dme,"A",{href:!0});var IQt=s(fH);wor=r(IQt,"from_config()"),IQt.forEach(t),Aor=r(Dme,` class
method.`),Dme.forEach(t),Lor=i(Ol),fk=n(Ol,"P",{});var flo=s(fk);yor=r(flo,"This class cannot be instantiated directly using "),HTe=n(flo,"CODE",{});var NQt=s(HTe);xor=r(NQt,"__init__()"),NQt.forEach(t),$or=r(flo," (throws an error)."),flo.forEach(t),kor=i(Ol),wt=n(Ol,"DIV",{class:!0});var F9=s(wt);T(gk.$$.fragment,F9),Sor=i(F9),JTe=n(F9,"P",{});var qQt=s(JTe);Ror=r(qQt,"Instantiates one of the model classes of the library (with a depth estimation head) from a configuration."),qQt.forEach(t),Por=i(F9),Xd=n(F9,"P",{});var Gme=s(Xd);Bor=r(Gme,`Note:
Loading a model from its configuration file does `),YTe=n(Gme,"STRONG",{});var jQt=s(YTe);Ior=r(jQt,"not"),jQt.forEach(t),Nor=r(Gme,` load the model weights. It only affects the
model\u2019s configuration. Use `),gH=n(Gme,"A",{href:!0});var DQt=s(gH);qor=r(DQt,"from_pretrained()"),DQt.forEach(t),jor=r(Gme," to load the model weights."),Gme.forEach(t),Dor=i(F9),T(rF.$$.fragment,F9),F9.forEach(t),Gor=i(Ol),ro=n(Ol,"DIV",{class:!0});var $a=s(ro);T(hk.$$.fragment,$a),Oor=i($a),ZTe=n($a,"P",{});var GQt=s(ZTe);Vor=r(GQt,"Instantiate one of the model classes of the library (with a depth estimation head) from a pretrained model."),GQt.forEach(t),Xor=i($a),dn=n($a,"P",{});var T9=s(dn);zor=r(T9,"The model class to instantiate is selected based on the "),KTe=n(T9,"CODE",{});var OQt=s(KTe);Qor=r(OQt,"model_type"),OQt.forEach(t),Wor=r(T9,` property of the config object (either
passed as an argument or loaded from `),eMe=n(T9,"CODE",{});var VQt=s(eMe);Uor=r(VQt,"pretrained_model_name_or_path"),VQt.forEach(t),Hor=r(T9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oMe=n(T9,"CODE",{});var XQt=s(oMe);Jor=r(XQt,"pretrained_model_name_or_path"),XQt.forEach(t),Yor=r(T9,":"),T9.forEach(t),Zor=i($a),uk=n($a,"UL",{});var glo=s(uk);tF=n(glo,"LI",{});var Oze=s(tF);rMe=n(Oze,"STRONG",{});var zQt=s(rMe);Kor=r(zQt,"dpt"),zQt.forEach(t),err=r(Oze," \u2014 "),hH=n(Oze,"A",{href:!0});var QQt=s(hH);orr=r(QQt,"DPTForDepthEstimation"),QQt.forEach(t),rrr=r(Oze," (DPT model)"),Oze.forEach(t),trr=i(glo),aF=n(glo,"LI",{});var Vze=s(aF);tMe=n(Vze,"STRONG",{});var WQt=s(tMe);arr=r(WQt,"glpn"),WQt.forEach(t),nrr=r(Vze," \u2014 "),uH=n(Vze,"A",{href:!0});var UQt=s(uH);srr=r(UQt,"GLPNForDepthEstimation"),UQt.forEach(t),lrr=r(Vze," (GLPN model)"),Vze.forEach(t),glo.forEach(t),irr=i($a),nF=n($a,"P",{});var Xze=s(nF);drr=r(Xze,"The model is set in evaluation mode by default using "),aMe=n(Xze,"CODE",{});var HQt=s(aMe);mrr=r(HQt,"model.eval()"),HQt.forEach(t),crr=r(Xze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),nMe=n(Xze,"CODE",{});var JQt=s(nMe);frr=r(JQt,"model.train()"),JQt.forEach(t),Xze.forEach(t),grr=i($a),T(sF.$$.fragment,$a),$a.forEach(t),Ol.forEach(t),Hao=i(c),zd=n(c,"H2",{class:!0});var hlo=s(zd);lF=n(hlo,"A",{id:!0,class:!0,href:!0});var YQt=s(lF);sMe=n(YQt,"SPAN",{});var ZQt=s(sMe);T(pk.$$.fragment,ZQt),ZQt.forEach(t),YQt.forEach(t),hrr=i(hlo),lMe=n(hlo,"SPAN",{});var KQt=s(lMe);urr=r(KQt,"AutoModelForMaskedLM"),KQt.forEach(t),hlo.forEach(t),Jao=i(c),Do=n(c,"DIV",{class:!0});var Vl=s(Do);T(_k.$$.fragment,Vl),prr=i(Vl),Qd=n(Vl,"P",{});var Ome=s(Qd);_rr=r(Ome,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),pH=n(Ome,"A",{href:!0});var eWt=s(pH);brr=r(eWt,"from_pretrained()"),eWt.forEach(t),vrr=r(Ome," class method or the "),_H=n(Ome,"A",{href:!0});var oWt=s(_H);Frr=r(oWt,"from_config()"),oWt.forEach(t),Trr=r(Ome,` class
method.`),Ome.forEach(t),Mrr=i(Vl),bk=n(Vl,"P",{});var ulo=s(bk);Err=r(ulo,"This class cannot be instantiated directly using "),iMe=n(ulo,"CODE",{});var rWt=s(iMe);Crr=r(rWt,"__init__()"),rWt.forEach(t),wrr=r(ulo," (throws an error)."),ulo.forEach(t),Arr=i(Vl),At=n(Vl,"DIV",{class:!0});var M9=s(At);T(vk.$$.fragment,M9),Lrr=i(M9),dMe=n(M9,"P",{});var tWt=s(dMe);yrr=r(tWt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),tWt.forEach(t),xrr=i(M9),Wd=n(M9,"P",{});var Vme=s(Wd);$rr=r(Vme,`Note:
Loading a model from its configuration file does `),mMe=n(Vme,"STRONG",{});var aWt=s(mMe);krr=r(aWt,"not"),aWt.forEach(t),Srr=r(Vme,` load the model weights. It only affects the
model\u2019s configuration. Use `),bH=n(Vme,"A",{href:!0});var nWt=s(bH);Rrr=r(nWt,"from_pretrained()"),nWt.forEach(t),Prr=r(Vme," to load the model weights."),Vme.forEach(t),Brr=i(M9),T(iF.$$.fragment,M9),M9.forEach(t),Irr=i(Vl),to=n(Vl,"DIV",{class:!0});var ka=s(to);T(Fk.$$.fragment,ka),Nrr=i(ka),cMe=n(ka,"P",{});var sWt=s(cMe);qrr=r(sWt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),sWt.forEach(t),jrr=i(ka),mn=n(ka,"P",{});var E9=s(mn);Drr=r(E9,"The model class to instantiate is selected based on the "),fMe=n(E9,"CODE",{});var lWt=s(fMe);Grr=r(lWt,"model_type"),lWt.forEach(t),Orr=r(E9,` property of the config object (either
passed as an argument or loaded from `),gMe=n(E9,"CODE",{});var iWt=s(gMe);Vrr=r(iWt,"pretrained_model_name_or_path"),iWt.forEach(t),Xrr=r(E9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hMe=n(E9,"CODE",{});var dWt=s(hMe);zrr=r(dWt,"pretrained_model_name_or_path"),dWt.forEach(t),Qrr=r(E9,":"),E9.forEach(t),Wrr=i(ka),Y=n(ka,"UL",{});var Z=s(Y);dF=n(Z,"LI",{});var zze=s(dF);uMe=n(zze,"STRONG",{});var mWt=s(uMe);Urr=r(mWt,"albert"),mWt.forEach(t),Hrr=r(zze," \u2014 "),vH=n(zze,"A",{href:!0});var cWt=s(vH);Jrr=r(cWt,"AlbertForMaskedLM"),cWt.forEach(t),Yrr=r(zze," (ALBERT model)"),zze.forEach(t),Zrr=i(Z),mF=n(Z,"LI",{});var Qze=s(mF);pMe=n(Qze,"STRONG",{});var fWt=s(pMe);Krr=r(fWt,"bart"),fWt.forEach(t),etr=r(Qze," \u2014 "),FH=n(Qze,"A",{href:!0});var gWt=s(FH);otr=r(gWt,"BartForConditionalGeneration"),gWt.forEach(t),rtr=r(Qze," (BART model)"),Qze.forEach(t),ttr=i(Z),cF=n(Z,"LI",{});var Wze=s(cF);_Me=n(Wze,"STRONG",{});var hWt=s(_Me);atr=r(hWt,"bert"),hWt.forEach(t),ntr=r(Wze," \u2014 "),TH=n(Wze,"A",{href:!0});var uWt=s(TH);str=r(uWt,"BertForMaskedLM"),uWt.forEach(t),ltr=r(Wze," (BERT model)"),Wze.forEach(t),itr=i(Z),fF=n(Z,"LI",{});var Uze=s(fF);bMe=n(Uze,"STRONG",{});var pWt=s(bMe);dtr=r(pWt,"big_bird"),pWt.forEach(t),mtr=r(Uze," \u2014 "),MH=n(Uze,"A",{href:!0});var _Wt=s(MH);ctr=r(_Wt,"BigBirdForMaskedLM"),_Wt.forEach(t),ftr=r(Uze," (BigBird model)"),Uze.forEach(t),gtr=i(Z),gF=n(Z,"LI",{});var Hze=s(gF);vMe=n(Hze,"STRONG",{});var bWt=s(vMe);htr=r(bWt,"camembert"),bWt.forEach(t),utr=r(Hze," \u2014 "),EH=n(Hze,"A",{href:!0});var vWt=s(EH);ptr=r(vWt,"CamembertForMaskedLM"),vWt.forEach(t),_tr=r(Hze," (CamemBERT model)"),Hze.forEach(t),btr=i(Z),hF=n(Z,"LI",{});var Jze=s(hF);FMe=n(Jze,"STRONG",{});var FWt=s(FMe);vtr=r(FWt,"convbert"),FWt.forEach(t),Ftr=r(Jze," \u2014 "),CH=n(Jze,"A",{href:!0});var TWt=s(CH);Ttr=r(TWt,"ConvBertForMaskedLM"),TWt.forEach(t),Mtr=r(Jze," (ConvBERT model)"),Jze.forEach(t),Etr=i(Z),uF=n(Z,"LI",{});var Yze=s(uF);TMe=n(Yze,"STRONG",{});var MWt=s(TMe);Ctr=r(MWt,"data2vec-text"),MWt.forEach(t),wtr=r(Yze," \u2014 "),wH=n(Yze,"A",{href:!0});var EWt=s(wH);Atr=r(EWt,"Data2VecTextForMaskedLM"),EWt.forEach(t),Ltr=r(Yze," (Data2VecText model)"),Yze.forEach(t),ytr=i(Z),pF=n(Z,"LI",{});var Zze=s(pF);MMe=n(Zze,"STRONG",{});var CWt=s(MMe);xtr=r(CWt,"deberta"),CWt.forEach(t),$tr=r(Zze," \u2014 "),AH=n(Zze,"A",{href:!0});var wWt=s(AH);ktr=r(wWt,"DebertaForMaskedLM"),wWt.forEach(t),Str=r(Zze," (DeBERTa model)"),Zze.forEach(t),Rtr=i(Z),_F=n(Z,"LI",{});var Kze=s(_F);EMe=n(Kze,"STRONG",{});var AWt=s(EMe);Ptr=r(AWt,"deberta-v2"),AWt.forEach(t),Btr=r(Kze," \u2014 "),LH=n(Kze,"A",{href:!0});var LWt=s(LH);Itr=r(LWt,"DebertaV2ForMaskedLM"),LWt.forEach(t),Ntr=r(Kze," (DeBERTa-v2 model)"),Kze.forEach(t),qtr=i(Z),bF=n(Z,"LI",{});var eQe=s(bF);CMe=n(eQe,"STRONG",{});var yWt=s(CMe);jtr=r(yWt,"distilbert"),yWt.forEach(t),Dtr=r(eQe," \u2014 "),yH=n(eQe,"A",{href:!0});var xWt=s(yH);Gtr=r(xWt,"DistilBertForMaskedLM"),xWt.forEach(t),Otr=r(eQe," (DistilBERT model)"),eQe.forEach(t),Vtr=i(Z),vF=n(Z,"LI",{});var oQe=s(vF);wMe=n(oQe,"STRONG",{});var $Wt=s(wMe);Xtr=r($Wt,"electra"),$Wt.forEach(t),ztr=r(oQe," \u2014 "),xH=n(oQe,"A",{href:!0});var kWt=s(xH);Qtr=r(kWt,"ElectraForMaskedLM"),kWt.forEach(t),Wtr=r(oQe," (ELECTRA model)"),oQe.forEach(t),Utr=i(Z),FF=n(Z,"LI",{});var rQe=s(FF);AMe=n(rQe,"STRONG",{});var SWt=s(AMe);Htr=r(SWt,"ernie"),SWt.forEach(t),Jtr=r(rQe," \u2014 "),$H=n(rQe,"A",{href:!0});var RWt=s($H);Ytr=r(RWt,"ErnieForMaskedLM"),RWt.forEach(t),Ztr=r(rQe," (ERNIE model)"),rQe.forEach(t),Ktr=i(Z),TF=n(Z,"LI",{});var tQe=s(TF);LMe=n(tQe,"STRONG",{});var PWt=s(LMe);ear=r(PWt,"flaubert"),PWt.forEach(t),oar=r(tQe," \u2014 "),kH=n(tQe,"A",{href:!0});var BWt=s(kH);rar=r(BWt,"FlaubertWithLMHeadModel"),BWt.forEach(t),tar=r(tQe," (FlauBERT model)"),tQe.forEach(t),aar=i(Z),MF=n(Z,"LI",{});var aQe=s(MF);yMe=n(aQe,"STRONG",{});var IWt=s(yMe);nar=r(IWt,"fnet"),IWt.forEach(t),sar=r(aQe," \u2014 "),SH=n(aQe,"A",{href:!0});var NWt=s(SH);lar=r(NWt,"FNetForMaskedLM"),NWt.forEach(t),iar=r(aQe," (FNet model)"),aQe.forEach(t),dar=i(Z),EF=n(Z,"LI",{});var nQe=s(EF);xMe=n(nQe,"STRONG",{});var qWt=s(xMe);mar=r(qWt,"funnel"),qWt.forEach(t),car=r(nQe," \u2014 "),RH=n(nQe,"A",{href:!0});var jWt=s(RH);far=r(jWt,"FunnelForMaskedLM"),jWt.forEach(t),gar=r(nQe," (Funnel Transformer model)"),nQe.forEach(t),har=i(Z),CF=n(Z,"LI",{});var sQe=s(CF);$Me=n(sQe,"STRONG",{});var DWt=s($Me);uar=r(DWt,"ibert"),DWt.forEach(t),par=r(sQe," \u2014 "),PH=n(sQe,"A",{href:!0});var GWt=s(PH);_ar=r(GWt,"IBertForMaskedLM"),GWt.forEach(t),bar=r(sQe," (I-BERT model)"),sQe.forEach(t),Far=i(Z),wF=n(Z,"LI",{});var lQe=s(wF);kMe=n(lQe,"STRONG",{});var OWt=s(kMe);Tar=r(OWt,"layoutlm"),OWt.forEach(t),Mar=r(lQe," \u2014 "),BH=n(lQe,"A",{href:!0});var VWt=s(BH);Ear=r(VWt,"LayoutLMForMaskedLM"),VWt.forEach(t),Car=r(lQe," (LayoutLM model)"),lQe.forEach(t),war=i(Z),AF=n(Z,"LI",{});var iQe=s(AF);SMe=n(iQe,"STRONG",{});var XWt=s(SMe);Aar=r(XWt,"longformer"),XWt.forEach(t),Lar=r(iQe," \u2014 "),IH=n(iQe,"A",{href:!0});var zWt=s(IH);yar=r(zWt,"LongformerForMaskedLM"),zWt.forEach(t),xar=r(iQe," (Longformer model)"),iQe.forEach(t),$ar=i(Z),LF=n(Z,"LI",{});var dQe=s(LF);RMe=n(dQe,"STRONG",{});var QWt=s(RMe);kar=r(QWt,"luke"),QWt.forEach(t),Sar=r(dQe," \u2014 "),NH=n(dQe,"A",{href:!0});var WWt=s(NH);Rar=r(WWt,"LukeForMaskedLM"),WWt.forEach(t),Par=r(dQe," (LUKE model)"),dQe.forEach(t),Bar=i(Z),yF=n(Z,"LI",{});var mQe=s(yF);PMe=n(mQe,"STRONG",{});var UWt=s(PMe);Iar=r(UWt,"mbart"),UWt.forEach(t),Nar=r(mQe," \u2014 "),qH=n(mQe,"A",{href:!0});var HWt=s(qH);qar=r(HWt,"MBartForConditionalGeneration"),HWt.forEach(t),jar=r(mQe," (mBART model)"),mQe.forEach(t),Dar=i(Z),xF=n(Z,"LI",{});var cQe=s(xF);BMe=n(cQe,"STRONG",{});var JWt=s(BMe);Gar=r(JWt,"megatron-bert"),JWt.forEach(t),Oar=r(cQe," \u2014 "),jH=n(cQe,"A",{href:!0});var YWt=s(jH);Var=r(YWt,"MegatronBertForMaskedLM"),YWt.forEach(t),Xar=r(cQe," (Megatron-BERT model)"),cQe.forEach(t),zar=i(Z),$F=n(Z,"LI",{});var fQe=s($F);IMe=n(fQe,"STRONG",{});var ZWt=s(IMe);Qar=r(ZWt,"mobilebert"),ZWt.forEach(t),War=r(fQe," \u2014 "),DH=n(fQe,"A",{href:!0});var KWt=s(DH);Uar=r(KWt,"MobileBertForMaskedLM"),KWt.forEach(t),Har=r(fQe," (MobileBERT model)"),fQe.forEach(t),Jar=i(Z),kF=n(Z,"LI",{});var gQe=s(kF);NMe=n(gQe,"STRONG",{});var eUt=s(NMe);Yar=r(eUt,"mpnet"),eUt.forEach(t),Zar=r(gQe," \u2014 "),GH=n(gQe,"A",{href:!0});var oUt=s(GH);Kar=r(oUt,"MPNetForMaskedLM"),oUt.forEach(t),enr=r(gQe," (MPNet model)"),gQe.forEach(t),onr=i(Z),SF=n(Z,"LI",{});var hQe=s(SF);qMe=n(hQe,"STRONG",{});var rUt=s(qMe);rnr=r(rUt,"mvp"),rUt.forEach(t),tnr=r(hQe," \u2014 "),OH=n(hQe,"A",{href:!0});var tUt=s(OH);anr=r(tUt,"MvpForConditionalGeneration"),tUt.forEach(t),nnr=r(hQe," (MVP model)"),hQe.forEach(t),snr=i(Z),RF=n(Z,"LI",{});var uQe=s(RF);jMe=n(uQe,"STRONG",{});var aUt=s(jMe);lnr=r(aUt,"nezha"),aUt.forEach(t),inr=r(uQe," \u2014 "),VH=n(uQe,"A",{href:!0});var nUt=s(VH);dnr=r(nUt,"NezhaForMaskedLM"),nUt.forEach(t),mnr=r(uQe," (Nezha model)"),uQe.forEach(t),cnr=i(Z),PF=n(Z,"LI",{});var pQe=s(PF);DMe=n(pQe,"STRONG",{});var sUt=s(DMe);fnr=r(sUt,"nystromformer"),sUt.forEach(t),gnr=r(pQe," \u2014 "),XH=n(pQe,"A",{href:!0});var lUt=s(XH);hnr=r(lUt,"NystromformerForMaskedLM"),lUt.forEach(t),unr=r(pQe," (Nystr\xF6mformer model)"),pQe.forEach(t),pnr=i(Z),BF=n(Z,"LI",{});var _Qe=s(BF);GMe=n(_Qe,"STRONG",{});var iUt=s(GMe);_nr=r(iUt,"perceiver"),iUt.forEach(t),bnr=r(_Qe," \u2014 "),zH=n(_Qe,"A",{href:!0});var dUt=s(zH);vnr=r(dUt,"PerceiverForMaskedLM"),dUt.forEach(t),Fnr=r(_Qe," (Perceiver model)"),_Qe.forEach(t),Tnr=i(Z),IF=n(Z,"LI",{});var bQe=s(IF);OMe=n(bQe,"STRONG",{});var mUt=s(OMe);Mnr=r(mUt,"qdqbert"),mUt.forEach(t),Enr=r(bQe," \u2014 "),QH=n(bQe,"A",{href:!0});var cUt=s(QH);Cnr=r(cUt,"QDQBertForMaskedLM"),cUt.forEach(t),wnr=r(bQe," (QDQBert model)"),bQe.forEach(t),Anr=i(Z),NF=n(Z,"LI",{});var vQe=s(NF);VMe=n(vQe,"STRONG",{});var fUt=s(VMe);Lnr=r(fUt,"reformer"),fUt.forEach(t),ynr=r(vQe," \u2014 "),WH=n(vQe,"A",{href:!0});var gUt=s(WH);xnr=r(gUt,"ReformerForMaskedLM"),gUt.forEach(t),$nr=r(vQe," (Reformer model)"),vQe.forEach(t),knr=i(Z),qF=n(Z,"LI",{});var FQe=s(qF);XMe=n(FQe,"STRONG",{});var hUt=s(XMe);Snr=r(hUt,"rembert"),hUt.forEach(t),Rnr=r(FQe," \u2014 "),UH=n(FQe,"A",{href:!0});var uUt=s(UH);Pnr=r(uUt,"RemBertForMaskedLM"),uUt.forEach(t),Bnr=r(FQe," (RemBERT model)"),FQe.forEach(t),Inr=i(Z),jF=n(Z,"LI",{});var TQe=s(jF);zMe=n(TQe,"STRONG",{});var pUt=s(zMe);Nnr=r(pUt,"roberta"),pUt.forEach(t),qnr=r(TQe," \u2014 "),HH=n(TQe,"A",{href:!0});var _Ut=s(HH);jnr=r(_Ut,"RobertaForMaskedLM"),_Ut.forEach(t),Dnr=r(TQe," (RoBERTa model)"),TQe.forEach(t),Gnr=i(Z),DF=n(Z,"LI",{});var MQe=s(DF);QMe=n(MQe,"STRONG",{});var bUt=s(QMe);Onr=r(bUt,"roc_bert"),bUt.forEach(t),Vnr=r(MQe," \u2014 "),JH=n(MQe,"A",{href:!0});var vUt=s(JH);Xnr=r(vUt,"RoCBertForMaskedLM"),vUt.forEach(t),znr=r(MQe," (RoCBert model)"),MQe.forEach(t),Qnr=i(Z),GF=n(Z,"LI",{});var EQe=s(GF);WMe=n(EQe,"STRONG",{});var FUt=s(WMe);Wnr=r(FUt,"roformer"),FUt.forEach(t),Unr=r(EQe," \u2014 "),YH=n(EQe,"A",{href:!0});var TUt=s(YH);Hnr=r(TUt,"RoFormerForMaskedLM"),TUt.forEach(t),Jnr=r(EQe," (RoFormer model)"),EQe.forEach(t),Ynr=i(Z),OF=n(Z,"LI",{});var CQe=s(OF);UMe=n(CQe,"STRONG",{});var MUt=s(UMe);Znr=r(MUt,"squeezebert"),MUt.forEach(t),Knr=r(CQe," \u2014 "),ZH=n(CQe,"A",{href:!0});var EUt=s(ZH);esr=r(EUt,"SqueezeBertForMaskedLM"),EUt.forEach(t),osr=r(CQe," (SqueezeBERT model)"),CQe.forEach(t),rsr=i(Z),VF=n(Z,"LI",{});var wQe=s(VF);HMe=n(wQe,"STRONG",{});var CUt=s(HMe);tsr=r(CUt,"tapas"),CUt.forEach(t),asr=r(wQe," \u2014 "),KH=n(wQe,"A",{href:!0});var wUt=s(KH);nsr=r(wUt,"TapasForMaskedLM"),wUt.forEach(t),ssr=r(wQe," (TAPAS model)"),wQe.forEach(t),lsr=i(Z),XF=n(Z,"LI",{});var AQe=s(XF);JMe=n(AQe,"STRONG",{});var AUt=s(JMe);isr=r(AUt,"wav2vec2"),AUt.forEach(t),dsr=r(AQe," \u2014 "),YMe=n(AQe,"CODE",{});var LUt=s(YMe);msr=r(LUt,"Wav2Vec2ForMaskedLM"),LUt.forEach(t),csr=r(AQe," (Wav2Vec2 model)"),AQe.forEach(t),fsr=i(Z),zF=n(Z,"LI",{});var LQe=s(zF);ZMe=n(LQe,"STRONG",{});var yUt=s(ZMe);gsr=r(yUt,"xlm"),yUt.forEach(t),hsr=r(LQe," \u2014 "),eJ=n(LQe,"A",{href:!0});var xUt=s(eJ);usr=r(xUt,"XLMWithLMHeadModel"),xUt.forEach(t),psr=r(LQe," (XLM model)"),LQe.forEach(t),_sr=i(Z),QF=n(Z,"LI",{});var yQe=s(QF);KMe=n(yQe,"STRONG",{});var $Ut=s(KMe);bsr=r($Ut,"xlm-roberta"),$Ut.forEach(t),vsr=r(yQe," \u2014 "),oJ=n(yQe,"A",{href:!0});var kUt=s(oJ);Fsr=r(kUt,"XLMRobertaForMaskedLM"),kUt.forEach(t),Tsr=r(yQe," (XLM-RoBERTa model)"),yQe.forEach(t),Msr=i(Z),WF=n(Z,"LI",{});var xQe=s(WF);eEe=n(xQe,"STRONG",{});var SUt=s(eEe);Esr=r(SUt,"xlm-roberta-xl"),SUt.forEach(t),Csr=r(xQe," \u2014 "),rJ=n(xQe,"A",{href:!0});var RUt=s(rJ);wsr=r(RUt,"XLMRobertaXLForMaskedLM"),RUt.forEach(t),Asr=r(xQe," (XLM-RoBERTa-XL model)"),xQe.forEach(t),Lsr=i(Z),UF=n(Z,"LI",{});var $Qe=s(UF);oEe=n($Qe,"STRONG",{});var PUt=s(oEe);ysr=r(PUt,"yoso"),PUt.forEach(t),xsr=r($Qe," \u2014 "),tJ=n($Qe,"A",{href:!0});var BUt=s(tJ);$sr=r(BUt,"YosoForMaskedLM"),BUt.forEach(t),ksr=r($Qe," (YOSO model)"),$Qe.forEach(t),Z.forEach(t),Ssr=i(ka),HF=n(ka,"P",{});var kQe=s(HF);Rsr=r(kQe,"The model is set in evaluation mode by default using "),rEe=n(kQe,"CODE",{});var IUt=s(rEe);Psr=r(IUt,"model.eval()"),IUt.forEach(t),Bsr=r(kQe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),tEe=n(kQe,"CODE",{});var NUt=s(tEe);Isr=r(NUt,"model.train()"),NUt.forEach(t),kQe.forEach(t),Nsr=i(ka),T(JF.$$.fragment,ka),ka.forEach(t),Vl.forEach(t),Yao=i(c),Ud=n(c,"H2",{class:!0});var plo=s(Ud);YF=n(plo,"A",{id:!0,class:!0,href:!0});var qUt=s(YF);aEe=n(qUt,"SPAN",{});var jUt=s(aEe);T(Tk.$$.fragment,jUt),jUt.forEach(t),qUt.forEach(t),qsr=i(plo),nEe=n(plo,"SPAN",{});var DUt=s(nEe);jsr=r(DUt,"AutoModelForSeq2SeqLM"),DUt.forEach(t),plo.forEach(t),Zao=i(c),Go=n(c,"DIV",{class:!0});var Xl=s(Go);T(Mk.$$.fragment,Xl),Dsr=i(Xl),Hd=n(Xl,"P",{});var Xme=s(Hd);Gsr=r(Xme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),aJ=n(Xme,"A",{href:!0});var GUt=s(aJ);Osr=r(GUt,"from_pretrained()"),GUt.forEach(t),Vsr=r(Xme," class method or the "),nJ=n(Xme,"A",{href:!0});var OUt=s(nJ);Xsr=r(OUt,"from_config()"),OUt.forEach(t),zsr=r(Xme,` class
method.`),Xme.forEach(t),Qsr=i(Xl),Ek=n(Xl,"P",{});var _lo=s(Ek);Wsr=r(_lo,"This class cannot be instantiated directly using "),sEe=n(_lo,"CODE",{});var VUt=s(sEe);Usr=r(VUt,"__init__()"),VUt.forEach(t),Hsr=r(_lo," (throws an error)."),_lo.forEach(t),Jsr=i(Xl),Lt=n(Xl,"DIV",{class:!0});var C9=s(Lt);T(Ck.$$.fragment,C9),Ysr=i(C9),lEe=n(C9,"P",{});var XUt=s(lEe);Zsr=r(XUt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),XUt.forEach(t),Ksr=i(C9),Jd=n(C9,"P",{});var zme=s(Jd);elr=r(zme,`Note:
Loading a model from its configuration file does `),iEe=n(zme,"STRONG",{});var zUt=s(iEe);olr=r(zUt,"not"),zUt.forEach(t),rlr=r(zme,` load the model weights. It only affects the
model\u2019s configuration. Use `),sJ=n(zme,"A",{href:!0});var QUt=s(sJ);tlr=r(QUt,"from_pretrained()"),QUt.forEach(t),alr=r(zme," to load the model weights."),zme.forEach(t),nlr=i(C9),T(ZF.$$.fragment,C9),C9.forEach(t),slr=i(Xl),ao=n(Xl,"DIV",{class:!0});var Sa=s(ao);T(wk.$$.fragment,Sa),llr=i(Sa),dEe=n(Sa,"P",{});var WUt=s(dEe);ilr=r(WUt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),WUt.forEach(t),dlr=i(Sa),cn=n(Sa,"P",{});var w9=s(cn);mlr=r(w9,"The model class to instantiate is selected based on the "),mEe=n(w9,"CODE",{});var UUt=s(mEe);clr=r(UUt,"model_type"),UUt.forEach(t),flr=r(w9,` property of the config object (either
passed as an argument or loaded from `),cEe=n(w9,"CODE",{});var HUt=s(cEe);glr=r(HUt,"pretrained_model_name_or_path"),HUt.forEach(t),hlr=r(w9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fEe=n(w9,"CODE",{});var JUt=s(fEe);ulr=r(JUt,"pretrained_model_name_or_path"),JUt.forEach(t),plr=r(w9,":"),w9.forEach(t),_lr=i(Sa),he=n(Sa,"UL",{});var _e=s(he);KF=n(_e,"LI",{});var SQe=s(KF);gEe=n(SQe,"STRONG",{});var YUt=s(gEe);blr=r(YUt,"bart"),YUt.forEach(t),vlr=r(SQe," \u2014 "),lJ=n(SQe,"A",{href:!0});var ZUt=s(lJ);Flr=r(ZUt,"BartForConditionalGeneration"),ZUt.forEach(t),Tlr=r(SQe," (BART model)"),SQe.forEach(t),Mlr=i(_e),eT=n(_e,"LI",{});var RQe=s(eT);hEe=n(RQe,"STRONG",{});var KUt=s(hEe);Elr=r(KUt,"bigbird_pegasus"),KUt.forEach(t),Clr=r(RQe," \u2014 "),iJ=n(RQe,"A",{href:!0});var eHt=s(iJ);wlr=r(eHt,"BigBirdPegasusForConditionalGeneration"),eHt.forEach(t),Alr=r(RQe," (BigBird-Pegasus model)"),RQe.forEach(t),Llr=i(_e),oT=n(_e,"LI",{});var PQe=s(oT);uEe=n(PQe,"STRONG",{});var oHt=s(uEe);ylr=r(oHt,"blenderbot"),oHt.forEach(t),xlr=r(PQe," \u2014 "),dJ=n(PQe,"A",{href:!0});var rHt=s(dJ);$lr=r(rHt,"BlenderbotForConditionalGeneration"),rHt.forEach(t),klr=r(PQe," (Blenderbot model)"),PQe.forEach(t),Slr=i(_e),rT=n(_e,"LI",{});var BQe=s(rT);pEe=n(BQe,"STRONG",{});var tHt=s(pEe);Rlr=r(tHt,"blenderbot-small"),tHt.forEach(t),Plr=r(BQe," \u2014 "),mJ=n(BQe,"A",{href:!0});var aHt=s(mJ);Blr=r(aHt,"BlenderbotSmallForConditionalGeneration"),aHt.forEach(t),Ilr=r(BQe," (BlenderbotSmall model)"),BQe.forEach(t),Nlr=i(_e),tT=n(_e,"LI",{});var IQe=s(tT);_Ee=n(IQe,"STRONG",{});var nHt=s(_Ee);qlr=r(nHt,"encoder-decoder"),nHt.forEach(t),jlr=r(IQe," \u2014 "),cJ=n(IQe,"A",{href:!0});var sHt=s(cJ);Dlr=r(sHt,"EncoderDecoderModel"),sHt.forEach(t),Glr=r(IQe," (Encoder decoder model)"),IQe.forEach(t),Olr=i(_e),aT=n(_e,"LI",{});var NQe=s(aT);bEe=n(NQe,"STRONG",{});var lHt=s(bEe);Vlr=r(lHt,"fsmt"),lHt.forEach(t),Xlr=r(NQe," \u2014 "),fJ=n(NQe,"A",{href:!0});var iHt=s(fJ);zlr=r(iHt,"FSMTForConditionalGeneration"),iHt.forEach(t),Qlr=r(NQe," (FairSeq Machine-Translation model)"),NQe.forEach(t),Wlr=i(_e),nT=n(_e,"LI",{});var qQe=s(nT);vEe=n(qQe,"STRONG",{});var dHt=s(vEe);Ulr=r(dHt,"led"),dHt.forEach(t),Hlr=r(qQe," \u2014 "),gJ=n(qQe,"A",{href:!0});var mHt=s(gJ);Jlr=r(mHt,"LEDForConditionalGeneration"),mHt.forEach(t),Ylr=r(qQe," (LED model)"),qQe.forEach(t),Zlr=i(_e),sT=n(_e,"LI",{});var jQe=s(sT);FEe=n(jQe,"STRONG",{});var cHt=s(FEe);Klr=r(cHt,"longt5"),cHt.forEach(t),eir=r(jQe," \u2014 "),hJ=n(jQe,"A",{href:!0});var fHt=s(hJ);oir=r(fHt,"LongT5ForConditionalGeneration"),fHt.forEach(t),rir=r(jQe," (LongT5 model)"),jQe.forEach(t),tir=i(_e),lT=n(_e,"LI",{});var DQe=s(lT);TEe=n(DQe,"STRONG",{});var gHt=s(TEe);air=r(gHt,"m2m_100"),gHt.forEach(t),nir=r(DQe," \u2014 "),uJ=n(DQe,"A",{href:!0});var hHt=s(uJ);sir=r(hHt,"M2M100ForConditionalGeneration"),hHt.forEach(t),lir=r(DQe," (M2M100 model)"),DQe.forEach(t),iir=i(_e),iT=n(_e,"LI",{});var GQe=s(iT);MEe=n(GQe,"STRONG",{});var uHt=s(MEe);dir=r(uHt,"marian"),uHt.forEach(t),mir=r(GQe," \u2014 "),pJ=n(GQe,"A",{href:!0});var pHt=s(pJ);cir=r(pHt,"MarianMTModel"),pHt.forEach(t),fir=r(GQe," (Marian model)"),GQe.forEach(t),gir=i(_e),dT=n(_e,"LI",{});var OQe=s(dT);EEe=n(OQe,"STRONG",{});var _Ht=s(EEe);hir=r(_Ht,"mbart"),_Ht.forEach(t),uir=r(OQe," \u2014 "),_J=n(OQe,"A",{href:!0});var bHt=s(_J);pir=r(bHt,"MBartForConditionalGeneration"),bHt.forEach(t),_ir=r(OQe," (mBART model)"),OQe.forEach(t),bir=i(_e),mT=n(_e,"LI",{});var VQe=s(mT);CEe=n(VQe,"STRONG",{});var vHt=s(CEe);vir=r(vHt,"mt5"),vHt.forEach(t),Fir=r(VQe," \u2014 "),bJ=n(VQe,"A",{href:!0});var FHt=s(bJ);Tir=r(FHt,"MT5ForConditionalGeneration"),FHt.forEach(t),Mir=r(VQe," (MT5 model)"),VQe.forEach(t),Eir=i(_e),cT=n(_e,"LI",{});var XQe=s(cT);wEe=n(XQe,"STRONG",{});var THt=s(wEe);Cir=r(THt,"mvp"),THt.forEach(t),wir=r(XQe," \u2014 "),vJ=n(XQe,"A",{href:!0});var MHt=s(vJ);Air=r(MHt,"MvpForConditionalGeneration"),MHt.forEach(t),Lir=r(XQe," (MVP model)"),XQe.forEach(t),yir=i(_e),fT=n(_e,"LI",{});var zQe=s(fT);AEe=n(zQe,"STRONG",{});var EHt=s(AEe);xir=r(EHt,"nllb"),EHt.forEach(t),$ir=r(zQe," \u2014 "),FJ=n(zQe,"A",{href:!0});var CHt=s(FJ);kir=r(CHt,"M2M100ForConditionalGeneration"),CHt.forEach(t),Sir=r(zQe," (NLLB model)"),zQe.forEach(t),Rir=i(_e),gT=n(_e,"LI",{});var QQe=s(gT);LEe=n(QQe,"STRONG",{});var wHt=s(LEe);Pir=r(wHt,"pegasus"),wHt.forEach(t),Bir=r(QQe," \u2014 "),TJ=n(QQe,"A",{href:!0});var AHt=s(TJ);Iir=r(AHt,"PegasusForConditionalGeneration"),AHt.forEach(t),Nir=r(QQe," (Pegasus model)"),QQe.forEach(t),qir=i(_e),hT=n(_e,"LI",{});var WQe=s(hT);yEe=n(WQe,"STRONG",{});var LHt=s(yEe);jir=r(LHt,"pegasus_x"),LHt.forEach(t),Dir=r(WQe," \u2014 "),MJ=n(WQe,"A",{href:!0});var yHt=s(MJ);Gir=r(yHt,"PegasusXForConditionalGeneration"),yHt.forEach(t),Oir=r(WQe," (PEGASUS-X model)"),WQe.forEach(t),Vir=i(_e),uT=n(_e,"LI",{});var UQe=s(uT);xEe=n(UQe,"STRONG",{});var xHt=s(xEe);Xir=r(xHt,"plbart"),xHt.forEach(t),zir=r(UQe," \u2014 "),EJ=n(UQe,"A",{href:!0});var $Ht=s(EJ);Qir=r($Ht,"PLBartForConditionalGeneration"),$Ht.forEach(t),Wir=r(UQe," (PLBart model)"),UQe.forEach(t),Uir=i(_e),pT=n(_e,"LI",{});var HQe=s(pT);$Ee=n(HQe,"STRONG",{});var kHt=s($Ee);Hir=r(kHt,"prophetnet"),kHt.forEach(t),Jir=r(HQe," \u2014 "),CJ=n(HQe,"A",{href:!0});var SHt=s(CJ);Yir=r(SHt,"ProphetNetForConditionalGeneration"),SHt.forEach(t),Zir=r(HQe," (ProphetNet model)"),HQe.forEach(t),Kir=i(_e),_T=n(_e,"LI",{});var JQe=s(_T);kEe=n(JQe,"STRONG",{});var RHt=s(kEe);edr=r(RHt,"t5"),RHt.forEach(t),odr=r(JQe," \u2014 "),wJ=n(JQe,"A",{href:!0});var PHt=s(wJ);rdr=r(PHt,"T5ForConditionalGeneration"),PHt.forEach(t),tdr=r(JQe," (T5 model)"),JQe.forEach(t),adr=i(_e),bT=n(_e,"LI",{});var YQe=s(bT);SEe=n(YQe,"STRONG",{});var BHt=s(SEe);ndr=r(BHt,"xlm-prophetnet"),BHt.forEach(t),sdr=r(YQe," \u2014 "),AJ=n(YQe,"A",{href:!0});var IHt=s(AJ);ldr=r(IHt,"XLMProphetNetForConditionalGeneration"),IHt.forEach(t),idr=r(YQe," (XLM-ProphetNet model)"),YQe.forEach(t),_e.forEach(t),ddr=i(Sa),vT=n(Sa,"P",{});var ZQe=s(vT);mdr=r(ZQe,"The model is set in evaluation mode by default using "),REe=n(ZQe,"CODE",{});var NHt=s(REe);cdr=r(NHt,"model.eval()"),NHt.forEach(t),fdr=r(ZQe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),PEe=n(ZQe,"CODE",{});var qHt=s(PEe);gdr=r(qHt,"model.train()"),qHt.forEach(t),ZQe.forEach(t),hdr=i(Sa),T(FT.$$.fragment,Sa),Sa.forEach(t),Xl.forEach(t),Kao=i(c),Yd=n(c,"H2",{class:!0});var blo=s(Yd);TT=n(blo,"A",{id:!0,class:!0,href:!0});var jHt=s(TT);BEe=n(jHt,"SPAN",{});var DHt=s(BEe);T(Ak.$$.fragment,DHt),DHt.forEach(t),jHt.forEach(t),udr=i(blo),IEe=n(blo,"SPAN",{});var GHt=s(IEe);pdr=r(GHt,"AutoModelForSequenceClassification"),GHt.forEach(t),blo.forEach(t),eno=i(c),Oo=n(c,"DIV",{class:!0});var zl=s(Oo);T(Lk.$$.fragment,zl),_dr=i(zl),Zd=n(zl,"P",{});var Qme=s(Zd);bdr=r(Qme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),LJ=n(Qme,"A",{href:!0});var OHt=s(LJ);vdr=r(OHt,"from_pretrained()"),OHt.forEach(t),Fdr=r(Qme," class method or the "),yJ=n(Qme,"A",{href:!0});var VHt=s(yJ);Tdr=r(VHt,"from_config()"),VHt.forEach(t),Mdr=r(Qme,` class
method.`),Qme.forEach(t),Edr=i(zl),yk=n(zl,"P",{});var vlo=s(yk);Cdr=r(vlo,"This class cannot be instantiated directly using "),NEe=n(vlo,"CODE",{});var XHt=s(NEe);wdr=r(XHt,"__init__()"),XHt.forEach(t),Adr=r(vlo," (throws an error)."),vlo.forEach(t),Ldr=i(zl),yt=n(zl,"DIV",{class:!0});var A9=s(yt);T(xk.$$.fragment,A9),ydr=i(A9),qEe=n(A9,"P",{});var zHt=s(qEe);xdr=r(zHt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),zHt.forEach(t),$dr=i(A9),Kd=n(A9,"P",{});var Wme=s(Kd);kdr=r(Wme,`Note:
Loading a model from its configuration file does `),jEe=n(Wme,"STRONG",{});var QHt=s(jEe);Sdr=r(QHt,"not"),QHt.forEach(t),Rdr=r(Wme,` load the model weights. It only affects the
model\u2019s configuration. Use `),xJ=n(Wme,"A",{href:!0});var WHt=s(xJ);Pdr=r(WHt,"from_pretrained()"),WHt.forEach(t),Bdr=r(Wme," to load the model weights."),Wme.forEach(t),Idr=i(A9),T(MT.$$.fragment,A9),A9.forEach(t),Ndr=i(zl),no=n(zl,"DIV",{class:!0});var Ra=s(no);T($k.$$.fragment,Ra),qdr=i(Ra),DEe=n(Ra,"P",{});var UHt=s(DEe);jdr=r(UHt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),UHt.forEach(t),Ddr=i(Ra),fn=n(Ra,"P",{});var L9=s(fn);Gdr=r(L9,"The model class to instantiate is selected based on the "),GEe=n(L9,"CODE",{});var HHt=s(GEe);Odr=r(HHt,"model_type"),HHt.forEach(t),Vdr=r(L9,` property of the config object (either
passed as an argument or loaded from `),OEe=n(L9,"CODE",{});var JHt=s(OEe);Xdr=r(JHt,"pretrained_model_name_or_path"),JHt.forEach(t),zdr=r(L9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),VEe=n(L9,"CODE",{});var YHt=s(VEe);Qdr=r(YHt,"pretrained_model_name_or_path"),YHt.forEach(t),Wdr=r(L9,":"),L9.forEach(t),Udr=i(Ra),I=n(Ra,"UL",{});var D=s(I);ET=n(D,"LI",{});var KQe=s(ET);XEe=n(KQe,"STRONG",{});var ZHt=s(XEe);Hdr=r(ZHt,"albert"),ZHt.forEach(t),Jdr=r(KQe," \u2014 "),$J=n(KQe,"A",{href:!0});var KHt=s($J);Ydr=r(KHt,"AlbertForSequenceClassification"),KHt.forEach(t),Zdr=r(KQe," (ALBERT model)"),KQe.forEach(t),Kdr=i(D),CT=n(D,"LI",{});var eWe=s(CT);zEe=n(eWe,"STRONG",{});var eJt=s(zEe);emr=r(eJt,"bart"),eJt.forEach(t),omr=r(eWe," \u2014 "),kJ=n(eWe,"A",{href:!0});var oJt=s(kJ);rmr=r(oJt,"BartForSequenceClassification"),oJt.forEach(t),tmr=r(eWe," (BART model)"),eWe.forEach(t),amr=i(D),wT=n(D,"LI",{});var oWe=s(wT);QEe=n(oWe,"STRONG",{});var rJt=s(QEe);nmr=r(rJt,"bert"),rJt.forEach(t),smr=r(oWe," \u2014 "),SJ=n(oWe,"A",{href:!0});var tJt=s(SJ);lmr=r(tJt,"BertForSequenceClassification"),tJt.forEach(t),imr=r(oWe," (BERT model)"),oWe.forEach(t),dmr=i(D),AT=n(D,"LI",{});var rWe=s(AT);WEe=n(rWe,"STRONG",{});var aJt=s(WEe);mmr=r(aJt,"big_bird"),aJt.forEach(t),cmr=r(rWe," \u2014 "),RJ=n(rWe,"A",{href:!0});var nJt=s(RJ);fmr=r(nJt,"BigBirdForSequenceClassification"),nJt.forEach(t),gmr=r(rWe," (BigBird model)"),rWe.forEach(t),hmr=i(D),LT=n(D,"LI",{});var tWe=s(LT);UEe=n(tWe,"STRONG",{});var sJt=s(UEe);umr=r(sJt,"bigbird_pegasus"),sJt.forEach(t),pmr=r(tWe," \u2014 "),PJ=n(tWe,"A",{href:!0});var lJt=s(PJ);_mr=r(lJt,"BigBirdPegasusForSequenceClassification"),lJt.forEach(t),bmr=r(tWe," (BigBird-Pegasus model)"),tWe.forEach(t),vmr=i(D),yT=n(D,"LI",{});var aWe=s(yT);HEe=n(aWe,"STRONG",{});var iJt=s(HEe);Fmr=r(iJt,"bloom"),iJt.forEach(t),Tmr=r(aWe," \u2014 "),BJ=n(aWe,"A",{href:!0});var dJt=s(BJ);Mmr=r(dJt,"BloomForSequenceClassification"),dJt.forEach(t),Emr=r(aWe," (BLOOM model)"),aWe.forEach(t),Cmr=i(D),xT=n(D,"LI",{});var nWe=s(xT);JEe=n(nWe,"STRONG",{});var mJt=s(JEe);wmr=r(mJt,"camembert"),mJt.forEach(t),Amr=r(nWe," \u2014 "),IJ=n(nWe,"A",{href:!0});var cJt=s(IJ);Lmr=r(cJt,"CamembertForSequenceClassification"),cJt.forEach(t),ymr=r(nWe," (CamemBERT model)"),nWe.forEach(t),xmr=i(D),$T=n(D,"LI",{});var sWe=s($T);YEe=n(sWe,"STRONG",{});var fJt=s(YEe);$mr=r(fJt,"canine"),fJt.forEach(t),kmr=r(sWe," \u2014 "),NJ=n(sWe,"A",{href:!0});var gJt=s(NJ);Smr=r(gJt,"CanineForSequenceClassification"),gJt.forEach(t),Rmr=r(sWe," (CANINE model)"),sWe.forEach(t),Pmr=i(D),kT=n(D,"LI",{});var lWe=s(kT);ZEe=n(lWe,"STRONG",{});var hJt=s(ZEe);Bmr=r(hJt,"convbert"),hJt.forEach(t),Imr=r(lWe," \u2014 "),qJ=n(lWe,"A",{href:!0});var uJt=s(qJ);Nmr=r(uJt,"ConvBertForSequenceClassification"),uJt.forEach(t),qmr=r(lWe," (ConvBERT model)"),lWe.forEach(t),jmr=i(D),ST=n(D,"LI",{});var iWe=s(ST);KEe=n(iWe,"STRONG",{});var pJt=s(KEe);Dmr=r(pJt,"ctrl"),pJt.forEach(t),Gmr=r(iWe," \u2014 "),jJ=n(iWe,"A",{href:!0});var _Jt=s(jJ);Omr=r(_Jt,"CTRLForSequenceClassification"),_Jt.forEach(t),Vmr=r(iWe," (CTRL model)"),iWe.forEach(t),Xmr=i(D),RT=n(D,"LI",{});var dWe=s(RT);e4e=n(dWe,"STRONG",{});var bJt=s(e4e);zmr=r(bJt,"data2vec-text"),bJt.forEach(t),Qmr=r(dWe," \u2014 "),DJ=n(dWe,"A",{href:!0});var vJt=s(DJ);Wmr=r(vJt,"Data2VecTextForSequenceClassification"),vJt.forEach(t),Umr=r(dWe," (Data2VecText model)"),dWe.forEach(t),Hmr=i(D),PT=n(D,"LI",{});var mWe=s(PT);o4e=n(mWe,"STRONG",{});var FJt=s(o4e);Jmr=r(FJt,"deberta"),FJt.forEach(t),Ymr=r(mWe," \u2014 "),GJ=n(mWe,"A",{href:!0});var TJt=s(GJ);Zmr=r(TJt,"DebertaForSequenceClassification"),TJt.forEach(t),Kmr=r(mWe," (DeBERTa model)"),mWe.forEach(t),ecr=i(D),BT=n(D,"LI",{});var cWe=s(BT);r4e=n(cWe,"STRONG",{});var MJt=s(r4e);ocr=r(MJt,"deberta-v2"),MJt.forEach(t),rcr=r(cWe," \u2014 "),OJ=n(cWe,"A",{href:!0});var EJt=s(OJ);tcr=r(EJt,"DebertaV2ForSequenceClassification"),EJt.forEach(t),acr=r(cWe," (DeBERTa-v2 model)"),cWe.forEach(t),ncr=i(D),IT=n(D,"LI",{});var fWe=s(IT);t4e=n(fWe,"STRONG",{});var CJt=s(t4e);scr=r(CJt,"distilbert"),CJt.forEach(t),lcr=r(fWe," \u2014 "),VJ=n(fWe,"A",{href:!0});var wJt=s(VJ);icr=r(wJt,"DistilBertForSequenceClassification"),wJt.forEach(t),dcr=r(fWe," (DistilBERT model)"),fWe.forEach(t),mcr=i(D),NT=n(D,"LI",{});var gWe=s(NT);a4e=n(gWe,"STRONG",{});var AJt=s(a4e);ccr=r(AJt,"electra"),AJt.forEach(t),fcr=r(gWe," \u2014 "),XJ=n(gWe,"A",{href:!0});var LJt=s(XJ);gcr=r(LJt,"ElectraForSequenceClassification"),LJt.forEach(t),hcr=r(gWe," (ELECTRA model)"),gWe.forEach(t),ucr=i(D),qT=n(D,"LI",{});var hWe=s(qT);n4e=n(hWe,"STRONG",{});var yJt=s(n4e);pcr=r(yJt,"ernie"),yJt.forEach(t),_cr=r(hWe," \u2014 "),zJ=n(hWe,"A",{href:!0});var xJt=s(zJ);bcr=r(xJt,"ErnieForSequenceClassification"),xJt.forEach(t),vcr=r(hWe," (ERNIE model)"),hWe.forEach(t),Fcr=i(D),jT=n(D,"LI",{});var uWe=s(jT);s4e=n(uWe,"STRONG",{});var $Jt=s(s4e);Tcr=r($Jt,"esm"),$Jt.forEach(t),Mcr=r(uWe," \u2014 "),QJ=n(uWe,"A",{href:!0});var kJt=s(QJ);Ecr=r(kJt,"EsmForSequenceClassification"),kJt.forEach(t),Ccr=r(uWe," (ESM model)"),uWe.forEach(t),wcr=i(D),DT=n(D,"LI",{});var pWe=s(DT);l4e=n(pWe,"STRONG",{});var SJt=s(l4e);Acr=r(SJt,"flaubert"),SJt.forEach(t),Lcr=r(pWe," \u2014 "),WJ=n(pWe,"A",{href:!0});var RJt=s(WJ);ycr=r(RJt,"FlaubertForSequenceClassification"),RJt.forEach(t),xcr=r(pWe," (FlauBERT model)"),pWe.forEach(t),$cr=i(D),GT=n(D,"LI",{});var _We=s(GT);i4e=n(_We,"STRONG",{});var PJt=s(i4e);kcr=r(PJt,"fnet"),PJt.forEach(t),Scr=r(_We," \u2014 "),UJ=n(_We,"A",{href:!0});var BJt=s(UJ);Rcr=r(BJt,"FNetForSequenceClassification"),BJt.forEach(t),Pcr=r(_We," (FNet model)"),_We.forEach(t),Bcr=i(D),OT=n(D,"LI",{});var bWe=s(OT);d4e=n(bWe,"STRONG",{});var IJt=s(d4e);Icr=r(IJt,"funnel"),IJt.forEach(t),Ncr=r(bWe," \u2014 "),HJ=n(bWe,"A",{href:!0});var NJt=s(HJ);qcr=r(NJt,"FunnelForSequenceClassification"),NJt.forEach(t),jcr=r(bWe," (Funnel Transformer model)"),bWe.forEach(t),Dcr=i(D),VT=n(D,"LI",{});var vWe=s(VT);m4e=n(vWe,"STRONG",{});var qJt=s(m4e);Gcr=r(qJt,"gpt2"),qJt.forEach(t),Ocr=r(vWe," \u2014 "),JJ=n(vWe,"A",{href:!0});var jJt=s(JJ);Vcr=r(jJt,"GPT2ForSequenceClassification"),jJt.forEach(t),Xcr=r(vWe," (OpenAI GPT-2 model)"),vWe.forEach(t),zcr=i(D),XT=n(D,"LI",{});var FWe=s(XT);c4e=n(FWe,"STRONG",{});var DJt=s(c4e);Qcr=r(DJt,"gpt_neo"),DJt.forEach(t),Wcr=r(FWe," \u2014 "),YJ=n(FWe,"A",{href:!0});var GJt=s(YJ);Ucr=r(GJt,"GPTNeoForSequenceClassification"),GJt.forEach(t),Hcr=r(FWe," (GPT Neo model)"),FWe.forEach(t),Jcr=i(D),zT=n(D,"LI",{});var TWe=s(zT);f4e=n(TWe,"STRONG",{});var OJt=s(f4e);Ycr=r(OJt,"gptj"),OJt.forEach(t),Zcr=r(TWe," \u2014 "),ZJ=n(TWe,"A",{href:!0});var VJt=s(ZJ);Kcr=r(VJt,"GPTJForSequenceClassification"),VJt.forEach(t),efr=r(TWe," (GPT-J model)"),TWe.forEach(t),ofr=i(D),QT=n(D,"LI",{});var MWe=s(QT);g4e=n(MWe,"STRONG",{});var XJt=s(g4e);rfr=r(XJt,"ibert"),XJt.forEach(t),tfr=r(MWe," \u2014 "),KJ=n(MWe,"A",{href:!0});var zJt=s(KJ);afr=r(zJt,"IBertForSequenceClassification"),zJt.forEach(t),nfr=r(MWe," (I-BERT model)"),MWe.forEach(t),sfr=i(D),WT=n(D,"LI",{});var EWe=s(WT);h4e=n(EWe,"STRONG",{});var QJt=s(h4e);lfr=r(QJt,"layoutlm"),QJt.forEach(t),ifr=r(EWe," \u2014 "),eY=n(EWe,"A",{href:!0});var WJt=s(eY);dfr=r(WJt,"LayoutLMForSequenceClassification"),WJt.forEach(t),mfr=r(EWe," (LayoutLM model)"),EWe.forEach(t),cfr=i(D),UT=n(D,"LI",{});var CWe=s(UT);u4e=n(CWe,"STRONG",{});var UJt=s(u4e);ffr=r(UJt,"layoutlmv2"),UJt.forEach(t),gfr=r(CWe," \u2014 "),oY=n(CWe,"A",{href:!0});var HJt=s(oY);hfr=r(HJt,"LayoutLMv2ForSequenceClassification"),HJt.forEach(t),ufr=r(CWe," (LayoutLMv2 model)"),CWe.forEach(t),pfr=i(D),HT=n(D,"LI",{});var wWe=s(HT);p4e=n(wWe,"STRONG",{});var JJt=s(p4e);_fr=r(JJt,"layoutlmv3"),JJt.forEach(t),bfr=r(wWe," \u2014 "),rY=n(wWe,"A",{href:!0});var YJt=s(rY);vfr=r(YJt,"LayoutLMv3ForSequenceClassification"),YJt.forEach(t),Ffr=r(wWe," (LayoutLMv3 model)"),wWe.forEach(t),Tfr=i(D),JT=n(D,"LI",{});var AWe=s(JT);_4e=n(AWe,"STRONG",{});var ZJt=s(_4e);Mfr=r(ZJt,"led"),ZJt.forEach(t),Efr=r(AWe," \u2014 "),tY=n(AWe,"A",{href:!0});var KJt=s(tY);Cfr=r(KJt,"LEDForSequenceClassification"),KJt.forEach(t),wfr=r(AWe," (LED model)"),AWe.forEach(t),Afr=i(D),YT=n(D,"LI",{});var LWe=s(YT);b4e=n(LWe,"STRONG",{});var eYt=s(b4e);Lfr=r(eYt,"lilt"),eYt.forEach(t),yfr=r(LWe," \u2014 "),aY=n(LWe,"A",{href:!0});var oYt=s(aY);xfr=r(oYt,"LiltForSequenceClassification"),oYt.forEach(t),$fr=r(LWe," (LiLT model)"),LWe.forEach(t),kfr=i(D),ZT=n(D,"LI",{});var yWe=s(ZT);v4e=n(yWe,"STRONG",{});var rYt=s(v4e);Sfr=r(rYt,"longformer"),rYt.forEach(t),Rfr=r(yWe," \u2014 "),nY=n(yWe,"A",{href:!0});var tYt=s(nY);Pfr=r(tYt,"LongformerForSequenceClassification"),tYt.forEach(t),Bfr=r(yWe," (Longformer model)"),yWe.forEach(t),Ifr=i(D),KT=n(D,"LI",{});var xWe=s(KT);F4e=n(xWe,"STRONG",{});var aYt=s(F4e);Nfr=r(aYt,"luke"),aYt.forEach(t),qfr=r(xWe," \u2014 "),sY=n(xWe,"A",{href:!0});var nYt=s(sY);jfr=r(nYt,"LukeForSequenceClassification"),nYt.forEach(t),Dfr=r(xWe," (LUKE model)"),xWe.forEach(t),Gfr=i(D),eM=n(D,"LI",{});var $We=s(eM);T4e=n($We,"STRONG",{});var sYt=s(T4e);Ofr=r(sYt,"markuplm"),sYt.forEach(t),Vfr=r($We," \u2014 "),lY=n($We,"A",{href:!0});var lYt=s(lY);Xfr=r(lYt,"MarkupLMForSequenceClassification"),lYt.forEach(t),zfr=r($We," (MarkupLM model)"),$We.forEach(t),Qfr=i(D),oM=n(D,"LI",{});var kWe=s(oM);M4e=n(kWe,"STRONG",{});var iYt=s(M4e);Wfr=r(iYt,"mbart"),iYt.forEach(t),Ufr=r(kWe," \u2014 "),iY=n(kWe,"A",{href:!0});var dYt=s(iY);Hfr=r(dYt,"MBartForSequenceClassification"),dYt.forEach(t),Jfr=r(kWe," (mBART model)"),kWe.forEach(t),Yfr=i(D),rM=n(D,"LI",{});var SWe=s(rM);E4e=n(SWe,"STRONG",{});var mYt=s(E4e);Zfr=r(mYt,"megatron-bert"),mYt.forEach(t),Kfr=r(SWe," \u2014 "),dY=n(SWe,"A",{href:!0});var cYt=s(dY);egr=r(cYt,"MegatronBertForSequenceClassification"),cYt.forEach(t),ogr=r(SWe," (Megatron-BERT model)"),SWe.forEach(t),rgr=i(D),tM=n(D,"LI",{});var RWe=s(tM);C4e=n(RWe,"STRONG",{});var fYt=s(C4e);tgr=r(fYt,"mobilebert"),fYt.forEach(t),agr=r(RWe," \u2014 "),mY=n(RWe,"A",{href:!0});var gYt=s(mY);ngr=r(gYt,"MobileBertForSequenceClassification"),gYt.forEach(t),sgr=r(RWe," (MobileBERT model)"),RWe.forEach(t),lgr=i(D),aM=n(D,"LI",{});var PWe=s(aM);w4e=n(PWe,"STRONG",{});var hYt=s(w4e);igr=r(hYt,"mpnet"),hYt.forEach(t),dgr=r(PWe," \u2014 "),cY=n(PWe,"A",{href:!0});var uYt=s(cY);mgr=r(uYt,"MPNetForSequenceClassification"),uYt.forEach(t),cgr=r(PWe," (MPNet model)"),PWe.forEach(t),fgr=i(D),nM=n(D,"LI",{});var BWe=s(nM);A4e=n(BWe,"STRONG",{});var pYt=s(A4e);ggr=r(pYt,"mvp"),pYt.forEach(t),hgr=r(BWe," \u2014 "),fY=n(BWe,"A",{href:!0});var _Yt=s(fY);ugr=r(_Yt,"MvpForSequenceClassification"),_Yt.forEach(t),pgr=r(BWe," (MVP model)"),BWe.forEach(t),_gr=i(D),sM=n(D,"LI",{});var IWe=s(sM);L4e=n(IWe,"STRONG",{});var bYt=s(L4e);bgr=r(bYt,"nezha"),bYt.forEach(t),vgr=r(IWe," \u2014 "),gY=n(IWe,"A",{href:!0});var vYt=s(gY);Fgr=r(vYt,"NezhaForSequenceClassification"),vYt.forEach(t),Tgr=r(IWe," (Nezha model)"),IWe.forEach(t),Mgr=i(D),lM=n(D,"LI",{});var NWe=s(lM);y4e=n(NWe,"STRONG",{});var FYt=s(y4e);Egr=r(FYt,"nystromformer"),FYt.forEach(t),Cgr=r(NWe," \u2014 "),hY=n(NWe,"A",{href:!0});var TYt=s(hY);wgr=r(TYt,"NystromformerForSequenceClassification"),TYt.forEach(t),Agr=r(NWe," (Nystr\xF6mformer model)"),NWe.forEach(t),Lgr=i(D),iM=n(D,"LI",{});var qWe=s(iM);x4e=n(qWe,"STRONG",{});var MYt=s(x4e);ygr=r(MYt,"openai-gpt"),MYt.forEach(t),xgr=r(qWe," \u2014 "),uY=n(qWe,"A",{href:!0});var EYt=s(uY);$gr=r(EYt,"OpenAIGPTForSequenceClassification"),EYt.forEach(t),kgr=r(qWe," (OpenAI GPT model)"),qWe.forEach(t),Sgr=i(D),dM=n(D,"LI",{});var jWe=s(dM);$4e=n(jWe,"STRONG",{});var CYt=s($4e);Rgr=r(CYt,"opt"),CYt.forEach(t),Pgr=r(jWe," \u2014 "),pY=n(jWe,"A",{href:!0});var wYt=s(pY);Bgr=r(wYt,"OPTForSequenceClassification"),wYt.forEach(t),Igr=r(jWe," (OPT model)"),jWe.forEach(t),Ngr=i(D),mM=n(D,"LI",{});var DWe=s(mM);k4e=n(DWe,"STRONG",{});var AYt=s(k4e);qgr=r(AYt,"perceiver"),AYt.forEach(t),jgr=r(DWe," \u2014 "),_Y=n(DWe,"A",{href:!0});var LYt=s(_Y);Dgr=r(LYt,"PerceiverForSequenceClassification"),LYt.forEach(t),Ggr=r(DWe," (Perceiver model)"),DWe.forEach(t),Ogr=i(D),cM=n(D,"LI",{});var GWe=s(cM);S4e=n(GWe,"STRONG",{});var yYt=s(S4e);Vgr=r(yYt,"plbart"),yYt.forEach(t),Xgr=r(GWe," \u2014 "),bY=n(GWe,"A",{href:!0});var xYt=s(bY);zgr=r(xYt,"PLBartForSequenceClassification"),xYt.forEach(t),Qgr=r(GWe," (PLBart model)"),GWe.forEach(t),Wgr=i(D),fM=n(D,"LI",{});var OWe=s(fM);R4e=n(OWe,"STRONG",{});var $Yt=s(R4e);Ugr=r($Yt,"qdqbert"),$Yt.forEach(t),Hgr=r(OWe," \u2014 "),vY=n(OWe,"A",{href:!0});var kYt=s(vY);Jgr=r(kYt,"QDQBertForSequenceClassification"),kYt.forEach(t),Ygr=r(OWe," (QDQBert model)"),OWe.forEach(t),Zgr=i(D),gM=n(D,"LI",{});var VWe=s(gM);P4e=n(VWe,"STRONG",{});var SYt=s(P4e);Kgr=r(SYt,"reformer"),SYt.forEach(t),ehr=r(VWe," \u2014 "),FY=n(VWe,"A",{href:!0});var RYt=s(FY);ohr=r(RYt,"ReformerForSequenceClassification"),RYt.forEach(t),rhr=r(VWe," (Reformer model)"),VWe.forEach(t),thr=i(D),hM=n(D,"LI",{});var XWe=s(hM);B4e=n(XWe,"STRONG",{});var PYt=s(B4e);ahr=r(PYt,"rembert"),PYt.forEach(t),nhr=r(XWe," \u2014 "),TY=n(XWe,"A",{href:!0});var BYt=s(TY);shr=r(BYt,"RemBertForSequenceClassification"),BYt.forEach(t),lhr=r(XWe," (RemBERT model)"),XWe.forEach(t),ihr=i(D),uM=n(D,"LI",{});var zWe=s(uM);I4e=n(zWe,"STRONG",{});var IYt=s(I4e);dhr=r(IYt,"roberta"),IYt.forEach(t),mhr=r(zWe," \u2014 "),MY=n(zWe,"A",{href:!0});var NYt=s(MY);chr=r(NYt,"RobertaForSequenceClassification"),NYt.forEach(t),fhr=r(zWe," (RoBERTa model)"),zWe.forEach(t),ghr=i(D),pM=n(D,"LI",{});var QWe=s(pM);N4e=n(QWe,"STRONG",{});var qYt=s(N4e);hhr=r(qYt,"roc_bert"),qYt.forEach(t),uhr=r(QWe," \u2014 "),EY=n(QWe,"A",{href:!0});var jYt=s(EY);phr=r(jYt,"RoCBertForSequenceClassification"),jYt.forEach(t),_hr=r(QWe," (RoCBert model)"),QWe.forEach(t),bhr=i(D),_M=n(D,"LI",{});var WWe=s(_M);q4e=n(WWe,"STRONG",{});var DYt=s(q4e);vhr=r(DYt,"roformer"),DYt.forEach(t),Fhr=r(WWe," \u2014 "),CY=n(WWe,"A",{href:!0});var GYt=s(CY);Thr=r(GYt,"RoFormerForSequenceClassification"),GYt.forEach(t),Mhr=r(WWe," (RoFormer model)"),WWe.forEach(t),Ehr=i(D),bM=n(D,"LI",{});var UWe=s(bM);j4e=n(UWe,"STRONG",{});var OYt=s(j4e);Chr=r(OYt,"squeezebert"),OYt.forEach(t),whr=r(UWe," \u2014 "),wY=n(UWe,"A",{href:!0});var VYt=s(wY);Ahr=r(VYt,"SqueezeBertForSequenceClassification"),VYt.forEach(t),Lhr=r(UWe," (SqueezeBERT model)"),UWe.forEach(t),yhr=i(D),vM=n(D,"LI",{});var HWe=s(vM);D4e=n(HWe,"STRONG",{});var XYt=s(D4e);xhr=r(XYt,"tapas"),XYt.forEach(t),$hr=r(HWe," \u2014 "),AY=n(HWe,"A",{href:!0});var zYt=s(AY);khr=r(zYt,"TapasForSequenceClassification"),zYt.forEach(t),Shr=r(HWe," (TAPAS model)"),HWe.forEach(t),Rhr=i(D),FM=n(D,"LI",{});var JWe=s(FM);G4e=n(JWe,"STRONG",{});var QYt=s(G4e);Phr=r(QYt,"transfo-xl"),QYt.forEach(t),Bhr=r(JWe," \u2014 "),LY=n(JWe,"A",{href:!0});var WYt=s(LY);Ihr=r(WYt,"TransfoXLForSequenceClassification"),WYt.forEach(t),Nhr=r(JWe," (Transformer-XL model)"),JWe.forEach(t),qhr=i(D),TM=n(D,"LI",{});var YWe=s(TM);O4e=n(YWe,"STRONG",{});var UYt=s(O4e);jhr=r(UYt,"xlm"),UYt.forEach(t),Dhr=r(YWe," \u2014 "),yY=n(YWe,"A",{href:!0});var HYt=s(yY);Ghr=r(HYt,"XLMForSequenceClassification"),HYt.forEach(t),Ohr=r(YWe," (XLM model)"),YWe.forEach(t),Vhr=i(D),MM=n(D,"LI",{});var ZWe=s(MM);V4e=n(ZWe,"STRONG",{});var JYt=s(V4e);Xhr=r(JYt,"xlm-roberta"),JYt.forEach(t),zhr=r(ZWe," \u2014 "),xY=n(ZWe,"A",{href:!0});var YYt=s(xY);Qhr=r(YYt,"XLMRobertaForSequenceClassification"),YYt.forEach(t),Whr=r(ZWe," (XLM-RoBERTa model)"),ZWe.forEach(t),Uhr=i(D),EM=n(D,"LI",{});var KWe=s(EM);X4e=n(KWe,"STRONG",{});var ZYt=s(X4e);Hhr=r(ZYt,"xlm-roberta-xl"),ZYt.forEach(t),Jhr=r(KWe," \u2014 "),$Y=n(KWe,"A",{href:!0});var KYt=s($Y);Yhr=r(KYt,"XLMRobertaXLForSequenceClassification"),KYt.forEach(t),Zhr=r(KWe," (XLM-RoBERTa-XL model)"),KWe.forEach(t),Khr=i(D),CM=n(D,"LI",{});var eUe=s(CM);z4e=n(eUe,"STRONG",{});var eZt=s(z4e);eur=r(eZt,"xlnet"),eZt.forEach(t),our=r(eUe," \u2014 "),kY=n(eUe,"A",{href:!0});var oZt=s(kY);rur=r(oZt,"XLNetForSequenceClassification"),oZt.forEach(t),tur=r(eUe," (XLNet model)"),eUe.forEach(t),aur=i(D),wM=n(D,"LI",{});var oUe=s(wM);Q4e=n(oUe,"STRONG",{});var rZt=s(Q4e);nur=r(rZt,"yoso"),rZt.forEach(t),sur=r(oUe," \u2014 "),SY=n(oUe,"A",{href:!0});var tZt=s(SY);lur=r(tZt,"YosoForSequenceClassification"),tZt.forEach(t),iur=r(oUe," (YOSO model)"),oUe.forEach(t),D.forEach(t),dur=i(Ra),AM=n(Ra,"P",{});var rUe=s(AM);mur=r(rUe,"The model is set in evaluation mode by default using "),W4e=n(rUe,"CODE",{});var aZt=s(W4e);cur=r(aZt,"model.eval()"),aZt.forEach(t),fur=r(rUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),U4e=n(rUe,"CODE",{});var nZt=s(U4e);gur=r(nZt,"model.train()"),nZt.forEach(t),rUe.forEach(t),hur=i(Ra),T(LM.$$.fragment,Ra),Ra.forEach(t),zl.forEach(t),ono=i(c),em=n(c,"H2",{class:!0});var Flo=s(em);yM=n(Flo,"A",{id:!0,class:!0,href:!0});var sZt=s(yM);H4e=n(sZt,"SPAN",{});var lZt=s(H4e);T(kk.$$.fragment,lZt),lZt.forEach(t),sZt.forEach(t),uur=i(Flo),J4e=n(Flo,"SPAN",{});var iZt=s(J4e);pur=r(iZt,"AutoModelForMultipleChoice"),iZt.forEach(t),Flo.forEach(t),rno=i(c),Vo=n(c,"DIV",{class:!0});var Ql=s(Vo);T(Sk.$$.fragment,Ql),_ur=i(Ql),om=n(Ql,"P",{});var Ume=s(om);bur=r(Ume,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),RY=n(Ume,"A",{href:!0});var dZt=s(RY);vur=r(dZt,"from_pretrained()"),dZt.forEach(t),Fur=r(Ume," class method or the "),PY=n(Ume,"A",{href:!0});var mZt=s(PY);Tur=r(mZt,"from_config()"),mZt.forEach(t),Mur=r(Ume,` class
method.`),Ume.forEach(t),Eur=i(Ql),Rk=n(Ql,"P",{});var Tlo=s(Rk);Cur=r(Tlo,"This class cannot be instantiated directly using "),Y4e=n(Tlo,"CODE",{});var cZt=s(Y4e);wur=r(cZt,"__init__()"),cZt.forEach(t),Aur=r(Tlo," (throws an error)."),Tlo.forEach(t),Lur=i(Ql),xt=n(Ql,"DIV",{class:!0});var y9=s(xt);T(Pk.$$.fragment,y9),yur=i(y9),Z4e=n(y9,"P",{});var fZt=s(Z4e);xur=r(fZt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),fZt.forEach(t),$ur=i(y9),rm=n(y9,"P",{});var Hme=s(rm);kur=r(Hme,`Note:
Loading a model from its configuration file does `),K4e=n(Hme,"STRONG",{});var gZt=s(K4e);Sur=r(gZt,"not"),gZt.forEach(t),Rur=r(Hme,` load the model weights. It only affects the
model\u2019s configuration. Use `),BY=n(Hme,"A",{href:!0});var hZt=s(BY);Pur=r(hZt,"from_pretrained()"),hZt.forEach(t),Bur=r(Hme," to load the model weights."),Hme.forEach(t),Iur=i(y9),T(xM.$$.fragment,y9),y9.forEach(t),Nur=i(Ql),so=n(Ql,"DIV",{class:!0});var Pa=s(so);T(Bk.$$.fragment,Pa),qur=i(Pa),eCe=n(Pa,"P",{});var uZt=s(eCe);jur=r(uZt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),uZt.forEach(t),Dur=i(Pa),gn=n(Pa,"P",{});var x9=s(gn);Gur=r(x9,"The model class to instantiate is selected based on the "),oCe=n(x9,"CODE",{});var pZt=s(oCe);Our=r(pZt,"model_type"),pZt.forEach(t),Vur=r(x9,` property of the config object (either
passed as an argument or loaded from `),rCe=n(x9,"CODE",{});var _Zt=s(rCe);Xur=r(_Zt,"pretrained_model_name_or_path"),_Zt.forEach(t),zur=r(x9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tCe=n(x9,"CODE",{});var bZt=s(tCe);Qur=r(bZt,"pretrained_model_name_or_path"),bZt.forEach(t),Wur=r(x9,":"),x9.forEach(t),Uur=i(Pa),K=n(Pa,"UL",{});var ee=s(K);$M=n(ee,"LI",{});var tUe=s($M);aCe=n(tUe,"STRONG",{});var vZt=s(aCe);Hur=r(vZt,"albert"),vZt.forEach(t),Jur=r(tUe," \u2014 "),IY=n(tUe,"A",{href:!0});var FZt=s(IY);Yur=r(FZt,"AlbertForMultipleChoice"),FZt.forEach(t),Zur=r(tUe," (ALBERT model)"),tUe.forEach(t),Kur=i(ee),kM=n(ee,"LI",{});var aUe=s(kM);nCe=n(aUe,"STRONG",{});var TZt=s(nCe);epr=r(TZt,"bert"),TZt.forEach(t),opr=r(aUe," \u2014 "),NY=n(aUe,"A",{href:!0});var MZt=s(NY);rpr=r(MZt,"BertForMultipleChoice"),MZt.forEach(t),tpr=r(aUe," (BERT model)"),aUe.forEach(t),apr=i(ee),SM=n(ee,"LI",{});var nUe=s(SM);sCe=n(nUe,"STRONG",{});var EZt=s(sCe);npr=r(EZt,"big_bird"),EZt.forEach(t),spr=r(nUe," \u2014 "),qY=n(nUe,"A",{href:!0});var CZt=s(qY);lpr=r(CZt,"BigBirdForMultipleChoice"),CZt.forEach(t),ipr=r(nUe," (BigBird model)"),nUe.forEach(t),dpr=i(ee),RM=n(ee,"LI",{});var sUe=s(RM);lCe=n(sUe,"STRONG",{});var wZt=s(lCe);mpr=r(wZt,"camembert"),wZt.forEach(t),cpr=r(sUe," \u2014 "),jY=n(sUe,"A",{href:!0});var AZt=s(jY);fpr=r(AZt,"CamembertForMultipleChoice"),AZt.forEach(t),gpr=r(sUe," (CamemBERT model)"),sUe.forEach(t),hpr=i(ee),PM=n(ee,"LI",{});var lUe=s(PM);iCe=n(lUe,"STRONG",{});var LZt=s(iCe);upr=r(LZt,"canine"),LZt.forEach(t),ppr=r(lUe," \u2014 "),DY=n(lUe,"A",{href:!0});var yZt=s(DY);_pr=r(yZt,"CanineForMultipleChoice"),yZt.forEach(t),bpr=r(lUe," (CANINE model)"),lUe.forEach(t),vpr=i(ee),BM=n(ee,"LI",{});var iUe=s(BM);dCe=n(iUe,"STRONG",{});var xZt=s(dCe);Fpr=r(xZt,"convbert"),xZt.forEach(t),Tpr=r(iUe," \u2014 "),GY=n(iUe,"A",{href:!0});var $Zt=s(GY);Mpr=r($Zt,"ConvBertForMultipleChoice"),$Zt.forEach(t),Epr=r(iUe," (ConvBERT model)"),iUe.forEach(t),Cpr=i(ee),IM=n(ee,"LI",{});var dUe=s(IM);mCe=n(dUe,"STRONG",{});var kZt=s(mCe);wpr=r(kZt,"data2vec-text"),kZt.forEach(t),Apr=r(dUe," \u2014 "),OY=n(dUe,"A",{href:!0});var SZt=s(OY);Lpr=r(SZt,"Data2VecTextForMultipleChoice"),SZt.forEach(t),ypr=r(dUe," (Data2VecText model)"),dUe.forEach(t),xpr=i(ee),NM=n(ee,"LI",{});var mUe=s(NM);cCe=n(mUe,"STRONG",{});var RZt=s(cCe);$pr=r(RZt,"deberta-v2"),RZt.forEach(t),kpr=r(mUe," \u2014 "),VY=n(mUe,"A",{href:!0});var PZt=s(VY);Spr=r(PZt,"DebertaV2ForMultipleChoice"),PZt.forEach(t),Rpr=r(mUe," (DeBERTa-v2 model)"),mUe.forEach(t),Ppr=i(ee),qM=n(ee,"LI",{});var cUe=s(qM);fCe=n(cUe,"STRONG",{});var BZt=s(fCe);Bpr=r(BZt,"distilbert"),BZt.forEach(t),Ipr=r(cUe," \u2014 "),XY=n(cUe,"A",{href:!0});var IZt=s(XY);Npr=r(IZt,"DistilBertForMultipleChoice"),IZt.forEach(t),qpr=r(cUe," (DistilBERT model)"),cUe.forEach(t),jpr=i(ee),jM=n(ee,"LI",{});var fUe=s(jM);gCe=n(fUe,"STRONG",{});var NZt=s(gCe);Dpr=r(NZt,"electra"),NZt.forEach(t),Gpr=r(fUe," \u2014 "),zY=n(fUe,"A",{href:!0});var qZt=s(zY);Opr=r(qZt,"ElectraForMultipleChoice"),qZt.forEach(t),Vpr=r(fUe," (ELECTRA model)"),fUe.forEach(t),Xpr=i(ee),DM=n(ee,"LI",{});var gUe=s(DM);hCe=n(gUe,"STRONG",{});var jZt=s(hCe);zpr=r(jZt,"ernie"),jZt.forEach(t),Qpr=r(gUe," \u2014 "),QY=n(gUe,"A",{href:!0});var DZt=s(QY);Wpr=r(DZt,"ErnieForMultipleChoice"),DZt.forEach(t),Upr=r(gUe," (ERNIE model)"),gUe.forEach(t),Hpr=i(ee),GM=n(ee,"LI",{});var hUe=s(GM);uCe=n(hUe,"STRONG",{});var GZt=s(uCe);Jpr=r(GZt,"flaubert"),GZt.forEach(t),Ypr=r(hUe," \u2014 "),WY=n(hUe,"A",{href:!0});var OZt=s(WY);Zpr=r(OZt,"FlaubertForMultipleChoice"),OZt.forEach(t),Kpr=r(hUe," (FlauBERT model)"),hUe.forEach(t),e_r=i(ee),OM=n(ee,"LI",{});var uUe=s(OM);pCe=n(uUe,"STRONG",{});var VZt=s(pCe);o_r=r(VZt,"fnet"),VZt.forEach(t),r_r=r(uUe," \u2014 "),UY=n(uUe,"A",{href:!0});var XZt=s(UY);t_r=r(XZt,"FNetForMultipleChoice"),XZt.forEach(t),a_r=r(uUe," (FNet model)"),uUe.forEach(t),n_r=i(ee),VM=n(ee,"LI",{});var pUe=s(VM);_Ce=n(pUe,"STRONG",{});var zZt=s(_Ce);s_r=r(zZt,"funnel"),zZt.forEach(t),l_r=r(pUe," \u2014 "),HY=n(pUe,"A",{href:!0});var QZt=s(HY);i_r=r(QZt,"FunnelForMultipleChoice"),QZt.forEach(t),d_r=r(pUe," (Funnel Transformer model)"),pUe.forEach(t),m_r=i(ee),XM=n(ee,"LI",{});var _Ue=s(XM);bCe=n(_Ue,"STRONG",{});var WZt=s(bCe);c_r=r(WZt,"ibert"),WZt.forEach(t),f_r=r(_Ue," \u2014 "),JY=n(_Ue,"A",{href:!0});var UZt=s(JY);g_r=r(UZt,"IBertForMultipleChoice"),UZt.forEach(t),h_r=r(_Ue," (I-BERT model)"),_Ue.forEach(t),u_r=i(ee),zM=n(ee,"LI",{});var bUe=s(zM);vCe=n(bUe,"STRONG",{});var HZt=s(vCe);p_r=r(HZt,"longformer"),HZt.forEach(t),__r=r(bUe," \u2014 "),YY=n(bUe,"A",{href:!0});var JZt=s(YY);b_r=r(JZt,"LongformerForMultipleChoice"),JZt.forEach(t),v_r=r(bUe," (Longformer model)"),bUe.forEach(t),F_r=i(ee),QM=n(ee,"LI",{});var vUe=s(QM);FCe=n(vUe,"STRONG",{});var YZt=s(FCe);T_r=r(YZt,"luke"),YZt.forEach(t),M_r=r(vUe," \u2014 "),ZY=n(vUe,"A",{href:!0});var ZZt=s(ZY);E_r=r(ZZt,"LukeForMultipleChoice"),ZZt.forEach(t),C_r=r(vUe," (LUKE model)"),vUe.forEach(t),w_r=i(ee),WM=n(ee,"LI",{});var FUe=s(WM);TCe=n(FUe,"STRONG",{});var KZt=s(TCe);A_r=r(KZt,"megatron-bert"),KZt.forEach(t),L_r=r(FUe," \u2014 "),KY=n(FUe,"A",{href:!0});var eKt=s(KY);y_r=r(eKt,"MegatronBertForMultipleChoice"),eKt.forEach(t),x_r=r(FUe," (Megatron-BERT model)"),FUe.forEach(t),$_r=i(ee),UM=n(ee,"LI",{});var TUe=s(UM);MCe=n(TUe,"STRONG",{});var oKt=s(MCe);k_r=r(oKt,"mobilebert"),oKt.forEach(t),S_r=r(TUe," \u2014 "),eZ=n(TUe,"A",{href:!0});var rKt=s(eZ);R_r=r(rKt,"MobileBertForMultipleChoice"),rKt.forEach(t),P_r=r(TUe," (MobileBERT model)"),TUe.forEach(t),B_r=i(ee),HM=n(ee,"LI",{});var MUe=s(HM);ECe=n(MUe,"STRONG",{});var tKt=s(ECe);I_r=r(tKt,"mpnet"),tKt.forEach(t),N_r=r(MUe," \u2014 "),oZ=n(MUe,"A",{href:!0});var aKt=s(oZ);q_r=r(aKt,"MPNetForMultipleChoice"),aKt.forEach(t),j_r=r(MUe," (MPNet model)"),MUe.forEach(t),D_r=i(ee),JM=n(ee,"LI",{});var EUe=s(JM);CCe=n(EUe,"STRONG",{});var nKt=s(CCe);G_r=r(nKt,"nezha"),nKt.forEach(t),O_r=r(EUe," \u2014 "),rZ=n(EUe,"A",{href:!0});var sKt=s(rZ);V_r=r(sKt,"NezhaForMultipleChoice"),sKt.forEach(t),X_r=r(EUe," (Nezha model)"),EUe.forEach(t),z_r=i(ee),YM=n(ee,"LI",{});var CUe=s(YM);wCe=n(CUe,"STRONG",{});var lKt=s(wCe);Q_r=r(lKt,"nystromformer"),lKt.forEach(t),W_r=r(CUe," \u2014 "),tZ=n(CUe,"A",{href:!0});var iKt=s(tZ);U_r=r(iKt,"NystromformerForMultipleChoice"),iKt.forEach(t),H_r=r(CUe," (Nystr\xF6mformer model)"),CUe.forEach(t),J_r=i(ee),ZM=n(ee,"LI",{});var wUe=s(ZM);ACe=n(wUe,"STRONG",{});var dKt=s(ACe);Y_r=r(dKt,"qdqbert"),dKt.forEach(t),Z_r=r(wUe," \u2014 "),aZ=n(wUe,"A",{href:!0});var mKt=s(aZ);K_r=r(mKt,"QDQBertForMultipleChoice"),mKt.forEach(t),e1r=r(wUe," (QDQBert model)"),wUe.forEach(t),o1r=i(ee),KM=n(ee,"LI",{});var AUe=s(KM);LCe=n(AUe,"STRONG",{});var cKt=s(LCe);r1r=r(cKt,"rembert"),cKt.forEach(t),t1r=r(AUe," \u2014 "),nZ=n(AUe,"A",{href:!0});var fKt=s(nZ);a1r=r(fKt,"RemBertForMultipleChoice"),fKt.forEach(t),n1r=r(AUe," (RemBERT model)"),AUe.forEach(t),s1r=i(ee),eE=n(ee,"LI",{});var LUe=s(eE);yCe=n(LUe,"STRONG",{});var gKt=s(yCe);l1r=r(gKt,"roberta"),gKt.forEach(t),i1r=r(LUe," \u2014 "),sZ=n(LUe,"A",{href:!0});var hKt=s(sZ);d1r=r(hKt,"RobertaForMultipleChoice"),hKt.forEach(t),m1r=r(LUe," (RoBERTa model)"),LUe.forEach(t),c1r=i(ee),oE=n(ee,"LI",{});var yUe=s(oE);xCe=n(yUe,"STRONG",{});var uKt=s(xCe);f1r=r(uKt,"roc_bert"),uKt.forEach(t),g1r=r(yUe," \u2014 "),lZ=n(yUe,"A",{href:!0});var pKt=s(lZ);h1r=r(pKt,"RoCBertForMultipleChoice"),pKt.forEach(t),u1r=r(yUe," (RoCBert model)"),yUe.forEach(t),p1r=i(ee),rE=n(ee,"LI",{});var xUe=s(rE);$Ce=n(xUe,"STRONG",{});var _Kt=s($Ce);_1r=r(_Kt,"roformer"),_Kt.forEach(t),b1r=r(xUe," \u2014 "),iZ=n(xUe,"A",{href:!0});var bKt=s(iZ);v1r=r(bKt,"RoFormerForMultipleChoice"),bKt.forEach(t),F1r=r(xUe," (RoFormer model)"),xUe.forEach(t),T1r=i(ee),tE=n(ee,"LI",{});var $Ue=s(tE);kCe=n($Ue,"STRONG",{});var vKt=s(kCe);M1r=r(vKt,"squeezebert"),vKt.forEach(t),E1r=r($Ue," \u2014 "),dZ=n($Ue,"A",{href:!0});var FKt=s(dZ);C1r=r(FKt,"SqueezeBertForMultipleChoice"),FKt.forEach(t),w1r=r($Ue," (SqueezeBERT model)"),$Ue.forEach(t),A1r=i(ee),aE=n(ee,"LI",{});var kUe=s(aE);SCe=n(kUe,"STRONG",{});var TKt=s(SCe);L1r=r(TKt,"xlm"),TKt.forEach(t),y1r=r(kUe," \u2014 "),mZ=n(kUe,"A",{href:!0});var MKt=s(mZ);x1r=r(MKt,"XLMForMultipleChoice"),MKt.forEach(t),$1r=r(kUe," (XLM model)"),kUe.forEach(t),k1r=i(ee),nE=n(ee,"LI",{});var SUe=s(nE);RCe=n(SUe,"STRONG",{});var EKt=s(RCe);S1r=r(EKt,"xlm-roberta"),EKt.forEach(t),R1r=r(SUe," \u2014 "),cZ=n(SUe,"A",{href:!0});var CKt=s(cZ);P1r=r(CKt,"XLMRobertaForMultipleChoice"),CKt.forEach(t),B1r=r(SUe," (XLM-RoBERTa model)"),SUe.forEach(t),I1r=i(ee),sE=n(ee,"LI",{});var RUe=s(sE);PCe=n(RUe,"STRONG",{});var wKt=s(PCe);N1r=r(wKt,"xlm-roberta-xl"),wKt.forEach(t),q1r=r(RUe," \u2014 "),fZ=n(RUe,"A",{href:!0});var AKt=s(fZ);j1r=r(AKt,"XLMRobertaXLForMultipleChoice"),AKt.forEach(t),D1r=r(RUe," (XLM-RoBERTa-XL model)"),RUe.forEach(t),G1r=i(ee),lE=n(ee,"LI",{});var PUe=s(lE);BCe=n(PUe,"STRONG",{});var LKt=s(BCe);O1r=r(LKt,"xlnet"),LKt.forEach(t),V1r=r(PUe," \u2014 "),gZ=n(PUe,"A",{href:!0});var yKt=s(gZ);X1r=r(yKt,"XLNetForMultipleChoice"),yKt.forEach(t),z1r=r(PUe," (XLNet model)"),PUe.forEach(t),Q1r=i(ee),iE=n(ee,"LI",{});var BUe=s(iE);ICe=n(BUe,"STRONG",{});var xKt=s(ICe);W1r=r(xKt,"yoso"),xKt.forEach(t),U1r=r(BUe," \u2014 "),hZ=n(BUe,"A",{href:!0});var $Kt=s(hZ);H1r=r($Kt,"YosoForMultipleChoice"),$Kt.forEach(t),J1r=r(BUe," (YOSO model)"),BUe.forEach(t),ee.forEach(t),Y1r=i(Pa),dE=n(Pa,"P",{});var IUe=s(dE);Z1r=r(IUe,"The model is set in evaluation mode by default using "),NCe=n(IUe,"CODE",{});var kKt=s(NCe);K1r=r(kKt,"model.eval()"),kKt.forEach(t),e2r=r(IUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qCe=n(IUe,"CODE",{});var SKt=s(qCe);o2r=r(SKt,"model.train()"),SKt.forEach(t),IUe.forEach(t),r2r=i(Pa),T(mE.$$.fragment,Pa),Pa.forEach(t),Ql.forEach(t),tno=i(c),tm=n(c,"H2",{class:!0});var Mlo=s(tm);cE=n(Mlo,"A",{id:!0,class:!0,href:!0});var RKt=s(cE);jCe=n(RKt,"SPAN",{});var PKt=s(jCe);T(Ik.$$.fragment,PKt),PKt.forEach(t),RKt.forEach(t),t2r=i(Mlo),DCe=n(Mlo,"SPAN",{});var BKt=s(DCe);a2r=r(BKt,"AutoModelForNextSentencePrediction"),BKt.forEach(t),Mlo.forEach(t),ano=i(c),Xo=n(c,"DIV",{class:!0});var Wl=s(Xo);T(Nk.$$.fragment,Wl),n2r=i(Wl),am=n(Wl,"P",{});var Jme=s(am);s2r=r(Jme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),uZ=n(Jme,"A",{href:!0});var IKt=s(uZ);l2r=r(IKt,"from_pretrained()"),IKt.forEach(t),i2r=r(Jme," class method or the "),pZ=n(Jme,"A",{href:!0});var NKt=s(pZ);d2r=r(NKt,"from_config()"),NKt.forEach(t),m2r=r(Jme,` class
method.`),Jme.forEach(t),c2r=i(Wl),qk=n(Wl,"P",{});var Elo=s(qk);f2r=r(Elo,"This class cannot be instantiated directly using "),GCe=n(Elo,"CODE",{});var qKt=s(GCe);g2r=r(qKt,"__init__()"),qKt.forEach(t),h2r=r(Elo," (throws an error)."),Elo.forEach(t),u2r=i(Wl),$t=n(Wl,"DIV",{class:!0});var $9=s($t);T(jk.$$.fragment,$9),p2r=i($9),OCe=n($9,"P",{});var jKt=s(OCe);_2r=r(jKt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),jKt.forEach(t),b2r=i($9),nm=n($9,"P",{});var Yme=s(nm);v2r=r(Yme,`Note:
Loading a model from its configuration file does `),VCe=n(Yme,"STRONG",{});var DKt=s(VCe);F2r=r(DKt,"not"),DKt.forEach(t),T2r=r(Yme,` load the model weights. It only affects the
model\u2019s configuration. Use `),_Z=n(Yme,"A",{href:!0});var GKt=s(_Z);M2r=r(GKt,"from_pretrained()"),GKt.forEach(t),E2r=r(Yme," to load the model weights."),Yme.forEach(t),C2r=i($9),T(fE.$$.fragment,$9),$9.forEach(t),w2r=i(Wl),lo=n(Wl,"DIV",{class:!0});var Ba=s(lo);T(Dk.$$.fragment,Ba),A2r=i(Ba),XCe=n(Ba,"P",{});var OKt=s(XCe);L2r=r(OKt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),OKt.forEach(t),y2r=i(Ba),hn=n(Ba,"P",{});var k9=s(hn);x2r=r(k9,"The model class to instantiate is selected based on the "),zCe=n(k9,"CODE",{});var VKt=s(zCe);$2r=r(VKt,"model_type"),VKt.forEach(t),k2r=r(k9,` property of the config object (either
passed as an argument or loaded from `),QCe=n(k9,"CODE",{});var XKt=s(QCe);S2r=r(XKt,"pretrained_model_name_or_path"),XKt.forEach(t),R2r=r(k9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),WCe=n(k9,"CODE",{});var zKt=s(WCe);P2r=r(zKt,"pretrained_model_name_or_path"),zKt.forEach(t),B2r=r(k9,":"),k9.forEach(t),I2r=i(Ba),Ue=n(Ba,"UL",{});var ht=s(Ue);gE=n(ht,"LI",{});var NUe=s(gE);UCe=n(NUe,"STRONG",{});var QKt=s(UCe);N2r=r(QKt,"bert"),QKt.forEach(t),q2r=r(NUe," \u2014 "),bZ=n(NUe,"A",{href:!0});var WKt=s(bZ);j2r=r(WKt,"BertForNextSentencePrediction"),WKt.forEach(t),D2r=r(NUe," (BERT model)"),NUe.forEach(t),G2r=i(ht),hE=n(ht,"LI",{});var qUe=s(hE);HCe=n(qUe,"STRONG",{});var UKt=s(HCe);O2r=r(UKt,"ernie"),UKt.forEach(t),V2r=r(qUe," \u2014 "),vZ=n(qUe,"A",{href:!0});var HKt=s(vZ);X2r=r(HKt,"ErnieForNextSentencePrediction"),HKt.forEach(t),z2r=r(qUe," (ERNIE model)"),qUe.forEach(t),Q2r=i(ht),uE=n(ht,"LI",{});var jUe=s(uE);JCe=n(jUe,"STRONG",{});var JKt=s(JCe);W2r=r(JKt,"fnet"),JKt.forEach(t),U2r=r(jUe," \u2014 "),FZ=n(jUe,"A",{href:!0});var YKt=s(FZ);H2r=r(YKt,"FNetForNextSentencePrediction"),YKt.forEach(t),J2r=r(jUe," (FNet model)"),jUe.forEach(t),Y2r=i(ht),pE=n(ht,"LI",{});var DUe=s(pE);YCe=n(DUe,"STRONG",{});var ZKt=s(YCe);Z2r=r(ZKt,"megatron-bert"),ZKt.forEach(t),K2r=r(DUe," \u2014 "),TZ=n(DUe,"A",{href:!0});var KKt=s(TZ);ebr=r(KKt,"MegatronBertForNextSentencePrediction"),KKt.forEach(t),obr=r(DUe," (Megatron-BERT model)"),DUe.forEach(t),rbr=i(ht),_E=n(ht,"LI",{});var GUe=s(_E);ZCe=n(GUe,"STRONG",{});var eea=s(ZCe);tbr=r(eea,"mobilebert"),eea.forEach(t),abr=r(GUe," \u2014 "),MZ=n(GUe,"A",{href:!0});var oea=s(MZ);nbr=r(oea,"MobileBertForNextSentencePrediction"),oea.forEach(t),sbr=r(GUe," (MobileBERT model)"),GUe.forEach(t),lbr=i(ht),bE=n(ht,"LI",{});var OUe=s(bE);KCe=n(OUe,"STRONG",{});var rea=s(KCe);ibr=r(rea,"nezha"),rea.forEach(t),dbr=r(OUe," \u2014 "),EZ=n(OUe,"A",{href:!0});var tea=s(EZ);mbr=r(tea,"NezhaForNextSentencePrediction"),tea.forEach(t),cbr=r(OUe," (Nezha model)"),OUe.forEach(t),fbr=i(ht),vE=n(ht,"LI",{});var VUe=s(vE);e3e=n(VUe,"STRONG",{});var aea=s(e3e);gbr=r(aea,"qdqbert"),aea.forEach(t),hbr=r(VUe," \u2014 "),CZ=n(VUe,"A",{href:!0});var nea=s(CZ);ubr=r(nea,"QDQBertForNextSentencePrediction"),nea.forEach(t),pbr=r(VUe," (QDQBert model)"),VUe.forEach(t),ht.forEach(t),_br=i(Ba),FE=n(Ba,"P",{});var XUe=s(FE);bbr=r(XUe,"The model is set in evaluation mode by default using "),o3e=n(XUe,"CODE",{});var sea=s(o3e);vbr=r(sea,"model.eval()"),sea.forEach(t),Fbr=r(XUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),r3e=n(XUe,"CODE",{});var lea=s(r3e);Tbr=r(lea,"model.train()"),lea.forEach(t),XUe.forEach(t),Mbr=i(Ba),T(TE.$$.fragment,Ba),Ba.forEach(t),Wl.forEach(t),nno=i(c),sm=n(c,"H2",{class:!0});var Clo=s(sm);ME=n(Clo,"A",{id:!0,class:!0,href:!0});var iea=s(ME);t3e=n(iea,"SPAN",{});var dea=s(t3e);T(Gk.$$.fragment,dea),dea.forEach(t),iea.forEach(t),Ebr=i(Clo),a3e=n(Clo,"SPAN",{});var mea=s(a3e);Cbr=r(mea,"AutoModelForTokenClassification"),mea.forEach(t),Clo.forEach(t),sno=i(c),zo=n(c,"DIV",{class:!0});var Ul=s(zo);T(Ok.$$.fragment,Ul),wbr=i(Ul),lm=n(Ul,"P",{});var Zme=s(lm);Abr=r(Zme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),wZ=n(Zme,"A",{href:!0});var cea=s(wZ);Lbr=r(cea,"from_pretrained()"),cea.forEach(t),ybr=r(Zme," class method or the "),AZ=n(Zme,"A",{href:!0});var fea=s(AZ);xbr=r(fea,"from_config()"),fea.forEach(t),$br=r(Zme,` class
method.`),Zme.forEach(t),kbr=i(Ul),Vk=n(Ul,"P",{});var wlo=s(Vk);Sbr=r(wlo,"This class cannot be instantiated directly using "),n3e=n(wlo,"CODE",{});var gea=s(n3e);Rbr=r(gea,"__init__()"),gea.forEach(t),Pbr=r(wlo," (throws an error)."),wlo.forEach(t),Bbr=i(Ul),kt=n(Ul,"DIV",{class:!0});var S9=s(kt);T(Xk.$$.fragment,S9),Ibr=i(S9),s3e=n(S9,"P",{});var hea=s(s3e);Nbr=r(hea,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),hea.forEach(t),qbr=i(S9),im=n(S9,"P",{});var Kme=s(im);jbr=r(Kme,`Note:
Loading a model from its configuration file does `),l3e=n(Kme,"STRONG",{});var uea=s(l3e);Dbr=r(uea,"not"),uea.forEach(t),Gbr=r(Kme,` load the model weights. It only affects the
model\u2019s configuration. Use `),LZ=n(Kme,"A",{href:!0});var pea=s(LZ);Obr=r(pea,"from_pretrained()"),pea.forEach(t),Vbr=r(Kme," to load the model weights."),Kme.forEach(t),Xbr=i(S9),T(EE.$$.fragment,S9),S9.forEach(t),zbr=i(Ul),io=n(Ul,"DIV",{class:!0});var Ia=s(io);T(zk.$$.fragment,Ia),Qbr=i(Ia),i3e=n(Ia,"P",{});var _ea=s(i3e);Wbr=r(_ea,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),_ea.forEach(t),Ubr=i(Ia),un=n(Ia,"P",{});var R9=s(un);Hbr=r(R9,"The model class to instantiate is selected based on the "),d3e=n(R9,"CODE",{});var bea=s(d3e);Jbr=r(bea,"model_type"),bea.forEach(t),Ybr=r(R9,` property of the config object (either
passed as an argument or loaded from `),m3e=n(R9,"CODE",{});var vea=s(m3e);Zbr=r(vea,"pretrained_model_name_or_path"),vea.forEach(t),Kbr=r(R9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c3e=n(R9,"CODE",{});var Fea=s(c3e);evr=r(Fea,"pretrained_model_name_or_path"),Fea.forEach(t),ovr=r(R9,":"),R9.forEach(t),rvr=i(Ia),U=n(Ia,"UL",{});var J=s(U);CE=n(J,"LI",{});var zUe=s(CE);f3e=n(zUe,"STRONG",{});var Tea=s(f3e);tvr=r(Tea,"albert"),Tea.forEach(t),avr=r(zUe," \u2014 "),yZ=n(zUe,"A",{href:!0});var Mea=s(yZ);nvr=r(Mea,"AlbertForTokenClassification"),Mea.forEach(t),svr=r(zUe," (ALBERT model)"),zUe.forEach(t),lvr=i(J),wE=n(J,"LI",{});var QUe=s(wE);g3e=n(QUe,"STRONG",{});var Eea=s(g3e);ivr=r(Eea,"bert"),Eea.forEach(t),dvr=r(QUe," \u2014 "),xZ=n(QUe,"A",{href:!0});var Cea=s(xZ);mvr=r(Cea,"BertForTokenClassification"),Cea.forEach(t),cvr=r(QUe," (BERT model)"),QUe.forEach(t),fvr=i(J),AE=n(J,"LI",{});var WUe=s(AE);h3e=n(WUe,"STRONG",{});var wea=s(h3e);gvr=r(wea,"big_bird"),wea.forEach(t),hvr=r(WUe," \u2014 "),$Z=n(WUe,"A",{href:!0});var Aea=s($Z);uvr=r(Aea,"BigBirdForTokenClassification"),Aea.forEach(t),pvr=r(WUe," (BigBird model)"),WUe.forEach(t),_vr=i(J),LE=n(J,"LI",{});var UUe=s(LE);u3e=n(UUe,"STRONG",{});var Lea=s(u3e);bvr=r(Lea,"bloom"),Lea.forEach(t),vvr=r(UUe," \u2014 "),kZ=n(UUe,"A",{href:!0});var yea=s(kZ);Fvr=r(yea,"BloomForTokenClassification"),yea.forEach(t),Tvr=r(UUe," (BLOOM model)"),UUe.forEach(t),Mvr=i(J),yE=n(J,"LI",{});var HUe=s(yE);p3e=n(HUe,"STRONG",{});var xea=s(p3e);Evr=r(xea,"camembert"),xea.forEach(t),Cvr=r(HUe," \u2014 "),SZ=n(HUe,"A",{href:!0});var $ea=s(SZ);wvr=r($ea,"CamembertForTokenClassification"),$ea.forEach(t),Avr=r(HUe," (CamemBERT model)"),HUe.forEach(t),Lvr=i(J),xE=n(J,"LI",{});var JUe=s(xE);_3e=n(JUe,"STRONG",{});var kea=s(_3e);yvr=r(kea,"canine"),kea.forEach(t),xvr=r(JUe," \u2014 "),RZ=n(JUe,"A",{href:!0});var Sea=s(RZ);$vr=r(Sea,"CanineForTokenClassification"),Sea.forEach(t),kvr=r(JUe," (CANINE model)"),JUe.forEach(t),Svr=i(J),$E=n(J,"LI",{});var YUe=s($E);b3e=n(YUe,"STRONG",{});var Rea=s(b3e);Rvr=r(Rea,"convbert"),Rea.forEach(t),Pvr=r(YUe," \u2014 "),PZ=n(YUe,"A",{href:!0});var Pea=s(PZ);Bvr=r(Pea,"ConvBertForTokenClassification"),Pea.forEach(t),Ivr=r(YUe," (ConvBERT model)"),YUe.forEach(t),Nvr=i(J),kE=n(J,"LI",{});var ZUe=s(kE);v3e=n(ZUe,"STRONG",{});var Bea=s(v3e);qvr=r(Bea,"data2vec-text"),Bea.forEach(t),jvr=r(ZUe," \u2014 "),BZ=n(ZUe,"A",{href:!0});var Iea=s(BZ);Dvr=r(Iea,"Data2VecTextForTokenClassification"),Iea.forEach(t),Gvr=r(ZUe," (Data2VecText model)"),ZUe.forEach(t),Ovr=i(J),SE=n(J,"LI",{});var KUe=s(SE);F3e=n(KUe,"STRONG",{});var Nea=s(F3e);Vvr=r(Nea,"deberta"),Nea.forEach(t),Xvr=r(KUe," \u2014 "),IZ=n(KUe,"A",{href:!0});var qea=s(IZ);zvr=r(qea,"DebertaForTokenClassification"),qea.forEach(t),Qvr=r(KUe," (DeBERTa model)"),KUe.forEach(t),Wvr=i(J),RE=n(J,"LI",{});var eHe=s(RE);T3e=n(eHe,"STRONG",{});var jea=s(T3e);Uvr=r(jea,"deberta-v2"),jea.forEach(t),Hvr=r(eHe," \u2014 "),NZ=n(eHe,"A",{href:!0});var Dea=s(NZ);Jvr=r(Dea,"DebertaV2ForTokenClassification"),Dea.forEach(t),Yvr=r(eHe," (DeBERTa-v2 model)"),eHe.forEach(t),Zvr=i(J),PE=n(J,"LI",{});var oHe=s(PE);M3e=n(oHe,"STRONG",{});var Gea=s(M3e);Kvr=r(Gea,"distilbert"),Gea.forEach(t),eFr=r(oHe," \u2014 "),qZ=n(oHe,"A",{href:!0});var Oea=s(qZ);oFr=r(Oea,"DistilBertForTokenClassification"),Oea.forEach(t),rFr=r(oHe," (DistilBERT model)"),oHe.forEach(t),tFr=i(J),BE=n(J,"LI",{});var rHe=s(BE);E3e=n(rHe,"STRONG",{});var Vea=s(E3e);aFr=r(Vea,"electra"),Vea.forEach(t),nFr=r(rHe," \u2014 "),jZ=n(rHe,"A",{href:!0});var Xea=s(jZ);sFr=r(Xea,"ElectraForTokenClassification"),Xea.forEach(t),lFr=r(rHe," (ELECTRA model)"),rHe.forEach(t),iFr=i(J),IE=n(J,"LI",{});var tHe=s(IE);C3e=n(tHe,"STRONG",{});var zea=s(C3e);dFr=r(zea,"ernie"),zea.forEach(t),mFr=r(tHe," \u2014 "),DZ=n(tHe,"A",{href:!0});var Qea=s(DZ);cFr=r(Qea,"ErnieForTokenClassification"),Qea.forEach(t),fFr=r(tHe," (ERNIE model)"),tHe.forEach(t),gFr=i(J),NE=n(J,"LI",{});var aHe=s(NE);w3e=n(aHe,"STRONG",{});var Wea=s(w3e);hFr=r(Wea,"esm"),Wea.forEach(t),uFr=r(aHe," \u2014 "),GZ=n(aHe,"A",{href:!0});var Uea=s(GZ);pFr=r(Uea,"EsmForTokenClassification"),Uea.forEach(t),_Fr=r(aHe," (ESM model)"),aHe.forEach(t),bFr=i(J),qE=n(J,"LI",{});var nHe=s(qE);A3e=n(nHe,"STRONG",{});var Hea=s(A3e);vFr=r(Hea,"flaubert"),Hea.forEach(t),FFr=r(nHe," \u2014 "),OZ=n(nHe,"A",{href:!0});var Jea=s(OZ);TFr=r(Jea,"FlaubertForTokenClassification"),Jea.forEach(t),MFr=r(nHe," (FlauBERT model)"),nHe.forEach(t),EFr=i(J),jE=n(J,"LI",{});var sHe=s(jE);L3e=n(sHe,"STRONG",{});var Yea=s(L3e);CFr=r(Yea,"fnet"),Yea.forEach(t),wFr=r(sHe," \u2014 "),VZ=n(sHe,"A",{href:!0});var Zea=s(VZ);AFr=r(Zea,"FNetForTokenClassification"),Zea.forEach(t),LFr=r(sHe," (FNet model)"),sHe.forEach(t),yFr=i(J),DE=n(J,"LI",{});var lHe=s(DE);y3e=n(lHe,"STRONG",{});var Kea=s(y3e);xFr=r(Kea,"funnel"),Kea.forEach(t),$Fr=r(lHe," \u2014 "),XZ=n(lHe,"A",{href:!0});var eoa=s(XZ);kFr=r(eoa,"FunnelForTokenClassification"),eoa.forEach(t),SFr=r(lHe," (Funnel Transformer model)"),lHe.forEach(t),RFr=i(J),GE=n(J,"LI",{});var iHe=s(GE);x3e=n(iHe,"STRONG",{});var ooa=s(x3e);PFr=r(ooa,"gpt2"),ooa.forEach(t),BFr=r(iHe," \u2014 "),zZ=n(iHe,"A",{href:!0});var roa=s(zZ);IFr=r(roa,"GPT2ForTokenClassification"),roa.forEach(t),NFr=r(iHe," (OpenAI GPT-2 model)"),iHe.forEach(t),qFr=i(J),OE=n(J,"LI",{});var dHe=s(OE);$3e=n(dHe,"STRONG",{});var toa=s($3e);jFr=r(toa,"ibert"),toa.forEach(t),DFr=r(dHe," \u2014 "),QZ=n(dHe,"A",{href:!0});var aoa=s(QZ);GFr=r(aoa,"IBertForTokenClassification"),aoa.forEach(t),OFr=r(dHe," (I-BERT model)"),dHe.forEach(t),VFr=i(J),VE=n(J,"LI",{});var mHe=s(VE);k3e=n(mHe,"STRONG",{});var noa=s(k3e);XFr=r(noa,"layoutlm"),noa.forEach(t),zFr=r(mHe," \u2014 "),WZ=n(mHe,"A",{href:!0});var soa=s(WZ);QFr=r(soa,"LayoutLMForTokenClassification"),soa.forEach(t),WFr=r(mHe," (LayoutLM model)"),mHe.forEach(t),UFr=i(J),XE=n(J,"LI",{});var cHe=s(XE);S3e=n(cHe,"STRONG",{});var loa=s(S3e);HFr=r(loa,"layoutlmv2"),loa.forEach(t),JFr=r(cHe," \u2014 "),UZ=n(cHe,"A",{href:!0});var ioa=s(UZ);YFr=r(ioa,"LayoutLMv2ForTokenClassification"),ioa.forEach(t),ZFr=r(cHe," (LayoutLMv2 model)"),cHe.forEach(t),KFr=i(J),zE=n(J,"LI",{});var fHe=s(zE);R3e=n(fHe,"STRONG",{});var doa=s(R3e);eTr=r(doa,"layoutlmv3"),doa.forEach(t),oTr=r(fHe," \u2014 "),HZ=n(fHe,"A",{href:!0});var moa=s(HZ);rTr=r(moa,"LayoutLMv3ForTokenClassification"),moa.forEach(t),tTr=r(fHe," (LayoutLMv3 model)"),fHe.forEach(t),aTr=i(J),QE=n(J,"LI",{});var gHe=s(QE);P3e=n(gHe,"STRONG",{});var coa=s(P3e);nTr=r(coa,"lilt"),coa.forEach(t),sTr=r(gHe," \u2014 "),JZ=n(gHe,"A",{href:!0});var foa=s(JZ);lTr=r(foa,"LiltForTokenClassification"),foa.forEach(t),iTr=r(gHe," (LiLT model)"),gHe.forEach(t),dTr=i(J),WE=n(J,"LI",{});var hHe=s(WE);B3e=n(hHe,"STRONG",{});var goa=s(B3e);mTr=r(goa,"longformer"),goa.forEach(t),cTr=r(hHe," \u2014 "),YZ=n(hHe,"A",{href:!0});var hoa=s(YZ);fTr=r(hoa,"LongformerForTokenClassification"),hoa.forEach(t),gTr=r(hHe," (Longformer model)"),hHe.forEach(t),hTr=i(J),UE=n(J,"LI",{});var uHe=s(UE);I3e=n(uHe,"STRONG",{});var uoa=s(I3e);uTr=r(uoa,"luke"),uoa.forEach(t),pTr=r(uHe," \u2014 "),ZZ=n(uHe,"A",{href:!0});var poa=s(ZZ);_Tr=r(poa,"LukeForTokenClassification"),poa.forEach(t),bTr=r(uHe," (LUKE model)"),uHe.forEach(t),vTr=i(J),HE=n(J,"LI",{});var pHe=s(HE);N3e=n(pHe,"STRONG",{});var _oa=s(N3e);FTr=r(_oa,"markuplm"),_oa.forEach(t),TTr=r(pHe," \u2014 "),KZ=n(pHe,"A",{href:!0});var boa=s(KZ);MTr=r(boa,"MarkupLMForTokenClassification"),boa.forEach(t),ETr=r(pHe," (MarkupLM model)"),pHe.forEach(t),CTr=i(J),JE=n(J,"LI",{});var _He=s(JE);q3e=n(_He,"STRONG",{});var voa=s(q3e);wTr=r(voa,"megatron-bert"),voa.forEach(t),ATr=r(_He," \u2014 "),eK=n(_He,"A",{href:!0});var Foa=s(eK);LTr=r(Foa,"MegatronBertForTokenClassification"),Foa.forEach(t),yTr=r(_He," (Megatron-BERT model)"),_He.forEach(t),xTr=i(J),YE=n(J,"LI",{});var bHe=s(YE);j3e=n(bHe,"STRONG",{});var Toa=s(j3e);$Tr=r(Toa,"mobilebert"),Toa.forEach(t),kTr=r(bHe," \u2014 "),oK=n(bHe,"A",{href:!0});var Moa=s(oK);STr=r(Moa,"MobileBertForTokenClassification"),Moa.forEach(t),RTr=r(bHe," (MobileBERT model)"),bHe.forEach(t),PTr=i(J),ZE=n(J,"LI",{});var vHe=s(ZE);D3e=n(vHe,"STRONG",{});var Eoa=s(D3e);BTr=r(Eoa,"mpnet"),Eoa.forEach(t),ITr=r(vHe," \u2014 "),rK=n(vHe,"A",{href:!0});var Coa=s(rK);NTr=r(Coa,"MPNetForTokenClassification"),Coa.forEach(t),qTr=r(vHe," (MPNet model)"),vHe.forEach(t),jTr=i(J),KE=n(J,"LI",{});var FHe=s(KE);G3e=n(FHe,"STRONG",{});var woa=s(G3e);DTr=r(woa,"nezha"),woa.forEach(t),GTr=r(FHe," \u2014 "),tK=n(FHe,"A",{href:!0});var Aoa=s(tK);OTr=r(Aoa,"NezhaForTokenClassification"),Aoa.forEach(t),VTr=r(FHe," (Nezha model)"),FHe.forEach(t),XTr=i(J),e4=n(J,"LI",{});var THe=s(e4);O3e=n(THe,"STRONG",{});var Loa=s(O3e);zTr=r(Loa,"nystromformer"),Loa.forEach(t),QTr=r(THe," \u2014 "),aK=n(THe,"A",{href:!0});var yoa=s(aK);WTr=r(yoa,"NystromformerForTokenClassification"),yoa.forEach(t),UTr=r(THe," (Nystr\xF6mformer model)"),THe.forEach(t),HTr=i(J),o4=n(J,"LI",{});var MHe=s(o4);V3e=n(MHe,"STRONG",{});var xoa=s(V3e);JTr=r(xoa,"qdqbert"),xoa.forEach(t),YTr=r(MHe," \u2014 "),nK=n(MHe,"A",{href:!0});var $oa=s(nK);ZTr=r($oa,"QDQBertForTokenClassification"),$oa.forEach(t),KTr=r(MHe," (QDQBert model)"),MHe.forEach(t),eMr=i(J),r4=n(J,"LI",{});var EHe=s(r4);X3e=n(EHe,"STRONG",{});var koa=s(X3e);oMr=r(koa,"rembert"),koa.forEach(t),rMr=r(EHe," \u2014 "),sK=n(EHe,"A",{href:!0});var Soa=s(sK);tMr=r(Soa,"RemBertForTokenClassification"),Soa.forEach(t),aMr=r(EHe," (RemBERT model)"),EHe.forEach(t),nMr=i(J),t4=n(J,"LI",{});var CHe=s(t4);z3e=n(CHe,"STRONG",{});var Roa=s(z3e);sMr=r(Roa,"roberta"),Roa.forEach(t),lMr=r(CHe," \u2014 "),lK=n(CHe,"A",{href:!0});var Poa=s(lK);iMr=r(Poa,"RobertaForTokenClassification"),Poa.forEach(t),dMr=r(CHe," (RoBERTa model)"),CHe.forEach(t),mMr=i(J),a4=n(J,"LI",{});var wHe=s(a4);Q3e=n(wHe,"STRONG",{});var Boa=s(Q3e);cMr=r(Boa,"roc_bert"),Boa.forEach(t),fMr=r(wHe," \u2014 "),iK=n(wHe,"A",{href:!0});var Ioa=s(iK);gMr=r(Ioa,"RoCBertForTokenClassification"),Ioa.forEach(t),hMr=r(wHe," (RoCBert model)"),wHe.forEach(t),uMr=i(J),n4=n(J,"LI",{});var AHe=s(n4);W3e=n(AHe,"STRONG",{});var Noa=s(W3e);pMr=r(Noa,"roformer"),Noa.forEach(t),_Mr=r(AHe," \u2014 "),dK=n(AHe,"A",{href:!0});var qoa=s(dK);bMr=r(qoa,"RoFormerForTokenClassification"),qoa.forEach(t),vMr=r(AHe," (RoFormer model)"),AHe.forEach(t),FMr=i(J),s4=n(J,"LI",{});var LHe=s(s4);U3e=n(LHe,"STRONG",{});var joa=s(U3e);TMr=r(joa,"squeezebert"),joa.forEach(t),MMr=r(LHe," \u2014 "),mK=n(LHe,"A",{href:!0});var Doa=s(mK);EMr=r(Doa,"SqueezeBertForTokenClassification"),Doa.forEach(t),CMr=r(LHe," (SqueezeBERT model)"),LHe.forEach(t),wMr=i(J),l4=n(J,"LI",{});var yHe=s(l4);H3e=n(yHe,"STRONG",{});var Goa=s(H3e);AMr=r(Goa,"xlm"),Goa.forEach(t),LMr=r(yHe," \u2014 "),cK=n(yHe,"A",{href:!0});var Ooa=s(cK);yMr=r(Ooa,"XLMForTokenClassification"),Ooa.forEach(t),xMr=r(yHe," (XLM model)"),yHe.forEach(t),$Mr=i(J),i4=n(J,"LI",{});var xHe=s(i4);J3e=n(xHe,"STRONG",{});var Voa=s(J3e);kMr=r(Voa,"xlm-roberta"),Voa.forEach(t),SMr=r(xHe," \u2014 "),fK=n(xHe,"A",{href:!0});var Xoa=s(fK);RMr=r(Xoa,"XLMRobertaForTokenClassification"),Xoa.forEach(t),PMr=r(xHe," (XLM-RoBERTa model)"),xHe.forEach(t),BMr=i(J),d4=n(J,"LI",{});var $He=s(d4);Y3e=n($He,"STRONG",{});var zoa=s(Y3e);IMr=r(zoa,"xlm-roberta-xl"),zoa.forEach(t),NMr=r($He," \u2014 "),gK=n($He,"A",{href:!0});var Qoa=s(gK);qMr=r(Qoa,"XLMRobertaXLForTokenClassification"),Qoa.forEach(t),jMr=r($He," (XLM-RoBERTa-XL model)"),$He.forEach(t),DMr=i(J),m4=n(J,"LI",{});var kHe=s(m4);Z3e=n(kHe,"STRONG",{});var Woa=s(Z3e);GMr=r(Woa,"xlnet"),Woa.forEach(t),OMr=r(kHe," \u2014 "),hK=n(kHe,"A",{href:!0});var Uoa=s(hK);VMr=r(Uoa,"XLNetForTokenClassification"),Uoa.forEach(t),XMr=r(kHe," (XLNet model)"),kHe.forEach(t),zMr=i(J),c4=n(J,"LI",{});var SHe=s(c4);K3e=n(SHe,"STRONG",{});var Hoa=s(K3e);QMr=r(Hoa,"yoso"),Hoa.forEach(t),WMr=r(SHe," \u2014 "),uK=n(SHe,"A",{href:!0});var Joa=s(uK);UMr=r(Joa,"YosoForTokenClassification"),Joa.forEach(t),HMr=r(SHe," (YOSO model)"),SHe.forEach(t),J.forEach(t),JMr=i(Ia),f4=n(Ia,"P",{});var RHe=s(f4);YMr=r(RHe,"The model is set in evaluation mode by default using "),e5e=n(RHe,"CODE",{});var Yoa=s(e5e);ZMr=r(Yoa,"model.eval()"),Yoa.forEach(t),KMr=r(RHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),o5e=n(RHe,"CODE",{});var Zoa=s(o5e);eEr=r(Zoa,"model.train()"),Zoa.forEach(t),RHe.forEach(t),oEr=i(Ia),T(g4.$$.fragment,Ia),Ia.forEach(t),Ul.forEach(t),lno=i(c),dm=n(c,"H2",{class:!0});var Alo=s(dm);h4=n(Alo,"A",{id:!0,class:!0,href:!0});var Koa=s(h4);r5e=n(Koa,"SPAN",{});var era=s(r5e);T(Qk.$$.fragment,era),era.forEach(t),Koa.forEach(t),rEr=i(Alo),t5e=n(Alo,"SPAN",{});var ora=s(t5e);tEr=r(ora,"AutoModelForQuestionAnswering"),ora.forEach(t),Alo.forEach(t),ino=i(c),Qo=n(c,"DIV",{class:!0});var Hl=s(Qo);T(Wk.$$.fragment,Hl),aEr=i(Hl),mm=n(Hl,"P",{});var ece=s(mm);nEr=r(ece,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),pK=n(ece,"A",{href:!0});var rra=s(pK);sEr=r(rra,"from_pretrained()"),rra.forEach(t),lEr=r(ece," class method or the "),_K=n(ece,"A",{href:!0});var tra=s(_K);iEr=r(tra,"from_config()"),tra.forEach(t),dEr=r(ece,` class
method.`),ece.forEach(t),mEr=i(Hl),Uk=n(Hl,"P",{});var Llo=s(Uk);cEr=r(Llo,"This class cannot be instantiated directly using "),a5e=n(Llo,"CODE",{});var ara=s(a5e);fEr=r(ara,"__init__()"),ara.forEach(t),gEr=r(Llo," (throws an error)."),Llo.forEach(t),hEr=i(Hl),St=n(Hl,"DIV",{class:!0});var P9=s(St);T(Hk.$$.fragment,P9),uEr=i(P9),n5e=n(P9,"P",{});var nra=s(n5e);pEr=r(nra,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),nra.forEach(t),_Er=i(P9),cm=n(P9,"P",{});var oce=s(cm);bEr=r(oce,`Note:
Loading a model from its configuration file does `),s5e=n(oce,"STRONG",{});var sra=s(s5e);vEr=r(sra,"not"),sra.forEach(t),FEr=r(oce,` load the model weights. It only affects the
model\u2019s configuration. Use `),bK=n(oce,"A",{href:!0});var lra=s(bK);TEr=r(lra,"from_pretrained()"),lra.forEach(t),MEr=r(oce," to load the model weights."),oce.forEach(t),EEr=i(P9),T(u4.$$.fragment,P9),P9.forEach(t),CEr=i(Hl),mo=n(Hl,"DIV",{class:!0});var Na=s(mo);T(Jk.$$.fragment,Na),wEr=i(Na),l5e=n(Na,"P",{});var ira=s(l5e);AEr=r(ira,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),ira.forEach(t),LEr=i(Na),pn=n(Na,"P",{});var B9=s(pn);yEr=r(B9,"The model class to instantiate is selected based on the "),i5e=n(B9,"CODE",{});var dra=s(i5e);xEr=r(dra,"model_type"),dra.forEach(t),$Er=r(B9,` property of the config object (either
passed as an argument or loaded from `),d5e=n(B9,"CODE",{});var mra=s(d5e);kEr=r(mra,"pretrained_model_name_or_path"),mra.forEach(t),SEr=r(B9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m5e=n(B9,"CODE",{});var cra=s(m5e);REr=r(cra,"pretrained_model_name_or_path"),cra.forEach(t),PEr=r(B9,":"),B9.forEach(t),BEr=i(Na),O=n(Na,"UL",{});var X=s(O);p4=n(X,"LI",{});var PHe=s(p4);c5e=n(PHe,"STRONG",{});var fra=s(c5e);IEr=r(fra,"albert"),fra.forEach(t),NEr=r(PHe," \u2014 "),vK=n(PHe,"A",{href:!0});var gra=s(vK);qEr=r(gra,"AlbertForQuestionAnswering"),gra.forEach(t),jEr=r(PHe," (ALBERT model)"),PHe.forEach(t),DEr=i(X),_4=n(X,"LI",{});var BHe=s(_4);f5e=n(BHe,"STRONG",{});var hra=s(f5e);GEr=r(hra,"bart"),hra.forEach(t),OEr=r(BHe," \u2014 "),FK=n(BHe,"A",{href:!0});var ura=s(FK);VEr=r(ura,"BartForQuestionAnswering"),ura.forEach(t),XEr=r(BHe," (BART model)"),BHe.forEach(t),zEr=i(X),b4=n(X,"LI",{});var IHe=s(b4);g5e=n(IHe,"STRONG",{});var pra=s(g5e);QEr=r(pra,"bert"),pra.forEach(t),WEr=r(IHe," \u2014 "),TK=n(IHe,"A",{href:!0});var _ra=s(TK);UEr=r(_ra,"BertForQuestionAnswering"),_ra.forEach(t),HEr=r(IHe," (BERT model)"),IHe.forEach(t),JEr=i(X),v4=n(X,"LI",{});var NHe=s(v4);h5e=n(NHe,"STRONG",{});var bra=s(h5e);YEr=r(bra,"big_bird"),bra.forEach(t),ZEr=r(NHe," \u2014 "),MK=n(NHe,"A",{href:!0});var vra=s(MK);KEr=r(vra,"BigBirdForQuestionAnswering"),vra.forEach(t),e4r=r(NHe," (BigBird model)"),NHe.forEach(t),o4r=i(X),F4=n(X,"LI",{});var qHe=s(F4);u5e=n(qHe,"STRONG",{});var Fra=s(u5e);r4r=r(Fra,"bigbird_pegasus"),Fra.forEach(t),t4r=r(qHe," \u2014 "),EK=n(qHe,"A",{href:!0});var Tra=s(EK);a4r=r(Tra,"BigBirdPegasusForQuestionAnswering"),Tra.forEach(t),n4r=r(qHe," (BigBird-Pegasus model)"),qHe.forEach(t),s4r=i(X),T4=n(X,"LI",{});var jHe=s(T4);p5e=n(jHe,"STRONG",{});var Mra=s(p5e);l4r=r(Mra,"bloom"),Mra.forEach(t),i4r=r(jHe," \u2014 "),CK=n(jHe,"A",{href:!0});var Era=s(CK);d4r=r(Era,"BloomForQuestionAnswering"),Era.forEach(t),m4r=r(jHe," (BLOOM model)"),jHe.forEach(t),c4r=i(X),M4=n(X,"LI",{});var DHe=s(M4);_5e=n(DHe,"STRONG",{});var Cra=s(_5e);f4r=r(Cra,"camembert"),Cra.forEach(t),g4r=r(DHe," \u2014 "),wK=n(DHe,"A",{href:!0});var wra=s(wK);h4r=r(wra,"CamembertForQuestionAnswering"),wra.forEach(t),u4r=r(DHe," (CamemBERT model)"),DHe.forEach(t),p4r=i(X),E4=n(X,"LI",{});var GHe=s(E4);b5e=n(GHe,"STRONG",{});var Ara=s(b5e);_4r=r(Ara,"canine"),Ara.forEach(t),b4r=r(GHe," \u2014 "),AK=n(GHe,"A",{href:!0});var Lra=s(AK);v4r=r(Lra,"CanineForQuestionAnswering"),Lra.forEach(t),F4r=r(GHe," (CANINE model)"),GHe.forEach(t),T4r=i(X),C4=n(X,"LI",{});var OHe=s(C4);v5e=n(OHe,"STRONG",{});var yra=s(v5e);M4r=r(yra,"convbert"),yra.forEach(t),E4r=r(OHe," \u2014 "),LK=n(OHe,"A",{href:!0});var xra=s(LK);C4r=r(xra,"ConvBertForQuestionAnswering"),xra.forEach(t),w4r=r(OHe," (ConvBERT model)"),OHe.forEach(t),A4r=i(X),w4=n(X,"LI",{});var VHe=s(w4);F5e=n(VHe,"STRONG",{});var $ra=s(F5e);L4r=r($ra,"data2vec-text"),$ra.forEach(t),y4r=r(VHe," \u2014 "),yK=n(VHe,"A",{href:!0});var kra=s(yK);x4r=r(kra,"Data2VecTextForQuestionAnswering"),kra.forEach(t),$4r=r(VHe," (Data2VecText model)"),VHe.forEach(t),k4r=i(X),A4=n(X,"LI",{});var XHe=s(A4);T5e=n(XHe,"STRONG",{});var Sra=s(T5e);S4r=r(Sra,"deberta"),Sra.forEach(t),R4r=r(XHe," \u2014 "),xK=n(XHe,"A",{href:!0});var Rra=s(xK);P4r=r(Rra,"DebertaForQuestionAnswering"),Rra.forEach(t),B4r=r(XHe," (DeBERTa model)"),XHe.forEach(t),I4r=i(X),L4=n(X,"LI",{});var zHe=s(L4);M5e=n(zHe,"STRONG",{});var Pra=s(M5e);N4r=r(Pra,"deberta-v2"),Pra.forEach(t),q4r=r(zHe," \u2014 "),$K=n(zHe,"A",{href:!0});var Bra=s($K);j4r=r(Bra,"DebertaV2ForQuestionAnswering"),Bra.forEach(t),D4r=r(zHe," (DeBERTa-v2 model)"),zHe.forEach(t),G4r=i(X),y4=n(X,"LI",{});var QHe=s(y4);E5e=n(QHe,"STRONG",{});var Ira=s(E5e);O4r=r(Ira,"distilbert"),Ira.forEach(t),V4r=r(QHe," \u2014 "),kK=n(QHe,"A",{href:!0});var Nra=s(kK);X4r=r(Nra,"DistilBertForQuestionAnswering"),Nra.forEach(t),z4r=r(QHe," (DistilBERT model)"),QHe.forEach(t),Q4r=i(X),x4=n(X,"LI",{});var WHe=s(x4);C5e=n(WHe,"STRONG",{});var qra=s(C5e);W4r=r(qra,"electra"),qra.forEach(t),U4r=r(WHe," \u2014 "),SK=n(WHe,"A",{href:!0});var jra=s(SK);H4r=r(jra,"ElectraForQuestionAnswering"),jra.forEach(t),J4r=r(WHe," (ELECTRA model)"),WHe.forEach(t),Y4r=i(X),$4=n(X,"LI",{});var UHe=s($4);w5e=n(UHe,"STRONG",{});var Dra=s(w5e);Z4r=r(Dra,"ernie"),Dra.forEach(t),K4r=r(UHe," \u2014 "),RK=n(UHe,"A",{href:!0});var Gra=s(RK);eCr=r(Gra,"ErnieForQuestionAnswering"),Gra.forEach(t),oCr=r(UHe," (ERNIE model)"),UHe.forEach(t),rCr=i(X),k4=n(X,"LI",{});var HHe=s(k4);A5e=n(HHe,"STRONG",{});var Ora=s(A5e);tCr=r(Ora,"flaubert"),Ora.forEach(t),aCr=r(HHe," \u2014 "),PK=n(HHe,"A",{href:!0});var Vra=s(PK);nCr=r(Vra,"FlaubertForQuestionAnsweringSimple"),Vra.forEach(t),sCr=r(HHe," (FlauBERT model)"),HHe.forEach(t),lCr=i(X),S4=n(X,"LI",{});var JHe=s(S4);L5e=n(JHe,"STRONG",{});var Xra=s(L5e);iCr=r(Xra,"fnet"),Xra.forEach(t),dCr=r(JHe," \u2014 "),BK=n(JHe,"A",{href:!0});var zra=s(BK);mCr=r(zra,"FNetForQuestionAnswering"),zra.forEach(t),cCr=r(JHe," (FNet model)"),JHe.forEach(t),fCr=i(X),R4=n(X,"LI",{});var YHe=s(R4);y5e=n(YHe,"STRONG",{});var Qra=s(y5e);gCr=r(Qra,"funnel"),Qra.forEach(t),hCr=r(YHe," \u2014 "),IK=n(YHe,"A",{href:!0});var Wra=s(IK);uCr=r(Wra,"FunnelForQuestionAnswering"),Wra.forEach(t),pCr=r(YHe," (Funnel Transformer model)"),YHe.forEach(t),_Cr=i(X),P4=n(X,"LI",{});var ZHe=s(P4);x5e=n(ZHe,"STRONG",{});var Ura=s(x5e);bCr=r(Ura,"gptj"),Ura.forEach(t),vCr=r(ZHe," \u2014 "),NK=n(ZHe,"A",{href:!0});var Hra=s(NK);FCr=r(Hra,"GPTJForQuestionAnswering"),Hra.forEach(t),TCr=r(ZHe," (GPT-J model)"),ZHe.forEach(t),MCr=i(X),B4=n(X,"LI",{});var KHe=s(B4);$5e=n(KHe,"STRONG",{});var Jra=s($5e);ECr=r(Jra,"ibert"),Jra.forEach(t),CCr=r(KHe," \u2014 "),qK=n(KHe,"A",{href:!0});var Yra=s(qK);wCr=r(Yra,"IBertForQuestionAnswering"),Yra.forEach(t),ACr=r(KHe," (I-BERT model)"),KHe.forEach(t),LCr=i(X),I4=n(X,"LI",{});var eJe=s(I4);k5e=n(eJe,"STRONG",{});var Zra=s(k5e);yCr=r(Zra,"layoutlmv2"),Zra.forEach(t),xCr=r(eJe," \u2014 "),jK=n(eJe,"A",{href:!0});var Kra=s(jK);$Cr=r(Kra,"LayoutLMv2ForQuestionAnswering"),Kra.forEach(t),kCr=r(eJe," (LayoutLMv2 model)"),eJe.forEach(t),SCr=i(X),N4=n(X,"LI",{});var oJe=s(N4);S5e=n(oJe,"STRONG",{});var eta=s(S5e);RCr=r(eta,"layoutlmv3"),eta.forEach(t),PCr=r(oJe," \u2014 "),DK=n(oJe,"A",{href:!0});var ota=s(DK);BCr=r(ota,"LayoutLMv3ForQuestionAnswering"),ota.forEach(t),ICr=r(oJe," (LayoutLMv3 model)"),oJe.forEach(t),NCr=i(X),q4=n(X,"LI",{});var rJe=s(q4);R5e=n(rJe,"STRONG",{});var rta=s(R5e);qCr=r(rta,"led"),rta.forEach(t),jCr=r(rJe," \u2014 "),GK=n(rJe,"A",{href:!0});var tta=s(GK);DCr=r(tta,"LEDForQuestionAnswering"),tta.forEach(t),GCr=r(rJe," (LED model)"),rJe.forEach(t),OCr=i(X),j4=n(X,"LI",{});var tJe=s(j4);P5e=n(tJe,"STRONG",{});var ata=s(P5e);VCr=r(ata,"lilt"),ata.forEach(t),XCr=r(tJe," \u2014 "),OK=n(tJe,"A",{href:!0});var nta=s(OK);zCr=r(nta,"LiltForQuestionAnswering"),nta.forEach(t),QCr=r(tJe," (LiLT model)"),tJe.forEach(t),WCr=i(X),D4=n(X,"LI",{});var aJe=s(D4);B5e=n(aJe,"STRONG",{});var sta=s(B5e);UCr=r(sta,"longformer"),sta.forEach(t),HCr=r(aJe," \u2014 "),VK=n(aJe,"A",{href:!0});var lta=s(VK);JCr=r(lta,"LongformerForQuestionAnswering"),lta.forEach(t),YCr=r(aJe," (Longformer model)"),aJe.forEach(t),ZCr=i(X),G4=n(X,"LI",{});var nJe=s(G4);I5e=n(nJe,"STRONG",{});var ita=s(I5e);KCr=r(ita,"luke"),ita.forEach(t),e3r=r(nJe," \u2014 "),XK=n(nJe,"A",{href:!0});var dta=s(XK);o3r=r(dta,"LukeForQuestionAnswering"),dta.forEach(t),r3r=r(nJe," (LUKE model)"),nJe.forEach(t),t3r=i(X),O4=n(X,"LI",{});var sJe=s(O4);N5e=n(sJe,"STRONG",{});var mta=s(N5e);a3r=r(mta,"lxmert"),mta.forEach(t),n3r=r(sJe," \u2014 "),zK=n(sJe,"A",{href:!0});var cta=s(zK);s3r=r(cta,"LxmertForQuestionAnswering"),cta.forEach(t),l3r=r(sJe," (LXMERT model)"),sJe.forEach(t),i3r=i(X),V4=n(X,"LI",{});var lJe=s(V4);q5e=n(lJe,"STRONG",{});var fta=s(q5e);d3r=r(fta,"markuplm"),fta.forEach(t),m3r=r(lJe," \u2014 "),QK=n(lJe,"A",{href:!0});var gta=s(QK);c3r=r(gta,"MarkupLMForQuestionAnswering"),gta.forEach(t),f3r=r(lJe," (MarkupLM model)"),lJe.forEach(t),g3r=i(X),X4=n(X,"LI",{});var iJe=s(X4);j5e=n(iJe,"STRONG",{});var hta=s(j5e);h3r=r(hta,"mbart"),hta.forEach(t),u3r=r(iJe," \u2014 "),WK=n(iJe,"A",{href:!0});var uta=s(WK);p3r=r(uta,"MBartForQuestionAnswering"),uta.forEach(t),_3r=r(iJe," (mBART model)"),iJe.forEach(t),b3r=i(X),z4=n(X,"LI",{});var dJe=s(z4);D5e=n(dJe,"STRONG",{});var pta=s(D5e);v3r=r(pta,"megatron-bert"),pta.forEach(t),F3r=r(dJe," \u2014 "),UK=n(dJe,"A",{href:!0});var _ta=s(UK);T3r=r(_ta,"MegatronBertForQuestionAnswering"),_ta.forEach(t),M3r=r(dJe," (Megatron-BERT model)"),dJe.forEach(t),E3r=i(X),Q4=n(X,"LI",{});var mJe=s(Q4);G5e=n(mJe,"STRONG",{});var bta=s(G5e);C3r=r(bta,"mobilebert"),bta.forEach(t),w3r=r(mJe," \u2014 "),HK=n(mJe,"A",{href:!0});var vta=s(HK);A3r=r(vta,"MobileBertForQuestionAnswering"),vta.forEach(t),L3r=r(mJe," (MobileBERT model)"),mJe.forEach(t),y3r=i(X),W4=n(X,"LI",{});var cJe=s(W4);O5e=n(cJe,"STRONG",{});var Fta=s(O5e);x3r=r(Fta,"mpnet"),Fta.forEach(t),$3r=r(cJe," \u2014 "),JK=n(cJe,"A",{href:!0});var Tta=s(JK);k3r=r(Tta,"MPNetForQuestionAnswering"),Tta.forEach(t),S3r=r(cJe," (MPNet model)"),cJe.forEach(t),R3r=i(X),U4=n(X,"LI",{});var fJe=s(U4);V5e=n(fJe,"STRONG",{});var Mta=s(V5e);P3r=r(Mta,"mvp"),Mta.forEach(t),B3r=r(fJe," \u2014 "),YK=n(fJe,"A",{href:!0});var Eta=s(YK);I3r=r(Eta,"MvpForQuestionAnswering"),Eta.forEach(t),N3r=r(fJe," (MVP model)"),fJe.forEach(t),q3r=i(X),H4=n(X,"LI",{});var gJe=s(H4);X5e=n(gJe,"STRONG",{});var Cta=s(X5e);j3r=r(Cta,"nezha"),Cta.forEach(t),D3r=r(gJe," \u2014 "),ZK=n(gJe,"A",{href:!0});var wta=s(ZK);G3r=r(wta,"NezhaForQuestionAnswering"),wta.forEach(t),O3r=r(gJe," (Nezha model)"),gJe.forEach(t),V3r=i(X),J4=n(X,"LI",{});var hJe=s(J4);z5e=n(hJe,"STRONG",{});var Ata=s(z5e);X3r=r(Ata,"nystromformer"),Ata.forEach(t),z3r=r(hJe," \u2014 "),KK=n(hJe,"A",{href:!0});var Lta=s(KK);Q3r=r(Lta,"NystromformerForQuestionAnswering"),Lta.forEach(t),W3r=r(hJe," (Nystr\xF6mformer model)"),hJe.forEach(t),U3r=i(X),Y4=n(X,"LI",{});var uJe=s(Y4);Q5e=n(uJe,"STRONG",{});var yta=s(Q5e);H3r=r(yta,"opt"),yta.forEach(t),J3r=r(uJe," \u2014 "),eee=n(uJe,"A",{href:!0});var xta=s(eee);Y3r=r(xta,"OPTForQuestionAnswering"),xta.forEach(t),Z3r=r(uJe," (OPT model)"),uJe.forEach(t),K3r=i(X),Z4=n(X,"LI",{});var pJe=s(Z4);W5e=n(pJe,"STRONG",{});var $ta=s(W5e);e5r=r($ta,"qdqbert"),$ta.forEach(t),o5r=r(pJe," \u2014 "),oee=n(pJe,"A",{href:!0});var kta=s(oee);r5r=r(kta,"QDQBertForQuestionAnswering"),kta.forEach(t),t5r=r(pJe," (QDQBert model)"),pJe.forEach(t),a5r=i(X),K4=n(X,"LI",{});var _Je=s(K4);U5e=n(_Je,"STRONG",{});var Sta=s(U5e);n5r=r(Sta,"reformer"),Sta.forEach(t),s5r=r(_Je," \u2014 "),ree=n(_Je,"A",{href:!0});var Rta=s(ree);l5r=r(Rta,"ReformerForQuestionAnswering"),Rta.forEach(t),i5r=r(_Je," (Reformer model)"),_Je.forEach(t),d5r=i(X),eC=n(X,"LI",{});var bJe=s(eC);H5e=n(bJe,"STRONG",{});var Pta=s(H5e);m5r=r(Pta,"rembert"),Pta.forEach(t),c5r=r(bJe," \u2014 "),tee=n(bJe,"A",{href:!0});var Bta=s(tee);f5r=r(Bta,"RemBertForQuestionAnswering"),Bta.forEach(t),g5r=r(bJe," (RemBERT model)"),bJe.forEach(t),h5r=i(X),oC=n(X,"LI",{});var vJe=s(oC);J5e=n(vJe,"STRONG",{});var Ita=s(J5e);u5r=r(Ita,"roberta"),Ita.forEach(t),p5r=r(vJe," \u2014 "),aee=n(vJe,"A",{href:!0});var Nta=s(aee);_5r=r(Nta,"RobertaForQuestionAnswering"),Nta.forEach(t),b5r=r(vJe," (RoBERTa model)"),vJe.forEach(t),v5r=i(X),rC=n(X,"LI",{});var FJe=s(rC);Y5e=n(FJe,"STRONG",{});var qta=s(Y5e);F5r=r(qta,"roc_bert"),qta.forEach(t),T5r=r(FJe," \u2014 "),nee=n(FJe,"A",{href:!0});var jta=s(nee);M5r=r(jta,"RoCBertForQuestionAnswering"),jta.forEach(t),E5r=r(FJe," (RoCBert model)"),FJe.forEach(t),C5r=i(X),tC=n(X,"LI",{});var TJe=s(tC);Z5e=n(TJe,"STRONG",{});var Dta=s(Z5e);w5r=r(Dta,"roformer"),Dta.forEach(t),A5r=r(TJe," \u2014 "),see=n(TJe,"A",{href:!0});var Gta=s(see);L5r=r(Gta,"RoFormerForQuestionAnswering"),Gta.forEach(t),y5r=r(TJe," (RoFormer model)"),TJe.forEach(t),x5r=i(X),aC=n(X,"LI",{});var MJe=s(aC);K5e=n(MJe,"STRONG",{});var Ota=s(K5e);$5r=r(Ota,"splinter"),Ota.forEach(t),k5r=r(MJe," \u2014 "),lee=n(MJe,"A",{href:!0});var Vta=s(lee);S5r=r(Vta,"SplinterForQuestionAnswering"),Vta.forEach(t),R5r=r(MJe," (Splinter model)"),MJe.forEach(t),P5r=i(X),nC=n(X,"LI",{});var EJe=s(nC);e0e=n(EJe,"STRONG",{});var Xta=s(e0e);B5r=r(Xta,"squeezebert"),Xta.forEach(t),I5r=r(EJe," \u2014 "),iee=n(EJe,"A",{href:!0});var zta=s(iee);N5r=r(zta,"SqueezeBertForQuestionAnswering"),zta.forEach(t),q5r=r(EJe," (SqueezeBERT model)"),EJe.forEach(t),j5r=i(X),sC=n(X,"LI",{});var CJe=s(sC);o0e=n(CJe,"STRONG",{});var Qta=s(o0e);D5r=r(Qta,"xlm"),Qta.forEach(t),G5r=r(CJe," \u2014 "),dee=n(CJe,"A",{href:!0});var Wta=s(dee);O5r=r(Wta,"XLMForQuestionAnsweringSimple"),Wta.forEach(t),V5r=r(CJe," (XLM model)"),CJe.forEach(t),X5r=i(X),lC=n(X,"LI",{});var wJe=s(lC);r0e=n(wJe,"STRONG",{});var Uta=s(r0e);z5r=r(Uta,"xlm-roberta"),Uta.forEach(t),Q5r=r(wJe," \u2014 "),mee=n(wJe,"A",{href:!0});var Hta=s(mee);W5r=r(Hta,"XLMRobertaForQuestionAnswering"),Hta.forEach(t),U5r=r(wJe," (XLM-RoBERTa model)"),wJe.forEach(t),H5r=i(X),iC=n(X,"LI",{});var AJe=s(iC);t0e=n(AJe,"STRONG",{});var Jta=s(t0e);J5r=r(Jta,"xlm-roberta-xl"),Jta.forEach(t),Y5r=r(AJe," \u2014 "),cee=n(AJe,"A",{href:!0});var Yta=s(cee);Z5r=r(Yta,"XLMRobertaXLForQuestionAnswering"),Yta.forEach(t),K5r=r(AJe," (XLM-RoBERTa-XL model)"),AJe.forEach(t),e0r=i(X),dC=n(X,"LI",{});var LJe=s(dC);a0e=n(LJe,"STRONG",{});var Zta=s(a0e);o0r=r(Zta,"xlnet"),Zta.forEach(t),r0r=r(LJe," \u2014 "),fee=n(LJe,"A",{href:!0});var Kta=s(fee);t0r=r(Kta,"XLNetForQuestionAnsweringSimple"),Kta.forEach(t),a0r=r(LJe," (XLNet model)"),LJe.forEach(t),n0r=i(X),mC=n(X,"LI",{});var yJe=s(mC);n0e=n(yJe,"STRONG",{});var eaa=s(n0e);s0r=r(eaa,"yoso"),eaa.forEach(t),l0r=r(yJe," \u2014 "),gee=n(yJe,"A",{href:!0});var oaa=s(gee);i0r=r(oaa,"YosoForQuestionAnswering"),oaa.forEach(t),d0r=r(yJe," (YOSO model)"),yJe.forEach(t),X.forEach(t),m0r=i(Na),cC=n(Na,"P",{});var xJe=s(cC);c0r=r(xJe,"The model is set in evaluation mode by default using "),s0e=n(xJe,"CODE",{});var raa=s(s0e);f0r=r(raa,"model.eval()"),raa.forEach(t),g0r=r(xJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),l0e=n(xJe,"CODE",{});var taa=s(l0e);h0r=r(taa,"model.train()"),taa.forEach(t),xJe.forEach(t),u0r=i(Na),T(fC.$$.fragment,Na),Na.forEach(t),Hl.forEach(t),dno=i(c),fm=n(c,"H2",{class:!0});var ylo=s(fm);gC=n(ylo,"A",{id:!0,class:!0,href:!0});var aaa=s(gC);i0e=n(aaa,"SPAN",{});var naa=s(i0e);T(Yk.$$.fragment,naa),naa.forEach(t),aaa.forEach(t),p0r=i(ylo),d0e=n(ylo,"SPAN",{});var saa=s(d0e);_0r=r(saa,"AutoModelForTableQuestionAnswering"),saa.forEach(t),ylo.forEach(t),mno=i(c),Wo=n(c,"DIV",{class:!0});var Jl=s(Wo);T(Zk.$$.fragment,Jl),b0r=i(Jl),gm=n(Jl,"P",{});var rce=s(gm);v0r=r(rce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),hee=n(rce,"A",{href:!0});var laa=s(hee);F0r=r(laa,"from_pretrained()"),laa.forEach(t),T0r=r(rce," class method or the "),uee=n(rce,"A",{href:!0});var iaa=s(uee);M0r=r(iaa,"from_config()"),iaa.forEach(t),E0r=r(rce,` class
method.`),rce.forEach(t),C0r=i(Jl),Kk=n(Jl,"P",{});var xlo=s(Kk);w0r=r(xlo,"This class cannot be instantiated directly using "),m0e=n(xlo,"CODE",{});var daa=s(m0e);A0r=r(daa,"__init__()"),daa.forEach(t),L0r=r(xlo," (throws an error)."),xlo.forEach(t),y0r=i(Jl),Rt=n(Jl,"DIV",{class:!0});var I9=s(Rt);T(eS.$$.fragment,I9),x0r=i(I9),c0e=n(I9,"P",{});var maa=s(c0e);$0r=r(maa,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),maa.forEach(t),k0r=i(I9),hm=n(I9,"P",{});var tce=s(hm);S0r=r(tce,`Note:
Loading a model from its configuration file does `),f0e=n(tce,"STRONG",{});var caa=s(f0e);R0r=r(caa,"not"),caa.forEach(t),P0r=r(tce,` load the model weights. It only affects the
model\u2019s configuration. Use `),pee=n(tce,"A",{href:!0});var faa=s(pee);B0r=r(faa,"from_pretrained()"),faa.forEach(t),I0r=r(tce," to load the model weights."),tce.forEach(t),N0r=i(I9),T(hC.$$.fragment,I9),I9.forEach(t),q0r=i(Jl),co=n(Jl,"DIV",{class:!0});var qa=s(co);T(oS.$$.fragment,qa),j0r=i(qa),g0e=n(qa,"P",{});var gaa=s(g0e);D0r=r(gaa,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),gaa.forEach(t),G0r=i(qa),_n=n(qa,"P",{});var N9=s(_n);O0r=r(N9,"The model class to instantiate is selected based on the "),h0e=n(N9,"CODE",{});var haa=s(h0e);V0r=r(haa,"model_type"),haa.forEach(t),X0r=r(N9,` property of the config object (either
passed as an argument or loaded from `),u0e=n(N9,"CODE",{});var uaa=s(u0e);z0r=r(uaa,"pretrained_model_name_or_path"),uaa.forEach(t),Q0r=r(N9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p0e=n(N9,"CODE",{});var paa=s(p0e);W0r=r(paa,"pretrained_model_name_or_path"),paa.forEach(t),U0r=r(N9,":"),N9.forEach(t),H0r=i(qa),_0e=n(qa,"UL",{});var _aa=s(_0e);uC=n(_aa,"LI",{});var $Je=s(uC);b0e=n($Je,"STRONG",{});var baa=s(b0e);J0r=r(baa,"tapas"),baa.forEach(t),Y0r=r($Je," \u2014 "),_ee=n($Je,"A",{href:!0});var vaa=s(_ee);Z0r=r(vaa,"TapasForQuestionAnswering"),vaa.forEach(t),K0r=r($Je," (TAPAS model)"),$Je.forEach(t),_aa.forEach(t),ewr=i(qa),pC=n(qa,"P",{});var kJe=s(pC);owr=r(kJe,"The model is set in evaluation mode by default using "),v0e=n(kJe,"CODE",{});var Faa=s(v0e);rwr=r(Faa,"model.eval()"),Faa.forEach(t),twr=r(kJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),F0e=n(kJe,"CODE",{});var Taa=s(F0e);awr=r(Taa,"model.train()"),Taa.forEach(t),kJe.forEach(t),nwr=i(qa),T(_C.$$.fragment,qa),qa.forEach(t),Jl.forEach(t),cno=i(c),um=n(c,"H2",{class:!0});var $lo=s(um);bC=n($lo,"A",{id:!0,class:!0,href:!0});var Maa=s(bC);T0e=n(Maa,"SPAN",{});var Eaa=s(T0e);T(rS.$$.fragment,Eaa),Eaa.forEach(t),Maa.forEach(t),swr=i($lo),M0e=n($lo,"SPAN",{});var Caa=s(M0e);lwr=r(Caa,"AutoModelForDocumentQuestionAnswering"),Caa.forEach(t),$lo.forEach(t),fno=i(c),Uo=n(c,"DIV",{class:!0});var Yl=s(Uo);T(tS.$$.fragment,Yl),iwr=i(Yl),pm=n(Yl,"P",{});var ace=s(pm);dwr=r(ace,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),bee=n(ace,"A",{href:!0});var waa=s(bee);mwr=r(waa,"from_pretrained()"),waa.forEach(t),cwr=r(ace," class method or the "),vee=n(ace,"A",{href:!0});var Aaa=s(vee);fwr=r(Aaa,"from_config()"),Aaa.forEach(t),gwr=r(ace,` class
method.`),ace.forEach(t),hwr=i(Yl),aS=n(Yl,"P",{});var klo=s(aS);uwr=r(klo,"This class cannot be instantiated directly using "),E0e=n(klo,"CODE",{});var Laa=s(E0e);pwr=r(Laa,"__init__()"),Laa.forEach(t),_wr=r(klo," (throws an error)."),klo.forEach(t),bwr=i(Yl),Pt=n(Yl,"DIV",{class:!0});var q9=s(Pt);T(nS.$$.fragment,q9),vwr=i(q9),C0e=n(q9,"P",{});var yaa=s(C0e);Fwr=r(yaa,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),yaa.forEach(t),Twr=i(q9),_m=n(q9,"P",{});var nce=s(_m);Mwr=r(nce,`Note:
Loading a model from its configuration file does `),w0e=n(nce,"STRONG",{});var xaa=s(w0e);Ewr=r(xaa,"not"),xaa.forEach(t),Cwr=r(nce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Fee=n(nce,"A",{href:!0});var $aa=s(Fee);wwr=r($aa,"from_pretrained()"),$aa.forEach(t),Awr=r(nce," to load the model weights."),nce.forEach(t),Lwr=i(q9),T(vC.$$.fragment,q9),q9.forEach(t),ywr=i(Yl),fo=n(Yl,"DIV",{class:!0});var ja=s(fo);T(sS.$$.fragment,ja),xwr=i(ja),A0e=n(ja,"P",{});var kaa=s(A0e);$wr=r(kaa,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),kaa.forEach(t),kwr=i(ja),bn=n(ja,"P",{});var j9=s(bn);Swr=r(j9,"The model class to instantiate is selected based on the "),L0e=n(j9,"CODE",{});var Saa=s(L0e);Rwr=r(Saa,"model_type"),Saa.forEach(t),Pwr=r(j9,` property of the config object (either
passed as an argument or loaded from `),y0e=n(j9,"CODE",{});var Raa=s(y0e);Bwr=r(Raa,"pretrained_model_name_or_path"),Raa.forEach(t),Iwr=r(j9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x0e=n(j9,"CODE",{});var Paa=s(x0e);Nwr=r(Paa,"pretrained_model_name_or_path"),Paa.forEach(t),qwr=r(j9,":"),j9.forEach(t),jwr=i(ja),bm=n(ja,"UL",{});var sce=s(bm);FC=n(sce,"LI",{});var SJe=s(FC);$0e=n(SJe,"STRONG",{});var Baa=s($0e);Dwr=r(Baa,"layoutlm"),Baa.forEach(t),Gwr=r(SJe," \u2014 "),Tee=n(SJe,"A",{href:!0});var Iaa=s(Tee);Owr=r(Iaa,"LayoutLMForQuestionAnswering"),Iaa.forEach(t),Vwr=r(SJe," (LayoutLM model)"),SJe.forEach(t),Xwr=i(sce),TC=n(sce,"LI",{});var RJe=s(TC);k0e=n(RJe,"STRONG",{});var Naa=s(k0e);zwr=r(Naa,"layoutlmv2"),Naa.forEach(t),Qwr=r(RJe," \u2014 "),Mee=n(RJe,"A",{href:!0});var qaa=s(Mee);Wwr=r(qaa,"LayoutLMv2ForQuestionAnswering"),qaa.forEach(t),Uwr=r(RJe," (LayoutLMv2 model)"),RJe.forEach(t),Hwr=i(sce),MC=n(sce,"LI",{});var PJe=s(MC);S0e=n(PJe,"STRONG",{});var jaa=s(S0e);Jwr=r(jaa,"layoutlmv3"),jaa.forEach(t),Ywr=r(PJe," \u2014 "),Eee=n(PJe,"A",{href:!0});var Daa=s(Eee);Zwr=r(Daa,"LayoutLMv3ForQuestionAnswering"),Daa.forEach(t),Kwr=r(PJe," (LayoutLMv3 model)"),PJe.forEach(t),sce.forEach(t),eAr=i(ja),EC=n(ja,"P",{});var BJe=s(EC);oAr=r(BJe,"The model is set in evaluation mode by default using "),R0e=n(BJe,"CODE",{});var Gaa=s(R0e);rAr=r(Gaa,"model.eval()"),Gaa.forEach(t),tAr=r(BJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),P0e=n(BJe,"CODE",{});var Oaa=s(P0e);aAr=r(Oaa,"model.train()"),Oaa.forEach(t),BJe.forEach(t),nAr=i(ja),T(CC.$$.fragment,ja),ja.forEach(t),Yl.forEach(t),gno=i(c),vm=n(c,"H2",{class:!0});var Slo=s(vm);wC=n(Slo,"A",{id:!0,class:!0,href:!0});var Vaa=s(wC);B0e=n(Vaa,"SPAN",{});var Xaa=s(B0e);T(lS.$$.fragment,Xaa),Xaa.forEach(t),Vaa.forEach(t),sAr=i(Slo),I0e=n(Slo,"SPAN",{});var zaa=s(I0e);lAr=r(zaa,"AutoModelForImageClassification"),zaa.forEach(t),Slo.forEach(t),hno=i(c),Ho=n(c,"DIV",{class:!0});var Zl=s(Ho);T(iS.$$.fragment,Zl),iAr=i(Zl),Fm=n(Zl,"P",{});var lce=s(Fm);dAr=r(lce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Cee=n(lce,"A",{href:!0});var Qaa=s(Cee);mAr=r(Qaa,"from_pretrained()"),Qaa.forEach(t),cAr=r(lce," class method or the "),wee=n(lce,"A",{href:!0});var Waa=s(wee);fAr=r(Waa,"from_config()"),Waa.forEach(t),gAr=r(lce,` class
method.`),lce.forEach(t),hAr=i(Zl),dS=n(Zl,"P",{});var Rlo=s(dS);uAr=r(Rlo,"This class cannot be instantiated directly using "),N0e=n(Rlo,"CODE",{});var Uaa=s(N0e);pAr=r(Uaa,"__init__()"),Uaa.forEach(t),_Ar=r(Rlo," (throws an error)."),Rlo.forEach(t),bAr=i(Zl),Bt=n(Zl,"DIV",{class:!0});var D9=s(Bt);T(mS.$$.fragment,D9),vAr=i(D9),q0e=n(D9,"P",{});var Haa=s(q0e);FAr=r(Haa,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Haa.forEach(t),TAr=i(D9),Tm=n(D9,"P",{});var ice=s(Tm);MAr=r(ice,`Note:
Loading a model from its configuration file does `),j0e=n(ice,"STRONG",{});var Jaa=s(j0e);EAr=r(Jaa,"not"),Jaa.forEach(t),CAr=r(ice,` load the model weights. It only affects the
model\u2019s configuration. Use `),Aee=n(ice,"A",{href:!0});var Yaa=s(Aee);wAr=r(Yaa,"from_pretrained()"),Yaa.forEach(t),AAr=r(ice," to load the model weights."),ice.forEach(t),LAr=i(D9),T(AC.$$.fragment,D9),D9.forEach(t),yAr=i(Zl),go=n(Zl,"DIV",{class:!0});var Da=s(go);T(cS.$$.fragment,Da),xAr=i(Da),D0e=n(Da,"P",{});var Zaa=s(D0e);$Ar=r(Zaa,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Zaa.forEach(t),kAr=i(Da),vn=n(Da,"P",{});var G9=s(vn);SAr=r(G9,"The model class to instantiate is selected based on the "),G0e=n(G9,"CODE",{});var Kaa=s(G0e);RAr=r(Kaa,"model_type"),Kaa.forEach(t),PAr=r(G9,` property of the config object (either
passed as an argument or loaded from `),O0e=n(G9,"CODE",{});var ena=s(O0e);BAr=r(ena,"pretrained_model_name_or_path"),ena.forEach(t),IAr=r(G9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V0e=n(G9,"CODE",{});var ona=s(V0e);NAr=r(ona,"pretrained_model_name_or_path"),ona.forEach(t),qAr=r(G9,":"),G9.forEach(t),jAr=i(Da),be=n(Da,"UL",{});var Fe=s(be);LC=n(Fe,"LI",{});var IJe=s(LC);X0e=n(IJe,"STRONG",{});var rna=s(X0e);DAr=r(rna,"beit"),rna.forEach(t),GAr=r(IJe," \u2014 "),Lee=n(IJe,"A",{href:!0});var tna=s(Lee);OAr=r(tna,"BeitForImageClassification"),tna.forEach(t),VAr=r(IJe," (BEiT model)"),IJe.forEach(t),XAr=i(Fe),yC=n(Fe,"LI",{});var NJe=s(yC);z0e=n(NJe,"STRONG",{});var ana=s(z0e);zAr=r(ana,"convnext"),ana.forEach(t),QAr=r(NJe," \u2014 "),yee=n(NJe,"A",{href:!0});var nna=s(yee);WAr=r(nna,"ConvNextForImageClassification"),nna.forEach(t),UAr=r(NJe," (ConvNeXT model)"),NJe.forEach(t),HAr=i(Fe),xC=n(Fe,"LI",{});var qJe=s(xC);Q0e=n(qJe,"STRONG",{});var sna=s(Q0e);JAr=r(sna,"cvt"),sna.forEach(t),YAr=r(qJe," \u2014 "),xee=n(qJe,"A",{href:!0});var lna=s(xee);ZAr=r(lna,"CvtForImageClassification"),lna.forEach(t),KAr=r(qJe," (CvT model)"),qJe.forEach(t),e6r=i(Fe),$C=n(Fe,"LI",{});var jJe=s($C);W0e=n(jJe,"STRONG",{});var ina=s(W0e);o6r=r(ina,"data2vec-vision"),ina.forEach(t),r6r=r(jJe," \u2014 "),$ee=n(jJe,"A",{href:!0});var dna=s($ee);t6r=r(dna,"Data2VecVisionForImageClassification"),dna.forEach(t),a6r=r(jJe," (Data2VecVision model)"),jJe.forEach(t),n6r=i(Fe),kl=n(Fe,"LI",{});var RN=s(kl);U0e=n(RN,"STRONG",{});var mna=s(U0e);s6r=r(mna,"deit"),mna.forEach(t),l6r=r(RN," \u2014 "),kee=n(RN,"A",{href:!0});var cna=s(kee);i6r=r(cna,"DeiTForImageClassification"),cna.forEach(t),d6r=r(RN," or "),See=n(RN,"A",{href:!0});var fna=s(See);m6r=r(fna,"DeiTForImageClassificationWithTeacher"),fna.forEach(t),c6r=r(RN," (DeiT model)"),RN.forEach(t),f6r=i(Fe),kC=n(Fe,"LI",{});var DJe=s(kC);H0e=n(DJe,"STRONG",{});var gna=s(H0e);g6r=r(gna,"imagegpt"),gna.forEach(t),h6r=r(DJe," \u2014 "),Ree=n(DJe,"A",{href:!0});var hna=s(Ree);u6r=r(hna,"ImageGPTForImageClassification"),hna.forEach(t),p6r=r(DJe," (ImageGPT model)"),DJe.forEach(t),_6r=i(Fe),Sl=n(Fe,"LI",{});var PN=s(Sl);J0e=n(PN,"STRONG",{});var una=s(J0e);b6r=r(una,"levit"),una.forEach(t),v6r=r(PN," \u2014 "),Pee=n(PN,"A",{href:!0});var pna=s(Pee);F6r=r(pna,"LevitForImageClassification"),pna.forEach(t),T6r=r(PN," or "),Bee=n(PN,"A",{href:!0});var _na=s(Bee);M6r=r(_na,"LevitForImageClassificationWithTeacher"),_na.forEach(t),E6r=r(PN," (LeViT model)"),PN.forEach(t),C6r=i(Fe),SC=n(Fe,"LI",{});var GJe=s(SC);Y0e=n(GJe,"STRONG",{});var bna=s(Y0e);w6r=r(bna,"mobilevit"),bna.forEach(t),A6r=r(GJe," \u2014 "),Iee=n(GJe,"A",{href:!0});var vna=s(Iee);L6r=r(vna,"MobileViTForImageClassification"),vna.forEach(t),y6r=r(GJe," (MobileViT model)"),GJe.forEach(t),x6r=i(Fe),It=n(Fe,"LI",{});var zf=s(It);Z0e=n(zf,"STRONG",{});var Fna=s(Z0e);$6r=r(Fna,"perceiver"),Fna.forEach(t),k6r=r(zf," \u2014 "),Nee=n(zf,"A",{href:!0});var Tna=s(Nee);S6r=r(Tna,"PerceiverForImageClassificationLearned"),Tna.forEach(t),R6r=r(zf," or "),qee=n(zf,"A",{href:!0});var Mna=s(qee);P6r=r(Mna,"PerceiverForImageClassificationFourier"),Mna.forEach(t),B6r=r(zf," or "),jee=n(zf,"A",{href:!0});var Ena=s(jee);I6r=r(Ena,"PerceiverForImageClassificationConvProcessing"),Ena.forEach(t),N6r=r(zf," (Perceiver model)"),zf.forEach(t),q6r=i(Fe),RC=n(Fe,"LI",{});var OJe=s(RC);K0e=n(OJe,"STRONG",{});var Cna=s(K0e);j6r=r(Cna,"poolformer"),Cna.forEach(t),D6r=r(OJe," \u2014 "),Dee=n(OJe,"A",{href:!0});var wna=s(Dee);G6r=r(wna,"PoolFormerForImageClassification"),wna.forEach(t),O6r=r(OJe," (PoolFormer model)"),OJe.forEach(t),V6r=i(Fe),PC=n(Fe,"LI",{});var VJe=s(PC);ewe=n(VJe,"STRONG",{});var Ana=s(ewe);X6r=r(Ana,"regnet"),Ana.forEach(t),z6r=r(VJe," \u2014 "),Gee=n(VJe,"A",{href:!0});var Lna=s(Gee);Q6r=r(Lna,"RegNetForImageClassification"),Lna.forEach(t),W6r=r(VJe," (RegNet model)"),VJe.forEach(t),U6r=i(Fe),BC=n(Fe,"LI",{});var XJe=s(BC);owe=n(XJe,"STRONG",{});var yna=s(owe);H6r=r(yna,"resnet"),yna.forEach(t),J6r=r(XJe," \u2014 "),Oee=n(XJe,"A",{href:!0});var xna=s(Oee);Y6r=r(xna,"ResNetForImageClassification"),xna.forEach(t),Z6r=r(XJe," (ResNet model)"),XJe.forEach(t),K6r=i(Fe),IC=n(Fe,"LI",{});var zJe=s(IC);rwe=n(zJe,"STRONG",{});var $na=s(rwe);e7r=r($na,"segformer"),$na.forEach(t),o7r=r(zJe," \u2014 "),Vee=n(zJe,"A",{href:!0});var kna=s(Vee);r7r=r(kna,"SegformerForImageClassification"),kna.forEach(t),t7r=r(zJe," (SegFormer model)"),zJe.forEach(t),a7r=i(Fe),NC=n(Fe,"LI",{});var QJe=s(NC);twe=n(QJe,"STRONG",{});var Sna=s(twe);n7r=r(Sna,"swin"),Sna.forEach(t),s7r=r(QJe," \u2014 "),Xee=n(QJe,"A",{href:!0});var Rna=s(Xee);l7r=r(Rna,"SwinForImageClassification"),Rna.forEach(t),i7r=r(QJe," (Swin Transformer model)"),QJe.forEach(t),d7r=i(Fe),qC=n(Fe,"LI",{});var WJe=s(qC);awe=n(WJe,"STRONG",{});var Pna=s(awe);m7r=r(Pna,"swinv2"),Pna.forEach(t),c7r=r(WJe," \u2014 "),zee=n(WJe,"A",{href:!0});var Bna=s(zee);f7r=r(Bna,"Swinv2ForImageClassification"),Bna.forEach(t),g7r=r(WJe," (Swin Transformer V2 model)"),WJe.forEach(t),h7r=i(Fe),jC=n(Fe,"LI",{});var UJe=s(jC);nwe=n(UJe,"STRONG",{});var Ina=s(nwe);u7r=r(Ina,"van"),Ina.forEach(t),p7r=r(UJe," \u2014 "),Qee=n(UJe,"A",{href:!0});var Nna=s(Qee);_7r=r(Nna,"VanForImageClassification"),Nna.forEach(t),b7r=r(UJe," (VAN model)"),UJe.forEach(t),v7r=i(Fe),DC=n(Fe,"LI",{});var HJe=s(DC);swe=n(HJe,"STRONG",{});var qna=s(swe);F7r=r(qna,"vit"),qna.forEach(t),T7r=r(HJe," \u2014 "),Wee=n(HJe,"A",{href:!0});var jna=s(Wee);M7r=r(jna,"ViTForImageClassification"),jna.forEach(t),E7r=r(HJe," (ViT model)"),HJe.forEach(t),C7r=i(Fe),GC=n(Fe,"LI",{});var JJe=s(GC);lwe=n(JJe,"STRONG",{});var Dna=s(lwe);w7r=r(Dna,"vit_msn"),Dna.forEach(t),A7r=r(JJe," \u2014 "),Uee=n(JJe,"A",{href:!0});var Gna=s(Uee);L7r=r(Gna,"ViTMSNForImageClassification"),Gna.forEach(t),y7r=r(JJe," (ViTMSN model)"),JJe.forEach(t),Fe.forEach(t),x7r=i(Da),OC=n(Da,"P",{});var YJe=s(OC);$7r=r(YJe,"The model is set in evaluation mode by default using "),iwe=n(YJe,"CODE",{});var Ona=s(iwe);k7r=r(Ona,"model.eval()"),Ona.forEach(t),S7r=r(YJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),dwe=n(YJe,"CODE",{});var Vna=s(dwe);R7r=r(Vna,"model.train()"),Vna.forEach(t),YJe.forEach(t),P7r=i(Da),T(VC.$$.fragment,Da),Da.forEach(t),Zl.forEach(t),uno=i(c),Mm=n(c,"H2",{class:!0});var Plo=s(Mm);XC=n(Plo,"A",{id:!0,class:!0,href:!0});var Xna=s(XC);mwe=n(Xna,"SPAN",{});var zna=s(mwe);T(fS.$$.fragment,zna),zna.forEach(t),Xna.forEach(t),B7r=i(Plo),cwe=n(Plo,"SPAN",{});var Qna=s(cwe);I7r=r(Qna,"AutoModelForVideoClassification"),Qna.forEach(t),Plo.forEach(t),pno=i(c),Jo=n(c,"DIV",{class:!0});var Kl=s(Jo);T(gS.$$.fragment,Kl),N7r=i(Kl),Em=n(Kl,"P",{});var dce=s(Em);q7r=r(dce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),Hee=n(dce,"A",{href:!0});var Wna=s(Hee);j7r=r(Wna,"from_pretrained()"),Wna.forEach(t),D7r=r(dce," class method or the "),Jee=n(dce,"A",{href:!0});var Una=s(Jee);G7r=r(Una,"from_config()"),Una.forEach(t),O7r=r(dce,` class
method.`),dce.forEach(t),V7r=i(Kl),hS=n(Kl,"P",{});var Blo=s(hS);X7r=r(Blo,"This class cannot be instantiated directly using "),fwe=n(Blo,"CODE",{});var Hna=s(fwe);z7r=r(Hna,"__init__()"),Hna.forEach(t),Q7r=r(Blo," (throws an error)."),Blo.forEach(t),W7r=i(Kl),Nt=n(Kl,"DIV",{class:!0});var O9=s(Nt);T(uS.$$.fragment,O9),U7r=i(O9),gwe=n(O9,"P",{});var Jna=s(gwe);H7r=r(Jna,"Instantiates one of the model classes of the library (with a video classification head) from a configuration."),Jna.forEach(t),J7r=i(O9),Cm=n(O9,"P",{});var mce=s(Cm);Y7r=r(mce,`Note:
Loading a model from its configuration file does `),hwe=n(mce,"STRONG",{});var Yna=s(hwe);Z7r=r(Yna,"not"),Yna.forEach(t),K7r=r(mce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Yee=n(mce,"A",{href:!0});var Zna=s(Yee);e8r=r(Zna,"from_pretrained()"),Zna.forEach(t),o8r=r(mce," to load the model weights."),mce.forEach(t),r8r=i(O9),T(zC.$$.fragment,O9),O9.forEach(t),t8r=i(Kl),ho=n(Kl,"DIV",{class:!0});var Ga=s(ho);T(pS.$$.fragment,Ga),a8r=i(Ga),uwe=n(Ga,"P",{});var Kna=s(uwe);n8r=r(Kna,"Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),Kna.forEach(t),s8r=i(Ga),Fn=n(Ga,"P",{});var V9=s(Fn);l8r=r(V9,"The model class to instantiate is selected based on the "),pwe=n(V9,"CODE",{});var esa=s(pwe);i8r=r(esa,"model_type"),esa.forEach(t),d8r=r(V9,` property of the config object (either
passed as an argument or loaded from `),_we=n(V9,"CODE",{});var osa=s(_we);m8r=r(osa,"pretrained_model_name_or_path"),osa.forEach(t),c8r=r(V9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bwe=n(V9,"CODE",{});var rsa=s(bwe);f8r=r(rsa,"pretrained_model_name_or_path"),rsa.forEach(t),g8r=r(V9,":"),V9.forEach(t),h8r=i(Ga),vwe=n(Ga,"UL",{});var tsa=s(vwe);QC=n(tsa,"LI",{});var ZJe=s(QC);Fwe=n(ZJe,"STRONG",{});var asa=s(Fwe);u8r=r(asa,"videomae"),asa.forEach(t),p8r=r(ZJe," \u2014 "),Zee=n(ZJe,"A",{href:!0});var nsa=s(Zee);_8r=r(nsa,"VideoMAEForVideoClassification"),nsa.forEach(t),b8r=r(ZJe," (VideoMAE model)"),ZJe.forEach(t),tsa.forEach(t),v8r=i(Ga),WC=n(Ga,"P",{});var KJe=s(WC);F8r=r(KJe,"The model is set in evaluation mode by default using "),Twe=n(KJe,"CODE",{});var ssa=s(Twe);T8r=r(ssa,"model.eval()"),ssa.forEach(t),M8r=r(KJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Mwe=n(KJe,"CODE",{});var lsa=s(Mwe);E8r=r(lsa,"model.train()"),lsa.forEach(t),KJe.forEach(t),C8r=i(Ga),T(UC.$$.fragment,Ga),Ga.forEach(t),Kl.forEach(t),_no=i(c),wm=n(c,"H2",{class:!0});var Ilo=s(wm);HC=n(Ilo,"A",{id:!0,class:!0,href:!0});var isa=s(HC);Ewe=n(isa,"SPAN",{});var dsa=s(Ewe);T(_S.$$.fragment,dsa),dsa.forEach(t),isa.forEach(t),w8r=i(Ilo),Cwe=n(Ilo,"SPAN",{});var msa=s(Cwe);A8r=r(msa,"AutoModelForVision2Seq"),msa.forEach(t),Ilo.forEach(t),bno=i(c),Yo=n(c,"DIV",{class:!0});var ei=s(Yo);T(bS.$$.fragment,ei),L8r=i(ei),Am=n(ei,"P",{});var cce=s(Am);y8r=r(cce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Kee=n(cce,"A",{href:!0});var csa=s(Kee);x8r=r(csa,"from_pretrained()"),csa.forEach(t),$8r=r(cce," class method or the "),eoe=n(cce,"A",{href:!0});var fsa=s(eoe);k8r=r(fsa,"from_config()"),fsa.forEach(t),S8r=r(cce,` class
method.`),cce.forEach(t),R8r=i(ei),vS=n(ei,"P",{});var Nlo=s(vS);P8r=r(Nlo,"This class cannot be instantiated directly using "),wwe=n(Nlo,"CODE",{});var gsa=s(wwe);B8r=r(gsa,"__init__()"),gsa.forEach(t),I8r=r(Nlo," (throws an error)."),Nlo.forEach(t),N8r=i(ei),qt=n(ei,"DIV",{class:!0});var X9=s(qt);T(FS.$$.fragment,X9),q8r=i(X9),Awe=n(X9,"P",{});var hsa=s(Awe);j8r=r(hsa,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),hsa.forEach(t),D8r=i(X9),Lm=n(X9,"P",{});var fce=s(Lm);G8r=r(fce,`Note:
Loading a model from its configuration file does `),Lwe=n(fce,"STRONG",{});var usa=s(Lwe);O8r=r(usa,"not"),usa.forEach(t),V8r=r(fce,` load the model weights. It only affects the
model\u2019s configuration. Use `),ooe=n(fce,"A",{href:!0});var psa=s(ooe);X8r=r(psa,"from_pretrained()"),psa.forEach(t),z8r=r(fce," to load the model weights."),fce.forEach(t),Q8r=i(X9),T(JC.$$.fragment,X9),X9.forEach(t),W8r=i(ei),uo=n(ei,"DIV",{class:!0});var Oa=s(uo);T(TS.$$.fragment,Oa),U8r=i(Oa),ywe=n(Oa,"P",{});var _sa=s(ywe);H8r=r(_sa,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),_sa.forEach(t),J8r=i(Oa),Tn=n(Oa,"P",{});var z9=s(Tn);Y8r=r(z9,"The model class to instantiate is selected based on the "),xwe=n(z9,"CODE",{});var bsa=s(xwe);Z8r=r(bsa,"model_type"),bsa.forEach(t),K8r=r(z9,` property of the config object (either
passed as an argument or loaded from `),$we=n(z9,"CODE",{});var vsa=s($we);eLr=r(vsa,"pretrained_model_name_or_path"),vsa.forEach(t),oLr=r(z9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kwe=n(z9,"CODE",{});var Fsa=s(kwe);rLr=r(Fsa,"pretrained_model_name_or_path"),Fsa.forEach(t),tLr=r(z9,":"),z9.forEach(t),aLr=i(Oa),Swe=n(Oa,"UL",{});var Tsa=s(Swe);YC=n(Tsa,"LI",{});var eYe=s(YC);Rwe=n(eYe,"STRONG",{});var Msa=s(Rwe);nLr=r(Msa,"vision-encoder-decoder"),Msa.forEach(t),sLr=r(eYe," \u2014 "),roe=n(eYe,"A",{href:!0});var Esa=s(roe);lLr=r(Esa,"VisionEncoderDecoderModel"),Esa.forEach(t),iLr=r(eYe," (Vision Encoder decoder model)"),eYe.forEach(t),Tsa.forEach(t),dLr=i(Oa),ZC=n(Oa,"P",{});var oYe=s(ZC);mLr=r(oYe,"The model is set in evaluation mode by default using "),Pwe=n(oYe,"CODE",{});var Csa=s(Pwe);cLr=r(Csa,"model.eval()"),Csa.forEach(t),fLr=r(oYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Bwe=n(oYe,"CODE",{});var wsa=s(Bwe);gLr=r(wsa,"model.train()"),wsa.forEach(t),oYe.forEach(t),hLr=i(Oa),T(KC.$$.fragment,Oa),Oa.forEach(t),ei.forEach(t),vno=i(c),ym=n(c,"H2",{class:!0});var qlo=s(ym);e3=n(qlo,"A",{id:!0,class:!0,href:!0});var Asa=s(e3);Iwe=n(Asa,"SPAN",{});var Lsa=s(Iwe);T(MS.$$.fragment,Lsa),Lsa.forEach(t),Asa.forEach(t),uLr=i(qlo),Nwe=n(qlo,"SPAN",{});var ysa=s(Nwe);pLr=r(ysa,"AutoModelForVisualQuestionAnswering"),ysa.forEach(t),qlo.forEach(t),Fno=i(c),Zo=n(c,"DIV",{class:!0});var oi=s(Zo);T(ES.$$.fragment,oi),_Lr=i(oi),xm=n(oi,"P",{});var gce=s(xm);bLr=r(gce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),toe=n(gce,"A",{href:!0});var xsa=s(toe);vLr=r(xsa,"from_pretrained()"),xsa.forEach(t),FLr=r(gce," class method or the "),aoe=n(gce,"A",{href:!0});var $sa=s(aoe);TLr=r($sa,"from_config()"),$sa.forEach(t),MLr=r(gce,` class
method.`),gce.forEach(t),ELr=i(oi),CS=n(oi,"P",{});var jlo=s(CS);CLr=r(jlo,"This class cannot be instantiated directly using "),qwe=n(jlo,"CODE",{});var ksa=s(qwe);wLr=r(ksa,"__init__()"),ksa.forEach(t),ALr=r(jlo," (throws an error)."),jlo.forEach(t),LLr=i(oi),jt=n(oi,"DIV",{class:!0});var Q9=s(jt);T(wS.$$.fragment,Q9),yLr=i(Q9),jwe=n(Q9,"P",{});var Ssa=s(jwe);xLr=r(Ssa,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),Ssa.forEach(t),$Lr=i(Q9),$m=n(Q9,"P",{});var hce=s($m);kLr=r(hce,`Note:
Loading a model from its configuration file does `),Dwe=n(hce,"STRONG",{});var Rsa=s(Dwe);SLr=r(Rsa,"not"),Rsa.forEach(t),RLr=r(hce,` load the model weights. It only affects the
model\u2019s configuration. Use `),noe=n(hce,"A",{href:!0});var Psa=s(noe);PLr=r(Psa,"from_pretrained()"),Psa.forEach(t),BLr=r(hce," to load the model weights."),hce.forEach(t),ILr=i(Q9),T(o3.$$.fragment,Q9),Q9.forEach(t),NLr=i(oi),po=n(oi,"DIV",{class:!0});var Va=s(po);T(AS.$$.fragment,Va),qLr=i(Va),Gwe=n(Va,"P",{});var Bsa=s(Gwe);jLr=r(Bsa,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),Bsa.forEach(t),DLr=i(Va),Mn=n(Va,"P",{});var W9=s(Mn);GLr=r(W9,"The model class to instantiate is selected based on the "),Owe=n(W9,"CODE",{});var Isa=s(Owe);OLr=r(Isa,"model_type"),Isa.forEach(t),VLr=r(W9,` property of the config object (either
passed as an argument or loaded from `),Vwe=n(W9,"CODE",{});var Nsa=s(Vwe);XLr=r(Nsa,"pretrained_model_name_or_path"),Nsa.forEach(t),zLr=r(W9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xwe=n(W9,"CODE",{});var qsa=s(Xwe);QLr=r(qsa,"pretrained_model_name_or_path"),qsa.forEach(t),WLr=r(W9,":"),W9.forEach(t),ULr=i(Va),zwe=n(Va,"UL",{});var jsa=s(zwe);r3=n(jsa,"LI",{});var rYe=s(r3);Qwe=n(rYe,"STRONG",{});var Dsa=s(Qwe);HLr=r(Dsa,"vilt"),Dsa.forEach(t),JLr=r(rYe," \u2014 "),soe=n(rYe,"A",{href:!0});var Gsa=s(soe);YLr=r(Gsa,"ViltForQuestionAnswering"),Gsa.forEach(t),ZLr=r(rYe," (ViLT model)"),rYe.forEach(t),jsa.forEach(t),KLr=i(Va),t3=n(Va,"P",{});var tYe=s(t3);eyr=r(tYe,"The model is set in evaluation mode by default using "),Wwe=n(tYe,"CODE",{});var Osa=s(Wwe);oyr=r(Osa,"model.eval()"),Osa.forEach(t),ryr=r(tYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Uwe=n(tYe,"CODE",{});var Vsa=s(Uwe);tyr=r(Vsa,"model.train()"),Vsa.forEach(t),tYe.forEach(t),ayr=i(Va),T(a3.$$.fragment,Va),Va.forEach(t),oi.forEach(t),Tno=i(c),km=n(c,"H2",{class:!0});var Dlo=s(km);n3=n(Dlo,"A",{id:!0,class:!0,href:!0});var Xsa=s(n3);Hwe=n(Xsa,"SPAN",{});var zsa=s(Hwe);T(LS.$$.fragment,zsa),zsa.forEach(t),Xsa.forEach(t),nyr=i(Dlo),Jwe=n(Dlo,"SPAN",{});var Qsa=s(Jwe);syr=r(Qsa,"AutoModelForAudioClassification"),Qsa.forEach(t),Dlo.forEach(t),Mno=i(c),Ko=n(c,"DIV",{class:!0});var ri=s(Ko);T(yS.$$.fragment,ri),lyr=i(ri),Sm=n(ri,"P",{});var uce=s(Sm);iyr=r(uce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),loe=n(uce,"A",{href:!0});var Wsa=s(loe);dyr=r(Wsa,"from_pretrained()"),Wsa.forEach(t),myr=r(uce," class method or the "),ioe=n(uce,"A",{href:!0});var Usa=s(ioe);cyr=r(Usa,"from_config()"),Usa.forEach(t),fyr=r(uce,` class
method.`),uce.forEach(t),gyr=i(ri),xS=n(ri,"P",{});var Glo=s(xS);hyr=r(Glo,"This class cannot be instantiated directly using "),Ywe=n(Glo,"CODE",{});var Hsa=s(Ywe);uyr=r(Hsa,"__init__()"),Hsa.forEach(t),pyr=r(Glo," (throws an error)."),Glo.forEach(t),_yr=i(ri),Dt=n(ri,"DIV",{class:!0});var U9=s(Dt);T($S.$$.fragment,U9),byr=i(U9),Zwe=n(U9,"P",{});var Jsa=s(Zwe);vyr=r(Jsa,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),Jsa.forEach(t),Fyr=i(U9),Rm=n(U9,"P",{});var pce=s(Rm);Tyr=r(pce,`Note:
Loading a model from its configuration file does `),Kwe=n(pce,"STRONG",{});var Ysa=s(Kwe);Myr=r(Ysa,"not"),Ysa.forEach(t),Eyr=r(pce,` load the model weights. It only affects the
model\u2019s configuration. Use `),doe=n(pce,"A",{href:!0});var Zsa=s(doe);Cyr=r(Zsa,"from_pretrained()"),Zsa.forEach(t),wyr=r(pce," to load the model weights."),pce.forEach(t),Ayr=i(U9),T(s3.$$.fragment,U9),U9.forEach(t),Lyr=i(ri),_o=n(ri,"DIV",{class:!0});var Xa=s(_o);T(kS.$$.fragment,Xa),yyr=i(Xa),eAe=n(Xa,"P",{});var Ksa=s(eAe);xyr=r(Ksa,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),Ksa.forEach(t),$yr=i(Xa),En=n(Xa,"P",{});var H9=s(En);kyr=r(H9,"The model class to instantiate is selected based on the "),oAe=n(H9,"CODE",{});var ela=s(oAe);Syr=r(ela,"model_type"),ela.forEach(t),Ryr=r(H9,` property of the config object (either
passed as an argument or loaded from `),rAe=n(H9,"CODE",{});var ola=s(rAe);Pyr=r(ola,"pretrained_model_name_or_path"),ola.forEach(t),Byr=r(H9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tAe=n(H9,"CODE",{});var rla=s(tAe);Iyr=r(rla,"pretrained_model_name_or_path"),rla.forEach(t),Nyr=r(H9,":"),H9.forEach(t),qyr=i(Xa),Be=n(Xa,"UL",{});var We=s(Be);l3=n(We,"LI",{});var aYe=s(l3);aAe=n(aYe,"STRONG",{});var tla=s(aAe);jyr=r(tla,"data2vec-audio"),tla.forEach(t),Dyr=r(aYe," \u2014 "),moe=n(aYe,"A",{href:!0});var ala=s(moe);Gyr=r(ala,"Data2VecAudioForSequenceClassification"),ala.forEach(t),Oyr=r(aYe," (Data2VecAudio model)"),aYe.forEach(t),Vyr=i(We),i3=n(We,"LI",{});var nYe=s(i3);nAe=n(nYe,"STRONG",{});var nla=s(nAe);Xyr=r(nla,"hubert"),nla.forEach(t),zyr=r(nYe," \u2014 "),coe=n(nYe,"A",{href:!0});var sla=s(coe);Qyr=r(sla,"HubertForSequenceClassification"),sla.forEach(t),Wyr=r(nYe," (Hubert model)"),nYe.forEach(t),Uyr=i(We),d3=n(We,"LI",{});var sYe=s(d3);sAe=n(sYe,"STRONG",{});var lla=s(sAe);Hyr=r(lla,"sew"),lla.forEach(t),Jyr=r(sYe," \u2014 "),foe=n(sYe,"A",{href:!0});var ila=s(foe);Yyr=r(ila,"SEWForSequenceClassification"),ila.forEach(t),Zyr=r(sYe," (SEW model)"),sYe.forEach(t),Kyr=i(We),m3=n(We,"LI",{});var lYe=s(m3);lAe=n(lYe,"STRONG",{});var dla=s(lAe);e9r=r(dla,"sew-d"),dla.forEach(t),o9r=r(lYe," \u2014 "),goe=n(lYe,"A",{href:!0});var mla=s(goe);r9r=r(mla,"SEWDForSequenceClassification"),mla.forEach(t),t9r=r(lYe," (SEW-D model)"),lYe.forEach(t),a9r=i(We),c3=n(We,"LI",{});var iYe=s(c3);iAe=n(iYe,"STRONG",{});var cla=s(iAe);n9r=r(cla,"unispeech"),cla.forEach(t),s9r=r(iYe," \u2014 "),hoe=n(iYe,"A",{href:!0});var fla=s(hoe);l9r=r(fla,"UniSpeechForSequenceClassification"),fla.forEach(t),i9r=r(iYe," (UniSpeech model)"),iYe.forEach(t),d9r=i(We),f3=n(We,"LI",{});var dYe=s(f3);dAe=n(dYe,"STRONG",{});var gla=s(dAe);m9r=r(gla,"unispeech-sat"),gla.forEach(t),c9r=r(dYe," \u2014 "),uoe=n(dYe,"A",{href:!0});var hla=s(uoe);f9r=r(hla,"UniSpeechSatForSequenceClassification"),hla.forEach(t),g9r=r(dYe," (UniSpeechSat model)"),dYe.forEach(t),h9r=i(We),g3=n(We,"LI",{});var mYe=s(g3);mAe=n(mYe,"STRONG",{});var ula=s(mAe);u9r=r(ula,"wav2vec2"),ula.forEach(t),p9r=r(mYe," \u2014 "),poe=n(mYe,"A",{href:!0});var pla=s(poe);_9r=r(pla,"Wav2Vec2ForSequenceClassification"),pla.forEach(t),b9r=r(mYe," (Wav2Vec2 model)"),mYe.forEach(t),v9r=i(We),h3=n(We,"LI",{});var cYe=s(h3);cAe=n(cYe,"STRONG",{});var _la=s(cAe);F9r=r(_la,"wav2vec2-conformer"),_la.forEach(t),T9r=r(cYe," \u2014 "),_oe=n(cYe,"A",{href:!0});var bla=s(_oe);M9r=r(bla,"Wav2Vec2ConformerForSequenceClassification"),bla.forEach(t),E9r=r(cYe," (Wav2Vec2-Conformer model)"),cYe.forEach(t),C9r=i(We),u3=n(We,"LI",{});var fYe=s(u3);fAe=n(fYe,"STRONG",{});var vla=s(fAe);w9r=r(vla,"wavlm"),vla.forEach(t),A9r=r(fYe," \u2014 "),boe=n(fYe,"A",{href:!0});var Fla=s(boe);L9r=r(Fla,"WavLMForSequenceClassification"),Fla.forEach(t),y9r=r(fYe," (WavLM model)"),fYe.forEach(t),We.forEach(t),x9r=i(Xa),p3=n(Xa,"P",{});var gYe=s(p3);$9r=r(gYe,"The model is set in evaluation mode by default using "),gAe=n(gYe,"CODE",{});var Tla=s(gAe);k9r=r(Tla,"model.eval()"),Tla.forEach(t),S9r=r(gYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),hAe=n(gYe,"CODE",{});var Mla=s(hAe);R9r=r(Mla,"model.train()"),Mla.forEach(t),gYe.forEach(t),P9r=i(Xa),T(_3.$$.fragment,Xa),Xa.forEach(t),ri.forEach(t),Eno=i(c),Pm=n(c,"H2",{class:!0});var Olo=s(Pm);b3=n(Olo,"A",{id:!0,class:!0,href:!0});var Ela=s(b3);uAe=n(Ela,"SPAN",{});var Cla=s(uAe);T(SS.$$.fragment,Cla),Cla.forEach(t),Ela.forEach(t),B9r=i(Olo),pAe=n(Olo,"SPAN",{});var wla=s(pAe);I9r=r(wla,"AutoModelForAudioFrameClassification"),wla.forEach(t),Olo.forEach(t),Cno=i(c),er=n(c,"DIV",{class:!0});var ti=s(er);T(RS.$$.fragment,ti),N9r=i(ti),Bm=n(ti,"P",{});var _ce=s(Bm);q9r=r(_ce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),voe=n(_ce,"A",{href:!0});var Ala=s(voe);j9r=r(Ala,"from_pretrained()"),Ala.forEach(t),D9r=r(_ce," class method or the "),Foe=n(_ce,"A",{href:!0});var Lla=s(Foe);G9r=r(Lla,"from_config()"),Lla.forEach(t),O9r=r(_ce,` class
method.`),_ce.forEach(t),V9r=i(ti),PS=n(ti,"P",{});var Vlo=s(PS);X9r=r(Vlo,"This class cannot be instantiated directly using "),_Ae=n(Vlo,"CODE",{});var yla=s(_Ae);z9r=r(yla,"__init__()"),yla.forEach(t),Q9r=r(Vlo," (throws an error)."),Vlo.forEach(t),W9r=i(ti),Gt=n(ti,"DIV",{class:!0});var J9=s(Gt);T(BS.$$.fragment,J9),U9r=i(J9),bAe=n(J9,"P",{});var xla=s(bAe);H9r=r(xla,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),xla.forEach(t),J9r=i(J9),Im=n(J9,"P",{});var bce=s(Im);Y9r=r(bce,`Note:
Loading a model from its configuration file does `),vAe=n(bce,"STRONG",{});var $la=s(vAe);Z9r=r($la,"not"),$la.forEach(t),K9r=r(bce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Toe=n(bce,"A",{href:!0});var kla=s(Toe);exr=r(kla,"from_pretrained()"),kla.forEach(t),oxr=r(bce," to load the model weights."),bce.forEach(t),rxr=i(J9),T(v3.$$.fragment,J9),J9.forEach(t),txr=i(ti),bo=n(ti,"DIV",{class:!0});var za=s(bo);T(IS.$$.fragment,za),axr=i(za),FAe=n(za,"P",{});var Sla=s(FAe);nxr=r(Sla,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),Sla.forEach(t),sxr=i(za),Cn=n(za,"P",{});var Y9=s(Cn);lxr=r(Y9,"The model class to instantiate is selected based on the "),TAe=n(Y9,"CODE",{});var Rla=s(TAe);ixr=r(Rla,"model_type"),Rla.forEach(t),dxr=r(Y9,` property of the config object (either
passed as an argument or loaded from `),MAe=n(Y9,"CODE",{});var Pla=s(MAe);mxr=r(Pla,"pretrained_model_name_or_path"),Pla.forEach(t),cxr=r(Y9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),EAe=n(Y9,"CODE",{});var Bla=s(EAe);fxr=r(Bla,"pretrained_model_name_or_path"),Bla.forEach(t),gxr=r(Y9,":"),Y9.forEach(t),hxr=i(za),ut=n(za,"UL",{});var ai=s(ut);F3=n(ai,"LI",{});var hYe=s(F3);CAe=n(hYe,"STRONG",{});var Ila=s(CAe);uxr=r(Ila,"data2vec-audio"),Ila.forEach(t),pxr=r(hYe," \u2014 "),Moe=n(hYe,"A",{href:!0});var Nla=s(Moe);_xr=r(Nla,"Data2VecAudioForAudioFrameClassification"),Nla.forEach(t),bxr=r(hYe," (Data2VecAudio model)"),hYe.forEach(t),vxr=i(ai),T3=n(ai,"LI",{});var uYe=s(T3);wAe=n(uYe,"STRONG",{});var qla=s(wAe);Fxr=r(qla,"unispeech-sat"),qla.forEach(t),Txr=r(uYe," \u2014 "),Eoe=n(uYe,"A",{href:!0});var jla=s(Eoe);Mxr=r(jla,"UniSpeechSatForAudioFrameClassification"),jla.forEach(t),Exr=r(uYe," (UniSpeechSat model)"),uYe.forEach(t),Cxr=i(ai),M3=n(ai,"LI",{});var pYe=s(M3);AAe=n(pYe,"STRONG",{});var Dla=s(AAe);wxr=r(Dla,"wav2vec2"),Dla.forEach(t),Axr=r(pYe," \u2014 "),Coe=n(pYe,"A",{href:!0});var Gla=s(Coe);Lxr=r(Gla,"Wav2Vec2ForAudioFrameClassification"),Gla.forEach(t),yxr=r(pYe," (Wav2Vec2 model)"),pYe.forEach(t),xxr=i(ai),E3=n(ai,"LI",{});var _Ye=s(E3);LAe=n(_Ye,"STRONG",{});var Ola=s(LAe);$xr=r(Ola,"wav2vec2-conformer"),Ola.forEach(t),kxr=r(_Ye," \u2014 "),woe=n(_Ye,"A",{href:!0});var Vla=s(woe);Sxr=r(Vla,"Wav2Vec2ConformerForAudioFrameClassification"),Vla.forEach(t),Rxr=r(_Ye," (Wav2Vec2-Conformer model)"),_Ye.forEach(t),Pxr=i(ai),C3=n(ai,"LI",{});var bYe=s(C3);yAe=n(bYe,"STRONG",{});var Xla=s(yAe);Bxr=r(Xla,"wavlm"),Xla.forEach(t),Ixr=r(bYe," \u2014 "),Aoe=n(bYe,"A",{href:!0});var zla=s(Aoe);Nxr=r(zla,"WavLMForAudioFrameClassification"),zla.forEach(t),qxr=r(bYe," (WavLM model)"),bYe.forEach(t),ai.forEach(t),jxr=i(za),w3=n(za,"P",{});var vYe=s(w3);Dxr=r(vYe,"The model is set in evaluation mode by default using "),xAe=n(vYe,"CODE",{});var Qla=s(xAe);Gxr=r(Qla,"model.eval()"),Qla.forEach(t),Oxr=r(vYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$Ae=n(vYe,"CODE",{});var Wla=s($Ae);Vxr=r(Wla,"model.train()"),Wla.forEach(t),vYe.forEach(t),Xxr=i(za),T(A3.$$.fragment,za),za.forEach(t),ti.forEach(t),wno=i(c),Nm=n(c,"H2",{class:!0});var Xlo=s(Nm);L3=n(Xlo,"A",{id:!0,class:!0,href:!0});var Ula=s(L3);kAe=n(Ula,"SPAN",{});var Hla=s(kAe);T(NS.$$.fragment,Hla),Hla.forEach(t),Ula.forEach(t),zxr=i(Xlo),SAe=n(Xlo,"SPAN",{});var Jla=s(SAe);Qxr=r(Jla,"AutoModelForCTC"),Jla.forEach(t),Xlo.forEach(t),Ano=i(c),or=n(c,"DIV",{class:!0});var ni=s(or);T(qS.$$.fragment,ni),Wxr=i(ni),qm=n(ni,"P",{});var vce=s(qm);Uxr=r(vce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),Loe=n(vce,"A",{href:!0});var Yla=s(Loe);Hxr=r(Yla,"from_pretrained()"),Yla.forEach(t),Jxr=r(vce," class method or the "),yoe=n(vce,"A",{href:!0});var Zla=s(yoe);Yxr=r(Zla,"from_config()"),Zla.forEach(t),Zxr=r(vce,` class
method.`),vce.forEach(t),Kxr=i(ni),jS=n(ni,"P",{});var zlo=s(jS);e$r=r(zlo,"This class cannot be instantiated directly using "),RAe=n(zlo,"CODE",{});var Kla=s(RAe);o$r=r(Kla,"__init__()"),Kla.forEach(t),r$r=r(zlo," (throws an error)."),zlo.forEach(t),t$r=i(ni),Ot=n(ni,"DIV",{class:!0});var Z9=s(Ot);T(DS.$$.fragment,Z9),a$r=i(Z9),PAe=n(Z9,"P",{});var eia=s(PAe);n$r=r(eia,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),eia.forEach(t),s$r=i(Z9),jm=n(Z9,"P",{});var Fce=s(jm);l$r=r(Fce,`Note:
Loading a model from its configuration file does `),BAe=n(Fce,"STRONG",{});var oia=s(BAe);i$r=r(oia,"not"),oia.forEach(t),d$r=r(Fce,` load the model weights. It only affects the
model\u2019s configuration. Use `),xoe=n(Fce,"A",{href:!0});var ria=s(xoe);m$r=r(ria,"from_pretrained()"),ria.forEach(t),c$r=r(Fce," to load the model weights."),Fce.forEach(t),f$r=i(Z9),T(y3.$$.fragment,Z9),Z9.forEach(t),g$r=i(ni),vo=n(ni,"DIV",{class:!0});var Qa=s(vo);T(GS.$$.fragment,Qa),h$r=i(Qa),IAe=n(Qa,"P",{});var tia=s(IAe);u$r=r(tia,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),tia.forEach(t),p$r=i(Qa),wn=n(Qa,"P",{});var K9=s(wn);_$r=r(K9,"The model class to instantiate is selected based on the "),NAe=n(K9,"CODE",{});var aia=s(NAe);b$r=r(aia,"model_type"),aia.forEach(t),v$r=r(K9,` property of the config object (either
passed as an argument or loaded from `),qAe=n(K9,"CODE",{});var nia=s(qAe);F$r=r(nia,"pretrained_model_name_or_path"),nia.forEach(t),T$r=r(K9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jAe=n(K9,"CODE",{});var sia=s(jAe);M$r=r(sia,"pretrained_model_name_or_path"),sia.forEach(t),E$r=r(K9,":"),K9.forEach(t),C$r=i(Qa),Le=n(Qa,"UL",{});var Ie=s(Le);x3=n(Ie,"LI",{});var FYe=s(x3);DAe=n(FYe,"STRONG",{});var lia=s(DAe);w$r=r(lia,"data2vec-audio"),lia.forEach(t),A$r=r(FYe," \u2014 "),$oe=n(FYe,"A",{href:!0});var iia=s($oe);L$r=r(iia,"Data2VecAudioForCTC"),iia.forEach(t),y$r=r(FYe," (Data2VecAudio model)"),FYe.forEach(t),x$r=i(Ie),$3=n(Ie,"LI",{});var TYe=s($3);GAe=n(TYe,"STRONG",{});var dia=s(GAe);$$r=r(dia,"hubert"),dia.forEach(t),k$r=r(TYe," \u2014 "),koe=n(TYe,"A",{href:!0});var mia=s(koe);S$r=r(mia,"HubertForCTC"),mia.forEach(t),R$r=r(TYe," (Hubert model)"),TYe.forEach(t),P$r=i(Ie),k3=n(Ie,"LI",{});var MYe=s(k3);OAe=n(MYe,"STRONG",{});var cia=s(OAe);B$r=r(cia,"mctct"),cia.forEach(t),I$r=r(MYe," \u2014 "),Soe=n(MYe,"A",{href:!0});var fia=s(Soe);N$r=r(fia,"MCTCTForCTC"),fia.forEach(t),q$r=r(MYe," (M-CTC-T model)"),MYe.forEach(t),j$r=i(Ie),S3=n(Ie,"LI",{});var EYe=s(S3);VAe=n(EYe,"STRONG",{});var gia=s(VAe);D$r=r(gia,"sew"),gia.forEach(t),G$r=r(EYe," \u2014 "),Roe=n(EYe,"A",{href:!0});var hia=s(Roe);O$r=r(hia,"SEWForCTC"),hia.forEach(t),V$r=r(EYe," (SEW model)"),EYe.forEach(t),X$r=i(Ie),R3=n(Ie,"LI",{});var CYe=s(R3);XAe=n(CYe,"STRONG",{});var uia=s(XAe);z$r=r(uia,"sew-d"),uia.forEach(t),Q$r=r(CYe," \u2014 "),Poe=n(CYe,"A",{href:!0});var pia=s(Poe);W$r=r(pia,"SEWDForCTC"),pia.forEach(t),U$r=r(CYe," (SEW-D model)"),CYe.forEach(t),H$r=i(Ie),P3=n(Ie,"LI",{});var wYe=s(P3);zAe=n(wYe,"STRONG",{});var _ia=s(zAe);J$r=r(_ia,"unispeech"),_ia.forEach(t),Y$r=r(wYe," \u2014 "),Boe=n(wYe,"A",{href:!0});var bia=s(Boe);Z$r=r(bia,"UniSpeechForCTC"),bia.forEach(t),K$r=r(wYe," (UniSpeech model)"),wYe.forEach(t),ekr=i(Ie),B3=n(Ie,"LI",{});var AYe=s(B3);QAe=n(AYe,"STRONG",{});var via=s(QAe);okr=r(via,"unispeech-sat"),via.forEach(t),rkr=r(AYe," \u2014 "),Ioe=n(AYe,"A",{href:!0});var Fia=s(Ioe);tkr=r(Fia,"UniSpeechSatForCTC"),Fia.forEach(t),akr=r(AYe," (UniSpeechSat model)"),AYe.forEach(t),nkr=i(Ie),I3=n(Ie,"LI",{});var LYe=s(I3);WAe=n(LYe,"STRONG",{});var Tia=s(WAe);skr=r(Tia,"wav2vec2"),Tia.forEach(t),lkr=r(LYe," \u2014 "),Noe=n(LYe,"A",{href:!0});var Mia=s(Noe);ikr=r(Mia,"Wav2Vec2ForCTC"),Mia.forEach(t),dkr=r(LYe," (Wav2Vec2 model)"),LYe.forEach(t),mkr=i(Ie),N3=n(Ie,"LI",{});var yYe=s(N3);UAe=n(yYe,"STRONG",{});var Eia=s(UAe);ckr=r(Eia,"wav2vec2-conformer"),Eia.forEach(t),fkr=r(yYe," \u2014 "),qoe=n(yYe,"A",{href:!0});var Cia=s(qoe);gkr=r(Cia,"Wav2Vec2ConformerForCTC"),Cia.forEach(t),hkr=r(yYe," (Wav2Vec2-Conformer model)"),yYe.forEach(t),ukr=i(Ie),q3=n(Ie,"LI",{});var xYe=s(q3);HAe=n(xYe,"STRONG",{});var wia=s(HAe);pkr=r(wia,"wavlm"),wia.forEach(t),_kr=r(xYe," \u2014 "),joe=n(xYe,"A",{href:!0});var Aia=s(joe);bkr=r(Aia,"WavLMForCTC"),Aia.forEach(t),vkr=r(xYe," (WavLM model)"),xYe.forEach(t),Ie.forEach(t),Fkr=i(Qa),j3=n(Qa,"P",{});var $Ye=s(j3);Tkr=r($Ye,"The model is set in evaluation mode by default using "),JAe=n($Ye,"CODE",{});var Lia=s(JAe);Mkr=r(Lia,"model.eval()"),Lia.forEach(t),Ekr=r($Ye,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),YAe=n($Ye,"CODE",{});var yia=s(YAe);Ckr=r(yia,"model.train()"),yia.forEach(t),$Ye.forEach(t),wkr=i(Qa),T(D3.$$.fragment,Qa),Qa.forEach(t),ni.forEach(t),Lno=i(c),Dm=n(c,"H2",{class:!0});var Qlo=s(Dm);G3=n(Qlo,"A",{id:!0,class:!0,href:!0});var xia=s(G3);ZAe=n(xia,"SPAN",{});var $ia=s(ZAe);T(OS.$$.fragment,$ia),$ia.forEach(t),xia.forEach(t),Akr=i(Qlo),KAe=n(Qlo,"SPAN",{});var kia=s(KAe);Lkr=r(kia,"AutoModelForSpeechSeq2Seq"),kia.forEach(t),Qlo.forEach(t),yno=i(c),rr=n(c,"DIV",{class:!0});var si=s(rr);T(VS.$$.fragment,si),ykr=i(si),Gm=n(si,"P",{});var Tce=s(Gm);xkr=r(Tce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),Doe=n(Tce,"A",{href:!0});var Sia=s(Doe);$kr=r(Sia,"from_pretrained()"),Sia.forEach(t),kkr=r(Tce," class method or the "),Goe=n(Tce,"A",{href:!0});var Ria=s(Goe);Skr=r(Ria,"from_config()"),Ria.forEach(t),Rkr=r(Tce,` class
method.`),Tce.forEach(t),Pkr=i(si),XS=n(si,"P",{});var Wlo=s(XS);Bkr=r(Wlo,"This class cannot be instantiated directly using "),e6e=n(Wlo,"CODE",{});var Pia=s(e6e);Ikr=r(Pia,"__init__()"),Pia.forEach(t),Nkr=r(Wlo," (throws an error)."),Wlo.forEach(t),qkr=i(si),Vt=n(si,"DIV",{class:!0});var ex=s(Vt);T(zS.$$.fragment,ex),jkr=i(ex),o6e=n(ex,"P",{});var Bia=s(o6e);Dkr=r(Bia,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Bia.forEach(t),Gkr=i(ex),Om=n(ex,"P",{});var Mce=s(Om);Okr=r(Mce,`Note:
Loading a model from its configuration file does `),r6e=n(Mce,"STRONG",{});var Iia=s(r6e);Vkr=r(Iia,"not"),Iia.forEach(t),Xkr=r(Mce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ooe=n(Mce,"A",{href:!0});var Nia=s(Ooe);zkr=r(Nia,"from_pretrained()"),Nia.forEach(t),Qkr=r(Mce," to load the model weights."),Mce.forEach(t),Wkr=i(ex),T(O3.$$.fragment,ex),ex.forEach(t),Ukr=i(si),Fo=n(si,"DIV",{class:!0});var Wa=s(Fo);T(QS.$$.fragment,Wa),Hkr=i(Wa),t6e=n(Wa,"P",{});var qia=s(t6e);Jkr=r(qia,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),qia.forEach(t),Ykr=i(Wa),An=n(Wa,"P",{});var ox=s(An);Zkr=r(ox,"The model class to instantiate is selected based on the "),a6e=n(ox,"CODE",{});var jia=s(a6e);Kkr=r(jia,"model_type"),jia.forEach(t),eSr=r(ox,` property of the config object (either
passed as an argument or loaded from `),n6e=n(ox,"CODE",{});var Dia=s(n6e);oSr=r(Dia,"pretrained_model_name_or_path"),Dia.forEach(t),rSr=r(ox,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),s6e=n(ox,"CODE",{});var Gia=s(s6e);tSr=r(Gia,"pretrained_model_name_or_path"),Gia.forEach(t),aSr=r(ox,":"),ox.forEach(t),nSr=i(Wa),Vm=n(Wa,"UL",{});var Ece=s(Vm);V3=n(Ece,"LI",{});var kYe=s(V3);l6e=n(kYe,"STRONG",{});var Oia=s(l6e);sSr=r(Oia,"speech-encoder-decoder"),Oia.forEach(t),lSr=r(kYe," \u2014 "),Voe=n(kYe,"A",{href:!0});var Via=s(Voe);iSr=r(Via,"SpeechEncoderDecoderModel"),Via.forEach(t),dSr=r(kYe," (Speech Encoder decoder model)"),kYe.forEach(t),mSr=i(Ece),X3=n(Ece,"LI",{});var SYe=s(X3);i6e=n(SYe,"STRONG",{});var Xia=s(i6e);cSr=r(Xia,"speech_to_text"),Xia.forEach(t),fSr=r(SYe," \u2014 "),Xoe=n(SYe,"A",{href:!0});var zia=s(Xoe);gSr=r(zia,"Speech2TextForConditionalGeneration"),zia.forEach(t),hSr=r(SYe," (Speech2Text model)"),SYe.forEach(t),uSr=i(Ece),z3=n(Ece,"LI",{});var RYe=s(z3);d6e=n(RYe,"STRONG",{});var Qia=s(d6e);pSr=r(Qia,"whisper"),Qia.forEach(t),_Sr=r(RYe," \u2014 "),zoe=n(RYe,"A",{href:!0});var Wia=s(zoe);bSr=r(Wia,"WhisperForConditionalGeneration"),Wia.forEach(t),vSr=r(RYe," (Whisper model)"),RYe.forEach(t),Ece.forEach(t),FSr=i(Wa),Q3=n(Wa,"P",{});var PYe=s(Q3);TSr=r(PYe,"The model is set in evaluation mode by default using "),m6e=n(PYe,"CODE",{});var Uia=s(m6e);MSr=r(Uia,"model.eval()"),Uia.forEach(t),ESr=r(PYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),c6e=n(PYe,"CODE",{});var Hia=s(c6e);CSr=r(Hia,"model.train()"),Hia.forEach(t),PYe.forEach(t),wSr=i(Wa),T(W3.$$.fragment,Wa),Wa.forEach(t),si.forEach(t),xno=i(c),Xm=n(c,"H2",{class:!0});var Ulo=s(Xm);U3=n(Ulo,"A",{id:!0,class:!0,href:!0});var Jia=s(U3);f6e=n(Jia,"SPAN",{});var Yia=s(f6e);T(WS.$$.fragment,Yia),Yia.forEach(t),Jia.forEach(t),ASr=i(Ulo),g6e=n(Ulo,"SPAN",{});var Zia=s(g6e);LSr=r(Zia,"AutoModelForAudioXVector"),Zia.forEach(t),Ulo.forEach(t),$no=i(c),tr=n(c,"DIV",{class:!0});var li=s(tr);T(US.$$.fragment,li),ySr=i(li),zm=n(li,"P",{});var Cce=s(zm);xSr=r(Cce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),Qoe=n(Cce,"A",{href:!0});var Kia=s(Qoe);$Sr=r(Kia,"from_pretrained()"),Kia.forEach(t),kSr=r(Cce," class method or the "),Woe=n(Cce,"A",{href:!0});var eda=s(Woe);SSr=r(eda,"from_config()"),eda.forEach(t),RSr=r(Cce,` class
method.`),Cce.forEach(t),PSr=i(li),HS=n(li,"P",{});var Hlo=s(HS);BSr=r(Hlo,"This class cannot be instantiated directly using "),h6e=n(Hlo,"CODE",{});var oda=s(h6e);ISr=r(oda,"__init__()"),oda.forEach(t),NSr=r(Hlo," (throws an error)."),Hlo.forEach(t),qSr=i(li),Xt=n(li,"DIV",{class:!0});var rx=s(Xt);T(JS.$$.fragment,rx),jSr=i(rx),u6e=n(rx,"P",{});var rda=s(u6e);DSr=r(rda,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),rda.forEach(t),GSr=i(rx),Qm=n(rx,"P",{});var wce=s(Qm);OSr=r(wce,`Note:
Loading a model from its configuration file does `),p6e=n(wce,"STRONG",{});var tda=s(p6e);VSr=r(tda,"not"),tda.forEach(t),XSr=r(wce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Uoe=n(wce,"A",{href:!0});var ada=s(Uoe);zSr=r(ada,"from_pretrained()"),ada.forEach(t),QSr=r(wce," to load the model weights."),wce.forEach(t),WSr=i(rx),T(H3.$$.fragment,rx),rx.forEach(t),USr=i(li),To=n(li,"DIV",{class:!0});var Ua=s(To);T(YS.$$.fragment,Ua),HSr=i(Ua),_6e=n(Ua,"P",{});var nda=s(_6e);JSr=r(nda,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),nda.forEach(t),YSr=i(Ua),Ln=n(Ua,"P",{});var tx=s(Ln);ZSr=r(tx,"The model class to instantiate is selected based on the "),b6e=n(tx,"CODE",{});var sda=s(b6e);KSr=r(sda,"model_type"),sda.forEach(t),eRr=r(tx,` property of the config object (either
passed as an argument or loaded from `),v6e=n(tx,"CODE",{});var lda=s(v6e);oRr=r(lda,"pretrained_model_name_or_path"),lda.forEach(t),rRr=r(tx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F6e=n(tx,"CODE",{});var ida=s(F6e);tRr=r(ida,"pretrained_model_name_or_path"),ida.forEach(t),aRr=r(tx,":"),tx.forEach(t),nRr=i(Ua),pt=n(Ua,"UL",{});var ii=s(pt);J3=n(ii,"LI",{});var BYe=s(J3);T6e=n(BYe,"STRONG",{});var dda=s(T6e);sRr=r(dda,"data2vec-audio"),dda.forEach(t),lRr=r(BYe," \u2014 "),Hoe=n(BYe,"A",{href:!0});var mda=s(Hoe);iRr=r(mda,"Data2VecAudioForXVector"),mda.forEach(t),dRr=r(BYe," (Data2VecAudio model)"),BYe.forEach(t),mRr=i(ii),Y3=n(ii,"LI",{});var IYe=s(Y3);M6e=n(IYe,"STRONG",{});var cda=s(M6e);cRr=r(cda,"unispeech-sat"),cda.forEach(t),fRr=r(IYe," \u2014 "),Joe=n(IYe,"A",{href:!0});var fda=s(Joe);gRr=r(fda,"UniSpeechSatForXVector"),fda.forEach(t),hRr=r(IYe," (UniSpeechSat model)"),IYe.forEach(t),uRr=i(ii),Z3=n(ii,"LI",{});var NYe=s(Z3);E6e=n(NYe,"STRONG",{});var gda=s(E6e);pRr=r(gda,"wav2vec2"),gda.forEach(t),_Rr=r(NYe," \u2014 "),Yoe=n(NYe,"A",{href:!0});var hda=s(Yoe);bRr=r(hda,"Wav2Vec2ForXVector"),hda.forEach(t),vRr=r(NYe," (Wav2Vec2 model)"),NYe.forEach(t),FRr=i(ii),K3=n(ii,"LI",{});var qYe=s(K3);C6e=n(qYe,"STRONG",{});var uda=s(C6e);TRr=r(uda,"wav2vec2-conformer"),uda.forEach(t),MRr=r(qYe," \u2014 "),Zoe=n(qYe,"A",{href:!0});var pda=s(Zoe);ERr=r(pda,"Wav2Vec2ConformerForXVector"),pda.forEach(t),CRr=r(qYe," (Wav2Vec2-Conformer model)"),qYe.forEach(t),wRr=i(ii),e5=n(ii,"LI",{});var jYe=s(e5);w6e=n(jYe,"STRONG",{});var _da=s(w6e);ARr=r(_da,"wavlm"),_da.forEach(t),LRr=r(jYe," \u2014 "),Koe=n(jYe,"A",{href:!0});var bda=s(Koe);yRr=r(bda,"WavLMForXVector"),bda.forEach(t),xRr=r(jYe," (WavLM model)"),jYe.forEach(t),ii.forEach(t),$Rr=i(Ua),o5=n(Ua,"P",{});var DYe=s(o5);kRr=r(DYe,"The model is set in evaluation mode by default using "),A6e=n(DYe,"CODE",{});var vda=s(A6e);SRr=r(vda,"model.eval()"),vda.forEach(t),RRr=r(DYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),L6e=n(DYe,"CODE",{});var Fda=s(L6e);PRr=r(Fda,"model.train()"),Fda.forEach(t),DYe.forEach(t),BRr=i(Ua),T(r5.$$.fragment,Ua),Ua.forEach(t),li.forEach(t),kno=i(c),Wm=n(c,"H2",{class:!0});var Jlo=s(Wm);t5=n(Jlo,"A",{id:!0,class:!0,href:!0});var Tda=s(t5);y6e=n(Tda,"SPAN",{});var Mda=s(y6e);T(ZS.$$.fragment,Mda),Mda.forEach(t),Tda.forEach(t),IRr=i(Jlo),x6e=n(Jlo,"SPAN",{});var Eda=s(x6e);NRr=r(Eda,"AutoModelForMaskedImageModeling"),Eda.forEach(t),Jlo.forEach(t),Sno=i(c),ar=n(c,"DIV",{class:!0});var di=s(ar);T(KS.$$.fragment,di),qRr=i(di),Um=n(di,"P",{});var Ace=s(Um);jRr=r(Ace,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),ere=n(Ace,"A",{href:!0});var Cda=s(ere);DRr=r(Cda,"from_pretrained()"),Cda.forEach(t),GRr=r(Ace," class method or the "),ore=n(Ace,"A",{href:!0});var wda=s(ore);ORr=r(wda,"from_config()"),wda.forEach(t),VRr=r(Ace,` class
method.`),Ace.forEach(t),XRr=i(di),eR=n(di,"P",{});var Ylo=s(eR);zRr=r(Ylo,"This class cannot be instantiated directly using "),$6e=n(Ylo,"CODE",{});var Ada=s($6e);QRr=r(Ada,"__init__()"),Ada.forEach(t),WRr=r(Ylo," (throws an error)."),Ylo.forEach(t),URr=i(di),zt=n(di,"DIV",{class:!0});var ax=s(zt);T(oR.$$.fragment,ax),HRr=i(ax),k6e=n(ax,"P",{});var Lda=s(k6e);JRr=r(Lda,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),Lda.forEach(t),YRr=i(ax),Hm=n(ax,"P",{});var Lce=s(Hm);ZRr=r(Lce,`Note:
Loading a model from its configuration file does `),S6e=n(Lce,"STRONG",{});var yda=s(S6e);KRr=r(yda,"not"),yda.forEach(t),ePr=r(Lce,` load the model weights. It only affects the
model\u2019s configuration. Use `),rre=n(Lce,"A",{href:!0});var xda=s(rre);oPr=r(xda,"from_pretrained()"),xda.forEach(t),rPr=r(Lce," to load the model weights."),Lce.forEach(t),tPr=i(ax),T(a5.$$.fragment,ax),ax.forEach(t),aPr=i(di),Mo=n(di,"DIV",{class:!0});var Ha=s(Mo);T(rR.$$.fragment,Ha),nPr=i(Ha),R6e=n(Ha,"P",{});var $da=s(R6e);sPr=r($da,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),$da.forEach(t),lPr=i(Ha),yn=n(Ha,"P",{});var nx=s(yn);iPr=r(nx,"The model class to instantiate is selected based on the "),P6e=n(nx,"CODE",{});var kda=s(P6e);dPr=r(kda,"model_type"),kda.forEach(t),mPr=r(nx,` property of the config object (either
passed as an argument or loaded from `),B6e=n(nx,"CODE",{});var Sda=s(B6e);cPr=r(Sda,"pretrained_model_name_or_path"),Sda.forEach(t),fPr=r(nx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I6e=n(nx,"CODE",{});var Rda=s(I6e);gPr=r(Rda,"pretrained_model_name_or_path"),Rda.forEach(t),hPr=r(nx,":"),nx.forEach(t),uPr=i(Ha),xn=n(Ha,"UL",{});var sx=s(xn);n5=n(sx,"LI",{});var GYe=s(n5);N6e=n(GYe,"STRONG",{});var Pda=s(N6e);pPr=r(Pda,"deit"),Pda.forEach(t),_Pr=r(GYe," \u2014 "),tre=n(GYe,"A",{href:!0});var Bda=s(tre);bPr=r(Bda,"DeiTForMaskedImageModeling"),Bda.forEach(t),vPr=r(GYe," (DeiT model)"),GYe.forEach(t),FPr=i(sx),s5=n(sx,"LI",{});var OYe=s(s5);q6e=n(OYe,"STRONG",{});var Ida=s(q6e);TPr=r(Ida,"swin"),Ida.forEach(t),MPr=r(OYe," \u2014 "),are=n(OYe,"A",{href:!0});var Nda=s(are);EPr=r(Nda,"SwinForMaskedImageModeling"),Nda.forEach(t),CPr=r(OYe," (Swin Transformer model)"),OYe.forEach(t),wPr=i(sx),l5=n(sx,"LI",{});var VYe=s(l5);j6e=n(VYe,"STRONG",{});var qda=s(j6e);APr=r(qda,"swinv2"),qda.forEach(t),LPr=r(VYe," \u2014 "),nre=n(VYe,"A",{href:!0});var jda=s(nre);yPr=r(jda,"Swinv2ForMaskedImageModeling"),jda.forEach(t),xPr=r(VYe," (Swin Transformer V2 model)"),VYe.forEach(t),$Pr=i(sx),i5=n(sx,"LI",{});var XYe=s(i5);D6e=n(XYe,"STRONG",{});var Dda=s(D6e);kPr=r(Dda,"vit"),Dda.forEach(t),SPr=r(XYe," \u2014 "),sre=n(XYe,"A",{href:!0});var Gda=s(sre);RPr=r(Gda,"ViTForMaskedImageModeling"),Gda.forEach(t),PPr=r(XYe," (ViT model)"),XYe.forEach(t),sx.forEach(t),BPr=i(Ha),d5=n(Ha,"P",{});var zYe=s(d5);IPr=r(zYe,"The model is set in evaluation mode by default using "),G6e=n(zYe,"CODE",{});var Oda=s(G6e);NPr=r(Oda,"model.eval()"),Oda.forEach(t),qPr=r(zYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),O6e=n(zYe,"CODE",{});var Vda=s(O6e);jPr=r(Vda,"model.train()"),Vda.forEach(t),zYe.forEach(t),DPr=i(Ha),T(m5.$$.fragment,Ha),Ha.forEach(t),di.forEach(t),Rno=i(c),Jm=n(c,"H2",{class:!0});var Zlo=s(Jm);c5=n(Zlo,"A",{id:!0,class:!0,href:!0});var Xda=s(c5);V6e=n(Xda,"SPAN",{});var zda=s(V6e);T(tR.$$.fragment,zda),zda.forEach(t),Xda.forEach(t),GPr=i(Zlo),X6e=n(Zlo,"SPAN",{});var Qda=s(X6e);OPr=r(Qda,"AutoModelForObjectDetection"),Qda.forEach(t),Zlo.forEach(t),Pno=i(c),nr=n(c,"DIV",{class:!0});var mi=s(nr);T(aR.$$.fragment,mi),VPr=i(mi),Ym=n(mi,"P",{});var yce=s(Ym);XPr=r(yce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),lre=n(yce,"A",{href:!0});var Wda=s(lre);zPr=r(Wda,"from_pretrained()"),Wda.forEach(t),QPr=r(yce," class method or the "),ire=n(yce,"A",{href:!0});var Uda=s(ire);WPr=r(Uda,"from_config()"),Uda.forEach(t),UPr=r(yce,` class
method.`),yce.forEach(t),HPr=i(mi),nR=n(mi,"P",{});var Klo=s(nR);JPr=r(Klo,"This class cannot be instantiated directly using "),z6e=n(Klo,"CODE",{});var Hda=s(z6e);YPr=r(Hda,"__init__()"),Hda.forEach(t),ZPr=r(Klo," (throws an error)."),Klo.forEach(t),KPr=i(mi),Qt=n(mi,"DIV",{class:!0});var lx=s(Qt);T(sR.$$.fragment,lx),eBr=i(lx),Q6e=n(lx,"P",{});var Jda=s(Q6e);oBr=r(Jda,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),Jda.forEach(t),rBr=i(lx),Zm=n(lx,"P",{});var xce=s(Zm);tBr=r(xce,`Note:
Loading a model from its configuration file does `),W6e=n(xce,"STRONG",{});var Yda=s(W6e);aBr=r(Yda,"not"),Yda.forEach(t),nBr=r(xce,` load the model weights. It only affects the
model\u2019s configuration. Use `),dre=n(xce,"A",{href:!0});var Zda=s(dre);sBr=r(Zda,"from_pretrained()"),Zda.forEach(t),lBr=r(xce," to load the model weights."),xce.forEach(t),iBr=i(lx),T(f5.$$.fragment,lx),lx.forEach(t),dBr=i(mi),Eo=n(mi,"DIV",{class:!0});var Ja=s(Eo);T(lR.$$.fragment,Ja),mBr=i(Ja),U6e=n(Ja,"P",{});var Kda=s(U6e);cBr=r(Kda,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),Kda.forEach(t),fBr=i(Ja),$n=n(Ja,"P",{});var ix=s($n);gBr=r(ix,"The model class to instantiate is selected based on the "),H6e=n(ix,"CODE",{});var ema=s(H6e);hBr=r(ema,"model_type"),ema.forEach(t),uBr=r(ix,` property of the config object (either
passed as an argument or loaded from `),J6e=n(ix,"CODE",{});var oma=s(J6e);pBr=r(oma,"pretrained_model_name_or_path"),oma.forEach(t),_Br=r(ix,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Y6e=n(ix,"CODE",{});var rma=s(Y6e);bBr=r(rma,"pretrained_model_name_or_path"),rma.forEach(t),vBr=r(ix,":"),ix.forEach(t),FBr=i(Ja),_t=n(Ja,"UL",{});var ci=s(_t);g5=n(ci,"LI",{});var QYe=s(g5);Z6e=n(QYe,"STRONG",{});var tma=s(Z6e);TBr=r(tma,"conditional_detr"),tma.forEach(t),MBr=r(QYe," \u2014 "),mre=n(QYe,"A",{href:!0});var ama=s(mre);EBr=r(ama,"ConditionalDetrForObjectDetection"),ama.forEach(t),CBr=r(QYe," (Conditional DETR model)"),QYe.forEach(t),wBr=i(ci),h5=n(ci,"LI",{});var WYe=s(h5);K6e=n(WYe,"STRONG",{});var nma=s(K6e);ABr=r(nma,"deformable_detr"),nma.forEach(t),LBr=r(WYe," \u2014 "),cre=n(WYe,"A",{href:!0});var sma=s(cre);yBr=r(sma,"DeformableDetrForObjectDetection"),sma.forEach(t),xBr=r(WYe," (Deformable DETR model)"),WYe.forEach(t),$Br=i(ci),u5=n(ci,"LI",{});var UYe=s(u5);e7e=n(UYe,"STRONG",{});var lma=s(e7e);kBr=r(lma,"detr"),lma.forEach(t),SBr=r(UYe," \u2014 "),fre=n(UYe,"A",{href:!0});var ima=s(fre);RBr=r(ima,"DetrForObjectDetection"),ima.forEach(t),PBr=r(UYe," (DETR model)"),UYe.forEach(t),BBr=i(ci),p5=n(ci,"LI",{});var HYe=s(p5);o7e=n(HYe,"STRONG",{});var dma=s(o7e);IBr=r(dma,"table-transformer"),dma.forEach(t),NBr=r(HYe," \u2014 "),gre=n(HYe,"A",{href:!0});var mma=s(gre);qBr=r(mma,"TableTransformerForObjectDetection"),mma.forEach(t),jBr=r(HYe," (Table Transformer model)"),HYe.forEach(t),DBr=i(ci),_5=n(ci,"LI",{});var JYe=s(_5);r7e=n(JYe,"STRONG",{});var cma=s(r7e);GBr=r(cma,"yolos"),cma.forEach(t),OBr=r(JYe," \u2014 "),hre=n(JYe,"A",{href:!0});var fma=s(hre);VBr=r(fma,"YolosForObjectDetection"),fma.forEach(t),XBr=r(JYe," (YOLOS model)"),JYe.forEach(t),ci.forEach(t),zBr=i(Ja),b5=n(Ja,"P",{});var YYe=s(b5);QBr=r(YYe,"The model is set in evaluation mode by default using "),t7e=n(YYe,"CODE",{});var gma=s(t7e);WBr=r(gma,"model.eval()"),gma.forEach(t),UBr=r(YYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),a7e=n(YYe,"CODE",{});var hma=s(a7e);HBr=r(hma,"model.train()"),hma.forEach(t),YYe.forEach(t),JBr=i(Ja),T(v5.$$.fragment,Ja),Ja.forEach(t),mi.forEach(t),Bno=i(c),Km=n(c,"H2",{class:!0});var eio=s(Km);F5=n(eio,"A",{id:!0,class:!0,href:!0});var uma=s(F5);n7e=n(uma,"SPAN",{});var pma=s(n7e);T(iR.$$.fragment,pma),pma.forEach(t),uma.forEach(t),YBr=i(eio),s7e=n(eio,"SPAN",{});var _ma=s(s7e);ZBr=r(_ma,"AutoModelForImageSegmentation"),_ma.forEach(t),eio.forEach(t),Ino=i(c),sr=n(c,"DIV",{class:!0});var fi=s(sr);T(dR.$$.fragment,fi),KBr=i(fi),ec=n(fi,"P",{});var $ce=s(ec);eIr=r($ce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),ure=n($ce,"A",{href:!0});var bma=s(ure);oIr=r(bma,"from_pretrained()"),bma.forEach(t),rIr=r($ce," class method or the "),pre=n($ce,"A",{href:!0});var vma=s(pre);tIr=r(vma,"from_config()"),vma.forEach(t),aIr=r($ce,` class
method.`),$ce.forEach(t),nIr=i(fi),mR=n(fi,"P",{});var oio=s(mR);sIr=r(oio,"This class cannot be instantiated directly using "),l7e=n(oio,"CODE",{});var Fma=s(l7e);lIr=r(Fma,"__init__()"),Fma.forEach(t),iIr=r(oio," (throws an error)."),oio.forEach(t),dIr=i(fi),Wt=n(fi,"DIV",{class:!0});var dx=s(Wt);T(cR.$$.fragment,dx),mIr=i(dx),i7e=n(dx,"P",{});var Tma=s(i7e);cIr=r(Tma,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),Tma.forEach(t),fIr=i(dx),oc=n(dx,"P",{});var kce=s(oc);gIr=r(kce,`Note:
Loading a model from its configuration file does `),d7e=n(kce,"STRONG",{});var Mma=s(d7e);hIr=r(Mma,"not"),Mma.forEach(t),uIr=r(kce,` load the model weights. It only affects the
model\u2019s configuration. Use `),_re=n(kce,"A",{href:!0});var Ema=s(_re);pIr=r(Ema,"from_pretrained()"),Ema.forEach(t),_Ir=r(kce," to load the model weights."),kce.forEach(t),bIr=i(dx),T(T5.$$.fragment,dx),dx.forEach(t),vIr=i(fi),Co=n(fi,"DIV",{class:!0});var Ya=s(Co);T(fR.$$.fragment,Ya),FIr=i(Ya),m7e=n(Ya,"P",{});var Cma=s(m7e);TIr=r(Cma,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),Cma.forEach(t),MIr=i(Ya),kn=n(Ya,"P",{});var mx=s(kn);EIr=r(mx,"The model class to instantiate is selected based on the "),c7e=n(mx,"CODE",{});var wma=s(c7e);CIr=r(wma,"model_type"),wma.forEach(t),wIr=r(mx,` property of the config object (either
passed as an argument or loaded from `),f7e=n(mx,"CODE",{});var Ama=s(f7e);AIr=r(Ama,"pretrained_model_name_or_path"),Ama.forEach(t),LIr=r(mx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),g7e=n(mx,"CODE",{});var Lma=s(g7e);yIr=r(Lma,"pretrained_model_name_or_path"),Lma.forEach(t),xIr=r(mx,":"),mx.forEach(t),$Ir=i(Ya),h7e=n(Ya,"UL",{});var yma=s(h7e);M5=n(yma,"LI",{});var ZYe=s(M5);u7e=n(ZYe,"STRONG",{});var xma=s(u7e);kIr=r(xma,"detr"),xma.forEach(t),SIr=r(ZYe," \u2014 "),bre=n(ZYe,"A",{href:!0});var $ma=s(bre);RIr=r($ma,"DetrForSegmentation"),$ma.forEach(t),PIr=r(ZYe," (DETR model)"),ZYe.forEach(t),yma.forEach(t),BIr=i(Ya),E5=n(Ya,"P",{});var KYe=s(E5);IIr=r(KYe,"The model is set in evaluation mode by default using "),p7e=n(KYe,"CODE",{});var kma=s(p7e);NIr=r(kma,"model.eval()"),kma.forEach(t),qIr=r(KYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_7e=n(KYe,"CODE",{});var Sma=s(_7e);jIr=r(Sma,"model.train()"),Sma.forEach(t),KYe.forEach(t),DIr=i(Ya),T(C5.$$.fragment,Ya),Ya.forEach(t),fi.forEach(t),Nno=i(c),rc=n(c,"H2",{class:!0});var rio=s(rc);w5=n(rio,"A",{id:!0,class:!0,href:!0});var Rma=s(w5);b7e=n(Rma,"SPAN",{});var Pma=s(b7e);T(gR.$$.fragment,Pma),Pma.forEach(t),Rma.forEach(t),GIr=i(rio),v7e=n(rio,"SPAN",{});var Bma=s(v7e);OIr=r(Bma,"AutoModelForSemanticSegmentation"),Bma.forEach(t),rio.forEach(t),qno=i(c),lr=n(c,"DIV",{class:!0});var gi=s(lr);T(hR.$$.fragment,gi),VIr=i(gi),tc=n(gi,"P",{});var Sce=s(tc);XIr=r(Sce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),vre=n(Sce,"A",{href:!0});var Ima=s(vre);zIr=r(Ima,"from_pretrained()"),Ima.forEach(t),QIr=r(Sce," class method or the "),Fre=n(Sce,"A",{href:!0});var Nma=s(Fre);WIr=r(Nma,"from_config()"),Nma.forEach(t),UIr=r(Sce,` class
method.`),Sce.forEach(t),HIr=i(gi),uR=n(gi,"P",{});var tio=s(uR);JIr=r(tio,"This class cannot be instantiated directly using "),F7e=n(tio,"CODE",{});var qma=s(F7e);YIr=r(qma,"__init__()"),qma.forEach(t),ZIr=r(tio," (throws an error)."),tio.forEach(t),KIr=i(gi),Ut=n(gi,"DIV",{class:!0});var cx=s(Ut);T(pR.$$.fragment,cx),eNr=i(cx),T7e=n(cx,"P",{});var jma=s(T7e);oNr=r(jma,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),jma.forEach(t),rNr=i(cx),ac=n(cx,"P",{});var Rce=s(ac);tNr=r(Rce,`Note:
Loading a model from its configuration file does `),M7e=n(Rce,"STRONG",{});var Dma=s(M7e);aNr=r(Dma,"not"),Dma.forEach(t),nNr=r(Rce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Tre=n(Rce,"A",{href:!0});var Gma=s(Tre);sNr=r(Gma,"from_pretrained()"),Gma.forEach(t),lNr=r(Rce," to load the model weights."),Rce.forEach(t),iNr=i(cx),T(A5.$$.fragment,cx),cx.forEach(t),dNr=i(gi),wo=n(gi,"DIV",{class:!0});var Za=s(wo);T(_R.$$.fragment,Za),mNr=i(Za),E7e=n(Za,"P",{});var Oma=s(E7e);cNr=r(Oma,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Oma.forEach(t),fNr=i(Za),Sn=n(Za,"P",{});var fx=s(Sn);gNr=r(fx,"The model class to instantiate is selected based on the "),C7e=n(fx,"CODE",{});var Vma=s(C7e);hNr=r(Vma,"model_type"),Vma.forEach(t),uNr=r(fx,` property of the config object (either
passed as an argument or loaded from `),w7e=n(fx,"CODE",{});var Xma=s(w7e);pNr=r(Xma,"pretrained_model_name_or_path"),Xma.forEach(t),_Nr=r(fx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),A7e=n(fx,"CODE",{});var zma=s(A7e);bNr=r(zma,"pretrained_model_name_or_path"),zma.forEach(t),vNr=r(fx,":"),fx.forEach(t),FNr=i(Za),bt=n(Za,"UL",{});var hi=s(bt);L5=n(hi,"LI",{});var eZe=s(L5);L7e=n(eZe,"STRONG",{});var Qma=s(L7e);TNr=r(Qma,"beit"),Qma.forEach(t),MNr=r(eZe," \u2014 "),Mre=n(eZe,"A",{href:!0});var Wma=s(Mre);ENr=r(Wma,"BeitForSemanticSegmentation"),Wma.forEach(t),CNr=r(eZe," (BEiT model)"),eZe.forEach(t),wNr=i(hi),y5=n(hi,"LI",{});var oZe=s(y5);y7e=n(oZe,"STRONG",{});var Uma=s(y7e);ANr=r(Uma,"data2vec-vision"),Uma.forEach(t),LNr=r(oZe," \u2014 "),Ere=n(oZe,"A",{href:!0});var Hma=s(Ere);yNr=r(Hma,"Data2VecVisionForSemanticSegmentation"),Hma.forEach(t),xNr=r(oZe," (Data2VecVision model)"),oZe.forEach(t),$Nr=i(hi),x5=n(hi,"LI",{});var rZe=s(x5);x7e=n(rZe,"STRONG",{});var Jma=s(x7e);kNr=r(Jma,"dpt"),Jma.forEach(t),SNr=r(rZe," \u2014 "),Cre=n(rZe,"A",{href:!0});var Yma=s(Cre);RNr=r(Yma,"DPTForSemanticSegmentation"),Yma.forEach(t),PNr=r(rZe," (DPT model)"),rZe.forEach(t),BNr=i(hi),$5=n(hi,"LI",{});var tZe=s($5);$7e=n(tZe,"STRONG",{});var Zma=s($7e);INr=r(Zma,"mobilevit"),Zma.forEach(t),NNr=r(tZe," \u2014 "),wre=n(tZe,"A",{href:!0});var Kma=s(wre);qNr=r(Kma,"MobileViTForSemanticSegmentation"),Kma.forEach(t),jNr=r(tZe," (MobileViT model)"),tZe.forEach(t),DNr=i(hi),k5=n(hi,"LI",{});var aZe=s(k5);k7e=n(aZe,"STRONG",{});var eca=s(k7e);GNr=r(eca,"segformer"),eca.forEach(t),ONr=r(aZe," \u2014 "),Are=n(aZe,"A",{href:!0});var oca=s(Are);VNr=r(oca,"SegformerForSemanticSegmentation"),oca.forEach(t),XNr=r(aZe," (SegFormer model)"),aZe.forEach(t),hi.forEach(t),zNr=i(Za),S5=n(Za,"P",{});var nZe=s(S5);QNr=r(nZe,"The model is set in evaluation mode by default using "),S7e=n(nZe,"CODE",{});var rca=s(S7e);WNr=r(rca,"model.eval()"),rca.forEach(t),UNr=r(nZe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),R7e=n(nZe,"CODE",{});var tca=s(R7e);HNr=r(tca,"model.train()"),tca.forEach(t),nZe.forEach(t),JNr=i(Za),T(R5.$$.fragment,Za),Za.forEach(t),gi.forEach(t),jno=i(c),nc=n(c,"H2",{class:!0});var aio=s(nc);P5=n(aio,"A",{id:!0,class:!0,href:!0});var aca=s(P5);P7e=n(aca,"SPAN",{});var nca=s(P7e);T(bR.$$.fragment,nca),nca.forEach(t),aca.forEach(t),YNr=i(aio),B7e=n(aio,"SPAN",{});var sca=s(B7e);ZNr=r(sca,"AutoModelForInstanceSegmentation"),sca.forEach(t),aio.forEach(t),Dno=i(c),ir=n(c,"DIV",{class:!0});var ui=s(ir);T(vR.$$.fragment,ui),KNr=i(ui),sc=n(ui,"P",{});var Pce=s(sc);eqr=r(Pce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),Lre=n(Pce,"A",{href:!0});var lca=s(Lre);oqr=r(lca,"from_pretrained()"),lca.forEach(t),rqr=r(Pce," class method or the "),yre=n(Pce,"A",{href:!0});var ica=s(yre);tqr=r(ica,"from_config()"),ica.forEach(t),aqr=r(Pce,` class
method.`),Pce.forEach(t),nqr=i(ui),FR=n(ui,"P",{});var nio=s(FR);sqr=r(nio,"This class cannot be instantiated directly using "),I7e=n(nio,"CODE",{});var dca=s(I7e);lqr=r(dca,"__init__()"),dca.forEach(t),iqr=r(nio," (throws an error)."),nio.forEach(t),dqr=i(ui),Ht=n(ui,"DIV",{class:!0});var gx=s(Ht);T(TR.$$.fragment,gx),mqr=i(gx),N7e=n(gx,"P",{});var mca=s(N7e);cqr=r(mca,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),mca.forEach(t),fqr=i(gx),lc=n(gx,"P",{});var Bce=s(lc);gqr=r(Bce,`Note:
Loading a model from its configuration file does `),q7e=n(Bce,"STRONG",{});var cca=s(q7e);hqr=r(cca,"not"),cca.forEach(t),uqr=r(Bce,` load the model weights. It only affects the
model\u2019s configuration. Use `),xre=n(Bce,"A",{href:!0});var fca=s(xre);pqr=r(fca,"from_pretrained()"),fca.forEach(t),_qr=r(Bce," to load the model weights."),Bce.forEach(t),bqr=i(gx),T(B5.$$.fragment,gx),gx.forEach(t),vqr=i(ui),Ao=n(ui,"DIV",{class:!0});var Ka=s(Ao);T(MR.$$.fragment,Ka),Fqr=i(Ka),j7e=n(Ka,"P",{});var gca=s(j7e);Tqr=r(gca,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),gca.forEach(t),Mqr=i(Ka),Rn=n(Ka,"P",{});var hx=s(Rn);Eqr=r(hx,"The model class to instantiate is selected based on the "),D7e=n(hx,"CODE",{});var hca=s(D7e);Cqr=r(hca,"model_type"),hca.forEach(t),wqr=r(hx,` property of the config object (either
passed as an argument or loaded from `),G7e=n(hx,"CODE",{});var uca=s(G7e);Aqr=r(uca,"pretrained_model_name_or_path"),uca.forEach(t),Lqr=r(hx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O7e=n(hx,"CODE",{});var pca=s(O7e);yqr=r(pca,"pretrained_model_name_or_path"),pca.forEach(t),xqr=r(hx,":"),hx.forEach(t),$qr=i(Ka),V7e=n(Ka,"UL",{});var _ca=s(V7e);I5=n(_ca,"LI",{});var sZe=s(I5);X7e=n(sZe,"STRONG",{});var bca=s(X7e);kqr=r(bca,"maskformer"),bca.forEach(t),Sqr=r(sZe," \u2014 "),$re=n(sZe,"A",{href:!0});var vca=s($re);Rqr=r(vca,"MaskFormerForInstanceSegmentation"),vca.forEach(t),Pqr=r(sZe," (MaskFormer model)"),sZe.forEach(t),_ca.forEach(t),Bqr=i(Ka),N5=n(Ka,"P",{});var lZe=s(N5);Iqr=r(lZe,"The model is set in evaluation mode by default using "),z7e=n(lZe,"CODE",{});var Fca=s(z7e);Nqr=r(Fca,"model.eval()"),Fca.forEach(t),qqr=r(lZe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Q7e=n(lZe,"CODE",{});var Tca=s(Q7e);jqr=r(Tca,"model.train()"),Tca.forEach(t),lZe.forEach(t),Dqr=i(Ka),T(q5.$$.fragment,Ka),Ka.forEach(t),ui.forEach(t),Gno=i(c),ic=n(c,"H2",{class:!0});var sio=s(ic);j5=n(sio,"A",{id:!0,class:!0,href:!0});var Mca=s(j5);W7e=n(Mca,"SPAN",{});var Eca=s(W7e);T(ER.$$.fragment,Eca),Eca.forEach(t),Mca.forEach(t),Gqr=i(sio),U7e=n(sio,"SPAN",{});var Cca=s(U7e);Oqr=r(Cca,"AutoModelForZeroShotObjectDetection"),Cca.forEach(t),sio.forEach(t),Ono=i(c),dr=n(c,"DIV",{class:!0});var pi=s(dr);T(CR.$$.fragment,pi),Vqr=i(pi),dc=n(pi,"P",{});var Ice=s(dc);Xqr=r(Ice,`This is a generic model class that will be instantiated as one of the model classes of the library (with a zero-shot object detection head) when created
with the `),kre=n(Ice,"A",{href:!0});var wca=s(kre);zqr=r(wca,"from_pretrained()"),wca.forEach(t),Qqr=r(Ice," class method or the "),Sre=n(Ice,"A",{href:!0});var Aca=s(Sre);Wqr=r(Aca,"from_config()"),Aca.forEach(t),Uqr=r(Ice,` class
method.`),Ice.forEach(t),Hqr=i(pi),wR=n(pi,"P",{});var lio=s(wR);Jqr=r(lio,"This class cannot be instantiated directly using "),H7e=n(lio,"CODE",{});var Lca=s(H7e);Yqr=r(Lca,"__init__()"),Lca.forEach(t),Zqr=r(lio," (throws an error)."),lio.forEach(t),Kqr=i(pi),Jt=n(pi,"DIV",{class:!0});var ux=s(Jt);T(AR.$$.fragment,ux),ejr=i(ux),J7e=n(ux,"P",{});var yca=s(J7e);ojr=r(yca,"Instantiates one of the model classes of the library (with a zero-shot object detection head) from a configuration."),yca.forEach(t),rjr=i(ux),mc=n(ux,"P",{});var Nce=s(mc);tjr=r(Nce,`Note:
Loading a model from its configuration file does `),Y7e=n(Nce,"STRONG",{});var xca=s(Y7e);ajr=r(xca,"not"),xca.forEach(t),njr=r(Nce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Rre=n(Nce,"A",{href:!0});var $ca=s(Rre);sjr=r($ca,"from_pretrained()"),$ca.forEach(t),ljr=r(Nce," to load the model weights."),Nce.forEach(t),ijr=i(ux),T(D5.$$.fragment,ux),ux.forEach(t),djr=i(pi),Lo=n(pi,"DIV",{class:!0});var en=s(Lo);T(LR.$$.fragment,en),mjr=i(en),Z7e=n(en,"P",{});var kca=s(Z7e);cjr=r(kca,"Instantiate one of the model classes of the library (with a zero-shot object detection head) from a pretrained model."),kca.forEach(t),fjr=i(en),Pn=n(en,"P",{});var px=s(Pn);gjr=r(px,"The model class to instantiate is selected based on the "),K7e=n(px,"CODE",{});var Sca=s(K7e);hjr=r(Sca,"model_type"),Sca.forEach(t),ujr=r(px,` property of the config object (either
passed as an argument or loaded from `),e8e=n(px,"CODE",{});var Rca=s(e8e);pjr=r(Rca,"pretrained_model_name_or_path"),Rca.forEach(t),_jr=r(px,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o8e=n(px,"CODE",{});var Pca=s(o8e);bjr=r(Pca,"pretrained_model_name_or_path"),Pca.forEach(t),vjr=r(px,":"),px.forEach(t),Fjr=i(en),r8e=n(en,"UL",{});var Bca=s(r8e);G5=n(Bca,"LI",{});var iZe=s(G5);t8e=n(iZe,"STRONG",{});var Ica=s(t8e);Tjr=r(Ica,"owlvit"),Ica.forEach(t),Mjr=r(iZe," \u2014 "),Pre=n(iZe,"A",{href:!0});var Nca=s(Pre);Ejr=r(Nca,"OwlViTForObjectDetection"),Nca.forEach(t),Cjr=r(iZe," (OWL-ViT model)"),iZe.forEach(t),Bca.forEach(t),wjr=i(en),O5=n(en,"P",{});var dZe=s(O5);Ajr=r(dZe,"The model is set in evaluation mode by default using "),a8e=n(dZe,"CODE",{});var qca=s(a8e);Ljr=r(qca,"model.eval()"),qca.forEach(t),yjr=r(dZe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),n8e=n(dZe,"CODE",{});var jca=s(n8e);xjr=r(jca,"model.train()"),jca.forEach(t),dZe.forEach(t),$jr=i(en),T(V5.$$.fragment,en),en.forEach(t),pi.forEach(t),Vno=i(c),cc=n(c,"H2",{class:!0});var iio=s(cc);X5=n(iio,"A",{id:!0,class:!0,href:!0});var Dca=s(X5);s8e=n(Dca,"SPAN",{});var Gca=s(s8e);T(yR.$$.fragment,Gca),Gca.forEach(t),Dca.forEach(t),kjr=i(iio),l8e=n(iio,"SPAN",{});var Oca=s(l8e);Sjr=r(Oca,"TFAutoModel"),Oca.forEach(t),iio.forEach(t),Xno=i(c),mr=n(c,"DIV",{class:!0});var _i=s(mr);T(xR.$$.fragment,_i),Rjr=i(_i),fc=n(_i,"P",{});var qce=s(fc);Pjr=r(qce,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Bre=n(qce,"A",{href:!0});var Vca=s(Bre);Bjr=r(Vca,"from_pretrained()"),Vca.forEach(t),Ijr=r(qce," class method or the "),Ire=n(qce,"A",{href:!0});var Xca=s(Ire);Njr=r(Xca,"from_config()"),Xca.forEach(t),qjr=r(qce,` class
method.`),qce.forEach(t),jjr=i(_i),$R=n(_i,"P",{});var dio=s($R);Djr=r(dio,"This class cannot be instantiated directly using "),i8e=n(dio,"CODE",{});var zca=s(i8e);Gjr=r(zca,"__init__()"),zca.forEach(t),Ojr=r(dio," (throws an error)."),dio.forEach(t),Vjr=i(_i),Yt=n(_i,"DIV",{class:!0});var _x=s(Yt);T(kR.$$.fragment,_x),Xjr=i(_x),d8e=n(_x,"P",{});var Qca=s(d8e);zjr=r(Qca,"Instantiates one of the base model classes of the library from a configuration."),Qca.forEach(t),Qjr=i(_x),gc=n(_x,"P",{});var jce=s(gc);Wjr=r(jce,`Note:
Loading a model from its configuration file does `),m8e=n(jce,"STRONG",{});var Wca=s(m8e);Ujr=r(Wca,"not"),Wca.forEach(t),Hjr=r(jce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Nre=n(jce,"A",{href:!0});var Uca=s(Nre);Jjr=r(Uca,"from_pretrained()"),Uca.forEach(t),Yjr=r(jce," to load the model weights."),jce.forEach(t),Zjr=i(_x),T(z5.$$.fragment,_x),_x.forEach(t),Kjr=i(_i),Dr=n(_i,"DIV",{class:!0});var bi=s(Dr);T(SR.$$.fragment,bi),eDr=i(bi),c8e=n(bi,"P",{});var Hca=s(c8e);oDr=r(Hca,"Instantiate one of the base model classes of the library from a pretrained model."),Hca.forEach(t),rDr=i(bi),Bn=n(bi,"P",{});var bx=s(Bn);tDr=r(bx,"The model class to instantiate is selected based on the "),f8e=n(bx,"CODE",{});var Jca=s(f8e);aDr=r(Jca,"model_type"),Jca.forEach(t),nDr=r(bx,` property of the config object (either
passed as an argument or loaded from `),g8e=n(bx,"CODE",{});var Yca=s(g8e);sDr=r(Yca,"pretrained_model_name_or_path"),Yca.forEach(t),lDr=r(bx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h8e=n(bx,"CODE",{});var Zca=s(h8e);iDr=r(Zca,"pretrained_model_name_or_path"),Zca.forEach(t),dDr=r(bx,":"),bx.forEach(t),mDr=i(bi),P=n(bi,"UL",{});var N=s(P);Q5=n(N,"LI",{});var mZe=s(Q5);u8e=n(mZe,"STRONG",{});var Kca=s(u8e);cDr=r(Kca,"albert"),Kca.forEach(t),fDr=r(mZe," \u2014 "),qre=n(mZe,"A",{href:!0});var efa=s(qre);gDr=r(efa,"TFAlbertModel"),efa.forEach(t),hDr=r(mZe," (ALBERT model)"),mZe.forEach(t),uDr=i(N),W5=n(N,"LI",{});var cZe=s(W5);p8e=n(cZe,"STRONG",{});var ofa=s(p8e);pDr=r(ofa,"bart"),ofa.forEach(t),_Dr=r(cZe," \u2014 "),jre=n(cZe,"A",{href:!0});var rfa=s(jre);bDr=r(rfa,"TFBartModel"),rfa.forEach(t),vDr=r(cZe," (BART model)"),cZe.forEach(t),FDr=i(N),U5=n(N,"LI",{});var fZe=s(U5);_8e=n(fZe,"STRONG",{});var tfa=s(_8e);TDr=r(tfa,"bert"),tfa.forEach(t),MDr=r(fZe," \u2014 "),Dre=n(fZe,"A",{href:!0});var afa=s(Dre);EDr=r(afa,"TFBertModel"),afa.forEach(t),CDr=r(fZe," (BERT model)"),fZe.forEach(t),wDr=i(N),H5=n(N,"LI",{});var gZe=s(H5);b8e=n(gZe,"STRONG",{});var nfa=s(b8e);ADr=r(nfa,"blenderbot"),nfa.forEach(t),LDr=r(gZe," \u2014 "),Gre=n(gZe,"A",{href:!0});var sfa=s(Gre);yDr=r(sfa,"TFBlenderbotModel"),sfa.forEach(t),xDr=r(gZe," (Blenderbot model)"),gZe.forEach(t),$Dr=i(N),J5=n(N,"LI",{});var hZe=s(J5);v8e=n(hZe,"STRONG",{});var lfa=s(v8e);kDr=r(lfa,"blenderbot-small"),lfa.forEach(t),SDr=r(hZe," \u2014 "),Ore=n(hZe,"A",{href:!0});var ifa=s(Ore);RDr=r(ifa,"TFBlenderbotSmallModel"),ifa.forEach(t),PDr=r(hZe," (BlenderbotSmall model)"),hZe.forEach(t),BDr=i(N),Y5=n(N,"LI",{});var uZe=s(Y5);F8e=n(uZe,"STRONG",{});var dfa=s(F8e);IDr=r(dfa,"camembert"),dfa.forEach(t),NDr=r(uZe," \u2014 "),Vre=n(uZe,"A",{href:!0});var mfa=s(Vre);qDr=r(mfa,"TFCamembertModel"),mfa.forEach(t),jDr=r(uZe," (CamemBERT model)"),uZe.forEach(t),DDr=i(N),Z5=n(N,"LI",{});var pZe=s(Z5);T8e=n(pZe,"STRONG",{});var cfa=s(T8e);GDr=r(cfa,"clip"),cfa.forEach(t),ODr=r(pZe," \u2014 "),Xre=n(pZe,"A",{href:!0});var ffa=s(Xre);VDr=r(ffa,"TFCLIPModel"),ffa.forEach(t),XDr=r(pZe," (CLIP model)"),pZe.forEach(t),zDr=i(N),K5=n(N,"LI",{});var _Ze=s(K5);M8e=n(_Ze,"STRONG",{});var gfa=s(M8e);QDr=r(gfa,"convbert"),gfa.forEach(t),WDr=r(_Ze," \u2014 "),zre=n(_Ze,"A",{href:!0});var hfa=s(zre);UDr=r(hfa,"TFConvBertModel"),hfa.forEach(t),HDr=r(_Ze," (ConvBERT model)"),_Ze.forEach(t),JDr=i(N),e0=n(N,"LI",{});var bZe=s(e0);E8e=n(bZe,"STRONG",{});var ufa=s(E8e);YDr=r(ufa,"convnext"),ufa.forEach(t),ZDr=r(bZe," \u2014 "),Qre=n(bZe,"A",{href:!0});var pfa=s(Qre);KDr=r(pfa,"TFConvNextModel"),pfa.forEach(t),eGr=r(bZe," (ConvNeXT model)"),bZe.forEach(t),oGr=i(N),o0=n(N,"LI",{});var vZe=s(o0);C8e=n(vZe,"STRONG",{});var _fa=s(C8e);rGr=r(_fa,"ctrl"),_fa.forEach(t),tGr=r(vZe," \u2014 "),Wre=n(vZe,"A",{href:!0});var bfa=s(Wre);aGr=r(bfa,"TFCTRLModel"),bfa.forEach(t),nGr=r(vZe," (CTRL model)"),vZe.forEach(t),sGr=i(N),r0=n(N,"LI",{});var FZe=s(r0);w8e=n(FZe,"STRONG",{});var vfa=s(w8e);lGr=r(vfa,"cvt"),vfa.forEach(t),iGr=r(FZe," \u2014 "),Ure=n(FZe,"A",{href:!0});var Ffa=s(Ure);dGr=r(Ffa,"TFCvtModel"),Ffa.forEach(t),mGr=r(FZe," (CvT model)"),FZe.forEach(t),cGr=i(N),t0=n(N,"LI",{});var TZe=s(t0);A8e=n(TZe,"STRONG",{});var Tfa=s(A8e);fGr=r(Tfa,"data2vec-vision"),Tfa.forEach(t),gGr=r(TZe," \u2014 "),Hre=n(TZe,"A",{href:!0});var Mfa=s(Hre);hGr=r(Mfa,"TFData2VecVisionModel"),Mfa.forEach(t),uGr=r(TZe," (Data2VecVision model)"),TZe.forEach(t),pGr=i(N),a0=n(N,"LI",{});var MZe=s(a0);L8e=n(MZe,"STRONG",{});var Efa=s(L8e);_Gr=r(Efa,"deberta"),Efa.forEach(t),bGr=r(MZe," \u2014 "),Jre=n(MZe,"A",{href:!0});var Cfa=s(Jre);vGr=r(Cfa,"TFDebertaModel"),Cfa.forEach(t),FGr=r(MZe," (DeBERTa model)"),MZe.forEach(t),TGr=i(N),n0=n(N,"LI",{});var EZe=s(n0);y8e=n(EZe,"STRONG",{});var wfa=s(y8e);MGr=r(wfa,"deberta-v2"),wfa.forEach(t),EGr=r(EZe," \u2014 "),Yre=n(EZe,"A",{href:!0});var Afa=s(Yre);CGr=r(Afa,"TFDebertaV2Model"),Afa.forEach(t),wGr=r(EZe," (DeBERTa-v2 model)"),EZe.forEach(t),AGr=i(N),s0=n(N,"LI",{});var CZe=s(s0);x8e=n(CZe,"STRONG",{});var Lfa=s(x8e);LGr=r(Lfa,"deit"),Lfa.forEach(t),yGr=r(CZe," \u2014 "),Zre=n(CZe,"A",{href:!0});var yfa=s(Zre);xGr=r(yfa,"TFDeiTModel"),yfa.forEach(t),$Gr=r(CZe," (DeiT model)"),CZe.forEach(t),kGr=i(N),l0=n(N,"LI",{});var wZe=s(l0);$8e=n(wZe,"STRONG",{});var xfa=s($8e);SGr=r(xfa,"distilbert"),xfa.forEach(t),RGr=r(wZe," \u2014 "),Kre=n(wZe,"A",{href:!0});var $fa=s(Kre);PGr=r($fa,"TFDistilBertModel"),$fa.forEach(t),BGr=r(wZe," (DistilBERT model)"),wZe.forEach(t),IGr=i(N),i0=n(N,"LI",{});var AZe=s(i0);k8e=n(AZe,"STRONG",{});var kfa=s(k8e);NGr=r(kfa,"dpr"),kfa.forEach(t),qGr=r(AZe," \u2014 "),ete=n(AZe,"A",{href:!0});var Sfa=s(ete);jGr=r(Sfa,"TFDPRQuestionEncoder"),Sfa.forEach(t),DGr=r(AZe," (DPR model)"),AZe.forEach(t),GGr=i(N),d0=n(N,"LI",{});var LZe=s(d0);S8e=n(LZe,"STRONG",{});var Rfa=s(S8e);OGr=r(Rfa,"electra"),Rfa.forEach(t),VGr=r(LZe," \u2014 "),ote=n(LZe,"A",{href:!0});var Pfa=s(ote);XGr=r(Pfa,"TFElectraModel"),Pfa.forEach(t),zGr=r(LZe," (ELECTRA model)"),LZe.forEach(t),QGr=i(N),m0=n(N,"LI",{});var yZe=s(m0);R8e=n(yZe,"STRONG",{});var Bfa=s(R8e);WGr=r(Bfa,"esm"),Bfa.forEach(t),UGr=r(yZe," \u2014 "),rte=n(yZe,"A",{href:!0});var Ifa=s(rte);HGr=r(Ifa,"TFEsmModel"),Ifa.forEach(t),JGr=r(yZe," (ESM model)"),yZe.forEach(t),YGr=i(N),c0=n(N,"LI",{});var xZe=s(c0);P8e=n(xZe,"STRONG",{});var Nfa=s(P8e);ZGr=r(Nfa,"flaubert"),Nfa.forEach(t),KGr=r(xZe," \u2014 "),tte=n(xZe,"A",{href:!0});var qfa=s(tte);eOr=r(qfa,"TFFlaubertModel"),qfa.forEach(t),oOr=r(xZe," (FlauBERT model)"),xZe.forEach(t),rOr=i(N),Rl=n(N,"LI",{});var BN=s(Rl);B8e=n(BN,"STRONG",{});var jfa=s(B8e);tOr=r(jfa,"funnel"),jfa.forEach(t),aOr=r(BN," \u2014 "),ate=n(BN,"A",{href:!0});var Dfa=s(ate);nOr=r(Dfa,"TFFunnelModel"),Dfa.forEach(t),sOr=r(BN," or "),nte=n(BN,"A",{href:!0});var Gfa=s(nte);lOr=r(Gfa,"TFFunnelBaseModel"),Gfa.forEach(t),iOr=r(BN," (Funnel Transformer model)"),BN.forEach(t),dOr=i(N),f0=n(N,"LI",{});var $Ze=s(f0);I8e=n($Ze,"STRONG",{});var Ofa=s(I8e);mOr=r(Ofa,"gpt2"),Ofa.forEach(t),cOr=r($Ze," \u2014 "),ste=n($Ze,"A",{href:!0});var Vfa=s(ste);fOr=r(Vfa,"TFGPT2Model"),Vfa.forEach(t),gOr=r($Ze," (OpenAI GPT-2 model)"),$Ze.forEach(t),hOr=i(N),g0=n(N,"LI",{});var kZe=s(g0);N8e=n(kZe,"STRONG",{});var Xfa=s(N8e);uOr=r(Xfa,"gptj"),Xfa.forEach(t),pOr=r(kZe," \u2014 "),lte=n(kZe,"A",{href:!0});var zfa=s(lte);_Or=r(zfa,"TFGPTJModel"),zfa.forEach(t),bOr=r(kZe," (GPT-J model)"),kZe.forEach(t),vOr=i(N),h0=n(N,"LI",{});var SZe=s(h0);q8e=n(SZe,"STRONG",{});var Qfa=s(q8e);FOr=r(Qfa,"groupvit"),Qfa.forEach(t),TOr=r(SZe," \u2014 "),ite=n(SZe,"A",{href:!0});var Wfa=s(ite);MOr=r(Wfa,"TFGroupViTModel"),Wfa.forEach(t),EOr=r(SZe," (GroupViT model)"),SZe.forEach(t),COr=i(N),u0=n(N,"LI",{});var RZe=s(u0);j8e=n(RZe,"STRONG",{});var Ufa=s(j8e);wOr=r(Ufa,"hubert"),Ufa.forEach(t),AOr=r(RZe," \u2014 "),dte=n(RZe,"A",{href:!0});var Hfa=s(dte);LOr=r(Hfa,"TFHubertModel"),Hfa.forEach(t),yOr=r(RZe," (Hubert model)"),RZe.forEach(t),xOr=i(N),p0=n(N,"LI",{});var PZe=s(p0);D8e=n(PZe,"STRONG",{});var Jfa=s(D8e);$Or=r(Jfa,"layoutlm"),Jfa.forEach(t),kOr=r(PZe," \u2014 "),mte=n(PZe,"A",{href:!0});var Yfa=s(mte);SOr=r(Yfa,"TFLayoutLMModel"),Yfa.forEach(t),ROr=r(PZe," (LayoutLM model)"),PZe.forEach(t),POr=i(N),_0=n(N,"LI",{});var BZe=s(_0);G8e=n(BZe,"STRONG",{});var Zfa=s(G8e);BOr=r(Zfa,"layoutlmv3"),Zfa.forEach(t),IOr=r(BZe," \u2014 "),cte=n(BZe,"A",{href:!0});var Kfa=s(cte);NOr=r(Kfa,"TFLayoutLMv3Model"),Kfa.forEach(t),qOr=r(BZe," (LayoutLMv3 model)"),BZe.forEach(t),jOr=i(N),b0=n(N,"LI",{});var IZe=s(b0);O8e=n(IZe,"STRONG",{});var ega=s(O8e);DOr=r(ega,"led"),ega.forEach(t),GOr=r(IZe," \u2014 "),fte=n(IZe,"A",{href:!0});var oga=s(fte);OOr=r(oga,"TFLEDModel"),oga.forEach(t),VOr=r(IZe," (LED model)"),IZe.forEach(t),XOr=i(N),v0=n(N,"LI",{});var NZe=s(v0);V8e=n(NZe,"STRONG",{});var rga=s(V8e);zOr=r(rga,"longformer"),rga.forEach(t),QOr=r(NZe," \u2014 "),gte=n(NZe,"A",{href:!0});var tga=s(gte);WOr=r(tga,"TFLongformerModel"),tga.forEach(t),UOr=r(NZe," (Longformer model)"),NZe.forEach(t),HOr=i(N),F0=n(N,"LI",{});var qZe=s(F0);X8e=n(qZe,"STRONG",{});var aga=s(X8e);JOr=r(aga,"lxmert"),aga.forEach(t),YOr=r(qZe," \u2014 "),hte=n(qZe,"A",{href:!0});var nga=s(hte);ZOr=r(nga,"TFLxmertModel"),nga.forEach(t),KOr=r(qZe," (LXMERT model)"),qZe.forEach(t),eVr=i(N),T0=n(N,"LI",{});var jZe=s(T0);z8e=n(jZe,"STRONG",{});var sga=s(z8e);oVr=r(sga,"marian"),sga.forEach(t),rVr=r(jZe," \u2014 "),ute=n(jZe,"A",{href:!0});var lga=s(ute);tVr=r(lga,"TFMarianModel"),lga.forEach(t),aVr=r(jZe," (Marian model)"),jZe.forEach(t),nVr=i(N),M0=n(N,"LI",{});var DZe=s(M0);Q8e=n(DZe,"STRONG",{});var iga=s(Q8e);sVr=r(iga,"mbart"),iga.forEach(t),lVr=r(DZe," \u2014 "),pte=n(DZe,"A",{href:!0});var dga=s(pte);iVr=r(dga,"TFMBartModel"),dga.forEach(t),dVr=r(DZe," (mBART model)"),DZe.forEach(t),mVr=i(N),E0=n(N,"LI",{});var GZe=s(E0);W8e=n(GZe,"STRONG",{});var mga=s(W8e);cVr=r(mga,"mobilebert"),mga.forEach(t),fVr=r(GZe," \u2014 "),_te=n(GZe,"A",{href:!0});var cga=s(_te);gVr=r(cga,"TFMobileBertModel"),cga.forEach(t),hVr=r(GZe," (MobileBERT model)"),GZe.forEach(t),uVr=i(N),C0=n(N,"LI",{});var OZe=s(C0);U8e=n(OZe,"STRONG",{});var fga=s(U8e);pVr=r(fga,"mobilevit"),fga.forEach(t),_Vr=r(OZe," \u2014 "),bte=n(OZe,"A",{href:!0});var gga=s(bte);bVr=r(gga,"TFMobileViTModel"),gga.forEach(t),vVr=r(OZe," (MobileViT model)"),OZe.forEach(t),FVr=i(N),w0=n(N,"LI",{});var VZe=s(w0);H8e=n(VZe,"STRONG",{});var hga=s(H8e);TVr=r(hga,"mpnet"),hga.forEach(t),MVr=r(VZe," \u2014 "),vte=n(VZe,"A",{href:!0});var uga=s(vte);EVr=r(uga,"TFMPNetModel"),uga.forEach(t),CVr=r(VZe," (MPNet model)"),VZe.forEach(t),wVr=i(N),A0=n(N,"LI",{});var XZe=s(A0);J8e=n(XZe,"STRONG",{});var pga=s(J8e);AVr=r(pga,"mt5"),pga.forEach(t),LVr=r(XZe," \u2014 "),Fte=n(XZe,"A",{href:!0});var _ga=s(Fte);yVr=r(_ga,"TFMT5Model"),_ga.forEach(t),xVr=r(XZe," (MT5 model)"),XZe.forEach(t),$Vr=i(N),L0=n(N,"LI",{});var zZe=s(L0);Y8e=n(zZe,"STRONG",{});var bga=s(Y8e);kVr=r(bga,"openai-gpt"),bga.forEach(t),SVr=r(zZe," \u2014 "),Tte=n(zZe,"A",{href:!0});var vga=s(Tte);RVr=r(vga,"TFOpenAIGPTModel"),vga.forEach(t),PVr=r(zZe," (OpenAI GPT model)"),zZe.forEach(t),BVr=i(N),y0=n(N,"LI",{});var QZe=s(y0);Z8e=n(QZe,"STRONG",{});var Fga=s(Z8e);IVr=r(Fga,"opt"),Fga.forEach(t),NVr=r(QZe," \u2014 "),Mte=n(QZe,"A",{href:!0});var Tga=s(Mte);qVr=r(Tga,"TFOPTModel"),Tga.forEach(t),jVr=r(QZe," (OPT model)"),QZe.forEach(t),DVr=i(N),x0=n(N,"LI",{});var WZe=s(x0);K8e=n(WZe,"STRONG",{});var Mga=s(K8e);GVr=r(Mga,"pegasus"),Mga.forEach(t),OVr=r(WZe," \u2014 "),Ete=n(WZe,"A",{href:!0});var Ega=s(Ete);VVr=r(Ega,"TFPegasusModel"),Ega.forEach(t),XVr=r(WZe," (Pegasus model)"),WZe.forEach(t),zVr=i(N),$0=n(N,"LI",{});var UZe=s($0);eLe=n(UZe,"STRONG",{});var Cga=s(eLe);QVr=r(Cga,"regnet"),Cga.forEach(t),WVr=r(UZe," \u2014 "),Cte=n(UZe,"A",{href:!0});var wga=s(Cte);UVr=r(wga,"TFRegNetModel"),wga.forEach(t),HVr=r(UZe," (RegNet model)"),UZe.forEach(t),JVr=i(N),k0=n(N,"LI",{});var HZe=s(k0);oLe=n(HZe,"STRONG",{});var Aga=s(oLe);YVr=r(Aga,"rembert"),Aga.forEach(t),ZVr=r(HZe," \u2014 "),wte=n(HZe,"A",{href:!0});var Lga=s(wte);KVr=r(Lga,"TFRemBertModel"),Lga.forEach(t),eXr=r(HZe," (RemBERT model)"),HZe.forEach(t),oXr=i(N),S0=n(N,"LI",{});var JZe=s(S0);rLe=n(JZe,"STRONG",{});var yga=s(rLe);rXr=r(yga,"resnet"),yga.forEach(t),tXr=r(JZe," \u2014 "),Ate=n(JZe,"A",{href:!0});var xga=s(Ate);aXr=r(xga,"TFResNetModel"),xga.forEach(t),nXr=r(JZe," (ResNet model)"),JZe.forEach(t),sXr=i(N),R0=n(N,"LI",{});var YZe=s(R0);tLe=n(YZe,"STRONG",{});var $ga=s(tLe);lXr=r($ga,"roberta"),$ga.forEach(t),iXr=r(YZe," \u2014 "),Lte=n(YZe,"A",{href:!0});var kga=s(Lte);dXr=r(kga,"TFRobertaModel"),kga.forEach(t),mXr=r(YZe," (RoBERTa model)"),YZe.forEach(t),cXr=i(N),P0=n(N,"LI",{});var ZZe=s(P0);aLe=n(ZZe,"STRONG",{});var Sga=s(aLe);fXr=r(Sga,"roformer"),Sga.forEach(t),gXr=r(ZZe," \u2014 "),yte=n(ZZe,"A",{href:!0});var Rga=s(yte);hXr=r(Rga,"TFRoFormerModel"),Rga.forEach(t),uXr=r(ZZe," (RoFormer model)"),ZZe.forEach(t),pXr=i(N),B0=n(N,"LI",{});var KZe=s(B0);nLe=n(KZe,"STRONG",{});var Pga=s(nLe);_Xr=r(Pga,"segformer"),Pga.forEach(t),bXr=r(KZe," \u2014 "),xte=n(KZe,"A",{href:!0});var Bga=s(xte);vXr=r(Bga,"TFSegformerModel"),Bga.forEach(t),FXr=r(KZe," (SegFormer model)"),KZe.forEach(t),TXr=i(N),I0=n(N,"LI",{});var eKe=s(I0);sLe=n(eKe,"STRONG",{});var Iga=s(sLe);MXr=r(Iga,"speech_to_text"),Iga.forEach(t),EXr=r(eKe," \u2014 "),$te=n(eKe,"A",{href:!0});var Nga=s($te);CXr=r(Nga,"TFSpeech2TextModel"),Nga.forEach(t),wXr=r(eKe," (Speech2Text model)"),eKe.forEach(t),AXr=i(N),N0=n(N,"LI",{});var oKe=s(N0);lLe=n(oKe,"STRONG",{});var qga=s(lLe);LXr=r(qga,"swin"),qga.forEach(t),yXr=r(oKe," \u2014 "),kte=n(oKe,"A",{href:!0});var jga=s(kte);xXr=r(jga,"TFSwinModel"),jga.forEach(t),$Xr=r(oKe," (Swin Transformer model)"),oKe.forEach(t),kXr=i(N),q0=n(N,"LI",{});var rKe=s(q0);iLe=n(rKe,"STRONG",{});var Dga=s(iLe);SXr=r(Dga,"t5"),Dga.forEach(t),RXr=r(rKe," \u2014 "),Ste=n(rKe,"A",{href:!0});var Gga=s(Ste);PXr=r(Gga,"TFT5Model"),Gga.forEach(t),BXr=r(rKe," (T5 model)"),rKe.forEach(t),IXr=i(N),j0=n(N,"LI",{});var tKe=s(j0);dLe=n(tKe,"STRONG",{});var Oga=s(dLe);NXr=r(Oga,"tapas"),Oga.forEach(t),qXr=r(tKe," \u2014 "),Rte=n(tKe,"A",{href:!0});var Vga=s(Rte);jXr=r(Vga,"TFTapasModel"),Vga.forEach(t),DXr=r(tKe," (TAPAS model)"),tKe.forEach(t),GXr=i(N),D0=n(N,"LI",{});var aKe=s(D0);mLe=n(aKe,"STRONG",{});var Xga=s(mLe);OXr=r(Xga,"transfo-xl"),Xga.forEach(t),VXr=r(aKe," \u2014 "),Pte=n(aKe,"A",{href:!0});var zga=s(Pte);XXr=r(zga,"TFTransfoXLModel"),zga.forEach(t),zXr=r(aKe," (Transformer-XL model)"),aKe.forEach(t),QXr=i(N),G0=n(N,"LI",{});var nKe=s(G0);cLe=n(nKe,"STRONG",{});var Qga=s(cLe);WXr=r(Qga,"vit"),Qga.forEach(t),UXr=r(nKe," \u2014 "),Bte=n(nKe,"A",{href:!0});var Wga=s(Bte);HXr=r(Wga,"TFViTModel"),Wga.forEach(t),JXr=r(nKe," (ViT model)"),nKe.forEach(t),YXr=i(N),O0=n(N,"LI",{});var sKe=s(O0);fLe=n(sKe,"STRONG",{});var Uga=s(fLe);ZXr=r(Uga,"vit_mae"),Uga.forEach(t),KXr=r(sKe," \u2014 "),Ite=n(sKe,"A",{href:!0});var Hga=s(Ite);ezr=r(Hga,"TFViTMAEModel"),Hga.forEach(t),ozr=r(sKe," (ViTMAE model)"),sKe.forEach(t),rzr=i(N),V0=n(N,"LI",{});var lKe=s(V0);gLe=n(lKe,"STRONG",{});var Jga=s(gLe);tzr=r(Jga,"wav2vec2"),Jga.forEach(t),azr=r(lKe," \u2014 "),Nte=n(lKe,"A",{href:!0});var Yga=s(Nte);nzr=r(Yga,"TFWav2Vec2Model"),Yga.forEach(t),szr=r(lKe," (Wav2Vec2 model)"),lKe.forEach(t),lzr=i(N),X0=n(N,"LI",{});var iKe=s(X0);hLe=n(iKe,"STRONG",{});var Zga=s(hLe);izr=r(Zga,"whisper"),Zga.forEach(t),dzr=r(iKe," \u2014 "),qte=n(iKe,"A",{href:!0});var Kga=s(qte);mzr=r(Kga,"TFWhisperModel"),Kga.forEach(t),czr=r(iKe," (Whisper model)"),iKe.forEach(t),fzr=i(N),z0=n(N,"LI",{});var dKe=s(z0);uLe=n(dKe,"STRONG",{});var eha=s(uLe);gzr=r(eha,"xglm"),eha.forEach(t),hzr=r(dKe," \u2014 "),jte=n(dKe,"A",{href:!0});var oha=s(jte);uzr=r(oha,"TFXGLMModel"),oha.forEach(t),pzr=r(dKe," (XGLM model)"),dKe.forEach(t),_zr=i(N),Q0=n(N,"LI",{});var mKe=s(Q0);pLe=n(mKe,"STRONG",{});var rha=s(pLe);bzr=r(rha,"xlm"),rha.forEach(t),vzr=r(mKe," \u2014 "),Dte=n(mKe,"A",{href:!0});var tha=s(Dte);Fzr=r(tha,"TFXLMModel"),tha.forEach(t),Tzr=r(mKe," (XLM model)"),mKe.forEach(t),Mzr=i(N),W0=n(N,"LI",{});var cKe=s(W0);_Le=n(cKe,"STRONG",{});var aha=s(_Le);Ezr=r(aha,"xlm-roberta"),aha.forEach(t),Czr=r(cKe," \u2014 "),Gte=n(cKe,"A",{href:!0});var nha=s(Gte);wzr=r(nha,"TFXLMRobertaModel"),nha.forEach(t),Azr=r(cKe," (XLM-RoBERTa model)"),cKe.forEach(t),Lzr=i(N),U0=n(N,"LI",{});var fKe=s(U0);bLe=n(fKe,"STRONG",{});var sha=s(bLe);yzr=r(sha,"xlnet"),sha.forEach(t),xzr=r(fKe," \u2014 "),Ote=n(fKe,"A",{href:!0});var lha=s(Ote);$zr=r(lha,"TFXLNetModel"),lha.forEach(t),kzr=r(fKe," (XLNet model)"),fKe.forEach(t),N.forEach(t),Szr=i(bi),T(H0.$$.fragment,bi),bi.forEach(t),_i.forEach(t),zno=i(c),hc=n(c,"H2",{class:!0});var mio=s(hc);J0=n(mio,"A",{id:!0,class:!0,href:!0});var iha=s(J0);vLe=n(iha,"SPAN",{});var dha=s(vLe);T(RR.$$.fragment,dha),dha.forEach(t),iha.forEach(t),Rzr=i(mio),FLe=n(mio,"SPAN",{});var mha=s(FLe);Pzr=r(mha,"TFAutoModelForPreTraining"),mha.forEach(t),mio.forEach(t),Qno=i(c),cr=n(c,"DIV",{class:!0});var vi=s(cr);T(PR.$$.fragment,vi),Bzr=i(vi),uc=n(vi,"P",{});var Dce=s(uc);Izr=r(Dce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Vte=n(Dce,"A",{href:!0});var cha=s(Vte);Nzr=r(cha,"from_pretrained()"),cha.forEach(t),qzr=r(Dce," class method or the "),Xte=n(Dce,"A",{href:!0});var fha=s(Xte);jzr=r(fha,"from_config()"),fha.forEach(t),Dzr=r(Dce,` class
method.`),Dce.forEach(t),Gzr=i(vi),BR=n(vi,"P",{});var cio=s(BR);Ozr=r(cio,"This class cannot be instantiated directly using "),TLe=n(cio,"CODE",{});var gha=s(TLe);Vzr=r(gha,"__init__()"),gha.forEach(t),Xzr=r(cio," (throws an error)."),cio.forEach(t),zzr=i(vi),Zt=n(vi,"DIV",{class:!0});var vx=s(Zt);T(IR.$$.fragment,vx),Qzr=i(vx),MLe=n(vx,"P",{});var hha=s(MLe);Wzr=r(hha,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),hha.forEach(t),Uzr=i(vx),pc=n(vx,"P",{});var Gce=s(pc);Hzr=r(Gce,`Note:
Loading a model from its configuration file does `),ELe=n(Gce,"STRONG",{});var uha=s(ELe);Jzr=r(uha,"not"),uha.forEach(t),Yzr=r(Gce,` load the model weights. It only affects the
model\u2019s configuration. Use `),zte=n(Gce,"A",{href:!0});var pha=s(zte);Zzr=r(pha,"from_pretrained()"),pha.forEach(t),Kzr=r(Gce," to load the model weights."),Gce.forEach(t),eQr=i(vx),T(Y0.$$.fragment,vx),vx.forEach(t),oQr=i(vi),Gr=n(vi,"DIV",{class:!0});var Fi=s(Gr);T(NR.$$.fragment,Fi),rQr=i(Fi),CLe=n(Fi,"P",{});var _ha=s(CLe);tQr=r(_ha,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),_ha.forEach(t),aQr=i(Fi),In=n(Fi,"P",{});var Fx=s(In);nQr=r(Fx,"The model class to instantiate is selected based on the "),wLe=n(Fx,"CODE",{});var bha=s(wLe);sQr=r(bha,"model_type"),bha.forEach(t),lQr=r(Fx,` property of the config object (either
passed as an argument or loaded from `),ALe=n(Fx,"CODE",{});var vha=s(ALe);iQr=r(vha,"pretrained_model_name_or_path"),vha.forEach(t),dQr=r(Fx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),LLe=n(Fx,"CODE",{});var Fha=s(LLe);mQr=r(Fha,"pretrained_model_name_or_path"),Fha.forEach(t),cQr=r(Fx,":"),Fx.forEach(t),fQr=i(Fi),le=n(Fi,"UL",{});var me=s(le);Z0=n(me,"LI",{});var gKe=s(Z0);yLe=n(gKe,"STRONG",{});var Tha=s(yLe);gQr=r(Tha,"albert"),Tha.forEach(t),hQr=r(gKe," \u2014 "),Qte=n(gKe,"A",{href:!0});var Mha=s(Qte);uQr=r(Mha,"TFAlbertForPreTraining"),Mha.forEach(t),pQr=r(gKe," (ALBERT model)"),gKe.forEach(t),_Qr=i(me),K0=n(me,"LI",{});var hKe=s(K0);xLe=n(hKe,"STRONG",{});var Eha=s(xLe);bQr=r(Eha,"bart"),Eha.forEach(t),vQr=r(hKe," \u2014 "),Wte=n(hKe,"A",{href:!0});var Cha=s(Wte);FQr=r(Cha,"TFBartForConditionalGeneration"),Cha.forEach(t),TQr=r(hKe," (BART model)"),hKe.forEach(t),MQr=i(me),ew=n(me,"LI",{});var uKe=s(ew);$Le=n(uKe,"STRONG",{});var wha=s($Le);EQr=r(wha,"bert"),wha.forEach(t),CQr=r(uKe," \u2014 "),Ute=n(uKe,"A",{href:!0});var Aha=s(Ute);wQr=r(Aha,"TFBertForPreTraining"),Aha.forEach(t),AQr=r(uKe," (BERT model)"),uKe.forEach(t),LQr=i(me),ow=n(me,"LI",{});var pKe=s(ow);kLe=n(pKe,"STRONG",{});var Lha=s(kLe);yQr=r(Lha,"camembert"),Lha.forEach(t),xQr=r(pKe," \u2014 "),Hte=n(pKe,"A",{href:!0});var yha=s(Hte);$Qr=r(yha,"TFCamembertForMaskedLM"),yha.forEach(t),kQr=r(pKe," (CamemBERT model)"),pKe.forEach(t),SQr=i(me),rw=n(me,"LI",{});var _Ke=s(rw);SLe=n(_Ke,"STRONG",{});var xha=s(SLe);RQr=r(xha,"ctrl"),xha.forEach(t),PQr=r(_Ke," \u2014 "),Jte=n(_Ke,"A",{href:!0});var $ha=s(Jte);BQr=r($ha,"TFCTRLLMHeadModel"),$ha.forEach(t),IQr=r(_Ke," (CTRL model)"),_Ke.forEach(t),NQr=i(me),tw=n(me,"LI",{});var bKe=s(tw);RLe=n(bKe,"STRONG",{});var kha=s(RLe);qQr=r(kha,"distilbert"),kha.forEach(t),jQr=r(bKe," \u2014 "),Yte=n(bKe,"A",{href:!0});var Sha=s(Yte);DQr=r(Sha,"TFDistilBertForMaskedLM"),Sha.forEach(t),GQr=r(bKe," (DistilBERT model)"),bKe.forEach(t),OQr=i(me),aw=n(me,"LI",{});var vKe=s(aw);PLe=n(vKe,"STRONG",{});var Rha=s(PLe);VQr=r(Rha,"electra"),Rha.forEach(t),XQr=r(vKe," \u2014 "),Zte=n(vKe,"A",{href:!0});var Pha=s(Zte);zQr=r(Pha,"TFElectraForPreTraining"),Pha.forEach(t),QQr=r(vKe," (ELECTRA model)"),vKe.forEach(t),WQr=i(me),nw=n(me,"LI",{});var FKe=s(nw);BLe=n(FKe,"STRONG",{});var Bha=s(BLe);UQr=r(Bha,"flaubert"),Bha.forEach(t),HQr=r(FKe," \u2014 "),Kte=n(FKe,"A",{href:!0});var Iha=s(Kte);JQr=r(Iha,"TFFlaubertWithLMHeadModel"),Iha.forEach(t),YQr=r(FKe," (FlauBERT model)"),FKe.forEach(t),ZQr=i(me),sw=n(me,"LI",{});var TKe=s(sw);ILe=n(TKe,"STRONG",{});var Nha=s(ILe);KQr=r(Nha,"funnel"),Nha.forEach(t),eWr=r(TKe," \u2014 "),eae=n(TKe,"A",{href:!0});var qha=s(eae);oWr=r(qha,"TFFunnelForPreTraining"),qha.forEach(t),rWr=r(TKe," (Funnel Transformer model)"),TKe.forEach(t),tWr=i(me),lw=n(me,"LI",{});var MKe=s(lw);NLe=n(MKe,"STRONG",{});var jha=s(NLe);aWr=r(jha,"gpt2"),jha.forEach(t),nWr=r(MKe," \u2014 "),oae=n(MKe,"A",{href:!0});var Dha=s(oae);sWr=r(Dha,"TFGPT2LMHeadModel"),Dha.forEach(t),lWr=r(MKe," (OpenAI GPT-2 model)"),MKe.forEach(t),iWr=i(me),iw=n(me,"LI",{});var EKe=s(iw);qLe=n(EKe,"STRONG",{});var Gha=s(qLe);dWr=r(Gha,"layoutlm"),Gha.forEach(t),mWr=r(EKe," \u2014 "),rae=n(EKe,"A",{href:!0});var Oha=s(rae);cWr=r(Oha,"TFLayoutLMForMaskedLM"),Oha.forEach(t),fWr=r(EKe," (LayoutLM model)"),EKe.forEach(t),gWr=i(me),dw=n(me,"LI",{});var CKe=s(dw);jLe=n(CKe,"STRONG",{});var Vha=s(jLe);hWr=r(Vha,"lxmert"),Vha.forEach(t),uWr=r(CKe," \u2014 "),tae=n(CKe,"A",{href:!0});var Xha=s(tae);pWr=r(Xha,"TFLxmertForPreTraining"),Xha.forEach(t),_Wr=r(CKe," (LXMERT model)"),CKe.forEach(t),bWr=i(me),mw=n(me,"LI",{});var wKe=s(mw);DLe=n(wKe,"STRONG",{});var zha=s(DLe);vWr=r(zha,"mobilebert"),zha.forEach(t),FWr=r(wKe," \u2014 "),aae=n(wKe,"A",{href:!0});var Qha=s(aae);TWr=r(Qha,"TFMobileBertForPreTraining"),Qha.forEach(t),MWr=r(wKe," (MobileBERT model)"),wKe.forEach(t),EWr=i(me),cw=n(me,"LI",{});var AKe=s(cw);GLe=n(AKe,"STRONG",{});var Wha=s(GLe);CWr=r(Wha,"mpnet"),Wha.forEach(t),wWr=r(AKe," \u2014 "),nae=n(AKe,"A",{href:!0});var Uha=s(nae);AWr=r(Uha,"TFMPNetForMaskedLM"),Uha.forEach(t),LWr=r(AKe," (MPNet model)"),AKe.forEach(t),yWr=i(me),fw=n(me,"LI",{});var LKe=s(fw);OLe=n(LKe,"STRONG",{});var Hha=s(OLe);xWr=r(Hha,"openai-gpt"),Hha.forEach(t),$Wr=r(LKe," \u2014 "),sae=n(LKe,"A",{href:!0});var Jha=s(sae);kWr=r(Jha,"TFOpenAIGPTLMHeadModel"),Jha.forEach(t),SWr=r(LKe," (OpenAI GPT model)"),LKe.forEach(t),RWr=i(me),gw=n(me,"LI",{});var yKe=s(gw);VLe=n(yKe,"STRONG",{});var Yha=s(VLe);PWr=r(Yha,"roberta"),Yha.forEach(t),BWr=r(yKe," \u2014 "),lae=n(yKe,"A",{href:!0});var Zha=s(lae);IWr=r(Zha,"TFRobertaForMaskedLM"),Zha.forEach(t),NWr=r(yKe," (RoBERTa model)"),yKe.forEach(t),qWr=i(me),hw=n(me,"LI",{});var xKe=s(hw);XLe=n(xKe,"STRONG",{});var Kha=s(XLe);jWr=r(Kha,"t5"),Kha.forEach(t),DWr=r(xKe," \u2014 "),iae=n(xKe,"A",{href:!0});var eua=s(iae);GWr=r(eua,"TFT5ForConditionalGeneration"),eua.forEach(t),OWr=r(xKe," (T5 model)"),xKe.forEach(t),VWr=i(me),uw=n(me,"LI",{});var $Ke=s(uw);zLe=n($Ke,"STRONG",{});var oua=s(zLe);XWr=r(oua,"tapas"),oua.forEach(t),zWr=r($Ke," \u2014 "),dae=n($Ke,"A",{href:!0});var rua=s(dae);QWr=r(rua,"TFTapasForMaskedLM"),rua.forEach(t),WWr=r($Ke," (TAPAS model)"),$Ke.forEach(t),UWr=i(me),pw=n(me,"LI",{});var kKe=s(pw);QLe=n(kKe,"STRONG",{});var tua=s(QLe);HWr=r(tua,"transfo-xl"),tua.forEach(t),JWr=r(kKe," \u2014 "),mae=n(kKe,"A",{href:!0});var aua=s(mae);YWr=r(aua,"TFTransfoXLLMHeadModel"),aua.forEach(t),ZWr=r(kKe," (Transformer-XL model)"),kKe.forEach(t),KWr=i(me),_w=n(me,"LI",{});var SKe=s(_w);WLe=n(SKe,"STRONG",{});var nua=s(WLe);eUr=r(nua,"vit_mae"),nua.forEach(t),oUr=r(SKe," \u2014 "),cae=n(SKe,"A",{href:!0});var sua=s(cae);rUr=r(sua,"TFViTMAEForPreTraining"),sua.forEach(t),tUr=r(SKe," (ViTMAE model)"),SKe.forEach(t),aUr=i(me),bw=n(me,"LI",{});var RKe=s(bw);ULe=n(RKe,"STRONG",{});var lua=s(ULe);nUr=r(lua,"xlm"),lua.forEach(t),sUr=r(RKe," \u2014 "),fae=n(RKe,"A",{href:!0});var iua=s(fae);lUr=r(iua,"TFXLMWithLMHeadModel"),iua.forEach(t),iUr=r(RKe," (XLM model)"),RKe.forEach(t),dUr=i(me),vw=n(me,"LI",{});var PKe=s(vw);HLe=n(PKe,"STRONG",{});var dua=s(HLe);mUr=r(dua,"xlm-roberta"),dua.forEach(t),cUr=r(PKe," \u2014 "),gae=n(PKe,"A",{href:!0});var mua=s(gae);fUr=r(mua,"TFXLMRobertaForMaskedLM"),mua.forEach(t),gUr=r(PKe," (XLM-RoBERTa model)"),PKe.forEach(t),hUr=i(me),Fw=n(me,"LI",{});var BKe=s(Fw);JLe=n(BKe,"STRONG",{});var cua=s(JLe);uUr=r(cua,"xlnet"),cua.forEach(t),pUr=r(BKe," \u2014 "),hae=n(BKe,"A",{href:!0});var fua=s(hae);_Ur=r(fua,"TFXLNetLMHeadModel"),fua.forEach(t),bUr=r(BKe," (XLNet model)"),BKe.forEach(t),me.forEach(t),vUr=i(Fi),T(Tw.$$.fragment,Fi),Fi.forEach(t),vi.forEach(t),Wno=i(c),_c=n(c,"H2",{class:!0});var fio=s(_c);Mw=n(fio,"A",{id:!0,class:!0,href:!0});var gua=s(Mw);YLe=n(gua,"SPAN",{});var hua=s(YLe);T(qR.$$.fragment,hua),hua.forEach(t),gua.forEach(t),FUr=i(fio),ZLe=n(fio,"SPAN",{});var uua=s(ZLe);TUr=r(uua,"TFAutoModelForCausalLM"),uua.forEach(t),fio.forEach(t),Uno=i(c),fr=n(c,"DIV",{class:!0});var Ti=s(fr);T(jR.$$.fragment,Ti),MUr=i(Ti),bc=n(Ti,"P",{});var Oce=s(bc);EUr=r(Oce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),uae=n(Oce,"A",{href:!0});var pua=s(uae);CUr=r(pua,"from_pretrained()"),pua.forEach(t),wUr=r(Oce," class method or the "),pae=n(Oce,"A",{href:!0});var _ua=s(pae);AUr=r(_ua,"from_config()"),_ua.forEach(t),LUr=r(Oce,` class
method.`),Oce.forEach(t),yUr=i(Ti),DR=n(Ti,"P",{});var gio=s(DR);xUr=r(gio,"This class cannot be instantiated directly using "),KLe=n(gio,"CODE",{});var bua=s(KLe);$Ur=r(bua,"__init__()"),bua.forEach(t),kUr=r(gio," (throws an error)."),gio.forEach(t),SUr=i(Ti),Kt=n(Ti,"DIV",{class:!0});var Tx=s(Kt);T(GR.$$.fragment,Tx),RUr=i(Tx),eye=n(Tx,"P",{});var vua=s(eye);PUr=r(vua,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),vua.forEach(t),BUr=i(Tx),vc=n(Tx,"P",{});var Vce=s(vc);IUr=r(Vce,`Note:
Loading a model from its configuration file does `),oye=n(Vce,"STRONG",{});var Fua=s(oye);NUr=r(Fua,"not"),Fua.forEach(t),qUr=r(Vce,` load the model weights. It only affects the
model\u2019s configuration. Use `),_ae=n(Vce,"A",{href:!0});var Tua=s(_ae);jUr=r(Tua,"from_pretrained()"),Tua.forEach(t),DUr=r(Vce," to load the model weights."),Vce.forEach(t),GUr=i(Tx),T(Ew.$$.fragment,Tx),Tx.forEach(t),OUr=i(Ti),Or=n(Ti,"DIV",{class:!0});var Mi=s(Or);T(OR.$$.fragment,Mi),VUr=i(Mi),rye=n(Mi,"P",{});var Mua=s(rye);XUr=r(Mua,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Mua.forEach(t),zUr=i(Mi),Nn=n(Mi,"P",{});var Mx=s(Nn);QUr=r(Mx,"The model class to instantiate is selected based on the "),tye=n(Mx,"CODE",{});var Eua=s(tye);WUr=r(Eua,"model_type"),Eua.forEach(t),UUr=r(Mx,` property of the config object (either
passed as an argument or loaded from `),aye=n(Mx,"CODE",{});var Cua=s(aye);HUr=r(Cua,"pretrained_model_name_or_path"),Cua.forEach(t),JUr=r(Mx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nye=n(Mx,"CODE",{});var wua=s(nye);YUr=r(wua,"pretrained_model_name_or_path"),wua.forEach(t),ZUr=r(Mx,":"),Mx.forEach(t),KUr=i(Mi),Me=n(Mi,"UL",{});var Ce=s(Me);Cw=n(Ce,"LI",{});var IKe=s(Cw);sye=n(IKe,"STRONG",{});var Aua=s(sye);eHr=r(Aua,"bert"),Aua.forEach(t),oHr=r(IKe," \u2014 "),bae=n(IKe,"A",{href:!0});var Lua=s(bae);rHr=r(Lua,"TFBertLMHeadModel"),Lua.forEach(t),tHr=r(IKe," (BERT model)"),IKe.forEach(t),aHr=i(Ce),ww=n(Ce,"LI",{});var NKe=s(ww);lye=n(NKe,"STRONG",{});var yua=s(lye);nHr=r(yua,"camembert"),yua.forEach(t),sHr=r(NKe," \u2014 "),vae=n(NKe,"A",{href:!0});var xua=s(vae);lHr=r(xua,"TFCamembertForCausalLM"),xua.forEach(t),iHr=r(NKe," (CamemBERT model)"),NKe.forEach(t),dHr=i(Ce),Aw=n(Ce,"LI",{});var qKe=s(Aw);iye=n(qKe,"STRONG",{});var $ua=s(iye);mHr=r($ua,"ctrl"),$ua.forEach(t),cHr=r(qKe," \u2014 "),Fae=n(qKe,"A",{href:!0});var kua=s(Fae);fHr=r(kua,"TFCTRLLMHeadModel"),kua.forEach(t),gHr=r(qKe," (CTRL model)"),qKe.forEach(t),hHr=i(Ce),Lw=n(Ce,"LI",{});var jKe=s(Lw);dye=n(jKe,"STRONG",{});var Sua=s(dye);uHr=r(Sua,"gpt2"),Sua.forEach(t),pHr=r(jKe," \u2014 "),Tae=n(jKe,"A",{href:!0});var Rua=s(Tae);_Hr=r(Rua,"TFGPT2LMHeadModel"),Rua.forEach(t),bHr=r(jKe," (OpenAI GPT-2 model)"),jKe.forEach(t),vHr=i(Ce),yw=n(Ce,"LI",{});var DKe=s(yw);mye=n(DKe,"STRONG",{});var Pua=s(mye);FHr=r(Pua,"gptj"),Pua.forEach(t),THr=r(DKe," \u2014 "),Mae=n(DKe,"A",{href:!0});var Bua=s(Mae);MHr=r(Bua,"TFGPTJForCausalLM"),Bua.forEach(t),EHr=r(DKe," (GPT-J model)"),DKe.forEach(t),CHr=i(Ce),xw=n(Ce,"LI",{});var GKe=s(xw);cye=n(GKe,"STRONG",{});var Iua=s(cye);wHr=r(Iua,"openai-gpt"),Iua.forEach(t),AHr=r(GKe," \u2014 "),Eae=n(GKe,"A",{href:!0});var Nua=s(Eae);LHr=r(Nua,"TFOpenAIGPTLMHeadModel"),Nua.forEach(t),yHr=r(GKe," (OpenAI GPT model)"),GKe.forEach(t),xHr=i(Ce),$w=n(Ce,"LI",{});var OKe=s($w);fye=n(OKe,"STRONG",{});var qua=s(fye);$Hr=r(qua,"opt"),qua.forEach(t),kHr=r(OKe," \u2014 "),Cae=n(OKe,"A",{href:!0});var jua=s(Cae);SHr=r(jua,"TFOPTForCausalLM"),jua.forEach(t),RHr=r(OKe," (OPT model)"),OKe.forEach(t),PHr=i(Ce),kw=n(Ce,"LI",{});var VKe=s(kw);gye=n(VKe,"STRONG",{});var Dua=s(gye);BHr=r(Dua,"rembert"),Dua.forEach(t),IHr=r(VKe," \u2014 "),wae=n(VKe,"A",{href:!0});var Gua=s(wae);NHr=r(Gua,"TFRemBertForCausalLM"),Gua.forEach(t),qHr=r(VKe," (RemBERT model)"),VKe.forEach(t),jHr=i(Ce),Sw=n(Ce,"LI",{});var XKe=s(Sw);hye=n(XKe,"STRONG",{});var Oua=s(hye);DHr=r(Oua,"roberta"),Oua.forEach(t),GHr=r(XKe," \u2014 "),Aae=n(XKe,"A",{href:!0});var Vua=s(Aae);OHr=r(Vua,"TFRobertaForCausalLM"),Vua.forEach(t),VHr=r(XKe," (RoBERTa model)"),XKe.forEach(t),XHr=i(Ce),Rw=n(Ce,"LI",{});var zKe=s(Rw);uye=n(zKe,"STRONG",{});var Xua=s(uye);zHr=r(Xua,"roformer"),Xua.forEach(t),QHr=r(zKe," \u2014 "),Lae=n(zKe,"A",{href:!0});var zua=s(Lae);WHr=r(zua,"TFRoFormerForCausalLM"),zua.forEach(t),UHr=r(zKe," (RoFormer model)"),zKe.forEach(t),HHr=i(Ce),Pw=n(Ce,"LI",{});var QKe=s(Pw);pye=n(QKe,"STRONG",{});var Qua=s(pye);JHr=r(Qua,"transfo-xl"),Qua.forEach(t),YHr=r(QKe," \u2014 "),yae=n(QKe,"A",{href:!0});var Wua=s(yae);ZHr=r(Wua,"TFTransfoXLLMHeadModel"),Wua.forEach(t),KHr=r(QKe," (Transformer-XL model)"),QKe.forEach(t),eJr=i(Ce),Bw=n(Ce,"LI",{});var WKe=s(Bw);_ye=n(WKe,"STRONG",{});var Uua=s(_ye);oJr=r(Uua,"xglm"),Uua.forEach(t),rJr=r(WKe," \u2014 "),xae=n(WKe,"A",{href:!0});var Hua=s(xae);tJr=r(Hua,"TFXGLMForCausalLM"),Hua.forEach(t),aJr=r(WKe," (XGLM model)"),WKe.forEach(t),nJr=i(Ce),Iw=n(Ce,"LI",{});var UKe=s(Iw);bye=n(UKe,"STRONG",{});var Jua=s(bye);sJr=r(Jua,"xlm"),Jua.forEach(t),lJr=r(UKe," \u2014 "),$ae=n(UKe,"A",{href:!0});var Yua=s($ae);iJr=r(Yua,"TFXLMWithLMHeadModel"),Yua.forEach(t),dJr=r(UKe," (XLM model)"),UKe.forEach(t),mJr=i(Ce),Nw=n(Ce,"LI",{});var HKe=s(Nw);vye=n(HKe,"STRONG",{});var Zua=s(vye);cJr=r(Zua,"xlnet"),Zua.forEach(t),fJr=r(HKe," \u2014 "),kae=n(HKe,"A",{href:!0});var Kua=s(kae);gJr=r(Kua,"TFXLNetLMHeadModel"),Kua.forEach(t),hJr=r(HKe," (XLNet model)"),HKe.forEach(t),Ce.forEach(t),uJr=i(Mi),T(qw.$$.fragment,Mi),Mi.forEach(t),Ti.forEach(t),Hno=i(c),Fc=n(c,"H2",{class:!0});var hio=s(Fc);jw=n(hio,"A",{id:!0,class:!0,href:!0});var epa=s(jw);Fye=n(epa,"SPAN",{});var opa=s(Fye);T(VR.$$.fragment,opa),opa.forEach(t),epa.forEach(t),pJr=i(hio),Tye=n(hio,"SPAN",{});var rpa=s(Tye);_Jr=r(rpa,"TFAutoModelForImageClassification"),rpa.forEach(t),hio.forEach(t),Jno=i(c),gr=n(c,"DIV",{class:!0});var Ei=s(gr);T(XR.$$.fragment,Ei),bJr=i(Ei),Tc=n(Ei,"P",{});var Xce=s(Tc);vJr=r(Xce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Sae=n(Xce,"A",{href:!0});var tpa=s(Sae);FJr=r(tpa,"from_pretrained()"),tpa.forEach(t),TJr=r(Xce," class method or the "),Rae=n(Xce,"A",{href:!0});var apa=s(Rae);MJr=r(apa,"from_config()"),apa.forEach(t),EJr=r(Xce,` class
method.`),Xce.forEach(t),CJr=i(Ei),zR=n(Ei,"P",{});var uio=s(zR);wJr=r(uio,"This class cannot be instantiated directly using "),Mye=n(uio,"CODE",{});var npa=s(Mye);AJr=r(npa,"__init__()"),npa.forEach(t),LJr=r(uio," (throws an error)."),uio.forEach(t),yJr=i(Ei),ea=n(Ei,"DIV",{class:!0});var Ex=s(ea);T(QR.$$.fragment,Ex),xJr=i(Ex),Eye=n(Ex,"P",{});var spa=s(Eye);$Jr=r(spa,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),spa.forEach(t),kJr=i(Ex),Mc=n(Ex,"P",{});var zce=s(Mc);SJr=r(zce,`Note:
Loading a model from its configuration file does `),Cye=n(zce,"STRONG",{});var lpa=s(Cye);RJr=r(lpa,"not"),lpa.forEach(t),PJr=r(zce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Pae=n(zce,"A",{href:!0});var ipa=s(Pae);BJr=r(ipa,"from_pretrained()"),ipa.forEach(t),IJr=r(zce," to load the model weights."),zce.forEach(t),NJr=i(Ex),T(Dw.$$.fragment,Ex),Ex.forEach(t),qJr=i(Ei),Vr=n(Ei,"DIV",{class:!0});var Ci=s(Vr);T(WR.$$.fragment,Ci),jJr=i(Ci),wye=n(Ci,"P",{});var dpa=s(wye);DJr=r(dpa,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),dpa.forEach(t),GJr=i(Ci),qn=n(Ci,"P",{});var Cx=s(qn);OJr=r(Cx,"The model class to instantiate is selected based on the "),Aye=n(Cx,"CODE",{});var mpa=s(Aye);VJr=r(mpa,"model_type"),mpa.forEach(t),XJr=r(Cx,` property of the config object (either
passed as an argument or loaded from `),Lye=n(Cx,"CODE",{});var cpa=s(Lye);zJr=r(cpa,"pretrained_model_name_or_path"),cpa.forEach(t),QJr=r(Cx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yye=n(Cx,"CODE",{});var fpa=s(yye);WJr=r(fpa,"pretrained_model_name_or_path"),fpa.forEach(t),UJr=r(Cx,":"),Cx.forEach(t),HJr=i(Ci),ye=n(Ci,"UL",{});var Ne=s(ye);Gw=n(Ne,"LI",{});var JKe=s(Gw);xye=n(JKe,"STRONG",{});var gpa=s(xye);JJr=r(gpa,"convnext"),gpa.forEach(t),YJr=r(JKe," \u2014 "),Bae=n(JKe,"A",{href:!0});var hpa=s(Bae);ZJr=r(hpa,"TFConvNextForImageClassification"),hpa.forEach(t),KJr=r(JKe," (ConvNeXT model)"),JKe.forEach(t),eYr=i(Ne),Ow=n(Ne,"LI",{});var YKe=s(Ow);$ye=n(YKe,"STRONG",{});var upa=s($ye);oYr=r(upa,"cvt"),upa.forEach(t),rYr=r(YKe," \u2014 "),Iae=n(YKe,"A",{href:!0});var ppa=s(Iae);tYr=r(ppa,"TFCvtForImageClassification"),ppa.forEach(t),aYr=r(YKe," (CvT model)"),YKe.forEach(t),nYr=i(Ne),Vw=n(Ne,"LI",{});var ZKe=s(Vw);kye=n(ZKe,"STRONG",{});var _pa=s(kye);sYr=r(_pa,"data2vec-vision"),_pa.forEach(t),lYr=r(ZKe," \u2014 "),Nae=n(ZKe,"A",{href:!0});var bpa=s(Nae);iYr=r(bpa,"TFData2VecVisionForImageClassification"),bpa.forEach(t),dYr=r(ZKe," (Data2VecVision model)"),ZKe.forEach(t),mYr=i(Ne),Pl=n(Ne,"LI",{});var IN=s(Pl);Sye=n(IN,"STRONG",{});var vpa=s(Sye);cYr=r(vpa,"deit"),vpa.forEach(t),fYr=r(IN," \u2014 "),qae=n(IN,"A",{href:!0});var Fpa=s(qae);gYr=r(Fpa,"TFDeiTForImageClassification"),Fpa.forEach(t),hYr=r(IN," or "),jae=n(IN,"A",{href:!0});var Tpa=s(jae);uYr=r(Tpa,"TFDeiTForImageClassificationWithTeacher"),Tpa.forEach(t),pYr=r(IN," (DeiT model)"),IN.forEach(t),_Yr=i(Ne),Xw=n(Ne,"LI",{});var KKe=s(Xw);Rye=n(KKe,"STRONG",{});var Mpa=s(Rye);bYr=r(Mpa,"mobilevit"),Mpa.forEach(t),vYr=r(KKe," \u2014 "),Dae=n(KKe,"A",{href:!0});var Epa=s(Dae);FYr=r(Epa,"TFMobileViTForImageClassification"),Epa.forEach(t),TYr=r(KKe," (MobileViT model)"),KKe.forEach(t),MYr=i(Ne),zw=n(Ne,"LI",{});var eeo=s(zw);Pye=n(eeo,"STRONG",{});var Cpa=s(Pye);EYr=r(Cpa,"regnet"),Cpa.forEach(t),CYr=r(eeo," \u2014 "),Gae=n(eeo,"A",{href:!0});var wpa=s(Gae);wYr=r(wpa,"TFRegNetForImageClassification"),wpa.forEach(t),AYr=r(eeo," (RegNet model)"),eeo.forEach(t),LYr=i(Ne),Qw=n(Ne,"LI",{});var oeo=s(Qw);Bye=n(oeo,"STRONG",{});var Apa=s(Bye);yYr=r(Apa,"resnet"),Apa.forEach(t),xYr=r(oeo," \u2014 "),Oae=n(oeo,"A",{href:!0});var Lpa=s(Oae);$Yr=r(Lpa,"TFResNetForImageClassification"),Lpa.forEach(t),kYr=r(oeo," (ResNet model)"),oeo.forEach(t),SYr=i(Ne),Ww=n(Ne,"LI",{});var reo=s(Ww);Iye=n(reo,"STRONG",{});var ypa=s(Iye);RYr=r(ypa,"segformer"),ypa.forEach(t),PYr=r(reo," \u2014 "),Vae=n(reo,"A",{href:!0});var xpa=s(Vae);BYr=r(xpa,"TFSegformerForImageClassification"),xpa.forEach(t),IYr=r(reo," (SegFormer model)"),reo.forEach(t),NYr=i(Ne),Uw=n(Ne,"LI",{});var teo=s(Uw);Nye=n(teo,"STRONG",{});var $pa=s(Nye);qYr=r($pa,"swin"),$pa.forEach(t),jYr=r(teo," \u2014 "),Xae=n(teo,"A",{href:!0});var kpa=s(Xae);DYr=r(kpa,"TFSwinForImageClassification"),kpa.forEach(t),GYr=r(teo," (Swin Transformer model)"),teo.forEach(t),OYr=i(Ne),Hw=n(Ne,"LI",{});var aeo=s(Hw);qye=n(aeo,"STRONG",{});var Spa=s(qye);VYr=r(Spa,"vit"),Spa.forEach(t),XYr=r(aeo," \u2014 "),zae=n(aeo,"A",{href:!0});var Rpa=s(zae);zYr=r(Rpa,"TFViTForImageClassification"),Rpa.forEach(t),QYr=r(aeo," (ViT model)"),aeo.forEach(t),Ne.forEach(t),WYr=i(Ci),T(Jw.$$.fragment,Ci),Ci.forEach(t),Ei.forEach(t),Yno=i(c),Ec=n(c,"H2",{class:!0});var pio=s(Ec);Yw=n(pio,"A",{id:!0,class:!0,href:!0});var Ppa=s(Yw);jye=n(Ppa,"SPAN",{});var Bpa=s(jye);T(UR.$$.fragment,Bpa),Bpa.forEach(t),Ppa.forEach(t),UYr=i(pio),Dye=n(pio,"SPAN",{});var Ipa=s(Dye);HYr=r(Ipa,"TFAutoModelForSemanticSegmentation"),Ipa.forEach(t),pio.forEach(t),Zno=i(c),hr=n(c,"DIV",{class:!0});var wi=s(hr);T(HR.$$.fragment,wi),JYr=i(wi),Cc=n(wi,"P",{});var Qce=s(Cc);YYr=r(Qce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),Qae=n(Qce,"A",{href:!0});var Npa=s(Qae);ZYr=r(Npa,"from_pretrained()"),Npa.forEach(t),KYr=r(Qce," class method or the "),Wae=n(Qce,"A",{href:!0});var qpa=s(Wae);eZr=r(qpa,"from_config()"),qpa.forEach(t),oZr=r(Qce,` class
method.`),Qce.forEach(t),rZr=i(wi),JR=n(wi,"P",{});var _io=s(JR);tZr=r(_io,"This class cannot be instantiated directly using "),Gye=n(_io,"CODE",{});var jpa=s(Gye);aZr=r(jpa,"__init__()"),jpa.forEach(t),nZr=r(_io," (throws an error)."),_io.forEach(t),sZr=i(wi),oa=n(wi,"DIV",{class:!0});var wx=s(oa);T(YR.$$.fragment,wx),lZr=i(wx),Oye=n(wx,"P",{});var Dpa=s(Oye);iZr=r(Dpa,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),Dpa.forEach(t),dZr=i(wx),wc=n(wx,"P",{});var Wce=s(wc);mZr=r(Wce,`Note:
Loading a model from its configuration file does `),Vye=n(Wce,"STRONG",{});var Gpa=s(Vye);cZr=r(Gpa,"not"),Gpa.forEach(t),fZr=r(Wce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Uae=n(Wce,"A",{href:!0});var Opa=s(Uae);gZr=r(Opa,"from_pretrained()"),Opa.forEach(t),hZr=r(Wce," to load the model weights."),Wce.forEach(t),uZr=i(wx),T(Zw.$$.fragment,wx),wx.forEach(t),pZr=i(wi),Xr=n(wi,"DIV",{class:!0});var Ai=s(Xr);T(ZR.$$.fragment,Ai),_Zr=i(Ai),Xye=n(Ai,"P",{});var Vpa=s(Xye);bZr=r(Vpa,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Vpa.forEach(t),vZr=i(Ai),jn=n(Ai,"P",{});var Ax=s(jn);FZr=r(Ax,"The model class to instantiate is selected based on the "),zye=n(Ax,"CODE",{});var Xpa=s(zye);TZr=r(Xpa,"model_type"),Xpa.forEach(t),MZr=r(Ax,` property of the config object (either
passed as an argument or loaded from `),Qye=n(Ax,"CODE",{});var zpa=s(Qye);EZr=r(zpa,"pretrained_model_name_or_path"),zpa.forEach(t),CZr=r(Ax,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wye=n(Ax,"CODE",{});var Qpa=s(Wye);wZr=r(Qpa,"pretrained_model_name_or_path"),Qpa.forEach(t),AZr=r(Ax,":"),Ax.forEach(t),LZr=i(Ai),Ac=n(Ai,"UL",{});var Uce=s(Ac);Kw=n(Uce,"LI",{});var neo=s(Kw);Uye=n(neo,"STRONG",{});var Wpa=s(Uye);yZr=r(Wpa,"data2vec-vision"),Wpa.forEach(t),xZr=r(neo," \u2014 "),Hae=n(neo,"A",{href:!0});var Upa=s(Hae);$Zr=r(Upa,"TFData2VecVisionForSemanticSegmentation"),Upa.forEach(t),kZr=r(neo," (Data2VecVision model)"),neo.forEach(t),SZr=i(Uce),eA=n(Uce,"LI",{});var seo=s(eA);Hye=n(seo,"STRONG",{});var Hpa=s(Hye);RZr=r(Hpa,"mobilevit"),Hpa.forEach(t),PZr=r(seo," \u2014 "),Jae=n(seo,"A",{href:!0});var Jpa=s(Jae);BZr=r(Jpa,"TFMobileViTForSemanticSegmentation"),Jpa.forEach(t),IZr=r(seo," (MobileViT model)"),seo.forEach(t),NZr=i(Uce),oA=n(Uce,"LI",{});var leo=s(oA);Jye=n(leo,"STRONG",{});var Ypa=s(Jye);qZr=r(Ypa,"segformer"),Ypa.forEach(t),jZr=r(leo," \u2014 "),Yae=n(leo,"A",{href:!0});var Zpa=s(Yae);DZr=r(Zpa,"TFSegformerForSemanticSegmentation"),Zpa.forEach(t),GZr=r(leo," (SegFormer model)"),leo.forEach(t),Uce.forEach(t),OZr=i(Ai),T(rA.$$.fragment,Ai),Ai.forEach(t),wi.forEach(t),Kno=i(c),Lc=n(c,"H2",{class:!0});var bio=s(Lc);tA=n(bio,"A",{id:!0,class:!0,href:!0});var Kpa=s(tA);Yye=n(Kpa,"SPAN",{});var e_a=s(Yye);T(KR.$$.fragment,e_a),e_a.forEach(t),Kpa.forEach(t),VZr=i(bio),Zye=n(bio,"SPAN",{});var o_a=s(Zye);XZr=r(o_a,"TFAutoModelForMaskedLM"),o_a.forEach(t),bio.forEach(t),eso=i(c),ur=n(c,"DIV",{class:!0});var Li=s(ur);T(eP.$$.fragment,Li),zZr=i(Li),yc=n(Li,"P",{});var Hce=s(yc);QZr=r(Hce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Zae=n(Hce,"A",{href:!0});var r_a=s(Zae);WZr=r(r_a,"from_pretrained()"),r_a.forEach(t),UZr=r(Hce," class method or the "),Kae=n(Hce,"A",{href:!0});var t_a=s(Kae);HZr=r(t_a,"from_config()"),t_a.forEach(t),JZr=r(Hce,` class
method.`),Hce.forEach(t),YZr=i(Li),oP=n(Li,"P",{});var vio=s(oP);ZZr=r(vio,"This class cannot be instantiated directly using "),Kye=n(vio,"CODE",{});var a_a=s(Kye);KZr=r(a_a,"__init__()"),a_a.forEach(t),eKr=r(vio," (throws an error)."),vio.forEach(t),oKr=i(Li),ra=n(Li,"DIV",{class:!0});var Lx=s(ra);T(rP.$$.fragment,Lx),rKr=i(Lx),e9e=n(Lx,"P",{});var n_a=s(e9e);tKr=r(n_a,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),n_a.forEach(t),aKr=i(Lx),xc=n(Lx,"P",{});var Jce=s(xc);nKr=r(Jce,`Note:
Loading a model from its configuration file does `),o9e=n(Jce,"STRONG",{});var s_a=s(o9e);sKr=r(s_a,"not"),s_a.forEach(t),lKr=r(Jce,` load the model weights. It only affects the
model\u2019s configuration. Use `),ene=n(Jce,"A",{href:!0});var l_a=s(ene);iKr=r(l_a,"from_pretrained()"),l_a.forEach(t),dKr=r(Jce," to load the model weights."),Jce.forEach(t),mKr=i(Lx),T(aA.$$.fragment,Lx),Lx.forEach(t),cKr=i(Li),zr=n(Li,"DIV",{class:!0});var yi=s(zr);T(tP.$$.fragment,yi),fKr=i(yi),r9e=n(yi,"P",{});var i_a=s(r9e);gKr=r(i_a,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),i_a.forEach(t),hKr=i(yi),Dn=n(yi,"P",{});var yx=s(Dn);uKr=r(yx,"The model class to instantiate is selected based on the "),t9e=n(yx,"CODE",{});var d_a=s(t9e);pKr=r(d_a,"model_type"),d_a.forEach(t),_Kr=r(yx,` property of the config object (either
passed as an argument or loaded from `),a9e=n(yx,"CODE",{});var m_a=s(a9e);bKr=r(m_a,"pretrained_model_name_or_path"),m_a.forEach(t),vKr=r(yx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n9e=n(yx,"CODE",{});var c_a=s(n9e);FKr=r(c_a,"pretrained_model_name_or_path"),c_a.forEach(t),TKr=r(yx,":"),yx.forEach(t),MKr=i(yi),ce=n(yi,"UL",{});var ue=s(ce);nA=n(ue,"LI",{});var ieo=s(nA);s9e=n(ieo,"STRONG",{});var f_a=s(s9e);EKr=r(f_a,"albert"),f_a.forEach(t),CKr=r(ieo," \u2014 "),one=n(ieo,"A",{href:!0});var g_a=s(one);wKr=r(g_a,"TFAlbertForMaskedLM"),g_a.forEach(t),AKr=r(ieo," (ALBERT model)"),ieo.forEach(t),LKr=i(ue),sA=n(ue,"LI",{});var deo=s(sA);l9e=n(deo,"STRONG",{});var h_a=s(l9e);yKr=r(h_a,"bert"),h_a.forEach(t),xKr=r(deo," \u2014 "),rne=n(deo,"A",{href:!0});var u_a=s(rne);$Kr=r(u_a,"TFBertForMaskedLM"),u_a.forEach(t),kKr=r(deo," (BERT model)"),deo.forEach(t),SKr=i(ue),lA=n(ue,"LI",{});var meo=s(lA);i9e=n(meo,"STRONG",{});var p_a=s(i9e);RKr=r(p_a,"camembert"),p_a.forEach(t),PKr=r(meo," \u2014 "),tne=n(meo,"A",{href:!0});var __a=s(tne);BKr=r(__a,"TFCamembertForMaskedLM"),__a.forEach(t),IKr=r(meo," (CamemBERT model)"),meo.forEach(t),NKr=i(ue),iA=n(ue,"LI",{});var ceo=s(iA);d9e=n(ceo,"STRONG",{});var b_a=s(d9e);qKr=r(b_a,"convbert"),b_a.forEach(t),jKr=r(ceo," \u2014 "),ane=n(ceo,"A",{href:!0});var v_a=s(ane);DKr=r(v_a,"TFConvBertForMaskedLM"),v_a.forEach(t),GKr=r(ceo," (ConvBERT model)"),ceo.forEach(t),OKr=i(ue),dA=n(ue,"LI",{});var feo=s(dA);m9e=n(feo,"STRONG",{});var F_a=s(m9e);VKr=r(F_a,"deberta"),F_a.forEach(t),XKr=r(feo," \u2014 "),nne=n(feo,"A",{href:!0});var T_a=s(nne);zKr=r(T_a,"TFDebertaForMaskedLM"),T_a.forEach(t),QKr=r(feo," (DeBERTa model)"),feo.forEach(t),WKr=i(ue),mA=n(ue,"LI",{});var geo=s(mA);c9e=n(geo,"STRONG",{});var M_a=s(c9e);UKr=r(M_a,"deberta-v2"),M_a.forEach(t),HKr=r(geo," \u2014 "),sne=n(geo,"A",{href:!0});var E_a=s(sne);JKr=r(E_a,"TFDebertaV2ForMaskedLM"),E_a.forEach(t),YKr=r(geo," (DeBERTa-v2 model)"),geo.forEach(t),ZKr=i(ue),cA=n(ue,"LI",{});var heo=s(cA);f9e=n(heo,"STRONG",{});var C_a=s(f9e);KKr=r(C_a,"distilbert"),C_a.forEach(t),eet=r(heo," \u2014 "),lne=n(heo,"A",{href:!0});var w_a=s(lne);oet=r(w_a,"TFDistilBertForMaskedLM"),w_a.forEach(t),ret=r(heo," (DistilBERT model)"),heo.forEach(t),tet=i(ue),fA=n(ue,"LI",{});var ueo=s(fA);g9e=n(ueo,"STRONG",{});var A_a=s(g9e);aet=r(A_a,"electra"),A_a.forEach(t),net=r(ueo," \u2014 "),ine=n(ueo,"A",{href:!0});var L_a=s(ine);set=r(L_a,"TFElectraForMaskedLM"),L_a.forEach(t),iet=r(ueo," (ELECTRA model)"),ueo.forEach(t),det=i(ue),gA=n(ue,"LI",{});var peo=s(gA);h9e=n(peo,"STRONG",{});var y_a=s(h9e);met=r(y_a,"esm"),y_a.forEach(t),cet=r(peo," \u2014 "),dne=n(peo,"A",{href:!0});var x_a=s(dne);fet=r(x_a,"TFEsmForMaskedLM"),x_a.forEach(t),get=r(peo," (ESM model)"),peo.forEach(t),het=i(ue),hA=n(ue,"LI",{});var _eo=s(hA);u9e=n(_eo,"STRONG",{});var $_a=s(u9e);uet=r($_a,"flaubert"),$_a.forEach(t),pet=r(_eo," \u2014 "),mne=n(_eo,"A",{href:!0});var k_a=s(mne);_et=r(k_a,"TFFlaubertWithLMHeadModel"),k_a.forEach(t),bet=r(_eo," (FlauBERT model)"),_eo.forEach(t),vet=i(ue),uA=n(ue,"LI",{});var beo=s(uA);p9e=n(beo,"STRONG",{});var S_a=s(p9e);Fet=r(S_a,"funnel"),S_a.forEach(t),Tet=r(beo," \u2014 "),cne=n(beo,"A",{href:!0});var R_a=s(cne);Met=r(R_a,"TFFunnelForMaskedLM"),R_a.forEach(t),Eet=r(beo," (Funnel Transformer model)"),beo.forEach(t),Cet=i(ue),pA=n(ue,"LI",{});var veo=s(pA);_9e=n(veo,"STRONG",{});var P_a=s(_9e);wet=r(P_a,"layoutlm"),P_a.forEach(t),Aet=r(veo," \u2014 "),fne=n(veo,"A",{href:!0});var B_a=s(fne);Let=r(B_a,"TFLayoutLMForMaskedLM"),B_a.forEach(t),yet=r(veo," (LayoutLM model)"),veo.forEach(t),xet=i(ue),_A=n(ue,"LI",{});var Feo=s(_A);b9e=n(Feo,"STRONG",{});var I_a=s(b9e);$et=r(I_a,"longformer"),I_a.forEach(t),ket=r(Feo," \u2014 "),gne=n(Feo,"A",{href:!0});var N_a=s(gne);Set=r(N_a,"TFLongformerForMaskedLM"),N_a.forEach(t),Ret=r(Feo," (Longformer model)"),Feo.forEach(t),Pet=i(ue),bA=n(ue,"LI",{});var Teo=s(bA);v9e=n(Teo,"STRONG",{});var q_a=s(v9e);Bet=r(q_a,"mobilebert"),q_a.forEach(t),Iet=r(Teo," \u2014 "),hne=n(Teo,"A",{href:!0});var j_a=s(hne);Net=r(j_a,"TFMobileBertForMaskedLM"),j_a.forEach(t),qet=r(Teo," (MobileBERT model)"),Teo.forEach(t),jet=i(ue),vA=n(ue,"LI",{});var Meo=s(vA);F9e=n(Meo,"STRONG",{});var D_a=s(F9e);Det=r(D_a,"mpnet"),D_a.forEach(t),Get=r(Meo," \u2014 "),une=n(Meo,"A",{href:!0});var G_a=s(une);Oet=r(G_a,"TFMPNetForMaskedLM"),G_a.forEach(t),Vet=r(Meo," (MPNet model)"),Meo.forEach(t),Xet=i(ue),FA=n(ue,"LI",{});var Eeo=s(FA);T9e=n(Eeo,"STRONG",{});var O_a=s(T9e);zet=r(O_a,"rembert"),O_a.forEach(t),Qet=r(Eeo," \u2014 "),pne=n(Eeo,"A",{href:!0});var V_a=s(pne);Wet=r(V_a,"TFRemBertForMaskedLM"),V_a.forEach(t),Uet=r(Eeo," (RemBERT model)"),Eeo.forEach(t),Het=i(ue),TA=n(ue,"LI",{});var Ceo=s(TA);M9e=n(Ceo,"STRONG",{});var X_a=s(M9e);Jet=r(X_a,"roberta"),X_a.forEach(t),Yet=r(Ceo," \u2014 "),_ne=n(Ceo,"A",{href:!0});var z_a=s(_ne);Zet=r(z_a,"TFRobertaForMaskedLM"),z_a.forEach(t),Ket=r(Ceo," (RoBERTa model)"),Ceo.forEach(t),eot=i(ue),MA=n(ue,"LI",{});var weo=s(MA);E9e=n(weo,"STRONG",{});var Q_a=s(E9e);oot=r(Q_a,"roformer"),Q_a.forEach(t),rot=r(weo," \u2014 "),bne=n(weo,"A",{href:!0});var W_a=s(bne);tot=r(W_a,"TFRoFormerForMaskedLM"),W_a.forEach(t),aot=r(weo," (RoFormer model)"),weo.forEach(t),not=i(ue),EA=n(ue,"LI",{});var Aeo=s(EA);C9e=n(Aeo,"STRONG",{});var U_a=s(C9e);sot=r(U_a,"tapas"),U_a.forEach(t),lot=r(Aeo," \u2014 "),vne=n(Aeo,"A",{href:!0});var H_a=s(vne);iot=r(H_a,"TFTapasForMaskedLM"),H_a.forEach(t),dot=r(Aeo," (TAPAS model)"),Aeo.forEach(t),mot=i(ue),CA=n(ue,"LI",{});var Leo=s(CA);w9e=n(Leo,"STRONG",{});var J_a=s(w9e);cot=r(J_a,"xlm"),J_a.forEach(t),fot=r(Leo," \u2014 "),Fne=n(Leo,"A",{href:!0});var Y_a=s(Fne);got=r(Y_a,"TFXLMWithLMHeadModel"),Y_a.forEach(t),hot=r(Leo," (XLM model)"),Leo.forEach(t),uot=i(ue),wA=n(ue,"LI",{});var yeo=s(wA);A9e=n(yeo,"STRONG",{});var Z_a=s(A9e);pot=r(Z_a,"xlm-roberta"),Z_a.forEach(t),_ot=r(yeo," \u2014 "),Tne=n(yeo,"A",{href:!0});var K_a=s(Tne);bot=r(K_a,"TFXLMRobertaForMaskedLM"),K_a.forEach(t),vot=r(yeo," (XLM-RoBERTa model)"),yeo.forEach(t),ue.forEach(t),Fot=i(yi),T(AA.$$.fragment,yi),yi.forEach(t),Li.forEach(t),oso=i(c),$c=n(c,"H2",{class:!0});var Fio=s($c);LA=n(Fio,"A",{id:!0,class:!0,href:!0});var e1a=s(LA);L9e=n(e1a,"SPAN",{});var o1a=s(L9e);T(aP.$$.fragment,o1a),o1a.forEach(t),e1a.forEach(t),Tot=i(Fio),y9e=n(Fio,"SPAN",{});var r1a=s(y9e);Mot=r(r1a,"TFAutoModelForSeq2SeqLM"),r1a.forEach(t),Fio.forEach(t),rso=i(c),pr=n(c,"DIV",{class:!0});var xi=s(pr);T(nP.$$.fragment,xi),Eot=i(xi),kc=n(xi,"P",{});var Yce=s(kc);Cot=r(Yce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Mne=n(Yce,"A",{href:!0});var t1a=s(Mne);wot=r(t1a,"from_pretrained()"),t1a.forEach(t),Aot=r(Yce," class method or the "),Ene=n(Yce,"A",{href:!0});var a1a=s(Ene);Lot=r(a1a,"from_config()"),a1a.forEach(t),yot=r(Yce,` class
method.`),Yce.forEach(t),xot=i(xi),sP=n(xi,"P",{});var Tio=s(sP);$ot=r(Tio,"This class cannot be instantiated directly using "),x9e=n(Tio,"CODE",{});var n1a=s(x9e);kot=r(n1a,"__init__()"),n1a.forEach(t),Sot=r(Tio," (throws an error)."),Tio.forEach(t),Rot=i(xi),ta=n(xi,"DIV",{class:!0});var xx=s(ta);T(lP.$$.fragment,xx),Pot=i(xx),$9e=n(xx,"P",{});var s1a=s($9e);Bot=r(s1a,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),s1a.forEach(t),Iot=i(xx),Sc=n(xx,"P",{});var Zce=s(Sc);Not=r(Zce,`Note:
Loading a model from its configuration file does `),k9e=n(Zce,"STRONG",{});var l1a=s(k9e);qot=r(l1a,"not"),l1a.forEach(t),jot=r(Zce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Cne=n(Zce,"A",{href:!0});var i1a=s(Cne);Dot=r(i1a,"from_pretrained()"),i1a.forEach(t),Got=r(Zce," to load the model weights."),Zce.forEach(t),Oot=i(xx),T(yA.$$.fragment,xx),xx.forEach(t),Vot=i(xi),Qr=n(xi,"DIV",{class:!0});var $i=s(Qr);T(iP.$$.fragment,$i),Xot=i($i),S9e=n($i,"P",{});var d1a=s(S9e);zot=r(d1a,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),d1a.forEach(t),Qot=i($i),Gn=n($i,"P",{});var $x=s(Gn);Wot=r($x,"The model class to instantiate is selected based on the "),R9e=n($x,"CODE",{});var m1a=s(R9e);Uot=r(m1a,"model_type"),m1a.forEach(t),Hot=r($x,` property of the config object (either
passed as an argument or loaded from `),P9e=n($x,"CODE",{});var c1a=s(P9e);Jot=r(c1a,"pretrained_model_name_or_path"),c1a.forEach(t),Yot=r($x,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),B9e=n($x,"CODE",{});var f1a=s(B9e);Zot=r(f1a,"pretrained_model_name_or_path"),f1a.forEach(t),Kot=r($x,":"),$x.forEach(t),ert=i($i),xe=n($i,"UL",{});var qe=s(xe);xA=n(qe,"LI",{});var xeo=s(xA);I9e=n(xeo,"STRONG",{});var g1a=s(I9e);ort=r(g1a,"bart"),g1a.forEach(t),rrt=r(xeo," \u2014 "),wne=n(xeo,"A",{href:!0});var h1a=s(wne);trt=r(h1a,"TFBartForConditionalGeneration"),h1a.forEach(t),art=r(xeo," (BART model)"),xeo.forEach(t),nrt=i(qe),$A=n(qe,"LI",{});var $eo=s($A);N9e=n($eo,"STRONG",{});var u1a=s(N9e);srt=r(u1a,"blenderbot"),u1a.forEach(t),lrt=r($eo," \u2014 "),Ane=n($eo,"A",{href:!0});var p1a=s(Ane);irt=r(p1a,"TFBlenderbotForConditionalGeneration"),p1a.forEach(t),drt=r($eo," (Blenderbot model)"),$eo.forEach(t),mrt=i(qe),kA=n(qe,"LI",{});var keo=s(kA);q9e=n(keo,"STRONG",{});var _1a=s(q9e);crt=r(_1a,"blenderbot-small"),_1a.forEach(t),frt=r(keo," \u2014 "),Lne=n(keo,"A",{href:!0});var b1a=s(Lne);grt=r(b1a,"TFBlenderbotSmallForConditionalGeneration"),b1a.forEach(t),hrt=r(keo," (BlenderbotSmall model)"),keo.forEach(t),urt=i(qe),SA=n(qe,"LI",{});var Seo=s(SA);j9e=n(Seo,"STRONG",{});var v1a=s(j9e);prt=r(v1a,"encoder-decoder"),v1a.forEach(t),_rt=r(Seo," \u2014 "),yne=n(Seo,"A",{href:!0});var F1a=s(yne);brt=r(F1a,"TFEncoderDecoderModel"),F1a.forEach(t),vrt=r(Seo," (Encoder decoder model)"),Seo.forEach(t),Frt=i(qe),RA=n(qe,"LI",{});var Reo=s(RA);D9e=n(Reo,"STRONG",{});var T1a=s(D9e);Trt=r(T1a,"led"),T1a.forEach(t),Mrt=r(Reo," \u2014 "),xne=n(Reo,"A",{href:!0});var M1a=s(xne);Ert=r(M1a,"TFLEDForConditionalGeneration"),M1a.forEach(t),Crt=r(Reo," (LED model)"),Reo.forEach(t),wrt=i(qe),PA=n(qe,"LI",{});var Peo=s(PA);G9e=n(Peo,"STRONG",{});var E1a=s(G9e);Art=r(E1a,"marian"),E1a.forEach(t),Lrt=r(Peo," \u2014 "),$ne=n(Peo,"A",{href:!0});var C1a=s($ne);yrt=r(C1a,"TFMarianMTModel"),C1a.forEach(t),xrt=r(Peo," (Marian model)"),Peo.forEach(t),$rt=i(qe),BA=n(qe,"LI",{});var Beo=s(BA);O9e=n(Beo,"STRONG",{});var w1a=s(O9e);krt=r(w1a,"mbart"),w1a.forEach(t),Srt=r(Beo," \u2014 "),kne=n(Beo,"A",{href:!0});var A1a=s(kne);Rrt=r(A1a,"TFMBartForConditionalGeneration"),A1a.forEach(t),Prt=r(Beo," (mBART model)"),Beo.forEach(t),Brt=i(qe),IA=n(qe,"LI",{});var Ieo=s(IA);V9e=n(Ieo,"STRONG",{});var L1a=s(V9e);Irt=r(L1a,"mt5"),L1a.forEach(t),Nrt=r(Ieo," \u2014 "),Sne=n(Ieo,"A",{href:!0});var y1a=s(Sne);qrt=r(y1a,"TFMT5ForConditionalGeneration"),y1a.forEach(t),jrt=r(Ieo," (MT5 model)"),Ieo.forEach(t),Drt=i(qe),NA=n(qe,"LI",{});var Neo=s(NA);X9e=n(Neo,"STRONG",{});var x1a=s(X9e);Grt=r(x1a,"pegasus"),x1a.forEach(t),Ort=r(Neo," \u2014 "),Rne=n(Neo,"A",{href:!0});var $1a=s(Rne);Vrt=r($1a,"TFPegasusForConditionalGeneration"),$1a.forEach(t),Xrt=r(Neo," (Pegasus model)"),Neo.forEach(t),zrt=i(qe),qA=n(qe,"LI",{});var qeo=s(qA);z9e=n(qeo,"STRONG",{});var k1a=s(z9e);Qrt=r(k1a,"t5"),k1a.forEach(t),Wrt=r(qeo," \u2014 "),Pne=n(qeo,"A",{href:!0});var S1a=s(Pne);Urt=r(S1a,"TFT5ForConditionalGeneration"),S1a.forEach(t),Hrt=r(qeo," (T5 model)"),qeo.forEach(t),qe.forEach(t),Jrt=i($i),T(jA.$$.fragment,$i),$i.forEach(t),xi.forEach(t),tso=i(c),Rc=n(c,"H2",{class:!0});var Mio=s(Rc);DA=n(Mio,"A",{id:!0,class:!0,href:!0});var R1a=s(DA);Q9e=n(R1a,"SPAN",{});var P1a=s(Q9e);T(dP.$$.fragment,P1a),P1a.forEach(t),R1a.forEach(t),Yrt=i(Mio),W9e=n(Mio,"SPAN",{});var B1a=s(W9e);Zrt=r(B1a,"TFAutoModelForSequenceClassification"),B1a.forEach(t),Mio.forEach(t),aso=i(c),_r=n(c,"DIV",{class:!0});var ki=s(_r);T(mP.$$.fragment,ki),Krt=i(ki),Pc=n(ki,"P",{});var Kce=s(Pc);ett=r(Kce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Bne=n(Kce,"A",{href:!0});var I1a=s(Bne);ott=r(I1a,"from_pretrained()"),I1a.forEach(t),rtt=r(Kce," class method or the "),Ine=n(Kce,"A",{href:!0});var N1a=s(Ine);ttt=r(N1a,"from_config()"),N1a.forEach(t),att=r(Kce,` class
method.`),Kce.forEach(t),ntt=i(ki),cP=n(ki,"P",{});var Eio=s(cP);stt=r(Eio,"This class cannot be instantiated directly using "),U9e=n(Eio,"CODE",{});var q1a=s(U9e);ltt=r(q1a,"__init__()"),q1a.forEach(t),itt=r(Eio," (throws an error)."),Eio.forEach(t),dtt=i(ki),aa=n(ki,"DIV",{class:!0});var kx=s(aa);T(fP.$$.fragment,kx),mtt=i(kx),H9e=n(kx,"P",{});var j1a=s(H9e);ctt=r(j1a,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),j1a.forEach(t),ftt=i(kx),Bc=n(kx,"P",{});var efe=s(Bc);gtt=r(efe,`Note:
Loading a model from its configuration file does `),J9e=n(efe,"STRONG",{});var D1a=s(J9e);htt=r(D1a,"not"),D1a.forEach(t),utt=r(efe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Nne=n(efe,"A",{href:!0});var G1a=s(Nne);ptt=r(G1a,"from_pretrained()"),G1a.forEach(t),_tt=r(efe," to load the model weights."),efe.forEach(t),btt=i(kx),T(GA.$$.fragment,kx),kx.forEach(t),vtt=i(ki),Wr=n(ki,"DIV",{class:!0});var Si=s(Wr);T(gP.$$.fragment,Si),Ftt=i(Si),Y9e=n(Si,"P",{});var O1a=s(Y9e);Ttt=r(O1a,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),O1a.forEach(t),Mtt=i(Si),On=n(Si,"P",{});var Sx=s(On);Ett=r(Sx,"The model class to instantiate is selected based on the "),Z9e=n(Sx,"CODE",{});var V1a=s(Z9e);Ctt=r(V1a,"model_type"),V1a.forEach(t),wtt=r(Sx,` property of the config object (either
passed as an argument or loaded from `),K9e=n(Sx,"CODE",{});var X1a=s(K9e);Att=r(X1a,"pretrained_model_name_or_path"),X1a.forEach(t),Ltt=r(Sx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),exe=n(Sx,"CODE",{});var z1a=s(exe);ytt=r(z1a,"pretrained_model_name_or_path"),z1a.forEach(t),xtt=r(Sx,":"),Sx.forEach(t),$tt=i(Si),re=n(Si,"UL",{});var ae=s(re);OA=n(ae,"LI",{});var jeo=s(OA);oxe=n(jeo,"STRONG",{});var Q1a=s(oxe);ktt=r(Q1a,"albert"),Q1a.forEach(t),Stt=r(jeo," \u2014 "),qne=n(jeo,"A",{href:!0});var W1a=s(qne);Rtt=r(W1a,"TFAlbertForSequenceClassification"),W1a.forEach(t),Ptt=r(jeo," (ALBERT model)"),jeo.forEach(t),Btt=i(ae),VA=n(ae,"LI",{});var Deo=s(VA);rxe=n(Deo,"STRONG",{});var U1a=s(rxe);Itt=r(U1a,"bert"),U1a.forEach(t),Ntt=r(Deo," \u2014 "),jne=n(Deo,"A",{href:!0});var H1a=s(jne);qtt=r(H1a,"TFBertForSequenceClassification"),H1a.forEach(t),jtt=r(Deo," (BERT model)"),Deo.forEach(t),Dtt=i(ae),XA=n(ae,"LI",{});var Geo=s(XA);txe=n(Geo,"STRONG",{});var J1a=s(txe);Gtt=r(J1a,"camembert"),J1a.forEach(t),Ott=r(Geo," \u2014 "),Dne=n(Geo,"A",{href:!0});var Y1a=s(Dne);Vtt=r(Y1a,"TFCamembertForSequenceClassification"),Y1a.forEach(t),Xtt=r(Geo," (CamemBERT model)"),Geo.forEach(t),ztt=i(ae),zA=n(ae,"LI",{});var Oeo=s(zA);axe=n(Oeo,"STRONG",{});var Z1a=s(axe);Qtt=r(Z1a,"convbert"),Z1a.forEach(t),Wtt=r(Oeo," \u2014 "),Gne=n(Oeo,"A",{href:!0});var K1a=s(Gne);Utt=r(K1a,"TFConvBertForSequenceClassification"),K1a.forEach(t),Htt=r(Oeo," (ConvBERT model)"),Oeo.forEach(t),Jtt=i(ae),QA=n(ae,"LI",{});var Veo=s(QA);nxe=n(Veo,"STRONG",{});var e2a=s(nxe);Ytt=r(e2a,"ctrl"),e2a.forEach(t),Ztt=r(Veo," \u2014 "),One=n(Veo,"A",{href:!0});var o2a=s(One);Ktt=r(o2a,"TFCTRLForSequenceClassification"),o2a.forEach(t),eat=r(Veo," (CTRL model)"),Veo.forEach(t),oat=i(ae),WA=n(ae,"LI",{});var Xeo=s(WA);sxe=n(Xeo,"STRONG",{});var r2a=s(sxe);rat=r(r2a,"deberta"),r2a.forEach(t),tat=r(Xeo," \u2014 "),Vne=n(Xeo,"A",{href:!0});var t2a=s(Vne);aat=r(t2a,"TFDebertaForSequenceClassification"),t2a.forEach(t),nat=r(Xeo," (DeBERTa model)"),Xeo.forEach(t),sat=i(ae),UA=n(ae,"LI",{});var zeo=s(UA);lxe=n(zeo,"STRONG",{});var a2a=s(lxe);lat=r(a2a,"deberta-v2"),a2a.forEach(t),iat=r(zeo," \u2014 "),Xne=n(zeo,"A",{href:!0});var n2a=s(Xne);dat=r(n2a,"TFDebertaV2ForSequenceClassification"),n2a.forEach(t),mat=r(zeo," (DeBERTa-v2 model)"),zeo.forEach(t),cat=i(ae),HA=n(ae,"LI",{});var Qeo=s(HA);ixe=n(Qeo,"STRONG",{});var s2a=s(ixe);fat=r(s2a,"distilbert"),s2a.forEach(t),gat=r(Qeo," \u2014 "),zne=n(Qeo,"A",{href:!0});var l2a=s(zne);hat=r(l2a,"TFDistilBertForSequenceClassification"),l2a.forEach(t),uat=r(Qeo," (DistilBERT model)"),Qeo.forEach(t),pat=i(ae),JA=n(ae,"LI",{});var Weo=s(JA);dxe=n(Weo,"STRONG",{});var i2a=s(dxe);_at=r(i2a,"electra"),i2a.forEach(t),bat=r(Weo," \u2014 "),Qne=n(Weo,"A",{href:!0});var d2a=s(Qne);vat=r(d2a,"TFElectraForSequenceClassification"),d2a.forEach(t),Fat=r(Weo," (ELECTRA model)"),Weo.forEach(t),Tat=i(ae),YA=n(ae,"LI",{});var Ueo=s(YA);mxe=n(Ueo,"STRONG",{});var m2a=s(mxe);Mat=r(m2a,"esm"),m2a.forEach(t),Eat=r(Ueo," \u2014 "),Wne=n(Ueo,"A",{href:!0});var c2a=s(Wne);Cat=r(c2a,"TFEsmForSequenceClassification"),c2a.forEach(t),wat=r(Ueo," (ESM model)"),Ueo.forEach(t),Aat=i(ae),ZA=n(ae,"LI",{});var Heo=s(ZA);cxe=n(Heo,"STRONG",{});var f2a=s(cxe);Lat=r(f2a,"flaubert"),f2a.forEach(t),yat=r(Heo," \u2014 "),Une=n(Heo,"A",{href:!0});var g2a=s(Une);xat=r(g2a,"TFFlaubertForSequenceClassification"),g2a.forEach(t),$at=r(Heo," (FlauBERT model)"),Heo.forEach(t),kat=i(ae),KA=n(ae,"LI",{});var Jeo=s(KA);fxe=n(Jeo,"STRONG",{});var h2a=s(fxe);Sat=r(h2a,"funnel"),h2a.forEach(t),Rat=r(Jeo," \u2014 "),Hne=n(Jeo,"A",{href:!0});var u2a=s(Hne);Pat=r(u2a,"TFFunnelForSequenceClassification"),u2a.forEach(t),Bat=r(Jeo," (Funnel Transformer model)"),Jeo.forEach(t),Iat=i(ae),e6=n(ae,"LI",{});var Yeo=s(e6);gxe=n(Yeo,"STRONG",{});var p2a=s(gxe);Nat=r(p2a,"gpt2"),p2a.forEach(t),qat=r(Yeo," \u2014 "),Jne=n(Yeo,"A",{href:!0});var _2a=s(Jne);jat=r(_2a,"TFGPT2ForSequenceClassification"),_2a.forEach(t),Dat=r(Yeo," (OpenAI GPT-2 model)"),Yeo.forEach(t),Gat=i(ae),o6=n(ae,"LI",{});var Zeo=s(o6);hxe=n(Zeo,"STRONG",{});var b2a=s(hxe);Oat=r(b2a,"gptj"),b2a.forEach(t),Vat=r(Zeo," \u2014 "),Yne=n(Zeo,"A",{href:!0});var v2a=s(Yne);Xat=r(v2a,"TFGPTJForSequenceClassification"),v2a.forEach(t),zat=r(Zeo," (GPT-J model)"),Zeo.forEach(t),Qat=i(ae),r6=n(ae,"LI",{});var Keo=s(r6);uxe=n(Keo,"STRONG",{});var F2a=s(uxe);Wat=r(F2a,"layoutlm"),F2a.forEach(t),Uat=r(Keo," \u2014 "),Zne=n(Keo,"A",{href:!0});var T2a=s(Zne);Hat=r(T2a,"TFLayoutLMForSequenceClassification"),T2a.forEach(t),Jat=r(Keo," (LayoutLM model)"),Keo.forEach(t),Yat=i(ae),t6=n(ae,"LI",{});var eoo=s(t6);pxe=n(eoo,"STRONG",{});var M2a=s(pxe);Zat=r(M2a,"layoutlmv3"),M2a.forEach(t),Kat=r(eoo," \u2014 "),Kne=n(eoo,"A",{href:!0});var E2a=s(Kne);ent=r(E2a,"TFLayoutLMv3ForSequenceClassification"),E2a.forEach(t),ont=r(eoo," (LayoutLMv3 model)"),eoo.forEach(t),rnt=i(ae),a6=n(ae,"LI",{});var ooo=s(a6);_xe=n(ooo,"STRONG",{});var C2a=s(_xe);tnt=r(C2a,"longformer"),C2a.forEach(t),ant=r(ooo," \u2014 "),ese=n(ooo,"A",{href:!0});var w2a=s(ese);nnt=r(w2a,"TFLongformerForSequenceClassification"),w2a.forEach(t),snt=r(ooo," (Longformer model)"),ooo.forEach(t),lnt=i(ae),n6=n(ae,"LI",{});var roo=s(n6);bxe=n(roo,"STRONG",{});var A2a=s(bxe);int=r(A2a,"mobilebert"),A2a.forEach(t),dnt=r(roo," \u2014 "),ose=n(roo,"A",{href:!0});var L2a=s(ose);mnt=r(L2a,"TFMobileBertForSequenceClassification"),L2a.forEach(t),cnt=r(roo," (MobileBERT model)"),roo.forEach(t),fnt=i(ae),s6=n(ae,"LI",{});var too=s(s6);vxe=n(too,"STRONG",{});var y2a=s(vxe);gnt=r(y2a,"mpnet"),y2a.forEach(t),hnt=r(too," \u2014 "),rse=n(too,"A",{href:!0});var x2a=s(rse);unt=r(x2a,"TFMPNetForSequenceClassification"),x2a.forEach(t),pnt=r(too," (MPNet model)"),too.forEach(t),_nt=i(ae),l6=n(ae,"LI",{});var aoo=s(l6);Fxe=n(aoo,"STRONG",{});var $2a=s(Fxe);bnt=r($2a,"openai-gpt"),$2a.forEach(t),vnt=r(aoo," \u2014 "),tse=n(aoo,"A",{href:!0});var k2a=s(tse);Fnt=r(k2a,"TFOpenAIGPTForSequenceClassification"),k2a.forEach(t),Tnt=r(aoo," (OpenAI GPT model)"),aoo.forEach(t),Mnt=i(ae),i6=n(ae,"LI",{});var noo=s(i6);Txe=n(noo,"STRONG",{});var S2a=s(Txe);Ent=r(S2a,"rembert"),S2a.forEach(t),Cnt=r(noo," \u2014 "),ase=n(noo,"A",{href:!0});var R2a=s(ase);wnt=r(R2a,"TFRemBertForSequenceClassification"),R2a.forEach(t),Ant=r(noo," (RemBERT model)"),noo.forEach(t),Lnt=i(ae),d6=n(ae,"LI",{});var soo=s(d6);Mxe=n(soo,"STRONG",{});var P2a=s(Mxe);ynt=r(P2a,"roberta"),P2a.forEach(t),xnt=r(soo," \u2014 "),nse=n(soo,"A",{href:!0});var B2a=s(nse);$nt=r(B2a,"TFRobertaForSequenceClassification"),B2a.forEach(t),knt=r(soo," (RoBERTa model)"),soo.forEach(t),Snt=i(ae),m6=n(ae,"LI",{});var loo=s(m6);Exe=n(loo,"STRONG",{});var I2a=s(Exe);Rnt=r(I2a,"roformer"),I2a.forEach(t),Pnt=r(loo," \u2014 "),sse=n(loo,"A",{href:!0});var N2a=s(sse);Bnt=r(N2a,"TFRoFormerForSequenceClassification"),N2a.forEach(t),Int=r(loo," (RoFormer model)"),loo.forEach(t),Nnt=i(ae),c6=n(ae,"LI",{});var ioo=s(c6);Cxe=n(ioo,"STRONG",{});var q2a=s(Cxe);qnt=r(q2a,"tapas"),q2a.forEach(t),jnt=r(ioo," \u2014 "),lse=n(ioo,"A",{href:!0});var j2a=s(lse);Dnt=r(j2a,"TFTapasForSequenceClassification"),j2a.forEach(t),Gnt=r(ioo," (TAPAS model)"),ioo.forEach(t),Ont=i(ae),f6=n(ae,"LI",{});var doo=s(f6);wxe=n(doo,"STRONG",{});var D2a=s(wxe);Vnt=r(D2a,"transfo-xl"),D2a.forEach(t),Xnt=r(doo," \u2014 "),ise=n(doo,"A",{href:!0});var G2a=s(ise);znt=r(G2a,"TFTransfoXLForSequenceClassification"),G2a.forEach(t),Qnt=r(doo," (Transformer-XL model)"),doo.forEach(t),Wnt=i(ae),g6=n(ae,"LI",{});var moo=s(g6);Axe=n(moo,"STRONG",{});var O2a=s(Axe);Unt=r(O2a,"xlm"),O2a.forEach(t),Hnt=r(moo," \u2014 "),dse=n(moo,"A",{href:!0});var V2a=s(dse);Jnt=r(V2a,"TFXLMForSequenceClassification"),V2a.forEach(t),Ynt=r(moo," (XLM model)"),moo.forEach(t),Znt=i(ae),h6=n(ae,"LI",{});var coo=s(h6);Lxe=n(coo,"STRONG",{});var X2a=s(Lxe);Knt=r(X2a,"xlm-roberta"),X2a.forEach(t),est=r(coo," \u2014 "),mse=n(coo,"A",{href:!0});var z2a=s(mse);ost=r(z2a,"TFXLMRobertaForSequenceClassification"),z2a.forEach(t),rst=r(coo," (XLM-RoBERTa model)"),coo.forEach(t),tst=i(ae),u6=n(ae,"LI",{});var foo=s(u6);yxe=n(foo,"STRONG",{});var Q2a=s(yxe);ast=r(Q2a,"xlnet"),Q2a.forEach(t),nst=r(foo," \u2014 "),cse=n(foo,"A",{href:!0});var W2a=s(cse);sst=r(W2a,"TFXLNetForSequenceClassification"),W2a.forEach(t),lst=r(foo," (XLNet model)"),foo.forEach(t),ae.forEach(t),ist=i(Si),T(p6.$$.fragment,Si),Si.forEach(t),ki.forEach(t),nso=i(c),Ic=n(c,"H2",{class:!0});var Cio=s(Ic);_6=n(Cio,"A",{id:!0,class:!0,href:!0});var U2a=s(_6);xxe=n(U2a,"SPAN",{});var H2a=s(xxe);T(hP.$$.fragment,H2a),H2a.forEach(t),U2a.forEach(t),dst=i(Cio),$xe=n(Cio,"SPAN",{});var J2a=s($xe);mst=r(J2a,"TFAutoModelForMultipleChoice"),J2a.forEach(t),Cio.forEach(t),sso=i(c),br=n(c,"DIV",{class:!0});var Ri=s(br);T(uP.$$.fragment,Ri),cst=i(Ri),Nc=n(Ri,"P",{});var ofe=s(Nc);fst=r(ofe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),fse=n(ofe,"A",{href:!0});var Y2a=s(fse);gst=r(Y2a,"from_pretrained()"),Y2a.forEach(t),hst=r(ofe," class method or the "),gse=n(ofe,"A",{href:!0});var Z2a=s(gse);ust=r(Z2a,"from_config()"),Z2a.forEach(t),pst=r(ofe,` class
method.`),ofe.forEach(t),_st=i(Ri),pP=n(Ri,"P",{});var wio=s(pP);bst=r(wio,"This class cannot be instantiated directly using "),kxe=n(wio,"CODE",{});var K2a=s(kxe);vst=r(K2a,"__init__()"),K2a.forEach(t),Fst=r(wio," (throws an error)."),wio.forEach(t),Tst=i(Ri),na=n(Ri,"DIV",{class:!0});var Rx=s(na);T(_P.$$.fragment,Rx),Mst=i(Rx),Sxe=n(Rx,"P",{});var eba=s(Sxe);Est=r(eba,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),eba.forEach(t),Cst=i(Rx),qc=n(Rx,"P",{});var rfe=s(qc);wst=r(rfe,`Note:
Loading a model from its configuration file does `),Rxe=n(rfe,"STRONG",{});var oba=s(Rxe);Ast=r(oba,"not"),oba.forEach(t),Lst=r(rfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),hse=n(rfe,"A",{href:!0});var rba=s(hse);yst=r(rba,"from_pretrained()"),rba.forEach(t),xst=r(rfe," to load the model weights."),rfe.forEach(t),$st=i(Rx),T(b6.$$.fragment,Rx),Rx.forEach(t),kst=i(Ri),Ur=n(Ri,"DIV",{class:!0});var Pi=s(Ur);T(bP.$$.fragment,Pi),Sst=i(Pi),Pxe=n(Pi,"P",{});var tba=s(Pxe);Rst=r(tba,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),tba.forEach(t),Pst=i(Pi),Vn=n(Pi,"P",{});var Px=s(Vn);Bst=r(Px,"The model class to instantiate is selected based on the "),Bxe=n(Px,"CODE",{});var aba=s(Bxe);Ist=r(aba,"model_type"),aba.forEach(t),Nst=r(Px,` property of the config object (either
passed as an argument or loaded from `),Ixe=n(Px,"CODE",{});var nba=s(Ixe);qst=r(nba,"pretrained_model_name_or_path"),nba.forEach(t),jst=r(Px,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nxe=n(Px,"CODE",{});var sba=s(Nxe);Dst=r(sba,"pretrained_model_name_or_path"),sba.forEach(t),Gst=r(Px,":"),Px.forEach(t),Ost=i(Pi),ve=n(Pi,"UL",{});var Te=s(ve);v6=n(Te,"LI",{});var goo=s(v6);qxe=n(goo,"STRONG",{});var lba=s(qxe);Vst=r(lba,"albert"),lba.forEach(t),Xst=r(goo," \u2014 "),use=n(goo,"A",{href:!0});var iba=s(use);zst=r(iba,"TFAlbertForMultipleChoice"),iba.forEach(t),Qst=r(goo," (ALBERT model)"),goo.forEach(t),Wst=i(Te),F6=n(Te,"LI",{});var hoo=s(F6);jxe=n(hoo,"STRONG",{});var dba=s(jxe);Ust=r(dba,"bert"),dba.forEach(t),Hst=r(hoo," \u2014 "),pse=n(hoo,"A",{href:!0});var mba=s(pse);Jst=r(mba,"TFBertForMultipleChoice"),mba.forEach(t),Yst=r(hoo," (BERT model)"),hoo.forEach(t),Zst=i(Te),T6=n(Te,"LI",{});var uoo=s(T6);Dxe=n(uoo,"STRONG",{});var cba=s(Dxe);Kst=r(cba,"camembert"),cba.forEach(t),elt=r(uoo," \u2014 "),_se=n(uoo,"A",{href:!0});var fba=s(_se);olt=r(fba,"TFCamembertForMultipleChoice"),fba.forEach(t),rlt=r(uoo," (CamemBERT model)"),uoo.forEach(t),tlt=i(Te),M6=n(Te,"LI",{});var poo=s(M6);Gxe=n(poo,"STRONG",{});var gba=s(Gxe);alt=r(gba,"convbert"),gba.forEach(t),nlt=r(poo," \u2014 "),bse=n(poo,"A",{href:!0});var hba=s(bse);slt=r(hba,"TFConvBertForMultipleChoice"),hba.forEach(t),llt=r(poo," (ConvBERT model)"),poo.forEach(t),ilt=i(Te),E6=n(Te,"LI",{});var _oo=s(E6);Oxe=n(_oo,"STRONG",{});var uba=s(Oxe);dlt=r(uba,"distilbert"),uba.forEach(t),mlt=r(_oo," \u2014 "),vse=n(_oo,"A",{href:!0});var pba=s(vse);clt=r(pba,"TFDistilBertForMultipleChoice"),pba.forEach(t),flt=r(_oo," (DistilBERT model)"),_oo.forEach(t),glt=i(Te),C6=n(Te,"LI",{});var boo=s(C6);Vxe=n(boo,"STRONG",{});var _ba=s(Vxe);hlt=r(_ba,"electra"),_ba.forEach(t),ult=r(boo," \u2014 "),Fse=n(boo,"A",{href:!0});var bba=s(Fse);plt=r(bba,"TFElectraForMultipleChoice"),bba.forEach(t),_lt=r(boo," (ELECTRA model)"),boo.forEach(t),blt=i(Te),w6=n(Te,"LI",{});var voo=s(w6);Xxe=n(voo,"STRONG",{});var vba=s(Xxe);vlt=r(vba,"flaubert"),vba.forEach(t),Flt=r(voo," \u2014 "),Tse=n(voo,"A",{href:!0});var Fba=s(Tse);Tlt=r(Fba,"TFFlaubertForMultipleChoice"),Fba.forEach(t),Mlt=r(voo," (FlauBERT model)"),voo.forEach(t),Elt=i(Te),A6=n(Te,"LI",{});var Foo=s(A6);zxe=n(Foo,"STRONG",{});var Tba=s(zxe);Clt=r(Tba,"funnel"),Tba.forEach(t),wlt=r(Foo," \u2014 "),Mse=n(Foo,"A",{href:!0});var Mba=s(Mse);Alt=r(Mba,"TFFunnelForMultipleChoice"),Mba.forEach(t),Llt=r(Foo," (Funnel Transformer model)"),Foo.forEach(t),ylt=i(Te),L6=n(Te,"LI",{});var Too=s(L6);Qxe=n(Too,"STRONG",{});var Eba=s(Qxe);xlt=r(Eba,"longformer"),Eba.forEach(t),$lt=r(Too," \u2014 "),Ese=n(Too,"A",{href:!0});var Cba=s(Ese);klt=r(Cba,"TFLongformerForMultipleChoice"),Cba.forEach(t),Slt=r(Too," (Longformer model)"),Too.forEach(t),Rlt=i(Te),y6=n(Te,"LI",{});var Moo=s(y6);Wxe=n(Moo,"STRONG",{});var wba=s(Wxe);Plt=r(wba,"mobilebert"),wba.forEach(t),Blt=r(Moo," \u2014 "),Cse=n(Moo,"A",{href:!0});var Aba=s(Cse);Ilt=r(Aba,"TFMobileBertForMultipleChoice"),Aba.forEach(t),Nlt=r(Moo," (MobileBERT model)"),Moo.forEach(t),qlt=i(Te),x6=n(Te,"LI",{});var Eoo=s(x6);Uxe=n(Eoo,"STRONG",{});var Lba=s(Uxe);jlt=r(Lba,"mpnet"),Lba.forEach(t),Dlt=r(Eoo," \u2014 "),wse=n(Eoo,"A",{href:!0});var yba=s(wse);Glt=r(yba,"TFMPNetForMultipleChoice"),yba.forEach(t),Olt=r(Eoo," (MPNet model)"),Eoo.forEach(t),Vlt=i(Te),$6=n(Te,"LI",{});var Coo=s($6);Hxe=n(Coo,"STRONG",{});var xba=s(Hxe);Xlt=r(xba,"rembert"),xba.forEach(t),zlt=r(Coo," \u2014 "),Ase=n(Coo,"A",{href:!0});var $ba=s(Ase);Qlt=r($ba,"TFRemBertForMultipleChoice"),$ba.forEach(t),Wlt=r(Coo," (RemBERT model)"),Coo.forEach(t),Ult=i(Te),k6=n(Te,"LI",{});var woo=s(k6);Jxe=n(woo,"STRONG",{});var kba=s(Jxe);Hlt=r(kba,"roberta"),kba.forEach(t),Jlt=r(woo," \u2014 "),Lse=n(woo,"A",{href:!0});var Sba=s(Lse);Ylt=r(Sba,"TFRobertaForMultipleChoice"),Sba.forEach(t),Zlt=r(woo," (RoBERTa model)"),woo.forEach(t),Klt=i(Te),S6=n(Te,"LI",{});var Aoo=s(S6);Yxe=n(Aoo,"STRONG",{});var Rba=s(Yxe);eit=r(Rba,"roformer"),Rba.forEach(t),oit=r(Aoo," \u2014 "),yse=n(Aoo,"A",{href:!0});var Pba=s(yse);rit=r(Pba,"TFRoFormerForMultipleChoice"),Pba.forEach(t),tit=r(Aoo," (RoFormer model)"),Aoo.forEach(t),ait=i(Te),R6=n(Te,"LI",{});var Loo=s(R6);Zxe=n(Loo,"STRONG",{});var Bba=s(Zxe);nit=r(Bba,"xlm"),Bba.forEach(t),sit=r(Loo," \u2014 "),xse=n(Loo,"A",{href:!0});var Iba=s(xse);lit=r(Iba,"TFXLMForMultipleChoice"),Iba.forEach(t),iit=r(Loo," (XLM model)"),Loo.forEach(t),dit=i(Te),P6=n(Te,"LI",{});var yoo=s(P6);Kxe=n(yoo,"STRONG",{});var Nba=s(Kxe);mit=r(Nba,"xlm-roberta"),Nba.forEach(t),cit=r(yoo," \u2014 "),$se=n(yoo,"A",{href:!0});var qba=s($se);fit=r(qba,"TFXLMRobertaForMultipleChoice"),qba.forEach(t),git=r(yoo," (XLM-RoBERTa model)"),yoo.forEach(t),hit=i(Te),B6=n(Te,"LI",{});var xoo=s(B6);e$e=n(xoo,"STRONG",{});var jba=s(e$e);uit=r(jba,"xlnet"),jba.forEach(t),pit=r(xoo," \u2014 "),kse=n(xoo,"A",{href:!0});var Dba=s(kse);_it=r(Dba,"TFXLNetForMultipleChoice"),Dba.forEach(t),bit=r(xoo," (XLNet model)"),xoo.forEach(t),Te.forEach(t),vit=i(Pi),T(I6.$$.fragment,Pi),Pi.forEach(t),Ri.forEach(t),lso=i(c),jc=n(c,"H2",{class:!0});var Aio=s(jc);N6=n(Aio,"A",{id:!0,class:!0,href:!0});var Gba=s(N6);o$e=n(Gba,"SPAN",{});var Oba=s(o$e);T(vP.$$.fragment,Oba),Oba.forEach(t),Gba.forEach(t),Fit=i(Aio),r$e=n(Aio,"SPAN",{});var Vba=s(r$e);Tit=r(Vba,"TFAutoModelForNextSentencePrediction"),Vba.forEach(t),Aio.forEach(t),iso=i(c),vr=n(c,"DIV",{class:!0});var Bi=s(vr);T(FP.$$.fragment,Bi),Mit=i(Bi),Dc=n(Bi,"P",{});var tfe=s(Dc);Eit=r(tfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Sse=n(tfe,"A",{href:!0});var Xba=s(Sse);Cit=r(Xba,"from_pretrained()"),Xba.forEach(t),wit=r(tfe," class method or the "),Rse=n(tfe,"A",{href:!0});var zba=s(Rse);Ait=r(zba,"from_config()"),zba.forEach(t),Lit=r(tfe,` class
method.`),tfe.forEach(t),yit=i(Bi),TP=n(Bi,"P",{});var Lio=s(TP);xit=r(Lio,"This class cannot be instantiated directly using "),t$e=n(Lio,"CODE",{});var Qba=s(t$e);$it=r(Qba,"__init__()"),Qba.forEach(t),kit=r(Lio," (throws an error)."),Lio.forEach(t),Sit=i(Bi),sa=n(Bi,"DIV",{class:!0});var Bx=s(sa);T(MP.$$.fragment,Bx),Rit=i(Bx),a$e=n(Bx,"P",{});var Wba=s(a$e);Pit=r(Wba,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Wba.forEach(t),Bit=i(Bx),Gc=n(Bx,"P",{});var afe=s(Gc);Iit=r(afe,`Note:
Loading a model from its configuration file does `),n$e=n(afe,"STRONG",{});var Uba=s(n$e);Nit=r(Uba,"not"),Uba.forEach(t),qit=r(afe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Pse=n(afe,"A",{href:!0});var Hba=s(Pse);jit=r(Hba,"from_pretrained()"),Hba.forEach(t),Dit=r(afe," to load the model weights."),afe.forEach(t),Git=i(Bx),T(q6.$$.fragment,Bx),Bx.forEach(t),Oit=i(Bi),Hr=n(Bi,"DIV",{class:!0});var Ii=s(Hr);T(EP.$$.fragment,Ii),Vit=i(Ii),s$e=n(Ii,"P",{});var Jba=s(s$e);Xit=r(Jba,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Jba.forEach(t),zit=i(Ii),Xn=n(Ii,"P",{});var Ix=s(Xn);Qit=r(Ix,"The model class to instantiate is selected based on the "),l$e=n(Ix,"CODE",{});var Yba=s(l$e);Wit=r(Yba,"model_type"),Yba.forEach(t),Uit=r(Ix,` property of the config object (either
passed as an argument or loaded from `),i$e=n(Ix,"CODE",{});var Zba=s(i$e);Hit=r(Zba,"pretrained_model_name_or_path"),Zba.forEach(t),Jit=r(Ix,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d$e=n(Ix,"CODE",{});var Kba=s(d$e);Yit=r(Kba,"pretrained_model_name_or_path"),Kba.forEach(t),Zit=r(Ix,":"),Ix.forEach(t),Kit=i(Ii),CP=n(Ii,"UL",{});var yio=s(CP);j6=n(yio,"LI",{});var $oo=s(j6);m$e=n($oo,"STRONG",{});var eva=s(m$e);edt=r(eva,"bert"),eva.forEach(t),odt=r($oo," \u2014 "),Bse=n($oo,"A",{href:!0});var ova=s(Bse);rdt=r(ova,"TFBertForNextSentencePrediction"),ova.forEach(t),tdt=r($oo," (BERT model)"),$oo.forEach(t),adt=i(yio),D6=n(yio,"LI",{});var koo=s(D6);c$e=n(koo,"STRONG",{});var rva=s(c$e);ndt=r(rva,"mobilebert"),rva.forEach(t),sdt=r(koo," \u2014 "),Ise=n(koo,"A",{href:!0});var tva=s(Ise);ldt=r(tva,"TFMobileBertForNextSentencePrediction"),tva.forEach(t),idt=r(koo," (MobileBERT model)"),koo.forEach(t),yio.forEach(t),ddt=i(Ii),T(G6.$$.fragment,Ii),Ii.forEach(t),Bi.forEach(t),dso=i(c),Oc=n(c,"H2",{class:!0});var xio=s(Oc);O6=n(xio,"A",{id:!0,class:!0,href:!0});var ava=s(O6);f$e=n(ava,"SPAN",{});var nva=s(f$e);T(wP.$$.fragment,nva),nva.forEach(t),ava.forEach(t),mdt=i(xio),g$e=n(xio,"SPAN",{});var sva=s(g$e);cdt=r(sva,"TFAutoModelForTableQuestionAnswering"),sva.forEach(t),xio.forEach(t),mso=i(c),Fr=n(c,"DIV",{class:!0});var Ni=s(Fr);T(AP.$$.fragment,Ni),fdt=i(Ni),Vc=n(Ni,"P",{});var nfe=s(Vc);gdt=r(nfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),Nse=n(nfe,"A",{href:!0});var lva=s(Nse);hdt=r(lva,"from_pretrained()"),lva.forEach(t),udt=r(nfe," class method or the "),qse=n(nfe,"A",{href:!0});var iva=s(qse);pdt=r(iva,"from_config()"),iva.forEach(t),_dt=r(nfe,` class
method.`),nfe.forEach(t),bdt=i(Ni),LP=n(Ni,"P",{});var $io=s(LP);vdt=r($io,"This class cannot be instantiated directly using "),h$e=n($io,"CODE",{});var dva=s(h$e);Fdt=r(dva,"__init__()"),dva.forEach(t),Tdt=r($io," (throws an error)."),$io.forEach(t),Mdt=i(Ni),la=n(Ni,"DIV",{class:!0});var Nx=s(la);T(yP.$$.fragment,Nx),Edt=i(Nx),u$e=n(Nx,"P",{});var mva=s(u$e);Cdt=r(mva,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),mva.forEach(t),wdt=i(Nx),Xc=n(Nx,"P",{});var sfe=s(Xc);Adt=r(sfe,`Note:
Loading a model from its configuration file does `),p$e=n(sfe,"STRONG",{});var cva=s(p$e);Ldt=r(cva,"not"),cva.forEach(t),ydt=r(sfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),jse=n(sfe,"A",{href:!0});var fva=s(jse);xdt=r(fva,"from_pretrained()"),fva.forEach(t),$dt=r(sfe," to load the model weights."),sfe.forEach(t),kdt=i(Nx),T(V6.$$.fragment,Nx),Nx.forEach(t),Sdt=i(Ni),Jr=n(Ni,"DIV",{class:!0});var qi=s(Jr);T(xP.$$.fragment,qi),Rdt=i(qi),_$e=n(qi,"P",{});var gva=s(_$e);Pdt=r(gva,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),gva.forEach(t),Bdt=i(qi),zn=n(qi,"P",{});var qx=s(zn);Idt=r(qx,"The model class to instantiate is selected based on the "),b$e=n(qx,"CODE",{});var hva=s(b$e);Ndt=r(hva,"model_type"),hva.forEach(t),qdt=r(qx,` property of the config object (either
passed as an argument or loaded from `),v$e=n(qx,"CODE",{});var uva=s(v$e);jdt=r(uva,"pretrained_model_name_or_path"),uva.forEach(t),Ddt=r(qx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),F$e=n(qx,"CODE",{});var pva=s(F$e);Gdt=r(pva,"pretrained_model_name_or_path"),pva.forEach(t),Odt=r(qx,":"),qx.forEach(t),Vdt=i(qi),T$e=n(qi,"UL",{});var _va=s(T$e);X6=n(_va,"LI",{});var Soo=s(X6);M$e=n(Soo,"STRONG",{});var bva=s(M$e);Xdt=r(bva,"tapas"),bva.forEach(t),zdt=r(Soo," \u2014 "),Dse=n(Soo,"A",{href:!0});var vva=s(Dse);Qdt=r(vva,"TFTapasForQuestionAnswering"),vva.forEach(t),Wdt=r(Soo," (TAPAS model)"),Soo.forEach(t),_va.forEach(t),Udt=i(qi),T(z6.$$.fragment,qi),qi.forEach(t),Ni.forEach(t),cso=i(c),zc=n(c,"H2",{class:!0});var kio=s(zc);Q6=n(kio,"A",{id:!0,class:!0,href:!0});var Fva=s(Q6);E$e=n(Fva,"SPAN",{});var Tva=s(E$e);T($P.$$.fragment,Tva),Tva.forEach(t),Fva.forEach(t),Hdt=i(kio),C$e=n(kio,"SPAN",{});var Mva=s(C$e);Jdt=r(Mva,"TFAutoModelForDocumentQuestionAnswering"),Mva.forEach(t),kio.forEach(t),fso=i(c),Tr=n(c,"DIV",{class:!0});var ji=s(Tr);T(kP.$$.fragment,ji),Ydt=i(ji),Qc=n(ji,"P",{});var lfe=s(Qc);Zdt=r(lfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),Gse=n(lfe,"A",{href:!0});var Eva=s(Gse);Kdt=r(Eva,"from_pretrained()"),Eva.forEach(t),emt=r(lfe," class method or the "),Ose=n(lfe,"A",{href:!0});var Cva=s(Ose);omt=r(Cva,"from_config()"),Cva.forEach(t),rmt=r(lfe,` class
method.`),lfe.forEach(t),tmt=i(ji),SP=n(ji,"P",{});var Sio=s(SP);amt=r(Sio,"This class cannot be instantiated directly using "),w$e=n(Sio,"CODE",{});var wva=s(w$e);nmt=r(wva,"__init__()"),wva.forEach(t),smt=r(Sio," (throws an error)."),Sio.forEach(t),lmt=i(ji),ia=n(ji,"DIV",{class:!0});var jx=s(ia);T(RP.$$.fragment,jx),imt=i(jx),A$e=n(jx,"P",{});var Ava=s(A$e);dmt=r(Ava,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),Ava.forEach(t),mmt=i(jx),Wc=n(jx,"P",{});var ife=s(Wc);cmt=r(ife,`Note:
Loading a model from its configuration file does `),L$e=n(ife,"STRONG",{});var Lva=s(L$e);fmt=r(Lva,"not"),Lva.forEach(t),gmt=r(ife,` load the model weights. It only affects the
model\u2019s configuration. Use `),Vse=n(ife,"A",{href:!0});var yva=s(Vse);hmt=r(yva,"from_pretrained()"),yva.forEach(t),umt=r(ife," to load the model weights."),ife.forEach(t),pmt=i(jx),T(W6.$$.fragment,jx),jx.forEach(t),_mt=i(ji),Yr=n(ji,"DIV",{class:!0});var Di=s(Yr);T(PP.$$.fragment,Di),bmt=i(Di),y$e=n(Di,"P",{});var xva=s(y$e);vmt=r(xva,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),xva.forEach(t),Fmt=i(Di),Qn=n(Di,"P",{});var Dx=s(Qn);Tmt=r(Dx,"The model class to instantiate is selected based on the "),x$e=n(Dx,"CODE",{});var $va=s(x$e);Mmt=r($va,"model_type"),$va.forEach(t),Emt=r(Dx,` property of the config object (either
passed as an argument or loaded from `),$$e=n(Dx,"CODE",{});var kva=s($$e);Cmt=r(kva,"pretrained_model_name_or_path"),kva.forEach(t),wmt=r(Dx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k$e=n(Dx,"CODE",{});var Sva=s(k$e);Amt=r(Sva,"pretrained_model_name_or_path"),Sva.forEach(t),Lmt=r(Dx,":"),Dx.forEach(t),ymt=i(Di),S$e=n(Di,"UL",{});var Rva=s(S$e);U6=n(Rva,"LI",{});var Roo=s(U6);R$e=n(Roo,"STRONG",{});var Pva=s(R$e);xmt=r(Pva,"layoutlm"),Pva.forEach(t),$mt=r(Roo," \u2014 "),Xse=n(Roo,"A",{href:!0});var Bva=s(Xse);kmt=r(Bva,"TFLayoutLMForQuestionAnswering"),Bva.forEach(t),Smt=r(Roo," (LayoutLM model)"),Roo.forEach(t),Rva.forEach(t),Rmt=i(Di),T(H6.$$.fragment,Di),Di.forEach(t),ji.forEach(t),gso=i(c),Uc=n(c,"H2",{class:!0});var Rio=s(Uc);J6=n(Rio,"A",{id:!0,class:!0,href:!0});var Iva=s(J6);P$e=n(Iva,"SPAN",{});var Nva=s(P$e);T(BP.$$.fragment,Nva),Nva.forEach(t),Iva.forEach(t),Pmt=i(Rio),B$e=n(Rio,"SPAN",{});var qva=s(B$e);Bmt=r(qva,"TFAutoModelForTokenClassification"),qva.forEach(t),Rio.forEach(t),hso=i(c),Mr=n(c,"DIV",{class:!0});var Gi=s(Mr);T(IP.$$.fragment,Gi),Imt=i(Gi),Hc=n(Gi,"P",{});var dfe=s(Hc);Nmt=r(dfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),zse=n(dfe,"A",{href:!0});var jva=s(zse);qmt=r(jva,"from_pretrained()"),jva.forEach(t),jmt=r(dfe," class method or the "),Qse=n(dfe,"A",{href:!0});var Dva=s(Qse);Dmt=r(Dva,"from_config()"),Dva.forEach(t),Gmt=r(dfe,` class
method.`),dfe.forEach(t),Omt=i(Gi),NP=n(Gi,"P",{});var Pio=s(NP);Vmt=r(Pio,"This class cannot be instantiated directly using "),I$e=n(Pio,"CODE",{});var Gva=s(I$e);Xmt=r(Gva,"__init__()"),Gva.forEach(t),zmt=r(Pio," (throws an error)."),Pio.forEach(t),Qmt=i(Gi),da=n(Gi,"DIV",{class:!0});var Gx=s(da);T(qP.$$.fragment,Gx),Wmt=i(Gx),N$e=n(Gx,"P",{});var Ova=s(N$e);Umt=r(Ova,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Ova.forEach(t),Hmt=i(Gx),Jc=n(Gx,"P",{});var mfe=s(Jc);Jmt=r(mfe,`Note:
Loading a model from its configuration file does `),q$e=n(mfe,"STRONG",{});var Vva=s(q$e);Ymt=r(Vva,"not"),Vva.forEach(t),Zmt=r(mfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Wse=n(mfe,"A",{href:!0});var Xva=s(Wse);Kmt=r(Xva,"from_pretrained()"),Xva.forEach(t),ect=r(mfe," to load the model weights."),mfe.forEach(t),oct=i(Gx),T(Y6.$$.fragment,Gx),Gx.forEach(t),rct=i(Gi),Zr=n(Gi,"DIV",{class:!0});var Oi=s(Zr);T(jP.$$.fragment,Oi),tct=i(Oi),j$e=n(Oi,"P",{});var zva=s(j$e);act=r(zva,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),zva.forEach(t),nct=i(Oi),Wn=n(Oi,"P",{});var Ox=s(Wn);sct=r(Ox,"The model class to instantiate is selected based on the "),D$e=n(Ox,"CODE",{});var Qva=s(D$e);lct=r(Qva,"model_type"),Qva.forEach(t),ict=r(Ox,` property of the config object (either
passed as an argument or loaded from `),G$e=n(Ox,"CODE",{});var Wva=s(G$e);dct=r(Wva,"pretrained_model_name_or_path"),Wva.forEach(t),mct=r(Ox,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O$e=n(Ox,"CODE",{});var Uva=s(O$e);cct=r(Uva,"pretrained_model_name_or_path"),Uva.forEach(t),fct=r(Ox,":"),Ox.forEach(t),gct=i(Oi),ie=n(Oi,"UL",{});var ge=s(ie);Z6=n(ge,"LI",{});var Poo=s(Z6);V$e=n(Poo,"STRONG",{});var Hva=s(V$e);hct=r(Hva,"albert"),Hva.forEach(t),uct=r(Poo," \u2014 "),Use=n(Poo,"A",{href:!0});var Jva=s(Use);pct=r(Jva,"TFAlbertForTokenClassification"),Jva.forEach(t),_ct=r(Poo," (ALBERT model)"),Poo.forEach(t),bct=i(ge),K6=n(ge,"LI",{});var Boo=s(K6);X$e=n(Boo,"STRONG",{});var Yva=s(X$e);vct=r(Yva,"bert"),Yva.forEach(t),Fct=r(Boo," \u2014 "),Hse=n(Boo,"A",{href:!0});var Zva=s(Hse);Tct=r(Zva,"TFBertForTokenClassification"),Zva.forEach(t),Mct=r(Boo," (BERT model)"),Boo.forEach(t),Ect=i(ge),e7=n(ge,"LI",{});var Ioo=s(e7);z$e=n(Ioo,"STRONG",{});var Kva=s(z$e);Cct=r(Kva,"camembert"),Kva.forEach(t),wct=r(Ioo," \u2014 "),Jse=n(Ioo,"A",{href:!0});var eFa=s(Jse);Act=r(eFa,"TFCamembertForTokenClassification"),eFa.forEach(t),Lct=r(Ioo," (CamemBERT model)"),Ioo.forEach(t),yct=i(ge),o7=n(ge,"LI",{});var Noo=s(o7);Q$e=n(Noo,"STRONG",{});var oFa=s(Q$e);xct=r(oFa,"convbert"),oFa.forEach(t),$ct=r(Noo," \u2014 "),Yse=n(Noo,"A",{href:!0});var rFa=s(Yse);kct=r(rFa,"TFConvBertForTokenClassification"),rFa.forEach(t),Sct=r(Noo," (ConvBERT model)"),Noo.forEach(t),Rct=i(ge),r7=n(ge,"LI",{});var qoo=s(r7);W$e=n(qoo,"STRONG",{});var tFa=s(W$e);Pct=r(tFa,"deberta"),tFa.forEach(t),Bct=r(qoo," \u2014 "),Zse=n(qoo,"A",{href:!0});var aFa=s(Zse);Ict=r(aFa,"TFDebertaForTokenClassification"),aFa.forEach(t),Nct=r(qoo," (DeBERTa model)"),qoo.forEach(t),qct=i(ge),t7=n(ge,"LI",{});var joo=s(t7);U$e=n(joo,"STRONG",{});var nFa=s(U$e);jct=r(nFa,"deberta-v2"),nFa.forEach(t),Dct=r(joo," \u2014 "),Kse=n(joo,"A",{href:!0});var sFa=s(Kse);Gct=r(sFa,"TFDebertaV2ForTokenClassification"),sFa.forEach(t),Oct=r(joo," (DeBERTa-v2 model)"),joo.forEach(t),Vct=i(ge),a7=n(ge,"LI",{});var Doo=s(a7);H$e=n(Doo,"STRONG",{});var lFa=s(H$e);Xct=r(lFa,"distilbert"),lFa.forEach(t),zct=r(Doo," \u2014 "),ele=n(Doo,"A",{href:!0});var iFa=s(ele);Qct=r(iFa,"TFDistilBertForTokenClassification"),iFa.forEach(t),Wct=r(Doo," (DistilBERT model)"),Doo.forEach(t),Uct=i(ge),n7=n(ge,"LI",{});var Goo=s(n7);J$e=n(Goo,"STRONG",{});var dFa=s(J$e);Hct=r(dFa,"electra"),dFa.forEach(t),Jct=r(Goo," \u2014 "),ole=n(Goo,"A",{href:!0});var mFa=s(ole);Yct=r(mFa,"TFElectraForTokenClassification"),mFa.forEach(t),Zct=r(Goo," (ELECTRA model)"),Goo.forEach(t),Kct=i(ge),s7=n(ge,"LI",{});var Ooo=s(s7);Y$e=n(Ooo,"STRONG",{});var cFa=s(Y$e);eft=r(cFa,"esm"),cFa.forEach(t),oft=r(Ooo," \u2014 "),rle=n(Ooo,"A",{href:!0});var fFa=s(rle);rft=r(fFa,"TFEsmForTokenClassification"),fFa.forEach(t),tft=r(Ooo," (ESM model)"),Ooo.forEach(t),aft=i(ge),l7=n(ge,"LI",{});var Voo=s(l7);Z$e=n(Voo,"STRONG",{});var gFa=s(Z$e);nft=r(gFa,"flaubert"),gFa.forEach(t),sft=r(Voo," \u2014 "),tle=n(Voo,"A",{href:!0});var hFa=s(tle);lft=r(hFa,"TFFlaubertForTokenClassification"),hFa.forEach(t),ift=r(Voo," (FlauBERT model)"),Voo.forEach(t),dft=i(ge),i7=n(ge,"LI",{});var Xoo=s(i7);K$e=n(Xoo,"STRONG",{});var uFa=s(K$e);mft=r(uFa,"funnel"),uFa.forEach(t),cft=r(Xoo," \u2014 "),ale=n(Xoo,"A",{href:!0});var pFa=s(ale);fft=r(pFa,"TFFunnelForTokenClassification"),pFa.forEach(t),gft=r(Xoo," (Funnel Transformer model)"),Xoo.forEach(t),hft=i(ge),d7=n(ge,"LI",{});var zoo=s(d7);eke=n(zoo,"STRONG",{});var _Fa=s(eke);uft=r(_Fa,"layoutlm"),_Fa.forEach(t),pft=r(zoo," \u2014 "),nle=n(zoo,"A",{href:!0});var bFa=s(nle);_ft=r(bFa,"TFLayoutLMForTokenClassification"),bFa.forEach(t),bft=r(zoo," (LayoutLM model)"),zoo.forEach(t),vft=i(ge),m7=n(ge,"LI",{});var Qoo=s(m7);oke=n(Qoo,"STRONG",{});var vFa=s(oke);Fft=r(vFa,"layoutlmv3"),vFa.forEach(t),Tft=r(Qoo," \u2014 "),sle=n(Qoo,"A",{href:!0});var FFa=s(sle);Mft=r(FFa,"TFLayoutLMv3ForTokenClassification"),FFa.forEach(t),Eft=r(Qoo," (LayoutLMv3 model)"),Qoo.forEach(t),Cft=i(ge),c7=n(ge,"LI",{});var Woo=s(c7);rke=n(Woo,"STRONG",{});var TFa=s(rke);wft=r(TFa,"longformer"),TFa.forEach(t),Aft=r(Woo," \u2014 "),lle=n(Woo,"A",{href:!0});var MFa=s(lle);Lft=r(MFa,"TFLongformerForTokenClassification"),MFa.forEach(t),yft=r(Woo," (Longformer model)"),Woo.forEach(t),xft=i(ge),f7=n(ge,"LI",{});var Uoo=s(f7);tke=n(Uoo,"STRONG",{});var EFa=s(tke);$ft=r(EFa,"mobilebert"),EFa.forEach(t),kft=r(Uoo," \u2014 "),ile=n(Uoo,"A",{href:!0});var CFa=s(ile);Sft=r(CFa,"TFMobileBertForTokenClassification"),CFa.forEach(t),Rft=r(Uoo," (MobileBERT model)"),Uoo.forEach(t),Pft=i(ge),g7=n(ge,"LI",{});var Hoo=s(g7);ake=n(Hoo,"STRONG",{});var wFa=s(ake);Bft=r(wFa,"mpnet"),wFa.forEach(t),Ift=r(Hoo," \u2014 "),dle=n(Hoo,"A",{href:!0});var AFa=s(dle);Nft=r(AFa,"TFMPNetForTokenClassification"),AFa.forEach(t),qft=r(Hoo," (MPNet model)"),Hoo.forEach(t),jft=i(ge),h7=n(ge,"LI",{});var Joo=s(h7);nke=n(Joo,"STRONG",{});var LFa=s(nke);Dft=r(LFa,"rembert"),LFa.forEach(t),Gft=r(Joo," \u2014 "),mle=n(Joo,"A",{href:!0});var yFa=s(mle);Oft=r(yFa,"TFRemBertForTokenClassification"),yFa.forEach(t),Vft=r(Joo," (RemBERT model)"),Joo.forEach(t),Xft=i(ge),u7=n(ge,"LI",{});var Yoo=s(u7);ske=n(Yoo,"STRONG",{});var xFa=s(ske);zft=r(xFa,"roberta"),xFa.forEach(t),Qft=r(Yoo," \u2014 "),cle=n(Yoo,"A",{href:!0});var $Fa=s(cle);Wft=r($Fa,"TFRobertaForTokenClassification"),$Fa.forEach(t),Uft=r(Yoo," (RoBERTa model)"),Yoo.forEach(t),Hft=i(ge),p7=n(ge,"LI",{});var Zoo=s(p7);lke=n(Zoo,"STRONG",{});var kFa=s(lke);Jft=r(kFa,"roformer"),kFa.forEach(t),Yft=r(Zoo," \u2014 "),fle=n(Zoo,"A",{href:!0});var SFa=s(fle);Zft=r(SFa,"TFRoFormerForTokenClassification"),SFa.forEach(t),Kft=r(Zoo," (RoFormer model)"),Zoo.forEach(t),egt=i(ge),_7=n(ge,"LI",{});var Koo=s(_7);ike=n(Koo,"STRONG",{});var RFa=s(ike);ogt=r(RFa,"xlm"),RFa.forEach(t),rgt=r(Koo," \u2014 "),gle=n(Koo,"A",{href:!0});var PFa=s(gle);tgt=r(PFa,"TFXLMForTokenClassification"),PFa.forEach(t),agt=r(Koo," (XLM model)"),Koo.forEach(t),ngt=i(ge),b7=n(ge,"LI",{});var ero=s(b7);dke=n(ero,"STRONG",{});var BFa=s(dke);sgt=r(BFa,"xlm-roberta"),BFa.forEach(t),lgt=r(ero," \u2014 "),hle=n(ero,"A",{href:!0});var IFa=s(hle);igt=r(IFa,"TFXLMRobertaForTokenClassification"),IFa.forEach(t),dgt=r(ero," (XLM-RoBERTa model)"),ero.forEach(t),mgt=i(ge),v7=n(ge,"LI",{});var oro=s(v7);mke=n(oro,"STRONG",{});var NFa=s(mke);cgt=r(NFa,"xlnet"),NFa.forEach(t),fgt=r(oro," \u2014 "),ule=n(oro,"A",{href:!0});var qFa=s(ule);ggt=r(qFa,"TFXLNetForTokenClassification"),qFa.forEach(t),hgt=r(oro," (XLNet model)"),oro.forEach(t),ge.forEach(t),ugt=i(Oi),T(F7.$$.fragment,Oi),Oi.forEach(t),Gi.forEach(t),uso=i(c),Yc=n(c,"H2",{class:!0});var Bio=s(Yc);T7=n(Bio,"A",{id:!0,class:!0,href:!0});var jFa=s(T7);cke=n(jFa,"SPAN",{});var DFa=s(cke);T(DP.$$.fragment,DFa),DFa.forEach(t),jFa.forEach(t),pgt=i(Bio),fke=n(Bio,"SPAN",{});var GFa=s(fke);_gt=r(GFa,"TFAutoModelForQuestionAnswering"),GFa.forEach(t),Bio.forEach(t),pso=i(c),Er=n(c,"DIV",{class:!0});var Vi=s(Er);T(GP.$$.fragment,Vi),bgt=i(Vi),Zc=n(Vi,"P",{});var cfe=s(Zc);vgt=r(cfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),ple=n(cfe,"A",{href:!0});var OFa=s(ple);Fgt=r(OFa,"from_pretrained()"),OFa.forEach(t),Tgt=r(cfe," class method or the "),_le=n(cfe,"A",{href:!0});var VFa=s(_le);Mgt=r(VFa,"from_config()"),VFa.forEach(t),Egt=r(cfe,` class
method.`),cfe.forEach(t),Cgt=i(Vi),OP=n(Vi,"P",{});var Iio=s(OP);wgt=r(Iio,"This class cannot be instantiated directly using "),gke=n(Iio,"CODE",{});var XFa=s(gke);Agt=r(XFa,"__init__()"),XFa.forEach(t),Lgt=r(Iio," (throws an error)."),Iio.forEach(t),ygt=i(Vi),ma=n(Vi,"DIV",{class:!0});var Vx=s(ma);T(VP.$$.fragment,Vx),xgt=i(Vx),hke=n(Vx,"P",{});var zFa=s(hke);$gt=r(zFa,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),zFa.forEach(t),kgt=i(Vx),Kc=n(Vx,"P",{});var ffe=s(Kc);Sgt=r(ffe,`Note:
Loading a model from its configuration file does `),uke=n(ffe,"STRONG",{});var QFa=s(uke);Rgt=r(QFa,"not"),QFa.forEach(t),Pgt=r(ffe,` load the model weights. It only affects the
model\u2019s configuration. Use `),ble=n(ffe,"A",{href:!0});var WFa=s(ble);Bgt=r(WFa,"from_pretrained()"),WFa.forEach(t),Igt=r(ffe," to load the model weights."),ffe.forEach(t),Ngt=i(Vx),T(M7.$$.fragment,Vx),Vx.forEach(t),qgt=i(Vi),Kr=n(Vi,"DIV",{class:!0});var Xi=s(Kr);T(XP.$$.fragment,Xi),jgt=i(Xi),pke=n(Xi,"P",{});var UFa=s(pke);Dgt=r(UFa,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),UFa.forEach(t),Ggt=i(Xi),Un=n(Xi,"P",{});var Xx=s(Un);Ogt=r(Xx,"The model class to instantiate is selected based on the "),_ke=n(Xx,"CODE",{});var HFa=s(_ke);Vgt=r(HFa,"model_type"),HFa.forEach(t),Xgt=r(Xx,` property of the config object (either
passed as an argument or loaded from `),bke=n(Xx,"CODE",{});var JFa=s(bke);zgt=r(JFa,"pretrained_model_name_or_path"),JFa.forEach(t),Qgt=r(Xx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vke=n(Xx,"CODE",{});var YFa=s(vke);Wgt=r(YFa,"pretrained_model_name_or_path"),YFa.forEach(t),Ugt=r(Xx,":"),Xx.forEach(t),Hgt=i(Xi),fe=n(Xi,"UL",{});var pe=s(fe);E7=n(pe,"LI",{});var rro=s(E7);Fke=n(rro,"STRONG",{});var ZFa=s(Fke);Jgt=r(ZFa,"albert"),ZFa.forEach(t),Ygt=r(rro," \u2014 "),vle=n(rro,"A",{href:!0});var KFa=s(vle);Zgt=r(KFa,"TFAlbertForQuestionAnswering"),KFa.forEach(t),Kgt=r(rro," (ALBERT model)"),rro.forEach(t),eht=i(pe),C7=n(pe,"LI",{});var tro=s(C7);Tke=n(tro,"STRONG",{});var eTa=s(Tke);oht=r(eTa,"bert"),eTa.forEach(t),rht=r(tro," \u2014 "),Fle=n(tro,"A",{href:!0});var oTa=s(Fle);tht=r(oTa,"TFBertForQuestionAnswering"),oTa.forEach(t),aht=r(tro," (BERT model)"),tro.forEach(t),nht=i(pe),w7=n(pe,"LI",{});var aro=s(w7);Mke=n(aro,"STRONG",{});var rTa=s(Mke);sht=r(rTa,"camembert"),rTa.forEach(t),lht=r(aro," \u2014 "),Tle=n(aro,"A",{href:!0});var tTa=s(Tle);iht=r(tTa,"TFCamembertForQuestionAnswering"),tTa.forEach(t),dht=r(aro," (CamemBERT model)"),aro.forEach(t),mht=i(pe),A7=n(pe,"LI",{});var nro=s(A7);Eke=n(nro,"STRONG",{});var aTa=s(Eke);cht=r(aTa,"convbert"),aTa.forEach(t),fht=r(nro," \u2014 "),Mle=n(nro,"A",{href:!0});var nTa=s(Mle);ght=r(nTa,"TFConvBertForQuestionAnswering"),nTa.forEach(t),hht=r(nro," (ConvBERT model)"),nro.forEach(t),uht=i(pe),L7=n(pe,"LI",{});var sro=s(L7);Cke=n(sro,"STRONG",{});var sTa=s(Cke);pht=r(sTa,"deberta"),sTa.forEach(t),_ht=r(sro," \u2014 "),Ele=n(sro,"A",{href:!0});var lTa=s(Ele);bht=r(lTa,"TFDebertaForQuestionAnswering"),lTa.forEach(t),vht=r(sro," (DeBERTa model)"),sro.forEach(t),Fht=i(pe),y7=n(pe,"LI",{});var lro=s(y7);wke=n(lro,"STRONG",{});var iTa=s(wke);Tht=r(iTa,"deberta-v2"),iTa.forEach(t),Mht=r(lro," \u2014 "),Cle=n(lro,"A",{href:!0});var dTa=s(Cle);Eht=r(dTa,"TFDebertaV2ForQuestionAnswering"),dTa.forEach(t),Cht=r(lro," (DeBERTa-v2 model)"),lro.forEach(t),wht=i(pe),x7=n(pe,"LI",{});var iro=s(x7);Ake=n(iro,"STRONG",{});var mTa=s(Ake);Aht=r(mTa,"distilbert"),mTa.forEach(t),Lht=r(iro," \u2014 "),wle=n(iro,"A",{href:!0});var cTa=s(wle);yht=r(cTa,"TFDistilBertForQuestionAnswering"),cTa.forEach(t),xht=r(iro," (DistilBERT model)"),iro.forEach(t),$ht=i(pe),$7=n(pe,"LI",{});var dro=s($7);Lke=n(dro,"STRONG",{});var fTa=s(Lke);kht=r(fTa,"electra"),fTa.forEach(t),Sht=r(dro," \u2014 "),Ale=n(dro,"A",{href:!0});var gTa=s(Ale);Rht=r(gTa,"TFElectraForQuestionAnswering"),gTa.forEach(t),Pht=r(dro," (ELECTRA model)"),dro.forEach(t),Bht=i(pe),k7=n(pe,"LI",{});var mro=s(k7);yke=n(mro,"STRONG",{});var hTa=s(yke);Iht=r(hTa,"flaubert"),hTa.forEach(t),Nht=r(mro," \u2014 "),Lle=n(mro,"A",{href:!0});var uTa=s(Lle);qht=r(uTa,"TFFlaubertForQuestionAnsweringSimple"),uTa.forEach(t),jht=r(mro," (FlauBERT model)"),mro.forEach(t),Dht=i(pe),S7=n(pe,"LI",{});var cro=s(S7);xke=n(cro,"STRONG",{});var pTa=s(xke);Ght=r(pTa,"funnel"),pTa.forEach(t),Oht=r(cro," \u2014 "),yle=n(cro,"A",{href:!0});var _Ta=s(yle);Vht=r(_Ta,"TFFunnelForQuestionAnswering"),_Ta.forEach(t),Xht=r(cro," (Funnel Transformer model)"),cro.forEach(t),zht=i(pe),R7=n(pe,"LI",{});var fro=s(R7);$ke=n(fro,"STRONG",{});var bTa=s($ke);Qht=r(bTa,"gptj"),bTa.forEach(t),Wht=r(fro," \u2014 "),xle=n(fro,"A",{href:!0});var vTa=s(xle);Uht=r(vTa,"TFGPTJForQuestionAnswering"),vTa.forEach(t),Hht=r(fro," (GPT-J model)"),fro.forEach(t),Jht=i(pe),P7=n(pe,"LI",{});var gro=s(P7);kke=n(gro,"STRONG",{});var FTa=s(kke);Yht=r(FTa,"layoutlmv3"),FTa.forEach(t),Zht=r(gro," \u2014 "),$le=n(gro,"A",{href:!0});var TTa=s($le);Kht=r(TTa,"TFLayoutLMv3ForQuestionAnswering"),TTa.forEach(t),eut=r(gro," (LayoutLMv3 model)"),gro.forEach(t),out=i(pe),B7=n(pe,"LI",{});var hro=s(B7);Ske=n(hro,"STRONG",{});var MTa=s(Ske);rut=r(MTa,"longformer"),MTa.forEach(t),tut=r(hro," \u2014 "),kle=n(hro,"A",{href:!0});var ETa=s(kle);aut=r(ETa,"TFLongformerForQuestionAnswering"),ETa.forEach(t),nut=r(hro," (Longformer model)"),hro.forEach(t),sut=i(pe),I7=n(pe,"LI",{});var uro=s(I7);Rke=n(uro,"STRONG",{});var CTa=s(Rke);lut=r(CTa,"mobilebert"),CTa.forEach(t),iut=r(uro," \u2014 "),Sle=n(uro,"A",{href:!0});var wTa=s(Sle);dut=r(wTa,"TFMobileBertForQuestionAnswering"),wTa.forEach(t),mut=r(uro," (MobileBERT model)"),uro.forEach(t),cut=i(pe),N7=n(pe,"LI",{});var pro=s(N7);Pke=n(pro,"STRONG",{});var ATa=s(Pke);fut=r(ATa,"mpnet"),ATa.forEach(t),gut=r(pro," \u2014 "),Rle=n(pro,"A",{href:!0});var LTa=s(Rle);hut=r(LTa,"TFMPNetForQuestionAnswering"),LTa.forEach(t),uut=r(pro," (MPNet model)"),pro.forEach(t),put=i(pe),q7=n(pe,"LI",{});var _ro=s(q7);Bke=n(_ro,"STRONG",{});var yTa=s(Bke);_ut=r(yTa,"rembert"),yTa.forEach(t),but=r(_ro," \u2014 "),Ple=n(_ro,"A",{href:!0});var xTa=s(Ple);vut=r(xTa,"TFRemBertForQuestionAnswering"),xTa.forEach(t),Fut=r(_ro," (RemBERT model)"),_ro.forEach(t),Tut=i(pe),j7=n(pe,"LI",{});var bro=s(j7);Ike=n(bro,"STRONG",{});var $Ta=s(Ike);Mut=r($Ta,"roberta"),$Ta.forEach(t),Eut=r(bro," \u2014 "),Ble=n(bro,"A",{href:!0});var kTa=s(Ble);Cut=r(kTa,"TFRobertaForQuestionAnswering"),kTa.forEach(t),wut=r(bro," (RoBERTa model)"),bro.forEach(t),Aut=i(pe),D7=n(pe,"LI",{});var vro=s(D7);Nke=n(vro,"STRONG",{});var STa=s(Nke);Lut=r(STa,"roformer"),STa.forEach(t),yut=r(vro," \u2014 "),Ile=n(vro,"A",{href:!0});var RTa=s(Ile);xut=r(RTa,"TFRoFormerForQuestionAnswering"),RTa.forEach(t),$ut=r(vro," (RoFormer model)"),vro.forEach(t),kut=i(pe),G7=n(pe,"LI",{});var Fro=s(G7);qke=n(Fro,"STRONG",{});var PTa=s(qke);Sut=r(PTa,"xlm"),PTa.forEach(t),Rut=r(Fro," \u2014 "),Nle=n(Fro,"A",{href:!0});var BTa=s(Nle);Put=r(BTa,"TFXLMForQuestionAnsweringSimple"),BTa.forEach(t),But=r(Fro," (XLM model)"),Fro.forEach(t),Iut=i(pe),O7=n(pe,"LI",{});var Tro=s(O7);jke=n(Tro,"STRONG",{});var ITa=s(jke);Nut=r(ITa,"xlm-roberta"),ITa.forEach(t),qut=r(Tro," \u2014 "),qle=n(Tro,"A",{href:!0});var NTa=s(qle);jut=r(NTa,"TFXLMRobertaForQuestionAnswering"),NTa.forEach(t),Dut=r(Tro," (XLM-RoBERTa model)"),Tro.forEach(t),Gut=i(pe),V7=n(pe,"LI",{});var Mro=s(V7);Dke=n(Mro,"STRONG",{});var qTa=s(Dke);Out=r(qTa,"xlnet"),qTa.forEach(t),Vut=r(Mro," \u2014 "),jle=n(Mro,"A",{href:!0});var jTa=s(jle);Xut=r(jTa,"TFXLNetForQuestionAnsweringSimple"),jTa.forEach(t),zut=r(Mro," (XLNet model)"),Mro.forEach(t),pe.forEach(t),Qut=i(Xi),T(X7.$$.fragment,Xi),Xi.forEach(t),Vi.forEach(t),_so=i(c),ef=n(c,"H2",{class:!0});var Nio=s(ef);z7=n(Nio,"A",{id:!0,class:!0,href:!0});var DTa=s(z7);Gke=n(DTa,"SPAN",{});var GTa=s(Gke);T(zP.$$.fragment,GTa),GTa.forEach(t),DTa.forEach(t),Wut=i(Nio),Oke=n(Nio,"SPAN",{});var OTa=s(Oke);Uut=r(OTa,"TFAutoModelForVision2Seq"),OTa.forEach(t),Nio.forEach(t),bso=i(c),Cr=n(c,"DIV",{class:!0});var zi=s(Cr);T(QP.$$.fragment,zi),Hut=i(zi),of=n(zi,"P",{});var gfe=s(of);Jut=r(gfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Dle=n(gfe,"A",{href:!0});var VTa=s(Dle);Yut=r(VTa,"from_pretrained()"),VTa.forEach(t),Zut=r(gfe," class method or the "),Gle=n(gfe,"A",{href:!0});var XTa=s(Gle);Kut=r(XTa,"from_config()"),XTa.forEach(t),ept=r(gfe,` class
method.`),gfe.forEach(t),opt=i(zi),WP=n(zi,"P",{});var qio=s(WP);rpt=r(qio,"This class cannot be instantiated directly using "),Vke=n(qio,"CODE",{});var zTa=s(Vke);tpt=r(zTa,"__init__()"),zTa.forEach(t),apt=r(qio," (throws an error)."),qio.forEach(t),npt=i(zi),ca=n(zi,"DIV",{class:!0});var zx=s(ca);T(UP.$$.fragment,zx),spt=i(zx),Xke=n(zx,"P",{});var QTa=s(Xke);lpt=r(QTa,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),QTa.forEach(t),ipt=i(zx),rf=n(zx,"P",{});var hfe=s(rf);dpt=r(hfe,`Note:
Loading a model from its configuration file does `),zke=n(hfe,"STRONG",{});var WTa=s(zke);mpt=r(WTa,"not"),WTa.forEach(t),cpt=r(hfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ole=n(hfe,"A",{href:!0});var UTa=s(Ole);fpt=r(UTa,"from_pretrained()"),UTa.forEach(t),gpt=r(hfe," to load the model weights."),hfe.forEach(t),hpt=i(zx),T(Q7.$$.fragment,zx),zx.forEach(t),upt=i(zi),et=n(zi,"DIV",{class:!0});var Qi=s(et);T(HP.$$.fragment,Qi),ppt=i(Qi),Qke=n(Qi,"P",{});var HTa=s(Qke);_pt=r(HTa,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),HTa.forEach(t),bpt=i(Qi),Hn=n(Qi,"P",{});var Qx=s(Hn);vpt=r(Qx,"The model class to instantiate is selected based on the "),Wke=n(Qx,"CODE",{});var JTa=s(Wke);Fpt=r(JTa,"model_type"),JTa.forEach(t),Tpt=r(Qx,` property of the config object (either
passed as an argument or loaded from `),Uke=n(Qx,"CODE",{});var YTa=s(Uke);Mpt=r(YTa,"pretrained_model_name_or_path"),YTa.forEach(t),Ept=r(Qx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Hke=n(Qx,"CODE",{});var ZTa=s(Hke);Cpt=r(ZTa,"pretrained_model_name_or_path"),ZTa.forEach(t),wpt=r(Qx,":"),Qx.forEach(t),Apt=i(Qi),Jke=n(Qi,"UL",{});var KTa=s(Jke);W7=n(KTa,"LI",{});var Ero=s(W7);Yke=n(Ero,"STRONG",{});var eMa=s(Yke);Lpt=r(eMa,"vision-encoder-decoder"),eMa.forEach(t),ypt=r(Ero," \u2014 "),Vle=n(Ero,"A",{href:!0});var oMa=s(Vle);xpt=r(oMa,"TFVisionEncoderDecoderModel"),oMa.forEach(t),$pt=r(Ero," (Vision Encoder decoder model)"),Ero.forEach(t),KTa.forEach(t),kpt=i(Qi),T(U7.$$.fragment,Qi),Qi.forEach(t),zi.forEach(t),vso=i(c),tf=n(c,"H2",{class:!0});var jio=s(tf);H7=n(jio,"A",{id:!0,class:!0,href:!0});var rMa=s(H7);Zke=n(rMa,"SPAN",{});var tMa=s(Zke);T(JP.$$.fragment,tMa),tMa.forEach(t),rMa.forEach(t),Spt=i(jio),Kke=n(jio,"SPAN",{});var aMa=s(Kke);Rpt=r(aMa,"TFAutoModelForSpeechSeq2Seq"),aMa.forEach(t),jio.forEach(t),Fso=i(c),wr=n(c,"DIV",{class:!0});var Wi=s(wr);T(YP.$$.fragment,Wi),Ppt=i(Wi),af=n(Wi,"P",{});var ufe=s(af);Bpt=r(ufe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),Xle=n(ufe,"A",{href:!0});var nMa=s(Xle);Ipt=r(nMa,"from_pretrained()"),nMa.forEach(t),Npt=r(ufe," class method or the "),zle=n(ufe,"A",{href:!0});var sMa=s(zle);qpt=r(sMa,"from_config()"),sMa.forEach(t),jpt=r(ufe,` class
method.`),ufe.forEach(t),Dpt=i(Wi),ZP=n(Wi,"P",{});var Dio=s(ZP);Gpt=r(Dio,"This class cannot be instantiated directly using "),eSe=n(Dio,"CODE",{});var lMa=s(eSe);Opt=r(lMa,"__init__()"),lMa.forEach(t),Vpt=r(Dio," (throws an error)."),Dio.forEach(t),Xpt=i(Wi),fa=n(Wi,"DIV",{class:!0});var Wx=s(fa);T(KP.$$.fragment,Wx),zpt=i(Wx),oSe=n(Wx,"P",{});var iMa=s(oSe);Qpt=r(iMa,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),iMa.forEach(t),Wpt=i(Wx),nf=n(Wx,"P",{});var pfe=s(nf);Upt=r(pfe,`Note:
Loading a model from its configuration file does `),rSe=n(pfe,"STRONG",{});var dMa=s(rSe);Hpt=r(dMa,"not"),dMa.forEach(t),Jpt=r(pfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Qle=n(pfe,"A",{href:!0});var mMa=s(Qle);Ypt=r(mMa,"from_pretrained()"),mMa.forEach(t),Zpt=r(pfe," to load the model weights."),pfe.forEach(t),Kpt=i(Wx),T(J7.$$.fragment,Wx),Wx.forEach(t),e_t=i(Wi),ot=n(Wi,"DIV",{class:!0});var Ui=s(ot);T(eB.$$.fragment,Ui),o_t=i(Ui),tSe=n(Ui,"P",{});var cMa=s(tSe);r_t=r(cMa,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),cMa.forEach(t),t_t=i(Ui),Jn=n(Ui,"P",{});var Ux=s(Jn);a_t=r(Ux,"The model class to instantiate is selected based on the "),aSe=n(Ux,"CODE",{});var fMa=s(aSe);n_t=r(fMa,"model_type"),fMa.forEach(t),s_t=r(Ux,` property of the config object (either
passed as an argument or loaded from `),nSe=n(Ux,"CODE",{});var gMa=s(nSe);l_t=r(gMa,"pretrained_model_name_or_path"),gMa.forEach(t),i_t=r(Ux,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sSe=n(Ux,"CODE",{});var hMa=s(sSe);d_t=r(hMa,"pretrained_model_name_or_path"),hMa.forEach(t),m_t=r(Ux,":"),Ux.forEach(t),c_t=i(Ui),oB=n(Ui,"UL",{});var Gio=s(oB);Y7=n(Gio,"LI",{});var Cro=s(Y7);lSe=n(Cro,"STRONG",{});var uMa=s(lSe);f_t=r(uMa,"speech_to_text"),uMa.forEach(t),g_t=r(Cro," \u2014 "),Wle=n(Cro,"A",{href:!0});var pMa=s(Wle);h_t=r(pMa,"TFSpeech2TextForConditionalGeneration"),pMa.forEach(t),u_t=r(Cro," (Speech2Text model)"),Cro.forEach(t),p_t=i(Gio),Z7=n(Gio,"LI",{});var wro=s(Z7);iSe=n(wro,"STRONG",{});var _Ma=s(iSe);__t=r(_Ma,"whisper"),_Ma.forEach(t),b_t=r(wro," \u2014 "),Ule=n(wro,"A",{href:!0});var bMa=s(Ule);v_t=r(bMa,"TFWhisperForConditionalGeneration"),bMa.forEach(t),F_t=r(wro," (Whisper model)"),wro.forEach(t),Gio.forEach(t),T_t=i(Ui),T(K7.$$.fragment,Ui),Ui.forEach(t),Wi.forEach(t),Tso=i(c),sf=n(c,"H2",{class:!0});var Oio=s(sf);e8=n(Oio,"A",{id:!0,class:!0,href:!0});var vMa=s(e8);dSe=n(vMa,"SPAN",{});var FMa=s(dSe);T(rB.$$.fragment,FMa),FMa.forEach(t),vMa.forEach(t),M_t=i(Oio),mSe=n(Oio,"SPAN",{});var TMa=s(mSe);E_t=r(TMa,"FlaxAutoModel"),TMa.forEach(t),Oio.forEach(t),Mso=i(c),Ar=n(c,"DIV",{class:!0});var Hi=s(Ar);T(tB.$$.fragment,Hi),C_t=i(Hi),lf=n(Hi,"P",{});var _fe=s(lf);w_t=r(_fe,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Hle=n(_fe,"A",{href:!0});var MMa=s(Hle);A_t=r(MMa,"from_pretrained()"),MMa.forEach(t),L_t=r(_fe," class method or the "),Jle=n(_fe,"A",{href:!0});var EMa=s(Jle);y_t=r(EMa,"from_config()"),EMa.forEach(t),x_t=r(_fe,` class
method.`),_fe.forEach(t),$_t=i(Hi),aB=n(Hi,"P",{});var Vio=s(aB);k_t=r(Vio,"This class cannot be instantiated directly using "),cSe=n(Vio,"CODE",{});var CMa=s(cSe);S_t=r(CMa,"__init__()"),CMa.forEach(t),R_t=r(Vio," (throws an error)."),Vio.forEach(t),P_t=i(Hi),ga=n(Hi,"DIV",{class:!0});var Hx=s(ga);T(nB.$$.fragment,Hx),B_t=i(Hx),fSe=n(Hx,"P",{});var wMa=s(fSe);I_t=r(wMa,"Instantiates one of the base model classes of the library from a configuration."),wMa.forEach(t),N_t=i(Hx),df=n(Hx,"P",{});var bfe=s(df);q_t=r(bfe,`Note:
Loading a model from its configuration file does `),gSe=n(bfe,"STRONG",{});var AMa=s(gSe);j_t=r(AMa,"not"),AMa.forEach(t),D_t=r(bfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Yle=n(bfe,"A",{href:!0});var LMa=s(Yle);G_t=r(LMa,"from_pretrained()"),LMa.forEach(t),O_t=r(bfe," to load the model weights."),bfe.forEach(t),V_t=i(Hx),T(o8.$$.fragment,Hx),Hx.forEach(t),X_t=i(Hi),rt=n(Hi,"DIV",{class:!0});var Ji=s(rt);T(sB.$$.fragment,Ji),z_t=i(Ji),hSe=n(Ji,"P",{});var yMa=s(hSe);Q_t=r(yMa,"Instantiate one of the base model classes of the library from a pretrained model."),yMa.forEach(t),W_t=i(Ji),Yn=n(Ji,"P",{});var Jx=s(Yn);U_t=r(Jx,"The model class to instantiate is selected based on the "),uSe=n(Jx,"CODE",{});var xMa=s(uSe);H_t=r(xMa,"model_type"),xMa.forEach(t),J_t=r(Jx,` property of the config object (either
passed as an argument or loaded from `),pSe=n(Jx,"CODE",{});var $Ma=s(pSe);Y_t=r($Ma,"pretrained_model_name_or_path"),$Ma.forEach(t),Z_t=r(Jx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_Se=n(Jx,"CODE",{});var kMa=s(_Se);K_t=r(kMa,"pretrained_model_name_or_path"),kMa.forEach(t),e1t=r(Jx,":"),Jx.forEach(t),o1t=i(Ji),te=n(Ji,"UL",{});var ne=s(te);r8=n(ne,"LI",{});var Aro=s(r8);bSe=n(Aro,"STRONG",{});var SMa=s(bSe);r1t=r(SMa,"albert"),SMa.forEach(t),t1t=r(Aro," \u2014 "),Zle=n(Aro,"A",{href:!0});var RMa=s(Zle);a1t=r(RMa,"FlaxAlbertModel"),RMa.forEach(t),n1t=r(Aro," (ALBERT model)"),Aro.forEach(t),s1t=i(ne),t8=n(ne,"LI",{});var Lro=s(t8);vSe=n(Lro,"STRONG",{});var PMa=s(vSe);l1t=r(PMa,"bart"),PMa.forEach(t),i1t=r(Lro," \u2014 "),Kle=n(Lro,"A",{href:!0});var BMa=s(Kle);d1t=r(BMa,"FlaxBartModel"),BMa.forEach(t),m1t=r(Lro," (BART model)"),Lro.forEach(t),c1t=i(ne),a8=n(ne,"LI",{});var yro=s(a8);FSe=n(yro,"STRONG",{});var IMa=s(FSe);f1t=r(IMa,"beit"),IMa.forEach(t),g1t=r(yro," \u2014 "),eie=n(yro,"A",{href:!0});var NMa=s(eie);h1t=r(NMa,"FlaxBeitModel"),NMa.forEach(t),u1t=r(yro," (BEiT model)"),yro.forEach(t),p1t=i(ne),n8=n(ne,"LI",{});var xro=s(n8);TSe=n(xro,"STRONG",{});var qMa=s(TSe);_1t=r(qMa,"bert"),qMa.forEach(t),b1t=r(xro," \u2014 "),oie=n(xro,"A",{href:!0});var jMa=s(oie);v1t=r(jMa,"FlaxBertModel"),jMa.forEach(t),F1t=r(xro," (BERT model)"),xro.forEach(t),T1t=i(ne),s8=n(ne,"LI",{});var $ro=s(s8);MSe=n($ro,"STRONG",{});var DMa=s(MSe);M1t=r(DMa,"big_bird"),DMa.forEach(t),E1t=r($ro," \u2014 "),rie=n($ro,"A",{href:!0});var GMa=s(rie);C1t=r(GMa,"FlaxBigBirdModel"),GMa.forEach(t),w1t=r($ro," (BigBird model)"),$ro.forEach(t),A1t=i(ne),l8=n(ne,"LI",{});var kro=s(l8);ESe=n(kro,"STRONG",{});var OMa=s(ESe);L1t=r(OMa,"blenderbot"),OMa.forEach(t),y1t=r(kro," \u2014 "),tie=n(kro,"A",{href:!0});var VMa=s(tie);x1t=r(VMa,"FlaxBlenderbotModel"),VMa.forEach(t),$1t=r(kro," (Blenderbot model)"),kro.forEach(t),k1t=i(ne),i8=n(ne,"LI",{});var Sro=s(i8);CSe=n(Sro,"STRONG",{});var XMa=s(CSe);S1t=r(XMa,"blenderbot-small"),XMa.forEach(t),R1t=r(Sro," \u2014 "),aie=n(Sro,"A",{href:!0});var zMa=s(aie);P1t=r(zMa,"FlaxBlenderbotSmallModel"),zMa.forEach(t),B1t=r(Sro," (BlenderbotSmall model)"),Sro.forEach(t),I1t=i(ne),d8=n(ne,"LI",{});var Rro=s(d8);wSe=n(Rro,"STRONG",{});var QMa=s(wSe);N1t=r(QMa,"clip"),QMa.forEach(t),q1t=r(Rro," \u2014 "),nie=n(Rro,"A",{href:!0});var WMa=s(nie);j1t=r(WMa,"FlaxCLIPModel"),WMa.forEach(t),D1t=r(Rro," (CLIP model)"),Rro.forEach(t),G1t=i(ne),m8=n(ne,"LI",{});var Pro=s(m8);ASe=n(Pro,"STRONG",{});var UMa=s(ASe);O1t=r(UMa,"distilbert"),UMa.forEach(t),V1t=r(Pro," \u2014 "),sie=n(Pro,"A",{href:!0});var HMa=s(sie);X1t=r(HMa,"FlaxDistilBertModel"),HMa.forEach(t),z1t=r(Pro," (DistilBERT model)"),Pro.forEach(t),Q1t=i(ne),c8=n(ne,"LI",{});var Bro=s(c8);LSe=n(Bro,"STRONG",{});var JMa=s(LSe);W1t=r(JMa,"electra"),JMa.forEach(t),U1t=r(Bro," \u2014 "),lie=n(Bro,"A",{href:!0});var YMa=s(lie);H1t=r(YMa,"FlaxElectraModel"),YMa.forEach(t),J1t=r(Bro," (ELECTRA model)"),Bro.forEach(t),Y1t=i(ne),f8=n(ne,"LI",{});var Iro=s(f8);ySe=n(Iro,"STRONG",{});var ZMa=s(ySe);Z1t=r(ZMa,"gpt2"),ZMa.forEach(t),K1t=r(Iro," \u2014 "),iie=n(Iro,"A",{href:!0});var KMa=s(iie);e2t=r(KMa,"FlaxGPT2Model"),KMa.forEach(t),o2t=r(Iro," (OpenAI GPT-2 model)"),Iro.forEach(t),r2t=i(ne),g8=n(ne,"LI",{});var Nro=s(g8);xSe=n(Nro,"STRONG",{});var eEa=s(xSe);t2t=r(eEa,"gpt_neo"),eEa.forEach(t),a2t=r(Nro," \u2014 "),die=n(Nro,"A",{href:!0});var oEa=s(die);n2t=r(oEa,"FlaxGPTNeoModel"),oEa.forEach(t),s2t=r(Nro," (GPT Neo model)"),Nro.forEach(t),l2t=i(ne),h8=n(ne,"LI",{});var qro=s(h8);$Se=n(qro,"STRONG",{});var rEa=s($Se);i2t=r(rEa,"gptj"),rEa.forEach(t),d2t=r(qro," \u2014 "),mie=n(qro,"A",{href:!0});var tEa=s(mie);m2t=r(tEa,"FlaxGPTJModel"),tEa.forEach(t),c2t=r(qro," (GPT-J model)"),qro.forEach(t),f2t=i(ne),u8=n(ne,"LI",{});var jro=s(u8);kSe=n(jro,"STRONG",{});var aEa=s(kSe);g2t=r(aEa,"longt5"),aEa.forEach(t),h2t=r(jro," \u2014 "),cie=n(jro,"A",{href:!0});var nEa=s(cie);u2t=r(nEa,"FlaxLongT5Model"),nEa.forEach(t),p2t=r(jro," (LongT5 model)"),jro.forEach(t),_2t=i(ne),p8=n(ne,"LI",{});var Dro=s(p8);SSe=n(Dro,"STRONG",{});var sEa=s(SSe);b2t=r(sEa,"marian"),sEa.forEach(t),v2t=r(Dro," \u2014 "),fie=n(Dro,"A",{href:!0});var lEa=s(fie);F2t=r(lEa,"FlaxMarianModel"),lEa.forEach(t),T2t=r(Dro," (Marian model)"),Dro.forEach(t),M2t=i(ne),_8=n(ne,"LI",{});var Gro=s(_8);RSe=n(Gro,"STRONG",{});var iEa=s(RSe);E2t=r(iEa,"mbart"),iEa.forEach(t),C2t=r(Gro," \u2014 "),gie=n(Gro,"A",{href:!0});var dEa=s(gie);w2t=r(dEa,"FlaxMBartModel"),dEa.forEach(t),A2t=r(Gro," (mBART model)"),Gro.forEach(t),L2t=i(ne),b8=n(ne,"LI",{});var Oro=s(b8);PSe=n(Oro,"STRONG",{});var mEa=s(PSe);y2t=r(mEa,"mt5"),mEa.forEach(t),x2t=r(Oro," \u2014 "),hie=n(Oro,"A",{href:!0});var cEa=s(hie);$2t=r(cEa,"FlaxMT5Model"),cEa.forEach(t),k2t=r(Oro," (MT5 model)"),Oro.forEach(t),S2t=i(ne),v8=n(ne,"LI",{});var Vro=s(v8);BSe=n(Vro,"STRONG",{});var fEa=s(BSe);R2t=r(fEa,"opt"),fEa.forEach(t),P2t=r(Vro," \u2014 "),uie=n(Vro,"A",{href:!0});var gEa=s(uie);B2t=r(gEa,"FlaxOPTModel"),gEa.forEach(t),I2t=r(Vro," (OPT model)"),Vro.forEach(t),N2t=i(ne),F8=n(ne,"LI",{});var Xro=s(F8);ISe=n(Xro,"STRONG",{});var hEa=s(ISe);q2t=r(hEa,"pegasus"),hEa.forEach(t),j2t=r(Xro," \u2014 "),pie=n(Xro,"A",{href:!0});var uEa=s(pie);D2t=r(uEa,"FlaxPegasusModel"),uEa.forEach(t),G2t=r(Xro," (Pegasus model)"),Xro.forEach(t),O2t=i(ne),T8=n(ne,"LI",{});var zro=s(T8);NSe=n(zro,"STRONG",{});var pEa=s(NSe);V2t=r(pEa,"roberta"),pEa.forEach(t),X2t=r(zro," \u2014 "),_ie=n(zro,"A",{href:!0});var _Ea=s(_ie);z2t=r(_Ea,"FlaxRobertaModel"),_Ea.forEach(t),Q2t=r(zro," (RoBERTa model)"),zro.forEach(t),W2t=i(ne),M8=n(ne,"LI",{});var Qro=s(M8);qSe=n(Qro,"STRONG",{});var bEa=s(qSe);U2t=r(bEa,"roformer"),bEa.forEach(t),H2t=r(Qro," \u2014 "),bie=n(Qro,"A",{href:!0});var vEa=s(bie);J2t=r(vEa,"FlaxRoFormerModel"),vEa.forEach(t),Y2t=r(Qro," (RoFormer model)"),Qro.forEach(t),Z2t=i(ne),E8=n(ne,"LI",{});var Wro=s(E8);jSe=n(Wro,"STRONG",{});var FEa=s(jSe);K2t=r(FEa,"t5"),FEa.forEach(t),ebt=r(Wro," \u2014 "),vie=n(Wro,"A",{href:!0});var TEa=s(vie);obt=r(TEa,"FlaxT5Model"),TEa.forEach(t),rbt=r(Wro," (T5 model)"),Wro.forEach(t),tbt=i(ne),C8=n(ne,"LI",{});var Uro=s(C8);DSe=n(Uro,"STRONG",{});var MEa=s(DSe);abt=r(MEa,"vision-text-dual-encoder"),MEa.forEach(t),nbt=r(Uro," \u2014 "),Fie=n(Uro,"A",{href:!0});var EEa=s(Fie);sbt=r(EEa,"FlaxVisionTextDualEncoderModel"),EEa.forEach(t),lbt=r(Uro," (VisionTextDualEncoder model)"),Uro.forEach(t),ibt=i(ne),w8=n(ne,"LI",{});var Hro=s(w8);GSe=n(Hro,"STRONG",{});var CEa=s(GSe);dbt=r(CEa,"vit"),CEa.forEach(t),mbt=r(Hro," \u2014 "),Tie=n(Hro,"A",{href:!0});var wEa=s(Tie);cbt=r(wEa,"FlaxViTModel"),wEa.forEach(t),fbt=r(Hro," (ViT model)"),Hro.forEach(t),gbt=i(ne),A8=n(ne,"LI",{});var Jro=s(A8);OSe=n(Jro,"STRONG",{});var AEa=s(OSe);hbt=r(AEa,"wav2vec2"),AEa.forEach(t),ubt=r(Jro," \u2014 "),Mie=n(Jro,"A",{href:!0});var LEa=s(Mie);pbt=r(LEa,"FlaxWav2Vec2Model"),LEa.forEach(t),_bt=r(Jro," (Wav2Vec2 model)"),Jro.forEach(t),bbt=i(ne),L8=n(ne,"LI",{});var Yro=s(L8);VSe=n(Yro,"STRONG",{});var yEa=s(VSe);vbt=r(yEa,"xglm"),yEa.forEach(t),Fbt=r(Yro," \u2014 "),Eie=n(Yro,"A",{href:!0});var xEa=s(Eie);Tbt=r(xEa,"FlaxXGLMModel"),xEa.forEach(t),Mbt=r(Yro," (XGLM model)"),Yro.forEach(t),Ebt=i(ne),y8=n(ne,"LI",{});var Zro=s(y8);XSe=n(Zro,"STRONG",{});var $Ea=s(XSe);Cbt=r($Ea,"xlm-roberta"),$Ea.forEach(t),wbt=r(Zro," \u2014 "),Cie=n(Zro,"A",{href:!0});var kEa=s(Cie);Abt=r(kEa,"FlaxXLMRobertaModel"),kEa.forEach(t),Lbt=r(Zro," (XLM-RoBERTa model)"),Zro.forEach(t),ne.forEach(t),ybt=i(Ji),T(x8.$$.fragment,Ji),Ji.forEach(t),Hi.forEach(t),Eso=i(c),mf=n(c,"H2",{class:!0});var Xio=s(mf);$8=n(Xio,"A",{id:!0,class:!0,href:!0});var SEa=s($8);zSe=n(SEa,"SPAN",{});var REa=s(zSe);T(lB.$$.fragment,REa),REa.forEach(t),SEa.forEach(t),xbt=i(Xio),QSe=n(Xio,"SPAN",{});var PEa=s(QSe);$bt=r(PEa,"FlaxAutoModelForCausalLM"),PEa.forEach(t),Xio.forEach(t),Cso=i(c),Lr=n(c,"DIV",{class:!0});var Yi=s(Lr);T(iB.$$.fragment,Yi),kbt=i(Yi),cf=n(Yi,"P",{});var vfe=s(cf);Sbt=r(vfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),wie=n(vfe,"A",{href:!0});var BEa=s(wie);Rbt=r(BEa,"from_pretrained()"),BEa.forEach(t),Pbt=r(vfe," class method or the "),Aie=n(vfe,"A",{href:!0});var IEa=s(Aie);Bbt=r(IEa,"from_config()"),IEa.forEach(t),Ibt=r(vfe,` class
method.`),vfe.forEach(t),Nbt=i(Yi),dB=n(Yi,"P",{});var zio=s(dB);qbt=r(zio,"This class cannot be instantiated directly using "),WSe=n(zio,"CODE",{});var NEa=s(WSe);jbt=r(NEa,"__init__()"),NEa.forEach(t),Dbt=r(zio," (throws an error)."),zio.forEach(t),Gbt=i(Yi),ha=n(Yi,"DIV",{class:!0});var Yx=s(ha);T(mB.$$.fragment,Yx),Obt=i(Yx),USe=n(Yx,"P",{});var qEa=s(USe);Vbt=r(qEa,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),qEa.forEach(t),Xbt=i(Yx),ff=n(Yx,"P",{});var Ffe=s(ff);zbt=r(Ffe,`Note:
Loading a model from its configuration file does `),HSe=n(Ffe,"STRONG",{});var jEa=s(HSe);Qbt=r(jEa,"not"),jEa.forEach(t),Wbt=r(Ffe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Lie=n(Ffe,"A",{href:!0});var DEa=s(Lie);Ubt=r(DEa,"from_pretrained()"),DEa.forEach(t),Hbt=r(Ffe," to load the model weights."),Ffe.forEach(t),Jbt=i(Yx),T(k8.$$.fragment,Yx),Yx.forEach(t),Ybt=i(Yi),tt=n(Yi,"DIV",{class:!0});var Zi=s(tt);T(cB.$$.fragment,Zi),Zbt=i(Zi),JSe=n(Zi,"P",{});var GEa=s(JSe);Kbt=r(GEa,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),GEa.forEach(t),evt=i(Zi),Zn=n(Zi,"P",{});var Zx=s(Zn);ovt=r(Zx,"The model class to instantiate is selected based on the "),YSe=n(Zx,"CODE",{});var OEa=s(YSe);rvt=r(OEa,"model_type"),OEa.forEach(t),tvt=r(Zx,` property of the config object (either
passed as an argument or loaded from `),ZSe=n(Zx,"CODE",{});var VEa=s(ZSe);avt=r(VEa,"pretrained_model_name_or_path"),VEa.forEach(t),nvt=r(Zx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KSe=n(Zx,"CODE",{});var XEa=s(KSe);svt=r(XEa,"pretrained_model_name_or_path"),XEa.forEach(t),lvt=r(Zx,":"),Zx.forEach(t),ivt=i(Zi),$e=n(Zi,"UL",{});var je=s($e);S8=n(je,"LI",{});var Kro=s(S8);eRe=n(Kro,"STRONG",{});var zEa=s(eRe);dvt=r(zEa,"bart"),zEa.forEach(t),mvt=r(Kro," \u2014 "),yie=n(Kro,"A",{href:!0});var QEa=s(yie);cvt=r(QEa,"FlaxBartForCausalLM"),QEa.forEach(t),fvt=r(Kro," (BART model)"),Kro.forEach(t),gvt=i(je),R8=n(je,"LI",{});var eto=s(R8);oRe=n(eto,"STRONG",{});var WEa=s(oRe);hvt=r(WEa,"bert"),WEa.forEach(t),uvt=r(eto," \u2014 "),xie=n(eto,"A",{href:!0});var UEa=s(xie);pvt=r(UEa,"FlaxBertForCausalLM"),UEa.forEach(t),_vt=r(eto," (BERT model)"),eto.forEach(t),bvt=i(je),P8=n(je,"LI",{});var oto=s(P8);rRe=n(oto,"STRONG",{});var HEa=s(rRe);vvt=r(HEa,"big_bird"),HEa.forEach(t),Fvt=r(oto," \u2014 "),$ie=n(oto,"A",{href:!0});var JEa=s($ie);Tvt=r(JEa,"FlaxBigBirdForCausalLM"),JEa.forEach(t),Mvt=r(oto," (BigBird model)"),oto.forEach(t),Evt=i(je),B8=n(je,"LI",{});var rto=s(B8);tRe=n(rto,"STRONG",{});var YEa=s(tRe);Cvt=r(YEa,"electra"),YEa.forEach(t),wvt=r(rto," \u2014 "),kie=n(rto,"A",{href:!0});var ZEa=s(kie);Avt=r(ZEa,"FlaxElectraForCausalLM"),ZEa.forEach(t),Lvt=r(rto," (ELECTRA model)"),rto.forEach(t),yvt=i(je),I8=n(je,"LI",{});var tto=s(I8);aRe=n(tto,"STRONG",{});var KEa=s(aRe);xvt=r(KEa,"gpt2"),KEa.forEach(t),$vt=r(tto," \u2014 "),Sie=n(tto,"A",{href:!0});var e4a=s(Sie);kvt=r(e4a,"FlaxGPT2LMHeadModel"),e4a.forEach(t),Svt=r(tto," (OpenAI GPT-2 model)"),tto.forEach(t),Rvt=i(je),N8=n(je,"LI",{});var ato=s(N8);nRe=n(ato,"STRONG",{});var o4a=s(nRe);Pvt=r(o4a,"gpt_neo"),o4a.forEach(t),Bvt=r(ato," \u2014 "),Rie=n(ato,"A",{href:!0});var r4a=s(Rie);Ivt=r(r4a,"FlaxGPTNeoForCausalLM"),r4a.forEach(t),Nvt=r(ato," (GPT Neo model)"),ato.forEach(t),qvt=i(je),q8=n(je,"LI",{});var nto=s(q8);sRe=n(nto,"STRONG",{});var t4a=s(sRe);jvt=r(t4a,"gptj"),t4a.forEach(t),Dvt=r(nto," \u2014 "),Pie=n(nto,"A",{href:!0});var a4a=s(Pie);Gvt=r(a4a,"FlaxGPTJForCausalLM"),a4a.forEach(t),Ovt=r(nto," (GPT-J model)"),nto.forEach(t),Vvt=i(je),j8=n(je,"LI",{});var sto=s(j8);lRe=n(sto,"STRONG",{});var n4a=s(lRe);Xvt=r(n4a,"opt"),n4a.forEach(t),zvt=r(sto," \u2014 "),Bie=n(sto,"A",{href:!0});var s4a=s(Bie);Qvt=r(s4a,"FlaxOPTForCausalLM"),s4a.forEach(t),Wvt=r(sto," (OPT model)"),sto.forEach(t),Uvt=i(je),D8=n(je,"LI",{});var lto=s(D8);iRe=n(lto,"STRONG",{});var l4a=s(iRe);Hvt=r(l4a,"roberta"),l4a.forEach(t),Jvt=r(lto," \u2014 "),Iie=n(lto,"A",{href:!0});var i4a=s(Iie);Yvt=r(i4a,"FlaxRobertaForCausalLM"),i4a.forEach(t),Zvt=r(lto," (RoBERTa model)"),lto.forEach(t),Kvt=i(je),G8=n(je,"LI",{});var ito=s(G8);dRe=n(ito,"STRONG",{});var d4a=s(dRe);eFt=r(d4a,"xglm"),d4a.forEach(t),oFt=r(ito," \u2014 "),Nie=n(ito,"A",{href:!0});var m4a=s(Nie);rFt=r(m4a,"FlaxXGLMForCausalLM"),m4a.forEach(t),tFt=r(ito," (XGLM model)"),ito.forEach(t),je.forEach(t),aFt=i(Zi),T(O8.$$.fragment,Zi),Zi.forEach(t),Yi.forEach(t),wso=i(c),gf=n(c,"H2",{class:!0});var Qio=s(gf);V8=n(Qio,"A",{id:!0,class:!0,href:!0});var c4a=s(V8);mRe=n(c4a,"SPAN",{});var f4a=s(mRe);T(fB.$$.fragment,f4a),f4a.forEach(t),c4a.forEach(t),nFt=i(Qio),cRe=n(Qio,"SPAN",{});var g4a=s(cRe);sFt=r(g4a,"FlaxAutoModelForPreTraining"),g4a.forEach(t),Qio.forEach(t),Aso=i(c),yr=n(c,"DIV",{class:!0});var Ki=s(yr);T(gB.$$.fragment,Ki),lFt=i(Ki),hf=n(Ki,"P",{});var Tfe=s(hf);iFt=r(Tfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),qie=n(Tfe,"A",{href:!0});var h4a=s(qie);dFt=r(h4a,"from_pretrained()"),h4a.forEach(t),mFt=r(Tfe," class method or the "),jie=n(Tfe,"A",{href:!0});var u4a=s(jie);cFt=r(u4a,"from_config()"),u4a.forEach(t),fFt=r(Tfe,` class
method.`),Tfe.forEach(t),gFt=i(Ki),hB=n(Ki,"P",{});var Wio=s(hB);hFt=r(Wio,"This class cannot be instantiated directly using "),fRe=n(Wio,"CODE",{});var p4a=s(fRe);uFt=r(p4a,"__init__()"),p4a.forEach(t),pFt=r(Wio," (throws an error)."),Wio.forEach(t),_Ft=i(Ki),ua=n(Ki,"DIV",{class:!0});var Kx=s(ua);T(uB.$$.fragment,Kx),bFt=i(Kx),gRe=n(Kx,"P",{});var _4a=s(gRe);vFt=r(_4a,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),_4a.forEach(t),FFt=i(Kx),uf=n(Kx,"P",{});var Mfe=s(uf);TFt=r(Mfe,`Note:
Loading a model from its configuration file does `),hRe=n(Mfe,"STRONG",{});var b4a=s(hRe);MFt=r(b4a,"not"),b4a.forEach(t),EFt=r(Mfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Die=n(Mfe,"A",{href:!0});var v4a=s(Die);CFt=r(v4a,"from_pretrained()"),v4a.forEach(t),wFt=r(Mfe," to load the model weights."),Mfe.forEach(t),AFt=i(Kx),T(X8.$$.fragment,Kx),Kx.forEach(t),LFt=i(Ki),at=n(Ki,"DIV",{class:!0});var ed=s(at);T(pB.$$.fragment,ed),yFt=i(ed),uRe=n(ed,"P",{});var F4a=s(uRe);xFt=r(F4a,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),F4a.forEach(t),$Ft=i(ed),Kn=n(ed,"P",{});var e$=s(Kn);kFt=r(e$,"The model class to instantiate is selected based on the "),pRe=n(e$,"CODE",{});var T4a=s(pRe);SFt=r(T4a,"model_type"),T4a.forEach(t),RFt=r(e$,` property of the config object (either
passed as an argument or loaded from `),_Re=n(e$,"CODE",{});var M4a=s(_Re);PFt=r(M4a,"pretrained_model_name_or_path"),M4a.forEach(t),BFt=r(e$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bRe=n(e$,"CODE",{});var E4a=s(bRe);IFt=r(E4a,"pretrained_model_name_or_path"),E4a.forEach(t),NFt=r(e$,":"),e$.forEach(t),qFt=i(ed),Ee=n(ed,"UL",{});var we=s(Ee);z8=n(we,"LI",{});var dto=s(z8);vRe=n(dto,"STRONG",{});var C4a=s(vRe);jFt=r(C4a,"albert"),C4a.forEach(t),DFt=r(dto," \u2014 "),Gie=n(dto,"A",{href:!0});var w4a=s(Gie);GFt=r(w4a,"FlaxAlbertForPreTraining"),w4a.forEach(t),OFt=r(dto," (ALBERT model)"),dto.forEach(t),VFt=i(we),Q8=n(we,"LI",{});var mto=s(Q8);FRe=n(mto,"STRONG",{});var A4a=s(FRe);XFt=r(A4a,"bart"),A4a.forEach(t),zFt=r(mto," \u2014 "),Oie=n(mto,"A",{href:!0});var L4a=s(Oie);QFt=r(L4a,"FlaxBartForConditionalGeneration"),L4a.forEach(t),WFt=r(mto," (BART model)"),mto.forEach(t),UFt=i(we),W8=n(we,"LI",{});var cto=s(W8);TRe=n(cto,"STRONG",{});var y4a=s(TRe);HFt=r(y4a,"bert"),y4a.forEach(t),JFt=r(cto," \u2014 "),Vie=n(cto,"A",{href:!0});var x4a=s(Vie);YFt=r(x4a,"FlaxBertForPreTraining"),x4a.forEach(t),ZFt=r(cto," (BERT model)"),cto.forEach(t),KFt=i(we),U8=n(we,"LI",{});var fto=s(U8);MRe=n(fto,"STRONG",{});var $4a=s(MRe);eTt=r($4a,"big_bird"),$4a.forEach(t),oTt=r(fto," \u2014 "),Xie=n(fto,"A",{href:!0});var k4a=s(Xie);rTt=r(k4a,"FlaxBigBirdForPreTraining"),k4a.forEach(t),tTt=r(fto," (BigBird model)"),fto.forEach(t),aTt=i(we),H8=n(we,"LI",{});var gto=s(H8);ERe=n(gto,"STRONG",{});var S4a=s(ERe);nTt=r(S4a,"electra"),S4a.forEach(t),sTt=r(gto," \u2014 "),zie=n(gto,"A",{href:!0});var R4a=s(zie);lTt=r(R4a,"FlaxElectraForPreTraining"),R4a.forEach(t),iTt=r(gto," (ELECTRA model)"),gto.forEach(t),dTt=i(we),J8=n(we,"LI",{});var hto=s(J8);CRe=n(hto,"STRONG",{});var P4a=s(CRe);mTt=r(P4a,"longt5"),P4a.forEach(t),cTt=r(hto," \u2014 "),Qie=n(hto,"A",{href:!0});var B4a=s(Qie);fTt=r(B4a,"FlaxLongT5ForConditionalGeneration"),B4a.forEach(t),gTt=r(hto," (LongT5 model)"),hto.forEach(t),hTt=i(we),Y8=n(we,"LI",{});var uto=s(Y8);wRe=n(uto,"STRONG",{});var I4a=s(wRe);uTt=r(I4a,"mbart"),I4a.forEach(t),pTt=r(uto," \u2014 "),Wie=n(uto,"A",{href:!0});var N4a=s(Wie);_Tt=r(N4a,"FlaxMBartForConditionalGeneration"),N4a.forEach(t),bTt=r(uto," (mBART model)"),uto.forEach(t),vTt=i(we),Z8=n(we,"LI",{});var pto=s(Z8);ARe=n(pto,"STRONG",{});var q4a=s(ARe);FTt=r(q4a,"mt5"),q4a.forEach(t),TTt=r(pto," \u2014 "),Uie=n(pto,"A",{href:!0});var j4a=s(Uie);MTt=r(j4a,"FlaxMT5ForConditionalGeneration"),j4a.forEach(t),ETt=r(pto," (MT5 model)"),pto.forEach(t),CTt=i(we),K8=n(we,"LI",{});var _to=s(K8);LRe=n(_to,"STRONG",{});var D4a=s(LRe);wTt=r(D4a,"roberta"),D4a.forEach(t),ATt=r(_to," \u2014 "),Hie=n(_to,"A",{href:!0});var G4a=s(Hie);LTt=r(G4a,"FlaxRobertaForMaskedLM"),G4a.forEach(t),yTt=r(_to," (RoBERTa model)"),_to.forEach(t),xTt=i(we),eL=n(we,"LI",{});var bto=s(eL);yRe=n(bto,"STRONG",{});var O4a=s(yRe);$Tt=r(O4a,"roformer"),O4a.forEach(t),kTt=r(bto," \u2014 "),Jie=n(bto,"A",{href:!0});var V4a=s(Jie);STt=r(V4a,"FlaxRoFormerForMaskedLM"),V4a.forEach(t),RTt=r(bto," (RoFormer model)"),bto.forEach(t),PTt=i(we),oL=n(we,"LI",{});var vto=s(oL);xRe=n(vto,"STRONG",{});var X4a=s(xRe);BTt=r(X4a,"t5"),X4a.forEach(t),ITt=r(vto," \u2014 "),Yie=n(vto,"A",{href:!0});var z4a=s(Yie);NTt=r(z4a,"FlaxT5ForConditionalGeneration"),z4a.forEach(t),qTt=r(vto," (T5 model)"),vto.forEach(t),jTt=i(we),rL=n(we,"LI",{});var Fto=s(rL);$Re=n(Fto,"STRONG",{});var Q4a=s($Re);DTt=r(Q4a,"wav2vec2"),Q4a.forEach(t),GTt=r(Fto," \u2014 "),Zie=n(Fto,"A",{href:!0});var W4a=s(Zie);OTt=r(W4a,"FlaxWav2Vec2ForPreTraining"),W4a.forEach(t),VTt=r(Fto," (Wav2Vec2 model)"),Fto.forEach(t),XTt=i(we),tL=n(we,"LI",{});var Tto=s(tL);kRe=n(Tto,"STRONG",{});var U4a=s(kRe);zTt=r(U4a,"xlm-roberta"),U4a.forEach(t),QTt=r(Tto," \u2014 "),Kie=n(Tto,"A",{href:!0});var H4a=s(Kie);WTt=r(H4a,"FlaxXLMRobertaForMaskedLM"),H4a.forEach(t),UTt=r(Tto," (XLM-RoBERTa model)"),Tto.forEach(t),we.forEach(t),HTt=i(ed),T(aL.$$.fragment,ed),ed.forEach(t),Ki.forEach(t),Lso=i(c),pf=n(c,"H2",{class:!0});var Uio=s(pf);nL=n(Uio,"A",{id:!0,class:!0,href:!0});var J4a=s(nL);SRe=n(J4a,"SPAN",{});var Y4a=s(SRe);T(_B.$$.fragment,Y4a),Y4a.forEach(t),J4a.forEach(t),JTt=i(Uio),RRe=n(Uio,"SPAN",{});var Z4a=s(RRe);YTt=r(Z4a,"FlaxAutoModelForMaskedLM"),Z4a.forEach(t),Uio.forEach(t),yso=i(c),xr=n(c,"DIV",{class:!0});var od=s(xr);T(bB.$$.fragment,od),ZTt=i(od),_f=n(od,"P",{});var Efe=s(_f);KTt=r(Efe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),ede=n(Efe,"A",{href:!0});var K4a=s(ede);eMt=r(K4a,"from_pretrained()"),K4a.forEach(t),oMt=r(Efe," class method or the "),ode=n(Efe,"A",{href:!0});var eCa=s(ode);rMt=r(eCa,"from_config()"),eCa.forEach(t),tMt=r(Efe,` class
method.`),Efe.forEach(t),aMt=i(od),vB=n(od,"P",{});var Hio=s(vB);nMt=r(Hio,"This class cannot be instantiated directly using "),PRe=n(Hio,"CODE",{});var oCa=s(PRe);sMt=r(oCa,"__init__()"),oCa.forEach(t),lMt=r(Hio," (throws an error)."),Hio.forEach(t),iMt=i(od),pa=n(od,"DIV",{class:!0});var o$=s(pa);T(FB.$$.fragment,o$),dMt=i(o$),BRe=n(o$,"P",{});var rCa=s(BRe);mMt=r(rCa,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),rCa.forEach(t),cMt=i(o$),bf=n(o$,"P",{});var Cfe=s(bf);fMt=r(Cfe,`Note:
Loading a model from its configuration file does `),IRe=n(Cfe,"STRONG",{});var tCa=s(IRe);gMt=r(tCa,"not"),tCa.forEach(t),hMt=r(Cfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),rde=n(Cfe,"A",{href:!0});var aCa=s(rde);uMt=r(aCa,"from_pretrained()"),aCa.forEach(t),pMt=r(Cfe," to load the model weights."),Cfe.forEach(t),_Mt=i(o$),T(sL.$$.fragment,o$),o$.forEach(t),bMt=i(od),nt=n(od,"DIV",{class:!0});var rd=s(nt);T(TB.$$.fragment,rd),vMt=i(rd),NRe=n(rd,"P",{});var nCa=s(NRe);FMt=r(nCa,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),nCa.forEach(t),TMt=i(rd),es=n(rd,"P",{});var r$=s(es);MMt=r(r$,"The model class to instantiate is selected based on the "),qRe=n(r$,"CODE",{});var sCa=s(qRe);EMt=r(sCa,"model_type"),sCa.forEach(t),CMt=r(r$,` property of the config object (either
passed as an argument or loaded from `),jRe=n(r$,"CODE",{});var lCa=s(jRe);wMt=r(lCa,"pretrained_model_name_or_path"),lCa.forEach(t),AMt=r(r$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),DRe=n(r$,"CODE",{});var iCa=s(DRe);LMt=r(iCa,"pretrained_model_name_or_path"),iCa.forEach(t),yMt=r(r$,":"),r$.forEach(t),xMt=i(rd),ke=n(rd,"UL",{});var De=s(ke);lL=n(De,"LI",{});var Mto=s(lL);GRe=n(Mto,"STRONG",{});var dCa=s(GRe);$Mt=r(dCa,"albert"),dCa.forEach(t),kMt=r(Mto," \u2014 "),tde=n(Mto,"A",{href:!0});var mCa=s(tde);SMt=r(mCa,"FlaxAlbertForMaskedLM"),mCa.forEach(t),RMt=r(Mto," (ALBERT model)"),Mto.forEach(t),PMt=i(De),iL=n(De,"LI",{});var Eto=s(iL);ORe=n(Eto,"STRONG",{});var cCa=s(ORe);BMt=r(cCa,"bart"),cCa.forEach(t),IMt=r(Eto," \u2014 "),ade=n(Eto,"A",{href:!0});var fCa=s(ade);NMt=r(fCa,"FlaxBartForConditionalGeneration"),fCa.forEach(t),qMt=r(Eto," (BART model)"),Eto.forEach(t),jMt=i(De),dL=n(De,"LI",{});var Cto=s(dL);VRe=n(Cto,"STRONG",{});var gCa=s(VRe);DMt=r(gCa,"bert"),gCa.forEach(t),GMt=r(Cto," \u2014 "),nde=n(Cto,"A",{href:!0});var hCa=s(nde);OMt=r(hCa,"FlaxBertForMaskedLM"),hCa.forEach(t),VMt=r(Cto," (BERT model)"),Cto.forEach(t),XMt=i(De),mL=n(De,"LI",{});var wto=s(mL);XRe=n(wto,"STRONG",{});var uCa=s(XRe);zMt=r(uCa,"big_bird"),uCa.forEach(t),QMt=r(wto," \u2014 "),sde=n(wto,"A",{href:!0});var pCa=s(sde);WMt=r(pCa,"FlaxBigBirdForMaskedLM"),pCa.forEach(t),UMt=r(wto," (BigBird model)"),wto.forEach(t),HMt=i(De),cL=n(De,"LI",{});var Ato=s(cL);zRe=n(Ato,"STRONG",{});var _Ca=s(zRe);JMt=r(_Ca,"distilbert"),_Ca.forEach(t),YMt=r(Ato," \u2014 "),lde=n(Ato,"A",{href:!0});var bCa=s(lde);ZMt=r(bCa,"FlaxDistilBertForMaskedLM"),bCa.forEach(t),KMt=r(Ato," (DistilBERT model)"),Ato.forEach(t),eEt=i(De),fL=n(De,"LI",{});var Lto=s(fL);QRe=n(Lto,"STRONG",{});var vCa=s(QRe);oEt=r(vCa,"electra"),vCa.forEach(t),rEt=r(Lto," \u2014 "),ide=n(Lto,"A",{href:!0});var FCa=s(ide);tEt=r(FCa,"FlaxElectraForMaskedLM"),FCa.forEach(t),aEt=r(Lto," (ELECTRA model)"),Lto.forEach(t),nEt=i(De),gL=n(De,"LI",{});var yto=s(gL);WRe=n(yto,"STRONG",{});var TCa=s(WRe);sEt=r(TCa,"mbart"),TCa.forEach(t),lEt=r(yto," \u2014 "),dde=n(yto,"A",{href:!0});var MCa=s(dde);iEt=r(MCa,"FlaxMBartForConditionalGeneration"),MCa.forEach(t),dEt=r(yto," (mBART model)"),yto.forEach(t),mEt=i(De),hL=n(De,"LI",{});var xto=s(hL);URe=n(xto,"STRONG",{});var ECa=s(URe);cEt=r(ECa,"roberta"),ECa.forEach(t),fEt=r(xto," \u2014 "),mde=n(xto,"A",{href:!0});var CCa=s(mde);gEt=r(CCa,"FlaxRobertaForMaskedLM"),CCa.forEach(t),hEt=r(xto," (RoBERTa model)"),xto.forEach(t),uEt=i(De),uL=n(De,"LI",{});var $to=s(uL);HRe=n($to,"STRONG",{});var wCa=s(HRe);pEt=r(wCa,"roformer"),wCa.forEach(t),_Et=r($to," \u2014 "),cde=n($to,"A",{href:!0});var ACa=s(cde);bEt=r(ACa,"FlaxRoFormerForMaskedLM"),ACa.forEach(t),vEt=r($to," (RoFormer model)"),$to.forEach(t),FEt=i(De),pL=n(De,"LI",{});var kto=s(pL);JRe=n(kto,"STRONG",{});var LCa=s(JRe);TEt=r(LCa,"xlm-roberta"),LCa.forEach(t),MEt=r(kto," \u2014 "),fde=n(kto,"A",{href:!0});var yCa=s(fde);EEt=r(yCa,"FlaxXLMRobertaForMaskedLM"),yCa.forEach(t),CEt=r(kto," (XLM-RoBERTa model)"),kto.forEach(t),De.forEach(t),wEt=i(rd),T(_L.$$.fragment,rd),rd.forEach(t),od.forEach(t),xso=i(c),vf=n(c,"H2",{class:!0});var Jio=s(vf);bL=n(Jio,"A",{id:!0,class:!0,href:!0});var xCa=s(bL);YRe=n(xCa,"SPAN",{});var $Ca=s(YRe);T(MB.$$.fragment,$Ca),$Ca.forEach(t),xCa.forEach(t),AEt=i(Jio),ZRe=n(Jio,"SPAN",{});var kCa=s(ZRe);LEt=r(kCa,"FlaxAutoModelForSeq2SeqLM"),kCa.forEach(t),Jio.forEach(t),$so=i(c),$r=n(c,"DIV",{class:!0});var td=s($r);T(EB.$$.fragment,td),yEt=i(td),Ff=n(td,"P",{});var wfe=s(Ff);xEt=r(wfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),gde=n(wfe,"A",{href:!0});var SCa=s(gde);$Et=r(SCa,"from_pretrained()"),SCa.forEach(t),kEt=r(wfe," class method or the "),hde=n(wfe,"A",{href:!0});var RCa=s(hde);SEt=r(RCa,"from_config()"),RCa.forEach(t),REt=r(wfe,` class
method.`),wfe.forEach(t),PEt=i(td),CB=n(td,"P",{});var Yio=s(CB);BEt=r(Yio,"This class cannot be instantiated directly using "),KRe=n(Yio,"CODE",{});var PCa=s(KRe);IEt=r(PCa,"__init__()"),PCa.forEach(t),NEt=r(Yio," (throws an error)."),Yio.forEach(t),qEt=i(td),_a=n(td,"DIV",{class:!0});var t$=s(_a);T(wB.$$.fragment,t$),jEt=i(t$),ePe=n(t$,"P",{});var BCa=s(ePe);DEt=r(BCa,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),BCa.forEach(t),GEt=i(t$),Tf=n(t$,"P",{});var Afe=s(Tf);OEt=r(Afe,`Note:
Loading a model from its configuration file does `),oPe=n(Afe,"STRONG",{});var ICa=s(oPe);VEt=r(ICa,"not"),ICa.forEach(t),XEt=r(Afe,` load the model weights. It only affects the
model\u2019s configuration. Use `),ude=n(Afe,"A",{href:!0});var NCa=s(ude);zEt=r(NCa,"from_pretrained()"),NCa.forEach(t),QEt=r(Afe," to load the model weights."),Afe.forEach(t),WEt=i(t$),T(vL.$$.fragment,t$),t$.forEach(t),UEt=i(td),st=n(td,"DIV",{class:!0});var ad=s(st);T(AB.$$.fragment,ad),HEt=i(ad),rPe=n(ad,"P",{});var qCa=s(rPe);JEt=r(qCa,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),qCa.forEach(t),YEt=i(ad),os=n(ad,"P",{});var a$=s(os);ZEt=r(a$,"The model class to instantiate is selected based on the "),tPe=n(a$,"CODE",{});var jCa=s(tPe);KEt=r(jCa,"model_type"),jCa.forEach(t),e4t=r(a$,` property of the config object (either
passed as an argument or loaded from `),aPe=n(a$,"CODE",{});var DCa=s(aPe);o4t=r(DCa,"pretrained_model_name_or_path"),DCa.forEach(t),r4t=r(a$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nPe=n(a$,"CODE",{});var GCa=s(nPe);t4t=r(GCa,"pretrained_model_name_or_path"),GCa.forEach(t),a4t=r(a$,":"),a$.forEach(t),n4t=i(ad),Se=n(ad,"UL",{});var Ge=s(Se);FL=n(Ge,"LI",{});var Sto=s(FL);sPe=n(Sto,"STRONG",{});var OCa=s(sPe);s4t=r(OCa,"bart"),OCa.forEach(t),l4t=r(Sto," \u2014 "),pde=n(Sto,"A",{href:!0});var VCa=s(pde);i4t=r(VCa,"FlaxBartForConditionalGeneration"),VCa.forEach(t),d4t=r(Sto," (BART model)"),Sto.forEach(t),m4t=i(Ge),TL=n(Ge,"LI",{});var Rto=s(TL);lPe=n(Rto,"STRONG",{});var XCa=s(lPe);c4t=r(XCa,"blenderbot"),XCa.forEach(t),f4t=r(Rto," \u2014 "),_de=n(Rto,"A",{href:!0});var zCa=s(_de);g4t=r(zCa,"FlaxBlenderbotForConditionalGeneration"),zCa.forEach(t),h4t=r(Rto," (Blenderbot model)"),Rto.forEach(t),u4t=i(Ge),ML=n(Ge,"LI",{});var Pto=s(ML);iPe=n(Pto,"STRONG",{});var QCa=s(iPe);p4t=r(QCa,"blenderbot-small"),QCa.forEach(t),_4t=r(Pto," \u2014 "),bde=n(Pto,"A",{href:!0});var WCa=s(bde);b4t=r(WCa,"FlaxBlenderbotSmallForConditionalGeneration"),WCa.forEach(t),v4t=r(Pto," (BlenderbotSmall model)"),Pto.forEach(t),F4t=i(Ge),EL=n(Ge,"LI",{});var Bto=s(EL);dPe=n(Bto,"STRONG",{});var UCa=s(dPe);T4t=r(UCa,"encoder-decoder"),UCa.forEach(t),M4t=r(Bto," \u2014 "),vde=n(Bto,"A",{href:!0});var HCa=s(vde);E4t=r(HCa,"FlaxEncoderDecoderModel"),HCa.forEach(t),C4t=r(Bto," (Encoder decoder model)"),Bto.forEach(t),w4t=i(Ge),CL=n(Ge,"LI",{});var Ito=s(CL);mPe=n(Ito,"STRONG",{});var JCa=s(mPe);A4t=r(JCa,"longt5"),JCa.forEach(t),L4t=r(Ito," \u2014 "),Fde=n(Ito,"A",{href:!0});var YCa=s(Fde);y4t=r(YCa,"FlaxLongT5ForConditionalGeneration"),YCa.forEach(t),x4t=r(Ito," (LongT5 model)"),Ito.forEach(t),$4t=i(Ge),wL=n(Ge,"LI",{});var Nto=s(wL);cPe=n(Nto,"STRONG",{});var ZCa=s(cPe);k4t=r(ZCa,"marian"),ZCa.forEach(t),S4t=r(Nto," \u2014 "),Tde=n(Nto,"A",{href:!0});var KCa=s(Tde);R4t=r(KCa,"FlaxMarianMTModel"),KCa.forEach(t),P4t=r(Nto," (Marian model)"),Nto.forEach(t),B4t=i(Ge),AL=n(Ge,"LI",{});var qto=s(AL);fPe=n(qto,"STRONG",{});var e3a=s(fPe);I4t=r(e3a,"mbart"),e3a.forEach(t),N4t=r(qto," \u2014 "),Mde=n(qto,"A",{href:!0});var o3a=s(Mde);q4t=r(o3a,"FlaxMBartForConditionalGeneration"),o3a.forEach(t),j4t=r(qto," (mBART model)"),qto.forEach(t),D4t=i(Ge),LL=n(Ge,"LI",{});var jto=s(LL);gPe=n(jto,"STRONG",{});var r3a=s(gPe);G4t=r(r3a,"mt5"),r3a.forEach(t),O4t=r(jto," \u2014 "),Ede=n(jto,"A",{href:!0});var t3a=s(Ede);V4t=r(t3a,"FlaxMT5ForConditionalGeneration"),t3a.forEach(t),X4t=r(jto," (MT5 model)"),jto.forEach(t),z4t=i(Ge),yL=n(Ge,"LI",{});var Dto=s(yL);hPe=n(Dto,"STRONG",{});var a3a=s(hPe);Q4t=r(a3a,"pegasus"),a3a.forEach(t),W4t=r(Dto," \u2014 "),Cde=n(Dto,"A",{href:!0});var n3a=s(Cde);U4t=r(n3a,"FlaxPegasusForConditionalGeneration"),n3a.forEach(t),H4t=r(Dto," (Pegasus model)"),Dto.forEach(t),J4t=i(Ge),xL=n(Ge,"LI",{});var Gto=s(xL);uPe=n(Gto,"STRONG",{});var s3a=s(uPe);Y4t=r(s3a,"t5"),s3a.forEach(t),Z4t=r(Gto," \u2014 "),wde=n(Gto,"A",{href:!0});var l3a=s(wde);K4t=r(l3a,"FlaxT5ForConditionalGeneration"),l3a.forEach(t),eCt=r(Gto," (T5 model)"),Gto.forEach(t),Ge.forEach(t),oCt=i(ad),T($L.$$.fragment,ad),ad.forEach(t),td.forEach(t),kso=i(c),Mf=n(c,"H2",{class:!0});var Zio=s(Mf);kL=n(Zio,"A",{id:!0,class:!0,href:!0});var i3a=s(kL);pPe=n(i3a,"SPAN",{});var d3a=s(pPe);T(LB.$$.fragment,d3a),d3a.forEach(t),i3a.forEach(t),rCt=i(Zio),_Pe=n(Zio,"SPAN",{});var m3a=s(_Pe);tCt=r(m3a,"FlaxAutoModelForSequenceClassification"),m3a.forEach(t),Zio.forEach(t),Sso=i(c),kr=n(c,"DIV",{class:!0});var nd=s(kr);T(yB.$$.fragment,nd),aCt=i(nd),Ef=n(nd,"P",{});var Lfe=s(Ef);nCt=r(Lfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Ade=n(Lfe,"A",{href:!0});var c3a=s(Ade);sCt=r(c3a,"from_pretrained()"),c3a.forEach(t),lCt=r(Lfe," class method or the "),Lde=n(Lfe,"A",{href:!0});var f3a=s(Lde);iCt=r(f3a,"from_config()"),f3a.forEach(t),dCt=r(Lfe,` class
method.`),Lfe.forEach(t),mCt=i(nd),xB=n(nd,"P",{});var Kio=s(xB);cCt=r(Kio,"This class cannot be instantiated directly using "),bPe=n(Kio,"CODE",{});var g3a=s(bPe);fCt=r(g3a,"__init__()"),g3a.forEach(t),gCt=r(Kio," (throws an error)."),Kio.forEach(t),hCt=i(nd),ba=n(nd,"DIV",{class:!0});var n$=s(ba);T($B.$$.fragment,n$),uCt=i(n$),vPe=n(n$,"P",{});var h3a=s(vPe);pCt=r(h3a,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),h3a.forEach(t),_Ct=i(n$),Cf=n(n$,"P",{});var yfe=s(Cf);bCt=r(yfe,`Note:
Loading a model from its configuration file does `),FPe=n(yfe,"STRONG",{});var u3a=s(FPe);vCt=r(u3a,"not"),u3a.forEach(t),FCt=r(yfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),yde=n(yfe,"A",{href:!0});var p3a=s(yde);TCt=r(p3a,"from_pretrained()"),p3a.forEach(t),MCt=r(yfe," to load the model weights."),yfe.forEach(t),ECt=i(n$),T(SL.$$.fragment,n$),n$.forEach(t),CCt=i(nd),lt=n(nd,"DIV",{class:!0});var sd=s(lt);T(kB.$$.fragment,sd),wCt=i(sd),TPe=n(sd,"P",{});var _3a=s(TPe);ACt=r(_3a,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),_3a.forEach(t),LCt=i(sd),rs=n(sd,"P",{});var s$=s(rs);yCt=r(s$,"The model class to instantiate is selected based on the "),MPe=n(s$,"CODE",{});var b3a=s(MPe);xCt=r(b3a,"model_type"),b3a.forEach(t),$Ct=r(s$,` property of the config object (either
passed as an argument or loaded from `),EPe=n(s$,"CODE",{});var v3a=s(EPe);kCt=r(v3a,"pretrained_model_name_or_path"),v3a.forEach(t),SCt=r(s$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),CPe=n(s$,"CODE",{});var F3a=s(CPe);RCt=r(F3a,"pretrained_model_name_or_path"),F3a.forEach(t),PCt=r(s$,":"),s$.forEach(t),BCt=i(sd),Re=n(sd,"UL",{});var Oe=s(Re);RL=n(Oe,"LI",{});var Oto=s(RL);wPe=n(Oto,"STRONG",{});var T3a=s(wPe);ICt=r(T3a,"albert"),T3a.forEach(t),NCt=r(Oto," \u2014 "),xde=n(Oto,"A",{href:!0});var M3a=s(xde);qCt=r(M3a,"FlaxAlbertForSequenceClassification"),M3a.forEach(t),jCt=r(Oto," (ALBERT model)"),Oto.forEach(t),DCt=i(Oe),PL=n(Oe,"LI",{});var Vto=s(PL);APe=n(Vto,"STRONG",{});var E3a=s(APe);GCt=r(E3a,"bart"),E3a.forEach(t),OCt=r(Vto," \u2014 "),$de=n(Vto,"A",{href:!0});var C3a=s($de);VCt=r(C3a,"FlaxBartForSequenceClassification"),C3a.forEach(t),XCt=r(Vto," (BART model)"),Vto.forEach(t),zCt=i(Oe),BL=n(Oe,"LI",{});var Xto=s(BL);LPe=n(Xto,"STRONG",{});var w3a=s(LPe);QCt=r(w3a,"bert"),w3a.forEach(t),WCt=r(Xto," \u2014 "),kde=n(Xto,"A",{href:!0});var A3a=s(kde);UCt=r(A3a,"FlaxBertForSequenceClassification"),A3a.forEach(t),HCt=r(Xto," (BERT model)"),Xto.forEach(t),JCt=i(Oe),IL=n(Oe,"LI",{});var zto=s(IL);yPe=n(zto,"STRONG",{});var L3a=s(yPe);YCt=r(L3a,"big_bird"),L3a.forEach(t),ZCt=r(zto," \u2014 "),Sde=n(zto,"A",{href:!0});var y3a=s(Sde);KCt=r(y3a,"FlaxBigBirdForSequenceClassification"),y3a.forEach(t),e3t=r(zto," (BigBird model)"),zto.forEach(t),o3t=i(Oe),NL=n(Oe,"LI",{});var Qto=s(NL);xPe=n(Qto,"STRONG",{});var x3a=s(xPe);r3t=r(x3a,"distilbert"),x3a.forEach(t),t3t=r(Qto," \u2014 "),Rde=n(Qto,"A",{href:!0});var $3a=s(Rde);a3t=r($3a,"FlaxDistilBertForSequenceClassification"),$3a.forEach(t),n3t=r(Qto," (DistilBERT model)"),Qto.forEach(t),s3t=i(Oe),qL=n(Oe,"LI",{});var Wto=s(qL);$Pe=n(Wto,"STRONG",{});var k3a=s($Pe);l3t=r(k3a,"electra"),k3a.forEach(t),i3t=r(Wto," \u2014 "),Pde=n(Wto,"A",{href:!0});var S3a=s(Pde);d3t=r(S3a,"FlaxElectraForSequenceClassification"),S3a.forEach(t),m3t=r(Wto," (ELECTRA model)"),Wto.forEach(t),c3t=i(Oe),jL=n(Oe,"LI",{});var Uto=s(jL);kPe=n(Uto,"STRONG",{});var R3a=s(kPe);f3t=r(R3a,"mbart"),R3a.forEach(t),g3t=r(Uto," \u2014 "),Bde=n(Uto,"A",{href:!0});var P3a=s(Bde);h3t=r(P3a,"FlaxMBartForSequenceClassification"),P3a.forEach(t),u3t=r(Uto," (mBART model)"),Uto.forEach(t),p3t=i(Oe),DL=n(Oe,"LI",{});var Hto=s(DL);SPe=n(Hto,"STRONG",{});var B3a=s(SPe);_3t=r(B3a,"roberta"),B3a.forEach(t),b3t=r(Hto," \u2014 "),Ide=n(Hto,"A",{href:!0});var I3a=s(Ide);v3t=r(I3a,"FlaxRobertaForSequenceClassification"),I3a.forEach(t),F3t=r(Hto," (RoBERTa model)"),Hto.forEach(t),T3t=i(Oe),GL=n(Oe,"LI",{});var Jto=s(GL);RPe=n(Jto,"STRONG",{});var N3a=s(RPe);M3t=r(N3a,"roformer"),N3a.forEach(t),E3t=r(Jto," \u2014 "),Nde=n(Jto,"A",{href:!0});var q3a=s(Nde);C3t=r(q3a,"FlaxRoFormerForSequenceClassification"),q3a.forEach(t),w3t=r(Jto," (RoFormer model)"),Jto.forEach(t),A3t=i(Oe),OL=n(Oe,"LI",{});var Yto=s(OL);PPe=n(Yto,"STRONG",{});var j3a=s(PPe);L3t=r(j3a,"xlm-roberta"),j3a.forEach(t),y3t=r(Yto," \u2014 "),qde=n(Yto,"A",{href:!0});var D3a=s(qde);x3t=r(D3a,"FlaxXLMRobertaForSequenceClassification"),D3a.forEach(t),$3t=r(Yto," (XLM-RoBERTa model)"),Yto.forEach(t),Oe.forEach(t),k3t=i(sd),T(VL.$$.fragment,sd),sd.forEach(t),nd.forEach(t),Rso=i(c),wf=n(c,"H2",{class:!0});var edo=s(wf);XL=n(edo,"A",{id:!0,class:!0,href:!0});var G3a=s(XL);BPe=n(G3a,"SPAN",{});var O3a=s(BPe);T(SB.$$.fragment,O3a),O3a.forEach(t),G3a.forEach(t),S3t=i(edo),IPe=n(edo,"SPAN",{});var V3a=s(IPe);R3t=r(V3a,"FlaxAutoModelForQuestionAnswering"),V3a.forEach(t),edo.forEach(t),Pso=i(c),Sr=n(c,"DIV",{class:!0});var ld=s(Sr);T(RB.$$.fragment,ld),P3t=i(ld),Af=n(ld,"P",{});var xfe=s(Af);B3t=r(xfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),jde=n(xfe,"A",{href:!0});var X3a=s(jde);I3t=r(X3a,"from_pretrained()"),X3a.forEach(t),N3t=r(xfe," class method or the "),Dde=n(xfe,"A",{href:!0});var z3a=s(Dde);q3t=r(z3a,"from_config()"),z3a.forEach(t),j3t=r(xfe,` class
method.`),xfe.forEach(t),D3t=i(ld),PB=n(ld,"P",{});var odo=s(PB);G3t=r(odo,"This class cannot be instantiated directly using "),NPe=n(odo,"CODE",{});var Q3a=s(NPe);O3t=r(Q3a,"__init__()"),Q3a.forEach(t),V3t=r(odo," (throws an error)."),odo.forEach(t),X3t=i(ld),va=n(ld,"DIV",{class:!0});var l$=s(va);T(BB.$$.fragment,l$),z3t=i(l$),qPe=n(l$,"P",{});var W3a=s(qPe);Q3t=r(W3a,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),W3a.forEach(t),W3t=i(l$),Lf=n(l$,"P",{});var $fe=s(Lf);U3t=r($fe,`Note:
Loading a model from its configuration file does `),jPe=n($fe,"STRONG",{});var U3a=s(jPe);H3t=r(U3a,"not"),U3a.forEach(t),J3t=r($fe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Gde=n($fe,"A",{href:!0});var H3a=s(Gde);Y3t=r(H3a,"from_pretrained()"),H3a.forEach(t),Z3t=r($fe," to load the model weights."),$fe.forEach(t),K3t=i(l$),T(zL.$$.fragment,l$),l$.forEach(t),e5t=i(ld),it=n(ld,"DIV",{class:!0});var id=s(it);T(IB.$$.fragment,id),o5t=i(id),DPe=n(id,"P",{});var J3a=s(DPe);r5t=r(J3a,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),J3a.forEach(t),t5t=i(id),ts=n(id,"P",{});var i$=s(ts);a5t=r(i$,"The model class to instantiate is selected based on the "),GPe=n(i$,"CODE",{});var Y3a=s(GPe);n5t=r(Y3a,"model_type"),Y3a.forEach(t),s5t=r(i$,` property of the config object (either
passed as an argument or loaded from `),OPe=n(i$,"CODE",{});var Z3a=s(OPe);l5t=r(Z3a,"pretrained_model_name_or_path"),Z3a.forEach(t),i5t=r(i$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),VPe=n(i$,"CODE",{});var K3a=s(VPe);d5t=r(K3a,"pretrained_model_name_or_path"),K3a.forEach(t),m5t=r(i$,":"),i$.forEach(t),c5t=i(id),Pe=n(id,"UL",{});var Ve=s(Pe);QL=n(Ve,"LI",{});var Zto=s(QL);XPe=n(Zto,"STRONG",{});var e5a=s(XPe);f5t=r(e5a,"albert"),e5a.forEach(t),g5t=r(Zto," \u2014 "),Ode=n(Zto,"A",{href:!0});var o5a=s(Ode);h5t=r(o5a,"FlaxAlbertForQuestionAnswering"),o5a.forEach(t),u5t=r(Zto," (ALBERT model)"),Zto.forEach(t),p5t=i(Ve),WL=n(Ve,"LI",{});var Kto=s(WL);zPe=n(Kto,"STRONG",{});var r5a=s(zPe);_5t=r(r5a,"bart"),r5a.forEach(t),b5t=r(Kto," \u2014 "),Vde=n(Kto,"A",{href:!0});var t5a=s(Vde);v5t=r(t5a,"FlaxBartForQuestionAnswering"),t5a.forEach(t),F5t=r(Kto," (BART model)"),Kto.forEach(t),T5t=i(Ve),UL=n(Ve,"LI",{});var eao=s(UL);QPe=n(eao,"STRONG",{});var a5a=s(QPe);M5t=r(a5a,"bert"),a5a.forEach(t),E5t=r(eao," \u2014 "),Xde=n(eao,"A",{href:!0});var n5a=s(Xde);C5t=r(n5a,"FlaxBertForQuestionAnswering"),n5a.forEach(t),w5t=r(eao," (BERT model)"),eao.forEach(t),A5t=i(Ve),HL=n(Ve,"LI",{});var oao=s(HL);WPe=n(oao,"STRONG",{});var s5a=s(WPe);L5t=r(s5a,"big_bird"),s5a.forEach(t),y5t=r(oao," \u2014 "),zde=n(oao,"A",{href:!0});var l5a=s(zde);x5t=r(l5a,"FlaxBigBirdForQuestionAnswering"),l5a.forEach(t),$5t=r(oao," (BigBird model)"),oao.forEach(t),k5t=i(Ve),JL=n(Ve,"LI",{});var rao=s(JL);UPe=n(rao,"STRONG",{});var i5a=s(UPe);S5t=r(i5a,"distilbert"),i5a.forEach(t),R5t=r(rao," \u2014 "),Qde=n(rao,"A",{href:!0});var d5a=s(Qde);P5t=r(d5a,"FlaxDistilBertForQuestionAnswering"),d5a.forEach(t),B5t=r(rao," (DistilBERT model)"),rao.forEach(t),I5t=i(Ve),YL=n(Ve,"LI",{});var tao=s(YL);HPe=n(tao,"STRONG",{});var m5a=s(HPe);N5t=r(m5a,"electra"),m5a.forEach(t),q5t=r(tao," \u2014 "),Wde=n(tao,"A",{href:!0});var c5a=s(Wde);j5t=r(c5a,"FlaxElectraForQuestionAnswering"),c5a.forEach(t),D5t=r(tao," (ELECTRA model)"),tao.forEach(t),G5t=i(Ve),ZL=n(Ve,"LI",{});var aao=s(ZL);JPe=n(aao,"STRONG",{});var f5a=s(JPe);O5t=r(f5a,"mbart"),f5a.forEach(t),V5t=r(aao," \u2014 "),Ude=n(aao,"A",{href:!0});var g5a=s(Ude);X5t=r(g5a,"FlaxMBartForQuestionAnswering"),g5a.forEach(t),z5t=r(aao," (mBART model)"),aao.forEach(t),Q5t=i(Ve),KL=n(Ve,"LI",{});var nao=s(KL);YPe=n(nao,"STRONG",{});var h5a=s(YPe);W5t=r(h5a,"roberta"),h5a.forEach(t),U5t=r(nao," \u2014 "),Hde=n(nao,"A",{href:!0});var u5a=s(Hde);H5t=r(u5a,"FlaxRobertaForQuestionAnswering"),u5a.forEach(t),J5t=r(nao," (RoBERTa model)"),nao.forEach(t),Y5t=i(Ve),ey=n(Ve,"LI",{});var sao=s(ey);ZPe=n(sao,"STRONG",{});var p5a=s(ZPe);Z5t=r(p5a,"roformer"),p5a.forEach(t),K5t=r(sao," \u2014 "),Jde=n(sao,"A",{href:!0});var _5a=s(Jde);e0t=r(_5a,"FlaxRoFormerForQuestionAnswering"),_5a.forEach(t),o0t=r(sao," (RoFormer model)"),sao.forEach(t),r0t=i(Ve),oy=n(Ve,"LI",{});var lao=s(oy);KPe=n(lao,"STRONG",{});var b5a=s(KPe);t0t=r(b5a,"xlm-roberta"),b5a.forEach(t),a0t=r(lao," \u2014 "),Yde=n(lao,"A",{href:!0});var v5a=s(Yde);n0t=r(v5a,"FlaxXLMRobertaForQuestionAnswering"),v5a.forEach(t),s0t=r(lao," (XLM-RoBERTa model)"),lao.forEach(t),Ve.forEach(t),l0t=i(id),T(ry.$$.fragment,id),id.forEach(t),ld.forEach(t),Bso=i(c),yf=n(c,"H2",{class:!0});var rdo=s(yf);ty=n(rdo,"A",{id:!0,class:!0,href:!0});var F5a=s(ty);eBe=n(F5a,"SPAN",{});var T5a=s(eBe);T(NB.$$.fragment,T5a),T5a.forEach(t),F5a.forEach(t),i0t=i(rdo),oBe=n(rdo,"SPAN",{});var M5a=s(oBe);d0t=r(M5a,"FlaxAutoModelForTokenClassification"),M5a.forEach(t),rdo.forEach(t),Iso=i(c),Rr=n(c,"DIV",{class:!0});var dd=s(Rr);T(qB.$$.fragment,dd),m0t=i(dd),xf=n(dd,"P",{});var kfe=s(xf);c0t=r(kfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Zde=n(kfe,"A",{href:!0});var E5a=s(Zde);f0t=r(E5a,"from_pretrained()"),E5a.forEach(t),g0t=r(kfe," class method or the "),Kde=n(kfe,"A",{href:!0});var C5a=s(Kde);h0t=r(C5a,"from_config()"),C5a.forEach(t),u0t=r(kfe,` class
method.`),kfe.forEach(t),p0t=i(dd),jB=n(dd,"P",{});var tdo=s(jB);_0t=r(tdo,"This class cannot be instantiated directly using "),rBe=n(tdo,"CODE",{});var w5a=s(rBe);b0t=r(w5a,"__init__()"),w5a.forEach(t),v0t=r(tdo," (throws an error)."),tdo.forEach(t),F0t=i(dd),Fa=n(dd,"DIV",{class:!0});var d$=s(Fa);T(DB.$$.fragment,d$),T0t=i(d$),tBe=n(d$,"P",{});var A5a=s(tBe);M0t=r(A5a,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),A5a.forEach(t),E0t=i(d$),$f=n(d$,"P",{});var Sfe=s($f);C0t=r(Sfe,`Note:
Loading a model from its configuration file does `),aBe=n(Sfe,"STRONG",{});var L5a=s(aBe);w0t=r(L5a,"not"),L5a.forEach(t),A0t=r(Sfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),eme=n(Sfe,"A",{href:!0});var y5a=s(eme);L0t=r(y5a,"from_pretrained()"),y5a.forEach(t),y0t=r(Sfe," to load the model weights."),Sfe.forEach(t),x0t=i(d$),T(ay.$$.fragment,d$),d$.forEach(t),$0t=i(dd),dt=n(dd,"DIV",{class:!0});var md=s(dt);T(GB.$$.fragment,md),k0t=i(md),nBe=n(md,"P",{});var x5a=s(nBe);S0t=r(x5a,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),x5a.forEach(t),R0t=i(md),as=n(md,"P",{});var m$=s(as);P0t=r(m$,"The model class to instantiate is selected based on the "),sBe=n(m$,"CODE",{});var $5a=s(sBe);B0t=r($5a,"model_type"),$5a.forEach(t),I0t=r(m$,` property of the config object (either
passed as an argument or loaded from `),lBe=n(m$,"CODE",{});var k5a=s(lBe);N0t=r(k5a,"pretrained_model_name_or_path"),k5a.forEach(t),q0t=r(m$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iBe=n(m$,"CODE",{});var S5a=s(iBe);j0t=r(S5a,"pretrained_model_name_or_path"),S5a.forEach(t),D0t=r(m$,":"),m$.forEach(t),G0t=i(md),ze=n(md,"UL",{});var yo=s(ze);ny=n(yo,"LI",{});var iao=s(ny);dBe=n(iao,"STRONG",{});var R5a=s(dBe);O0t=r(R5a,"albert"),R5a.forEach(t),V0t=r(iao," \u2014 "),ome=n(iao,"A",{href:!0});var P5a=s(ome);X0t=r(P5a,"FlaxAlbertForTokenClassification"),P5a.forEach(t),z0t=r(iao," (ALBERT model)"),iao.forEach(t),Q0t=i(yo),sy=n(yo,"LI",{});var dao=s(sy);mBe=n(dao,"STRONG",{});var B5a=s(mBe);W0t=r(B5a,"bert"),B5a.forEach(t),U0t=r(dao," \u2014 "),rme=n(dao,"A",{href:!0});var I5a=s(rme);H0t=r(I5a,"FlaxBertForTokenClassification"),I5a.forEach(t),J0t=r(dao," (BERT model)"),dao.forEach(t),Y0t=i(yo),ly=n(yo,"LI",{});var mao=s(ly);cBe=n(mao,"STRONG",{});var N5a=s(cBe);Z0t=r(N5a,"big_bird"),N5a.forEach(t),K0t=r(mao," \u2014 "),tme=n(mao,"A",{href:!0});var q5a=s(tme);ewt=r(q5a,"FlaxBigBirdForTokenClassification"),q5a.forEach(t),owt=r(mao," (BigBird model)"),mao.forEach(t),rwt=i(yo),iy=n(yo,"LI",{});var cao=s(iy);fBe=n(cao,"STRONG",{});var j5a=s(fBe);twt=r(j5a,"distilbert"),j5a.forEach(t),awt=r(cao," \u2014 "),ame=n(cao,"A",{href:!0});var D5a=s(ame);nwt=r(D5a,"FlaxDistilBertForTokenClassification"),D5a.forEach(t),swt=r(cao," (DistilBERT model)"),cao.forEach(t),lwt=i(yo),dy=n(yo,"LI",{});var fao=s(dy);gBe=n(fao,"STRONG",{});var G5a=s(gBe);iwt=r(G5a,"electra"),G5a.forEach(t),dwt=r(fao," \u2014 "),nme=n(fao,"A",{href:!0});var O5a=s(nme);mwt=r(O5a,"FlaxElectraForTokenClassification"),O5a.forEach(t),cwt=r(fao," (ELECTRA model)"),fao.forEach(t),fwt=i(yo),my=n(yo,"LI",{});var gao=s(my);hBe=n(gao,"STRONG",{});var V5a=s(hBe);gwt=r(V5a,"roberta"),V5a.forEach(t),hwt=r(gao," \u2014 "),sme=n(gao,"A",{href:!0});var X5a=s(sme);uwt=r(X5a,"FlaxRobertaForTokenClassification"),X5a.forEach(t),pwt=r(gao," (RoBERTa model)"),gao.forEach(t),_wt=i(yo),cy=n(yo,"LI",{});var hao=s(cy);uBe=n(hao,"STRONG",{});var z5a=s(uBe);bwt=r(z5a,"roformer"),z5a.forEach(t),vwt=r(hao," \u2014 "),lme=n(hao,"A",{href:!0});var Q5a=s(lme);Fwt=r(Q5a,"FlaxRoFormerForTokenClassification"),Q5a.forEach(t),Twt=r(hao," (RoFormer model)"),hao.forEach(t),Mwt=i(yo),fy=n(yo,"LI",{});var uao=s(fy);pBe=n(uao,"STRONG",{});var W5a=s(pBe);Ewt=r(W5a,"xlm-roberta"),W5a.forEach(t),Cwt=r(uao," \u2014 "),ime=n(uao,"A",{href:!0});var U5a=s(ime);wwt=r(U5a,"FlaxXLMRobertaForTokenClassification"),U5a.forEach(t),Awt=r(uao," (XLM-RoBERTa model)"),uao.forEach(t),yo.forEach(t),Lwt=i(md),T(gy.$$.fragment,md),md.forEach(t),dd.forEach(t),Nso=i(c),kf=n(c,"H2",{class:!0});var ado=s(kf);hy=n(ado,"A",{id:!0,class:!0,href:!0});var H5a=s(hy);_Be=n(H5a,"SPAN",{});var J5a=s(_Be);T(OB.$$.fragment,J5a),J5a.forEach(t),H5a.forEach(t),ywt=i(ado),bBe=n(ado,"SPAN",{});var Y5a=s(bBe);xwt=r(Y5a,"FlaxAutoModelForMultipleChoice"),Y5a.forEach(t),ado.forEach(t),qso=i(c),Pr=n(c,"DIV",{class:!0});var cd=s(Pr);T(VB.$$.fragment,cd),$wt=i(cd),Sf=n(cd,"P",{});var Rfe=s(Sf);kwt=r(Rfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),dme=n(Rfe,"A",{href:!0});var Z5a=s(dme);Swt=r(Z5a,"from_pretrained()"),Z5a.forEach(t),Rwt=r(Rfe," class method or the "),mme=n(Rfe,"A",{href:!0});var K5a=s(mme);Pwt=r(K5a,"from_config()"),K5a.forEach(t),Bwt=r(Rfe,` class
method.`),Rfe.forEach(t),Iwt=i(cd),XB=n(cd,"P",{});var ndo=s(XB);Nwt=r(ndo,"This class cannot be instantiated directly using "),vBe=n(ndo,"CODE",{});var e0a=s(vBe);qwt=r(e0a,"__init__()"),e0a.forEach(t),jwt=r(ndo," (throws an error)."),ndo.forEach(t),Dwt=i(cd),Ta=n(cd,"DIV",{class:!0});var c$=s(Ta);T(zB.$$.fragment,c$),Gwt=i(c$),FBe=n(c$,"P",{});var o0a=s(FBe);Owt=r(o0a,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),o0a.forEach(t),Vwt=i(c$),Rf=n(c$,"P",{});var Pfe=s(Rf);Xwt=r(Pfe,`Note:
Loading a model from its configuration file does `),TBe=n(Pfe,"STRONG",{});var r0a=s(TBe);zwt=r(r0a,"not"),r0a.forEach(t),Qwt=r(Pfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),cme=n(Pfe,"A",{href:!0});var t0a=s(cme);Wwt=r(t0a,"from_pretrained()"),t0a.forEach(t),Uwt=r(Pfe," to load the model weights."),Pfe.forEach(t),Hwt=i(c$),T(uy.$$.fragment,c$),c$.forEach(t),Jwt=i(cd),mt=n(cd,"DIV",{class:!0});var fd=s(mt);T(QB.$$.fragment,fd),Ywt=i(fd),MBe=n(fd,"P",{});var a0a=s(MBe);Zwt=r(a0a,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),a0a.forEach(t),Kwt=i(fd),ns=n(fd,"P",{});var f$=s(ns);eAt=r(f$,"The model class to instantiate is selected based on the "),EBe=n(f$,"CODE",{});var n0a=s(EBe);oAt=r(n0a,"model_type"),n0a.forEach(t),rAt=r(f$,` property of the config object (either
passed as an argument or loaded from `),CBe=n(f$,"CODE",{});var s0a=s(CBe);tAt=r(s0a,"pretrained_model_name_or_path"),s0a.forEach(t),aAt=r(f$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wBe=n(f$,"CODE",{});var l0a=s(wBe);nAt=r(l0a,"pretrained_model_name_or_path"),l0a.forEach(t),sAt=r(f$,":"),f$.forEach(t),lAt=i(fd),Qe=n(fd,"UL",{});var xo=s(Qe);py=n(xo,"LI",{});var pao=s(py);ABe=n(pao,"STRONG",{});var i0a=s(ABe);iAt=r(i0a,"albert"),i0a.forEach(t),dAt=r(pao," \u2014 "),fme=n(pao,"A",{href:!0});var d0a=s(fme);mAt=r(d0a,"FlaxAlbertForMultipleChoice"),d0a.forEach(t),cAt=r(pao," (ALBERT model)"),pao.forEach(t),fAt=i(xo),_y=n(xo,"LI",{});var _ao=s(_y);LBe=n(_ao,"STRONG",{});var m0a=s(LBe);gAt=r(m0a,"bert"),m0a.forEach(t),hAt=r(_ao," \u2014 "),gme=n(_ao,"A",{href:!0});var c0a=s(gme);uAt=r(c0a,"FlaxBertForMultipleChoice"),c0a.forEach(t),pAt=r(_ao," (BERT model)"),_ao.forEach(t),_At=i(xo),by=n(xo,"LI",{});var bao=s(by);yBe=n(bao,"STRONG",{});var f0a=s(yBe);bAt=r(f0a,"big_bird"),f0a.forEach(t),vAt=r(bao," \u2014 "),hme=n(bao,"A",{href:!0});var g0a=s(hme);FAt=r(g0a,"FlaxBigBirdForMultipleChoice"),g0a.forEach(t),TAt=r(bao," (BigBird model)"),bao.forEach(t),MAt=i(xo),vy=n(xo,"LI",{});var vao=s(vy);xBe=n(vao,"STRONG",{});var h0a=s(xBe);EAt=r(h0a,"distilbert"),h0a.forEach(t),CAt=r(vao," \u2014 "),ume=n(vao,"A",{href:!0});var u0a=s(ume);wAt=r(u0a,"FlaxDistilBertForMultipleChoice"),u0a.forEach(t),AAt=r(vao," (DistilBERT model)"),vao.forEach(t),LAt=i(xo),Fy=n(xo,"LI",{});var Fao=s(Fy);$Be=n(Fao,"STRONG",{});var p0a=s($Be);yAt=r(p0a,"electra"),p0a.forEach(t),xAt=r(Fao," \u2014 "),pme=n(Fao,"A",{href:!0});var _0a=s(pme);$At=r(_0a,"FlaxElectraForMultipleChoice"),_0a.forEach(t),kAt=r(Fao," (ELECTRA model)"),Fao.forEach(t),SAt=i(xo),Ty=n(xo,"LI",{});var Tao=s(Ty);kBe=n(Tao,"STRONG",{});var b0a=s(kBe);RAt=r(b0a,"roberta"),b0a.forEach(t),PAt=r(Tao," \u2014 "),_me=n(Tao,"A",{href:!0});var v0a=s(_me);BAt=r(v0a,"FlaxRobertaForMultipleChoice"),v0a.forEach(t),IAt=r(Tao," (RoBERTa model)"),Tao.forEach(t),NAt=i(xo),My=n(xo,"LI",{});var Mao=s(My);SBe=n(Mao,"STRONG",{});var F0a=s(SBe);qAt=r(F0a,"roformer"),F0a.forEach(t),jAt=r(Mao," \u2014 "),bme=n(Mao,"A",{href:!0});var T0a=s(bme);DAt=r(T0a,"FlaxRoFormerForMultipleChoice"),T0a.forEach(t),GAt=r(Mao," (RoFormer model)"),Mao.forEach(t),OAt=i(xo),Ey=n(xo,"LI",{});var Eao=s(Ey);RBe=n(Eao,"STRONG",{});var M0a=s(RBe);VAt=r(M0a,"xlm-roberta"),M0a.forEach(t),XAt=r(Eao," \u2014 "),vme=n(Eao,"A",{href:!0});var E0a=s(vme);zAt=r(E0a,"FlaxXLMRobertaForMultipleChoice"),E0a.forEach(t),QAt=r(Eao," (XLM-RoBERTa model)"),Eao.forEach(t),xo.forEach(t),WAt=i(fd),T(Cy.$$.fragment,fd),fd.forEach(t),cd.forEach(t),jso=i(c),Pf=n(c,"H2",{class:!0});var sdo=s(Pf);wy=n(sdo,"A",{id:!0,class:!0,href:!0});var C0a=s(wy);PBe=n(C0a,"SPAN",{});var w0a=s(PBe);T(WB.$$.fragment,w0a),w0a.forEach(t),C0a.forEach(t),UAt=i(sdo),BBe=n(sdo,"SPAN",{});var A0a=s(BBe);HAt=r(A0a,"FlaxAutoModelForNextSentencePrediction"),A0a.forEach(t),sdo.forEach(t),Dso=i(c),Br=n(c,"DIV",{class:!0});var gd=s(Br);T(UB.$$.fragment,gd),JAt=i(gd),Bf=n(gd,"P",{});var Bfe=s(Bf);YAt=r(Bfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Fme=n(Bfe,"A",{href:!0});var L0a=s(Fme);ZAt=r(L0a,"from_pretrained()"),L0a.forEach(t),KAt=r(Bfe," class method or the "),Tme=n(Bfe,"A",{href:!0});var y0a=s(Tme);e6t=r(y0a,"from_config()"),y0a.forEach(t),o6t=r(Bfe,` class
method.`),Bfe.forEach(t),r6t=i(gd),HB=n(gd,"P",{});var ldo=s(HB);t6t=r(ldo,"This class cannot be instantiated directly using "),IBe=n(ldo,"CODE",{});var x0a=s(IBe);a6t=r(x0a,"__init__()"),x0a.forEach(t),n6t=r(ldo," (throws an error)."),ldo.forEach(t),s6t=i(gd),Ma=n(gd,"DIV",{class:!0});var g$=s(Ma);T(JB.$$.fragment,g$),l6t=i(g$),NBe=n(g$,"P",{});var $0a=s(NBe);i6t=r($0a,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),$0a.forEach(t),d6t=i(g$),If=n(g$,"P",{});var Ife=s(If);m6t=r(Ife,`Note:
Loading a model from its configuration file does `),qBe=n(Ife,"STRONG",{});var k0a=s(qBe);c6t=r(k0a,"not"),k0a.forEach(t),f6t=r(Ife,` load the model weights. It only affects the
model\u2019s configuration. Use `),Mme=n(Ife,"A",{href:!0});var S0a=s(Mme);g6t=r(S0a,"from_pretrained()"),S0a.forEach(t),h6t=r(Ife," to load the model weights."),Ife.forEach(t),u6t=i(g$),T(Ay.$$.fragment,g$),g$.forEach(t),p6t=i(gd),ct=n(gd,"DIV",{class:!0});var hd=s(ct);T(YB.$$.fragment,hd),_6t=i(hd),jBe=n(hd,"P",{});var R0a=s(jBe);b6t=r(R0a,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),R0a.forEach(t),v6t=i(hd),ss=n(hd,"P",{});var h$=s(ss);F6t=r(h$,"The model class to instantiate is selected based on the "),DBe=n(h$,"CODE",{});var P0a=s(DBe);T6t=r(P0a,"model_type"),P0a.forEach(t),M6t=r(h$,` property of the config object (either
passed as an argument or loaded from `),GBe=n(h$,"CODE",{});var B0a=s(GBe);E6t=r(B0a,"pretrained_model_name_or_path"),B0a.forEach(t),C6t=r(h$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),OBe=n(h$,"CODE",{});var I0a=s(OBe);w6t=r(I0a,"pretrained_model_name_or_path"),I0a.forEach(t),A6t=r(h$,":"),h$.forEach(t),L6t=i(hd),VBe=n(hd,"UL",{});var N0a=s(VBe);Ly=n(N0a,"LI",{});var Cao=s(Ly);XBe=n(Cao,"STRONG",{});var q0a=s(XBe);y6t=r(q0a,"bert"),q0a.forEach(t),x6t=r(Cao," \u2014 "),Eme=n(Cao,"A",{href:!0});var j0a=s(Eme);$6t=r(j0a,"FlaxBertForNextSentencePrediction"),j0a.forEach(t),k6t=r(Cao," (BERT model)"),Cao.forEach(t),N0a.forEach(t),S6t=i(hd),T(yy.$$.fragment,hd),hd.forEach(t),gd.forEach(t),Gso=i(c),Nf=n(c,"H2",{class:!0});var ido=s(Nf);xy=n(ido,"A",{id:!0,class:!0,href:!0});var D0a=s(xy);zBe=n(D0a,"SPAN",{});var G0a=s(zBe);T(ZB.$$.fragment,G0a),G0a.forEach(t),D0a.forEach(t),R6t=i(ido),QBe=n(ido,"SPAN",{});var O0a=s(QBe);P6t=r(O0a,"FlaxAutoModelForImageClassification"),O0a.forEach(t),ido.forEach(t),Oso=i(c),Ir=n(c,"DIV",{class:!0});var ud=s(Ir);T(KB.$$.fragment,ud),B6t=i(ud),qf=n(ud,"P",{});var Nfe=s(qf);I6t=r(Nfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Cme=n(Nfe,"A",{href:!0});var V0a=s(Cme);N6t=r(V0a,"from_pretrained()"),V0a.forEach(t),q6t=r(Nfe," class method or the "),wme=n(Nfe,"A",{href:!0});var X0a=s(wme);j6t=r(X0a,"from_config()"),X0a.forEach(t),D6t=r(Nfe,` class
method.`),Nfe.forEach(t),G6t=i(ud),eI=n(ud,"P",{});var ddo=s(eI);O6t=r(ddo,"This class cannot be instantiated directly using "),WBe=n(ddo,"CODE",{});var z0a=s(WBe);V6t=r(z0a,"__init__()"),z0a.forEach(t),X6t=r(ddo," (throws an error)."),ddo.forEach(t),z6t=i(ud),Ea=n(ud,"DIV",{class:!0});var u$=s(Ea);T(oI.$$.fragment,u$),Q6t=i(u$),UBe=n(u$,"P",{});var Q0a=s(UBe);W6t=r(Q0a,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Q0a.forEach(t),U6t=i(u$),jf=n(u$,"P",{});var qfe=s(jf);H6t=r(qfe,`Note:
Loading a model from its configuration file does `),HBe=n(qfe,"STRONG",{});var W0a=s(HBe);J6t=r(W0a,"not"),W0a.forEach(t),Y6t=r(qfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ame=n(qfe,"A",{href:!0});var U0a=s(Ame);Z6t=r(U0a,"from_pretrained()"),U0a.forEach(t),K6t=r(qfe," to load the model weights."),qfe.forEach(t),e7t=i(u$),T($y.$$.fragment,u$),u$.forEach(t),o7t=i(ud),ft=n(ud,"DIV",{class:!0});var pd=s(ft);T(rI.$$.fragment,pd),r7t=i(pd),JBe=n(pd,"P",{});var H0a=s(JBe);t7t=r(H0a,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),H0a.forEach(t),a7t=i(pd),ls=n(pd,"P",{});var p$=s(ls);n7t=r(p$,"The model class to instantiate is selected based on the "),YBe=n(p$,"CODE",{});var J0a=s(YBe);s7t=r(J0a,"model_type"),J0a.forEach(t),l7t=r(p$,` property of the config object (either
passed as an argument or loaded from `),ZBe=n(p$,"CODE",{});var Y0a=s(ZBe);i7t=r(Y0a,"pretrained_model_name_or_path"),Y0a.forEach(t),d7t=r(p$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KBe=n(p$,"CODE",{});var Z0a=s(KBe);m7t=r(Z0a,"pretrained_model_name_or_path"),Z0a.forEach(t),c7t=r(p$,":"),p$.forEach(t),f7t=i(pd),tI=n(pd,"UL",{});var mdo=s(tI);ky=n(mdo,"LI",{});var wao=s(ky);eIe=n(wao,"STRONG",{});var K0a=s(eIe);g7t=r(K0a,"beit"),K0a.forEach(t),h7t=r(wao," \u2014 "),Lme=n(wao,"A",{href:!0});var ewa=s(Lme);u7t=r(ewa,"FlaxBeitForImageClassification"),ewa.forEach(t),p7t=r(wao," (BEiT model)"),wao.forEach(t),_7t=i(mdo),Sy=n(mdo,"LI",{});var Aao=s(Sy);oIe=n(Aao,"STRONG",{});var owa=s(oIe);b7t=r(owa,"vit"),owa.forEach(t),v7t=r(Aao," \u2014 "),yme=n(Aao,"A",{href:!0});var rwa=s(yme);F7t=r(rwa,"FlaxViTForImageClassification"),rwa.forEach(t),T7t=r(Aao," (ViT model)"),Aao.forEach(t),mdo.forEach(t),M7t=i(pd),T(Ry.$$.fragment,pd),pd.forEach(t),ud.forEach(t),Vso=i(c),Df=n(c,"H2",{class:!0});var cdo=s(Df);Py=n(cdo,"A",{id:!0,class:!0,href:!0});var twa=s(Py);rIe=n(twa,"SPAN",{});var awa=s(rIe);T(aI.$$.fragment,awa),awa.forEach(t),twa.forEach(t),E7t=i(cdo),tIe=n(cdo,"SPAN",{});var nwa=s(tIe);C7t=r(nwa,"FlaxAutoModelForVision2Seq"),nwa.forEach(t),cdo.forEach(t),Xso=i(c),Nr=n(c,"DIV",{class:!0});var _d=s(Nr);T(nI.$$.fragment,_d),w7t=i(_d),Gf=n(_d,"P",{});var jfe=s(Gf);A7t=r(jfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),xme=n(jfe,"A",{href:!0});var swa=s(xme);L7t=r(swa,"from_pretrained()"),swa.forEach(t),y7t=r(jfe," class method or the "),$me=n(jfe,"A",{href:!0});var lwa=s($me);x7t=r(lwa,"from_config()"),lwa.forEach(t),$7t=r(jfe,` class
method.`),jfe.forEach(t),k7t=i(_d),sI=n(_d,"P",{});var fdo=s(sI);S7t=r(fdo,"This class cannot be instantiated directly using "),aIe=n(fdo,"CODE",{});var iwa=s(aIe);R7t=r(iwa,"__init__()"),iwa.forEach(t),P7t=r(fdo," (throws an error)."),fdo.forEach(t),B7t=i(_d),Ca=n(_d,"DIV",{class:!0});var _$=s(Ca);T(lI.$$.fragment,_$),I7t=i(_$),nIe=n(_$,"P",{});var dwa=s(nIe);N7t=r(dwa,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),dwa.forEach(t),q7t=i(_$),Of=n(_$,"P",{});var Dfe=s(Of);j7t=r(Dfe,`Note:
Loading a model from its configuration file does `),sIe=n(Dfe,"STRONG",{});var mwa=s(sIe);D7t=r(mwa,"not"),mwa.forEach(t),G7t=r(Dfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),kme=n(Dfe,"A",{href:!0});var cwa=s(kme);O7t=r(cwa,"from_pretrained()"),cwa.forEach(t),V7t=r(Dfe," to load the model weights."),Dfe.forEach(t),X7t=i(_$),T(By.$$.fragment,_$),_$.forEach(t),z7t=i(_d),gt=n(_d,"DIV",{class:!0});var bd=s(gt);T(iI.$$.fragment,bd),Q7t=i(bd),lIe=n(bd,"P",{});var fwa=s(lIe);W7t=r(fwa,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),fwa.forEach(t),U7t=i(bd),is=n(bd,"P",{});var b$=s(is);H7t=r(b$,"The model class to instantiate is selected based on the "),iIe=n(b$,"CODE",{});var gwa=s(iIe);J7t=r(gwa,"model_type"),gwa.forEach(t),Y7t=r(b$,` property of the config object (either
passed as an argument or loaded from `),dIe=n(b$,"CODE",{});var hwa=s(dIe);Z7t=r(hwa,"pretrained_model_name_or_path"),hwa.forEach(t),K7t=r(b$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mIe=n(b$,"CODE",{});var uwa=s(mIe);e8t=r(uwa,"pretrained_model_name_or_path"),uwa.forEach(t),o8t=r(b$,":"),b$.forEach(t),r8t=i(bd),cIe=n(bd,"UL",{});var pwa=s(cIe);Iy=n(pwa,"LI",{});var Lao=s(Iy);fIe=n(Lao,"STRONG",{});var _wa=s(fIe);t8t=r(_wa,"vision-encoder-decoder"),_wa.forEach(t),a8t=r(Lao," \u2014 "),Sme=n(Lao,"A",{href:!0});var bwa=s(Sme);n8t=r(bwa,"FlaxVisionEncoderDecoderModel"),bwa.forEach(t),s8t=r(Lao," (Vision Encoder decoder model)"),Lao.forEach(t),pwa.forEach(t),l8t=i(bd),T(Ny.$$.fragment,bd),bd.forEach(t),_d.forEach(t),this.h()},h(){d(g,"name","hf:doc:metadata"),d(g,"content",JSON.stringify(I6a)),d(f,"id","auto-classes"),d(f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(f,"href","#auto-classes"),d(u,"class","relative group"),d(ms,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig"),d(fs,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoModel"),d(gs,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer"),d(wd,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),d(Jf,"id","extending-the-auto-classes"),d(Jf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Jf,"href","#extending-the-auto-classes"),d(Ad,"class","relative group"),d(Zf,"id","transformers.AutoConfig"),d(Zf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Zf,"href","#transformers.AutoConfig"),d(Ld,"class","relative group"),d(VN,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),d(XN,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig"),d(zN,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartConfig"),d(QN,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig"),d(WN,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertConfig"),d(UN,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig"),d(HN,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig"),d(JN,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),d(YN,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig"),d(ZN,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),d(KN,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig"),d(eq,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig"),d(oq,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig"),d(rq,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig"),d(tq,"href","/docs/transformers/main/en/model_doc/clipseg#transformers.CLIPSegConfig"),d(aq,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig"),d(nq,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig"),d(sq,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig"),d(lq,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig"),d(iq,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig"),d(dq,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig"),d(mq,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),d(cq,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig"),d(fq,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),d(gq,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig"),d(hq,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config"),d(uq,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),d(pq,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig"),d(_q,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig"),d(bq,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig"),d(vq,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig"),d(Fq,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig"),d(Tq,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig"),d(Mq,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig"),d(Eq,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig"),d(Cq,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),d(wq,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig"),d(Aq,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig"),d(Lq,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig"),d(yq,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig"),d(xq,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig"),d($q,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig"),d(kq,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig"),d(Sq,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig"),d(Rq,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config"),d(Pq,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),d(Bq,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),d(Iq,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig"),d(Nq,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig"),d(qq,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig"),d(jq,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig"),d(Dq,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig"),d(Gq,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig"),d(Oq,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig"),d(Vq,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),d(Xq,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),d(zq,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDConfig"),d(Qq,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig"),d(Wq,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig"),d(Uq,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig"),d(Hq,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config"),d(Jq,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig"),d(Yq,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig"),d(Zq,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config"),d(Kq,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig"),d(ej,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig"),d(oj,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig"),d(rj,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig"),d(tj,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig"),d(aj,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),d(nj,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig"),d(sj,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig"),d(lj,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig"),d(ij,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config"),d(dj,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig"),d(mj,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig"),d(cj,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig"),d(fj,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),d(gj,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig"),d(hj,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig"),d(uj,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig"),d(pj,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig"),d(_j,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig"),d(bj,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig"),d(vj,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig"),d(Fj,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig"),d(Tj,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig"),d(Mj,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagConfig"),d(Ej,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmConfig"),d(Cj,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig"),d(wj,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig"),d(Aj,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig"),d(Lj,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig"),d(yj,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig"),d(xj,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig"),d($j,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig"),d(kj,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig"),d(Sj,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig"),d(Rj,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig"),d(Pj,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig"),d(Bj,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),d(Ij,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),d(Nj,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),d(qj,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig"),d(jj,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),d(Dj,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig"),d(Gj,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config"),d(Oj,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Config"),d(Vj,"href","/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerConfig"),d(Xj,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig"),d(zj,"href","/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig"),d(Qj,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),d(Wj,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),d(Uj,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig"),d(Hj,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig"),d(Jj,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),d(Yj,"href","/docs/transformers/main/en/model_doc/van#transformers.VanConfig"),d(Zj,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig"),d(Kj,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig"),d(eD,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),d(oD,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),d(rD,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig"),d(tD,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig"),d(aD,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig"),d(nD,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig"),d(sD,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),d(lD,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),d(iD,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig"),d(dD,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig"),d(mD,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig"),d(cD,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig"),d(fD,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig"),d(gD,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),d(hD,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),d(uD,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),d(pD,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig"),d(_D,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig"),d(bD,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig"),d(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(xu,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d($u,"id","transformers.AutoTokenizer"),d($u,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d($u,"href","#transformers.AutoTokenizer"),d(xd,"class","relative group"),d(vD,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),d(FD,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),d(TD,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),d(MD,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizer"),d(ED,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizerFast"),d(CD,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizer"),d(wD,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizerFast"),d(AD,"href","/docs/transformers/main/en/model_doc/bartpho#transformers.BartphoTokenizer"),d(LD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(yD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(xD,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),d($D,"href","/docs/transformers/main/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),d(kD,"href","/docs/transformers/main/en/model_doc/bertweet#transformers.BertweetTokenizer"),d(SD,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizer"),d(RD,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),d(PD,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),d(BD,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),d(ID,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),d(ND,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),d(qD,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),d(jD,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomTokenizerFast"),d(DD,"href","/docs/transformers/main/en/model_doc/byt5#transformers.ByT5Tokenizer"),d(GD,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizer"),d(OD,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizerFast"),d(VD,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineTokenizer"),d(XD,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),d(zD,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),d(QD,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),d(WD,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),d(UD,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizer"),d(HD,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizerFast"),d(JD,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizer"),d(YD,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),d(ZD,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizer"),d(KD,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizerFast"),d(eG,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLTokenizer"),d(oG,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),d(rG,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),d(tG,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizer"),d(aG,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizerFast"),d(nG,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),d(sG,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),d(lG,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizer"),d(iG,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),d(dG,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),d(mG,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),d(cG,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizer"),d(fG,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizerFast"),d(gG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(hG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(uG,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmTokenizer"),d(pG,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertTokenizer"),d(_G,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizer"),d(bG,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizerFast"),d(vG,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTTokenizer"),d(FG,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizer"),d(TG,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizerFast"),d(MG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),d(EG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),d(CG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),d(wG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),d(AG,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),d(LG,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseTokenizer"),d(yG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),d(xG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),d($G,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),d(kG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),d(SG,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizer"),d(RG,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizerFast"),d(PG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),d(BG,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),d(IG,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),d(NG,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),d(qG,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),d(jG,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),d(DG,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),d(GG,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),d(OG,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),d(VG,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),d(XG,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),d(zG,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizer"),d(QG,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizerFast"),d(WG,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),d(UG,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),d(HG,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizer"),d(JG,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizerFast"),d(YG,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),d(ZG,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),d(KG,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeTokenizer"),d(eO,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizer"),d(oO,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),d(rO,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),d(tO,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianTokenizer"),d(aO,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizer"),d(nO,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizerFast"),d(sO,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50Tokenizer"),d(lO,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50TokenizerFast"),d(iO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(dO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(mO,"href","/docs/transformers/main/en/model_doc/mluke#transformers.MLukeTokenizer"),d(cO,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),d(fO,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),d(gO,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizer"),d(hO,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),d(uO,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),d(pO,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),d(_O,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizer"),d(bO,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizerFast"),d(vO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(FO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(TO,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizer"),d(MO,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizerFast"),d(EO,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),d(CO,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),d(wO,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),d(AO,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),d(LO,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),d(yO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),d(xO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),d($O,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),d(kO,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),d(SO,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),d(RO,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),d(PO,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverTokenizer"),d(BO,"href","/docs/transformers/main/en/model_doc/phobert#transformers.PhobertTokenizer"),d(IO,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartTokenizer"),d(NO,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),d(qO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(jO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(DO,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagTokenizer"),d(GO,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizer"),d(OO,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizerFast"),d(VO,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizer"),d(XO,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizerFast"),d(zO,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizer"),d(QO,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizerFast"),d(WO,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizer"),d(UO,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),d(HO,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),d(JO,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),d(YO,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizer"),d(ZO,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),d(KO,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),d(eV,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),d(oV,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizer"),d(rV,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizerFast"),d(tV,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),d(aV,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),d(nV,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),d(sV,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),d(lV,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasTokenizer"),d(iV,"href","/docs/transformers/main/en/model_doc/tapex#transformers.TapexTokenizer"),d(dV,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),d(mV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(cV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(fV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(gV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(hV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),d(uV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),d(pV,"href","/docs/transformers/main/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),d(_V,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperTokenizer"),d(bV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),d(vV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),d(FV,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizer"),d(TV,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizerFast"),d(MV,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMTokenizer"),d(EV,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),d(CV,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),d(wV,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),d(AV,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),d(LV,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),d(yV,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizer"),d(xV,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),d($V,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),d(kV,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),d(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(hp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(up,"id","transformers.AutoFeatureExtractor"),d(up,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(up,"href","#transformers.AutoFeatureExtractor"),d($d,"class","relative group"),d(SV,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),d(RV,"href","/docs/transformers/main/en/model_doc/beit#transformers.models.beit.image_processing_beit.BeitImageProcessor"),d(PV,"href","/docs/transformers/main/en/model_doc/clip#transformers.models.clip.image_processing_clip.CLIPImageProcessor"),d(BV,"href","/docs/transformers/main/en/model_doc/vit#transformers.models.vit.image_processing_vit.ViTImageProcessor"),d(IV,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrFeatureExtractor"),d(NV,"href","/docs/transformers/main/en/model_doc/convnext#transformers.models.convnext.image_processing_convnext.ConvNextImageProcessor"),d(qV,"href","/docs/transformers/main/en/model_doc/convnext#transformers.models.convnext.image_processing_convnext.ConvNextImageProcessor"),d(jV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),d(DV,"href","/docs/transformers/main/en/model_doc/beit#transformers.models.beit.image_processing_beit.BeitImageProcessor"),d(GV,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrFeatureExtractor"),d(OV,"href","/docs/transformers/main/en/model_doc/deit#transformers.models.deit.image_processing_deit.DeiTImageProcessor"),d(VV,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrFeatureExtractor"),d(XV,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutFeatureExtractor"),d(zV,"href","/docs/transformers/main/en/model_doc/dpt#transformers.models.dpt.image_processing_dpt.DPTImageProcessor"),d(QV,"href","/docs/transformers/main/en/model_doc/flava#transformers.models.flava.image_processing_flava.FlavaImageProcessor"),d(WV,"href","/docs/transformers/main/en/model_doc/glpn#transformers.models.glpn.image_processing_glpn.GLPNImageProcessor"),d(UV,"href","/docs/transformers/main/en/model_doc/clip#transformers.models.clip.image_processing_clip.CLIPImageProcessor"),d(HV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),d(JV,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.models.imagegpt.image_processing_imagegpt.ImageGPTImageProcessor"),d(YV,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.models.layoutlmv2.image_processing_layoutlmv2.LayoutLMv2ImageProcessor"),d(ZV,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.models.layoutlmv3.image_processing_layoutlmv3.LayoutLMv3ImageProcessor"),d(KV,"href","/docs/transformers/main/en/model_doc/levit#transformers.models.levit.image_processing_levit.LevitImageProcessor"),d(eX,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),d(oX,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),d(rX,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.models.mobilevit.image_processing_mobilevit.MobileViTImageProcessor"),d(tX,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTFeatureExtractor"),d(aX,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.models.perceiver.image_processing_perceiver.PerceiverImageProcessor"),d(nX,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.models.poolformer.image_processing_poolformer.PoolFormerImageProcessor"),d(sX,"href","/docs/transformers/main/en/model_doc/convnext#transformers.models.convnext.image_processing_convnext.ConvNextImageProcessor"),d(lX,"href","/docs/transformers/main/en/model_doc/convnext#transformers.models.convnext.image_processing_convnext.ConvNextImageProcessor"),d(iX,"href","/docs/transformers/main/en/model_doc/segformer#transformers.models.segformer.image_processing_segformer.SegformerImageProcessor"),d(dX,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),d(mX,"href","/docs/transformers/main/en/model_doc/vit#transformers.models.vit.image_processing_vit.ViTImageProcessor"),d(cX,"href","/docs/transformers/main/en/model_doc/vit#transformers.models.vit.image_processing_vit.ViTImageProcessor"),d(fX,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrFeatureExtractor"),d(gX,"href","/docs/transformers/main/en/model_doc/convnext#transformers.models.convnext.image_processing_convnext.ConvNextImageProcessor"),d(hX,"href","/docs/transformers/main/en/model_doc/videomae#transformers.models.videomae.image_processing_videomae.VideoMAEImageProcessor"),d(uX,"href","/docs/transformers/main/en/model_doc/vilt#transformers.models.vilt.image_processing_vilt.ViltImageProcessor"),d(pX,"href","/docs/transformers/main/en/model_doc/vit#transformers.models.vit.image_processing_vit.ViTImageProcessor"),d(_X,"href","/docs/transformers/main/en/model_doc/vit#transformers.models.vit.image_processing_vit.ViTImageProcessor"),d(bX,"href","/docs/transformers/main/en/model_doc/vit#transformers.models.vit.image_processing_vit.ViTImageProcessor"),d(vX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),d(FX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),d(TX,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperFeatureExtractor"),d(MX,"href","/docs/transformers/main/en/model_doc/clip#transformers.models.clip.image_processing_clip.CLIPImageProcessor"),d(EX,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosFeatureExtractor"),d(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(d_,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(m_,"id","transformers.AutoProcessor"),d(m_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(m_,"href","#transformers.AutoProcessor"),d(kd,"class","relative group"),d(CX,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),d(wX,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),d(AX,"href","/docs/transformers/main/en/model_doc/clipseg#transformers.CLIPSegProcessor"),d(LX,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaProcessor"),d(yX,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),d(xX,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),d($X,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),d(kX,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),d(SX,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMProcessor"),d(RX,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTProcessor"),d(PX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(BX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(IX,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),d(NX,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),d(qX,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRProcessor"),d(jX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(DX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(GX,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltProcessor"),d(OX,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),d(VX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(XX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(zX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(QX,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperProcessor"),d(WX,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPProcessor"),d(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(I_,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(N_,"id","transformers.AutoModel"),d(N_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(N_,"href","#transformers.AutoModel"),d(Rd,"class","relative group"),d(UX,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(HX,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(JX,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(YX,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel"),d(ZX,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartModel"),d(KX,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitModel"),d(ez,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),d(oz,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),d(rz,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel"),d(tz,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),d(az,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel"),d(nz,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),d(sz,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel"),d(lz,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel"),d(iz,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineModel"),d(dz,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel"),d(mz,"href","/docs/transformers/main/en/model_doc/clipseg#transformers.CLIPSegModel"),d(cz,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel"),d(fz,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrModel"),d(gz,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel"),d(hz,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel"),d(uz,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel"),d(pz,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel"),d(_z,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel"),d(bz,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel"),d(vz,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel"),d(Fz,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel"),d(Tz,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model"),d(Mz,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),d(Ez,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrModel"),d(Cz,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel"),d(wz,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrModel"),d(Az,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel"),d(Lz,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel"),d(yz,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder"),d(xz,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel"),d($z,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel"),d(kz,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel"),d(Sz,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmModel"),d(Rz,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel"),d(Pz,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel"),d(Bz,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel"),d(Iz,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel"),d(Nz,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel"),d(qz,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel"),d(jz,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel"),d(Dz,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model"),d(Gz,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel"),d(Oz,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),d(Vz,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel"),d(Xz,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel"),d(zz,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel"),d(Qz,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel"),d(Wz,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel"),d(Uz,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel"),d(Hz,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel"),d(Jz,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),d(Yz,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),d(Zz,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDModel"),d(Kz,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitModel"),d(eQ,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltModel"),d(oQ,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel"),d(rQ,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model"),d(tQ,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeModel"),d(aQ,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel"),d(nQ,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),d(sQ,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianModel"),d(lQ,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMModel"),d(iQ,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel"),d(dQ,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel"),d(mQ,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel"),d(cQ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel"),d(fQ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel"),d(gQ,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel"),d(hQ,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel"),d(uQ,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model"),d(pQ,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel"),d(_Q,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel"),d(bQ,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),d(vQ,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel"),d(FQ,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),d(TQ,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTModel"),d(MQ,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel"),d(EQ,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel"),d(CQ,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel"),d(wQ,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel"),d(AQ,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel"),d(LQ,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel"),d(yQ,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel"),d(xQ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel"),d($Q,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel"),d(kQ,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel"),d(SQ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel"),d(RQ,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel"),d(PQ,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),d(BQ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel"),d(IQ,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertModel"),d(NQ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel"),d(qQ,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel"),d(jQ,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWModel"),d(DQ,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel"),d(GQ,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel"),d(OQ,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel"),d(VQ,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel"),d(XQ,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinModel"),d(zQ,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model"),d(QQ,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Model"),d(WQ,"href","/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerModel"),d(UQ,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel"),d(HQ,"href","/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel"),d(JQ,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),d(YQ,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel"),d(ZQ,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel"),d(KQ,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),d(eW,"href","/docs/transformers/main/en/model_doc/van#transformers.VanModel"),d(oW,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel"),d(rW,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel"),d(tW,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),d(aW,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel"),d(nW,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTModel"),d(sW,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel"),d(lW,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNModel"),d(iW,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),d(dW,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),d(mW,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel"),d(cW,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperModel"),d(fW,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel"),d(gW,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel"),d(hW,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel"),d(uW,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),d(pW,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),d(_W,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),d(bW,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel"),d(vW,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel"),d(FW,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel"),d(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(db,"id","transformers.AutoModelForPreTraining"),d(db,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(db,"href","#transformers.AutoModelForPreTraining"),d(Id,"class","relative group"),d(TW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(MW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(EW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(CW,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining"),d(wW,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),d(AW,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining"),d(LW,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),d(yW,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),d(xW,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),d($W,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),d(kW,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),d(SW,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),d(RW,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),d(PW,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),d(BW,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining"),d(IW,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining"),d(NW,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),d(qW,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining"),d(jW,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining"),d(DW,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),d(GW,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining"),d(OW,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),d(VW,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),d(XW,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),d(zW,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),d(QW,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),d(WW,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining"),d(UW,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),d(HW,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),d(JW,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),d(YW,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),d(ZW,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining"),d(KW,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),d(eU,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),d(oU,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),d(rU,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForPreTraining"),d(tU,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining"),d(aU,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),d(nU,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),d(sU,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),d(lU,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),d(iU,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),d(dU,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),d(mU,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining"),d(cU,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),d(fU,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),d(gU,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),d(hU,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),d(uU,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),d(pU,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),d(_U,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),d(bU,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),d(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(iv,"id","transformers.AutoModelForCausalLM"),d(iv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(iv,"href","#transformers.AutoModelForCausalLM"),d(jd,"class","relative group"),d(vU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(FU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(TU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(MU,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM"),d(EU,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel"),d(CU,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),d(wU,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),d(AU,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),d(LU,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),d(yU,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),d(xU,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),d($U,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM"),d(kU,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM"),d(SU,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),d(RU,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),d(PU,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM"),d(BU,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM"),d(IU,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),d(NU,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),d(qU,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),d(jU,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM"),d(DU,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM"),d(GU,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM"),d(OU,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM"),d(VU,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),d(XU,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM"),d(zU,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),d(QU,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM"),d(WU,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM"),d(UU,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM"),d(HU,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),d(JU,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),d(YU,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),d(ZU,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM"),d(KU,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM"),d(eH,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForCausalLM"),d(oH,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM"),d(rH,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),d(tH,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),d(aH,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM"),d(nH,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM"),d(sH,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),d(lH,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),d(iH,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),d(dH,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),d(mH,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),d(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(oF,"id","transformers.AutoModelForDepthEstimation"),d(oF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(oF,"href","#transformers.AutoModelForDepthEstimation"),d(Od,"class","relative group"),d(cH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(fH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(gH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(hH,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTForDepthEstimation"),d(uH,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNForDepthEstimation"),d(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(lF,"id","transformers.AutoModelForMaskedLM"),d(lF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(lF,"href","#transformers.AutoModelForMaskedLM"),d(zd,"class","relative group"),d(pH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(_H,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(bH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(vH,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM"),d(FH,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),d(TH,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM"),d(MH,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),d(EH,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),d(CH,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),d(wH,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),d(AH,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),d(LH,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),d(yH,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),d(xH,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM"),d($H,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM"),d(kH,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),d(SH,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM"),d(RH,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM"),d(PH,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),d(BH,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),d(IH,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),d(NH,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),d(qH,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),d(jH,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),d(DH,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),d(GH,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),d(OH,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),d(VH,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM"),d(XH,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),d(zH,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),d(QH,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),d(WH,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM"),d(UH,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM"),d(HH,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),d(JH,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForMaskedLM"),d(YH,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),d(ZH,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),d(KH,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),d(eJ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),d(oJ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),d(rJ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),d(tJ,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM"),d(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(YF,"id","transformers.AutoModelForSeq2SeqLM"),d(YF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(YF,"href","#transformers.AutoModelForSeq2SeqLM"),d(Ud,"class","relative group"),d(aJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(nJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(sJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(lJ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),d(iJ,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),d(dJ,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),d(mJ,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),d(cJ,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),d(fJ,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),d(gJ,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration"),d(hJ,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),d(uJ,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),d(pJ,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel"),d(_J,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),d(bJ,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),d(vJ,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),d(FJ,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),d(TJ,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),d(MJ,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration"),d(EJ,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),d(CJ,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),d(wJ,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),d(AJ,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),d(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(TT,"id","transformers.AutoModelForSequenceClassification"),d(TT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(TT,"href","#transformers.AutoModelForSequenceClassification"),d(Yd,"class","relative group"),d(LJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(yJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(xJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d($J,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification"),d(kJ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification"),d(SJ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification"),d(RJ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),d(PJ,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),d(BJ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification"),d(IJ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),d(NJ,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification"),d(qJ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),d(jJ,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),d(DJ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),d(GJ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),d(OJ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),d(VJ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),d(XJ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification"),d(zJ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification"),d(QJ,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmForSequenceClassification"),d(WJ,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),d(UJ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification"),d(HJ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),d(JJ,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),d(YJ,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),d(ZJ,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),d(KJ,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification"),d(eY,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),d(oY,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),d(rY,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),d(tY,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification"),d(aY,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltForSequenceClassification"),d(nY,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),d(sY,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification"),d(lY,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification"),d(iY,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification"),d(dY,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),d(mY,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),d(cY,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),d(fY,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification"),d(gY,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification"),d(hY,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),d(uY,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),d(pY,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification"),d(_Y,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),d(bY,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),d(vY,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),d(FY,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),d(TY,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),d(MY,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),d(EY,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForSequenceClassification"),d(CY,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),d(wY,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),d(AY,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification"),d(LY,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),d(yY,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification"),d(xY,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),d($Y,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),d(kY,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),d(SY,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification"),d(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(yM,"id","transformers.AutoModelForMultipleChoice"),d(yM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(yM,"href","#transformers.AutoModelForMultipleChoice"),d(em,"class","relative group"),d(RY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(PY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(BY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(IY,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice"),d(NY,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice"),d(qY,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),d(jY,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),d(DY,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice"),d(GY,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),d(OY,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),d(VY,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),d(XY,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),d(zY,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice"),d(QY,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice"),d(WY,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),d(UY,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice"),d(HY,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),d(JY,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice"),d(YY,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),d(ZY,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice"),d(KY,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),d(eZ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),d(oZ,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),d(rZ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice"),d(tZ,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),d(aZ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),d(nZ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),d(sZ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),d(lZ,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForMultipleChoice"),d(iZ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),d(dZ,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),d(mZ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice"),d(cZ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),d(fZ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),d(gZ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),d(hZ,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice"),d(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(cE,"id","transformers.AutoModelForNextSentencePrediction"),d(cE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(cE,"href","#transformers.AutoModelForNextSentencePrediction"),d(tm,"class","relative group"),d(uZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(pZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(_Z,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(bZ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction"),d(vZ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction"),d(FZ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),d(TZ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),d(MZ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),d(EZ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction"),d(CZ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),d(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ME,"id","transformers.AutoModelForTokenClassification"),d(ME,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ME,"href","#transformers.AutoModelForTokenClassification"),d(sm,"class","relative group"),d(wZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(AZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(LZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(yZ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification"),d(xZ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification"),d($Z,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),d(kZ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification"),d(SZ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification"),d(RZ,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification"),d(PZ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),d(BZ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),d(IZ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification"),d(NZ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),d(qZ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),d(jZ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification"),d(DZ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification"),d(GZ,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmForTokenClassification"),d(OZ,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),d(VZ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification"),d(XZ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification"),d(zZ,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),d(QZ,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification"),d(WZ,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),d(UZ,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),d(HZ,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),d(JZ,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltForTokenClassification"),d(YZ,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification"),d(ZZ,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification"),d(KZ,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification"),d(eK,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),d(oK,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),d(rK,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),d(tK,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification"),d(aK,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),d(nK,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),d(sK,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification"),d(lK,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification"),d(iK,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForTokenClassification"),d(dK,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),d(mK,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),d(cK,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification"),d(fK,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),d(gK,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),d(hK,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),d(uK,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification"),d(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(h4,"id","transformers.AutoModelForQuestionAnswering"),d(h4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(h4,"href","#transformers.AutoModelForQuestionAnswering"),d(dm,"class","relative group"),d(pK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(_K,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(bK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(vK,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),d(FK,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering"),d(TK,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering"),d(MK,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),d(EK,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),d(CK,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForQuestionAnswering"),d(wK,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),d(AK,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering"),d(LK,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),d(yK,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),d(xK,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),d($K,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),d(kK,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),d(SK,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),d(RK,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering"),d(PK,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),d(BK,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),d(IK,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),d(NK,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),d(qK,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),d(jK,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),d(DK,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),d(GK,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering"),d(OK,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltForQuestionAnswering"),d(VK,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),d(XK,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering"),d(zK,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),d(QK,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering"),d(WK,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),d(UK,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),d(HK,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),d(JK,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),d(YK,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering"),d(ZK,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering"),d(KK,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),d(eee,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForQuestionAnswering"),d(oee,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),d(ree,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),d(tee,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),d(aee,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),d(nee,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForQuestionAnswering"),d(see,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),d(lee,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),d(iee,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),d(dee,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),d(mee,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),d(cee,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),d(fee,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),d(gee,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),d(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(gC,"id","transformers.AutoModelForTableQuestionAnswering"),d(gC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(gC,"href","#transformers.AutoModelForTableQuestionAnswering"),d(fm,"class","relative group"),d(hee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(uee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(pee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(_ee,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),d(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(bC,"id","transformers.AutoModelForDocumentQuestionAnswering"),d(bC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(bC,"href","#transformers.AutoModelForDocumentQuestionAnswering"),d(um,"class","relative group"),d(bee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(vee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Fee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Tee,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering"),d(Mee,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),d(Eee,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),d(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(wC,"id","transformers.AutoModelForImageClassification"),d(wC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(wC,"href","#transformers.AutoModelForImageClassification"),d(vm,"class","relative group"),d(Cee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(wee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Aee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Lee,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification"),d(yee,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification"),d(xee,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification"),d($ee,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),d(kee,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification"),d(See,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),d(Ree,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),d(Pee,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification"),d(Bee,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),d(Iee,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification"),d(Nee,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),d(qee,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),d(jee,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),d(Dee,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),d(Gee,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification"),d(Oee,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification"),d(Vee,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification"),d(Xee,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification"),d(zee,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification"),d(Qee,"href","/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification"),d(Wee,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification"),d(Uee,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification"),d(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(XC,"id","transformers.AutoModelForVideoClassification"),d(XC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(XC,"href","#transformers.AutoModelForVideoClassification"),d(Mm,"class","relative group"),d(Hee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Jee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Yee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Zee,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification"),d(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(HC,"id","transformers.AutoModelForVision2Seq"),d(HC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(HC,"href","#transformers.AutoModelForVision2Seq"),d(wm,"class","relative group"),d(Kee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(eoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(ooe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(roe,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),d(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(e3,"id","transformers.AutoModelForVisualQuestionAnswering"),d(e3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(e3,"href","#transformers.AutoModelForVisualQuestionAnswering"),d(ym,"class","relative group"),d(toe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(aoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(noe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(soe,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),d(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(n3,"id","transformers.AutoModelForAudioClassification"),d(n3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(n3,"href","#transformers.AutoModelForAudioClassification"),d(km,"class","relative group"),d(loe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ioe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(doe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(moe,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),d(coe,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification"),d(foe,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification"),d(goe,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),d(hoe,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),d(uoe,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),d(poe,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),d(_oe,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),d(boe,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),d(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(b3,"id","transformers.AutoModelForAudioFrameClassification"),d(b3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(b3,"href","#transformers.AutoModelForAudioFrameClassification"),d(Pm,"class","relative group"),d(voe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Foe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Toe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Moe,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),d(Eoe,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),d(Coe,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),d(woe,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),d(Aoe,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),d(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(L3,"id","transformers.AutoModelForCTC"),d(L3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(L3,"href","#transformers.AutoModelForCTC"),d(Nm,"class","relative group"),d(Loe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(yoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(xoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d($oe,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),d(koe,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC"),d(Soe,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC"),d(Roe,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC"),d(Poe,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC"),d(Boe,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC"),d(Ioe,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),d(Noe,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),d(qoe,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),d(joe,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC"),d(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(G3,"id","transformers.AutoModelForSpeechSeq2Seq"),d(G3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(G3,"href","#transformers.AutoModelForSpeechSeq2Seq"),d(Dm,"class","relative group"),d(Doe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Goe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Ooe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Voe,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),d(Xoe,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),d(zoe,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperForConditionalGeneration"),d(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(U3,"id","transformers.AutoModelForAudioXVector"),d(U3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(U3,"href","#transformers.AutoModelForAudioXVector"),d(Xm,"class","relative group"),d(Qoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Woe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Uoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Hoe,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),d(Joe,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),d(Yoe,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),d(Zoe,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),d(Koe,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector"),d(To,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(t5,"id","transformers.AutoModelForMaskedImageModeling"),d(t5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(t5,"href","#transformers.AutoModelForMaskedImageModeling"),d(Wm,"class","relative group"),d(ere,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ore,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(rre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(tre,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),d(are,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),d(nre,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling"),d(sre,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),d(Mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(c5,"id","transformers.AutoModelForObjectDetection"),d(c5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(c5,"href","#transformers.AutoModelForObjectDetection"),d(Jm,"class","relative group"),d(lre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ire,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(dre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(mre,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection"),d(cre,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection"),d(fre,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection"),d(gre,"href","/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerForObjectDetection"),d(hre,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection"),d(Eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(F5,"id","transformers.AutoModelForImageSegmentation"),d(F5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(F5,"href","#transformers.AutoModelForImageSegmentation"),d(Km,"class","relative group"),d(ure,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(pre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(_re,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(bre,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation"),d(Co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(w5,"id","transformers.AutoModelForSemanticSegmentation"),d(w5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(w5,"href","#transformers.AutoModelForSemanticSegmentation"),d(rc,"class","relative group"),d(vre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Fre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Tre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Mre,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),d(Ere,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),d(Cre,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),d(wre,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation"),d(Are,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),d(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(P5,"id","transformers.AutoModelForInstanceSegmentation"),d(P5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(P5,"href","#transformers.AutoModelForInstanceSegmentation"),d(nc,"class","relative group"),d(Lre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(yre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(xre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d($re,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),d(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(j5,"id","transformers.AutoModelForZeroShotObjectDetection"),d(j5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(j5,"href","#transformers.AutoModelForZeroShotObjectDetection"),d(ic,"class","relative group"),d(kre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Sre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Rre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Pre,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTForObjectDetection"),d(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(X5,"id","transformers.TFAutoModel"),d(X5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(X5,"href","#transformers.TFAutoModel"),d(cc,"class","relative group"),d(Bre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ire,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Nre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(qre,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel"),d(jre,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel"),d(Dre,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel"),d(Gre,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),d(Ore,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),d(Vre,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel"),d(Xre,"href","/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel"),d(zre,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel"),d(Qre,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel"),d(Wre,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel"),d(Ure,"href","/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtModel"),d(Hre,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),d(Jre,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel"),d(Yre,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),d(Zre,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel"),d(Kre,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel"),d(ete,"href","/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),d(ote,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel"),d(rte,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmModel"),d(tte,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel"),d(ate,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel"),d(nte,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel"),d(ste,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model"),d(lte,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel"),d(ite,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.TFGroupViTModel"),d(dte,"href","/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel"),d(mte,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),d(cte,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model"),d(fte,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel"),d(gte,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel"),d(hte,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel"),d(ute,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel"),d(pte,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel"),d(_te,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel"),d(bte,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel"),d(vte,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel"),d(Fte,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model"),d(Tte,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),d(Mte,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel"),d(Ete,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel"),d(Cte,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel"),d(wte,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel"),d(Ate,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel"),d(Lte,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel"),d(yte,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel"),d(xte,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel"),d($te,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),d(kte,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel"),d(Ste,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model"),d(Rte,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel"),d(Pte,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),d(Bte,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel"),d(Ite,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel"),d(Nte,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),d(qte,"href","/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperModel"),d(jte,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel"),d(Dte,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel"),d(Gte,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),d(Ote,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel"),d(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(J0,"id","transformers.TFAutoModelForPreTraining"),d(J0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(J0,"href","#transformers.TFAutoModelForPreTraining"),d(hc,"class","relative group"),d(Vte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Xte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(zte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Qte,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining"),d(Wte,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),d(Ute,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining"),d(Hte,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),d(Jte,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),d(Yte,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),d(Zte,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining"),d(Kte,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),d(eae,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),d(oae,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),d(rae,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),d(tae,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),d(aae,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),d(nae,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),d(sae,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),d(lae,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),d(iae,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),d(dae,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),d(mae,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),d(cae,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),d(fae,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),d(gae,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),d(hae,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),d(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Mw,"id","transformers.TFAutoModelForCausalLM"),d(Mw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Mw,"href","#transformers.TFAutoModelForCausalLM"),d(_c,"class","relative group"),d(uae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(pae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(_ae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(bae,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel"),d(vae,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),d(Fae,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),d(Tae,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),d(Mae,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),d(Eae,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),d(Cae,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM"),d(wae,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),d(Aae,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),d(Lae,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),d(yae,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),d(xae,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM"),d($ae,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),d(kae,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),d(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(jw,"id","transformers.TFAutoModelForImageClassification"),d(jw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(jw,"href","#transformers.TFAutoModelForImageClassification"),d(Fc,"class","relative group"),d(Sae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Rae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Pae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Bae,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),d(Iae,"href","/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtForImageClassification"),d(Nae,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),d(qae,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification"),d(jae,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher"),d(Dae,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification"),d(Gae,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification"),d(Oae,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification"),d(Vae,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification"),d(Xae,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification"),d(zae,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification"),d(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Yw,"id","transformers.TFAutoModelForSemanticSegmentation"),d(Yw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Yw,"href","#transformers.TFAutoModelForSemanticSegmentation"),d(Ec,"class","relative group"),d(Qae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Wae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Uae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Hae,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation"),d(Jae,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation"),d(Yae,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation"),d(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(tA,"id","transformers.TFAutoModelForMaskedLM"),d(tA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(tA,"href","#transformers.TFAutoModelForMaskedLM"),d(Lc,"class","relative group"),d(Zae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Kae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(ene,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ra,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(one,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),d(rne,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM"),d(tne,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),d(ane,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),d(nne,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),d(sne,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),d(lne,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),d(ine,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM"),d(dne,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForMaskedLM"),d(mne,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),d(cne,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),d(fne,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),d(gne,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),d(hne,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),d(une,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),d(pne,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),d(_ne,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),d(bne,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),d(vne,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),d(Fne,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),d(Tne,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),d(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(LA,"id","transformers.TFAutoModelForSeq2SeqLM"),d(LA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(LA,"href","#transformers.TFAutoModelForSeq2SeqLM"),d($c,"class","relative group"),d(Mne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ene,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Cne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(wne,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),d(Ane,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),d(Lne,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),d(yne,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),d(xne,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),d($ne,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel"),d(kne,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),d(Sne,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),d(Rne,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),d(Pne,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),d(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(DA,"id","transformers.TFAutoModelForSequenceClassification"),d(DA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(DA,"href","#transformers.TFAutoModelForSequenceClassification"),d(Rc,"class","relative group"),d(Bne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ine,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Nne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(aa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(qne,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),d(jne,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification"),d(Dne,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),d(Gne,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),d(One,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),d(Vne,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),d(Xne,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),d(zne,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),d(Qne,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),d(Wne,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForSequenceClassification"),d(Une,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),d(Hne,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),d(Jne,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),d(Yne,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),d(Zne,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),d(Kne,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification"),d(ese,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),d(ose,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),d(rse,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),d(tse,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),d(ase,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),d(nse,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),d(sse,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),d(lse,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),d(ise,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),d(dse,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),d(mse,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),d(cse,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),d(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(_6,"id","transformers.TFAutoModelForMultipleChoice"),d(_6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(_6,"href","#transformers.TFAutoModelForMultipleChoice"),d(Ic,"class","relative group"),d(fse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(gse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(hse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(na,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(use,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),d(pse,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice"),d(_se,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),d(bse,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),d(vse,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),d(Fse,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),d(Tse,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),d(Mse,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),d(Ese,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),d(Cse,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),d(wse,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),d(Ase,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),d(Lse,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),d(yse,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),d(xse,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),d($se,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),d(kse,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),d(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(N6,"id","transformers.TFAutoModelForNextSentencePrediction"),d(N6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(N6,"href","#transformers.TFAutoModelForNextSentencePrediction"),d(jc,"class","relative group"),d(Sse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Rse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Pse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(sa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Bse,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),d(Ise,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),d(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(O6,"id","transformers.TFAutoModelForTableQuestionAnswering"),d(O6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(O6,"href","#transformers.TFAutoModelForTableQuestionAnswering"),d(Oc,"class","relative group"),d(Nse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(qse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(jse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(la,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Dse,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),d(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Q6,"id","transformers.TFAutoModelForDocumentQuestionAnswering"),d(Q6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Q6,"href","#transformers.TFAutoModelForDocumentQuestionAnswering"),d(zc,"class","relative group"),d(Gse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ose,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Vse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ia,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Xse,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering"),d(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(J6,"id","transformers.TFAutoModelForTokenClassification"),d(J6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(J6,"href","#transformers.TFAutoModelForTokenClassification"),d(Uc,"class","relative group"),d(zse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Qse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Wse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(da,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Use,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),d(Hse,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification"),d(Jse,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),d(Yse,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),d(Zse,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),d(Kse,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),d(ele,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),d(ole,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification"),d(rle,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForTokenClassification"),d(tle,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),d(ale,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),d(nle,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),d(sle,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification"),d(lle,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),d(ile,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),d(dle,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),d(mle,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),d(cle,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),d(fle,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),d(gle,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),d(hle,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),d(ule,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),d(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(T7,"id","transformers.TFAutoModelForQuestionAnswering"),d(T7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(T7,"href","#transformers.TFAutoModelForQuestionAnswering"),d(Yc,"class","relative group"),d(ple,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(_le,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(ble,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ma,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(vle,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),d(Fle,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),d(Tle,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),d(Mle,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),d(Ele,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),d(Cle,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),d(wle,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),d(Ale,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),d(Lle,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),d(yle,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),d(xle,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),d($le,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering"),d(kle,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),d(Sle,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),d(Rle,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),d(Ple,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),d(Ble,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),d(Ile,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),d(Nle,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),d(qle,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),d(jle,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),d(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(z7,"id","transformers.TFAutoModelForVision2Seq"),d(z7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(z7,"href","#transformers.TFAutoModelForVision2Seq"),d(ef,"class","relative group"),d(Dle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Gle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Ole,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ca,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Vle,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),d(et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(H7,"id","transformers.TFAutoModelForSpeechSeq2Seq"),d(H7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(H7,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),d(tf,"class","relative group"),d(Xle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(zle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Qle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(fa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Wle,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),d(Ule,"href","/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration"),d(ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(e8,"id","transformers.FlaxAutoModel"),d(e8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(e8,"href","#transformers.FlaxAutoModel"),d(sf,"class","relative group"),d(Hle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Jle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Yle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ga,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Zle,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel"),d(Kle,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel"),d(eie,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel"),d(oie,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel"),d(rie,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),d(tie,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),d(aie,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),d(nie,"href","/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel"),d(sie,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),d(lie,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel"),d(iie,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model"),d(die,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),d(mie,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel"),d(cie,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model"),d(fie,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel"),d(gie,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel"),d(hie,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model"),d(uie,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel"),d(pie,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel"),d(_ie,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel"),d(bie,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel"),d(vie,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model"),d(Fie,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),d(Tie,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel"),d(Mie,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),d(Eie,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel"),d(Cie,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),d(rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d($8,"id","transformers.FlaxAutoModelForCausalLM"),d($8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d($8,"href","#transformers.FlaxAutoModelForCausalLM"),d(mf,"class","relative group"),d(wie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Aie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Lie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ha,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(yie,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM"),d(xie,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM"),d($ie,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),d(kie,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),d(Sie,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),d(Rie,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),d(Pie,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),d(Bie,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),d(Iie,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),d(Nie,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),d(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(V8,"id","transformers.FlaxAutoModelForPreTraining"),d(V8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(V8,"href","#transformers.FlaxAutoModelForPreTraining"),d(gf,"class","relative group"),d(qie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(jie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Die,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ua,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Gie,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),d(Oie,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),d(Vie,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining"),d(Xie,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),d(zie,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),d(Qie,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),d(Wie,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),d(Uie,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),d(Hie,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),d(Jie,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),d(Yie,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),d(Zie,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),d(Kie,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),d(at,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(nL,"id","transformers.FlaxAutoModelForMaskedLM"),d(nL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(nL,"href","#transformers.FlaxAutoModelForMaskedLM"),d(pf,"class","relative group"),d(ede,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ode,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(rde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(pa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(tde,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),d(ade,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),d(nde,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),d(sde,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),d(lde,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),d(ide,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),d(dde,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),d(mde,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),d(cde,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),d(fde,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),d(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(bL,"id","transformers.FlaxAutoModelForSeq2SeqLM"),d(bL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(bL,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),d(vf,"class","relative group"),d(gde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(hde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(ude,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(_a,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(pde,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),d(_de,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),d(bde,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),d(vde,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),d(Fde,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),d(Tde,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel"),d(Mde,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),d(Ede,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),d(Cde,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),d(wde,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),d(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(kL,"id","transformers.FlaxAutoModelForSequenceClassification"),d(kL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(kL,"href","#transformers.FlaxAutoModelForSequenceClassification"),d(Mf,"class","relative group"),d(Ade,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Lde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(yde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ba,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(xde,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),d($de,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),d(kde,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),d(Sde,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),d(Rde,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),d(Pde,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),d(Bde,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),d(Ide,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),d(Nde,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),d(qde,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),d(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(XL,"id","transformers.FlaxAutoModelForQuestionAnswering"),d(XL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(XL,"href","#transformers.FlaxAutoModelForQuestionAnswering"),d(wf,"class","relative group"),d(jde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Dde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Gde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(va,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ode,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),d(Vde,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),d(Xde,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),d(zde,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),d(Qde,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),d(Wde,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),d(Ude,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),d(Hde,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),d(Jde,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),d(Yde,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),d(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ty,"id","transformers.FlaxAutoModelForTokenClassification"),d(ty,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ty,"href","#transformers.FlaxAutoModelForTokenClassification"),d(yf,"class","relative group"),d(Zde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Kde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(eme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Fa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ome,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),d(rme,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),d(tme,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),d(ame,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),d(nme,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),d(sme,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),d(lme,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),d(ime,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),d(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(hy,"id","transformers.FlaxAutoModelForMultipleChoice"),d(hy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(hy,"href","#transformers.FlaxAutoModelForMultipleChoice"),d(kf,"class","relative group"),d(dme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(mme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(cme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(fme,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),d(gme,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),d(hme,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),d(ume,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),d(pme,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),d(_me,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),d(bme,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),d(vme,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),d(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(wy,"id","transformers.FlaxAutoModelForNextSentencePrediction"),d(wy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(wy,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),d(Pf,"class","relative group"),d(Fme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Tme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Mme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ma,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Eme,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),d(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(xy,"id","transformers.FlaxAutoModelForImageClassification"),d(xy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(xy,"href","#transformers.FlaxAutoModelForImageClassification"),d(Nf,"class","relative group"),d(Cme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(wme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Ame,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Lme,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),d(yme,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification"),d(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Py,"id","transformers.FlaxAutoModelForVision2Seq"),d(Py,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Py,"href","#transformers.FlaxAutoModelForVision2Seq"),d(Df,"class","relative group"),d(xme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d($me,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(kme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ca,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Sme,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),d(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(c,_){e(document.head,g),b(c,v,_),b(c,u,_),e(u,f),e(f,p),M(m,p,null),e(u,h),e(u,$o),e($o,vd),b(c,Qf,_),b(c,Tt,_),e(Tt,Fd),e(Tt,Td),e(Td,v$),e(Tt,Wf),b(c,Xe,_),b(c,He,_),e(He,Md),e(He,ms),e(ms,F$),e(He,cs),e(He,fs),e(fs,T$),e(He,Ed),e(He,gs),e(gs,M$),e(He,Cd),b(c,Uf,_),M(on,c,_),b(c,Je,_),b(c,Ae,_),e(Ae,NN),e(Ae,wd),e(wd,qN),e(Ae,jN),b(c,ko,_),b(c,rn,_),e(rn,DN),e(rn,Hf),e(Hf,GN),e(rn,gdo),b(c,yao,_),b(c,Ad,_),e(Ad,Jf),e(Jf,Gfe),M(E$,Gfe,null),e(Ad,hdo),e(Ad,Ofe),e(Ofe,udo),b(c,xao,_),b(c,hs,_),e(hs,pdo),e(hs,Vfe),e(Vfe,_do),e(hs,bdo),e(hs,Xfe),e(Xfe,vdo),e(hs,Fdo),b(c,$ao,_),M(C$,c,_),b(c,kao,_),b(c,ON,_),e(ON,Tdo),b(c,Sao,_),M(Yf,c,_),b(c,Rao,_),b(c,Ld,_),e(Ld,Zf),e(Zf,zfe),M(w$,zfe,null),e(Ld,Mdo),e(Ld,Qfe),e(Qfe,Edo),b(c,Pao,_),b(c,So,_),M(A$,So,null),e(So,Cdo),e(So,L$),e(L$,wdo),e(L$,VN),e(VN,Ado),e(L$,Ldo),e(So,ydo),e(So,y$),e(y$,xdo),e(y$,Wfe),e(Wfe,$do),e(y$,kdo),e(So,Sdo),e(So,qr),M(x$,qr,null),e(qr,Rdo),e(qr,Ufe),e(Ufe,Pdo),e(qr,Bdo),e(qr,yd),e(yd,Ido),e(yd,Hfe),e(Hfe,Ndo),e(yd,qdo),e(yd,Jfe),e(Jfe,jdo),e(yd,Ddo),e(qr,Gdo),e(qr,A),e(A,Kf),e(Kf,Yfe),e(Yfe,Odo),e(Kf,Vdo),e(Kf,XN),e(XN,Xdo),e(Kf,zdo),e(A,Qdo),e(A,eg),e(eg,Zfe),e(Zfe,Wdo),e(eg,Udo),e(eg,zN),e(zN,Hdo),e(eg,Jdo),e(A,Ydo),e(A,og),e(og,Kfe),e(Kfe,Zdo),e(og,Kdo),e(og,QN),e(QN,emo),e(og,omo),e(A,rmo),e(A,rg),e(rg,ege),e(ege,tmo),e(rg,amo),e(rg,WN),e(WN,nmo),e(rg,smo),e(A,lmo),e(A,tg),e(tg,oge),e(oge,imo),e(tg,dmo),e(tg,UN),e(UN,mmo),e(tg,cmo),e(A,fmo),e(A,ag),e(ag,rge),e(rge,gmo),e(ag,hmo),e(ag,HN),e(HN,umo),e(ag,pmo),e(A,_mo),e(A,ng),e(ng,tge),e(tge,bmo),e(ng,vmo),e(ng,JN),e(JN,Fmo),e(ng,Tmo),e(A,Mmo),e(A,sg),e(sg,age),e(age,Emo),e(sg,Cmo),e(sg,YN),e(YN,wmo),e(sg,Amo),e(A,Lmo),e(A,lg),e(lg,nge),e(nge,ymo),e(lg,xmo),e(lg,ZN),e(ZN,$mo),e(lg,kmo),e(A,Smo),e(A,ig),e(ig,sge),e(sge,Rmo),e(ig,Pmo),e(ig,KN),e(KN,Bmo),e(ig,Imo),e(A,Nmo),e(A,dg),e(dg,lge),e(lge,qmo),e(dg,jmo),e(dg,eq),e(eq,Dmo),e(dg,Gmo),e(A,Omo),e(A,mg),e(mg,ige),e(ige,Vmo),e(mg,Xmo),e(mg,oq),e(oq,zmo),e(mg,Qmo),e(A,Wmo),e(A,cg),e(cg,dge),e(dge,Umo),e(cg,Hmo),e(cg,rq),e(rq,Jmo),e(cg,Ymo),e(A,Zmo),e(A,fg),e(fg,mge),e(mge,Kmo),e(fg,eco),e(fg,tq),e(tq,oco),e(fg,rco),e(A,tco),e(A,gg),e(gg,cge),e(cge,aco),e(gg,nco),e(gg,aq),e(aq,sco),e(gg,lco),e(A,ico),e(A,hg),e(hg,fge),e(fge,dco),e(hg,mco),e(hg,nq),e(nq,cco),e(hg,fco),e(A,gco),e(A,ug),e(ug,gge),e(gge,hco),e(ug,uco),e(ug,sq),e(sq,pco),e(ug,_co),e(A,bco),e(A,pg),e(pg,hge),e(hge,vco),e(pg,Fco),e(pg,lq),e(lq,Tco),e(pg,Mco),e(A,Eco),e(A,_g),e(_g,uge),e(uge,Cco),e(_g,wco),e(_g,iq),e(iq,Aco),e(_g,Lco),e(A,yco),e(A,bg),e(bg,pge),e(pge,xco),e(bg,$co),e(bg,dq),e(dq,kco),e(bg,Sco),e(A,Rco),e(A,vg),e(vg,_ge),e(_ge,Pco),e(vg,Bco),e(vg,mq),e(mq,Ico),e(vg,Nco),e(A,qco),e(A,Fg),e(Fg,bge),e(bge,jco),e(Fg,Dco),e(Fg,cq),e(cq,Gco),e(Fg,Oco),e(A,Vco),e(A,Tg),e(Tg,vge),e(vge,Xco),e(Tg,zco),e(Tg,fq),e(fq,Qco),e(Tg,Wco),e(A,Uco),e(A,Mg),e(Mg,Fge),e(Fge,Hco),e(Mg,Jco),e(Mg,gq),e(gq,Yco),e(Mg,Zco),e(A,Kco),e(A,Eg),e(Eg,Tge),e(Tge,efo),e(Eg,ofo),e(Eg,hq),e(hq,rfo),e(Eg,tfo),e(A,afo),e(A,Cg),e(Cg,Mge),e(Mge,nfo),e(Cg,sfo),e(Cg,uq),e(uq,lfo),e(Cg,ifo),e(A,dfo),e(A,wg),e(wg,Ege),e(Ege,mfo),e(wg,cfo),e(wg,pq),e(pq,ffo),e(wg,gfo),e(A,hfo),e(A,Ag),e(Ag,Cge),e(Cge,ufo),e(Ag,pfo),e(Ag,_q),e(_q,_fo),e(Ag,bfo),e(A,vfo),e(A,Lg),e(Lg,wge),e(wge,Ffo),e(Lg,Tfo),e(Lg,bq),e(bq,Mfo),e(Lg,Efo),e(A,Cfo),e(A,yg),e(yg,Age),e(Age,wfo),e(yg,Afo),e(yg,vq),e(vq,Lfo),e(yg,yfo),e(A,xfo),e(A,xg),e(xg,Lge),e(Lge,$fo),e(xg,kfo),e(xg,Fq),e(Fq,Sfo),e(xg,Rfo),e(A,Pfo),e(A,$g),e($g,yge),e(yge,Bfo),e($g,Ifo),e($g,Tq),e(Tq,Nfo),e($g,qfo),e(A,jfo),e(A,kg),e(kg,xge),e(xge,Dfo),e(kg,Gfo),e(kg,Mq),e(Mq,Ofo),e(kg,Vfo),e(A,Xfo),e(A,Sg),e(Sg,$ge),e($ge,zfo),e(Sg,Qfo),e(Sg,Eq),e(Eq,Wfo),e(Sg,Ufo),e(A,Hfo),e(A,Rg),e(Rg,kge),e(kge,Jfo),e(Rg,Yfo),e(Rg,Cq),e(Cq,Zfo),e(Rg,Kfo),e(A,ego),e(A,Pg),e(Pg,Sge),e(Sge,ogo),e(Pg,rgo),e(Pg,wq),e(wq,tgo),e(Pg,ago),e(A,ngo),e(A,Bg),e(Bg,Rge),e(Rge,sgo),e(Bg,lgo),e(Bg,Aq),e(Aq,igo),e(Bg,dgo),e(A,mgo),e(A,Ig),e(Ig,Pge),e(Pge,cgo),e(Ig,fgo),e(Ig,Lq),e(Lq,ggo),e(Ig,hgo),e(A,ugo),e(A,Ng),e(Ng,Bge),e(Bge,pgo),e(Ng,_go),e(Ng,yq),e(yq,bgo),e(Ng,vgo),e(A,Fgo),e(A,qg),e(qg,Ige),e(Ige,Tgo),e(qg,Mgo),e(qg,xq),e(xq,Ego),e(qg,Cgo),e(A,wgo),e(A,jg),e(jg,Nge),e(Nge,Ago),e(jg,Lgo),e(jg,$q),e($q,ygo),e(jg,xgo),e(A,$go),e(A,Dg),e(Dg,qge),e(qge,kgo),e(Dg,Sgo),e(Dg,kq),e(kq,Rgo),e(Dg,Pgo),e(A,Bgo),e(A,Gg),e(Gg,jge),e(jge,Igo),e(Gg,Ngo),e(Gg,Sq),e(Sq,qgo),e(Gg,jgo),e(A,Dgo),e(A,Og),e(Og,Dge),e(Dge,Ggo),e(Og,Ogo),e(Og,Rq),e(Rq,Vgo),e(Og,Xgo),e(A,zgo),e(A,Vg),e(Vg,Gge),e(Gge,Qgo),e(Vg,Wgo),e(Vg,Pq),e(Pq,Ugo),e(Vg,Hgo),e(A,Jgo),e(A,Xg),e(Xg,Oge),e(Oge,Ygo),e(Xg,Zgo),e(Xg,Bq),e(Bq,Kgo),e(Xg,eho),e(A,oho),e(A,zg),e(zg,Vge),e(Vge,rho),e(zg,tho),e(zg,Iq),e(Iq,aho),e(zg,nho),e(A,sho),e(A,Qg),e(Qg,Xge),e(Xge,lho),e(Qg,iho),e(Qg,Nq),e(Nq,dho),e(Qg,mho),e(A,cho),e(A,Wg),e(Wg,zge),e(zge,fho),e(Wg,gho),e(Wg,qq),e(qq,hho),e(Wg,uho),e(A,pho),e(A,Ug),e(Ug,Qge),e(Qge,_ho),e(Ug,bho),e(Ug,jq),e(jq,vho),e(Ug,Fho),e(A,Tho),e(A,Hg),e(Hg,Wge),e(Wge,Mho),e(Hg,Eho),e(Hg,Dq),e(Dq,Cho),e(Hg,who),e(A,Aho),e(A,Jg),e(Jg,Uge),e(Uge,Lho),e(Jg,yho),e(Jg,Gq),e(Gq,xho),e(Jg,$ho),e(A,kho),e(A,Yg),e(Yg,Hge),e(Hge,Sho),e(Yg,Rho),e(Yg,Oq),e(Oq,Pho),e(Yg,Bho),e(A,Iho),e(A,Zg),e(Zg,Jge),e(Jge,Nho),e(Zg,qho),e(Zg,Vq),e(Vq,jho),e(Zg,Dho),e(A,Gho),e(A,Kg),e(Kg,Yge),e(Yge,Oho),e(Kg,Vho),e(Kg,Xq),e(Xq,Xho),e(Kg,zho),e(A,Qho),e(A,eh),e(eh,Zge),e(Zge,Who),e(eh,Uho),e(eh,zq),e(zq,Hho),e(eh,Jho),e(A,Yho),e(A,oh),e(oh,Kge),e(Kge,Zho),e(oh,Kho),e(oh,Qq),e(Qq,euo),e(oh,ouo),e(A,ruo),e(A,rh),e(rh,ehe),e(ehe,tuo),e(rh,auo),e(rh,Wq),e(Wq,nuo),e(rh,suo),e(A,luo),e(A,th),e(th,ohe),e(ohe,iuo),e(th,duo),e(th,Uq),e(Uq,muo),e(th,cuo),e(A,fuo),e(A,ah),e(ah,rhe),e(rhe,guo),e(ah,huo),e(ah,Hq),e(Hq,uuo),e(ah,puo),e(A,_uo),e(A,nh),e(nh,the),e(the,buo),e(nh,vuo),e(nh,Jq),e(Jq,Fuo),e(nh,Tuo),e(A,Muo),e(A,sh),e(sh,ahe),e(ahe,Euo),e(sh,Cuo),e(sh,Yq),e(Yq,wuo),e(sh,Auo),e(A,Luo),e(A,lh),e(lh,nhe),e(nhe,yuo),e(lh,xuo),e(lh,Zq),e(Zq,$uo),e(lh,kuo),e(A,Suo),e(A,ih),e(ih,she),e(she,Ruo),e(ih,Puo),e(ih,Kq),e(Kq,Buo),e(ih,Iuo),e(A,Nuo),e(A,dh),e(dh,lhe),e(lhe,quo),e(dh,juo),e(dh,ej),e(ej,Duo),e(dh,Guo),e(A,Ouo),e(A,mh),e(mh,ihe),e(ihe,Vuo),e(mh,Xuo),e(mh,oj),e(oj,zuo),e(mh,Quo),e(A,Wuo),e(A,ch),e(ch,dhe),e(dhe,Uuo),e(ch,Huo),e(ch,rj),e(rj,Juo),e(ch,Yuo),e(A,Zuo),e(A,fh),e(fh,mhe),e(mhe,Kuo),e(fh,epo),e(fh,tj),e(tj,opo),e(fh,rpo),e(A,tpo),e(A,gh),e(gh,che),e(che,apo),e(gh,npo),e(gh,aj),e(aj,spo),e(gh,lpo),e(A,ipo),e(A,hh),e(hh,fhe),e(fhe,dpo),e(hh,mpo),e(hh,nj),e(nj,cpo),e(hh,fpo),e(A,gpo),e(A,uh),e(uh,ghe),e(ghe,hpo),e(uh,upo),e(uh,sj),e(sj,ppo),e(uh,_po),e(A,bpo),e(A,ph),e(ph,hhe),e(hhe,vpo),e(ph,Fpo),e(ph,lj),e(lj,Tpo),e(ph,Mpo),e(A,Epo),e(A,_h),e(_h,uhe),e(uhe,Cpo),e(_h,wpo),e(_h,ij),e(ij,Apo),e(_h,Lpo),e(A,ypo),e(A,bh),e(bh,phe),e(phe,xpo),e(bh,$po),e(bh,dj),e(dj,kpo),e(bh,Spo),e(A,Rpo),e(A,vh),e(vh,_he),e(_he,Ppo),e(vh,Bpo),e(vh,mj),e(mj,Ipo),e(vh,Npo),e(A,qpo),e(A,Fh),e(Fh,bhe),e(bhe,jpo),e(Fh,Dpo),e(Fh,cj),e(cj,Gpo),e(Fh,Opo),e(A,Vpo),e(A,Th),e(Th,vhe),e(vhe,Xpo),e(Th,zpo),e(Th,fj),e(fj,Qpo),e(Th,Wpo),e(A,Upo),e(A,Mh),e(Mh,Fhe),e(Fhe,Hpo),e(Mh,Jpo),e(Mh,gj),e(gj,Ypo),e(Mh,Zpo),e(A,Kpo),e(A,Eh),e(Eh,The),e(The,e_o),e(Eh,o_o),e(Eh,hj),e(hj,r_o),e(Eh,t_o),e(A,a_o),e(A,Ch),e(Ch,Mhe),e(Mhe,n_o),e(Ch,s_o),e(Ch,uj),e(uj,l_o),e(Ch,i_o),e(A,d_o),e(A,wh),e(wh,Ehe),e(Ehe,m_o),e(wh,c_o),e(wh,pj),e(pj,f_o),e(wh,g_o),e(A,h_o),e(A,Ah),e(Ah,Che),e(Che,u_o),e(Ah,p_o),e(Ah,_j),e(_j,__o),e(Ah,b_o),e(A,v_o),e(A,Lh),e(Lh,whe),e(whe,F_o),e(Lh,T_o),e(Lh,bj),e(bj,M_o),e(Lh,E_o),e(A,C_o),e(A,yh),e(yh,Ahe),e(Ahe,w_o),e(yh,A_o),e(yh,vj),e(vj,L_o),e(yh,y_o),e(A,x_o),e(A,xh),e(xh,Lhe),e(Lhe,$_o),e(xh,k_o),e(xh,Fj),e(Fj,S_o),e(xh,R_o),e(A,P_o),e(A,$h),e($h,yhe),e(yhe,B_o),e($h,I_o),e($h,Tj),e(Tj,N_o),e($h,q_o),e(A,j_o),e(A,kh),e(kh,xhe),e(xhe,D_o),e(kh,G_o),e(kh,Mj),e(Mj,O_o),e(kh,V_o),e(A,X_o),e(A,Sh),e(Sh,$he),e($he,z_o),e(Sh,Q_o),e(Sh,Ej),e(Ej,W_o),e(Sh,U_o),e(A,H_o),e(A,Rh),e(Rh,khe),e(khe,J_o),e(Rh,Y_o),e(Rh,Cj),e(Cj,Z_o),e(Rh,K_o),e(A,e1o),e(A,Ph),e(Ph,She),e(She,o1o),e(Ph,r1o),e(Ph,wj),e(wj,t1o),e(Ph,a1o),e(A,n1o),e(A,Bh),e(Bh,Rhe),e(Rhe,s1o),e(Bh,l1o),e(Bh,Aj),e(Aj,i1o),e(Bh,d1o),e(A,m1o),e(A,Ih),e(Ih,Phe),e(Phe,c1o),e(Ih,f1o),e(Ih,Lj),e(Lj,g1o),e(Ih,h1o),e(A,u1o),e(A,Nh),e(Nh,Bhe),e(Bhe,p1o),e(Nh,_1o),e(Nh,yj),e(yj,b1o),e(Nh,v1o),e(A,F1o),e(A,qh),e(qh,Ihe),e(Ihe,T1o),e(qh,M1o),e(qh,xj),e(xj,E1o),e(qh,C1o),e(A,w1o),e(A,jh),e(jh,Nhe),e(Nhe,A1o),e(jh,L1o),e(jh,$j),e($j,y1o),e(jh,x1o),e(A,$1o),e(A,Dh),e(Dh,qhe),e(qhe,k1o),e(Dh,S1o),e(Dh,kj),e(kj,R1o),e(Dh,P1o),e(A,B1o),e(A,Gh),e(Gh,jhe),e(jhe,I1o),e(Gh,N1o),e(Gh,Sj),e(Sj,q1o),e(Gh,j1o),e(A,D1o),e(A,Oh),e(Oh,Dhe),e(Dhe,G1o),e(Oh,O1o),e(Oh,Rj),e(Rj,V1o),e(Oh,X1o),e(A,z1o),e(A,Vh),e(Vh,Ghe),e(Ghe,Q1o),e(Vh,W1o),e(Vh,Pj),e(Pj,U1o),e(Vh,H1o),e(A,J1o),e(A,Xh),e(Xh,Ohe),e(Ohe,Y1o),e(Xh,Z1o),e(Xh,Bj),e(Bj,K1o),e(Xh,e2o),e(A,o2o),e(A,zh),e(zh,Vhe),e(Vhe,r2o),e(zh,t2o),e(zh,Ij),e(Ij,a2o),e(zh,n2o),e(A,s2o),e(A,Qh),e(Qh,Xhe),e(Xhe,l2o),e(Qh,i2o),e(Qh,Nj),e(Nj,d2o),e(Qh,m2o),e(A,c2o),e(A,Wh),e(Wh,zhe),e(zhe,f2o),e(Wh,g2o),e(Wh,qj),e(qj,h2o),e(Wh,u2o),e(A,p2o),e(A,Uh),e(Uh,Qhe),e(Qhe,_2o),e(Uh,b2o),e(Uh,jj),e(jj,v2o),e(Uh,F2o),e(A,T2o),e(A,Hh),e(Hh,Whe),e(Whe,M2o),e(Hh,E2o),e(Hh,Dj),e(Dj,C2o),e(Hh,w2o),e(A,A2o),e(A,Jh),e(Jh,Uhe),e(Uhe,L2o),e(Jh,y2o),e(Jh,Gj),e(Gj,x2o),e(Jh,$2o),e(A,k2o),e(A,Yh),e(Yh,Hhe),e(Hhe,S2o),e(Yh,R2o),e(Yh,Oj),e(Oj,P2o),e(Yh,B2o),e(A,I2o),e(A,Zh),e(Zh,Jhe),e(Jhe,N2o),e(Zh,q2o),e(Zh,Vj),e(Vj,j2o),e(Zh,D2o),e(A,G2o),e(A,Kh),e(Kh,Yhe),e(Yhe,O2o),e(Kh,V2o),e(Kh,Xj),e(Xj,X2o),e(Kh,z2o),e(A,Q2o),e(A,eu),e(eu,Zhe),e(Zhe,W2o),e(eu,U2o),e(eu,zj),e(zj,H2o),e(eu,J2o),e(A,Y2o),e(A,ou),e(ou,Khe),e(Khe,Z2o),e(ou,K2o),e(ou,Qj),e(Qj,ebo),e(ou,obo),e(A,rbo),e(A,ru),e(ru,eue),e(eue,tbo),e(ru,abo),e(ru,Wj),e(Wj,nbo),e(ru,sbo),e(A,lbo),e(A,tu),e(tu,oue),e(oue,ibo),e(tu,dbo),e(tu,Uj),e(Uj,mbo),e(tu,cbo),e(A,fbo),e(A,au),e(au,rue),e(rue,gbo),e(au,hbo),e(au,Hj),e(Hj,ubo),e(au,pbo),e(A,_bo),e(A,nu),e(nu,tue),e(tue,bbo),e(nu,vbo),e(nu,Jj),e(Jj,Fbo),e(nu,Tbo),e(A,Mbo),e(A,su),e(su,aue),e(aue,Ebo),e(su,Cbo),e(su,Yj),e(Yj,wbo),e(su,Abo),e(A,Lbo),e(A,lu),e(lu,nue),e(nue,ybo),e(lu,xbo),e(lu,Zj),e(Zj,$bo),e(lu,kbo),e(A,Sbo),e(A,iu),e(iu,sue),e(sue,Rbo),e(iu,Pbo),e(iu,Kj),e(Kj,Bbo),e(iu,Ibo),e(A,Nbo),e(A,du),e(du,lue),e(lue,qbo),e(du,jbo),e(du,eD),e(eD,Dbo),e(du,Gbo),e(A,Obo),e(A,mu),e(mu,iue),e(iue,Vbo),e(mu,Xbo),e(mu,oD),e(oD,zbo),e(mu,Qbo),e(A,Wbo),e(A,cu),e(cu,due),e(due,Ubo),e(cu,Hbo),e(cu,rD),e(rD,Jbo),e(cu,Ybo),e(A,Zbo),e(A,fu),e(fu,mue),e(mue,Kbo),e(fu,evo),e(fu,tD),e(tD,ovo),e(fu,rvo),e(A,tvo),e(A,gu),e(gu,cue),e(cue,avo),e(gu,nvo),e(gu,aD),e(aD,svo),e(gu,lvo),e(A,ivo),e(A,hu),e(hu,fue),e(fue,dvo),e(hu,mvo),e(hu,nD),e(nD,cvo),e(hu,fvo),e(A,gvo),e(A,uu),e(uu,gue),e(gue,hvo),e(uu,uvo),e(uu,sD),e(sD,pvo),e(uu,_vo),e(A,bvo),e(A,pu),e(pu,hue),e(hue,vvo),e(pu,Fvo),e(pu,lD),e(lD,Tvo),e(pu,Mvo),e(A,Evo),e(A,_u),e(_u,uue),e(uue,Cvo),e(_u,wvo),e(_u,iD),e(iD,Avo),e(_u,Lvo),e(A,yvo),e(A,bu),e(bu,pue),e(pue,xvo),e(bu,$vo),e(bu,dD),e(dD,kvo),e(bu,Svo),e(A,Rvo),e(A,vu),e(vu,_ue),e(_ue,Pvo),e(vu,Bvo),e(vu,mD),e(mD,Ivo),e(vu,Nvo),e(A,qvo),e(A,Fu),e(Fu,bue),e(bue,jvo),e(Fu,Dvo),e(Fu,cD),e(cD,Gvo),e(Fu,Ovo),e(A,Vvo),e(A,Tu),e(Tu,vue),e(vue,Xvo),e(Tu,zvo),e(Tu,fD),e(fD,Qvo),e(Tu,Wvo),e(A,Uvo),e(A,Mu),e(Mu,Fue),e(Fue,Hvo),e(Mu,Jvo),e(Mu,gD),e(gD,Yvo),e(Mu,Zvo),e(A,Kvo),e(A,Eu),e(Eu,Tue),e(Tue,eFo),e(Eu,oFo),e(Eu,hD),e(hD,rFo),e(Eu,tFo),e(A,aFo),e(A,Cu),e(Cu,Mue),e(Mue,nFo),e(Cu,sFo),e(Cu,uD),e(uD,lFo),e(Cu,iFo),e(A,dFo),e(A,wu),e(wu,Eue),e(Eue,mFo),e(wu,cFo),e(wu,pD),e(pD,fFo),e(wu,gFo),e(A,hFo),e(A,Au),e(Au,Cue),e(Cue,uFo),e(Au,pFo),e(Au,_D),e(_D,_Fo),e(Au,bFo),e(A,vFo),e(A,Lu),e(Lu,wue),e(wue,FFo),e(Lu,TFo),e(Lu,bD),e(bD,MFo),e(Lu,EFo),e(qr,CFo),M(yu,qr,null),e(So,wFo),e(So,xu),M($$,xu,null),e(xu,AFo),e(xu,Aue),e(Aue,LFo),b(c,Bao,_),b(c,xd,_),e(xd,$u),e($u,Lue),M(k$,Lue,null),e(xd,yFo),e(xd,yue),e(yue,xFo),b(c,Iao,_),b(c,Ro,_),M(S$,Ro,null),e(Ro,$Fo),e(Ro,R$),e(R$,kFo),e(R$,vD),e(vD,SFo),e(R$,RFo),e(Ro,PFo),e(Ro,P$),e(P$,BFo),e(P$,xue),e(xue,IFo),e(P$,NFo),e(Ro,qFo),e(Ro,jr),M(B$,jr,null),e(jr,jFo),e(jr,$ue),e($ue,DFo),e(jr,GFo),e(jr,tn),e(tn,OFo),e(tn,kue),e(kue,VFo),e(tn,XFo),e(tn,Sue),e(Sue,zFo),e(tn,QFo),e(tn,Rue),e(Rue,WFo),e(tn,UFo),e(jr,HFo),e(jr,k),e(k,us),e(us,Pue),e(Pue,JFo),e(us,YFo),e(us,FD),e(FD,ZFo),e(us,KFo),e(us,TD),e(TD,eTo),e(us,oTo),e(k,rTo),e(k,ps),e(ps,Bue),e(Bue,tTo),e(ps,aTo),e(ps,MD),e(MD,nTo),e(ps,sTo),e(ps,ED),e(ED,lTo),e(ps,iTo),e(k,dTo),e(k,_s),e(_s,Iue),e(Iue,mTo),e(_s,cTo),e(_s,CD),e(CD,fTo),e(_s,gTo),e(_s,wD),e(wD,hTo),e(_s,uTo),e(k,pTo),e(k,ku),e(ku,Nue),e(Nue,_To),e(ku,bTo),e(ku,AD),e(AD,vTo),e(ku,FTo),e(k,TTo),e(k,bs),e(bs,que),e(que,MTo),e(bs,ETo),e(bs,LD),e(LD,CTo),e(bs,wTo),e(bs,yD),e(yD,ATo),e(bs,LTo),e(k,yTo),e(k,Su),e(Su,jue),e(jue,xTo),e(Su,$To),e(Su,xD),e(xD,kTo),e(Su,STo),e(k,RTo),e(k,Ru),e(Ru,Due),e(Due,PTo),e(Ru,BTo),e(Ru,$D),e($D,ITo),e(Ru,NTo),e(k,qTo),e(k,Pu),e(Pu,Gue),e(Gue,jTo),e(Pu,DTo),e(Pu,kD),e(kD,GTo),e(Pu,OTo),e(k,VTo),e(k,vs),e(vs,Oue),e(Oue,XTo),e(vs,zTo),e(vs,SD),e(SD,QTo),e(vs,WTo),e(vs,RD),e(RD,UTo),e(vs,HTo),e(k,JTo),e(k,Fs),e(Fs,Vue),e(Vue,YTo),e(Fs,ZTo),e(Fs,PD),e(PD,KTo),e(Fs,eMo),e(Fs,BD),e(BD,oMo),e(Fs,rMo),e(k,tMo),e(k,Ts),e(Ts,Xue),e(Xue,aMo),e(Ts,nMo),e(Ts,ID),e(ID,sMo),e(Ts,lMo),e(Ts,ND),e(ND,iMo),e(Ts,dMo),e(k,mMo),e(k,Bu),e(Bu,zue),e(zue,cMo),e(Bu,fMo),e(Bu,qD),e(qD,gMo),e(Bu,hMo),e(k,uMo),e(k,Iu),e(Iu,Que),e(Que,pMo),e(Iu,_Mo),e(Iu,jD),e(jD,bMo),e(Iu,vMo),e(k,FMo),e(k,Nu),e(Nu,Wue),e(Wue,TMo),e(Nu,MMo),e(Nu,DD),e(DD,EMo),e(Nu,CMo),e(k,wMo),e(k,Ms),e(Ms,Uue),e(Uue,AMo),e(Ms,LMo),e(Ms,GD),e(GD,yMo),e(Ms,xMo),e(Ms,OD),e(OD,$Mo),e(Ms,kMo),e(k,SMo),e(k,qu),e(qu,Hue),e(Hue,RMo),e(qu,PMo),e(qu,VD),e(VD,BMo),e(qu,IMo),e(k,NMo),e(k,Es),e(Es,Jue),e(Jue,qMo),e(Es,jMo),e(Es,XD),e(XD,DMo),e(Es,GMo),e(Es,zD),e(zD,OMo),e(Es,VMo),e(k,XMo),e(k,Cs),e(Cs,Yue),e(Yue,zMo),e(Cs,QMo),e(Cs,QD),e(QD,WMo),e(Cs,UMo),e(Cs,WD),e(WD,HMo),e(Cs,JMo),e(k,YMo),e(k,ws),e(ws,Zue),e(Zue,ZMo),e(ws,KMo),e(ws,UD),e(UD,eEo),e(ws,oEo),e(ws,HD),e(HD,rEo),e(ws,tEo),e(k,aEo),e(k,As),e(As,Kue),e(Kue,nEo),e(As,sEo),e(As,JD),e(JD,lEo),e(As,iEo),e(As,YD),e(YD,dEo),e(As,mEo),e(k,cEo),e(k,Ls),e(Ls,epe),e(epe,fEo),e(Ls,gEo),e(Ls,ZD),e(ZD,hEo),e(Ls,uEo),e(Ls,KD),e(KD,pEo),e(Ls,_Eo),e(k,bEo),e(k,ju),e(ju,ope),e(ope,vEo),e(ju,FEo),e(ju,eG),e(eG,TEo),e(ju,MEo),e(k,EEo),e(k,ys),e(ys,rpe),e(rpe,CEo),e(ys,wEo),e(ys,oG),e(oG,AEo),e(ys,LEo),e(ys,rG),e(rG,yEo),e(ys,xEo),e(k,$Eo),e(k,xs),e(xs,tpe),e(tpe,kEo),e(xs,SEo),e(xs,tG),e(tG,REo),e(xs,PEo),e(xs,aG),e(aG,BEo),e(xs,IEo),e(k,NEo),e(k,$s),e($s,ape),e(ape,qEo),e($s,jEo),e($s,nG),e(nG,DEo),e($s,GEo),e($s,sG),e(sG,OEo),e($s,VEo),e(k,XEo),e(k,ks),e(ks,npe),e(npe,zEo),e(ks,QEo),e(ks,lG),e(lG,WEo),e(ks,UEo),e(ks,iG),e(iG,HEo),e(ks,JEo),e(k,YEo),e(k,Ss),e(Ss,spe),e(spe,ZEo),e(Ss,KEo),e(Ss,dG),e(dG,e4o),e(Ss,o4o),e(Ss,mG),e(mG,r4o),e(Ss,t4o),e(k,a4o),e(k,Rs),e(Rs,lpe),e(lpe,n4o),e(Rs,s4o),e(Rs,cG),e(cG,l4o),e(Rs,i4o),e(Rs,fG),e(fG,d4o),e(Rs,m4o),e(k,c4o),e(k,Ps),e(Ps,ipe),e(ipe,f4o),e(Ps,g4o),e(Ps,gG),e(gG,h4o),e(Ps,u4o),e(Ps,hG),e(hG,p4o),e(Ps,_4o),e(k,b4o),e(k,Du),e(Du,dpe),e(dpe,v4o),e(Du,F4o),e(Du,uG),e(uG,T4o),e(Du,M4o),e(k,E4o),e(k,Gu),e(Gu,mpe),e(mpe,C4o),e(Gu,w4o),e(Gu,pG),e(pG,A4o),e(Gu,L4o),e(k,y4o),e(k,Bs),e(Bs,cpe),e(cpe,x4o),e(Bs,$4o),e(Bs,_G),e(_G,k4o),e(Bs,S4o),e(Bs,bG),e(bG,R4o),e(Bs,P4o),e(k,B4o),e(k,Ou),e(Ou,fpe),e(fpe,I4o),e(Ou,N4o),e(Ou,vG),e(vG,q4o),e(Ou,j4o),e(k,D4o),e(k,Is),e(Is,gpe),e(gpe,G4o),e(Is,O4o),e(Is,FG),e(FG,V4o),e(Is,X4o),e(Is,TG),e(TG,z4o),e(Is,Q4o),e(k,W4o),e(k,Ns),e(Ns,hpe),e(hpe,U4o),e(Ns,H4o),e(Ns,MG),e(MG,J4o),e(Ns,Y4o),e(Ns,EG),e(EG,Z4o),e(Ns,K4o),e(k,eCo),e(k,qs),e(qs,upe),e(upe,oCo),e(qs,rCo),e(qs,CG),e(CG,tCo),e(qs,aCo),e(qs,wG),e(wG,nCo),e(qs,sCo),e(k,lCo),e(k,Vu),e(Vu,ppe),e(ppe,iCo),e(Vu,dCo),e(Vu,AG),e(AG,mCo),e(Vu,cCo),e(k,fCo),e(k,Xu),e(Xu,_pe),e(_pe,gCo),e(Xu,hCo),e(Xu,LG),e(LG,uCo),e(Xu,pCo),e(k,_Co),e(k,js),e(js,bpe),e(bpe,bCo),e(js,vCo),e(js,yG),e(yG,FCo),e(js,TCo),e(js,xG),e(xG,MCo),e(js,ECo),e(k,CCo),e(k,Ds),e(Ds,vpe),e(vpe,wCo),e(Ds,ACo),e(Ds,$G),e($G,LCo),e(Ds,yCo),e(Ds,kG),e(kG,xCo),e(Ds,$Co),e(k,kCo),e(k,Gs),e(Gs,Fpe),e(Fpe,SCo),e(Gs,RCo),e(Gs,SG),e(SG,PCo),e(Gs,BCo),e(Gs,RG),e(RG,ICo),e(Gs,NCo),e(k,qCo),e(k,zu),e(zu,Tpe),e(Tpe,jCo),e(zu,DCo),e(zu,PG),e(PG,GCo),e(zu,OCo),e(k,VCo),e(k,Os),e(Os,Mpe),e(Mpe,XCo),e(Os,zCo),e(Os,BG),e(BG,QCo),e(Os,WCo),e(Os,IG),e(IG,UCo),e(Os,HCo),e(k,JCo),e(k,Vs),e(Vs,Epe),e(Epe,YCo),e(Vs,ZCo),e(Vs,NG),e(NG,KCo),e(Vs,e3o),e(Vs,qG),e(qG,o3o),e(Vs,r3o),e(k,t3o),e(k,Xs),e(Xs,Cpe),e(Cpe,a3o),e(Xs,n3o),e(Xs,jG),e(jG,s3o),e(Xs,l3o),e(Xs,DG),e(DG,i3o),e(Xs,d3o),e(k,m3o),e(k,zs),e(zs,wpe),e(wpe,c3o),e(zs,f3o),e(zs,GG),e(GG,g3o),e(zs,h3o),e(zs,OG),e(OG,u3o),e(zs,p3o),e(k,_3o),e(k,Qs),e(Qs,Ape),e(Ape,b3o),e(Qs,v3o),e(Qs,VG),e(VG,F3o),e(Qs,T3o),e(Qs,XG),e(XG,M3o),e(Qs,E3o),e(k,C3o),e(k,Ws),e(Ws,Lpe),e(Lpe,w3o),e(Ws,A3o),e(Ws,zG),e(zG,L3o),e(Ws,y3o),e(Ws,QG),e(QG,x3o),e(Ws,$3o),e(k,k3o),e(k,Us),e(Us,ype),e(ype,S3o),e(Us,R3o),e(Us,WG),e(WG,P3o),e(Us,B3o),e(Us,UG),e(UG,I3o),e(Us,N3o),e(k,q3o),e(k,Hs),e(Hs,xpe),e(xpe,j3o),e(Hs,D3o),e(Hs,HG),e(HG,G3o),e(Hs,O3o),e(Hs,JG),e(JG,V3o),e(Hs,X3o),e(k,z3o),e(k,Js),e(Js,$pe),e($pe,Q3o),e(Js,W3o),e(Js,YG),e(YG,U3o),e(Js,H3o),e(Js,ZG),e(ZG,J3o),e(Js,Y3o),e(k,Z3o),e(k,Qu),e(Qu,kpe),e(kpe,K3o),e(Qu,e5o),e(Qu,KG),e(KG,o5o),e(Qu,r5o),e(k,t5o),e(k,Ys),e(Ys,Spe),e(Spe,a5o),e(Ys,n5o),e(Ys,eO),e(eO,s5o),e(Ys,l5o),e(Ys,oO),e(oO,i5o),e(Ys,d5o),e(k,m5o),e(k,Wu),e(Wu,Rpe),e(Rpe,c5o),e(Wu,f5o),e(Wu,rO),e(rO,g5o),e(Wu,h5o),e(k,u5o),e(k,Uu),e(Uu,Ppe),e(Ppe,p5o),e(Uu,_5o),e(Uu,tO),e(tO,b5o),e(Uu,v5o),e(k,F5o),e(k,Zs),e(Zs,Bpe),e(Bpe,T5o),e(Zs,M5o),e(Zs,aO),e(aO,E5o),e(Zs,C5o),e(Zs,nO),e(nO,w5o),e(Zs,A5o),e(k,L5o),e(k,Ks),e(Ks,Ipe),e(Ipe,y5o),e(Ks,x5o),e(Ks,sO),e(sO,$5o),e(Ks,k5o),e(Ks,lO),e(lO,S5o),e(Ks,R5o),e(k,P5o),e(k,el),e(el,Npe),e(Npe,B5o),e(el,I5o),e(el,iO),e(iO,N5o),e(el,q5o),e(el,dO),e(dO,j5o),e(el,D5o),e(k,G5o),e(k,Hu),e(Hu,qpe),e(qpe,O5o),e(Hu,V5o),e(Hu,mO),e(mO,X5o),e(Hu,z5o),e(k,Q5o),e(k,ol),e(ol,jpe),e(jpe,W5o),e(ol,U5o),e(ol,cO),e(cO,H5o),e(ol,J5o),e(ol,fO),e(fO,Y5o),e(ol,Z5o),e(k,K5o),e(k,rl),e(rl,Dpe),e(Dpe,e0o),e(rl,o0o),e(rl,gO),e(gO,r0o),e(rl,t0o),e(rl,hO),e(hO,a0o),e(rl,n0o),e(k,s0o),e(k,tl),e(tl,Gpe),e(Gpe,l0o),e(tl,i0o),e(tl,uO),e(uO,d0o),e(tl,m0o),e(tl,pO),e(pO,c0o),e(tl,f0o),e(k,g0o),e(k,al),e(al,Ope),e(Ope,h0o),e(al,u0o),e(al,_O),e(_O,p0o),e(al,_0o),e(al,bO),e(bO,b0o),e(al,v0o),e(k,F0o),e(k,nl),e(nl,Vpe),e(Vpe,T0o),e(nl,M0o),e(nl,vO),e(vO,E0o),e(nl,C0o),e(nl,FO),e(FO,w0o),e(nl,A0o),e(k,L0o),e(k,sl),e(sl,Xpe),e(Xpe,y0o),e(sl,x0o),e(sl,TO),e(TO,$0o),e(sl,k0o),e(sl,MO),e(MO,S0o),e(sl,R0o),e(k,P0o),e(k,ll),e(ll,zpe),e(zpe,B0o),e(ll,I0o),e(ll,EO),e(EO,N0o),e(ll,q0o),e(ll,CO),e(CO,j0o),e(ll,D0o),e(k,G0o),e(k,il),e(il,Qpe),e(Qpe,O0o),e(il,V0o),e(il,wO),e(wO,X0o),e(il,z0o),e(il,AO),e(AO,Q0o),e(il,W0o),e(k,U0o),e(k,Ju),e(Ju,Wpe),e(Wpe,H0o),e(Ju,J0o),e(Ju,LO),e(LO,Y0o),e(Ju,Z0o),e(k,K0o),e(k,dl),e(dl,Upe),e(Upe,ewo),e(dl,owo),e(dl,yO),e(yO,rwo),e(dl,two),e(dl,xO),e(xO,awo),e(dl,nwo),e(k,swo),e(k,ml),e(ml,Hpe),e(Hpe,lwo),e(ml,iwo),e(ml,$O),e($O,dwo),e(ml,mwo),e(ml,kO),e(kO,cwo),e(ml,fwo),e(k,gwo),e(k,cl),e(cl,Jpe),e(Jpe,hwo),e(cl,uwo),e(cl,SO),e(SO,pwo),e(cl,_wo),e(cl,RO),e(RO,bwo),e(cl,vwo),e(k,Fwo),e(k,Yu),e(Yu,Ype),e(Ype,Two),e(Yu,Mwo),e(Yu,PO),e(PO,Ewo),e(Yu,Cwo),e(k,wwo),e(k,Zu),e(Zu,Zpe),e(Zpe,Awo),e(Zu,Lwo),e(Zu,BO),e(BO,ywo),e(Zu,xwo),e(k,$wo),e(k,Ku),e(Ku,Kpe),e(Kpe,kwo),e(Ku,Swo),e(Ku,IO),e(IO,Rwo),e(Ku,Pwo),e(k,Bwo),e(k,ep),e(ep,e_e),e(e_e,Iwo),e(ep,Nwo),e(ep,NO),e(NO,qwo),e(ep,jwo),e(k,Dwo),e(k,fl),e(fl,o_e),e(o_e,Gwo),e(fl,Owo),e(fl,qO),e(qO,Vwo),e(fl,Xwo),e(fl,jO),e(jO,zwo),e(fl,Qwo),e(k,Wwo),e(k,op),e(op,r_e),e(r_e,Uwo),e(op,Hwo),e(op,DO),e(DO,Jwo),e(op,Ywo),e(k,Zwo),e(k,gl),e(gl,t_e),e(t_e,Kwo),e(gl,eAo),e(gl,GO),e(GO,oAo),e(gl,rAo),e(gl,OO),e(OO,tAo),e(gl,aAo),e(k,nAo),e(k,hl),e(hl,a_e),e(a_e,sAo),e(hl,lAo),e(hl,VO),e(VO,iAo),e(hl,dAo),e(hl,XO),e(XO,mAo),e(hl,cAo),e(k,fAo),e(k,ul),e(ul,n_e),e(n_e,gAo),e(ul,hAo),e(ul,zO),e(zO,uAo),e(ul,pAo),e(ul,QO),e(QO,_Ao),e(ul,bAo),e(k,vAo),e(k,pl),e(pl,s_e),e(s_e,FAo),e(pl,TAo),e(pl,WO),e(WO,MAo),e(pl,EAo),e(pl,UO),e(UO,CAo),e(pl,wAo),e(k,AAo),e(k,_l),e(_l,l_e),e(l_e,LAo),e(_l,yAo),e(_l,HO),e(HO,xAo),e(_l,$Ao),e(_l,JO),e(JO,kAo),e(_l,SAo),e(k,RAo),e(k,bl),e(bl,i_e),e(i_e,PAo),e(bl,BAo),e(bl,YO),e(YO,IAo),e(bl,NAo),e(bl,ZO),e(ZO,qAo),e(bl,jAo),e(k,DAo),e(k,rp),e(rp,d_e),e(d_e,GAo),e(rp,OAo),e(rp,KO),e(KO,VAo),e(rp,XAo),e(k,zAo),e(k,tp),e(tp,m_e),e(m_e,QAo),e(tp,WAo),e(tp,eV),e(eV,UAo),e(tp,HAo),e(k,JAo),e(k,vl),e(vl,c_e),e(c_e,YAo),e(vl,ZAo),e(vl,oV),e(oV,KAo),e(vl,e6o),e(vl,rV),e(rV,o6o),e(vl,r6o),e(k,t6o),e(k,Fl),e(Fl,f_e),e(f_e,a6o),e(Fl,n6o),e(Fl,tV),e(tV,s6o),e(Fl,l6o),e(Fl,aV),e(aV,i6o),e(Fl,d6o),e(k,m6o),e(k,Tl),e(Tl,g_e),e(g_e,c6o),e(Tl,f6o),e(Tl,nV),e(nV,g6o),e(Tl,h6o),e(Tl,sV),e(sV,u6o),e(Tl,p6o),e(k,_6o),e(k,ap),e(ap,h_e),e(h_e,b6o),e(ap,v6o),e(ap,lV),e(lV,F6o),e(ap,T6o),e(k,M6o),e(k,np),e(np,u_e),e(u_e,E6o),e(np,C6o),e(np,iV),e(iV,w6o),e(np,A6o),e(k,L6o),e(k,sp),e(sp,p_e),e(p_e,y6o),e(sp,x6o),e(sp,dV),e(dV,$6o),e(sp,k6o),e(k,S6o),e(k,Ml),e(Ml,__e),e(__e,R6o),e(Ml,P6o),e(Ml,mV),e(mV,B6o),e(Ml,I6o),e(Ml,cV),e(cV,N6o),e(Ml,q6o),e(k,j6o),e(k,El),e(El,b_e),e(b_e,D6o),e(El,G6o),e(El,fV),e(fV,O6o),e(El,V6o),e(El,gV),e(gV,X6o),e(El,z6o),e(k,Q6o),e(k,lp),e(lp,v_e),e(v_e,W6o),e(lp,U6o),e(lp,hV),e(hV,H6o),e(lp,J6o),e(k,Y6o),e(k,ip),e(ip,F_e),e(F_e,Z6o),e(ip,K6o),e(ip,uV),e(uV,e7o),e(ip,o7o),e(k,r7o),e(k,dp),e(dp,T_e),e(T_e,t7o),e(dp,a7o),e(dp,pV),e(pV,n7o),e(dp,s7o),e(k,l7o),e(k,mp),e(mp,M_e),e(M_e,i7o),e(mp,d7o),e(mp,_V),e(_V,m7o),e(mp,c7o),e(k,f7o),e(k,Cl),e(Cl,E_e),e(E_e,g7o),e(Cl,h7o),e(Cl,bV),e(bV,u7o),e(Cl,p7o),e(Cl,vV),e(vV,_7o),e(Cl,b7o),e(k,v7o),e(k,wl),e(wl,C_e),e(C_e,F7o),e(wl,T7o),e(wl,FV),e(FV,M7o),e(wl,E7o),e(wl,TV),e(TV,C7o),e(wl,w7o),e(k,A7o),e(k,cp),e(cp,w_e),e(w_e,L7o),e(cp,y7o),e(cp,MV),e(MV,x7o),e(cp,$7o),e(k,k7o),e(k,fp),e(fp,A_e),e(A_e,S7o),e(fp,R7o),e(fp,EV),e(EV,P7o),e(fp,B7o),e(k,I7o),e(k,Al),e(Al,L_e),e(L_e,N7o),e(Al,q7o),e(Al,CV),e(CV,j7o),e(Al,D7o),e(Al,wV),e(wV,G7o),e(Al,O7o),e(k,V7o),e(k,Ll),e(Ll,y_e),e(y_e,X7o),e(Ll,z7o),e(Ll,AV),e(AV,Q7o),e(Ll,W7o),e(Ll,LV),e(LV,U7o),e(Ll,H7o),e(k,J7o),e(k,yl),e(yl,x_e),e(x_e,Y7o),e(yl,Z7o),e(yl,yV),e(yV,K7o),e(yl,e8o),e(yl,xV),e(xV,o8o),e(yl,r8o),e(k,t8o),e(k,xl),e(xl,$_e),e($_e,a8o),e(xl,n8o),e(xl,$V),e($V,s8o),e(xl,l8o),e(xl,kV),e(kV,i8o),e(xl,d8o),e(jr,m8o),M(gp,jr,null),e(Ro,c8o),e(Ro,hp),M(I$,hp,null),e(hp,f8o),e(hp,k_e),e(k_e,g8o),b(c,Nao,_),b(c,$d,_),e($d,up),e(up,S_e),M(N$,S_e,null),e($d,h8o),e($d,R_e),e(R_e,u8o),b(c,qao,_),b(c,Po,_),M(q$,Po,null),e(Po,p8o),e(Po,j$),e(j$,_8o),e(j$,SV),e(SV,b8o),e(j$,v8o),e(Po,F8o),e(Po,D$),e(D$,T8o),e(D$,P_e),e(P_e,M8o),e(D$,E8o),e(Po,C8o),e(Po,Ye),M(G$,Ye,null),e(Ye,w8o),e(Ye,B_e),e(B_e,A8o),e(Ye,L8o),e(Ye,an),e(an,y8o),e(an,I_e),e(I_e,x8o),e(an,$8o),e(an,N_e),e(N_e,k8o),e(an,S8o),e(an,q_e),e(q_e,R8o),e(an,P8o),e(Ye,B8o),e(Ye,z),e(z,pp),e(pp,j_e),e(j_e,I8o),e(pp,N8o),e(pp,RV),e(RV,q8o),e(pp,j8o),e(z,D8o),e(z,_p),e(_p,D_e),e(D_e,G8o),e(_p,O8o),e(_p,PV),e(PV,V8o),e(_p,X8o),e(z,z8o),e(z,bp),e(bp,G_e),e(G_e,Q8o),e(bp,W8o),e(bp,BV),e(BV,U8o),e(bp,H8o),e(z,J8o),e(z,vp),e(vp,O_e),e(O_e,Y8o),e(vp,Z8o),e(vp,IV),e(IV,K8o),e(vp,eLo),e(z,oLo),e(z,Fp),e(Fp,V_e),e(V_e,rLo),e(Fp,tLo),e(Fp,NV),e(NV,aLo),e(Fp,nLo),e(z,sLo),e(z,Tp),e(Tp,X_e),e(X_e,lLo),e(Tp,iLo),e(Tp,qV),e(qV,dLo),e(Tp,mLo),e(z,cLo),e(z,Mp),e(Mp,z_e),e(z_e,fLo),e(Mp,gLo),e(Mp,jV),e(jV,hLo),e(Mp,uLo),e(z,pLo),e(z,Ep),e(Ep,Q_e),e(Q_e,_Lo),e(Ep,bLo),e(Ep,DV),e(DV,vLo),e(Ep,FLo),e(z,TLo),e(z,Cp),e(Cp,W_e),e(W_e,MLo),e(Cp,ELo),e(Cp,GV),e(GV,CLo),e(Cp,wLo),e(z,ALo),e(z,wp),e(wp,U_e),e(U_e,LLo),e(wp,yLo),e(wp,OV),e(OV,xLo),e(wp,$Lo),e(z,kLo),e(z,Ap),e(Ap,H_e),e(H_e,SLo),e(Ap,RLo),e(Ap,VV),e(VV,PLo),e(Ap,BLo),e(z,ILo),e(z,Lp),e(Lp,J_e),e(J_e,NLo),e(Lp,qLo),e(Lp,XV),e(XV,jLo),e(Lp,DLo),e(z,GLo),e(z,yp),e(yp,Y_e),e(Y_e,OLo),e(yp,VLo),e(yp,zV),e(zV,XLo),e(yp,zLo),e(z,QLo),e(z,xp),e(xp,Z_e),e(Z_e,WLo),e(xp,ULo),e(xp,QV),e(QV,HLo),e(xp,JLo),e(z,YLo),e(z,$p),e($p,K_e),e(K_e,ZLo),e($p,KLo),e($p,WV),e(WV,eyo),e($p,oyo),e(z,ryo),e(z,kp),e(kp,e1e),e(e1e,tyo),e(kp,ayo),e(kp,UV),e(UV,nyo),e(kp,syo),e(z,lyo),e(z,Sp),e(Sp,o1e),e(o1e,iyo),e(Sp,dyo),e(Sp,HV),e(HV,myo),e(Sp,cyo),e(z,fyo),e(z,Rp),e(Rp,r1e),e(r1e,gyo),e(Rp,hyo),e(Rp,JV),e(JV,uyo),e(Rp,pyo),e(z,_yo),e(z,Pp),e(Pp,t1e),e(t1e,byo),e(Pp,vyo),e(Pp,YV),e(YV,Fyo),e(Pp,Tyo),e(z,Myo),e(z,Bp),e(Bp,a1e),e(a1e,Eyo),e(Bp,Cyo),e(Bp,ZV),e(ZV,wyo),e(Bp,Ayo),e(z,Lyo),e(z,Ip),e(Ip,n1e),e(n1e,yyo),e(Ip,xyo),e(Ip,KV),e(KV,$yo),e(Ip,kyo),e(z,Syo),e(z,Np),e(Np,s1e),e(s1e,Ryo),e(Np,Pyo),e(Np,eX),e(eX,Byo),e(Np,Iyo),e(z,Nyo),e(z,qp),e(qp,l1e),e(l1e,qyo),e(qp,jyo),e(qp,oX),e(oX,Dyo),e(qp,Gyo),e(z,Oyo),e(z,jp),e(jp,i1e),e(i1e,Vyo),e(jp,Xyo),e(jp,rX),e(rX,zyo),e(jp,Qyo),e(z,Wyo),e(z,Dp),e(Dp,d1e),e(d1e,Uyo),e(Dp,Hyo),e(Dp,tX),e(tX,Jyo),e(Dp,Yyo),e(z,Zyo),e(z,Gp),e(Gp,m1e),e(m1e,Kyo),e(Gp,e9o),e(Gp,aX),e(aX,o9o),e(Gp,r9o),e(z,t9o),e(z,Op),e(Op,c1e),e(c1e,a9o),e(Op,n9o),e(Op,nX),e(nX,s9o),e(Op,l9o),e(z,i9o),e(z,Vp),e(Vp,f1e),e(f1e,d9o),e(Vp,m9o),e(Vp,sX),e(sX,c9o),e(Vp,f9o),e(z,g9o),e(z,Xp),e(Xp,g1e),e(g1e,h9o),e(Xp,u9o),e(Xp,lX),e(lX,p9o),e(Xp,_9o),e(z,b9o),e(z,zp),e(zp,h1e),e(h1e,v9o),e(zp,F9o),e(zp,iX),e(iX,T9o),e(zp,M9o),e(z,E9o),e(z,Qp),e(Qp,u1e),e(u1e,C9o),e(Qp,w9o),e(Qp,dX),e(dX,A9o),e(Qp,L9o),e(z,y9o),e(z,Wp),e(Wp,p1e),e(p1e,x9o),e(Wp,$9o),e(Wp,mX),e(mX,k9o),e(Wp,S9o),e(z,R9o),e(z,Up),e(Up,_1e),e(_1e,P9o),e(Up,B9o),e(Up,cX),e(cX,I9o),e(Up,N9o),e(z,q9o),e(z,Hp),e(Hp,b1e),e(b1e,j9o),e(Hp,D9o),e(Hp,fX),e(fX,G9o),e(Hp,O9o),e(z,V9o),e(z,Jp),e(Jp,v1e),e(v1e,X9o),e(Jp,z9o),e(Jp,gX),e(gX,Q9o),e(Jp,W9o),e(z,U9o),e(z,Yp),e(Yp,F1e),e(F1e,H9o),e(Yp,J9o),e(Yp,hX),e(hX,Y9o),e(Yp,Z9o),e(z,K9o),e(z,Zp),e(Zp,T1e),e(T1e,exo),e(Zp,oxo),e(Zp,uX),e(uX,rxo),e(Zp,txo),e(z,axo),e(z,Kp),e(Kp,M1e),e(M1e,nxo),e(Kp,sxo),e(Kp,pX),e(pX,lxo),e(Kp,ixo),e(z,dxo),e(z,e_),e(e_,E1e),e(E1e,mxo),e(e_,cxo),e(e_,_X),e(_X,fxo),e(e_,gxo),e(z,hxo),e(z,o_),e(o_,C1e),e(C1e,uxo),e(o_,pxo),e(o_,bX),e(bX,_xo),e(o_,bxo),e(z,vxo),e(z,r_),e(r_,w1e),e(w1e,Fxo),e(r_,Txo),e(r_,vX),e(vX,Mxo),e(r_,Exo),e(z,Cxo),e(z,t_),e(t_,A1e),e(A1e,wxo),e(t_,Axo),e(t_,FX),e(FX,Lxo),e(t_,yxo),e(z,xxo),e(z,a_),e(a_,L1e),e(L1e,$xo),e(a_,kxo),e(a_,TX),e(TX,Sxo),e(a_,Rxo),e(z,Pxo),e(z,n_),e(n_,y1e),e(y1e,Bxo),e(n_,Ixo),e(n_,MX),e(MX,Nxo),e(n_,qxo),e(z,jxo),e(z,s_),e(s_,x1e),e(x1e,Dxo),e(s_,Gxo),e(s_,EX),e(EX,Oxo),e(s_,Vxo),e(Ye,Xxo),M(l_,Ye,null),e(Ye,zxo),M(i_,Ye,null),e(Po,Qxo),e(Po,d_),M(O$,d_,null),e(d_,Wxo),e(d_,$1e),e($1e,Uxo),b(c,jao,_),b(c,kd,_),e(kd,m_),e(m_,k1e),M(V$,k1e,null),e(kd,Hxo),e(kd,S1e),e(S1e,Jxo),b(c,Dao,_),b(c,Bo,_),M(X$,Bo,null),e(Bo,Yxo),e(Bo,z$),e(z$,Zxo),e(z$,CX),e(CX,Kxo),e(z$,e$o),e(Bo,o$o),e(Bo,Q$),e(Q$,r$o),e(Q$,R1e),e(R1e,t$o),e(Q$,a$o),e(Bo,n$o),e(Bo,Ze),M(W$,Ze,null),e(Ze,s$o),e(Ze,P1e),e(P1e,l$o),e(Ze,i$o),e(Ze,Sd),e(Sd,d$o),e(Sd,B1e),e(B1e,m$o),e(Sd,c$o),e(Sd,I1e),e(I1e,f$o),e(Sd,g$o),e(Ze,h$o),e(Ze,se),e(se,c_),e(c_,N1e),e(N1e,u$o),e(c_,p$o),e(c_,wX),e(wX,_$o),e(c_,b$o),e(se,v$o),e(se,f_),e(f_,q1e),e(q1e,F$o),e(f_,T$o),e(f_,AX),e(AX,M$o),e(f_,E$o),e(se,C$o),e(se,g_),e(g_,j1e),e(j1e,w$o),e(g_,A$o),e(g_,LX),e(LX,L$o),e(g_,y$o),e(se,x$o),e(se,h_),e(h_,D1e),e(D1e,$$o),e(h_,k$o),e(h_,yX),e(yX,S$o),e(h_,R$o),e(se,P$o),e(se,u_),e(u_,G1e),e(G1e,B$o),e(u_,I$o),e(u_,xX),e(xX,N$o),e(u_,q$o),e(se,j$o),e(se,p_),e(p_,O1e),e(O1e,D$o),e(p_,G$o),e(p_,$X),e($X,O$o),e(p_,V$o),e(se,X$o),e(se,__),e(__,V1e),e(V1e,z$o),e(__,Q$o),e(__,kX),e(kX,W$o),e(__,U$o),e(se,H$o),e(se,b_),e(b_,X1e),e(X1e,J$o),e(b_,Y$o),e(b_,SX),e(SX,Z$o),e(b_,K$o),e(se,eko),e(se,v_),e(v_,z1e),e(z1e,oko),e(v_,rko),e(v_,RX),e(RX,tko),e(v_,ako),e(se,nko),e(se,F_),e(F_,Q1e),e(Q1e,sko),e(F_,lko),e(F_,PX),e(PX,iko),e(F_,dko),e(se,mko),e(se,T_),e(T_,W1e),e(W1e,cko),e(T_,fko),e(T_,BX),e(BX,gko),e(T_,hko),e(se,uko),e(se,M_),e(M_,U1e),e(U1e,pko),e(M_,_ko),e(M_,IX),e(IX,bko),e(M_,vko),e(se,Fko),e(se,E_),e(E_,H1e),e(H1e,Tko),e(E_,Mko),e(E_,NX),e(NX,Eko),e(E_,Cko),e(se,wko),e(se,C_),e(C_,J1e),e(J1e,Ako),e(C_,Lko),e(C_,qX),e(qX,yko),e(C_,xko),e(se,$ko),e(se,w_),e(w_,Y1e),e(Y1e,kko),e(w_,Sko),e(w_,jX),e(jX,Rko),e(w_,Pko),e(se,Bko),e(se,A_),e(A_,Z1e),e(Z1e,Iko),e(A_,Nko),e(A_,DX),e(DX,qko),e(A_,jko),e(se,Dko),e(se,L_),e(L_,K1e),e(K1e,Gko),e(L_,Oko),e(L_,GX),e(GX,Vko),e(L_,Xko),e(se,zko),e(se,y_),e(y_,e2e),e(e2e,Qko),e(y_,Wko),e(y_,OX),e(OX,Uko),e(y_,Hko),e(se,Jko),e(se,x_),e(x_,o2e),e(o2e,Yko),e(x_,Zko),e(x_,VX),e(VX,Kko),e(x_,eSo),e(se,oSo),e(se,$_),e($_,r2e),e(r2e,rSo),e($_,tSo),e($_,XX),e(XX,aSo),e($_,nSo),e(se,sSo),e(se,k_),e(k_,t2e),e(t2e,lSo),e(k_,iSo),e(k_,zX),e(zX,dSo),e(k_,mSo),e(se,cSo),e(se,S_),e(S_,a2e),e(a2e,fSo),e(S_,gSo),e(S_,QX),e(QX,hSo),e(S_,uSo),e(se,pSo),e(se,R_),e(R_,n2e),e(n2e,_So),e(R_,bSo),e(R_,WX),e(WX,vSo),e(R_,FSo),e(Ze,TSo),M(P_,Ze,null),e(Ze,MSo),M(B_,Ze,null),e(Bo,ESo),e(Bo,I_),M(U$,I_,null),e(I_,CSo),e(I_,s2e),e(s2e,wSo),b(c,Gao,_),b(c,Rd,_),e(Rd,N_),e(N_,l2e),M(H$,l2e,null),e(Rd,ASo),e(Rd,i2e),e(i2e,LSo),b(c,Oao,_),b(c,Io,_),M(J$,Io,null),e(Io,ySo),e(Io,Pd),e(Pd,xSo),e(Pd,UX),e(UX,$So),e(Pd,kSo),e(Pd,HX),e(HX,SSo),e(Pd,RSo),e(Io,PSo),e(Io,Y$),e(Y$,BSo),e(Y$,d2e),e(d2e,ISo),e(Y$,NSo),e(Io,qSo),e(Io,Mt),M(Z$,Mt,null),e(Mt,jSo),e(Mt,m2e),e(m2e,DSo),e(Mt,GSo),e(Mt,Bd),e(Bd,OSo),e(Bd,c2e),e(c2e,VSo),e(Bd,XSo),e(Bd,JX),e(JX,zSo),e(Bd,QSo),e(Mt,WSo),M(q_,Mt,null),e(Io,USo),e(Io,Ke),M(K$,Ke,null),e(Ke,HSo),e(Ke,f2e),e(f2e,JSo),e(Ke,YSo),e(Ke,nn),e(nn,ZSo),e(nn,g2e),e(g2e,KSo),e(nn,eRo),e(nn,h2e),e(h2e,oRo),e(nn,rRo),e(nn,u2e),e(u2e,tRo),e(nn,aRo),e(Ke,nRo),e(Ke,y),e(y,j_),e(j_,p2e),e(p2e,sRo),e(j_,lRo),e(j_,YX),e(YX,iRo),e(j_,dRo),e(y,mRo),e(y,D_),e(D_,_2e),e(_2e,cRo),e(D_,fRo),e(D_,ZX),e(ZX,gRo),e(D_,hRo),e(y,uRo),e(y,G_),e(G_,b2e),e(b2e,pRo),e(G_,_Ro),e(G_,KX),e(KX,bRo),e(G_,vRo),e(y,FRo),e(y,O_),e(O_,v2e),e(v2e,TRo),e(O_,MRo),e(O_,ez),e(ez,ERo),e(O_,CRo),e(y,wRo),e(y,V_),e(V_,F2e),e(F2e,ARo),e(V_,LRo),e(V_,oz),e(oz,yRo),e(V_,xRo),e(y,$Ro),e(y,X_),e(X_,T2e),e(T2e,kRo),e(X_,SRo),e(X_,rz),e(rz,RRo),e(X_,PRo),e(y,BRo),e(y,z_),e(z_,M2e),e(M2e,IRo),e(z_,NRo),e(z_,tz),e(tz,qRo),e(z_,jRo),e(y,DRo),e(y,Q_),e(Q_,E2e),e(E2e,GRo),e(Q_,ORo),e(Q_,az),e(az,VRo),e(Q_,XRo),e(y,zRo),e(y,W_),e(W_,C2e),e(C2e,QRo),e(W_,WRo),e(W_,nz),e(nz,URo),e(W_,HRo),e(y,JRo),e(y,U_),e(U_,w2e),e(w2e,YRo),e(U_,ZRo),e(U_,sz),e(sz,KRo),e(U_,ePo),e(y,oPo),e(y,H_),e(H_,A2e),e(A2e,rPo),e(H_,tPo),e(H_,lz),e(lz,aPo),e(H_,nPo),e(y,sPo),e(y,J_),e(J_,L2e),e(L2e,lPo),e(J_,iPo),e(J_,iz),e(iz,dPo),e(J_,mPo),e(y,cPo),e(y,Y_),e(Y_,y2e),e(y2e,fPo),e(Y_,gPo),e(Y_,dz),e(dz,hPo),e(Y_,uPo),e(y,pPo),e(y,Z_),e(Z_,x2e),e(x2e,_Po),e(Z_,bPo),e(Z_,mz),e(mz,vPo),e(Z_,FPo),e(y,TPo),e(y,K_),e(K_,$2e),e($2e,MPo),e(K_,EPo),e(K_,cz),e(cz,CPo),e(K_,wPo),e(y,APo),e(y,e1),e(e1,k2e),e(k2e,LPo),e(e1,yPo),e(e1,fz),e(fz,xPo),e(e1,$Po),e(y,kPo),e(y,o1),e(o1,S2e),e(S2e,SPo),e(o1,RPo),e(o1,gz),e(gz,PPo),e(o1,BPo),e(y,IPo),e(y,r1),e(r1,R2e),e(R2e,NPo),e(r1,qPo),e(r1,hz),e(hz,jPo),e(r1,DPo),e(y,GPo),e(y,t1),e(t1,P2e),e(P2e,OPo),e(t1,VPo),e(t1,uz),e(uz,XPo),e(t1,zPo),e(y,QPo),e(y,a1),e(a1,B2e),e(B2e,WPo),e(a1,UPo),e(a1,pz),e(pz,HPo),e(a1,JPo),e(y,YPo),e(y,n1),e(n1,I2e),e(I2e,ZPo),e(n1,KPo),e(n1,_z),e(_z,eBo),e(n1,oBo),e(y,rBo),e(y,s1),e(s1,N2e),e(N2e,tBo),e(s1,aBo),e(s1,bz),e(bz,nBo),e(s1,sBo),e(y,lBo),e(y,l1),e(l1,q2e),e(q2e,iBo),e(l1,dBo),e(l1,vz),e(vz,mBo),e(l1,cBo),e(y,fBo),e(y,i1),e(i1,j2e),e(j2e,gBo),e(i1,hBo),e(i1,Fz),e(Fz,uBo),e(i1,pBo),e(y,_Bo),e(y,d1),e(d1,D2e),e(D2e,bBo),e(d1,vBo),e(d1,Tz),e(Tz,FBo),e(d1,TBo),e(y,MBo),e(y,m1),e(m1,G2e),e(G2e,EBo),e(m1,CBo),e(m1,Mz),e(Mz,wBo),e(m1,ABo),e(y,LBo),e(y,c1),e(c1,O2e),e(O2e,yBo),e(c1,xBo),e(c1,Ez),e(Ez,$Bo),e(c1,kBo),e(y,SBo),e(y,f1),e(f1,V2e),e(V2e,RBo),e(f1,PBo),e(f1,Cz),e(Cz,BBo),e(f1,IBo),e(y,NBo),e(y,g1),e(g1,X2e),e(X2e,qBo),e(g1,jBo),e(g1,wz),e(wz,DBo),e(g1,GBo),e(y,OBo),e(y,h1),e(h1,z2e),e(z2e,VBo),e(h1,XBo),e(h1,Az),e(Az,zBo),e(h1,QBo),e(y,WBo),e(y,u1),e(u1,Q2e),e(Q2e,UBo),e(u1,HBo),e(u1,Lz),e(Lz,JBo),e(u1,YBo),e(y,ZBo),e(y,p1),e(p1,W2e),e(W2e,KBo),e(p1,eIo),e(p1,yz),e(yz,oIo),e(p1,rIo),e(y,tIo),e(y,_1),e(_1,U2e),e(U2e,aIo),e(_1,nIo),e(_1,xz),e(xz,sIo),e(_1,lIo),e(y,iIo),e(y,b1),e(b1,H2e),e(H2e,dIo),e(b1,mIo),e(b1,$z),e($z,cIo),e(b1,fIo),e(y,gIo),e(y,v1),e(v1,J2e),e(J2e,hIo),e(v1,uIo),e(v1,kz),e(kz,pIo),e(v1,_Io),e(y,bIo),e(y,F1),e(F1,Y2e),e(Y2e,vIo),e(F1,FIo),e(F1,Sz),e(Sz,TIo),e(F1,MIo),e(y,EIo),e(y,T1),e(T1,Z2e),e(Z2e,CIo),e(T1,wIo),e(T1,Rz),e(Rz,AIo),e(T1,LIo),e(y,yIo),e(y,M1),e(M1,K2e),e(K2e,xIo),e(M1,$Io),e(M1,Pz),e(Pz,kIo),e(M1,SIo),e(y,RIo),e(y,E1),e(E1,ebe),e(ebe,PIo),e(E1,BIo),e(E1,Bz),e(Bz,IIo),e(E1,NIo),e(y,qIo),e(y,C1),e(C1,obe),e(obe,jIo),e(C1,DIo),e(C1,Iz),e(Iz,GIo),e(C1,OIo),e(y,VIo),e(y,$l),e($l,rbe),e(rbe,XIo),e($l,zIo),e($l,Nz),e(Nz,QIo),e($l,WIo),e($l,qz),e(qz,UIo),e($l,HIo),e(y,JIo),e(y,w1),e(w1,tbe),e(tbe,YIo),e(w1,ZIo),e(w1,jz),e(jz,KIo),e(w1,eNo),e(y,oNo),e(y,A1),e(A1,abe),e(abe,rNo),e(A1,tNo),e(A1,Dz),e(Dz,aNo),e(A1,nNo),e(y,sNo),e(y,L1),e(L1,nbe),e(nbe,lNo),e(L1,iNo),e(L1,Gz),e(Gz,dNo),e(L1,mNo),e(y,cNo),e(y,y1),e(y1,sbe),e(sbe,fNo),e(y1,gNo),e(y1,Oz),e(Oz,hNo),e(y1,uNo),e(y,pNo),e(y,x1),e(x1,lbe),e(lbe,_No),e(x1,bNo),e(x1,Vz),e(Vz,vNo),e(x1,FNo),e(y,TNo),e(y,$1),e($1,ibe),e(ibe,MNo),e($1,ENo),e($1,Xz),e(Xz,CNo),e($1,wNo),e(y,ANo),e(y,k1),e(k1,dbe),e(dbe,LNo),e(k1,yNo),e(k1,zz),e(zz,xNo),e(k1,$No),e(y,kNo),e(y,S1),e(S1,mbe),e(mbe,SNo),e(S1,RNo),e(S1,Qz),e(Qz,PNo),e(S1,BNo),e(y,INo),e(y,R1),e(R1,cbe),e(cbe,NNo),e(R1,qNo),e(R1,Wz),e(Wz,jNo),e(R1,DNo),e(y,GNo),e(y,P1),e(P1,fbe),e(fbe,ONo),e(P1,VNo),e(P1,Uz),e(Uz,XNo),e(P1,zNo),e(y,QNo),e(y,B1),e(B1,gbe),e(gbe,WNo),e(B1,UNo),e(B1,Hz),e(Hz,HNo),e(B1,JNo),e(y,YNo),e(y,I1),e(I1,hbe),e(hbe,ZNo),e(I1,KNo),e(I1,Jz),e(Jz,eqo),e(I1,oqo),e(y,rqo),e(y,N1),e(N1,ube),e(ube,tqo),e(N1,aqo),e(N1,Yz),e(Yz,nqo),e(N1,sqo),e(y,lqo),e(y,q1),e(q1,pbe),e(pbe,iqo),e(q1,dqo),e(q1,Zz),e(Zz,mqo),e(q1,cqo),e(y,fqo),e(y,j1),e(j1,_be),e(_be,gqo),e(j1,hqo),e(j1,Kz),e(Kz,uqo),e(j1,pqo),e(y,_qo),e(y,D1),e(D1,bbe),e(bbe,bqo),e(D1,vqo),e(D1,eQ),e(eQ,Fqo),e(D1,Tqo),e(y,Mqo),e(y,G1),e(G1,vbe),e(vbe,Eqo),e(G1,Cqo),e(G1,oQ),e(oQ,wqo),e(G1,Aqo),e(y,Lqo),e(y,O1),e(O1,Fbe),e(Fbe,yqo),e(O1,xqo),e(O1,rQ),e(rQ,$qo),e(O1,kqo),e(y,Sqo),e(y,V1),e(V1,Tbe),e(Tbe,Rqo),e(V1,Pqo),e(V1,tQ),e(tQ,Bqo),e(V1,Iqo),e(y,Nqo),e(y,X1),e(X1,Mbe),e(Mbe,qqo),e(X1,jqo),e(X1,aQ),e(aQ,Dqo),e(X1,Gqo),e(y,Oqo),e(y,z1),e(z1,Ebe),e(Ebe,Vqo),e(z1,Xqo),e(z1,nQ),e(nQ,zqo),e(z1,Qqo),e(y,Wqo),e(y,Q1),e(Q1,Cbe),e(Cbe,Uqo),e(Q1,Hqo),e(Q1,sQ),e(sQ,Jqo),e(Q1,Yqo),e(y,Zqo),e(y,W1),e(W1,wbe),e(wbe,Kqo),e(W1,ejo),e(W1,lQ),e(lQ,ojo),e(W1,rjo),e(y,tjo),e(y,U1),e(U1,Abe),e(Abe,ajo),e(U1,njo),e(U1,iQ),e(iQ,sjo),e(U1,ljo),e(y,ijo),e(y,H1),e(H1,Lbe),e(Lbe,djo),e(H1,mjo),e(H1,dQ),e(dQ,cjo),e(H1,fjo),e(y,gjo),e(y,J1),e(J1,ybe),e(ybe,hjo),e(J1,ujo),e(J1,mQ),e(mQ,pjo),e(J1,_jo),e(y,bjo),e(y,Y1),e(Y1,xbe),e(xbe,vjo),e(Y1,Fjo),e(Y1,cQ),e(cQ,Tjo),e(Y1,Mjo),e(y,Ejo),e(y,Z1),e(Z1,$be),e($be,Cjo),e(Z1,wjo),e(Z1,fQ),e(fQ,Ajo),e(Z1,Ljo),e(y,yjo),e(y,K1),e(K1,kbe),e(kbe,xjo),e(K1,$jo),e(K1,gQ),e(gQ,kjo),e(K1,Sjo),e(y,Rjo),e(y,e2),e(e2,Sbe),e(Sbe,Pjo),e(e2,Bjo),e(e2,hQ),e(hQ,Ijo),e(e2,Njo),e(y,qjo),e(y,o2),e(o2,Rbe),e(Rbe,jjo),e(o2,Djo),e(o2,uQ),e(uQ,Gjo),e(o2,Ojo),e(y,Vjo),e(y,r2),e(r2,Pbe),e(Pbe,Xjo),e(r2,zjo),e(r2,pQ),e(pQ,Qjo),e(r2,Wjo),e(y,Ujo),e(y,t2),e(t2,Bbe),e(Bbe,Hjo),e(t2,Jjo),e(t2,_Q),e(_Q,Yjo),e(t2,Zjo),e(y,Kjo),e(y,a2),e(a2,Ibe),e(Ibe,eDo),e(a2,oDo),e(a2,bQ),e(bQ,rDo),e(a2,tDo),e(y,aDo),e(y,n2),e(n2,Nbe),e(Nbe,nDo),e(n2,sDo),e(n2,vQ),e(vQ,lDo),e(n2,iDo),e(y,dDo),e(y,s2),e(s2,qbe),e(qbe,mDo),e(s2,cDo),e(s2,FQ),e(FQ,fDo),e(s2,gDo),e(y,hDo),e(y,l2),e(l2,jbe),e(jbe,uDo),e(l2,pDo),e(l2,TQ),e(TQ,_Do),e(l2,bDo),e(y,vDo),e(y,i2),e(i2,Dbe),e(Dbe,FDo),e(i2,TDo),e(i2,MQ),e(MQ,MDo),e(i2,EDo),e(y,CDo),e(y,d2),e(d2,Gbe),e(Gbe,wDo),e(d2,ADo),e(d2,EQ),e(EQ,LDo),e(d2,yDo),e(y,xDo),e(y,m2),e(m2,Obe),e(Obe,$Do),e(m2,kDo),e(m2,CQ),e(CQ,SDo),e(m2,RDo),e(y,PDo),e(y,c2),e(c2,Vbe),e(Vbe,BDo),e(c2,IDo),e(c2,wQ),e(wQ,NDo),e(c2,qDo),e(y,jDo),e(y,f2),e(f2,Xbe),e(Xbe,DDo),e(f2,GDo),e(f2,AQ),e(AQ,ODo),e(f2,VDo),e(y,XDo),e(y,g2),e(g2,zbe),e(zbe,zDo),e(g2,QDo),e(g2,LQ),e(LQ,WDo),e(g2,UDo),e(y,HDo),e(y,h2),e(h2,Qbe),e(Qbe,JDo),e(h2,YDo),e(h2,yQ),e(yQ,ZDo),e(h2,KDo),e(y,eGo),e(y,u2),e(u2,Wbe),e(Wbe,oGo),e(u2,rGo),e(u2,xQ),e(xQ,tGo),e(u2,aGo),e(y,nGo),e(y,p2),e(p2,Ube),e(Ube,sGo),e(p2,lGo),e(p2,$Q),e($Q,iGo),e(p2,dGo),e(y,mGo),e(y,_2),e(_2,Hbe),e(Hbe,cGo),e(_2,fGo),e(_2,kQ),e(kQ,gGo),e(_2,hGo),e(y,uGo),e(y,b2),e(b2,Jbe),e(Jbe,pGo),e(b2,_Go),e(b2,SQ),e(SQ,bGo),e(b2,vGo),e(y,FGo),e(y,v2),e(v2,Ybe),e(Ybe,TGo),e(v2,MGo),e(v2,RQ),e(RQ,EGo),e(v2,CGo),e(y,wGo),e(y,F2),e(F2,Zbe),e(Zbe,AGo),e(F2,LGo),e(F2,PQ),e(PQ,yGo),e(F2,xGo),e(y,$Go),e(y,T2),e(T2,Kbe),e(Kbe,kGo),e(T2,SGo),e(T2,BQ),e(BQ,RGo),e(T2,PGo),e(y,BGo),e(y,M2),e(M2,eve),e(eve,IGo),e(M2,NGo),e(M2,IQ),e(IQ,qGo),e(M2,jGo),e(y,DGo),e(y,E2),e(E2,ove),e(ove,GGo),e(E2,OGo),e(E2,NQ),e(NQ,VGo),e(E2,XGo),e(y,zGo),e(y,C2),e(C2,rve),e(rve,QGo),e(C2,WGo),e(C2,qQ),e(qQ,UGo),e(C2,HGo),e(y,JGo),e(y,w2),e(w2,tve),e(tve,YGo),e(w2,ZGo),e(w2,jQ),e(jQ,KGo),e(w2,eOo),e(y,oOo),e(y,A2),e(A2,ave),e(ave,rOo),e(A2,tOo),e(A2,DQ),e(DQ,aOo),e(A2,nOo),e(y,sOo),e(y,L2),e(L2,nve),e(nve,lOo),e(L2,iOo),e(L2,GQ),e(GQ,dOo),e(L2,mOo),e(y,cOo),e(y,y2),e(y2,sve),e(sve,fOo),e(y2,gOo),e(y2,OQ),e(OQ,hOo),e(y2,uOo),e(y,pOo),e(y,x2),e(x2,lve),e(lve,_Oo),e(x2,bOo),e(x2,VQ),e(VQ,vOo),e(x2,FOo),e(y,TOo),e(y,$2),e($2,ive),e(ive,MOo),e($2,EOo),e($2,XQ),e(XQ,COo),e($2,wOo),e(y,AOo),e(y,k2),e(k2,dve),e(dve,LOo),e(k2,yOo),e(k2,zQ),e(zQ,xOo),e(k2,$Oo),e(y,kOo),e(y,S2),e(S2,mve),e(mve,SOo),e(S2,ROo),e(S2,QQ),e(QQ,POo),e(S2,BOo),e(y,IOo),e(y,R2),e(R2,cve),e(cve,NOo),e(R2,qOo),e(R2,WQ),e(WQ,jOo),e(R2,DOo),e(y,GOo),e(y,P2),e(P2,fve),e(fve,OOo),e(P2,VOo),e(P2,UQ),e(UQ,XOo),e(P2,zOo),e(y,QOo),e(y,B2),e(B2,gve),e(gve,WOo),e(B2,UOo),e(B2,HQ),e(HQ,HOo),e(B2,JOo),e(y,YOo),e(y,I2),e(I2,hve),e(hve,ZOo),e(I2,KOo),e(I2,JQ),e(JQ,eVo),e(I2,oVo),e(y,rVo),e(y,N2),e(N2,uve),e(uve,tVo),e(N2,aVo),e(N2,YQ),e(YQ,nVo),e(N2,sVo),e(y,lVo),e(y,q2),e(q2,pve),e(pve,iVo),e(q2,dVo),e(q2,ZQ),e(ZQ,mVo),e(q2,cVo),e(y,fVo),e(y,j2),e(j2,_ve),e(_ve,gVo),e(j2,hVo),e(j2,KQ),e(KQ,uVo),e(j2,pVo),e(y,_Vo),e(y,D2),e(D2,bve),e(bve,bVo),e(D2,vVo),e(D2,eW),e(eW,FVo),e(D2,TVo),e(y,MVo),e(y,G2),e(G2,vve),e(vve,EVo),e(G2,CVo),e(G2,oW),e(oW,wVo),e(G2,AVo),e(y,LVo),e(y,O2),e(O2,Fve),e(Fve,yVo),e(O2,xVo),e(O2,rW),e(rW,$Vo),e(O2,kVo),e(y,SVo),e(y,V2),e(V2,Tve),e(Tve,RVo),e(V2,PVo),e(V2,tW),e(tW,BVo),e(V2,IVo),e(y,NVo),e(y,X2),e(X2,Mve),e(Mve,qVo),e(X2,jVo),e(X2,aW),e(aW,DVo),e(X2,GVo),e(y,OVo),e(y,z2),e(z2,Eve),e(Eve,VVo),e(z2,XVo),e(z2,nW),e(nW,zVo),e(z2,QVo),e(y,WVo),e(y,Q2),e(Q2,Cve),e(Cve,UVo),e(Q2,HVo),e(Q2,sW),e(sW,JVo),e(Q2,YVo),e(y,ZVo),e(y,W2),e(W2,wve),e(wve,KVo),e(W2,eXo),e(W2,lW),e(lW,oXo),e(W2,rXo),e(y,tXo),e(y,U2),e(U2,Ave),e(Ave,aXo),e(U2,nXo),e(U2,iW),e(iW,sXo),e(U2,lXo),e(y,iXo),e(y,H2),e(H2,Lve),e(Lve,dXo),e(H2,mXo),e(H2,dW),e(dW,cXo),e(H2,fXo),e(y,gXo),e(y,J2),e(J2,yve),e(yve,hXo),e(J2,uXo),e(J2,mW),e(mW,pXo),e(J2,_Xo),e(y,bXo),e(y,Y2),e(Y2,xve),e(xve,vXo),e(Y2,FXo),e(Y2,cW),e(cW,TXo),e(Y2,MXo),e(y,EXo),e(y,Z2),e(Z2,$ve),e($ve,CXo),e(Z2,wXo),e(Z2,fW),e(fW,AXo),e(Z2,LXo),e(y,yXo),e(y,K2),e(K2,kve),e(kve,xXo),e(K2,$Xo),e(K2,gW),e(gW,kXo),e(K2,SXo),e(y,RXo),e(y,eb),e(eb,Sve),e(Sve,PXo),e(eb,BXo),e(eb,hW),e(hW,IXo),e(eb,NXo),e(y,qXo),e(y,ob),e(ob,Rve),e(Rve,jXo),e(ob,DXo),e(ob,uW),e(uW,GXo),e(ob,OXo),e(y,VXo),e(y,rb),e(rb,Pve),e(Pve,XXo),e(rb,zXo),e(rb,pW),e(pW,QXo),e(rb,WXo),e(y,UXo),e(y,tb),e(tb,Bve),e(Bve,HXo),e(tb,JXo),e(tb,_W),e(_W,YXo),e(tb,ZXo),e(y,KXo),e(y,ab),e(ab,Ive),e(Ive,ezo),e(ab,ozo),e(ab,bW),e(bW,rzo),e(ab,tzo),e(y,azo),e(y,nb),e(nb,Nve),e(Nve,nzo),e(nb,szo),e(nb,vW),e(vW,lzo),e(nb,izo),e(y,dzo),e(y,sb),e(sb,qve),e(qve,mzo),e(sb,czo),e(sb,FW),e(FW,fzo),e(sb,gzo),e(Ke,hzo),e(Ke,lb),e(lb,uzo),e(lb,jve),e(jve,pzo),e(lb,_zo),e(lb,Dve),e(Dve,bzo),e(Ke,vzo),M(ib,Ke,null),b(c,Vao,_),b(c,Id,_),e(Id,db),e(db,Gve),M(ek,Gve,null),e(Id,Fzo),e(Id,Ove),e(Ove,Tzo),b(c,Xao,_),b(c,No,_),M(ok,No,null),e(No,Mzo),e(No,Nd),e(Nd,Ezo),e(Nd,TW),e(TW,Czo),e(Nd,wzo),e(Nd,MW),e(MW,Azo),e(Nd,Lzo),e(No,yzo),e(No,rk),e(rk,xzo),e(rk,Vve),e(Vve,$zo),e(rk,kzo),e(No,Szo),e(No,Et),M(tk,Et,null),e(Et,Rzo),e(Et,Xve),e(Xve,Pzo),e(Et,Bzo),e(Et,qd),e(qd,Izo),e(qd,zve),e(zve,Nzo),e(qd,qzo),e(qd,EW),e(EW,jzo),e(qd,Dzo),e(Et,Gzo),M(mb,Et,null),e(No,Ozo),e(No,eo),M(ak,eo,null),e(eo,Vzo),e(eo,Qve),e(Qve,Xzo),e(eo,zzo),e(eo,sn),e(sn,Qzo),e(sn,Wve),e(Wve,Wzo),e(sn,Uzo),e(sn,Uve),e(Uve,Hzo),e(sn,Jzo),e(sn,Hve),e(Hve,Yzo),e(sn,Zzo),e(eo,Kzo),e(eo,G),e(G,cb),e(cb,Jve),e(Jve,eQo),e(cb,oQo),e(cb,CW),e(CW,rQo),e(cb,tQo),e(G,aQo),e(G,fb),e(fb,Yve),e(Yve,nQo),e(fb,sQo),e(fb,wW),e(wW,lQo),e(fb,iQo),e(G,dQo),e(G,gb),e(gb,Zve),e(Zve,mQo),e(gb,cQo),e(gb,AW),e(AW,fQo),e(gb,gQo),e(G,hQo),e(G,hb),e(hb,Kve),e(Kve,uQo),e(hb,pQo),e(hb,LW),e(LW,_Qo),e(hb,bQo),e(G,vQo),e(G,ub),e(ub,eFe),e(eFe,FQo),e(ub,TQo),e(ub,yW),e(yW,MQo),e(ub,EQo),e(G,CQo),e(G,pb),e(pb,oFe),e(oFe,wQo),e(pb,AQo),e(pb,xW),e(xW,LQo),e(pb,yQo),e(G,xQo),e(G,_b),e(_b,rFe),e(rFe,$Qo),e(_b,kQo),e(_b,$W),e($W,SQo),e(_b,RQo),e(G,PQo),e(G,bb),e(bb,tFe),e(tFe,BQo),e(bb,IQo),e(bb,kW),e(kW,NQo),e(bb,qQo),e(G,jQo),e(G,vb),e(vb,aFe),e(aFe,DQo),e(vb,GQo),e(vb,SW),e(SW,OQo),e(vb,VQo),e(G,XQo),e(G,Fb),e(Fb,nFe),e(nFe,zQo),e(Fb,QQo),e(Fb,RW),e(RW,WQo),e(Fb,UQo),e(G,HQo),e(G,Tb),e(Tb,sFe),e(sFe,JQo),e(Tb,YQo),e(Tb,PW),e(PW,ZQo),e(Tb,KQo),e(G,eWo),e(G,Mb),e(Mb,lFe),e(lFe,oWo),e(Mb,rWo),e(Mb,BW),e(BW,tWo),e(Mb,aWo),e(G,nWo),e(G,Eb),e(Eb,iFe),e(iFe,sWo),e(Eb,lWo),e(Eb,IW),e(IW,iWo),e(Eb,dWo),e(G,mWo),e(G,Cb),e(Cb,dFe),e(dFe,cWo),e(Cb,fWo),e(Cb,NW),e(NW,gWo),e(Cb,hWo),e(G,uWo),e(G,wb),e(wb,mFe),e(mFe,pWo),e(wb,_Wo),e(wb,qW),e(qW,bWo),e(wb,vWo),e(G,FWo),e(G,Ab),e(Ab,cFe),e(cFe,TWo),e(Ab,MWo),e(Ab,jW),e(jW,EWo),e(Ab,CWo),e(G,wWo),e(G,Lb),e(Lb,fFe),e(fFe,AWo),e(Lb,LWo),e(Lb,DW),e(DW,yWo),e(Lb,xWo),e(G,$Wo),e(G,yb),e(yb,gFe),e(gFe,kWo),e(yb,SWo),e(yb,GW),e(GW,RWo),e(yb,PWo),e(G,BWo),e(G,xb),e(xb,hFe),e(hFe,IWo),e(xb,NWo),e(xb,OW),e(OW,qWo),e(xb,jWo),e(G,DWo),e(G,$b),e($b,uFe),e(uFe,GWo),e($b,OWo),e($b,VW),e(VW,VWo),e($b,XWo),e(G,zWo),e(G,kb),e(kb,pFe),e(pFe,QWo),e(kb,WWo),e(kb,XW),e(XW,UWo),e(kb,HWo),e(G,JWo),e(G,Sb),e(Sb,_Fe),e(_Fe,YWo),e(Sb,ZWo),e(Sb,zW),e(zW,KWo),e(Sb,eUo),e(G,oUo),e(G,Rb),e(Rb,bFe),e(bFe,rUo),e(Rb,tUo),e(Rb,QW),e(QW,aUo),e(Rb,nUo),e(G,sUo),e(G,Pb),e(Pb,vFe),e(vFe,lUo),e(Pb,iUo),e(Pb,WW),e(WW,dUo),e(Pb,mUo),e(G,cUo),e(G,Bb),e(Bb,FFe),e(FFe,fUo),e(Bb,gUo),e(Bb,UW),e(UW,hUo),e(Bb,uUo),e(G,pUo),e(G,Ib),e(Ib,TFe),e(TFe,_Uo),e(Ib,bUo),e(Ib,HW),e(HW,vUo),e(Ib,FUo),e(G,TUo),e(G,Nb),e(Nb,MFe),e(MFe,MUo),e(Nb,EUo),e(Nb,JW),e(JW,CUo),e(Nb,wUo),e(G,AUo),e(G,qb),e(qb,EFe),e(EFe,LUo),e(qb,yUo),e(qb,YW),e(YW,xUo),e(qb,$Uo),e(G,kUo),e(G,jb),e(jb,CFe),e(CFe,SUo),e(jb,RUo),e(jb,ZW),e(ZW,PUo),e(jb,BUo),e(G,IUo),e(G,Db),e(Db,wFe),e(wFe,NUo),e(Db,qUo),e(Db,KW),e(KW,jUo),e(Db,DUo),e(G,GUo),e(G,Gb),e(Gb,AFe),e(AFe,OUo),e(Gb,VUo),e(Gb,eU),e(eU,XUo),e(Gb,zUo),e(G,QUo),e(G,Ob),e(Ob,LFe),e(LFe,WUo),e(Ob,UUo),e(Ob,oU),e(oU,HUo),e(Ob,JUo),e(G,YUo),e(G,Vb),e(Vb,yFe),e(yFe,ZUo),e(Vb,KUo),e(Vb,rU),e(rU,eHo),e(Vb,oHo),e(G,rHo),e(G,Xb),e(Xb,xFe),e(xFe,tHo),e(Xb,aHo),e(Xb,tU),e(tU,nHo),e(Xb,sHo),e(G,lHo),e(G,zb),e(zb,$Fe),e($Fe,iHo),e(zb,dHo),e(zb,aU),e(aU,mHo),e(zb,cHo),e(G,fHo),e(G,Qb),e(Qb,kFe),e(kFe,gHo),e(Qb,hHo),e(Qb,nU),e(nU,uHo),e(Qb,pHo),e(G,_Ho),e(G,Wb),e(Wb,SFe),e(SFe,bHo),e(Wb,vHo),e(Wb,sU),e(sU,FHo),e(Wb,THo),e(G,MHo),e(G,Ub),e(Ub,RFe),e(RFe,EHo),e(Ub,CHo),e(Ub,lU),e(lU,wHo),e(Ub,AHo),e(G,LHo),e(G,Hb),e(Hb,PFe),e(PFe,yHo),e(Hb,xHo),e(Hb,iU),e(iU,$Ho),e(Hb,kHo),e(G,SHo),e(G,Jb),e(Jb,BFe),e(BFe,RHo),e(Jb,PHo),e(Jb,dU),e(dU,BHo),e(Jb,IHo),e(G,NHo),e(G,Yb),e(Yb,IFe),e(IFe,qHo),e(Yb,jHo),e(Yb,mU),e(mU,DHo),e(Yb,GHo),e(G,OHo),e(G,Zb),e(Zb,NFe),e(NFe,VHo),e(Zb,XHo),e(Zb,cU),e(cU,zHo),e(Zb,QHo),e(G,WHo),e(G,Kb),e(Kb,qFe),e(qFe,UHo),e(Kb,HHo),e(Kb,fU),e(fU,JHo),e(Kb,YHo),e(G,ZHo),e(G,ev),e(ev,jFe),e(jFe,KHo),e(ev,eJo),e(ev,gU),e(gU,oJo),e(ev,rJo),e(G,tJo),e(G,ov),e(ov,DFe),e(DFe,aJo),e(ov,nJo),e(ov,hU),e(hU,sJo),e(ov,lJo),e(G,iJo),e(G,rv),e(rv,GFe),e(GFe,dJo),e(rv,mJo),e(rv,uU),e(uU,cJo),e(rv,fJo),e(G,gJo),e(G,tv),e(tv,OFe),e(OFe,hJo),e(tv,uJo),e(tv,pU),e(pU,pJo),e(tv,_Jo),e(G,bJo),e(G,av),e(av,VFe),e(VFe,vJo),e(av,FJo),e(av,_U),e(_U,TJo),e(av,MJo),e(G,EJo),e(G,nv),e(nv,XFe),e(XFe,CJo),e(nv,wJo),e(nv,bU),e(bU,AJo),e(nv,LJo),e(eo,yJo),e(eo,sv),e(sv,xJo),e(sv,zFe),e(zFe,$Jo),e(sv,kJo),e(sv,QFe),e(QFe,SJo),e(eo,RJo),M(lv,eo,null),b(c,zao,_),b(c,jd,_),e(jd,iv),e(iv,WFe),M(nk,WFe,null),e(jd,PJo),e(jd,UFe),e(UFe,BJo),b(c,Qao,_),b(c,qo,_),M(sk,qo,null),e(qo,IJo),e(qo,Dd),e(Dd,NJo),e(Dd,vU),e(vU,qJo),e(Dd,jJo),e(Dd,FU),e(FU,DJo),e(Dd,GJo),e(qo,OJo),e(qo,lk),e(lk,VJo),e(lk,HFe),e(HFe,XJo),e(lk,zJo),e(qo,QJo),e(qo,Ct),M(ik,Ct,null),e(Ct,WJo),e(Ct,JFe),e(JFe,UJo),e(Ct,HJo),e(Ct,Gd),e(Gd,JJo),e(Gd,YFe),e(YFe,YJo),e(Gd,ZJo),e(Gd,TU),e(TU,KJo),e(Gd,eYo),e(Ct,oYo),M(dv,Ct,null),e(qo,rYo),e(qo,oo),M(dk,oo,null),e(oo,tYo),e(oo,ZFe),e(ZFe,aYo),e(oo,nYo),e(oo,ln),e(ln,sYo),e(ln,KFe),e(KFe,lYo),e(ln,iYo),e(ln,eTe),e(eTe,dYo),e(ln,mYo),e(ln,oTe),e(oTe,cYo),e(ln,fYo),e(oo,gYo),e(oo,W),e(W,mv),e(mv,rTe),e(rTe,hYo),e(mv,uYo),e(mv,MU),e(MU,pYo),e(mv,_Yo),e(W,bYo),e(W,cv),e(cv,tTe),e(tTe,vYo),e(cv,FYo),e(cv,EU),e(EU,TYo),e(cv,MYo),e(W,EYo),e(W,fv),e(fv,aTe),e(aTe,CYo),e(fv,wYo),e(fv,CU),e(CU,AYo),e(fv,LYo),e(W,yYo),e(W,gv),e(gv,nTe),e(nTe,xYo),e(gv,$Yo),e(gv,wU),e(wU,kYo),e(gv,SYo),e(W,RYo),e(W,hv),e(hv,sTe),e(sTe,PYo),e(hv,BYo),e(hv,AU),e(AU,IYo),e(hv,NYo),e(W,qYo),e(W,uv),e(uv,lTe),e(lTe,jYo),e(uv,DYo),e(uv,LU),e(LU,GYo),e(uv,OYo),e(W,VYo),e(W,pv),e(pv,iTe),e(iTe,XYo),e(pv,zYo),e(pv,yU),e(yU,QYo),e(pv,WYo),e(W,UYo),e(W,_v),e(_v,dTe),e(dTe,HYo),e(_v,JYo),e(_v,xU),e(xU,YYo),e(_v,ZYo),e(W,KYo),e(W,bv),e(bv,mTe),e(mTe,eZo),e(bv,oZo),e(bv,$U),e($U,rZo),e(bv,tZo),e(W,aZo),e(W,vv),e(vv,cTe),e(cTe,nZo),e(vv,sZo),e(vv,kU),e(kU,lZo),e(vv,iZo),e(W,dZo),e(W,Fv),e(Fv,fTe),e(fTe,mZo),e(Fv,cZo),e(Fv,SU),e(SU,fZo),e(Fv,gZo),e(W,hZo),e(W,Tv),e(Tv,gTe),e(gTe,uZo),e(Tv,pZo),e(Tv,RU),e(RU,_Zo),e(Tv,bZo),e(W,vZo),e(W,Mv),e(Mv,hTe),e(hTe,FZo),e(Mv,TZo),e(Mv,PU),e(PU,MZo),e(Mv,EZo),e(W,CZo),e(W,Ev),e(Ev,uTe),e(uTe,wZo),e(Ev,AZo),e(Ev,BU),e(BU,LZo),e(Ev,yZo),e(W,xZo),e(W,Cv),e(Cv,pTe),e(pTe,$Zo),e(Cv,kZo),e(Cv,IU),e(IU,SZo),e(Cv,RZo),e(W,PZo),e(W,wv),e(wv,_Te),e(_Te,BZo),e(wv,IZo),e(wv,NU),e(NU,NZo),e(wv,qZo),e(W,jZo),e(W,Av),e(Av,bTe),e(bTe,DZo),e(Av,GZo),e(Av,qU),e(qU,OZo),e(Av,VZo),e(W,XZo),e(W,Lv),e(Lv,vTe),e(vTe,zZo),e(Lv,QZo),e(Lv,jU),e(jU,WZo),e(Lv,UZo),e(W,HZo),e(W,yv),e(yv,FTe),e(FTe,JZo),e(yv,YZo),e(yv,DU),e(DU,ZZo),e(yv,KZo),e(W,eKo),e(W,xv),e(xv,TTe),e(TTe,oKo),e(xv,rKo),e(xv,GU),e(GU,tKo),e(xv,aKo),e(W,nKo),e(W,$v),e($v,MTe),e(MTe,sKo),e($v,lKo),e($v,OU),e(OU,iKo),e($v,dKo),e(W,mKo),e(W,kv),e(kv,ETe),e(ETe,cKo),e(kv,fKo),e(kv,VU),e(VU,gKo),e(kv,hKo),e(W,uKo),e(W,Sv),e(Sv,CTe),e(CTe,pKo),e(Sv,_Ko),e(Sv,XU),e(XU,bKo),e(Sv,vKo),e(W,FKo),e(W,Rv),e(Rv,wTe),e(wTe,TKo),e(Rv,MKo),e(Rv,zU),e(zU,EKo),e(Rv,CKo),e(W,wKo),e(W,Pv),e(Pv,ATe),e(ATe,AKo),e(Pv,LKo),e(Pv,QU),e(QU,yKo),e(Pv,xKo),e(W,$Ko),e(W,Bv),e(Bv,LTe),e(LTe,kKo),e(Bv,SKo),e(Bv,WU),e(WU,RKo),e(Bv,PKo),e(W,BKo),e(W,Iv),e(Iv,yTe),e(yTe,IKo),e(Iv,NKo),e(Iv,UU),e(UU,qKo),e(Iv,jKo),e(W,DKo),e(W,Nv),e(Nv,xTe),e(xTe,GKo),e(Nv,OKo),e(Nv,HU),e(HU,VKo),e(Nv,XKo),e(W,zKo),e(W,qv),e(qv,$Te),e($Te,QKo),e(qv,WKo),e(qv,JU),e(JU,UKo),e(qv,HKo),e(W,JKo),e(W,jv),e(jv,kTe),e(kTe,YKo),e(jv,ZKo),e(jv,YU),e(YU,KKo),e(jv,eer),e(W,oer),e(W,Dv),e(Dv,STe),e(STe,rer),e(Dv,ter),e(Dv,ZU),e(ZU,aer),e(Dv,ner),e(W,ser),e(W,Gv),e(Gv,RTe),e(RTe,ler),e(Gv,ier),e(Gv,KU),e(KU,der),e(Gv,mer),e(W,cer),e(W,Ov),e(Ov,PTe),e(PTe,fer),e(Ov,ger),e(Ov,eH),e(eH,her),e(Ov,uer),e(W,per),e(W,Vv),e(Vv,BTe),e(BTe,_er),e(Vv,ber),e(Vv,oH),e(oH,ver),e(Vv,Fer),e(W,Ter),e(W,Xv),e(Xv,ITe),e(ITe,Mer),e(Xv,Eer),e(Xv,rH),e(rH,Cer),e(Xv,wer),e(W,Aer),e(W,zv),e(zv,NTe),e(NTe,Ler),e(zv,yer),e(zv,tH),e(tH,xer),e(zv,$er),e(W,ker),e(W,Qv),e(Qv,qTe),e(qTe,Ser),e(Qv,Rer),e(Qv,aH),e(aH,Per),e(Qv,Ber),e(W,Ier),e(W,Wv),e(Wv,jTe),e(jTe,Ner),e(Wv,qer),e(Wv,nH),e(nH,jer),e(Wv,Der),e(W,Ger),e(W,Uv),e(Uv,DTe),e(DTe,Oer),e(Uv,Ver),e(Uv,sH),e(sH,Xer),e(Uv,zer),e(W,Qer),e(W,Hv),e(Hv,GTe),e(GTe,Wer),e(Hv,Uer),e(Hv,lH),e(lH,Her),e(Hv,Jer),e(W,Yer),e(W,Jv),e(Jv,OTe),e(OTe,Zer),e(Jv,Ker),e(Jv,iH),e(iH,eor),e(Jv,oor),e(W,ror),e(W,Yv),e(Yv,VTe),e(VTe,tor),e(Yv,aor),e(Yv,dH),e(dH,nor),e(Yv,sor),e(W,lor),e(W,Zv),e(Zv,XTe),e(XTe,ior),e(Zv,dor),e(Zv,mH),e(mH,mor),e(Zv,cor),e(oo,gor),e(oo,Kv),e(Kv,hor),e(Kv,zTe),e(zTe,uor),e(Kv,por),e(Kv,QTe),e(QTe,_or),e(oo,bor),M(eF,oo,null),b(c,Wao,_),b(c,Od,_),e(Od,oF),e(oF,WTe),M(mk,WTe,null),e(Od,vor),e(Od,UTe),e(UTe,For),b(c,Uao,_),b(c,jo,_),M(ck,jo,null),e(jo,Tor),e(jo,Vd),e(Vd,Mor),e(Vd,cH),e(cH,Eor),e(Vd,Cor),e(Vd,fH),e(fH,wor),e(Vd,Aor),e(jo,Lor),e(jo,fk),e(fk,yor),e(fk,HTe),e(HTe,xor),e(fk,$or),e(jo,kor),e(jo,wt),M(gk,wt,null),e(wt,Sor),e(wt,JTe),e(JTe,Ror),e(wt,Por),e(wt,Xd),e(Xd,Bor),e(Xd,YTe),e(YTe,Ior),e(Xd,Nor),e(Xd,gH),e(gH,qor),e(Xd,jor),e(wt,Dor),M(rF,wt,null),e(jo,Gor),e(jo,ro),M(hk,ro,null),e(ro,Oor),e(ro,ZTe),e(ZTe,Vor),e(ro,Xor),e(ro,dn),e(dn,zor),e(dn,KTe),e(KTe,Qor),e(dn,Wor),e(dn,eMe),e(eMe,Uor),e(dn,Hor),e(dn,oMe),e(oMe,Jor),e(dn,Yor),e(ro,Zor),e(ro,uk),e(uk,tF),e(tF,rMe),e(rMe,Kor),e(tF,err),e(tF,hH),e(hH,orr),e(tF,rrr),e(uk,trr),e(uk,aF),e(aF,tMe),e(tMe,arr),e(aF,nrr),e(aF,uH),e(uH,srr),e(aF,lrr),e(ro,irr),e(ro,nF),e(nF,drr),e(nF,aMe),e(aMe,mrr),e(nF,crr),e(nF,nMe),e(nMe,frr),e(ro,grr),M(sF,ro,null),b(c,Hao,_),b(c,zd,_),e(zd,lF),e(lF,sMe),M(pk,sMe,null),e(zd,hrr),e(zd,lMe),e(lMe,urr),b(c,Jao,_),b(c,Do,_),M(_k,Do,null),e(Do,prr),e(Do,Qd),e(Qd,_rr),e(Qd,pH),e(pH,brr),e(Qd,vrr),e(Qd,_H),e(_H,Frr),e(Qd,Trr),e(Do,Mrr),e(Do,bk),e(bk,Err),e(bk,iMe),e(iMe,Crr),e(bk,wrr),e(Do,Arr),e(Do,At),M(vk,At,null),e(At,Lrr),e(At,dMe),e(dMe,yrr),e(At,xrr),e(At,Wd),e(Wd,$rr),e(Wd,mMe),e(mMe,krr),e(Wd,Srr),e(Wd,bH),e(bH,Rrr),e(Wd,Prr),e(At,Brr),M(iF,At,null),e(Do,Irr),e(Do,to),M(Fk,to,null),e(to,Nrr),e(to,cMe),e(cMe,qrr),e(to,jrr),e(to,mn),e(mn,Drr),e(mn,fMe),e(fMe,Grr),e(mn,Orr),e(mn,gMe),e(gMe,Vrr),e(mn,Xrr),e(mn,hMe),e(hMe,zrr),e(mn,Qrr),e(to,Wrr),e(to,Y),e(Y,dF),e(dF,uMe),e(uMe,Urr),e(dF,Hrr),e(dF,vH),e(vH,Jrr),e(dF,Yrr),e(Y,Zrr),e(Y,mF),e(mF,pMe),e(pMe,Krr),e(mF,etr),e(mF,FH),e(FH,otr),e(mF,rtr),e(Y,ttr),e(Y,cF),e(cF,_Me),e(_Me,atr),e(cF,ntr),e(cF,TH),e(TH,str),e(cF,ltr),e(Y,itr),e(Y,fF),e(fF,bMe),e(bMe,dtr),e(fF,mtr),e(fF,MH),e(MH,ctr),e(fF,ftr),e(Y,gtr),e(Y,gF),e(gF,vMe),e(vMe,htr),e(gF,utr),e(gF,EH),e(EH,ptr),e(gF,_tr),e(Y,btr),e(Y,hF),e(hF,FMe),e(FMe,vtr),e(hF,Ftr),e(hF,CH),e(CH,Ttr),e(hF,Mtr),e(Y,Etr),e(Y,uF),e(uF,TMe),e(TMe,Ctr),e(uF,wtr),e(uF,wH),e(wH,Atr),e(uF,Ltr),e(Y,ytr),e(Y,pF),e(pF,MMe),e(MMe,xtr),e(pF,$tr),e(pF,AH),e(AH,ktr),e(pF,Str),e(Y,Rtr),e(Y,_F),e(_F,EMe),e(EMe,Ptr),e(_F,Btr),e(_F,LH),e(LH,Itr),e(_F,Ntr),e(Y,qtr),e(Y,bF),e(bF,CMe),e(CMe,jtr),e(bF,Dtr),e(bF,yH),e(yH,Gtr),e(bF,Otr),e(Y,Vtr),e(Y,vF),e(vF,wMe),e(wMe,Xtr),e(vF,ztr),e(vF,xH),e(xH,Qtr),e(vF,Wtr),e(Y,Utr),e(Y,FF),e(FF,AMe),e(AMe,Htr),e(FF,Jtr),e(FF,$H),e($H,Ytr),e(FF,Ztr),e(Y,Ktr),e(Y,TF),e(TF,LMe),e(LMe,ear),e(TF,oar),e(TF,kH),e(kH,rar),e(TF,tar),e(Y,aar),e(Y,MF),e(MF,yMe),e(yMe,nar),e(MF,sar),e(MF,SH),e(SH,lar),e(MF,iar),e(Y,dar),e(Y,EF),e(EF,xMe),e(xMe,mar),e(EF,car),e(EF,RH),e(RH,far),e(EF,gar),e(Y,har),e(Y,CF),e(CF,$Me),e($Me,uar),e(CF,par),e(CF,PH),e(PH,_ar),e(CF,bar),e(Y,Far),e(Y,wF),e(wF,kMe),e(kMe,Tar),e(wF,Mar),e(wF,BH),e(BH,Ear),e(wF,Car),e(Y,war),e(Y,AF),e(AF,SMe),e(SMe,Aar),e(AF,Lar),e(AF,IH),e(IH,yar),e(AF,xar),e(Y,$ar),e(Y,LF),e(LF,RMe),e(RMe,kar),e(LF,Sar),e(LF,NH),e(NH,Rar),e(LF,Par),e(Y,Bar),e(Y,yF),e(yF,PMe),e(PMe,Iar),e(yF,Nar),e(yF,qH),e(qH,qar),e(yF,jar),e(Y,Dar),e(Y,xF),e(xF,BMe),e(BMe,Gar),e(xF,Oar),e(xF,jH),e(jH,Var),e(xF,Xar),e(Y,zar),e(Y,$F),e($F,IMe),e(IMe,Qar),e($F,War),e($F,DH),e(DH,Uar),e($F,Har),e(Y,Jar),e(Y,kF),e(kF,NMe),e(NMe,Yar),e(kF,Zar),e(kF,GH),e(GH,Kar),e(kF,enr),e(Y,onr),e(Y,SF),e(SF,qMe),e(qMe,rnr),e(SF,tnr),e(SF,OH),e(OH,anr),e(SF,nnr),e(Y,snr),e(Y,RF),e(RF,jMe),e(jMe,lnr),e(RF,inr),e(RF,VH),e(VH,dnr),e(RF,mnr),e(Y,cnr),e(Y,PF),e(PF,DMe),e(DMe,fnr),e(PF,gnr),e(PF,XH),e(XH,hnr),e(PF,unr),e(Y,pnr),e(Y,BF),e(BF,GMe),e(GMe,_nr),e(BF,bnr),e(BF,zH),e(zH,vnr),e(BF,Fnr),e(Y,Tnr),e(Y,IF),e(IF,OMe),e(OMe,Mnr),e(IF,Enr),e(IF,QH),e(QH,Cnr),e(IF,wnr),e(Y,Anr),e(Y,NF),e(NF,VMe),e(VMe,Lnr),e(NF,ynr),e(NF,WH),e(WH,xnr),e(NF,$nr),e(Y,knr),e(Y,qF),e(qF,XMe),e(XMe,Snr),e(qF,Rnr),e(qF,UH),e(UH,Pnr),e(qF,Bnr),e(Y,Inr),e(Y,jF),e(jF,zMe),e(zMe,Nnr),e(jF,qnr),e(jF,HH),e(HH,jnr),e(jF,Dnr),e(Y,Gnr),e(Y,DF),e(DF,QMe),e(QMe,Onr),e(DF,Vnr),e(DF,JH),e(JH,Xnr),e(DF,znr),e(Y,Qnr),e(Y,GF),e(GF,WMe),e(WMe,Wnr),e(GF,Unr),e(GF,YH),e(YH,Hnr),e(GF,Jnr),e(Y,Ynr),e(Y,OF),e(OF,UMe),e(UMe,Znr),e(OF,Knr),e(OF,ZH),e(ZH,esr),e(OF,osr),e(Y,rsr),e(Y,VF),e(VF,HMe),e(HMe,tsr),e(VF,asr),e(VF,KH),e(KH,nsr),e(VF,ssr),e(Y,lsr),e(Y,XF),e(XF,JMe),e(JMe,isr),e(XF,dsr),e(XF,YMe),e(YMe,msr),e(XF,csr),e(Y,fsr),e(Y,zF),e(zF,ZMe),e(ZMe,gsr),e(zF,hsr),e(zF,eJ),e(eJ,usr),e(zF,psr),e(Y,_sr),e(Y,QF),e(QF,KMe),e(KMe,bsr),e(QF,vsr),e(QF,oJ),e(oJ,Fsr),e(QF,Tsr),e(Y,Msr),e(Y,WF),e(WF,eEe),e(eEe,Esr),e(WF,Csr),e(WF,rJ),e(rJ,wsr),e(WF,Asr),e(Y,Lsr),e(Y,UF),e(UF,oEe),e(oEe,ysr),e(UF,xsr),e(UF,tJ),e(tJ,$sr),e(UF,ksr),e(to,Ssr),e(to,HF),e(HF,Rsr),e(HF,rEe),e(rEe,Psr),e(HF,Bsr),e(HF,tEe),e(tEe,Isr),e(to,Nsr),M(JF,to,null),b(c,Yao,_),b(c,Ud,_),e(Ud,YF),e(YF,aEe),M(Tk,aEe,null),e(Ud,qsr),e(Ud,nEe),e(nEe,jsr),b(c,Zao,_),b(c,Go,_),M(Mk,Go,null),e(Go,Dsr),e(Go,Hd),e(Hd,Gsr),e(Hd,aJ),e(aJ,Osr),e(Hd,Vsr),e(Hd,nJ),e(nJ,Xsr),e(Hd,zsr),e(Go,Qsr),e(Go,Ek),e(Ek,Wsr),e(Ek,sEe),e(sEe,Usr),e(Ek,Hsr),e(Go,Jsr),e(Go,Lt),M(Ck,Lt,null),e(Lt,Ysr),e(Lt,lEe),e(lEe,Zsr),e(Lt,Ksr),e(Lt,Jd),e(Jd,elr),e(Jd,iEe),e(iEe,olr),e(Jd,rlr),e(Jd,sJ),e(sJ,tlr),e(Jd,alr),e(Lt,nlr),M(ZF,Lt,null),e(Go,slr),e(Go,ao),M(wk,ao,null),e(ao,llr),e(ao,dEe),e(dEe,ilr),e(ao,dlr),e(ao,cn),e(cn,mlr),e(cn,mEe),e(mEe,clr),e(cn,flr),e(cn,cEe),e(cEe,glr),e(cn,hlr),e(cn,fEe),e(fEe,ulr),e(cn,plr),e(ao,_lr),e(ao,he),e(he,KF),e(KF,gEe),e(gEe,blr),e(KF,vlr),e(KF,lJ),e(lJ,Flr),e(KF,Tlr),e(he,Mlr),e(he,eT),e(eT,hEe),e(hEe,Elr),e(eT,Clr),e(eT,iJ),e(iJ,wlr),e(eT,Alr),e(he,Llr),e(he,oT),e(oT,uEe),e(uEe,ylr),e(oT,xlr),e(oT,dJ),e(dJ,$lr),e(oT,klr),e(he,Slr),e(he,rT),e(rT,pEe),e(pEe,Rlr),e(rT,Plr),e(rT,mJ),e(mJ,Blr),e(rT,Ilr),e(he,Nlr),e(he,tT),e(tT,_Ee),e(_Ee,qlr),e(tT,jlr),e(tT,cJ),e(cJ,Dlr),e(tT,Glr),e(he,Olr),e(he,aT),e(aT,bEe),e(bEe,Vlr),e(aT,Xlr),e(aT,fJ),e(fJ,zlr),e(aT,Qlr),e(he,Wlr),e(he,nT),e(nT,vEe),e(vEe,Ulr),e(nT,Hlr),e(nT,gJ),e(gJ,Jlr),e(nT,Ylr),e(he,Zlr),e(he,sT),e(sT,FEe),e(FEe,Klr),e(sT,eir),e(sT,hJ),e(hJ,oir),e(sT,rir),e(he,tir),e(he,lT),e(lT,TEe),e(TEe,air),e(lT,nir),e(lT,uJ),e(uJ,sir),e(lT,lir),e(he,iir),e(he,iT),e(iT,MEe),e(MEe,dir),e(iT,mir),e(iT,pJ),e(pJ,cir),e(iT,fir),e(he,gir),e(he,dT),e(dT,EEe),e(EEe,hir),e(dT,uir),e(dT,_J),e(_J,pir),e(dT,_ir),e(he,bir),e(he,mT),e(mT,CEe),e(CEe,vir),e(mT,Fir),e(mT,bJ),e(bJ,Tir),e(mT,Mir),e(he,Eir),e(he,cT),e(cT,wEe),e(wEe,Cir),e(cT,wir),e(cT,vJ),e(vJ,Air),e(cT,Lir),e(he,yir),e(he,fT),e(fT,AEe),e(AEe,xir),e(fT,$ir),e(fT,FJ),e(FJ,kir),e(fT,Sir),e(he,Rir),e(he,gT),e(gT,LEe),e(LEe,Pir),e(gT,Bir),e(gT,TJ),e(TJ,Iir),e(gT,Nir),e(he,qir),e(he,hT),e(hT,yEe),e(yEe,jir),e(hT,Dir),e(hT,MJ),e(MJ,Gir),e(hT,Oir),e(he,Vir),e(he,uT),e(uT,xEe),e(xEe,Xir),e(uT,zir),e(uT,EJ),e(EJ,Qir),e(uT,Wir),e(he,Uir),e(he,pT),e(pT,$Ee),e($Ee,Hir),e(pT,Jir),e(pT,CJ),e(CJ,Yir),e(pT,Zir),e(he,Kir),e(he,_T),e(_T,kEe),e(kEe,edr),e(_T,odr),e(_T,wJ),e(wJ,rdr),e(_T,tdr),e(he,adr),e(he,bT),e(bT,SEe),e(SEe,ndr),e(bT,sdr),e(bT,AJ),e(AJ,ldr),e(bT,idr),e(ao,ddr),e(ao,vT),e(vT,mdr),e(vT,REe),e(REe,cdr),e(vT,fdr),e(vT,PEe),e(PEe,gdr),e(ao,hdr),M(FT,ao,null),b(c,Kao,_),b(c,Yd,_),e(Yd,TT),e(TT,BEe),M(Ak,BEe,null),e(Yd,udr),e(Yd,IEe),e(IEe,pdr),b(c,eno,_),b(c,Oo,_),M(Lk,Oo,null),e(Oo,_dr),e(Oo,Zd),e(Zd,bdr),e(Zd,LJ),e(LJ,vdr),e(Zd,Fdr),e(Zd,yJ),e(yJ,Tdr),e(Zd,Mdr),e(Oo,Edr),e(Oo,yk),e(yk,Cdr),e(yk,NEe),e(NEe,wdr),e(yk,Adr),e(Oo,Ldr),e(Oo,yt),M(xk,yt,null),e(yt,ydr),e(yt,qEe),e(qEe,xdr),e(yt,$dr),e(yt,Kd),e(Kd,kdr),e(Kd,jEe),e(jEe,Sdr),e(Kd,Rdr),e(Kd,xJ),e(xJ,Pdr),e(Kd,Bdr),e(yt,Idr),M(MT,yt,null),e(Oo,Ndr),e(Oo,no),M($k,no,null),e(no,qdr),e(no,DEe),e(DEe,jdr),e(no,Ddr),e(no,fn),e(fn,Gdr),e(fn,GEe),e(GEe,Odr),e(fn,Vdr),e(fn,OEe),e(OEe,Xdr),e(fn,zdr),e(fn,VEe),e(VEe,Qdr),e(fn,Wdr),e(no,Udr),e(no,I),e(I,ET),e(ET,XEe),e(XEe,Hdr),e(ET,Jdr),e(ET,$J),e($J,Ydr),e(ET,Zdr),e(I,Kdr),e(I,CT),e(CT,zEe),e(zEe,emr),e(CT,omr),e(CT,kJ),e(kJ,rmr),e(CT,tmr),e(I,amr),e(I,wT),e(wT,QEe),e(QEe,nmr),e(wT,smr),e(wT,SJ),e(SJ,lmr),e(wT,imr),e(I,dmr),e(I,AT),e(AT,WEe),e(WEe,mmr),e(AT,cmr),e(AT,RJ),e(RJ,fmr),e(AT,gmr),e(I,hmr),e(I,LT),e(LT,UEe),e(UEe,umr),e(LT,pmr),e(LT,PJ),e(PJ,_mr),e(LT,bmr),e(I,vmr),e(I,yT),e(yT,HEe),e(HEe,Fmr),e(yT,Tmr),e(yT,BJ),e(BJ,Mmr),e(yT,Emr),e(I,Cmr),e(I,xT),e(xT,JEe),e(JEe,wmr),e(xT,Amr),e(xT,IJ),e(IJ,Lmr),e(xT,ymr),e(I,xmr),e(I,$T),e($T,YEe),e(YEe,$mr),e($T,kmr),e($T,NJ),e(NJ,Smr),e($T,Rmr),e(I,Pmr),e(I,kT),e(kT,ZEe),e(ZEe,Bmr),e(kT,Imr),e(kT,qJ),e(qJ,Nmr),e(kT,qmr),e(I,jmr),e(I,ST),e(ST,KEe),e(KEe,Dmr),e(ST,Gmr),e(ST,jJ),e(jJ,Omr),e(ST,Vmr),e(I,Xmr),e(I,RT),e(RT,e4e),e(e4e,zmr),e(RT,Qmr),e(RT,DJ),e(DJ,Wmr),e(RT,Umr),e(I,Hmr),e(I,PT),e(PT,o4e),e(o4e,Jmr),e(PT,Ymr),e(PT,GJ),e(GJ,Zmr),e(PT,Kmr),e(I,ecr),e(I,BT),e(BT,r4e),e(r4e,ocr),e(BT,rcr),e(BT,OJ),e(OJ,tcr),e(BT,acr),e(I,ncr),e(I,IT),e(IT,t4e),e(t4e,scr),e(IT,lcr),e(IT,VJ),e(VJ,icr),e(IT,dcr),e(I,mcr),e(I,NT),e(NT,a4e),e(a4e,ccr),e(NT,fcr),e(NT,XJ),e(XJ,gcr),e(NT,hcr),e(I,ucr),e(I,qT),e(qT,n4e),e(n4e,pcr),e(qT,_cr),e(qT,zJ),e(zJ,bcr),e(qT,vcr),e(I,Fcr),e(I,jT),e(jT,s4e),e(s4e,Tcr),e(jT,Mcr),e(jT,QJ),e(QJ,Ecr),e(jT,Ccr),e(I,wcr),e(I,DT),e(DT,l4e),e(l4e,Acr),e(DT,Lcr),e(DT,WJ),e(WJ,ycr),e(DT,xcr),e(I,$cr),e(I,GT),e(GT,i4e),e(i4e,kcr),e(GT,Scr),e(GT,UJ),e(UJ,Rcr),e(GT,Pcr),e(I,Bcr),e(I,OT),e(OT,d4e),e(d4e,Icr),e(OT,Ncr),e(OT,HJ),e(HJ,qcr),e(OT,jcr),e(I,Dcr),e(I,VT),e(VT,m4e),e(m4e,Gcr),e(VT,Ocr),e(VT,JJ),e(JJ,Vcr),e(VT,Xcr),e(I,zcr),e(I,XT),e(XT,c4e),e(c4e,Qcr),e(XT,Wcr),e(XT,YJ),e(YJ,Ucr),e(XT,Hcr),e(I,Jcr),e(I,zT),e(zT,f4e),e(f4e,Ycr),e(zT,Zcr),e(zT,ZJ),e(ZJ,Kcr),e(zT,efr),e(I,ofr),e(I,QT),e(QT,g4e),e(g4e,rfr),e(QT,tfr),e(QT,KJ),e(KJ,afr),e(QT,nfr),e(I,sfr),e(I,WT),e(WT,h4e),e(h4e,lfr),e(WT,ifr),e(WT,eY),e(eY,dfr),e(WT,mfr),e(I,cfr),e(I,UT),e(UT,u4e),e(u4e,ffr),e(UT,gfr),e(UT,oY),e(oY,hfr),e(UT,ufr),e(I,pfr),e(I,HT),e(HT,p4e),e(p4e,_fr),e(HT,bfr),e(HT,rY),e(rY,vfr),e(HT,Ffr),e(I,Tfr),e(I,JT),e(JT,_4e),e(_4e,Mfr),e(JT,Efr),e(JT,tY),e(tY,Cfr),e(JT,wfr),e(I,Afr),e(I,YT),e(YT,b4e),e(b4e,Lfr),e(YT,yfr),e(YT,aY),e(aY,xfr),e(YT,$fr),e(I,kfr),e(I,ZT),e(ZT,v4e),e(v4e,Sfr),e(ZT,Rfr),e(ZT,nY),e(nY,Pfr),e(ZT,Bfr),e(I,Ifr),e(I,KT),e(KT,F4e),e(F4e,Nfr),e(KT,qfr),e(KT,sY),e(sY,jfr),e(KT,Dfr),e(I,Gfr),e(I,eM),e(eM,T4e),e(T4e,Ofr),e(eM,Vfr),e(eM,lY),e(lY,Xfr),e(eM,zfr),e(I,Qfr),e(I,oM),e(oM,M4e),e(M4e,Wfr),e(oM,Ufr),e(oM,iY),e(iY,Hfr),e(oM,Jfr),e(I,Yfr),e(I,rM),e(rM,E4e),e(E4e,Zfr),e(rM,Kfr),e(rM,dY),e(dY,egr),e(rM,ogr),e(I,rgr),e(I,tM),e(tM,C4e),e(C4e,tgr),e(tM,agr),e(tM,mY),e(mY,ngr),e(tM,sgr),e(I,lgr),e(I,aM),e(aM,w4e),e(w4e,igr),e(aM,dgr),e(aM,cY),e(cY,mgr),e(aM,cgr),e(I,fgr),e(I,nM),e(nM,A4e),e(A4e,ggr),e(nM,hgr),e(nM,fY),e(fY,ugr),e(nM,pgr),e(I,_gr),e(I,sM),e(sM,L4e),e(L4e,bgr),e(sM,vgr),e(sM,gY),e(gY,Fgr),e(sM,Tgr),e(I,Mgr),e(I,lM),e(lM,y4e),e(y4e,Egr),e(lM,Cgr),e(lM,hY),e(hY,wgr),e(lM,Agr),e(I,Lgr),e(I,iM),e(iM,x4e),e(x4e,ygr),e(iM,xgr),e(iM,uY),e(uY,$gr),e(iM,kgr),e(I,Sgr),e(I,dM),e(dM,$4e),e($4e,Rgr),e(dM,Pgr),e(dM,pY),e(pY,Bgr),e(dM,Igr),e(I,Ngr),e(I,mM),e(mM,k4e),e(k4e,qgr),e(mM,jgr),e(mM,_Y),e(_Y,Dgr),e(mM,Ggr),e(I,Ogr),e(I,cM),e(cM,S4e),e(S4e,Vgr),e(cM,Xgr),e(cM,bY),e(bY,zgr),e(cM,Qgr),e(I,Wgr),e(I,fM),e(fM,R4e),e(R4e,Ugr),e(fM,Hgr),e(fM,vY),e(vY,Jgr),e(fM,Ygr),e(I,Zgr),e(I,gM),e(gM,P4e),e(P4e,Kgr),e(gM,ehr),e(gM,FY),e(FY,ohr),e(gM,rhr),e(I,thr),e(I,hM),e(hM,B4e),e(B4e,ahr),e(hM,nhr),e(hM,TY),e(TY,shr),e(hM,lhr),e(I,ihr),e(I,uM),e(uM,I4e),e(I4e,dhr),e(uM,mhr),e(uM,MY),e(MY,chr),e(uM,fhr),e(I,ghr),e(I,pM),e(pM,N4e),e(N4e,hhr),e(pM,uhr),e(pM,EY),e(EY,phr),e(pM,_hr),e(I,bhr),e(I,_M),e(_M,q4e),e(q4e,vhr),e(_M,Fhr),e(_M,CY),e(CY,Thr),e(_M,Mhr),e(I,Ehr),e(I,bM),e(bM,j4e),e(j4e,Chr),e(bM,whr),e(bM,wY),e(wY,Ahr),e(bM,Lhr),e(I,yhr),e(I,vM),e(vM,D4e),e(D4e,xhr),e(vM,$hr),e(vM,AY),e(AY,khr),e(vM,Shr),e(I,Rhr),e(I,FM),e(FM,G4e),e(G4e,Phr),e(FM,Bhr),e(FM,LY),e(LY,Ihr),e(FM,Nhr),e(I,qhr),e(I,TM),e(TM,O4e),e(O4e,jhr),e(TM,Dhr),e(TM,yY),e(yY,Ghr),e(TM,Ohr),e(I,Vhr),e(I,MM),e(MM,V4e),e(V4e,Xhr),e(MM,zhr),e(MM,xY),e(xY,Qhr),e(MM,Whr),e(I,Uhr),e(I,EM),e(EM,X4e),e(X4e,Hhr),e(EM,Jhr),e(EM,$Y),e($Y,Yhr),e(EM,Zhr),e(I,Khr),e(I,CM),e(CM,z4e),e(z4e,eur),e(CM,our),e(CM,kY),e(kY,rur),e(CM,tur),e(I,aur),e(I,wM),e(wM,Q4e),e(Q4e,nur),e(wM,sur),e(wM,SY),e(SY,lur),e(wM,iur),e(no,dur),e(no,AM),e(AM,mur),e(AM,W4e),e(W4e,cur),e(AM,fur),e(AM,U4e),e(U4e,gur),e(no,hur),M(LM,no,null),b(c,ono,_),b(c,em,_),e(em,yM),e(yM,H4e),M(kk,H4e,null),e(em,uur),e(em,J4e),e(J4e,pur),b(c,rno,_),b(c,Vo,_),M(Sk,Vo,null),e(Vo,_ur),e(Vo,om),e(om,bur),e(om,RY),e(RY,vur),e(om,Fur),e(om,PY),e(PY,Tur),e(om,Mur),e(Vo,Eur),e(Vo,Rk),e(Rk,Cur),e(Rk,Y4e),e(Y4e,wur),e(Rk,Aur),e(Vo,Lur),e(Vo,xt),M(Pk,xt,null),e(xt,yur),e(xt,Z4e),e(Z4e,xur),e(xt,$ur),e(xt,rm),e(rm,kur),e(rm,K4e),e(K4e,Sur),e(rm,Rur),e(rm,BY),e(BY,Pur),e(rm,Bur),e(xt,Iur),M(xM,xt,null),e(Vo,Nur),e(Vo,so),M(Bk,so,null),e(so,qur),e(so,eCe),e(eCe,jur),e(so,Dur),e(so,gn),e(gn,Gur),e(gn,oCe),e(oCe,Our),e(gn,Vur),e(gn,rCe),e(rCe,Xur),e(gn,zur),e(gn,tCe),e(tCe,Qur),e(gn,Wur),e(so,Uur),e(so,K),e(K,$M),e($M,aCe),e(aCe,Hur),e($M,Jur),e($M,IY),e(IY,Yur),e($M,Zur),e(K,Kur),e(K,kM),e(kM,nCe),e(nCe,epr),e(kM,opr),e(kM,NY),e(NY,rpr),e(kM,tpr),e(K,apr),e(K,SM),e(SM,sCe),e(sCe,npr),e(SM,spr),e(SM,qY),e(qY,lpr),e(SM,ipr),e(K,dpr),e(K,RM),e(RM,lCe),e(lCe,mpr),e(RM,cpr),e(RM,jY),e(jY,fpr),e(RM,gpr),e(K,hpr),e(K,PM),e(PM,iCe),e(iCe,upr),e(PM,ppr),e(PM,DY),e(DY,_pr),e(PM,bpr),e(K,vpr),e(K,BM),e(BM,dCe),e(dCe,Fpr),e(BM,Tpr),e(BM,GY),e(GY,Mpr),e(BM,Epr),e(K,Cpr),e(K,IM),e(IM,mCe),e(mCe,wpr),e(IM,Apr),e(IM,OY),e(OY,Lpr),e(IM,ypr),e(K,xpr),e(K,NM),e(NM,cCe),e(cCe,$pr),e(NM,kpr),e(NM,VY),e(VY,Spr),e(NM,Rpr),e(K,Ppr),e(K,qM),e(qM,fCe),e(fCe,Bpr),e(qM,Ipr),e(qM,XY),e(XY,Npr),e(qM,qpr),e(K,jpr),e(K,jM),e(jM,gCe),e(gCe,Dpr),e(jM,Gpr),e(jM,zY),e(zY,Opr),e(jM,Vpr),e(K,Xpr),e(K,DM),e(DM,hCe),e(hCe,zpr),e(DM,Qpr),e(DM,QY),e(QY,Wpr),e(DM,Upr),e(K,Hpr),e(K,GM),e(GM,uCe),e(uCe,Jpr),e(GM,Ypr),e(GM,WY),e(WY,Zpr),e(GM,Kpr),e(K,e_r),e(K,OM),e(OM,pCe),e(pCe,o_r),e(OM,r_r),e(OM,UY),e(UY,t_r),e(OM,a_r),e(K,n_r),e(K,VM),e(VM,_Ce),e(_Ce,s_r),e(VM,l_r),e(VM,HY),e(HY,i_r),e(VM,d_r),e(K,m_r),e(K,XM),e(XM,bCe),e(bCe,c_r),e(XM,f_r),e(XM,JY),e(JY,g_r),e(XM,h_r),e(K,u_r),e(K,zM),e(zM,vCe),e(vCe,p_r),e(zM,__r),e(zM,YY),e(YY,b_r),e(zM,v_r),e(K,F_r),e(K,QM),e(QM,FCe),e(FCe,T_r),e(QM,M_r),e(QM,ZY),e(ZY,E_r),e(QM,C_r),e(K,w_r),e(K,WM),e(WM,TCe),e(TCe,A_r),e(WM,L_r),e(WM,KY),e(KY,y_r),e(WM,x_r),e(K,$_r),e(K,UM),e(UM,MCe),e(MCe,k_r),e(UM,S_r),e(UM,eZ),e(eZ,R_r),e(UM,P_r),e(K,B_r),e(K,HM),e(HM,ECe),e(ECe,I_r),e(HM,N_r),e(HM,oZ),e(oZ,q_r),e(HM,j_r),e(K,D_r),e(K,JM),e(JM,CCe),e(CCe,G_r),e(JM,O_r),e(JM,rZ),e(rZ,V_r),e(JM,X_r),e(K,z_r),e(K,YM),e(YM,wCe),e(wCe,Q_r),e(YM,W_r),e(YM,tZ),e(tZ,U_r),e(YM,H_r),e(K,J_r),e(K,ZM),e(ZM,ACe),e(ACe,Y_r),e(ZM,Z_r),e(ZM,aZ),e(aZ,K_r),e(ZM,e1r),e(K,o1r),e(K,KM),e(KM,LCe),e(LCe,r1r),e(KM,t1r),e(KM,nZ),e(nZ,a1r),e(KM,n1r),e(K,s1r),e(K,eE),e(eE,yCe),e(yCe,l1r),e(eE,i1r),e(eE,sZ),e(sZ,d1r),e(eE,m1r),e(K,c1r),e(K,oE),e(oE,xCe),e(xCe,f1r),e(oE,g1r),e(oE,lZ),e(lZ,h1r),e(oE,u1r),e(K,p1r),e(K,rE),e(rE,$Ce),e($Ce,_1r),e(rE,b1r),e(rE,iZ),e(iZ,v1r),e(rE,F1r),e(K,T1r),e(K,tE),e(tE,kCe),e(kCe,M1r),e(tE,E1r),e(tE,dZ),e(dZ,C1r),e(tE,w1r),e(K,A1r),e(K,aE),e(aE,SCe),e(SCe,L1r),e(aE,y1r),e(aE,mZ),e(mZ,x1r),e(aE,$1r),e(K,k1r),e(K,nE),e(nE,RCe),e(RCe,S1r),e(nE,R1r),e(nE,cZ),e(cZ,P1r),e(nE,B1r),e(K,I1r),e(K,sE),e(sE,PCe),e(PCe,N1r),e(sE,q1r),e(sE,fZ),e(fZ,j1r),e(sE,D1r),e(K,G1r),e(K,lE),e(lE,BCe),e(BCe,O1r),e(lE,V1r),e(lE,gZ),e(gZ,X1r),e(lE,z1r),e(K,Q1r),e(K,iE),e(iE,ICe),e(ICe,W1r),e(iE,U1r),e(iE,hZ),e(hZ,H1r),e(iE,J1r),e(so,Y1r),e(so,dE),e(dE,Z1r),e(dE,NCe),e(NCe,K1r),e(dE,e2r),e(dE,qCe),e(qCe,o2r),e(so,r2r),M(mE,so,null),b(c,tno,_),b(c,tm,_),e(tm,cE),e(cE,jCe),M(Ik,jCe,null),e(tm,t2r),e(tm,DCe),e(DCe,a2r),b(c,ano,_),b(c,Xo,_),M(Nk,Xo,null),e(Xo,n2r),e(Xo,am),e(am,s2r),e(am,uZ),e(uZ,l2r),e(am,i2r),e(am,pZ),e(pZ,d2r),e(am,m2r),e(Xo,c2r),e(Xo,qk),e(qk,f2r),e(qk,GCe),e(GCe,g2r),e(qk,h2r),e(Xo,u2r),e(Xo,$t),M(jk,$t,null),e($t,p2r),e($t,OCe),e(OCe,_2r),e($t,b2r),e($t,nm),e(nm,v2r),e(nm,VCe),e(VCe,F2r),e(nm,T2r),e(nm,_Z),e(_Z,M2r),e(nm,E2r),e($t,C2r),M(fE,$t,null),e(Xo,w2r),e(Xo,lo),M(Dk,lo,null),e(lo,A2r),e(lo,XCe),e(XCe,L2r),e(lo,y2r),e(lo,hn),e(hn,x2r),e(hn,zCe),e(zCe,$2r),e(hn,k2r),e(hn,QCe),e(QCe,S2r),e(hn,R2r),e(hn,WCe),e(WCe,P2r),e(hn,B2r),e(lo,I2r),e(lo,Ue),e(Ue,gE),e(gE,UCe),e(UCe,N2r),e(gE,q2r),e(gE,bZ),e(bZ,j2r),e(gE,D2r),e(Ue,G2r),e(Ue,hE),e(hE,HCe),e(HCe,O2r),e(hE,V2r),e(hE,vZ),e(vZ,X2r),e(hE,z2r),e(Ue,Q2r),e(Ue,uE),e(uE,JCe),e(JCe,W2r),e(uE,U2r),e(uE,FZ),e(FZ,H2r),e(uE,J2r),e(Ue,Y2r),e(Ue,pE),e(pE,YCe),e(YCe,Z2r),e(pE,K2r),e(pE,TZ),e(TZ,ebr),e(pE,obr),e(Ue,rbr),e(Ue,_E),e(_E,ZCe),e(ZCe,tbr),e(_E,abr),e(_E,MZ),e(MZ,nbr),e(_E,sbr),e(Ue,lbr),e(Ue,bE),e(bE,KCe),e(KCe,ibr),e(bE,dbr),e(bE,EZ),e(EZ,mbr),e(bE,cbr),e(Ue,fbr),e(Ue,vE),e(vE,e3e),e(e3e,gbr),e(vE,hbr),e(vE,CZ),e(CZ,ubr),e(vE,pbr),e(lo,_br),e(lo,FE),e(FE,bbr),e(FE,o3e),e(o3e,vbr),e(FE,Fbr),e(FE,r3e),e(r3e,Tbr),e(lo,Mbr),M(TE,lo,null),b(c,nno,_),b(c,sm,_),e(sm,ME),e(ME,t3e),M(Gk,t3e,null),e(sm,Ebr),e(sm,a3e),e(a3e,Cbr),b(c,sno,_),b(c,zo,_),M(Ok,zo,null),e(zo,wbr),e(zo,lm),e(lm,Abr),e(lm,wZ),e(wZ,Lbr),e(lm,ybr),e(lm,AZ),e(AZ,xbr),e(lm,$br),e(zo,kbr),e(zo,Vk),e(Vk,Sbr),e(Vk,n3e),e(n3e,Rbr),e(Vk,Pbr),e(zo,Bbr),e(zo,kt),M(Xk,kt,null),e(kt,Ibr),e(kt,s3e),e(s3e,Nbr),e(kt,qbr),e(kt,im),e(im,jbr),e(im,l3e),e(l3e,Dbr),e(im,Gbr),e(im,LZ),e(LZ,Obr),e(im,Vbr),e(kt,Xbr),M(EE,kt,null),e(zo,zbr),e(zo,io),M(zk,io,null),e(io,Qbr),e(io,i3e),e(i3e,Wbr),e(io,Ubr),e(io,un),e(un,Hbr),e(un,d3e),e(d3e,Jbr),e(un,Ybr),e(un,m3e),e(m3e,Zbr),e(un,Kbr),e(un,c3e),e(c3e,evr),e(un,ovr),e(io,rvr),e(io,U),e(U,CE),e(CE,f3e),e(f3e,tvr),e(CE,avr),e(CE,yZ),e(yZ,nvr),e(CE,svr),e(U,lvr),e(U,wE),e(wE,g3e),e(g3e,ivr),e(wE,dvr),e(wE,xZ),e(xZ,mvr),e(wE,cvr),e(U,fvr),e(U,AE),e(AE,h3e),e(h3e,gvr),e(AE,hvr),e(AE,$Z),e($Z,uvr),e(AE,pvr),e(U,_vr),e(U,LE),e(LE,u3e),e(u3e,bvr),e(LE,vvr),e(LE,kZ),e(kZ,Fvr),e(LE,Tvr),e(U,Mvr),e(U,yE),e(yE,p3e),e(p3e,Evr),e(yE,Cvr),e(yE,SZ),e(SZ,wvr),e(yE,Avr),e(U,Lvr),e(U,xE),e(xE,_3e),e(_3e,yvr),e(xE,xvr),e(xE,RZ),e(RZ,$vr),e(xE,kvr),e(U,Svr),e(U,$E),e($E,b3e),e(b3e,Rvr),e($E,Pvr),e($E,PZ),e(PZ,Bvr),e($E,Ivr),e(U,Nvr),e(U,kE),e(kE,v3e),e(v3e,qvr),e(kE,jvr),e(kE,BZ),e(BZ,Dvr),e(kE,Gvr),e(U,Ovr),e(U,SE),e(SE,F3e),e(F3e,Vvr),e(SE,Xvr),e(SE,IZ),e(IZ,zvr),e(SE,Qvr),e(U,Wvr),e(U,RE),e(RE,T3e),e(T3e,Uvr),e(RE,Hvr),e(RE,NZ),e(NZ,Jvr),e(RE,Yvr),e(U,Zvr),e(U,PE),e(PE,M3e),e(M3e,Kvr),e(PE,eFr),e(PE,qZ),e(qZ,oFr),e(PE,rFr),e(U,tFr),e(U,BE),e(BE,E3e),e(E3e,aFr),e(BE,nFr),e(BE,jZ),e(jZ,sFr),e(BE,lFr),e(U,iFr),e(U,IE),e(IE,C3e),e(C3e,dFr),e(IE,mFr),e(IE,DZ),e(DZ,cFr),e(IE,fFr),e(U,gFr),e(U,NE),e(NE,w3e),e(w3e,hFr),e(NE,uFr),e(NE,GZ),e(GZ,pFr),e(NE,_Fr),e(U,bFr),e(U,qE),e(qE,A3e),e(A3e,vFr),e(qE,FFr),e(qE,OZ),e(OZ,TFr),e(qE,MFr),e(U,EFr),e(U,jE),e(jE,L3e),e(L3e,CFr),e(jE,wFr),e(jE,VZ),e(VZ,AFr),e(jE,LFr),e(U,yFr),e(U,DE),e(DE,y3e),e(y3e,xFr),e(DE,$Fr),e(DE,XZ),e(XZ,kFr),e(DE,SFr),e(U,RFr),e(U,GE),e(GE,x3e),e(x3e,PFr),e(GE,BFr),e(GE,zZ),e(zZ,IFr),e(GE,NFr),e(U,qFr),e(U,OE),e(OE,$3e),e($3e,jFr),e(OE,DFr),e(OE,QZ),e(QZ,GFr),e(OE,OFr),e(U,VFr),e(U,VE),e(VE,k3e),e(k3e,XFr),e(VE,zFr),e(VE,WZ),e(WZ,QFr),e(VE,WFr),e(U,UFr),e(U,XE),e(XE,S3e),e(S3e,HFr),e(XE,JFr),e(XE,UZ),e(UZ,YFr),e(XE,ZFr),e(U,KFr),e(U,zE),e(zE,R3e),e(R3e,eTr),e(zE,oTr),e(zE,HZ),e(HZ,rTr),e(zE,tTr),e(U,aTr),e(U,QE),e(QE,P3e),e(P3e,nTr),e(QE,sTr),e(QE,JZ),e(JZ,lTr),e(QE,iTr),e(U,dTr),e(U,WE),e(WE,B3e),e(B3e,mTr),e(WE,cTr),e(WE,YZ),e(YZ,fTr),e(WE,gTr),e(U,hTr),e(U,UE),e(UE,I3e),e(I3e,uTr),e(UE,pTr),e(UE,ZZ),e(ZZ,_Tr),e(UE,bTr),e(U,vTr),e(U,HE),e(HE,N3e),e(N3e,FTr),e(HE,TTr),e(HE,KZ),e(KZ,MTr),e(HE,ETr),e(U,CTr),e(U,JE),e(JE,q3e),e(q3e,wTr),e(JE,ATr),e(JE,eK),e(eK,LTr),e(JE,yTr),e(U,xTr),e(U,YE),e(YE,j3e),e(j3e,$Tr),e(YE,kTr),e(YE,oK),e(oK,STr),e(YE,RTr),e(U,PTr),e(U,ZE),e(ZE,D3e),e(D3e,BTr),e(ZE,ITr),e(ZE,rK),e(rK,NTr),e(ZE,qTr),e(U,jTr),e(U,KE),e(KE,G3e),e(G3e,DTr),e(KE,GTr),e(KE,tK),e(tK,OTr),e(KE,VTr),e(U,XTr),e(U,e4),e(e4,O3e),e(O3e,zTr),e(e4,QTr),e(e4,aK),e(aK,WTr),e(e4,UTr),e(U,HTr),e(U,o4),e(o4,V3e),e(V3e,JTr),e(o4,YTr),e(o4,nK),e(nK,ZTr),e(o4,KTr),e(U,eMr),e(U,r4),e(r4,X3e),e(X3e,oMr),e(r4,rMr),e(r4,sK),e(sK,tMr),e(r4,aMr),e(U,nMr),e(U,t4),e(t4,z3e),e(z3e,sMr),e(t4,lMr),e(t4,lK),e(lK,iMr),e(t4,dMr),e(U,mMr),e(U,a4),e(a4,Q3e),e(Q3e,cMr),e(a4,fMr),e(a4,iK),e(iK,gMr),e(a4,hMr),e(U,uMr),e(U,n4),e(n4,W3e),e(W3e,pMr),e(n4,_Mr),e(n4,dK),e(dK,bMr),e(n4,vMr),e(U,FMr),e(U,s4),e(s4,U3e),e(U3e,TMr),e(s4,MMr),e(s4,mK),e(mK,EMr),e(s4,CMr),e(U,wMr),e(U,l4),e(l4,H3e),e(H3e,AMr),e(l4,LMr),e(l4,cK),e(cK,yMr),e(l4,xMr),e(U,$Mr),e(U,i4),e(i4,J3e),e(J3e,kMr),e(i4,SMr),e(i4,fK),e(fK,RMr),e(i4,PMr),e(U,BMr),e(U,d4),e(d4,Y3e),e(Y3e,IMr),e(d4,NMr),e(d4,gK),e(gK,qMr),e(d4,jMr),e(U,DMr),e(U,m4),e(m4,Z3e),e(Z3e,GMr),e(m4,OMr),e(m4,hK),e(hK,VMr),e(m4,XMr),e(U,zMr),e(U,c4),e(c4,K3e),e(K3e,QMr),e(c4,WMr),e(c4,uK),e(uK,UMr),e(c4,HMr),e(io,JMr),e(io,f4),e(f4,YMr),e(f4,e5e),e(e5e,ZMr),e(f4,KMr),e(f4,o5e),e(o5e,eEr),e(io,oEr),M(g4,io,null),b(c,lno,_),b(c,dm,_),e(dm,h4),e(h4,r5e),M(Qk,r5e,null),e(dm,rEr),e(dm,t5e),e(t5e,tEr),b(c,ino,_),b(c,Qo,_),M(Wk,Qo,null),e(Qo,aEr),e(Qo,mm),e(mm,nEr),e(mm,pK),e(pK,sEr),e(mm,lEr),e(mm,_K),e(_K,iEr),e(mm,dEr),e(Qo,mEr),e(Qo,Uk),e(Uk,cEr),e(Uk,a5e),e(a5e,fEr),e(Uk,gEr),e(Qo,hEr),e(Qo,St),M(Hk,St,null),e(St,uEr),e(St,n5e),e(n5e,pEr),e(St,_Er),e(St,cm),e(cm,bEr),e(cm,s5e),e(s5e,vEr),e(cm,FEr),e(cm,bK),e(bK,TEr),e(cm,MEr),e(St,EEr),M(u4,St,null),e(Qo,CEr),e(Qo,mo),M(Jk,mo,null),e(mo,wEr),e(mo,l5e),e(l5e,AEr),e(mo,LEr),e(mo,pn),e(pn,yEr),e(pn,i5e),e(i5e,xEr),e(pn,$Er),e(pn,d5e),e(d5e,kEr),e(pn,SEr),e(pn,m5e),e(m5e,REr),e(pn,PEr),e(mo,BEr),e(mo,O),e(O,p4),e(p4,c5e),e(c5e,IEr),e(p4,NEr),e(p4,vK),e(vK,qEr),e(p4,jEr),e(O,DEr),e(O,_4),e(_4,f5e),e(f5e,GEr),e(_4,OEr),e(_4,FK),e(FK,VEr),e(_4,XEr),e(O,zEr),e(O,b4),e(b4,g5e),e(g5e,QEr),e(b4,WEr),e(b4,TK),e(TK,UEr),e(b4,HEr),e(O,JEr),e(O,v4),e(v4,h5e),e(h5e,YEr),e(v4,ZEr),e(v4,MK),e(MK,KEr),e(v4,e4r),e(O,o4r),e(O,F4),e(F4,u5e),e(u5e,r4r),e(F4,t4r),e(F4,EK),e(EK,a4r),e(F4,n4r),e(O,s4r),e(O,T4),e(T4,p5e),e(p5e,l4r),e(T4,i4r),e(T4,CK),e(CK,d4r),e(T4,m4r),e(O,c4r),e(O,M4),e(M4,_5e),e(_5e,f4r),e(M4,g4r),e(M4,wK),e(wK,h4r),e(M4,u4r),e(O,p4r),e(O,E4),e(E4,b5e),e(b5e,_4r),e(E4,b4r),e(E4,AK),e(AK,v4r),e(E4,F4r),e(O,T4r),e(O,C4),e(C4,v5e),e(v5e,M4r),e(C4,E4r),e(C4,LK),e(LK,C4r),e(C4,w4r),e(O,A4r),e(O,w4),e(w4,F5e),e(F5e,L4r),e(w4,y4r),e(w4,yK),e(yK,x4r),e(w4,$4r),e(O,k4r),e(O,A4),e(A4,T5e),e(T5e,S4r),e(A4,R4r),e(A4,xK),e(xK,P4r),e(A4,B4r),e(O,I4r),e(O,L4),e(L4,M5e),e(M5e,N4r),e(L4,q4r),e(L4,$K),e($K,j4r),e(L4,D4r),e(O,G4r),e(O,y4),e(y4,E5e),e(E5e,O4r),e(y4,V4r),e(y4,kK),e(kK,X4r),e(y4,z4r),e(O,Q4r),e(O,x4),e(x4,C5e),e(C5e,W4r),e(x4,U4r),e(x4,SK),e(SK,H4r),e(x4,J4r),e(O,Y4r),e(O,$4),e($4,w5e),e(w5e,Z4r),e($4,K4r),e($4,RK),e(RK,eCr),e($4,oCr),e(O,rCr),e(O,k4),e(k4,A5e),e(A5e,tCr),e(k4,aCr),e(k4,PK),e(PK,nCr),e(k4,sCr),e(O,lCr),e(O,S4),e(S4,L5e),e(L5e,iCr),e(S4,dCr),e(S4,BK),e(BK,mCr),e(S4,cCr),e(O,fCr),e(O,R4),e(R4,y5e),e(y5e,gCr),e(R4,hCr),e(R4,IK),e(IK,uCr),e(R4,pCr),e(O,_Cr),e(O,P4),e(P4,x5e),e(x5e,bCr),e(P4,vCr),e(P4,NK),e(NK,FCr),e(P4,TCr),e(O,MCr),e(O,B4),e(B4,$5e),e($5e,ECr),e(B4,CCr),e(B4,qK),e(qK,wCr),e(B4,ACr),e(O,LCr),e(O,I4),e(I4,k5e),e(k5e,yCr),e(I4,xCr),e(I4,jK),e(jK,$Cr),e(I4,kCr),e(O,SCr),e(O,N4),e(N4,S5e),e(S5e,RCr),e(N4,PCr),e(N4,DK),e(DK,BCr),e(N4,ICr),e(O,NCr),e(O,q4),e(q4,R5e),e(R5e,qCr),e(q4,jCr),e(q4,GK),e(GK,DCr),e(q4,GCr),e(O,OCr),e(O,j4),e(j4,P5e),e(P5e,VCr),e(j4,XCr),e(j4,OK),e(OK,zCr),e(j4,QCr),e(O,WCr),e(O,D4),e(D4,B5e),e(B5e,UCr),e(D4,HCr),e(D4,VK),e(VK,JCr),e(D4,YCr),e(O,ZCr),e(O,G4),e(G4,I5e),e(I5e,KCr),e(G4,e3r),e(G4,XK),e(XK,o3r),e(G4,r3r),e(O,t3r),e(O,O4),e(O4,N5e),e(N5e,a3r),e(O4,n3r),e(O4,zK),e(zK,s3r),e(O4,l3r),e(O,i3r),e(O,V4),e(V4,q5e),e(q5e,d3r),e(V4,m3r),e(V4,QK),e(QK,c3r),e(V4,f3r),e(O,g3r),e(O,X4),e(X4,j5e),e(j5e,h3r),e(X4,u3r),e(X4,WK),e(WK,p3r),e(X4,_3r),e(O,b3r),e(O,z4),e(z4,D5e),e(D5e,v3r),e(z4,F3r),e(z4,UK),e(UK,T3r),e(z4,M3r),e(O,E3r),e(O,Q4),e(Q4,G5e),e(G5e,C3r),e(Q4,w3r),e(Q4,HK),e(HK,A3r),e(Q4,L3r),e(O,y3r),e(O,W4),e(W4,O5e),e(O5e,x3r),e(W4,$3r),e(W4,JK),e(JK,k3r),e(W4,S3r),e(O,R3r),e(O,U4),e(U4,V5e),e(V5e,P3r),e(U4,B3r),e(U4,YK),e(YK,I3r),e(U4,N3r),e(O,q3r),e(O,H4),e(H4,X5e),e(X5e,j3r),e(H4,D3r),e(H4,ZK),e(ZK,G3r),e(H4,O3r),e(O,V3r),e(O,J4),e(J4,z5e),e(z5e,X3r),e(J4,z3r),e(J4,KK),e(KK,Q3r),e(J4,W3r),e(O,U3r),e(O,Y4),e(Y4,Q5e),e(Q5e,H3r),e(Y4,J3r),e(Y4,eee),e(eee,Y3r),e(Y4,Z3r),e(O,K3r),e(O,Z4),e(Z4,W5e),e(W5e,e5r),e(Z4,o5r),e(Z4,oee),e(oee,r5r),e(Z4,t5r),e(O,a5r),e(O,K4),e(K4,U5e),e(U5e,n5r),e(K4,s5r),e(K4,ree),e(ree,l5r),e(K4,i5r),e(O,d5r),e(O,eC),e(eC,H5e),e(H5e,m5r),e(eC,c5r),e(eC,tee),e(tee,f5r),e(eC,g5r),e(O,h5r),e(O,oC),e(oC,J5e),e(J5e,u5r),e(oC,p5r),e(oC,aee),e(aee,_5r),e(oC,b5r),e(O,v5r),e(O,rC),e(rC,Y5e),e(Y5e,F5r),e(rC,T5r),e(rC,nee),e(nee,M5r),e(rC,E5r),e(O,C5r),e(O,tC),e(tC,Z5e),e(Z5e,w5r),e(tC,A5r),e(tC,see),e(see,L5r),e(tC,y5r),e(O,x5r),e(O,aC),e(aC,K5e),e(K5e,$5r),e(aC,k5r),e(aC,lee),e(lee,S5r),e(aC,R5r),e(O,P5r),e(O,nC),e(nC,e0e),e(e0e,B5r),e(nC,I5r),e(nC,iee),e(iee,N5r),e(nC,q5r),e(O,j5r),e(O,sC),e(sC,o0e),e(o0e,D5r),e(sC,G5r),e(sC,dee),e(dee,O5r),e(sC,V5r),e(O,X5r),e(O,lC),e(lC,r0e),e(r0e,z5r),e(lC,Q5r),e(lC,mee),e(mee,W5r),e(lC,U5r),e(O,H5r),e(O,iC),e(iC,t0e),e(t0e,J5r),e(iC,Y5r),e(iC,cee),e(cee,Z5r),e(iC,K5r),e(O,e0r),e(O,dC),e(dC,a0e),e(a0e,o0r),e(dC,r0r),e(dC,fee),e(fee,t0r),e(dC,a0r),e(O,n0r),e(O,mC),e(mC,n0e),e(n0e,s0r),e(mC,l0r),e(mC,gee),e(gee,i0r),e(mC,d0r),e(mo,m0r),e(mo,cC),e(cC,c0r),e(cC,s0e),e(s0e,f0r),e(cC,g0r),e(cC,l0e),e(l0e,h0r),e(mo,u0r),M(fC,mo,null),b(c,dno,_),b(c,fm,_),e(fm,gC),e(gC,i0e),M(Yk,i0e,null),e(fm,p0r),e(fm,d0e),e(d0e,_0r),b(c,mno,_),b(c,Wo,_),M(Zk,Wo,null),e(Wo,b0r),e(Wo,gm),e(gm,v0r),e(gm,hee),e(hee,F0r),e(gm,T0r),e(gm,uee),e(uee,M0r),e(gm,E0r),e(Wo,C0r),e(Wo,Kk),e(Kk,w0r),e(Kk,m0e),e(m0e,A0r),e(Kk,L0r),e(Wo,y0r),e(Wo,Rt),M(eS,Rt,null),e(Rt,x0r),e(Rt,c0e),e(c0e,$0r),e(Rt,k0r),e(Rt,hm),e(hm,S0r),e(hm,f0e),e(f0e,R0r),e(hm,P0r),e(hm,pee),e(pee,B0r),e(hm,I0r),e(Rt,N0r),M(hC,Rt,null),e(Wo,q0r),e(Wo,co),M(oS,co,null),e(co,j0r),e(co,g0e),e(g0e,D0r),e(co,G0r),e(co,_n),e(_n,O0r),e(_n,h0e),e(h0e,V0r),e(_n,X0r),e(_n,u0e),e(u0e,z0r),e(_n,Q0r),e(_n,p0e),e(p0e,W0r),e(_n,U0r),e(co,H0r),e(co,_0e),e(_0e,uC),e(uC,b0e),e(b0e,J0r),e(uC,Y0r),e(uC,_ee),e(_ee,Z0r),e(uC,K0r),e(co,ewr),e(co,pC),e(pC,owr),e(pC,v0e),e(v0e,rwr),e(pC,twr),e(pC,F0e),e(F0e,awr),e(co,nwr),M(_C,co,null),b(c,cno,_),b(c,um,_),e(um,bC),e(bC,T0e),M(rS,T0e,null),e(um,swr),e(um,M0e),e(M0e,lwr),b(c,fno,_),b(c,Uo,_),M(tS,Uo,null),e(Uo,iwr),e(Uo,pm),e(pm,dwr),e(pm,bee),e(bee,mwr),e(pm,cwr),e(pm,vee),e(vee,fwr),e(pm,gwr),e(Uo,hwr),e(Uo,aS),e(aS,uwr),e(aS,E0e),e(E0e,pwr),e(aS,_wr),e(Uo,bwr),e(Uo,Pt),M(nS,Pt,null),e(Pt,vwr),e(Pt,C0e),e(C0e,Fwr),e(Pt,Twr),e(Pt,_m),e(_m,Mwr),e(_m,w0e),e(w0e,Ewr),e(_m,Cwr),e(_m,Fee),e(Fee,wwr),e(_m,Awr),e(Pt,Lwr),M(vC,Pt,null),e(Uo,ywr),e(Uo,fo),M(sS,fo,null),e(fo,xwr),e(fo,A0e),e(A0e,$wr),e(fo,kwr),e(fo,bn),e(bn,Swr),e(bn,L0e),e(L0e,Rwr),e(bn,Pwr),e(bn,y0e),e(y0e,Bwr),e(bn,Iwr),e(bn,x0e),e(x0e,Nwr),e(bn,qwr),e(fo,jwr),e(fo,bm),e(bm,FC),e(FC,$0e),e($0e,Dwr),e(FC,Gwr),e(FC,Tee),e(Tee,Owr),e(FC,Vwr),e(bm,Xwr),e(bm,TC),e(TC,k0e),e(k0e,zwr),e(TC,Qwr),e(TC,Mee),e(Mee,Wwr),e(TC,Uwr),e(bm,Hwr),e(bm,MC),e(MC,S0e),e(S0e,Jwr),e(MC,Ywr),e(MC,Eee),e(Eee,Zwr),e(MC,Kwr),e(fo,eAr),e(fo,EC),e(EC,oAr),e(EC,R0e),e(R0e,rAr),e(EC,tAr),e(EC,P0e),e(P0e,aAr),e(fo,nAr),M(CC,fo,null),b(c,gno,_),b(c,vm,_),e(vm,wC),e(wC,B0e),M(lS,B0e,null),e(vm,sAr),e(vm,I0e),e(I0e,lAr),b(c,hno,_),b(c,Ho,_),M(iS,Ho,null),e(Ho,iAr),e(Ho,Fm),e(Fm,dAr),e(Fm,Cee),e(Cee,mAr),e(Fm,cAr),e(Fm,wee),e(wee,fAr),e(Fm,gAr),e(Ho,hAr),e(Ho,dS),e(dS,uAr),e(dS,N0e),e(N0e,pAr),e(dS,_Ar),e(Ho,bAr),e(Ho,Bt),M(mS,Bt,null),e(Bt,vAr),e(Bt,q0e),e(q0e,FAr),e(Bt,TAr),e(Bt,Tm),e(Tm,MAr),e(Tm,j0e),e(j0e,EAr),e(Tm,CAr),e(Tm,Aee),e(Aee,wAr),e(Tm,AAr),e(Bt,LAr),M(AC,Bt,null),e(Ho,yAr),e(Ho,go),M(cS,go,null),e(go,xAr),e(go,D0e),e(D0e,$Ar),e(go,kAr),e(go,vn),e(vn,SAr),e(vn,G0e),e(G0e,RAr),e(vn,PAr),e(vn,O0e),e(O0e,BAr),e(vn,IAr),e(vn,V0e),e(V0e,NAr),e(vn,qAr),e(go,jAr),e(go,be),e(be,LC),e(LC,X0e),e(X0e,DAr),e(LC,GAr),e(LC,Lee),e(Lee,OAr),e(LC,VAr),e(be,XAr),e(be,yC),e(yC,z0e),e(z0e,zAr),e(yC,QAr),e(yC,yee),e(yee,WAr),e(yC,UAr),e(be,HAr),e(be,xC),e(xC,Q0e),e(Q0e,JAr),e(xC,YAr),e(xC,xee),e(xee,ZAr),e(xC,KAr),e(be,e6r),e(be,$C),e($C,W0e),e(W0e,o6r),e($C,r6r),e($C,$ee),e($ee,t6r),e($C,a6r),e(be,n6r),e(be,kl),e(kl,U0e),e(U0e,s6r),e(kl,l6r),e(kl,kee),e(kee,i6r),e(kl,d6r),e(kl,See),e(See,m6r),e(kl,c6r),e(be,f6r),e(be,kC),e(kC,H0e),e(H0e,g6r),e(kC,h6r),e(kC,Ree),e(Ree,u6r),e(kC,p6r),e(be,_6r),e(be,Sl),e(Sl,J0e),e(J0e,b6r),e(Sl,v6r),e(Sl,Pee),e(Pee,F6r),e(Sl,T6r),e(Sl,Bee),e(Bee,M6r),e(Sl,E6r),e(be,C6r),e(be,SC),e(SC,Y0e),e(Y0e,w6r),e(SC,A6r),e(SC,Iee),e(Iee,L6r),e(SC,y6r),e(be,x6r),e(be,It),e(It,Z0e),e(Z0e,$6r),e(It,k6r),e(It,Nee),e(Nee,S6r),e(It,R6r),e(It,qee),e(qee,P6r),e(It,B6r),e(It,jee),e(jee,I6r),e(It,N6r),e(be,q6r),e(be,RC),e(RC,K0e),e(K0e,j6r),e(RC,D6r),e(RC,Dee),e(Dee,G6r),e(RC,O6r),e(be,V6r),e(be,PC),e(PC,ewe),e(ewe,X6r),e(PC,z6r),e(PC,Gee),e(Gee,Q6r),e(PC,W6r),e(be,U6r),e(be,BC),e(BC,owe),e(owe,H6r),e(BC,J6r),e(BC,Oee),e(Oee,Y6r),e(BC,Z6r),e(be,K6r),e(be,IC),e(IC,rwe),e(rwe,e7r),e(IC,o7r),e(IC,Vee),e(Vee,r7r),e(IC,t7r),e(be,a7r),e(be,NC),e(NC,twe),e(twe,n7r),e(NC,s7r),e(NC,Xee),e(Xee,l7r),e(NC,i7r),e(be,d7r),e(be,qC),e(qC,awe),e(awe,m7r),e(qC,c7r),e(qC,zee),e(zee,f7r),e(qC,g7r),e(be,h7r),e(be,jC),e(jC,nwe),e(nwe,u7r),e(jC,p7r),e(jC,Qee),e(Qee,_7r),e(jC,b7r),e(be,v7r),e(be,DC),e(DC,swe),e(swe,F7r),e(DC,T7r),e(DC,Wee),e(Wee,M7r),e(DC,E7r),e(be,C7r),e(be,GC),e(GC,lwe),e(lwe,w7r),e(GC,A7r),e(GC,Uee),e(Uee,L7r),e(GC,y7r),e(go,x7r),e(go,OC),e(OC,$7r),e(OC,iwe),e(iwe,k7r),e(OC,S7r),e(OC,dwe),e(dwe,R7r),e(go,P7r),M(VC,go,null),b(c,uno,_),b(c,Mm,_),e(Mm,XC),e(XC,mwe),M(fS,mwe,null),e(Mm,B7r),e(Mm,cwe),e(cwe,I7r),b(c,pno,_),b(c,Jo,_),M(gS,Jo,null),e(Jo,N7r),e(Jo,Em),e(Em,q7r),e(Em,Hee),e(Hee,j7r),e(Em,D7r),e(Em,Jee),e(Jee,G7r),e(Em,O7r),e(Jo,V7r),e(Jo,hS),e(hS,X7r),e(hS,fwe),e(fwe,z7r),e(hS,Q7r),e(Jo,W7r),e(Jo,Nt),M(uS,Nt,null),e(Nt,U7r),e(Nt,gwe),e(gwe,H7r),e(Nt,J7r),e(Nt,Cm),e(Cm,Y7r),e(Cm,hwe),e(hwe,Z7r),e(Cm,K7r),e(Cm,Yee),e(Yee,e8r),e(Cm,o8r),e(Nt,r8r),M(zC,Nt,null),e(Jo,t8r),e(Jo,ho),M(pS,ho,null),e(ho,a8r),e(ho,uwe),e(uwe,n8r),e(ho,s8r),e(ho,Fn),e(Fn,l8r),e(Fn,pwe),e(pwe,i8r),e(Fn,d8r),e(Fn,_we),e(_we,m8r),e(Fn,c8r),e(Fn,bwe),e(bwe,f8r),e(Fn,g8r),e(ho,h8r),e(ho,vwe),e(vwe,QC),e(QC,Fwe),e(Fwe,u8r),e(QC,p8r),e(QC,Zee),e(Zee,_8r),e(QC,b8r),e(ho,v8r),e(ho,WC),e(WC,F8r),e(WC,Twe),e(Twe,T8r),e(WC,M8r),e(WC,Mwe),e(Mwe,E8r),e(ho,C8r),M(UC,ho,null),b(c,_no,_),b(c,wm,_),e(wm,HC),e(HC,Ewe),M(_S,Ewe,null),e(wm,w8r),e(wm,Cwe),e(Cwe,A8r),b(c,bno,_),b(c,Yo,_),M(bS,Yo,null),e(Yo,L8r),e(Yo,Am),e(Am,y8r),e(Am,Kee),e(Kee,x8r),e(Am,$8r),e(Am,eoe),e(eoe,k8r),e(Am,S8r),e(Yo,R8r),e(Yo,vS),e(vS,P8r),e(vS,wwe),e(wwe,B8r),e(vS,I8r),e(Yo,N8r),e(Yo,qt),M(FS,qt,null),e(qt,q8r),e(qt,Awe),e(Awe,j8r),e(qt,D8r),e(qt,Lm),e(Lm,G8r),e(Lm,Lwe),e(Lwe,O8r),e(Lm,V8r),e(Lm,ooe),e(ooe,X8r),e(Lm,z8r),e(qt,Q8r),M(JC,qt,null),e(Yo,W8r),e(Yo,uo),M(TS,uo,null),e(uo,U8r),e(uo,ywe),e(ywe,H8r),e(uo,J8r),e(uo,Tn),e(Tn,Y8r),e(Tn,xwe),e(xwe,Z8r),e(Tn,K8r),e(Tn,$we),e($we,eLr),e(Tn,oLr),e(Tn,kwe),e(kwe,rLr),e(Tn,tLr),e(uo,aLr),e(uo,Swe),e(Swe,YC),e(YC,Rwe),e(Rwe,nLr),e(YC,sLr),e(YC,roe),e(roe,lLr),e(YC,iLr),e(uo,dLr),e(uo,ZC),e(ZC,mLr),e(ZC,Pwe),e(Pwe,cLr),e(ZC,fLr),e(ZC,Bwe),e(Bwe,gLr),e(uo,hLr),M(KC,uo,null),b(c,vno,_),b(c,ym,_),e(ym,e3),e(e3,Iwe),M(MS,Iwe,null),e(ym,uLr),e(ym,Nwe),e(Nwe,pLr),b(c,Fno,_),b(c,Zo,_),M(ES,Zo,null),e(Zo,_Lr),e(Zo,xm),e(xm,bLr),e(xm,toe),e(toe,vLr),e(xm,FLr),e(xm,aoe),e(aoe,TLr),e(xm,MLr),e(Zo,ELr),e(Zo,CS),e(CS,CLr),e(CS,qwe),e(qwe,wLr),e(CS,ALr),e(Zo,LLr),e(Zo,jt),M(wS,jt,null),e(jt,yLr),e(jt,jwe),e(jwe,xLr),e(jt,$Lr),e(jt,$m),e($m,kLr),e($m,Dwe),e(Dwe,SLr),e($m,RLr),e($m,noe),e(noe,PLr),e($m,BLr),e(jt,ILr),M(o3,jt,null),e(Zo,NLr),e(Zo,po),M(AS,po,null),e(po,qLr),e(po,Gwe),e(Gwe,jLr),e(po,DLr),e(po,Mn),e(Mn,GLr),e(Mn,Owe),e(Owe,OLr),e(Mn,VLr),e(Mn,Vwe),e(Vwe,XLr),e(Mn,zLr),e(Mn,Xwe),e(Xwe,QLr),e(Mn,WLr),e(po,ULr),e(po,zwe),e(zwe,r3),e(r3,Qwe),e(Qwe,HLr),e(r3,JLr),e(r3,soe),e(soe,YLr),e(r3,ZLr),e(po,KLr),e(po,t3),e(t3,eyr),e(t3,Wwe),e(Wwe,oyr),e(t3,ryr),e(t3,Uwe),e(Uwe,tyr),e(po,ayr),M(a3,po,null),b(c,Tno,_),b(c,km,_),e(km,n3),e(n3,Hwe),M(LS,Hwe,null),e(km,nyr),e(km,Jwe),e(Jwe,syr),b(c,Mno,_),b(c,Ko,_),M(yS,Ko,null),e(Ko,lyr),e(Ko,Sm),e(Sm,iyr),e(Sm,loe),e(loe,dyr),e(Sm,myr),e(Sm,ioe),e(ioe,cyr),e(Sm,fyr),e(Ko,gyr),e(Ko,xS),e(xS,hyr),e(xS,Ywe),e(Ywe,uyr),e(xS,pyr),e(Ko,_yr),e(Ko,Dt),M($S,Dt,null),e(Dt,byr),e(Dt,Zwe),e(Zwe,vyr),e(Dt,Fyr),e(Dt,Rm),e(Rm,Tyr),e(Rm,Kwe),e(Kwe,Myr),e(Rm,Eyr),e(Rm,doe),e(doe,Cyr),e(Rm,wyr),e(Dt,Ayr),M(s3,Dt,null),e(Ko,Lyr),e(Ko,_o),M(kS,_o,null),e(_o,yyr),e(_o,eAe),e(eAe,xyr),e(_o,$yr),e(_o,En),e(En,kyr),e(En,oAe),e(oAe,Syr),e(En,Ryr),e(En,rAe),e(rAe,Pyr),e(En,Byr),e(En,tAe),e(tAe,Iyr),e(En,Nyr),e(_o,qyr),e(_o,Be),e(Be,l3),e(l3,aAe),e(aAe,jyr),e(l3,Dyr),e(l3,moe),e(moe,Gyr),e(l3,Oyr),e(Be,Vyr),e(Be,i3),e(i3,nAe),e(nAe,Xyr),e(i3,zyr),e(i3,coe),e(coe,Qyr),e(i3,Wyr),e(Be,Uyr),e(Be,d3),e(d3,sAe),e(sAe,Hyr),e(d3,Jyr),e(d3,foe),e(foe,Yyr),e(d3,Zyr),e(Be,Kyr),e(Be,m3),e(m3,lAe),e(lAe,e9r),e(m3,o9r),e(m3,goe),e(goe,r9r),e(m3,t9r),e(Be,a9r),e(Be,c3),e(c3,iAe),e(iAe,n9r),e(c3,s9r),e(c3,hoe),e(hoe,l9r),e(c3,i9r),e(Be,d9r),e(Be,f3),e(f3,dAe),e(dAe,m9r),e(f3,c9r),e(f3,uoe),e(uoe,f9r),e(f3,g9r),e(Be,h9r),e(Be,g3),e(g3,mAe),e(mAe,u9r),e(g3,p9r),e(g3,poe),e(poe,_9r),e(g3,b9r),e(Be,v9r),e(Be,h3),e(h3,cAe),e(cAe,F9r),e(h3,T9r),e(h3,_oe),e(_oe,M9r),e(h3,E9r),e(Be,C9r),e(Be,u3),e(u3,fAe),e(fAe,w9r),e(u3,A9r),e(u3,boe),e(boe,L9r),e(u3,y9r),e(_o,x9r),e(_o,p3),e(p3,$9r),e(p3,gAe),e(gAe,k9r),e(p3,S9r),e(p3,hAe),e(hAe,R9r),e(_o,P9r),M(_3,_o,null),b(c,Eno,_),b(c,Pm,_),e(Pm,b3),e(b3,uAe),M(SS,uAe,null),e(Pm,B9r),e(Pm,pAe),e(pAe,I9r),b(c,Cno,_),b(c,er,_),M(RS,er,null),e(er,N9r),e(er,Bm),e(Bm,q9r),e(Bm,voe),e(voe,j9r),e(Bm,D9r),e(Bm,Foe),e(Foe,G9r),e(Bm,O9r),e(er,V9r),e(er,PS),e(PS,X9r),e(PS,_Ae),e(_Ae,z9r),e(PS,Q9r),e(er,W9r),e(er,Gt),M(BS,Gt,null),e(Gt,U9r),e(Gt,bAe),e(bAe,H9r),e(Gt,J9r),e(Gt,Im),e(Im,Y9r),e(Im,vAe),e(vAe,Z9r),e(Im,K9r),e(Im,Toe),e(Toe,exr),e(Im,oxr),e(Gt,rxr),M(v3,Gt,null),e(er,txr),e(er,bo),M(IS,bo,null),e(bo,axr),e(bo,FAe),e(FAe,nxr),e(bo,sxr),e(bo,Cn),e(Cn,lxr),e(Cn,TAe),e(TAe,ixr),e(Cn,dxr),e(Cn,MAe),e(MAe,mxr),e(Cn,cxr),e(Cn,EAe),e(EAe,fxr),e(Cn,gxr),e(bo,hxr),e(bo,ut),e(ut,F3),e(F3,CAe),e(CAe,uxr),e(F3,pxr),e(F3,Moe),e(Moe,_xr),e(F3,bxr),e(ut,vxr),e(ut,T3),e(T3,wAe),e(wAe,Fxr),e(T3,Txr),e(T3,Eoe),e(Eoe,Mxr),e(T3,Exr),e(ut,Cxr),e(ut,M3),e(M3,AAe),e(AAe,wxr),e(M3,Axr),e(M3,Coe),e(Coe,Lxr),e(M3,yxr),e(ut,xxr),e(ut,E3),e(E3,LAe),e(LAe,$xr),e(E3,kxr),e(E3,woe),e(woe,Sxr),e(E3,Rxr),e(ut,Pxr),e(ut,C3),e(C3,yAe),e(yAe,Bxr),e(C3,Ixr),e(C3,Aoe),e(Aoe,Nxr),e(C3,qxr),e(bo,jxr),e(bo,w3),e(w3,Dxr),e(w3,xAe),e(xAe,Gxr),e(w3,Oxr),e(w3,$Ae),e($Ae,Vxr),e(bo,Xxr),M(A3,bo,null),b(c,wno,_),b(c,Nm,_),e(Nm,L3),e(L3,kAe),M(NS,kAe,null),e(Nm,zxr),e(Nm,SAe),e(SAe,Qxr),b(c,Ano,_),b(c,or,_),M(qS,or,null),e(or,Wxr),e(or,qm),e(qm,Uxr),e(qm,Loe),e(Loe,Hxr),e(qm,Jxr),e(qm,yoe),e(yoe,Yxr),e(qm,Zxr),e(or,Kxr),e(or,jS),e(jS,e$r),e(jS,RAe),e(RAe,o$r),e(jS,r$r),e(or,t$r),e(or,Ot),M(DS,Ot,null),e(Ot,a$r),e(Ot,PAe),e(PAe,n$r),e(Ot,s$r),e(Ot,jm),e(jm,l$r),e(jm,BAe),e(BAe,i$r),e(jm,d$r),e(jm,xoe),e(xoe,m$r),e(jm,c$r),e(Ot,f$r),M(y3,Ot,null),e(or,g$r),e(or,vo),M(GS,vo,null),e(vo,h$r),e(vo,IAe),e(IAe,u$r),e(vo,p$r),e(vo,wn),e(wn,_$r),e(wn,NAe),e(NAe,b$r),e(wn,v$r),e(wn,qAe),e(qAe,F$r),e(wn,T$r),e(wn,jAe),e(jAe,M$r),e(wn,E$r),e(vo,C$r),e(vo,Le),e(Le,x3),e(x3,DAe),e(DAe,w$r),e(x3,A$r),e(x3,$oe),e($oe,L$r),e(x3,y$r),e(Le,x$r),e(Le,$3),e($3,GAe),e(GAe,$$r),e($3,k$r),e($3,koe),e(koe,S$r),e($3,R$r),e(Le,P$r),e(Le,k3),e(k3,OAe),e(OAe,B$r),e(k3,I$r),e(k3,Soe),e(Soe,N$r),e(k3,q$r),e(Le,j$r),e(Le,S3),e(S3,VAe),e(VAe,D$r),e(S3,G$r),e(S3,Roe),e(Roe,O$r),e(S3,V$r),e(Le,X$r),e(Le,R3),e(R3,XAe),e(XAe,z$r),e(R3,Q$r),e(R3,Poe),e(Poe,W$r),e(R3,U$r),e(Le,H$r),e(Le,P3),e(P3,zAe),e(zAe,J$r),e(P3,Y$r),e(P3,Boe),e(Boe,Z$r),e(P3,K$r),e(Le,ekr),e(Le,B3),e(B3,QAe),e(QAe,okr),e(B3,rkr),e(B3,Ioe),e(Ioe,tkr),e(B3,akr),e(Le,nkr),e(Le,I3),e(I3,WAe),e(WAe,skr),e(I3,lkr),e(I3,Noe),e(Noe,ikr),e(I3,dkr),e(Le,mkr),e(Le,N3),e(N3,UAe),e(UAe,ckr),e(N3,fkr),e(N3,qoe),e(qoe,gkr),e(N3,hkr),e(Le,ukr),e(Le,q3),e(q3,HAe),e(HAe,pkr),e(q3,_kr),e(q3,joe),e(joe,bkr),e(q3,vkr),e(vo,Fkr),e(vo,j3),e(j3,Tkr),e(j3,JAe),e(JAe,Mkr),e(j3,Ekr),e(j3,YAe),e(YAe,Ckr),e(vo,wkr),M(D3,vo,null),b(c,Lno,_),b(c,Dm,_),e(Dm,G3),e(G3,ZAe),M(OS,ZAe,null),e(Dm,Akr),e(Dm,KAe),e(KAe,Lkr),b(c,yno,_),b(c,rr,_),M(VS,rr,null),e(rr,ykr),e(rr,Gm),e(Gm,xkr),e(Gm,Doe),e(Doe,$kr),e(Gm,kkr),e(Gm,Goe),e(Goe,Skr),e(Gm,Rkr),e(rr,Pkr),e(rr,XS),e(XS,Bkr),e(XS,e6e),e(e6e,Ikr),e(XS,Nkr),e(rr,qkr),e(rr,Vt),M(zS,Vt,null),e(Vt,jkr),e(Vt,o6e),e(o6e,Dkr),e(Vt,Gkr),e(Vt,Om),e(Om,Okr),e(Om,r6e),e(r6e,Vkr),e(Om,Xkr),e(Om,Ooe),e(Ooe,zkr),e(Om,Qkr),e(Vt,Wkr),M(O3,Vt,null),e(rr,Ukr),e(rr,Fo),M(QS,Fo,null),e(Fo,Hkr),e(Fo,t6e),e(t6e,Jkr),e(Fo,Ykr),e(Fo,An),e(An,Zkr),e(An,a6e),e(a6e,Kkr),e(An,eSr),e(An,n6e),e(n6e,oSr),e(An,rSr),e(An,s6e),e(s6e,tSr),e(An,aSr),e(Fo,nSr),e(Fo,Vm),e(Vm,V3),e(V3,l6e),e(l6e,sSr),e(V3,lSr),e(V3,Voe),e(Voe,iSr),e(V3,dSr),e(Vm,mSr),e(Vm,X3),e(X3,i6e),e(i6e,cSr),e(X3,fSr),e(X3,Xoe),e(Xoe,gSr),e(X3,hSr),e(Vm,uSr),e(Vm,z3),e(z3,d6e),e(d6e,pSr),e(z3,_Sr),e(z3,zoe),e(zoe,bSr),e(z3,vSr),e(Fo,FSr),e(Fo,Q3),e(Q3,TSr),e(Q3,m6e),e(m6e,MSr),e(Q3,ESr),e(Q3,c6e),e(c6e,CSr),e(Fo,wSr),M(W3,Fo,null),b(c,xno,_),b(c,Xm,_),e(Xm,U3),e(U3,f6e),M(WS,f6e,null),e(Xm,ASr),e(Xm,g6e),e(g6e,LSr),b(c,$no,_),b(c,tr,_),M(US,tr,null),e(tr,ySr),e(tr,zm),e(zm,xSr),e(zm,Qoe),e(Qoe,$Sr),e(zm,kSr),e(zm,Woe),e(Woe,SSr),e(zm,RSr),e(tr,PSr),e(tr,HS),e(HS,BSr),e(HS,h6e),e(h6e,ISr),e(HS,NSr),e(tr,qSr),e(tr,Xt),M(JS,Xt,null),e(Xt,jSr),e(Xt,u6e),e(u6e,DSr),e(Xt,GSr),e(Xt,Qm),e(Qm,OSr),e(Qm,p6e),e(p6e,VSr),e(Qm,XSr),e(Qm,Uoe),e(Uoe,zSr),e(Qm,QSr),e(Xt,WSr),M(H3,Xt,null),e(tr,USr),e(tr,To),M(YS,To,null),e(To,HSr),e(To,_6e),e(_6e,JSr),e(To,YSr),e(To,Ln),e(Ln,ZSr),e(Ln,b6e),e(b6e,KSr),e(Ln,eRr),e(Ln,v6e),e(v6e,oRr),e(Ln,rRr),e(Ln,F6e),e(F6e,tRr),e(Ln,aRr),e(To,nRr),e(To,pt),e(pt,J3),e(J3,T6e),e(T6e,sRr),e(J3,lRr),e(J3,Hoe),e(Hoe,iRr),e(J3,dRr),e(pt,mRr),e(pt,Y3),e(Y3,M6e),e(M6e,cRr),e(Y3,fRr),e(Y3,Joe),e(Joe,gRr),e(Y3,hRr),e(pt,uRr),e(pt,Z3),e(Z3,E6e),e(E6e,pRr),e(Z3,_Rr),e(Z3,Yoe),e(Yoe,bRr),e(Z3,vRr),e(pt,FRr),e(pt,K3),e(K3,C6e),e(C6e,TRr),e(K3,MRr),e(K3,Zoe),e(Zoe,ERr),e(K3,CRr),e(pt,wRr),e(pt,e5),e(e5,w6e),e(w6e,ARr),e(e5,LRr),e(e5,Koe),e(Koe,yRr),e(e5,xRr),e(To,$Rr),e(To,o5),e(o5,kRr),e(o5,A6e),e(A6e,SRr),e(o5,RRr),e(o5,L6e),e(L6e,PRr),e(To,BRr),M(r5,To,null),b(c,kno,_),b(c,Wm,_),e(Wm,t5),e(t5,y6e),M(ZS,y6e,null),e(Wm,IRr),e(Wm,x6e),e(x6e,NRr),b(c,Sno,_),b(c,ar,_),M(KS,ar,null),e(ar,qRr),e(ar,Um),e(Um,jRr),e(Um,ere),e(ere,DRr),e(Um,GRr),e(Um,ore),e(ore,ORr),e(Um,VRr),e(ar,XRr),e(ar,eR),e(eR,zRr),e(eR,$6e),e($6e,QRr),e(eR,WRr),e(ar,URr),e(ar,zt),M(oR,zt,null),e(zt,HRr),e(zt,k6e),e(k6e,JRr),e(zt,YRr),e(zt,Hm),e(Hm,ZRr),e(Hm,S6e),e(S6e,KRr),e(Hm,ePr),e(Hm,rre),e(rre,oPr),e(Hm,rPr),e(zt,tPr),M(a5,zt,null),e(ar,aPr),e(ar,Mo),M(rR,Mo,null),e(Mo,nPr),e(Mo,R6e),e(R6e,sPr),e(Mo,lPr),e(Mo,yn),e(yn,iPr),e(yn,P6e),e(P6e,dPr),e(yn,mPr),e(yn,B6e),e(B6e,cPr),e(yn,fPr),e(yn,I6e),e(I6e,gPr),e(yn,hPr),e(Mo,uPr),e(Mo,xn),e(xn,n5),e(n5,N6e),e(N6e,pPr),e(n5,_Pr),e(n5,tre),e(tre,bPr),e(n5,vPr),e(xn,FPr),e(xn,s5),e(s5,q6e),e(q6e,TPr),e(s5,MPr),e(s5,are),e(are,EPr),e(s5,CPr),e(xn,wPr),e(xn,l5),e(l5,j6e),e(j6e,APr),e(l5,LPr),e(l5,nre),e(nre,yPr),e(l5,xPr),e(xn,$Pr),e(xn,i5),e(i5,D6e),e(D6e,kPr),e(i5,SPr),e(i5,sre),e(sre,RPr),e(i5,PPr),e(Mo,BPr),e(Mo,d5),e(d5,IPr),e(d5,G6e),e(G6e,NPr),e(d5,qPr),e(d5,O6e),e(O6e,jPr),e(Mo,DPr),M(m5,Mo,null),b(c,Rno,_),b(c,Jm,_),e(Jm,c5),e(c5,V6e),M(tR,V6e,null),e(Jm,GPr),e(Jm,X6e),e(X6e,OPr),b(c,Pno,_),b(c,nr,_),M(aR,nr,null),e(nr,VPr),e(nr,Ym),e(Ym,XPr),e(Ym,lre),e(lre,zPr),e(Ym,QPr),e(Ym,ire),e(ire,WPr),e(Ym,UPr),e(nr,HPr),e(nr,nR),e(nR,JPr),e(nR,z6e),e(z6e,YPr),e(nR,ZPr),e(nr,KPr),e(nr,Qt),M(sR,Qt,null),e(Qt,eBr),e(Qt,Q6e),e(Q6e,oBr),e(Qt,rBr),e(Qt,Zm),e(Zm,tBr),e(Zm,W6e),e(W6e,aBr),e(Zm,nBr),e(Zm,dre),e(dre,sBr),e(Zm,lBr),e(Qt,iBr),M(f5,Qt,null),e(nr,dBr),e(nr,Eo),M(lR,Eo,null),e(Eo,mBr),e(Eo,U6e),e(U6e,cBr),e(Eo,fBr),e(Eo,$n),e($n,gBr),e($n,H6e),e(H6e,hBr),e($n,uBr),e($n,J6e),e(J6e,pBr),e($n,_Br),e($n,Y6e),e(Y6e,bBr),e($n,vBr),e(Eo,FBr),e(Eo,_t),e(_t,g5),e(g5,Z6e),e(Z6e,TBr),e(g5,MBr),e(g5,mre),e(mre,EBr),e(g5,CBr),e(_t,wBr),e(_t,h5),e(h5,K6e),e(K6e,ABr),e(h5,LBr),e(h5,cre),e(cre,yBr),e(h5,xBr),e(_t,$Br),e(_t,u5),e(u5,e7e),e(e7e,kBr),e(u5,SBr),e(u5,fre),e(fre,RBr),e(u5,PBr),e(_t,BBr),e(_t,p5),e(p5,o7e),e(o7e,IBr),e(p5,NBr),e(p5,gre),e(gre,qBr),e(p5,jBr),e(_t,DBr),e(_t,_5),e(_5,r7e),e(r7e,GBr),e(_5,OBr),e(_5,hre),e(hre,VBr),e(_5,XBr),e(Eo,zBr),e(Eo,b5),e(b5,QBr),e(b5,t7e),e(t7e,WBr),e(b5,UBr),e(b5,a7e),e(a7e,HBr),e(Eo,JBr),M(v5,Eo,null),b(c,Bno,_),b(c,Km,_),e(Km,F5),e(F5,n7e),M(iR,n7e,null),e(Km,YBr),e(Km,s7e),e(s7e,ZBr),b(c,Ino,_),b(c,sr,_),M(dR,sr,null),e(sr,KBr),e(sr,ec),e(ec,eIr),e(ec,ure),e(ure,oIr),e(ec,rIr),e(ec,pre),e(pre,tIr),e(ec,aIr),e(sr,nIr),e(sr,mR),e(mR,sIr),e(mR,l7e),e(l7e,lIr),e(mR,iIr),e(sr,dIr),e(sr,Wt),M(cR,Wt,null),e(Wt,mIr),e(Wt,i7e),e(i7e,cIr),e(Wt,fIr),e(Wt,oc),e(oc,gIr),e(oc,d7e),e(d7e,hIr),e(oc,uIr),e(oc,_re),e(_re,pIr),e(oc,_Ir),e(Wt,bIr),M(T5,Wt,null),e(sr,vIr),e(sr,Co),M(fR,Co,null),e(Co,FIr),e(Co,m7e),e(m7e,TIr),e(Co,MIr),e(Co,kn),e(kn,EIr),e(kn,c7e),e(c7e,CIr),e(kn,wIr),e(kn,f7e),e(f7e,AIr),e(kn,LIr),e(kn,g7e),e(g7e,yIr),e(kn,xIr),e(Co,$Ir),e(Co,h7e),e(h7e,M5),e(M5,u7e),e(u7e,kIr),e(M5,SIr),e(M5,bre),e(bre,RIr),e(M5,PIr),e(Co,BIr),e(Co,E5),e(E5,IIr),e(E5,p7e),e(p7e,NIr),e(E5,qIr),e(E5,_7e),e(_7e,jIr),e(Co,DIr),M(C5,Co,null),b(c,Nno,_),b(c,rc,_),e(rc,w5),e(w5,b7e),M(gR,b7e,null),e(rc,GIr),e(rc,v7e),e(v7e,OIr),b(c,qno,_),b(c,lr,_),M(hR,lr,null),e(lr,VIr),e(lr,tc),e(tc,XIr),e(tc,vre),e(vre,zIr),e(tc,QIr),e(tc,Fre),e(Fre,WIr),e(tc,UIr),e(lr,HIr),e(lr,uR),e(uR,JIr),e(uR,F7e),e(F7e,YIr),e(uR,ZIr),e(lr,KIr),e(lr,Ut),M(pR,Ut,null),e(Ut,eNr),e(Ut,T7e),e(T7e,oNr),e(Ut,rNr),e(Ut,ac),e(ac,tNr),e(ac,M7e),e(M7e,aNr),e(ac,nNr),e(ac,Tre),e(Tre,sNr),e(ac,lNr),e(Ut,iNr),M(A5,Ut,null),e(lr,dNr),e(lr,wo),M(_R,wo,null),e(wo,mNr),e(wo,E7e),e(E7e,cNr),e(wo,fNr),e(wo,Sn),e(Sn,gNr),e(Sn,C7e),e(C7e,hNr),e(Sn,uNr),e(Sn,w7e),e(w7e,pNr),e(Sn,_Nr),e(Sn,A7e),e(A7e,bNr),e(Sn,vNr),e(wo,FNr),e(wo,bt),e(bt,L5),e(L5,L7e),e(L7e,TNr),e(L5,MNr),e(L5,Mre),e(Mre,ENr),e(L5,CNr),e(bt,wNr),e(bt,y5),e(y5,y7e),e(y7e,ANr),e(y5,LNr),e(y5,Ere),e(Ere,yNr),e(y5,xNr),e(bt,$Nr),e(bt,x5),e(x5,x7e),e(x7e,kNr),e(x5,SNr),e(x5,Cre),e(Cre,RNr),e(x5,PNr),e(bt,BNr),e(bt,$5),e($5,$7e),e($7e,INr),e($5,NNr),e($5,wre),e(wre,qNr),e($5,jNr),e(bt,DNr),e(bt,k5),e(k5,k7e),e(k7e,GNr),e(k5,ONr),e(k5,Are),e(Are,VNr),e(k5,XNr),e(wo,zNr),e(wo,S5),e(S5,QNr),e(S5,S7e),e(S7e,WNr),e(S5,UNr),e(S5,R7e),e(R7e,HNr),e(wo,JNr),M(R5,wo,null),b(c,jno,_),b(c,nc,_),e(nc,P5),e(P5,P7e),M(bR,P7e,null),e(nc,YNr),e(nc,B7e),e(B7e,ZNr),b(c,Dno,_),b(c,ir,_),M(vR,ir,null),e(ir,KNr),e(ir,sc),e(sc,eqr),e(sc,Lre),e(Lre,oqr),e(sc,rqr),e(sc,yre),e(yre,tqr),e(sc,aqr),e(ir,nqr),e(ir,FR),e(FR,sqr),e(FR,I7e),e(I7e,lqr),e(FR,iqr),e(ir,dqr),e(ir,Ht),M(TR,Ht,null),e(Ht,mqr),e(Ht,N7e),e(N7e,cqr),e(Ht,fqr),e(Ht,lc),e(lc,gqr),e(lc,q7e),e(q7e,hqr),e(lc,uqr),e(lc,xre),e(xre,pqr),e(lc,_qr),e(Ht,bqr),M(B5,Ht,null),e(ir,vqr),e(ir,Ao),M(MR,Ao,null),e(Ao,Fqr),e(Ao,j7e),e(j7e,Tqr),e(Ao,Mqr),e(Ao,Rn),e(Rn,Eqr),e(Rn,D7e),e(D7e,Cqr),e(Rn,wqr),e(Rn,G7e),e(G7e,Aqr),e(Rn,Lqr),e(Rn,O7e),e(O7e,yqr),e(Rn,xqr),e(Ao,$qr),e(Ao,V7e),e(V7e,I5),e(I5,X7e),e(X7e,kqr),e(I5,Sqr),e(I5,$re),e($re,Rqr),e(I5,Pqr),e(Ao,Bqr),e(Ao,N5),e(N5,Iqr),e(N5,z7e),e(z7e,Nqr),e(N5,qqr),e(N5,Q7e),e(Q7e,jqr),e(Ao,Dqr),M(q5,Ao,null),b(c,Gno,_),b(c,ic,_),e(ic,j5),e(j5,W7e),M(ER,W7e,null),e(ic,Gqr),e(ic,U7e),e(U7e,Oqr),b(c,Ono,_),b(c,dr,_),M(CR,dr,null),e(dr,Vqr),e(dr,dc),e(dc,Xqr),e(dc,kre),e(kre,zqr),e(dc,Qqr),e(dc,Sre),e(Sre,Wqr),e(dc,Uqr),e(dr,Hqr),e(dr,wR),e(wR,Jqr),e(wR,H7e),e(H7e,Yqr),e(wR,Zqr),e(dr,Kqr),e(dr,Jt),M(AR,Jt,null),e(Jt,ejr),e(Jt,J7e),e(J7e,ojr),e(Jt,rjr),e(Jt,mc),e(mc,tjr),e(mc,Y7e),e(Y7e,ajr),e(mc,njr),e(mc,Rre),e(Rre,sjr),e(mc,ljr),e(Jt,ijr),M(D5,Jt,null),e(dr,djr),e(dr,Lo),M(LR,Lo,null),e(Lo,mjr),e(Lo,Z7e),e(Z7e,cjr),e(Lo,fjr),e(Lo,Pn),e(Pn,gjr),e(Pn,K7e),e(K7e,hjr),e(Pn,ujr),e(Pn,e8e),e(e8e,pjr),e(Pn,_jr),e(Pn,o8e),e(o8e,bjr),e(Pn,vjr),e(Lo,Fjr),e(Lo,r8e),e(r8e,G5),e(G5,t8e),e(t8e,Tjr),e(G5,Mjr),e(G5,Pre),e(Pre,Ejr),e(G5,Cjr),e(Lo,wjr),e(Lo,O5),e(O5,Ajr),e(O5,a8e),e(a8e,Ljr),e(O5,yjr),e(O5,n8e),e(n8e,xjr),e(Lo,$jr),M(V5,Lo,null),b(c,Vno,_),b(c,cc,_),e(cc,X5),e(X5,s8e),M(yR,s8e,null),e(cc,kjr),e(cc,l8e),e(l8e,Sjr),b(c,Xno,_),b(c,mr,_),M(xR,mr,null),e(mr,Rjr),e(mr,fc),e(fc,Pjr),e(fc,Bre),e(Bre,Bjr),e(fc,Ijr),e(fc,Ire),e(Ire,Njr),e(fc,qjr),e(mr,jjr),e(mr,$R),e($R,Djr),e($R,i8e),e(i8e,Gjr),e($R,Ojr),e(mr,Vjr),e(mr,Yt),M(kR,Yt,null),e(Yt,Xjr),e(Yt,d8e),e(d8e,zjr),e(Yt,Qjr),e(Yt,gc),e(gc,Wjr),e(gc,m8e),e(m8e,Ujr),e(gc,Hjr),e(gc,Nre),e(Nre,Jjr),e(gc,Yjr),e(Yt,Zjr),M(z5,Yt,null),e(mr,Kjr),e(mr,Dr),M(SR,Dr,null),e(Dr,eDr),e(Dr,c8e),e(c8e,oDr),e(Dr,rDr),e(Dr,Bn),e(Bn,tDr),e(Bn,f8e),e(f8e,aDr),e(Bn,nDr),e(Bn,g8e),e(g8e,sDr),e(Bn,lDr),e(Bn,h8e),e(h8e,iDr),e(Bn,dDr),e(Dr,mDr),e(Dr,P),e(P,Q5),e(Q5,u8e),e(u8e,cDr),e(Q5,fDr),e(Q5,qre),e(qre,gDr),e(Q5,hDr),e(P,uDr),e(P,W5),e(W5,p8e),e(p8e,pDr),e(W5,_Dr),e(W5,jre),e(jre,bDr),e(W5,vDr),e(P,FDr),e(P,U5),e(U5,_8e),e(_8e,TDr),e(U5,MDr),e(U5,Dre),e(Dre,EDr),e(U5,CDr),e(P,wDr),e(P,H5),e(H5,b8e),e(b8e,ADr),e(H5,LDr),e(H5,Gre),e(Gre,yDr),e(H5,xDr),e(P,$Dr),e(P,J5),e(J5,v8e),e(v8e,kDr),e(J5,SDr),e(J5,Ore),e(Ore,RDr),e(J5,PDr),e(P,BDr),e(P,Y5),e(Y5,F8e),e(F8e,IDr),e(Y5,NDr),e(Y5,Vre),e(Vre,qDr),e(Y5,jDr),e(P,DDr),e(P,Z5),e(Z5,T8e),e(T8e,GDr),e(Z5,ODr),e(Z5,Xre),e(Xre,VDr),e(Z5,XDr),e(P,zDr),e(P,K5),e(K5,M8e),e(M8e,QDr),e(K5,WDr),e(K5,zre),e(zre,UDr),e(K5,HDr),e(P,JDr),e(P,e0),e(e0,E8e),e(E8e,YDr),e(e0,ZDr),e(e0,Qre),e(Qre,KDr),e(e0,eGr),e(P,oGr),e(P,o0),e(o0,C8e),e(C8e,rGr),e(o0,tGr),e(o0,Wre),e(Wre,aGr),e(o0,nGr),e(P,sGr),e(P,r0),e(r0,w8e),e(w8e,lGr),e(r0,iGr),e(r0,Ure),e(Ure,dGr),e(r0,mGr),e(P,cGr),e(P,t0),e(t0,A8e),e(A8e,fGr),e(t0,gGr),e(t0,Hre),e(Hre,hGr),e(t0,uGr),e(P,pGr),e(P,a0),e(a0,L8e),e(L8e,_Gr),e(a0,bGr),e(a0,Jre),e(Jre,vGr),e(a0,FGr),e(P,TGr),e(P,n0),e(n0,y8e),e(y8e,MGr),e(n0,EGr),e(n0,Yre),e(Yre,CGr),e(n0,wGr),e(P,AGr),e(P,s0),e(s0,x8e),e(x8e,LGr),e(s0,yGr),e(s0,Zre),e(Zre,xGr),e(s0,$Gr),e(P,kGr),e(P,l0),e(l0,$8e),e($8e,SGr),e(l0,RGr),e(l0,Kre),e(Kre,PGr),e(l0,BGr),e(P,IGr),e(P,i0),e(i0,k8e),e(k8e,NGr),e(i0,qGr),e(i0,ete),e(ete,jGr),e(i0,DGr),e(P,GGr),e(P,d0),e(d0,S8e),e(S8e,OGr),e(d0,VGr),e(d0,ote),e(ote,XGr),e(d0,zGr),e(P,QGr),e(P,m0),e(m0,R8e),e(R8e,WGr),e(m0,UGr),e(m0,rte),e(rte,HGr),e(m0,JGr),e(P,YGr),e(P,c0),e(c0,P8e),e(P8e,ZGr),e(c0,KGr),e(c0,tte),e(tte,eOr),e(c0,oOr),e(P,rOr),e(P,Rl),e(Rl,B8e),e(B8e,tOr),e(Rl,aOr),e(Rl,ate),e(ate,nOr),e(Rl,sOr),e(Rl,nte),e(nte,lOr),e(Rl,iOr),e(P,dOr),e(P,f0),e(f0,I8e),e(I8e,mOr),e(f0,cOr),e(f0,ste),e(ste,fOr),e(f0,gOr),e(P,hOr),e(P,g0),e(g0,N8e),e(N8e,uOr),e(g0,pOr),e(g0,lte),e(lte,_Or),e(g0,bOr),e(P,vOr),e(P,h0),e(h0,q8e),e(q8e,FOr),e(h0,TOr),e(h0,ite),e(ite,MOr),e(h0,EOr),e(P,COr),e(P,u0),e(u0,j8e),e(j8e,wOr),e(u0,AOr),e(u0,dte),e(dte,LOr),e(u0,yOr),e(P,xOr),e(P,p0),e(p0,D8e),e(D8e,$Or),e(p0,kOr),e(p0,mte),e(mte,SOr),e(p0,ROr),e(P,POr),e(P,_0),e(_0,G8e),e(G8e,BOr),e(_0,IOr),e(_0,cte),e(cte,NOr),e(_0,qOr),e(P,jOr),e(P,b0),e(b0,O8e),e(O8e,DOr),e(b0,GOr),e(b0,fte),e(fte,OOr),e(b0,VOr),e(P,XOr),e(P,v0),e(v0,V8e),e(V8e,zOr),e(v0,QOr),e(v0,gte),e(gte,WOr),e(v0,UOr),e(P,HOr),e(P,F0),e(F0,X8e),e(X8e,JOr),e(F0,YOr),e(F0,hte),e(hte,ZOr),e(F0,KOr),e(P,eVr),e(P,T0),e(T0,z8e),e(z8e,oVr),e(T0,rVr),e(T0,ute),e(ute,tVr),e(T0,aVr),e(P,nVr),e(P,M0),e(M0,Q8e),e(Q8e,sVr),e(M0,lVr),e(M0,pte),e(pte,iVr),e(M0,dVr),e(P,mVr),e(P,E0),e(E0,W8e),e(W8e,cVr),e(E0,fVr),e(E0,_te),e(_te,gVr),e(E0,hVr),e(P,uVr),e(P,C0),e(C0,U8e),e(U8e,pVr),e(C0,_Vr),e(C0,bte),e(bte,bVr),e(C0,vVr),e(P,FVr),e(P,w0),e(w0,H8e),e(H8e,TVr),e(w0,MVr),e(w0,vte),e(vte,EVr),e(w0,CVr),e(P,wVr),e(P,A0),e(A0,J8e),e(J8e,AVr),e(A0,LVr),e(A0,Fte),e(Fte,yVr),e(A0,xVr),e(P,$Vr),e(P,L0),e(L0,Y8e),e(Y8e,kVr),e(L0,SVr),e(L0,Tte),e(Tte,RVr),e(L0,PVr),e(P,BVr),e(P,y0),e(y0,Z8e),e(Z8e,IVr),e(y0,NVr),e(y0,Mte),e(Mte,qVr),e(y0,jVr),e(P,DVr),e(P,x0),e(x0,K8e),e(K8e,GVr),e(x0,OVr),e(x0,Ete),e(Ete,VVr),e(x0,XVr),e(P,zVr),e(P,$0),e($0,eLe),e(eLe,QVr),e($0,WVr),e($0,Cte),e(Cte,UVr),e($0,HVr),e(P,JVr),e(P,k0),e(k0,oLe),e(oLe,YVr),e(k0,ZVr),e(k0,wte),e(wte,KVr),e(k0,eXr),e(P,oXr),e(P,S0),e(S0,rLe),e(rLe,rXr),e(S0,tXr),e(S0,Ate),e(Ate,aXr),e(S0,nXr),e(P,sXr),e(P,R0),e(R0,tLe),e(tLe,lXr),e(R0,iXr),e(R0,Lte),e(Lte,dXr),e(R0,mXr),e(P,cXr),e(P,P0),e(P0,aLe),e(aLe,fXr),e(P0,gXr),e(P0,yte),e(yte,hXr),e(P0,uXr),e(P,pXr),e(P,B0),e(B0,nLe),e(nLe,_Xr),e(B0,bXr),e(B0,xte),e(xte,vXr),e(B0,FXr),e(P,TXr),e(P,I0),e(I0,sLe),e(sLe,MXr),e(I0,EXr),e(I0,$te),e($te,CXr),e(I0,wXr),e(P,AXr),e(P,N0),e(N0,lLe),e(lLe,LXr),e(N0,yXr),e(N0,kte),e(kte,xXr),e(N0,$Xr),e(P,kXr),e(P,q0),e(q0,iLe),e(iLe,SXr),e(q0,RXr),e(q0,Ste),e(Ste,PXr),e(q0,BXr),e(P,IXr),e(P,j0),e(j0,dLe),e(dLe,NXr),e(j0,qXr),e(j0,Rte),e(Rte,jXr),e(j0,DXr),e(P,GXr),e(P,D0),e(D0,mLe),e(mLe,OXr),e(D0,VXr),e(D0,Pte),e(Pte,XXr),e(D0,zXr),e(P,QXr),e(P,G0),e(G0,cLe),e(cLe,WXr),e(G0,UXr),e(G0,Bte),e(Bte,HXr),e(G0,JXr),e(P,YXr),e(P,O0),e(O0,fLe),e(fLe,ZXr),e(O0,KXr),e(O0,Ite),e(Ite,ezr),e(O0,ozr),e(P,rzr),e(P,V0),e(V0,gLe),e(gLe,tzr),e(V0,azr),e(V0,Nte),e(Nte,nzr),e(V0,szr),e(P,lzr),e(P,X0),e(X0,hLe),e(hLe,izr),e(X0,dzr),e(X0,qte),e(qte,mzr),e(X0,czr),e(P,fzr),e(P,z0),e(z0,uLe),e(uLe,gzr),e(z0,hzr),e(z0,jte),e(jte,uzr),e(z0,pzr),e(P,_zr),e(P,Q0),e(Q0,pLe),e(pLe,bzr),e(Q0,vzr),e(Q0,Dte),e(Dte,Fzr),e(Q0,Tzr),e(P,Mzr),e(P,W0),e(W0,_Le),e(_Le,Ezr),e(W0,Czr),e(W0,Gte),e(Gte,wzr),e(W0,Azr),e(P,Lzr),e(P,U0),e(U0,bLe),e(bLe,yzr),e(U0,xzr),e(U0,Ote),e(Ote,$zr),e(U0,kzr),e(Dr,Szr),M(H0,Dr,null),b(c,zno,_),b(c,hc,_),e(hc,J0),e(J0,vLe),M(RR,vLe,null),e(hc,Rzr),e(hc,FLe),e(FLe,Pzr),b(c,Qno,_),b(c,cr,_),M(PR,cr,null),e(cr,Bzr),e(cr,uc),e(uc,Izr),e(uc,Vte),e(Vte,Nzr),e(uc,qzr),e(uc,Xte),e(Xte,jzr),e(uc,Dzr),e(cr,Gzr),e(cr,BR),e(BR,Ozr),e(BR,TLe),e(TLe,Vzr),e(BR,Xzr),e(cr,zzr),e(cr,Zt),M(IR,Zt,null),e(Zt,Qzr),e(Zt,MLe),e(MLe,Wzr),e(Zt,Uzr),e(Zt,pc),e(pc,Hzr),e(pc,ELe),e(ELe,Jzr),e(pc,Yzr),e(pc,zte),e(zte,Zzr),e(pc,Kzr),e(Zt,eQr),M(Y0,Zt,null),e(cr,oQr),e(cr,Gr),M(NR,Gr,null),e(Gr,rQr),e(Gr,CLe),e(CLe,tQr),e(Gr,aQr),e(Gr,In),e(In,nQr),e(In,wLe),e(wLe,sQr),e(In,lQr),e(In,ALe),e(ALe,iQr),e(In,dQr),e(In,LLe),e(LLe,mQr),e(In,cQr),e(Gr,fQr),e(Gr,le),e(le,Z0),e(Z0,yLe),e(yLe,gQr),e(Z0,hQr),e(Z0,Qte),e(Qte,uQr),e(Z0,pQr),e(le,_Qr),e(le,K0),e(K0,xLe),e(xLe,bQr),e(K0,vQr),e(K0,Wte),e(Wte,FQr),e(K0,TQr),e(le,MQr),e(le,ew),e(ew,$Le),e($Le,EQr),e(ew,CQr),e(ew,Ute),e(Ute,wQr),e(ew,AQr),e(le,LQr),e(le,ow),e(ow,kLe),e(kLe,yQr),e(ow,xQr),e(ow,Hte),e(Hte,$Qr),e(ow,kQr),e(le,SQr),e(le,rw),e(rw,SLe),e(SLe,RQr),e(rw,PQr),e(rw,Jte),e(Jte,BQr),e(rw,IQr),e(le,NQr),e(le,tw),e(tw,RLe),e(RLe,qQr),e(tw,jQr),e(tw,Yte),e(Yte,DQr),e(tw,GQr),e(le,OQr),e(le,aw),e(aw,PLe),e(PLe,VQr),e(aw,XQr),e(aw,Zte),e(Zte,zQr),e(aw,QQr),e(le,WQr),e(le,nw),e(nw,BLe),e(BLe,UQr),e(nw,HQr),e(nw,Kte),e(Kte,JQr),e(nw,YQr),e(le,ZQr),e(le,sw),e(sw,ILe),e(ILe,KQr),e(sw,eWr),e(sw,eae),e(eae,oWr),e(sw,rWr),e(le,tWr),e(le,lw),e(lw,NLe),e(NLe,aWr),e(lw,nWr),e(lw,oae),e(oae,sWr),e(lw,lWr),e(le,iWr),e(le,iw),e(iw,qLe),e(qLe,dWr),e(iw,mWr),e(iw,rae),e(rae,cWr),e(iw,fWr),e(le,gWr),e(le,dw),e(dw,jLe),e(jLe,hWr),e(dw,uWr),e(dw,tae),e(tae,pWr),e(dw,_Wr),e(le,bWr),e(le,mw),e(mw,DLe),e(DLe,vWr),e(mw,FWr),e(mw,aae),e(aae,TWr),e(mw,MWr),e(le,EWr),e(le,cw),e(cw,GLe),e(GLe,CWr),e(cw,wWr),e(cw,nae),e(nae,AWr),e(cw,LWr),e(le,yWr),e(le,fw),e(fw,OLe),e(OLe,xWr),e(fw,$Wr),e(fw,sae),e(sae,kWr),e(fw,SWr),e(le,RWr),e(le,gw),e(gw,VLe),e(VLe,PWr),e(gw,BWr),e(gw,lae),e(lae,IWr),e(gw,NWr),e(le,qWr),e(le,hw),e(hw,XLe),e(XLe,jWr),e(hw,DWr),e(hw,iae),e(iae,GWr),e(hw,OWr),e(le,VWr),e(le,uw),e(uw,zLe),e(zLe,XWr),e(uw,zWr),e(uw,dae),e(dae,QWr),e(uw,WWr),e(le,UWr),e(le,pw),e(pw,QLe),e(QLe,HWr),e(pw,JWr),e(pw,mae),e(mae,YWr),e(pw,ZWr),e(le,KWr),e(le,_w),e(_w,WLe),e(WLe,eUr),e(_w,oUr),e(_w,cae),e(cae,rUr),e(_w,tUr),e(le,aUr),e(le,bw),e(bw,ULe),e(ULe,nUr),e(bw,sUr),e(bw,fae),e(fae,lUr),e(bw,iUr),e(le,dUr),e(le,vw),e(vw,HLe),e(HLe,mUr),e(vw,cUr),e(vw,gae),e(gae,fUr),e(vw,gUr),e(le,hUr),e(le,Fw),e(Fw,JLe),e(JLe,uUr),e(Fw,pUr),e(Fw,hae),e(hae,_Ur),e(Fw,bUr),e(Gr,vUr),M(Tw,Gr,null),b(c,Wno,_),b(c,_c,_),e(_c,Mw),e(Mw,YLe),M(qR,YLe,null),e(_c,FUr),e(_c,ZLe),e(ZLe,TUr),b(c,Uno,_),b(c,fr,_),M(jR,fr,null),e(fr,MUr),e(fr,bc),e(bc,EUr),e(bc,uae),e(uae,CUr),e(bc,wUr),e(bc,pae),e(pae,AUr),e(bc,LUr),e(fr,yUr),e(fr,DR),e(DR,xUr),e(DR,KLe),e(KLe,$Ur),e(DR,kUr),e(fr,SUr),e(fr,Kt),M(GR,Kt,null),e(Kt,RUr),e(Kt,eye),e(eye,PUr),e(Kt,BUr),e(Kt,vc),e(vc,IUr),e(vc,oye),e(oye,NUr),e(vc,qUr),e(vc,_ae),e(_ae,jUr),e(vc,DUr),e(Kt,GUr),M(Ew,Kt,null),e(fr,OUr),e(fr,Or),M(OR,Or,null),e(Or,VUr),e(Or,rye),e(rye,XUr),e(Or,zUr),e(Or,Nn),e(Nn,QUr),e(Nn,tye),e(tye,WUr),e(Nn,UUr),e(Nn,aye),e(aye,HUr),e(Nn,JUr),e(Nn,nye),e(nye,YUr),e(Nn,ZUr),e(Or,KUr),e(Or,Me),e(Me,Cw),e(Cw,sye),e(sye,eHr),e(Cw,oHr),e(Cw,bae),e(bae,rHr),e(Cw,tHr),e(Me,aHr),e(Me,ww),e(ww,lye),e(lye,nHr),e(ww,sHr),e(ww,vae),e(vae,lHr),e(ww,iHr),e(Me,dHr),e(Me,Aw),e(Aw,iye),e(iye,mHr),e(Aw,cHr),e(Aw,Fae),e(Fae,fHr),e(Aw,gHr),e(Me,hHr),e(Me,Lw),e(Lw,dye),e(dye,uHr),e(Lw,pHr),e(Lw,Tae),e(Tae,_Hr),e(Lw,bHr),e(Me,vHr),e(Me,yw),e(yw,mye),e(mye,FHr),e(yw,THr),e(yw,Mae),e(Mae,MHr),e(yw,EHr),e(Me,CHr),e(Me,xw),e(xw,cye),e(cye,wHr),e(xw,AHr),e(xw,Eae),e(Eae,LHr),e(xw,yHr),e(Me,xHr),e(Me,$w),e($w,fye),e(fye,$Hr),e($w,kHr),e($w,Cae),e(Cae,SHr),e($w,RHr),e(Me,PHr),e(Me,kw),e(kw,gye),e(gye,BHr),e(kw,IHr),e(kw,wae),e(wae,NHr),e(kw,qHr),e(Me,jHr),e(Me,Sw),e(Sw,hye),e(hye,DHr),e(Sw,GHr),e(Sw,Aae),e(Aae,OHr),e(Sw,VHr),e(Me,XHr),e(Me,Rw),e(Rw,uye),e(uye,zHr),e(Rw,QHr),e(Rw,Lae),e(Lae,WHr),e(Rw,UHr),e(Me,HHr),e(Me,Pw),e(Pw,pye),e(pye,JHr),e(Pw,YHr),e(Pw,yae),e(yae,ZHr),e(Pw,KHr),e(Me,eJr),e(Me,Bw),e(Bw,_ye),e(_ye,oJr),e(Bw,rJr),e(Bw,xae),e(xae,tJr),e(Bw,aJr),e(Me,nJr),e(Me,Iw),e(Iw,bye),e(bye,sJr),e(Iw,lJr),e(Iw,$ae),e($ae,iJr),e(Iw,dJr),e(Me,mJr),e(Me,Nw),e(Nw,vye),e(vye,cJr),e(Nw,fJr),e(Nw,kae),e(kae,gJr),e(Nw,hJr),e(Or,uJr),M(qw,Or,null),b(c,Hno,_),b(c,Fc,_),e(Fc,jw),e(jw,Fye),M(VR,Fye,null),e(Fc,pJr),e(Fc,Tye),e(Tye,_Jr),b(c,Jno,_),b(c,gr,_),M(XR,gr,null),e(gr,bJr),e(gr,Tc),e(Tc,vJr),e(Tc,Sae),e(Sae,FJr),e(Tc,TJr),e(Tc,Rae),e(Rae,MJr),e(Tc,EJr),e(gr,CJr),e(gr,zR),e(zR,wJr),e(zR,Mye),e(Mye,AJr),e(zR,LJr),e(gr,yJr),e(gr,ea),M(QR,ea,null),e(ea,xJr),e(ea,Eye),e(Eye,$Jr),e(ea,kJr),e(ea,Mc),e(Mc,SJr),e(Mc,Cye),e(Cye,RJr),e(Mc,PJr),e(Mc,Pae),e(Pae,BJr),e(Mc,IJr),e(ea,NJr),M(Dw,ea,null),e(gr,qJr),e(gr,Vr),M(WR,Vr,null),e(Vr,jJr),e(Vr,wye),e(wye,DJr),e(Vr,GJr),e(Vr,qn),e(qn,OJr),e(qn,Aye),e(Aye,VJr),e(qn,XJr),e(qn,Lye),e(Lye,zJr),e(qn,QJr),e(qn,yye),e(yye,WJr),e(qn,UJr),e(Vr,HJr),e(Vr,ye),e(ye,Gw),e(Gw,xye),e(xye,JJr),e(Gw,YJr),e(Gw,Bae),e(Bae,ZJr),e(Gw,KJr),e(ye,eYr),e(ye,Ow),e(Ow,$ye),e($ye,oYr),e(Ow,rYr),e(Ow,Iae),e(Iae,tYr),e(Ow,aYr),e(ye,nYr),e(ye,Vw),e(Vw,kye),e(kye,sYr),e(Vw,lYr),e(Vw,Nae),e(Nae,iYr),e(Vw,dYr),e(ye,mYr),e(ye,Pl),e(Pl,Sye),e(Sye,cYr),e(Pl,fYr),e(Pl,qae),e(qae,gYr),e(Pl,hYr),e(Pl,jae),e(jae,uYr),e(Pl,pYr),e(ye,_Yr),e(ye,Xw),e(Xw,Rye),e(Rye,bYr),e(Xw,vYr),e(Xw,Dae),e(Dae,FYr),e(Xw,TYr),e(ye,MYr),e(ye,zw),e(zw,Pye),e(Pye,EYr),e(zw,CYr),e(zw,Gae),e(Gae,wYr),e(zw,AYr),e(ye,LYr),e(ye,Qw),e(Qw,Bye),e(Bye,yYr),e(Qw,xYr),e(Qw,Oae),e(Oae,$Yr),e(Qw,kYr),e(ye,SYr),e(ye,Ww),e(Ww,Iye),e(Iye,RYr),e(Ww,PYr),e(Ww,Vae),e(Vae,BYr),e(Ww,IYr),e(ye,NYr),e(ye,Uw),e(Uw,Nye),e(Nye,qYr),e(Uw,jYr),e(Uw,Xae),e(Xae,DYr),e(Uw,GYr),e(ye,OYr),e(ye,Hw),e(Hw,qye),e(qye,VYr),e(Hw,XYr),e(Hw,zae),e(zae,zYr),e(Hw,QYr),e(Vr,WYr),M(Jw,Vr,null),b(c,Yno,_),b(c,Ec,_),e(Ec,Yw),e(Yw,jye),M(UR,jye,null),e(Ec,UYr),e(Ec,Dye),e(Dye,HYr),b(c,Zno,_),b(c,hr,_),M(HR,hr,null),e(hr,JYr),e(hr,Cc),e(Cc,YYr),e(Cc,Qae),e(Qae,ZYr),e(Cc,KYr),e(Cc,Wae),e(Wae,eZr),e(Cc,oZr),e(hr,rZr),e(hr,JR),e(JR,tZr),e(JR,Gye),e(Gye,aZr),e(JR,nZr),e(hr,sZr),e(hr,oa),M(YR,oa,null),e(oa,lZr),e(oa,Oye),e(Oye,iZr),e(oa,dZr),e(oa,wc),e(wc,mZr),e(wc,Vye),e(Vye,cZr),e(wc,fZr),e(wc,Uae),e(Uae,gZr),e(wc,hZr),e(oa,uZr),M(Zw,oa,null),e(hr,pZr),e(hr,Xr),M(ZR,Xr,null),e(Xr,_Zr),e(Xr,Xye),e(Xye,bZr),e(Xr,vZr),e(Xr,jn),e(jn,FZr),e(jn,zye),e(zye,TZr),e(jn,MZr),e(jn,Qye),e(Qye,EZr),e(jn,CZr),e(jn,Wye),e(Wye,wZr),e(jn,AZr),e(Xr,LZr),e(Xr,Ac),e(Ac,Kw),e(Kw,Uye),e(Uye,yZr),e(Kw,xZr),e(Kw,Hae),e(Hae,$Zr),e(Kw,kZr),e(Ac,SZr),e(Ac,eA),e(eA,Hye),e(Hye,RZr),e(eA,PZr),e(eA,Jae),e(Jae,BZr),e(eA,IZr),e(Ac,NZr),e(Ac,oA),e(oA,Jye),e(Jye,qZr),e(oA,jZr),e(oA,Yae),e(Yae,DZr),e(oA,GZr),e(Xr,OZr),M(rA,Xr,null),b(c,Kno,_),b(c,Lc,_),e(Lc,tA),e(tA,Yye),M(KR,Yye,null),e(Lc,VZr),e(Lc,Zye),e(Zye,XZr),b(c,eso,_),b(c,ur,_),M(eP,ur,null),e(ur,zZr),e(ur,yc),e(yc,QZr),e(yc,Zae),e(Zae,WZr),e(yc,UZr),e(yc,Kae),e(Kae,HZr),e(yc,JZr),e(ur,YZr),e(ur,oP),e(oP,ZZr),e(oP,Kye),e(Kye,KZr),e(oP,eKr),e(ur,oKr),e(ur,ra),M(rP,ra,null),e(ra,rKr),e(ra,e9e),e(e9e,tKr),e(ra,aKr),e(ra,xc),e(xc,nKr),e(xc,o9e),e(o9e,sKr),e(xc,lKr),e(xc,ene),e(ene,iKr),e(xc,dKr),e(ra,mKr),M(aA,ra,null),e(ur,cKr),e(ur,zr),M(tP,zr,null),e(zr,fKr),e(zr,r9e),e(r9e,gKr),e(zr,hKr),e(zr,Dn),e(Dn,uKr),e(Dn,t9e),e(t9e,pKr),e(Dn,_Kr),e(Dn,a9e),e(a9e,bKr),e(Dn,vKr),e(Dn,n9e),e(n9e,FKr),e(Dn,TKr),e(zr,MKr),e(zr,ce),e(ce,nA),e(nA,s9e),e(s9e,EKr),e(nA,CKr),e(nA,one),e(one,wKr),e(nA,AKr),e(ce,LKr),e(ce,sA),e(sA,l9e),e(l9e,yKr),e(sA,xKr),e(sA,rne),e(rne,$Kr),e(sA,kKr),e(ce,SKr),e(ce,lA),e(lA,i9e),e(i9e,RKr),e(lA,PKr),e(lA,tne),e(tne,BKr),e(lA,IKr),e(ce,NKr),e(ce,iA),e(iA,d9e),e(d9e,qKr),e(iA,jKr),e(iA,ane),e(ane,DKr),e(iA,GKr),e(ce,OKr),e(ce,dA),e(dA,m9e),e(m9e,VKr),e(dA,XKr),e(dA,nne),e(nne,zKr),e(dA,QKr),e(ce,WKr),e(ce,mA),e(mA,c9e),e(c9e,UKr),e(mA,HKr),e(mA,sne),e(sne,JKr),e(mA,YKr),e(ce,ZKr),e(ce,cA),e(cA,f9e),e(f9e,KKr),e(cA,eet),e(cA,lne),e(lne,oet),e(cA,ret),e(ce,tet),e(ce,fA),e(fA,g9e),e(g9e,aet),e(fA,net),e(fA,ine),e(ine,set),e(fA,iet),e(ce,det),e(ce,gA),e(gA,h9e),e(h9e,met),e(gA,cet),e(gA,dne),e(dne,fet),e(gA,get),e(ce,het),e(ce,hA),e(hA,u9e),e(u9e,uet),e(hA,pet),e(hA,mne),e(mne,_et),e(hA,bet),e(ce,vet),e(ce,uA),e(uA,p9e),e(p9e,Fet),e(uA,Tet),e(uA,cne),e(cne,Met),e(uA,Eet),e(ce,Cet),e(ce,pA),e(pA,_9e),e(_9e,wet),e(pA,Aet),e(pA,fne),e(fne,Let),e(pA,yet),e(ce,xet),e(ce,_A),e(_A,b9e),e(b9e,$et),e(_A,ket),e(_A,gne),e(gne,Set),e(_A,Ret),e(ce,Pet),e(ce,bA),e(bA,v9e),e(v9e,Bet),e(bA,Iet),e(bA,hne),e(hne,Net),e(bA,qet),e(ce,jet),e(ce,vA),e(vA,F9e),e(F9e,Det),e(vA,Get),e(vA,une),e(une,Oet),e(vA,Vet),e(ce,Xet),e(ce,FA),e(FA,T9e),e(T9e,zet),e(FA,Qet),e(FA,pne),e(pne,Wet),e(FA,Uet),e(ce,Het),e(ce,TA),e(TA,M9e),e(M9e,Jet),e(TA,Yet),e(TA,_ne),e(_ne,Zet),e(TA,Ket),e(ce,eot),e(ce,MA),e(MA,E9e),e(E9e,oot),e(MA,rot),e(MA,bne),e(bne,tot),e(MA,aot),e(ce,not),e(ce,EA),e(EA,C9e),e(C9e,sot),e(EA,lot),e(EA,vne),e(vne,iot),e(EA,dot),e(ce,mot),e(ce,CA),e(CA,w9e),e(w9e,cot),e(CA,fot),e(CA,Fne),e(Fne,got),e(CA,hot),e(ce,uot),e(ce,wA),e(wA,A9e),e(A9e,pot),e(wA,_ot),e(wA,Tne),e(Tne,bot),e(wA,vot),e(zr,Fot),M(AA,zr,null),b(c,oso,_),b(c,$c,_),e($c,LA),e(LA,L9e),M(aP,L9e,null),e($c,Tot),e($c,y9e),e(y9e,Mot),b(c,rso,_),b(c,pr,_),M(nP,pr,null),e(pr,Eot),e(pr,kc),e(kc,Cot),e(kc,Mne),e(Mne,wot),e(kc,Aot),e(kc,Ene),e(Ene,Lot),e(kc,yot),e(pr,xot),e(pr,sP),e(sP,$ot),e(sP,x9e),e(x9e,kot),e(sP,Sot),e(pr,Rot),e(pr,ta),M(lP,ta,null),e(ta,Pot),e(ta,$9e),e($9e,Bot),e(ta,Iot),e(ta,Sc),e(Sc,Not),e(Sc,k9e),e(k9e,qot),e(Sc,jot),e(Sc,Cne),e(Cne,Dot),e(Sc,Got),e(ta,Oot),M(yA,ta,null),e(pr,Vot),e(pr,Qr),M(iP,Qr,null),e(Qr,Xot),e(Qr,S9e),e(S9e,zot),e(Qr,Qot),e(Qr,Gn),e(Gn,Wot),e(Gn,R9e),e(R9e,Uot),e(Gn,Hot),e(Gn,P9e),e(P9e,Jot),e(Gn,Yot),e(Gn,B9e),e(B9e,Zot),e(Gn,Kot),e(Qr,ert),e(Qr,xe),e(xe,xA),e(xA,I9e),e(I9e,ort),e(xA,rrt),e(xA,wne),e(wne,trt),e(xA,art),e(xe,nrt),e(xe,$A),e($A,N9e),e(N9e,srt),e($A,lrt),e($A,Ane),e(Ane,irt),e($A,drt),e(xe,mrt),e(xe,kA),e(kA,q9e),e(q9e,crt),e(kA,frt),e(kA,Lne),e(Lne,grt),e(kA,hrt),e(xe,urt),e(xe,SA),e(SA,j9e),e(j9e,prt),e(SA,_rt),e(SA,yne),e(yne,brt),e(SA,vrt),e(xe,Frt),e(xe,RA),e(RA,D9e),e(D9e,Trt),e(RA,Mrt),e(RA,xne),e(xne,Ert),e(RA,Crt),e(xe,wrt),e(xe,PA),e(PA,G9e),e(G9e,Art),e(PA,Lrt),e(PA,$ne),e($ne,yrt),e(PA,xrt),e(xe,$rt),e(xe,BA),e(BA,O9e),e(O9e,krt),e(BA,Srt),e(BA,kne),e(kne,Rrt),e(BA,Prt),e(xe,Brt),e(xe,IA),e(IA,V9e),e(V9e,Irt),e(IA,Nrt),e(IA,Sne),e(Sne,qrt),e(IA,jrt),e(xe,Drt),e(xe,NA),e(NA,X9e),e(X9e,Grt),e(NA,Ort),e(NA,Rne),e(Rne,Vrt),e(NA,Xrt),e(xe,zrt),e(xe,qA),e(qA,z9e),e(z9e,Qrt),e(qA,Wrt),e(qA,Pne),e(Pne,Urt),e(qA,Hrt),e(Qr,Jrt),M(jA,Qr,null),b(c,tso,_),b(c,Rc,_),e(Rc,DA),e(DA,Q9e),M(dP,Q9e,null),e(Rc,Yrt),e(Rc,W9e),e(W9e,Zrt),b(c,aso,_),b(c,_r,_),M(mP,_r,null),e(_r,Krt),e(_r,Pc),e(Pc,ett),e(Pc,Bne),e(Bne,ott),e(Pc,rtt),e(Pc,Ine),e(Ine,ttt),e(Pc,att),e(_r,ntt),e(_r,cP),e(cP,stt),e(cP,U9e),e(U9e,ltt),e(cP,itt),e(_r,dtt),e(_r,aa),M(fP,aa,null),e(aa,mtt),e(aa,H9e),e(H9e,ctt),e(aa,ftt),e(aa,Bc),e(Bc,gtt),e(Bc,J9e),e(J9e,htt),e(Bc,utt),e(Bc,Nne),e(Nne,ptt),e(Bc,_tt),e(aa,btt),M(GA,aa,null),e(_r,vtt),e(_r,Wr),M(gP,Wr,null),e(Wr,Ftt),e(Wr,Y9e),e(Y9e,Ttt),e(Wr,Mtt),e(Wr,On),e(On,Ett),e(On,Z9e),e(Z9e,Ctt),e(On,wtt),e(On,K9e),e(K9e,Att),e(On,Ltt),e(On,exe),e(exe,ytt),e(On,xtt),e(Wr,$tt),e(Wr,re),e(re,OA),e(OA,oxe),e(oxe,ktt),e(OA,Stt),e(OA,qne),e(qne,Rtt),e(OA,Ptt),e(re,Btt),e(re,VA),e(VA,rxe),e(rxe,Itt),e(VA,Ntt),e(VA,jne),e(jne,qtt),e(VA,jtt),e(re,Dtt),e(re,XA),e(XA,txe),e(txe,Gtt),e(XA,Ott),e(XA,Dne),e(Dne,Vtt),e(XA,Xtt),e(re,ztt),e(re,zA),e(zA,axe),e(axe,Qtt),e(zA,Wtt),e(zA,Gne),e(Gne,Utt),e(zA,Htt),e(re,Jtt),e(re,QA),e(QA,nxe),e(nxe,Ytt),e(QA,Ztt),e(QA,One),e(One,Ktt),e(QA,eat),e(re,oat),e(re,WA),e(WA,sxe),e(sxe,rat),e(WA,tat),e(WA,Vne),e(Vne,aat),e(WA,nat),e(re,sat),e(re,UA),e(UA,lxe),e(lxe,lat),e(UA,iat),e(UA,Xne),e(Xne,dat),e(UA,mat),e(re,cat),e(re,HA),e(HA,ixe),e(ixe,fat),e(HA,gat),e(HA,zne),e(zne,hat),e(HA,uat),e(re,pat),e(re,JA),e(JA,dxe),e(dxe,_at),e(JA,bat),e(JA,Qne),e(Qne,vat),e(JA,Fat),e(re,Tat),e(re,YA),e(YA,mxe),e(mxe,Mat),e(YA,Eat),e(YA,Wne),e(Wne,Cat),e(YA,wat),e(re,Aat),e(re,ZA),e(ZA,cxe),e(cxe,Lat),e(ZA,yat),e(ZA,Une),e(Une,xat),e(ZA,$at),e(re,kat),e(re,KA),e(KA,fxe),e(fxe,Sat),e(KA,Rat),e(KA,Hne),e(Hne,Pat),e(KA,Bat),e(re,Iat),e(re,e6),e(e6,gxe),e(gxe,Nat),e(e6,qat),e(e6,Jne),e(Jne,jat),e(e6,Dat),e(re,Gat),e(re,o6),e(o6,hxe),e(hxe,Oat),e(o6,Vat),e(o6,Yne),e(Yne,Xat),e(o6,zat),e(re,Qat),e(re,r6),e(r6,uxe),e(uxe,Wat),e(r6,Uat),e(r6,Zne),e(Zne,Hat),e(r6,Jat),e(re,Yat),e(re,t6),e(t6,pxe),e(pxe,Zat),e(t6,Kat),e(t6,Kne),e(Kne,ent),e(t6,ont),e(re,rnt),e(re,a6),e(a6,_xe),e(_xe,tnt),e(a6,ant),e(a6,ese),e(ese,nnt),e(a6,snt),e(re,lnt),e(re,n6),e(n6,bxe),e(bxe,int),e(n6,dnt),e(n6,ose),e(ose,mnt),e(n6,cnt),e(re,fnt),e(re,s6),e(s6,vxe),e(vxe,gnt),e(s6,hnt),e(s6,rse),e(rse,unt),e(s6,pnt),e(re,_nt),e(re,l6),e(l6,Fxe),e(Fxe,bnt),e(l6,vnt),e(l6,tse),e(tse,Fnt),e(l6,Tnt),e(re,Mnt),e(re,i6),e(i6,Txe),e(Txe,Ent),e(i6,Cnt),e(i6,ase),e(ase,wnt),e(i6,Ant),e(re,Lnt),e(re,d6),e(d6,Mxe),e(Mxe,ynt),e(d6,xnt),e(d6,nse),e(nse,$nt),e(d6,knt),e(re,Snt),e(re,m6),e(m6,Exe),e(Exe,Rnt),e(m6,Pnt),e(m6,sse),e(sse,Bnt),e(m6,Int),e(re,Nnt),e(re,c6),e(c6,Cxe),e(Cxe,qnt),e(c6,jnt),e(c6,lse),e(lse,Dnt),e(c6,Gnt),e(re,Ont),e(re,f6),e(f6,wxe),e(wxe,Vnt),e(f6,Xnt),e(f6,ise),e(ise,znt),e(f6,Qnt),e(re,Wnt),e(re,g6),e(g6,Axe),e(Axe,Unt),e(g6,Hnt),e(g6,dse),e(dse,Jnt),e(g6,Ynt),e(re,Znt),e(re,h6),e(h6,Lxe),e(Lxe,Knt),e(h6,est),e(h6,mse),e(mse,ost),e(h6,rst),e(re,tst),e(re,u6),e(u6,yxe),e(yxe,ast),e(u6,nst),e(u6,cse),e(cse,sst),e(u6,lst),e(Wr,ist),M(p6,Wr,null),b(c,nso,_),b(c,Ic,_),e(Ic,_6),e(_6,xxe),M(hP,xxe,null),e(Ic,dst),e(Ic,$xe),e($xe,mst),b(c,sso,_),b(c,br,_),M(uP,br,null),e(br,cst),e(br,Nc),e(Nc,fst),e(Nc,fse),e(fse,gst),e(Nc,hst),e(Nc,gse),e(gse,ust),e(Nc,pst),e(br,_st),e(br,pP),e(pP,bst),e(pP,kxe),e(kxe,vst),e(pP,Fst),e(br,Tst),e(br,na),M(_P,na,null),e(na,Mst),e(na,Sxe),e(Sxe,Est),e(na,Cst),e(na,qc),e(qc,wst),e(qc,Rxe),e(Rxe,Ast),e(qc,Lst),e(qc,hse),e(hse,yst),e(qc,xst),e(na,$st),M(b6,na,null),e(br,kst),e(br,Ur),M(bP,Ur,null),e(Ur,Sst),e(Ur,Pxe),e(Pxe,Rst),e(Ur,Pst),e(Ur,Vn),e(Vn,Bst),e(Vn,Bxe),e(Bxe,Ist),e(Vn,Nst),e(Vn,Ixe),e(Ixe,qst),e(Vn,jst),e(Vn,Nxe),e(Nxe,Dst),e(Vn,Gst),e(Ur,Ost),e(Ur,ve),e(ve,v6),e(v6,qxe),e(qxe,Vst),e(v6,Xst),e(v6,use),e(use,zst),e(v6,Qst),e(ve,Wst),e(ve,F6),e(F6,jxe),e(jxe,Ust),e(F6,Hst),e(F6,pse),e(pse,Jst),e(F6,Yst),e(ve,Zst),e(ve,T6),e(T6,Dxe),e(Dxe,Kst),e(T6,elt),e(T6,_se),e(_se,olt),e(T6,rlt),e(ve,tlt),e(ve,M6),e(M6,Gxe),e(Gxe,alt),e(M6,nlt),e(M6,bse),e(bse,slt),e(M6,llt),e(ve,ilt),e(ve,E6),e(E6,Oxe),e(Oxe,dlt),e(E6,mlt),e(E6,vse),e(vse,clt),e(E6,flt),e(ve,glt),e(ve,C6),e(C6,Vxe),e(Vxe,hlt),e(C6,ult),e(C6,Fse),e(Fse,plt),e(C6,_lt),e(ve,blt),e(ve,w6),e(w6,Xxe),e(Xxe,vlt),e(w6,Flt),e(w6,Tse),e(Tse,Tlt),e(w6,Mlt),e(ve,Elt),e(ve,A6),e(A6,zxe),e(zxe,Clt),e(A6,wlt),e(A6,Mse),e(Mse,Alt),e(A6,Llt),e(ve,ylt),e(ve,L6),e(L6,Qxe),e(Qxe,xlt),e(L6,$lt),e(L6,Ese),e(Ese,klt),e(L6,Slt),e(ve,Rlt),e(ve,y6),e(y6,Wxe),e(Wxe,Plt),e(y6,Blt),e(y6,Cse),e(Cse,Ilt),e(y6,Nlt),e(ve,qlt),e(ve,x6),e(x6,Uxe),e(Uxe,jlt),e(x6,Dlt),e(x6,wse),e(wse,Glt),e(x6,Olt),e(ve,Vlt),e(ve,$6),e($6,Hxe),e(Hxe,Xlt),e($6,zlt),e($6,Ase),e(Ase,Qlt),e($6,Wlt),e(ve,Ult),e(ve,k6),e(k6,Jxe),e(Jxe,Hlt),e(k6,Jlt),e(k6,Lse),e(Lse,Ylt),e(k6,Zlt),e(ve,Klt),e(ve,S6),e(S6,Yxe),e(Yxe,eit),e(S6,oit),e(S6,yse),e(yse,rit),e(S6,tit),e(ve,ait),e(ve,R6),e(R6,Zxe),e(Zxe,nit),e(R6,sit),e(R6,xse),e(xse,lit),e(R6,iit),e(ve,dit),e(ve,P6),e(P6,Kxe),e(Kxe,mit),e(P6,cit),e(P6,$se),e($se,fit),e(P6,git),e(ve,hit),e(ve,B6),e(B6,e$e),e(e$e,uit),e(B6,pit),e(B6,kse),e(kse,_it),e(B6,bit),e(Ur,vit),M(I6,Ur,null),b(c,lso,_),b(c,jc,_),e(jc,N6),e(N6,o$e),M(vP,o$e,null),e(jc,Fit),e(jc,r$e),e(r$e,Tit),b(c,iso,_),b(c,vr,_),M(FP,vr,null),e(vr,Mit),e(vr,Dc),e(Dc,Eit),e(Dc,Sse),e(Sse,Cit),e(Dc,wit),e(Dc,Rse),e(Rse,Ait),e(Dc,Lit),e(vr,yit),e(vr,TP),e(TP,xit),e(TP,t$e),e(t$e,$it),e(TP,kit),e(vr,Sit),e(vr,sa),M(MP,sa,null),e(sa,Rit),e(sa,a$e),e(a$e,Pit),e(sa,Bit),e(sa,Gc),e(Gc,Iit),e(Gc,n$e),e(n$e,Nit),e(Gc,qit),e(Gc,Pse),e(Pse,jit),e(Gc,Dit),e(sa,Git),M(q6,sa,null),e(vr,Oit),e(vr,Hr),M(EP,Hr,null),e(Hr,Vit),e(Hr,s$e),e(s$e,Xit),e(Hr,zit),e(Hr,Xn),e(Xn,Qit),e(Xn,l$e),e(l$e,Wit),e(Xn,Uit),e(Xn,i$e),e(i$e,Hit),e(Xn,Jit),e(Xn,d$e),e(d$e,Yit),e(Xn,Zit),e(Hr,Kit),e(Hr,CP),e(CP,j6),e(j6,m$e),e(m$e,edt),e(j6,odt),e(j6,Bse),e(Bse,rdt),e(j6,tdt),e(CP,adt),e(CP,D6),e(D6,c$e),e(c$e,ndt),e(D6,sdt),e(D6,Ise),e(Ise,ldt),e(D6,idt),e(Hr,ddt),M(G6,Hr,null),b(c,dso,_),b(c,Oc,_),e(Oc,O6),e(O6,f$e),M(wP,f$e,null),e(Oc,mdt),e(Oc,g$e),e(g$e,cdt),b(c,mso,_),b(c,Fr,_),M(AP,Fr,null),e(Fr,fdt),e(Fr,Vc),e(Vc,gdt),e(Vc,Nse),e(Nse,hdt),e(Vc,udt),e(Vc,qse),e(qse,pdt),e(Vc,_dt),e(Fr,bdt),e(Fr,LP),e(LP,vdt),e(LP,h$e),e(h$e,Fdt),e(LP,Tdt),e(Fr,Mdt),e(Fr,la),M(yP,la,null),e(la,Edt),e(la,u$e),e(u$e,Cdt),e(la,wdt),e(la,Xc),e(Xc,Adt),e(Xc,p$e),e(p$e,Ldt),e(Xc,ydt),e(Xc,jse),e(jse,xdt),e(Xc,$dt),e(la,kdt),M(V6,la,null),e(Fr,Sdt),e(Fr,Jr),M(xP,Jr,null),e(Jr,Rdt),e(Jr,_$e),e(_$e,Pdt),e(Jr,Bdt),e(Jr,zn),e(zn,Idt),e(zn,b$e),e(b$e,Ndt),e(zn,qdt),e(zn,v$e),e(v$e,jdt),e(zn,Ddt),e(zn,F$e),e(F$e,Gdt),e(zn,Odt),e(Jr,Vdt),e(Jr,T$e),e(T$e,X6),e(X6,M$e),e(M$e,Xdt),e(X6,zdt),e(X6,Dse),e(Dse,Qdt),e(X6,Wdt),e(Jr,Udt),M(z6,Jr,null),b(c,cso,_),b(c,zc,_),e(zc,Q6),e(Q6,E$e),M($P,E$e,null),e(zc,Hdt),e(zc,C$e),e(C$e,Jdt),b(c,fso,_),b(c,Tr,_),M(kP,Tr,null),e(Tr,Ydt),e(Tr,Qc),e(Qc,Zdt),e(Qc,Gse),e(Gse,Kdt),e(Qc,emt),e(Qc,Ose),e(Ose,omt),e(Qc,rmt),e(Tr,tmt),e(Tr,SP),e(SP,amt),e(SP,w$e),e(w$e,nmt),e(SP,smt),e(Tr,lmt),e(Tr,ia),M(RP,ia,null),e(ia,imt),e(ia,A$e),e(A$e,dmt),e(ia,mmt),e(ia,Wc),e(Wc,cmt),e(Wc,L$e),e(L$e,fmt),e(Wc,gmt),e(Wc,Vse),e(Vse,hmt),e(Wc,umt),e(ia,pmt),M(W6,ia,null),e(Tr,_mt),e(Tr,Yr),M(PP,Yr,null),e(Yr,bmt),e(Yr,y$e),e(y$e,vmt),e(Yr,Fmt),e(Yr,Qn),e(Qn,Tmt),e(Qn,x$e),e(x$e,Mmt),e(Qn,Emt),e(Qn,$$e),e($$e,Cmt),e(Qn,wmt),e(Qn,k$e),e(k$e,Amt),e(Qn,Lmt),e(Yr,ymt),e(Yr,S$e),e(S$e,U6),e(U6,R$e),e(R$e,xmt),e(U6,$mt),e(U6,Xse),e(Xse,kmt),e(U6,Smt),e(Yr,Rmt),M(H6,Yr,null),b(c,gso,_),b(c,Uc,_),e(Uc,J6),e(J6,P$e),M(BP,P$e,null),e(Uc,Pmt),e(Uc,B$e),e(B$e,Bmt),b(c,hso,_),b(c,Mr,_),M(IP,Mr,null),e(Mr,Imt),e(Mr,Hc),e(Hc,Nmt),e(Hc,zse),e(zse,qmt),e(Hc,jmt),e(Hc,Qse),e(Qse,Dmt),e(Hc,Gmt),e(Mr,Omt),e(Mr,NP),e(NP,Vmt),e(NP,I$e),e(I$e,Xmt),e(NP,zmt),e(Mr,Qmt),e(Mr,da),M(qP,da,null),e(da,Wmt),e(da,N$e),e(N$e,Umt),e(da,Hmt),e(da,Jc),e(Jc,Jmt),e(Jc,q$e),e(q$e,Ymt),e(Jc,Zmt),e(Jc,Wse),e(Wse,Kmt),e(Jc,ect),e(da,oct),M(Y6,da,null),e(Mr,rct),e(Mr,Zr),M(jP,Zr,null),e(Zr,tct),e(Zr,j$e),e(j$e,act),e(Zr,nct),e(Zr,Wn),e(Wn,sct),e(Wn,D$e),e(D$e,lct),e(Wn,ict),e(Wn,G$e),e(G$e,dct),e(Wn,mct),e(Wn,O$e),e(O$e,cct),e(Wn,fct),e(Zr,gct),e(Zr,ie),e(ie,Z6),e(Z6,V$e),e(V$e,hct),e(Z6,uct),e(Z6,Use),e(Use,pct),e(Z6,_ct),e(ie,bct),e(ie,K6),e(K6,X$e),e(X$e,vct),e(K6,Fct),e(K6,Hse),e(Hse,Tct),e(K6,Mct),e(ie,Ect),e(ie,e7),e(e7,z$e),e(z$e,Cct),e(e7,wct),e(e7,Jse),e(Jse,Act),e(e7,Lct),e(ie,yct),e(ie,o7),e(o7,Q$e),e(Q$e,xct),e(o7,$ct),e(o7,Yse),e(Yse,kct),e(o7,Sct),e(ie,Rct),e(ie,r7),e(r7,W$e),e(W$e,Pct),e(r7,Bct),e(r7,Zse),e(Zse,Ict),e(r7,Nct),e(ie,qct),e(ie,t7),e(t7,U$e),e(U$e,jct),e(t7,Dct),e(t7,Kse),e(Kse,Gct),e(t7,Oct),e(ie,Vct),e(ie,a7),e(a7,H$e),e(H$e,Xct),e(a7,zct),e(a7,ele),e(ele,Qct),e(a7,Wct),e(ie,Uct),e(ie,n7),e(n7,J$e),e(J$e,Hct),e(n7,Jct),e(n7,ole),e(ole,Yct),e(n7,Zct),e(ie,Kct),e(ie,s7),e(s7,Y$e),e(Y$e,eft),e(s7,oft),e(s7,rle),e(rle,rft),e(s7,tft),e(ie,aft),e(ie,l7),e(l7,Z$e),e(Z$e,nft),e(l7,sft),e(l7,tle),e(tle,lft),e(l7,ift),e(ie,dft),e(ie,i7),e(i7,K$e),e(K$e,mft),e(i7,cft),e(i7,ale),e(ale,fft),e(i7,gft),e(ie,hft),e(ie,d7),e(d7,eke),e(eke,uft),e(d7,pft),e(d7,nle),e(nle,_ft),e(d7,bft),e(ie,vft),e(ie,m7),e(m7,oke),e(oke,Fft),e(m7,Tft),e(m7,sle),e(sle,Mft),e(m7,Eft),e(ie,Cft),e(ie,c7),e(c7,rke),e(rke,wft),e(c7,Aft),e(c7,lle),e(lle,Lft),e(c7,yft),e(ie,xft),e(ie,f7),e(f7,tke),e(tke,$ft),e(f7,kft),e(f7,ile),e(ile,Sft),e(f7,Rft),e(ie,Pft),e(ie,g7),e(g7,ake),e(ake,Bft),e(g7,Ift),e(g7,dle),e(dle,Nft),e(g7,qft),e(ie,jft),e(ie,h7),e(h7,nke),e(nke,Dft),e(h7,Gft),e(h7,mle),e(mle,Oft),e(h7,Vft),e(ie,Xft),e(ie,u7),e(u7,ske),e(ske,zft),e(u7,Qft),e(u7,cle),e(cle,Wft),e(u7,Uft),e(ie,Hft),e(ie,p7),e(p7,lke),e(lke,Jft),e(p7,Yft),e(p7,fle),e(fle,Zft),e(p7,Kft),e(ie,egt),e(ie,_7),e(_7,ike),e(ike,ogt),e(_7,rgt),e(_7,gle),e(gle,tgt),e(_7,agt),e(ie,ngt),e(ie,b7),e(b7,dke),e(dke,sgt),e(b7,lgt),e(b7,hle),e(hle,igt),e(b7,dgt),e(ie,mgt),e(ie,v7),e(v7,mke),e(mke,cgt),e(v7,fgt),e(v7,ule),e(ule,ggt),e(v7,hgt),e(Zr,ugt),M(F7,Zr,null),b(c,uso,_),b(c,Yc,_),e(Yc,T7),e(T7,cke),M(DP,cke,null),e(Yc,pgt),e(Yc,fke),e(fke,_gt),b(c,pso,_),b(c,Er,_),M(GP,Er,null),e(Er,bgt),e(Er,Zc),e(Zc,vgt),e(Zc,ple),e(ple,Fgt),e(Zc,Tgt),e(Zc,_le),e(_le,Mgt),e(Zc,Egt),e(Er,Cgt),e(Er,OP),e(OP,wgt),e(OP,gke),e(gke,Agt),e(OP,Lgt),e(Er,ygt),e(Er,ma),M(VP,ma,null),e(ma,xgt),e(ma,hke),e(hke,$gt),e(ma,kgt),e(ma,Kc),e(Kc,Sgt),e(Kc,uke),e(uke,Rgt),e(Kc,Pgt),e(Kc,ble),e(ble,Bgt),e(Kc,Igt),e(ma,Ngt),M(M7,ma,null),e(Er,qgt),e(Er,Kr),M(XP,Kr,null),e(Kr,jgt),e(Kr,pke),e(pke,Dgt),e(Kr,Ggt),e(Kr,Un),e(Un,Ogt),e(Un,_ke),e(_ke,Vgt),e(Un,Xgt),e(Un,bke),e(bke,zgt),e(Un,Qgt),e(Un,vke),e(vke,Wgt),e(Un,Ugt),e(Kr,Hgt),e(Kr,fe),e(fe,E7),e(E7,Fke),e(Fke,Jgt),e(E7,Ygt),e(E7,vle),e(vle,Zgt),e(E7,Kgt),e(fe,eht),e(fe,C7),e(C7,Tke),e(Tke,oht),e(C7,rht),e(C7,Fle),e(Fle,tht),e(C7,aht),e(fe,nht),e(fe,w7),e(w7,Mke),e(Mke,sht),e(w7,lht),e(w7,Tle),e(Tle,iht),e(w7,dht),e(fe,mht),e(fe,A7),e(A7,Eke),e(Eke,cht),e(A7,fht),e(A7,Mle),e(Mle,ght),e(A7,hht),e(fe,uht),e(fe,L7),e(L7,Cke),e(Cke,pht),e(L7,_ht),e(L7,Ele),e(Ele,bht),e(L7,vht),e(fe,Fht),e(fe,y7),e(y7,wke),e(wke,Tht),e(y7,Mht),e(y7,Cle),e(Cle,Eht),e(y7,Cht),e(fe,wht),e(fe,x7),e(x7,Ake),e(Ake,Aht),e(x7,Lht),e(x7,wle),e(wle,yht),e(x7,xht),e(fe,$ht),e(fe,$7),e($7,Lke),e(Lke,kht),e($7,Sht),e($7,Ale),e(Ale,Rht),e($7,Pht),e(fe,Bht),e(fe,k7),e(k7,yke),e(yke,Iht),e(k7,Nht),e(k7,Lle),e(Lle,qht),e(k7,jht),e(fe,Dht),e(fe,S7),e(S7,xke),e(xke,Ght),e(S7,Oht),e(S7,yle),e(yle,Vht),e(S7,Xht),e(fe,zht),e(fe,R7),e(R7,$ke),e($ke,Qht),e(R7,Wht),e(R7,xle),e(xle,Uht),e(R7,Hht),e(fe,Jht),e(fe,P7),e(P7,kke),e(kke,Yht),e(P7,Zht),e(P7,$le),e($le,Kht),e(P7,eut),e(fe,out),e(fe,B7),e(B7,Ske),e(Ske,rut),e(B7,tut),e(B7,kle),e(kle,aut),e(B7,nut),e(fe,sut),e(fe,I7),e(I7,Rke),e(Rke,lut),e(I7,iut),e(I7,Sle),e(Sle,dut),e(I7,mut),e(fe,cut),e(fe,N7),e(N7,Pke),e(Pke,fut),e(N7,gut),e(N7,Rle),e(Rle,hut),e(N7,uut),e(fe,put),e(fe,q7),e(q7,Bke),e(Bke,_ut),e(q7,but),e(q7,Ple),e(Ple,vut),e(q7,Fut),e(fe,Tut),e(fe,j7),e(j7,Ike),e(Ike,Mut),e(j7,Eut),e(j7,Ble),e(Ble,Cut),e(j7,wut),e(fe,Aut),e(fe,D7),e(D7,Nke),e(Nke,Lut),e(D7,yut),e(D7,Ile),e(Ile,xut),e(D7,$ut),e(fe,kut),e(fe,G7),e(G7,qke),e(qke,Sut),e(G7,Rut),e(G7,Nle),e(Nle,Put),e(G7,But),e(fe,Iut),e(fe,O7),e(O7,jke),e(jke,Nut),e(O7,qut),e(O7,qle),e(qle,jut),e(O7,Dut),e(fe,Gut),e(fe,V7),e(V7,Dke),e(Dke,Out),e(V7,Vut),e(V7,jle),e(jle,Xut),e(V7,zut),e(Kr,Qut),M(X7,Kr,null),b(c,_so,_),b(c,ef,_),e(ef,z7),e(z7,Gke),M(zP,Gke,null),e(ef,Wut),e(ef,Oke),e(Oke,Uut),b(c,bso,_),b(c,Cr,_),M(QP,Cr,null),e(Cr,Hut),e(Cr,of),e(of,Jut),e(of,Dle),e(Dle,Yut),e(of,Zut),e(of,Gle),e(Gle,Kut),e(of,ept),e(Cr,opt),e(Cr,WP),e(WP,rpt),e(WP,Vke),e(Vke,tpt),e(WP,apt),e(Cr,npt),e(Cr,ca),M(UP,ca,null),e(ca,spt),e(ca,Xke),e(Xke,lpt),e(ca,ipt),e(ca,rf),e(rf,dpt),e(rf,zke),e(zke,mpt),e(rf,cpt),e(rf,Ole),e(Ole,fpt),e(rf,gpt),e(ca,hpt),M(Q7,ca,null),e(Cr,upt),e(Cr,et),M(HP,et,null),e(et,ppt),e(et,Qke),e(Qke,_pt),e(et,bpt),e(et,Hn),e(Hn,vpt),e(Hn,Wke),e(Wke,Fpt),e(Hn,Tpt),e(Hn,Uke),e(Uke,Mpt),e(Hn,Ept),e(Hn,Hke),e(Hke,Cpt),e(Hn,wpt),e(et,Apt),e(et,Jke),e(Jke,W7),e(W7,Yke),e(Yke,Lpt),e(W7,ypt),e(W7,Vle),e(Vle,xpt),e(W7,$pt),e(et,kpt),M(U7,et,null),b(c,vso,_),b(c,tf,_),e(tf,H7),e(H7,Zke),M(JP,Zke,null),e(tf,Spt),e(tf,Kke),e(Kke,Rpt),b(c,Fso,_),b(c,wr,_),M(YP,wr,null),e(wr,Ppt),e(wr,af),e(af,Bpt),e(af,Xle),e(Xle,Ipt),e(af,Npt),e(af,zle),e(zle,qpt),e(af,jpt),e(wr,Dpt),e(wr,ZP),e(ZP,Gpt),e(ZP,eSe),e(eSe,Opt),e(ZP,Vpt),e(wr,Xpt),e(wr,fa),M(KP,fa,null),e(fa,zpt),e(fa,oSe),e(oSe,Qpt),e(fa,Wpt),e(fa,nf),e(nf,Upt),e(nf,rSe),e(rSe,Hpt),e(nf,Jpt),e(nf,Qle),e(Qle,Ypt),e(nf,Zpt),e(fa,Kpt),M(J7,fa,null),e(wr,e_t),e(wr,ot),M(eB,ot,null),e(ot,o_t),e(ot,tSe),e(tSe,r_t),e(ot,t_t),e(ot,Jn),e(Jn,a_t),e(Jn,aSe),e(aSe,n_t),e(Jn,s_t),e(Jn,nSe),e(nSe,l_t),e(Jn,i_t),e(Jn,sSe),e(sSe,d_t),e(Jn,m_t),e(ot,c_t),e(ot,oB),e(oB,Y7),e(Y7,lSe),e(lSe,f_t),e(Y7,g_t),e(Y7,Wle),e(Wle,h_t),e(Y7,u_t),e(oB,p_t),e(oB,Z7),e(Z7,iSe),e(iSe,__t),e(Z7,b_t),e(Z7,Ule),e(Ule,v_t),e(Z7,F_t),e(ot,T_t),M(K7,ot,null),b(c,Tso,_),b(c,sf,_),e(sf,e8),e(e8,dSe),M(rB,dSe,null),e(sf,M_t),e(sf,mSe),e(mSe,E_t),b(c,Mso,_),b(c,Ar,_),M(tB,Ar,null),e(Ar,C_t),e(Ar,lf),e(lf,w_t),e(lf,Hle),e(Hle,A_t),e(lf,L_t),e(lf,Jle),e(Jle,y_t),e(lf,x_t),e(Ar,$_t),e(Ar,aB),e(aB,k_t),e(aB,cSe),e(cSe,S_t),e(aB,R_t),e(Ar,P_t),e(Ar,ga),M(nB,ga,null),e(ga,B_t),e(ga,fSe),e(fSe,I_t),e(ga,N_t),e(ga,df),e(df,q_t),e(df,gSe),e(gSe,j_t),e(df,D_t),e(df,Yle),e(Yle,G_t),e(df,O_t),e(ga,V_t),M(o8,ga,null),e(Ar,X_t),e(Ar,rt),M(sB,rt,null),e(rt,z_t),e(rt,hSe),e(hSe,Q_t),e(rt,W_t),e(rt,Yn),e(Yn,U_t),e(Yn,uSe),e(uSe,H_t),e(Yn,J_t),e(Yn,pSe),e(pSe,Y_t),e(Yn,Z_t),e(Yn,_Se),e(_Se,K_t),e(Yn,e1t),e(rt,o1t),e(rt,te),e(te,r8),e(r8,bSe),e(bSe,r1t),e(r8,t1t),e(r8,Zle),e(Zle,a1t),e(r8,n1t),e(te,s1t),e(te,t8),e(t8,vSe),e(vSe,l1t),e(t8,i1t),e(t8,Kle),e(Kle,d1t),e(t8,m1t),e(te,c1t),e(te,a8),e(a8,FSe),e(FSe,f1t),e(a8,g1t),e(a8,eie),e(eie,h1t),e(a8,u1t),e(te,p1t),e(te,n8),e(n8,TSe),e(TSe,_1t),e(n8,b1t),e(n8,oie),e(oie,v1t),e(n8,F1t),e(te,T1t),e(te,s8),e(s8,MSe),e(MSe,M1t),e(s8,E1t),e(s8,rie),e(rie,C1t),e(s8,w1t),e(te,A1t),e(te,l8),e(l8,ESe),e(ESe,L1t),e(l8,y1t),e(l8,tie),e(tie,x1t),e(l8,$1t),e(te,k1t),e(te,i8),e(i8,CSe),e(CSe,S1t),e(i8,R1t),e(i8,aie),e(aie,P1t),e(i8,B1t),e(te,I1t),e(te,d8),e(d8,wSe),e(wSe,N1t),e(d8,q1t),e(d8,nie),e(nie,j1t),e(d8,D1t),e(te,G1t),e(te,m8),e(m8,ASe),e(ASe,O1t),e(m8,V1t),e(m8,sie),e(sie,X1t),e(m8,z1t),e(te,Q1t),e(te,c8),e(c8,LSe),e(LSe,W1t),e(c8,U1t),e(c8,lie),e(lie,H1t),e(c8,J1t),e(te,Y1t),e(te,f8),e(f8,ySe),e(ySe,Z1t),e(f8,K1t),e(f8,iie),e(iie,e2t),e(f8,o2t),e(te,r2t),e(te,g8),e(g8,xSe),e(xSe,t2t),e(g8,a2t),e(g8,die),e(die,n2t),e(g8,s2t),e(te,l2t),e(te,h8),e(h8,$Se),e($Se,i2t),e(h8,d2t),e(h8,mie),e(mie,m2t),e(h8,c2t),e(te,f2t),e(te,u8),e(u8,kSe),e(kSe,g2t),e(u8,h2t),e(u8,cie),e(cie,u2t),e(u8,p2t),e(te,_2t),e(te,p8),e(p8,SSe),e(SSe,b2t),e(p8,v2t),e(p8,fie),e(fie,F2t),e(p8,T2t),e(te,M2t),e(te,_8),e(_8,RSe),e(RSe,E2t),e(_8,C2t),e(_8,gie),e(gie,w2t),e(_8,A2t),e(te,L2t),e(te,b8),e(b8,PSe),e(PSe,y2t),e(b8,x2t),e(b8,hie),e(hie,$2t),e(b8,k2t),e(te,S2t),e(te,v8),e(v8,BSe),e(BSe,R2t),e(v8,P2t),e(v8,uie),e(uie,B2t),e(v8,I2t),e(te,N2t),e(te,F8),e(F8,ISe),e(ISe,q2t),e(F8,j2t),e(F8,pie),e(pie,D2t),e(F8,G2t),e(te,O2t),e(te,T8),e(T8,NSe),e(NSe,V2t),e(T8,X2t),e(T8,_ie),e(_ie,z2t),e(T8,Q2t),e(te,W2t),e(te,M8),e(M8,qSe),e(qSe,U2t),e(M8,H2t),e(M8,bie),e(bie,J2t),e(M8,Y2t),e(te,Z2t),e(te,E8),e(E8,jSe),e(jSe,K2t),e(E8,ebt),e(E8,vie),e(vie,obt),e(E8,rbt),e(te,tbt),e(te,C8),e(C8,DSe),e(DSe,abt),e(C8,nbt),e(C8,Fie),e(Fie,sbt),e(C8,lbt),e(te,ibt),e(te,w8),e(w8,GSe),e(GSe,dbt),e(w8,mbt),e(w8,Tie),e(Tie,cbt),e(w8,fbt),e(te,gbt),e(te,A8),e(A8,OSe),e(OSe,hbt),e(A8,ubt),e(A8,Mie),e(Mie,pbt),e(A8,_bt),e(te,bbt),e(te,L8),e(L8,VSe),e(VSe,vbt),e(L8,Fbt),e(L8,Eie),e(Eie,Tbt),e(L8,Mbt),e(te,Ebt),e(te,y8),e(y8,XSe),e(XSe,Cbt),e(y8,wbt),e(y8,Cie),e(Cie,Abt),e(y8,Lbt),e(rt,ybt),M(x8,rt,null),b(c,Eso,_),b(c,mf,_),e(mf,$8),e($8,zSe),M(lB,zSe,null),e(mf,xbt),e(mf,QSe),e(QSe,$bt),b(c,Cso,_),b(c,Lr,_),M(iB,Lr,null),e(Lr,kbt),e(Lr,cf),e(cf,Sbt),e(cf,wie),e(wie,Rbt),e(cf,Pbt),e(cf,Aie),e(Aie,Bbt),e(cf,Ibt),e(Lr,Nbt),e(Lr,dB),e(dB,qbt),e(dB,WSe),e(WSe,jbt),e(dB,Dbt),e(Lr,Gbt),e(Lr,ha),M(mB,ha,null),e(ha,Obt),e(ha,USe),e(USe,Vbt),e(ha,Xbt),e(ha,ff),e(ff,zbt),e(ff,HSe),e(HSe,Qbt),e(ff,Wbt),e(ff,Lie),e(Lie,Ubt),e(ff,Hbt),e(ha,Jbt),M(k8,ha,null),e(Lr,Ybt),e(Lr,tt),M(cB,tt,null),e(tt,Zbt),e(tt,JSe),e(JSe,Kbt),e(tt,evt),e(tt,Zn),e(Zn,ovt),e(Zn,YSe),e(YSe,rvt),e(Zn,tvt),e(Zn,ZSe),e(ZSe,avt),e(Zn,nvt),e(Zn,KSe),e(KSe,svt),e(Zn,lvt),e(tt,ivt),e(tt,$e),e($e,S8),e(S8,eRe),e(eRe,dvt),e(S8,mvt),e(S8,yie),e(yie,cvt),e(S8,fvt),e($e,gvt),e($e,R8),e(R8,oRe),e(oRe,hvt),e(R8,uvt),e(R8,xie),e(xie,pvt),e(R8,_vt),e($e,bvt),e($e,P8),e(P8,rRe),e(rRe,vvt),e(P8,Fvt),e(P8,$ie),e($ie,Tvt),e(P8,Mvt),e($e,Evt),e($e,B8),e(B8,tRe),e(tRe,Cvt),e(B8,wvt),e(B8,kie),e(kie,Avt),e(B8,Lvt),e($e,yvt),e($e,I8),e(I8,aRe),e(aRe,xvt),e(I8,$vt),e(I8,Sie),e(Sie,kvt),e(I8,Svt),e($e,Rvt),e($e,N8),e(N8,nRe),e(nRe,Pvt),e(N8,Bvt),e(N8,Rie),e(Rie,Ivt),e(N8,Nvt),e($e,qvt),e($e,q8),e(q8,sRe),e(sRe,jvt),e(q8,Dvt),e(q8,Pie),e(Pie,Gvt),e(q8,Ovt),e($e,Vvt),e($e,j8),e(j8,lRe),e(lRe,Xvt),e(j8,zvt),e(j8,Bie),e(Bie,Qvt),e(j8,Wvt),e($e,Uvt),e($e,D8),e(D8,iRe),e(iRe,Hvt),e(D8,Jvt),e(D8,Iie),e(Iie,Yvt),e(D8,Zvt),e($e,Kvt),e($e,G8),e(G8,dRe),e(dRe,eFt),e(G8,oFt),e(G8,Nie),e(Nie,rFt),e(G8,tFt),e(tt,aFt),M(O8,tt,null),b(c,wso,_),b(c,gf,_),e(gf,V8),e(V8,mRe),M(fB,mRe,null),e(gf,nFt),e(gf,cRe),e(cRe,sFt),b(c,Aso,_),b(c,yr,_),M(gB,yr,null),e(yr,lFt),e(yr,hf),e(hf,iFt),e(hf,qie),e(qie,dFt),e(hf,mFt),e(hf,jie),e(jie,cFt),e(hf,fFt),e(yr,gFt),e(yr,hB),e(hB,hFt),e(hB,fRe),e(fRe,uFt),e(hB,pFt),e(yr,_Ft),e(yr,ua),M(uB,ua,null),e(ua,bFt),e(ua,gRe),e(gRe,vFt),e(ua,FFt),e(ua,uf),e(uf,TFt),e(uf,hRe),e(hRe,MFt),e(uf,EFt),e(uf,Die),e(Die,CFt),e(uf,wFt),e(ua,AFt),M(X8,ua,null),e(yr,LFt),e(yr,at),M(pB,at,null),e(at,yFt),e(at,uRe),e(uRe,xFt),e(at,$Ft),e(at,Kn),e(Kn,kFt),e(Kn,pRe),e(pRe,SFt),e(Kn,RFt),e(Kn,_Re),e(_Re,PFt),e(Kn,BFt),e(Kn,bRe),e(bRe,IFt),e(Kn,NFt),e(at,qFt),e(at,Ee),e(Ee,z8),e(z8,vRe),e(vRe,jFt),e(z8,DFt),e(z8,Gie),e(Gie,GFt),e(z8,OFt),e(Ee,VFt),e(Ee,Q8),e(Q8,FRe),e(FRe,XFt),e(Q8,zFt),e(Q8,Oie),e(Oie,QFt),e(Q8,WFt),e(Ee,UFt),e(Ee,W8),e(W8,TRe),e(TRe,HFt),e(W8,JFt),e(W8,Vie),e(Vie,YFt),e(W8,ZFt),e(Ee,KFt),e(Ee,U8),e(U8,MRe),e(MRe,eTt),e(U8,oTt),e(U8,Xie),e(Xie,rTt),e(U8,tTt),e(Ee,aTt),e(Ee,H8),e(H8,ERe),e(ERe,nTt),e(H8,sTt),e(H8,zie),e(zie,lTt),e(H8,iTt),e(Ee,dTt),e(Ee,J8),e(J8,CRe),e(CRe,mTt),e(J8,cTt),e(J8,Qie),e(Qie,fTt),e(J8,gTt),e(Ee,hTt),e(Ee,Y8),e(Y8,wRe),e(wRe,uTt),e(Y8,pTt),e(Y8,Wie),e(Wie,_Tt),e(Y8,bTt),e(Ee,vTt),e(Ee,Z8),e(Z8,ARe),e(ARe,FTt),e(Z8,TTt),e(Z8,Uie),e(Uie,MTt),e(Z8,ETt),e(Ee,CTt),e(Ee,K8),e(K8,LRe),e(LRe,wTt),e(K8,ATt),e(K8,Hie),e(Hie,LTt),e(K8,yTt),e(Ee,xTt),e(Ee,eL),e(eL,yRe),e(yRe,$Tt),e(eL,kTt),e(eL,Jie),e(Jie,STt),e(eL,RTt),e(Ee,PTt),e(Ee,oL),e(oL,xRe),e(xRe,BTt),e(oL,ITt),e(oL,Yie),e(Yie,NTt),e(oL,qTt),e(Ee,jTt),e(Ee,rL),e(rL,$Re),e($Re,DTt),e(rL,GTt),e(rL,Zie),e(Zie,OTt),e(rL,VTt),e(Ee,XTt),e(Ee,tL),e(tL,kRe),e(kRe,zTt),e(tL,QTt),e(tL,Kie),e(Kie,WTt),e(tL,UTt),e(at,HTt),M(aL,at,null),b(c,Lso,_),b(c,pf,_),e(pf,nL),e(nL,SRe),M(_B,SRe,null),e(pf,JTt),e(pf,RRe),e(RRe,YTt),b(c,yso,_),b(c,xr,_),M(bB,xr,null),e(xr,ZTt),e(xr,_f),e(_f,KTt),e(_f,ede),e(ede,eMt),e(_f,oMt),e(_f,ode),e(ode,rMt),e(_f,tMt),e(xr,aMt),e(xr,vB),e(vB,nMt),e(vB,PRe),e(PRe,sMt),e(vB,lMt),e(xr,iMt),e(xr,pa),M(FB,pa,null),e(pa,dMt),e(pa,BRe),e(BRe,mMt),e(pa,cMt),e(pa,bf),e(bf,fMt),e(bf,IRe),e(IRe,gMt),e(bf,hMt),e(bf,rde),e(rde,uMt),e(bf,pMt),e(pa,_Mt),M(sL,pa,null),e(xr,bMt),e(xr,nt),M(TB,nt,null),e(nt,vMt),e(nt,NRe),e(NRe,FMt),e(nt,TMt),e(nt,es),e(es,MMt),e(es,qRe),e(qRe,EMt),e(es,CMt),e(es,jRe),e(jRe,wMt),e(es,AMt),e(es,DRe),e(DRe,LMt),e(es,yMt),e(nt,xMt),e(nt,ke),e(ke,lL),e(lL,GRe),e(GRe,$Mt),e(lL,kMt),e(lL,tde),e(tde,SMt),e(lL,RMt),e(ke,PMt),e(ke,iL),e(iL,ORe),e(ORe,BMt),e(iL,IMt),e(iL,ade),e(ade,NMt),e(iL,qMt),e(ke,jMt),e(ke,dL),e(dL,VRe),e(VRe,DMt),e(dL,GMt),e(dL,nde),e(nde,OMt),e(dL,VMt),e(ke,XMt),e(ke,mL),e(mL,XRe),e(XRe,zMt),e(mL,QMt),e(mL,sde),e(sde,WMt),e(mL,UMt),e(ke,HMt),e(ke,cL),e(cL,zRe),e(zRe,JMt),e(cL,YMt),e(cL,lde),e(lde,ZMt),e(cL,KMt),e(ke,eEt),e(ke,fL),e(fL,QRe),e(QRe,oEt),e(fL,rEt),e(fL,ide),e(ide,tEt),e(fL,aEt),e(ke,nEt),e(ke,gL),e(gL,WRe),e(WRe,sEt),e(gL,lEt),e(gL,dde),e(dde,iEt),e(gL,dEt),e(ke,mEt),e(ke,hL),e(hL,URe),e(URe,cEt),e(hL,fEt),e(hL,mde),e(mde,gEt),e(hL,hEt),e(ke,uEt),e(ke,uL),e(uL,HRe),e(HRe,pEt),e(uL,_Et),e(uL,cde),e(cde,bEt),e(uL,vEt),e(ke,FEt),e(ke,pL),e(pL,JRe),e(JRe,TEt),e(pL,MEt),e(pL,fde),e(fde,EEt),e(pL,CEt),e(nt,wEt),M(_L,nt,null),b(c,xso,_),b(c,vf,_),e(vf,bL),e(bL,YRe),M(MB,YRe,null),e(vf,AEt),e(vf,ZRe),e(ZRe,LEt),b(c,$so,_),b(c,$r,_),M(EB,$r,null),e($r,yEt),e($r,Ff),e(Ff,xEt),e(Ff,gde),e(gde,$Et),e(Ff,kEt),e(Ff,hde),e(hde,SEt),e(Ff,REt),e($r,PEt),e($r,CB),e(CB,BEt),e(CB,KRe),e(KRe,IEt),e(CB,NEt),e($r,qEt),e($r,_a),M(wB,_a,null),e(_a,jEt),e(_a,ePe),e(ePe,DEt),e(_a,GEt),e(_a,Tf),e(Tf,OEt),e(Tf,oPe),e(oPe,VEt),e(Tf,XEt),e(Tf,ude),e(ude,zEt),e(Tf,QEt),e(_a,WEt),M(vL,_a,null),e($r,UEt),e($r,st),M(AB,st,null),e(st,HEt),e(st,rPe),e(rPe,JEt),e(st,YEt),e(st,os),e(os,ZEt),e(os,tPe),e(tPe,KEt),e(os,e4t),e(os,aPe),e(aPe,o4t),e(os,r4t),e(os,nPe),e(nPe,t4t),e(os,a4t),e(st,n4t),e(st,Se),e(Se,FL),e(FL,sPe),e(sPe,s4t),e(FL,l4t),e(FL,pde),e(pde,i4t),e(FL,d4t),e(Se,m4t),e(Se,TL),e(TL,lPe),e(lPe,c4t),e(TL,f4t),e(TL,_de),e(_de,g4t),e(TL,h4t),e(Se,u4t),e(Se,ML),e(ML,iPe),e(iPe,p4t),e(ML,_4t),e(ML,bde),e(bde,b4t),e(ML,v4t),e(Se,F4t),e(Se,EL),e(EL,dPe),e(dPe,T4t),e(EL,M4t),e(EL,vde),e(vde,E4t),e(EL,C4t),e(Se,w4t),e(Se,CL),e(CL,mPe),e(mPe,A4t),e(CL,L4t),e(CL,Fde),e(Fde,y4t),e(CL,x4t),e(Se,$4t),e(Se,wL),e(wL,cPe),e(cPe,k4t),e(wL,S4t),e(wL,Tde),e(Tde,R4t),e(wL,P4t),e(Se,B4t),e(Se,AL),e(AL,fPe),e(fPe,I4t),e(AL,N4t),e(AL,Mde),e(Mde,q4t),e(AL,j4t),e(Se,D4t),e(Se,LL),e(LL,gPe),e(gPe,G4t),e(LL,O4t),e(LL,Ede),e(Ede,V4t),e(LL,X4t),e(Se,z4t),e(Se,yL),e(yL,hPe),e(hPe,Q4t),e(yL,W4t),e(yL,Cde),e(Cde,U4t),e(yL,H4t),e(Se,J4t),e(Se,xL),e(xL,uPe),e(uPe,Y4t),e(xL,Z4t),e(xL,wde),e(wde,K4t),e(xL,eCt),e(st,oCt),M($L,st,null),b(c,kso,_),b(c,Mf,_),e(Mf,kL),e(kL,pPe),M(LB,pPe,null),e(Mf,rCt),e(Mf,_Pe),e(_Pe,tCt),b(c,Sso,_),b(c,kr,_),M(yB,kr,null),e(kr,aCt),e(kr,Ef),e(Ef,nCt),e(Ef,Ade),e(Ade,sCt),e(Ef,lCt),e(Ef,Lde),e(Lde,iCt),e(Ef,dCt),e(kr,mCt),e(kr,xB),e(xB,cCt),e(xB,bPe),e(bPe,fCt),e(xB,gCt),e(kr,hCt),e(kr,ba),M($B,ba,null),e(ba,uCt),e(ba,vPe),e(vPe,pCt),e(ba,_Ct),e(ba,Cf),e(Cf,bCt),e(Cf,FPe),e(FPe,vCt),e(Cf,FCt),e(Cf,yde),e(yde,TCt),e(Cf,MCt),e(ba,ECt),M(SL,ba,null),e(kr,CCt),e(kr,lt),M(kB,lt,null),e(lt,wCt),e(lt,TPe),e(TPe,ACt),e(lt,LCt),e(lt,rs),e(rs,yCt),e(rs,MPe),e(MPe,xCt),e(rs,$Ct),e(rs,EPe),e(EPe,kCt),e(rs,SCt),e(rs,CPe),e(CPe,RCt),e(rs,PCt),e(lt,BCt),e(lt,Re),e(Re,RL),e(RL,wPe),e(wPe,ICt),e(RL,NCt),e(RL,xde),e(xde,qCt),e(RL,jCt),e(Re,DCt),e(Re,PL),e(PL,APe),e(APe,GCt),e(PL,OCt),e(PL,$de),e($de,VCt),e(PL,XCt),e(Re,zCt),e(Re,BL),e(BL,LPe),e(LPe,QCt),e(BL,WCt),e(BL,kde),e(kde,UCt),e(BL,HCt),e(Re,JCt),e(Re,IL),e(IL,yPe),e(yPe,YCt),e(IL,ZCt),e(IL,Sde),e(Sde,KCt),e(IL,e3t),e(Re,o3t),e(Re,NL),e(NL,xPe),e(xPe,r3t),e(NL,t3t),e(NL,Rde),e(Rde,a3t),e(NL,n3t),e(Re,s3t),e(Re,qL),e(qL,$Pe),e($Pe,l3t),e(qL,i3t),e(qL,Pde),e(Pde,d3t),e(qL,m3t),e(Re,c3t),e(Re,jL),e(jL,kPe),e(kPe,f3t),e(jL,g3t),e(jL,Bde),e(Bde,h3t),e(jL,u3t),e(Re,p3t),e(Re,DL),e(DL,SPe),e(SPe,_3t),e(DL,b3t),e(DL,Ide),e(Ide,v3t),e(DL,F3t),e(Re,T3t),e(Re,GL),e(GL,RPe),e(RPe,M3t),e(GL,E3t),e(GL,Nde),e(Nde,C3t),e(GL,w3t),e(Re,A3t),e(Re,OL),e(OL,PPe),e(PPe,L3t),e(OL,y3t),e(OL,qde),e(qde,x3t),e(OL,$3t),e(lt,k3t),M(VL,lt,null),b(c,Rso,_),b(c,wf,_),e(wf,XL),e(XL,BPe),M(SB,BPe,null),e(wf,S3t),e(wf,IPe),e(IPe,R3t),b(c,Pso,_),b(c,Sr,_),M(RB,Sr,null),e(Sr,P3t),e(Sr,Af),e(Af,B3t),e(Af,jde),e(jde,I3t),e(Af,N3t),e(Af,Dde),e(Dde,q3t),e(Af,j3t),e(Sr,D3t),e(Sr,PB),e(PB,G3t),e(PB,NPe),e(NPe,O3t),e(PB,V3t),e(Sr,X3t),e(Sr,va),M(BB,va,null),e(va,z3t),e(va,qPe),e(qPe,Q3t),e(va,W3t),e(va,Lf),e(Lf,U3t),e(Lf,jPe),e(jPe,H3t),e(Lf,J3t),e(Lf,Gde),e(Gde,Y3t),e(Lf,Z3t),e(va,K3t),M(zL,va,null),e(Sr,e5t),e(Sr,it),M(IB,it,null),e(it,o5t),e(it,DPe),e(DPe,r5t),e(it,t5t),e(it,ts),e(ts,a5t),e(ts,GPe),e(GPe,n5t),e(ts,s5t),e(ts,OPe),e(OPe,l5t),e(ts,i5t),e(ts,VPe),e(VPe,d5t),e(ts,m5t),e(it,c5t),e(it,Pe),e(Pe,QL),e(QL,XPe),e(XPe,f5t),e(QL,g5t),e(QL,Ode),e(Ode,h5t),e(QL,u5t),e(Pe,p5t),e(Pe,WL),e(WL,zPe),e(zPe,_5t),e(WL,b5t),e(WL,Vde),e(Vde,v5t),e(WL,F5t),e(Pe,T5t),e(Pe,UL),e(UL,QPe),e(QPe,M5t),e(UL,E5t),e(UL,Xde),e(Xde,C5t),e(UL,w5t),e(Pe,A5t),e(Pe,HL),e(HL,WPe),e(WPe,L5t),e(HL,y5t),e(HL,zde),e(zde,x5t),e(HL,$5t),e(Pe,k5t),e(Pe,JL),e(JL,UPe),e(UPe,S5t),e(JL,R5t),e(JL,Qde),e(Qde,P5t),e(JL,B5t),e(Pe,I5t),e(Pe,YL),e(YL,HPe),e(HPe,N5t),e(YL,q5t),e(YL,Wde),e(Wde,j5t),e(YL,D5t),e(Pe,G5t),e(Pe,ZL),e(ZL,JPe),e(JPe,O5t),e(ZL,V5t),e(ZL,Ude),e(Ude,X5t),e(ZL,z5t),e(Pe,Q5t),e(Pe,KL),e(KL,YPe),e(YPe,W5t),e(KL,U5t),e(KL,Hde),e(Hde,H5t),e(KL,J5t),e(Pe,Y5t),e(Pe,ey),e(ey,ZPe),e(ZPe,Z5t),e(ey,K5t),e(ey,Jde),e(Jde,e0t),e(ey,o0t),e(Pe,r0t),e(Pe,oy),e(oy,KPe),e(KPe,t0t),e(oy,a0t),e(oy,Yde),e(Yde,n0t),e(oy,s0t),e(it,l0t),M(ry,it,null),b(c,Bso,_),b(c,yf,_),e(yf,ty),e(ty,eBe),M(NB,eBe,null),e(yf,i0t),e(yf,oBe),e(oBe,d0t),b(c,Iso,_),b(c,Rr,_),M(qB,Rr,null),e(Rr,m0t),e(Rr,xf),e(xf,c0t),e(xf,Zde),e(Zde,f0t),e(xf,g0t),e(xf,Kde),e(Kde,h0t),e(xf,u0t),e(Rr,p0t),e(Rr,jB),e(jB,_0t),e(jB,rBe),e(rBe,b0t),e(jB,v0t),e(Rr,F0t),e(Rr,Fa),M(DB,Fa,null),e(Fa,T0t),e(Fa,tBe),e(tBe,M0t),e(Fa,E0t),e(Fa,$f),e($f,C0t),e($f,aBe),e(aBe,w0t),e($f,A0t),e($f,eme),e(eme,L0t),e($f,y0t),e(Fa,x0t),M(ay,Fa,null),e(Rr,$0t),e(Rr,dt),M(GB,dt,null),e(dt,k0t),e(dt,nBe),e(nBe,S0t),e(dt,R0t),e(dt,as),e(as,P0t),e(as,sBe),e(sBe,B0t),e(as,I0t),e(as,lBe),e(lBe,N0t),e(as,q0t),e(as,iBe),e(iBe,j0t),e(as,D0t),e(dt,G0t),e(dt,ze),e(ze,ny),e(ny,dBe),e(dBe,O0t),e(ny,V0t),e(ny,ome),e(ome,X0t),e(ny,z0t),e(ze,Q0t),e(ze,sy),e(sy,mBe),e(mBe,W0t),e(sy,U0t),e(sy,rme),e(rme,H0t),e(sy,J0t),e(ze,Y0t),e(ze,ly),e(ly,cBe),e(cBe,Z0t),e(ly,K0t),e(ly,tme),e(tme,ewt),e(ly,owt),e(ze,rwt),e(ze,iy),e(iy,fBe),e(fBe,twt),e(iy,awt),e(iy,ame),e(ame,nwt),e(iy,swt),e(ze,lwt),e(ze,dy),e(dy,gBe),e(gBe,iwt),e(dy,dwt),e(dy,nme),e(nme,mwt),e(dy,cwt),e(ze,fwt),e(ze,my),e(my,hBe),e(hBe,gwt),e(my,hwt),e(my,sme),e(sme,uwt),e(my,pwt),e(ze,_wt),e(ze,cy),e(cy,uBe),e(uBe,bwt),e(cy,vwt),e(cy,lme),e(lme,Fwt),e(cy,Twt),e(ze,Mwt),e(ze,fy),e(fy,pBe),e(pBe,Ewt),e(fy,Cwt),e(fy,ime),e(ime,wwt),e(fy,Awt),e(dt,Lwt),M(gy,dt,null),b(c,Nso,_),b(c,kf,_),e(kf,hy),e(hy,_Be),M(OB,_Be,null),e(kf,ywt),e(kf,bBe),e(bBe,xwt),b(c,qso,_),b(c,Pr,_),M(VB,Pr,null),e(Pr,$wt),e(Pr,Sf),e(Sf,kwt),e(Sf,dme),e(dme,Swt),e(Sf,Rwt),e(Sf,mme),e(mme,Pwt),e(Sf,Bwt),e(Pr,Iwt),e(Pr,XB),e(XB,Nwt),e(XB,vBe),e(vBe,qwt),e(XB,jwt),e(Pr,Dwt),e(Pr,Ta),M(zB,Ta,null),e(Ta,Gwt),e(Ta,FBe),e(FBe,Owt),e(Ta,Vwt),e(Ta,Rf),e(Rf,Xwt),e(Rf,TBe),e(TBe,zwt),e(Rf,Qwt),e(Rf,cme),e(cme,Wwt),e(Rf,Uwt),e(Ta,Hwt),M(uy,Ta,null),e(Pr,Jwt),e(Pr,mt),M(QB,mt,null),e(mt,Ywt),e(mt,MBe),e(MBe,Zwt),e(mt,Kwt),e(mt,ns),e(ns,eAt),e(ns,EBe),e(EBe,oAt),e(ns,rAt),e(ns,CBe),e(CBe,tAt),e(ns,aAt),e(ns,wBe),e(wBe,nAt),e(ns,sAt),e(mt,lAt),e(mt,Qe),e(Qe,py),e(py,ABe),e(ABe,iAt),e(py,dAt),e(py,fme),e(fme,mAt),e(py,cAt),e(Qe,fAt),e(Qe,_y),e(_y,LBe),e(LBe,gAt),e(_y,hAt),e(_y,gme),e(gme,uAt),e(_y,pAt),e(Qe,_At),e(Qe,by),e(by,yBe),e(yBe,bAt),e(by,vAt),e(by,hme),e(hme,FAt),e(by,TAt),e(Qe,MAt),e(Qe,vy),e(vy,xBe),e(xBe,EAt),e(vy,CAt),e(vy,ume),e(ume,wAt),e(vy,AAt),e(Qe,LAt),e(Qe,Fy),e(Fy,$Be),e($Be,yAt),e(Fy,xAt),e(Fy,pme),e(pme,$At),e(Fy,kAt),e(Qe,SAt),e(Qe,Ty),e(Ty,kBe),e(kBe,RAt),e(Ty,PAt),e(Ty,_me),e(_me,BAt),e(Ty,IAt),e(Qe,NAt),e(Qe,My),e(My,SBe),e(SBe,qAt),e(My,jAt),e(My,bme),e(bme,DAt),e(My,GAt),e(Qe,OAt),e(Qe,Ey),e(Ey,RBe),e(RBe,VAt),e(Ey,XAt),e(Ey,vme),e(vme,zAt),e(Ey,QAt),e(mt,WAt),M(Cy,mt,null),b(c,jso,_),b(c,Pf,_),e(Pf,wy),e(wy,PBe),M(WB,PBe,null),e(Pf,UAt),e(Pf,BBe),e(BBe,HAt),b(c,Dso,_),b(c,Br,_),M(UB,Br,null),e(Br,JAt),e(Br,Bf),e(Bf,YAt),e(Bf,Fme),e(Fme,ZAt),e(Bf,KAt),e(Bf,Tme),e(Tme,e6t),e(Bf,o6t),e(Br,r6t),e(Br,HB),e(HB,t6t),e(HB,IBe),e(IBe,a6t),e(HB,n6t),e(Br,s6t),e(Br,Ma),M(JB,Ma,null),e(Ma,l6t),e(Ma,NBe),e(NBe,i6t),e(Ma,d6t),e(Ma,If),e(If,m6t),e(If,qBe),e(qBe,c6t),e(If,f6t),e(If,Mme),e(Mme,g6t),e(If,h6t),e(Ma,u6t),M(Ay,Ma,null),e(Br,p6t),e(Br,ct),M(YB,ct,null),e(ct,_6t),e(ct,jBe),e(jBe,b6t),e(ct,v6t),e(ct,ss),e(ss,F6t),e(ss,DBe),e(DBe,T6t),e(ss,M6t),e(ss,GBe),e(GBe,E6t),e(ss,C6t),e(ss,OBe),e(OBe,w6t),e(ss,A6t),e(ct,L6t),e(ct,VBe),e(VBe,Ly),e(Ly,XBe),e(XBe,y6t),e(Ly,x6t),e(Ly,Eme),e(Eme,$6t),e(Ly,k6t),e(ct,S6t),M(yy,ct,null),b(c,Gso,_),b(c,Nf,_),e(Nf,xy),e(xy,zBe),M(ZB,zBe,null),e(Nf,R6t),e(Nf,QBe),e(QBe,P6t),b(c,Oso,_),b(c,Ir,_),M(KB,Ir,null),e(Ir,B6t),e(Ir,qf),e(qf,I6t),e(qf,Cme),e(Cme,N6t),e(qf,q6t),e(qf,wme),e(wme,j6t),e(qf,D6t),e(Ir,G6t),e(Ir,eI),e(eI,O6t),e(eI,WBe),e(WBe,V6t),e(eI,X6t),e(Ir,z6t),e(Ir,Ea),M(oI,Ea,null),e(Ea,Q6t),e(Ea,UBe),e(UBe,W6t),e(Ea,U6t),e(Ea,jf),e(jf,H6t),e(jf,HBe),e(HBe,J6t),e(jf,Y6t),e(jf,Ame),e(Ame,Z6t),e(jf,K6t),e(Ea,e7t),M($y,Ea,null),e(Ir,o7t),e(Ir,ft),M(rI,ft,null),e(ft,r7t),e(ft,JBe),e(JBe,t7t),e(ft,a7t),e(ft,ls),e(ls,n7t),e(ls,YBe),e(YBe,s7t),e(ls,l7t),e(ls,ZBe),e(ZBe,i7t),e(ls,d7t),e(ls,KBe),e(KBe,m7t),e(ls,c7t),e(ft,f7t),e(ft,tI),e(tI,ky),e(ky,eIe),e(eIe,g7t),e(ky,h7t),e(ky,Lme),e(Lme,u7t),e(ky,p7t),e(tI,_7t),e(tI,Sy),e(Sy,oIe),e(oIe,b7t),e(Sy,v7t),e(Sy,yme),e(yme,F7t),e(Sy,T7t),e(ft,M7t),M(Ry,ft,null),b(c,Vso,_),b(c,Df,_),e(Df,Py),e(Py,rIe),M(aI,rIe,null),e(Df,E7t),e(Df,tIe),e(tIe,C7t),b(c,Xso,_),b(c,Nr,_),M(nI,Nr,null),e(Nr,w7t),e(Nr,Gf),e(Gf,A7t),e(Gf,xme),e(xme,L7t),e(Gf,y7t),e(Gf,$me),e($me,x7t),e(Gf,$7t),e(Nr,k7t),e(Nr,sI),e(sI,S7t),e(sI,aIe),e(aIe,R7t),e(sI,P7t),e(Nr,B7t),e(Nr,Ca),M(lI,Ca,null),e(Ca,I7t),e(Ca,nIe),e(nIe,N7t),e(Ca,q7t),e(Ca,Of),e(Of,j7t),e(Of,sIe),e(sIe,D7t),e(Of,G7t),e(Of,kme),e(kme,O7t),e(Of,V7t),e(Ca,X7t),M(By,Ca,null),e(Nr,z7t),e(Nr,gt),M(iI,gt,null),e(gt,Q7t),e(gt,lIe),e(lIe,W7t),e(gt,U7t),e(gt,is),e(is,H7t),e(is,iIe),e(iIe,J7t),e(is,Y7t),e(is,dIe),e(dIe,Z7t),e(is,K7t),e(is,mIe),e(mIe,e8t),e(is,o8t),e(gt,r8t),e(gt,cIe),e(cIe,Iy),e(Iy,fIe),e(fIe,t8t),e(Iy,a8t),e(Iy,Sme),e(Sme,n8t),e(Iy,s8t),e(gt,l8t),M(Ny,gt,null),zso=!0},p(c,[_]){const dI={};_&2&&(dI.$$scope={dirty:_,ctx:c}),Yf.$set(dI);const gIe={};_&2&&(gIe.$$scope={dirty:_,ctx:c}),yu.$set(gIe);const hIe={};_&2&&(hIe.$$scope={dirty:_,ctx:c}),gp.$set(hIe);const uIe={};_&2&&(uIe.$$scope={dirty:_,ctx:c}),l_.$set(uIe);const mI={};_&2&&(mI.$$scope={dirty:_,ctx:c}),i_.$set(mI);const pIe={};_&2&&(pIe.$$scope={dirty:_,ctx:c}),P_.$set(pIe);const ds={};_&2&&(ds.$$scope={dirty:_,ctx:c}),B_.$set(ds);const _Ie={};_&2&&(_Ie.$$scope={dirty:_,ctx:c}),q_.$set(_Ie);const bIe={};_&2&&(bIe.$$scope={dirty:_,ctx:c}),ib.$set(bIe);const vIe={};_&2&&(vIe.$$scope={dirty:_,ctx:c}),mb.$set(vIe);const cI={};_&2&&(cI.$$scope={dirty:_,ctx:c}),lv.$set(cI);const FIe={};_&2&&(FIe.$$scope={dirty:_,ctx:c}),dv.$set(FIe);const fI={};_&2&&(fI.$$scope={dirty:_,ctx:c}),eF.$set(fI);const TIe={};_&2&&(TIe.$$scope={dirty:_,ctx:c}),rF.$set(TIe);const gI={};_&2&&(gI.$$scope={dirty:_,ctx:c}),sF.$set(gI);const MIe={};_&2&&(MIe.$$scope={dirty:_,ctx:c}),iF.$set(MIe);const EIe={};_&2&&(EIe.$$scope={dirty:_,ctx:c}),JF.$set(EIe);const CIe={};_&2&&(CIe.$$scope={dirty:_,ctx:c}),ZF.$set(CIe);const Vf={};_&2&&(Vf.$$scope={dirty:_,ctx:c}),FT.$set(Vf);const wIe={};_&2&&(wIe.$$scope={dirty:_,ctx:c}),MT.$set(wIe);const AIe={};_&2&&(AIe.$$scope={dirty:_,ctx:c}),LM.$set(AIe);const LIe={};_&2&&(LIe.$$scope={dirty:_,ctx:c}),xM.$set(LIe);const hI={};_&2&&(hI.$$scope={dirty:_,ctx:c}),mE.$set(hI);const yIe={};_&2&&(yIe.$$scope={dirty:_,ctx:c}),fE.$set(yIe);const xIe={};_&2&&(xIe.$$scope={dirty:_,ctx:c}),TE.$set(xIe);const $Ie={};_&2&&($Ie.$$scope={dirty:_,ctx:c}),EE.$set($Ie);const vt={};_&2&&(vt.$$scope={dirty:_,ctx:c}),g4.$set(vt);const uI={};_&2&&(uI.$$scope={dirty:_,ctx:c}),u4.$set(uI);const kIe={};_&2&&(kIe.$$scope={dirty:_,ctx:c}),fC.$set(kIe);const pI={};_&2&&(pI.$$scope={dirty:_,ctx:c}),hC.$set(pI);const SIe={};_&2&&(SIe.$$scope={dirty:_,ctx:c}),_C.$set(SIe);const Ft={};_&2&&(Ft.$$scope={dirty:_,ctx:c}),vC.$set(Ft);const RIe={};_&2&&(RIe.$$scope={dirty:_,ctx:c}),CC.$set(RIe);const Xf={};_&2&&(Xf.$$scope={dirty:_,ctx:c}),AC.$set(Xf);const PIe={};_&2&&(PIe.$$scope={dirty:_,ctx:c}),VC.$set(PIe);const BIe={};_&2&&(BIe.$$scope={dirty:_,ctx:c}),zC.$set(BIe);const L={};_&2&&(L.$$scope={dirty:_,ctx:c}),UC.$set(L);const qy={};_&2&&(qy.$$scope={dirty:_,ctx:c}),JC.$set(qy);const IIe={};_&2&&(IIe.$$scope={dirty:_,ctx:c}),KC.$set(IIe);const NIe={};_&2&&(NIe.$$scope={dirty:_,ctx:c}),o3.$set(NIe);const jy={};_&2&&(jy.$$scope={dirty:_,ctx:c}),a3.$set(jy);const qIe={};_&2&&(qIe.$$scope={dirty:_,ctx:c}),s3.$set(qIe);const jIe={};_&2&&(jIe.$$scope={dirty:_,ctx:c}),_3.$set(jIe);const Dy={};_&2&&(Dy.$$scope={dirty:_,ctx:c}),v3.$set(Dy);const DIe={};_&2&&(DIe.$$scope={dirty:_,ctx:c}),A3.$set(DIe);const GIe={};_&2&&(GIe.$$scope={dirty:_,ctx:c}),y3.$set(GIe);const Gy={};_&2&&(Gy.$$scope={dirty:_,ctx:c}),D3.$set(Gy);const OIe={};_&2&&(OIe.$$scope={dirty:_,ctx:c}),O3.$set(OIe);const VIe={};_&2&&(VIe.$$scope={dirty:_,ctx:c}),W3.$set(VIe);const Oy={};_&2&&(Oy.$$scope={dirty:_,ctx:c}),H3.$set(Oy);const XIe={};_&2&&(XIe.$$scope={dirty:_,ctx:c}),r5.$set(XIe);const zIe={};_&2&&(zIe.$$scope={dirty:_,ctx:c}),a5.$set(zIe);const Vy={};_&2&&(Vy.$$scope={dirty:_,ctx:c}),m5.$set(Vy);const QIe={};_&2&&(QIe.$$scope={dirty:_,ctx:c}),f5.$set(QIe);const WIe={};_&2&&(WIe.$$scope={dirty:_,ctx:c}),v5.$set(WIe);const Xy={};_&2&&(Xy.$$scope={dirty:_,ctx:c}),T5.$set(Xy);const UIe={};_&2&&(UIe.$$scope={dirty:_,ctx:c}),C5.$set(UIe);const HIe={};_&2&&(HIe.$$scope={dirty:_,ctx:c}),A5.$set(HIe);const zy={};_&2&&(zy.$$scope={dirty:_,ctx:c}),R5.$set(zy);const JIe={};_&2&&(JIe.$$scope={dirty:_,ctx:c}),B5.$set(JIe);const YIe={};_&2&&(YIe.$$scope={dirty:_,ctx:c}),q5.$set(YIe);const Qy={};_&2&&(Qy.$$scope={dirty:_,ctx:c}),D5.$set(Qy);const ZIe={};_&2&&(ZIe.$$scope={dirty:_,ctx:c}),V5.$set(ZIe);const KIe={};_&2&&(KIe.$$scope={dirty:_,ctx:c}),z5.$set(KIe);const Wy={};_&2&&(Wy.$$scope={dirty:_,ctx:c}),H0.$set(Wy);const eNe={};_&2&&(eNe.$$scope={dirty:_,ctx:c}),Y0.$set(eNe);const oNe={};_&2&&(oNe.$$scope={dirty:_,ctx:c}),Tw.$set(oNe);const Uy={};_&2&&(Uy.$$scope={dirty:_,ctx:c}),Ew.$set(Uy);const rNe={};_&2&&(rNe.$$scope={dirty:_,ctx:c}),qw.$set(rNe);const tNe={};_&2&&(tNe.$$scope={dirty:_,ctx:c}),Dw.$set(tNe);const Hy={};_&2&&(Hy.$$scope={dirty:_,ctx:c}),Jw.$set(Hy);const aNe={};_&2&&(aNe.$$scope={dirty:_,ctx:c}),Zw.$set(aNe);const nNe={};_&2&&(nNe.$$scope={dirty:_,ctx:c}),rA.$set(nNe);const Jy={};_&2&&(Jy.$$scope={dirty:_,ctx:c}),aA.$set(Jy);const sNe={};_&2&&(sNe.$$scope={dirty:_,ctx:c}),AA.$set(sNe);const lNe={};_&2&&(lNe.$$scope={dirty:_,ctx:c}),yA.$set(lNe);const Yy={};_&2&&(Yy.$$scope={dirty:_,ctx:c}),jA.$set(Yy);const iNe={};_&2&&(iNe.$$scope={dirty:_,ctx:c}),GA.$set(iNe);const dNe={};_&2&&(dNe.$$scope={dirty:_,ctx:c}),p6.$set(dNe);const Zy={};_&2&&(Zy.$$scope={dirty:_,ctx:c}),b6.$set(Zy);const mNe={};_&2&&(mNe.$$scope={dirty:_,ctx:c}),I6.$set(mNe);const cNe={};_&2&&(cNe.$$scope={dirty:_,ctx:c}),q6.$set(cNe);const Ky={};_&2&&(Ky.$$scope={dirty:_,ctx:c}),G6.$set(Ky);const fNe={};_&2&&(fNe.$$scope={dirty:_,ctx:c}),V6.$set(fNe);const gNe={};_&2&&(gNe.$$scope={dirty:_,ctx:c}),z6.$set(gNe);const e9={};_&2&&(e9.$$scope={dirty:_,ctx:c}),W6.$set(e9);const hNe={};_&2&&(hNe.$$scope={dirty:_,ctx:c}),H6.$set(hNe);const uNe={};_&2&&(uNe.$$scope={dirty:_,ctx:c}),Y6.$set(uNe);const o9={};_&2&&(o9.$$scope={dirty:_,ctx:c}),F7.$set(o9);const pNe={};_&2&&(pNe.$$scope={dirty:_,ctx:c}),M7.$set(pNe);const _Ne={};_&2&&(_Ne.$$scope={dirty:_,ctx:c}),X7.$set(_Ne);const r9={};_&2&&(r9.$$scope={dirty:_,ctx:c}),Q7.$set(r9);const bNe={};_&2&&(bNe.$$scope={dirty:_,ctx:c}),U7.$set(bNe);const vNe={};_&2&&(vNe.$$scope={dirty:_,ctx:c}),J7.$set(vNe);const t9={};_&2&&(t9.$$scope={dirty:_,ctx:c}),K7.$set(t9);const FNe={};_&2&&(FNe.$$scope={dirty:_,ctx:c}),o8.$set(FNe);const TNe={};_&2&&(TNe.$$scope={dirty:_,ctx:c}),x8.$set(TNe);const a9={};_&2&&(a9.$$scope={dirty:_,ctx:c}),k8.$set(a9);const MNe={};_&2&&(MNe.$$scope={dirty:_,ctx:c}),O8.$set(MNe);const ENe={};_&2&&(ENe.$$scope={dirty:_,ctx:c}),X8.$set(ENe);const n9={};_&2&&(n9.$$scope={dirty:_,ctx:c}),aL.$set(n9);const CNe={};_&2&&(CNe.$$scope={dirty:_,ctx:c}),sL.$set(CNe);const wNe={};_&2&&(wNe.$$scope={dirty:_,ctx:c}),_L.$set(wNe);const s9={};_&2&&(s9.$$scope={dirty:_,ctx:c}),vL.$set(s9);const ANe={};_&2&&(ANe.$$scope={dirty:_,ctx:c}),$L.$set(ANe);const LNe={};_&2&&(LNe.$$scope={dirty:_,ctx:c}),SL.$set(LNe);const l9={};_&2&&(l9.$$scope={dirty:_,ctx:c}),VL.$set(l9);const yNe={};_&2&&(yNe.$$scope={dirty:_,ctx:c}),zL.$set(yNe);const xNe={};_&2&&(xNe.$$scope={dirty:_,ctx:c}),ry.$set(xNe);const i9={};_&2&&(i9.$$scope={dirty:_,ctx:c}),ay.$set(i9);const $Ne={};_&2&&($Ne.$$scope={dirty:_,ctx:c}),gy.$set($Ne);const kNe={};_&2&&(kNe.$$scope={dirty:_,ctx:c}),uy.$set(kNe);const d9={};_&2&&(d9.$$scope={dirty:_,ctx:c}),Cy.$set(d9);const SNe={};_&2&&(SNe.$$scope={dirty:_,ctx:c}),Ay.$set(SNe);const RNe={};_&2&&(RNe.$$scope={dirty:_,ctx:c}),yy.$set(RNe);const m9={};_&2&&(m9.$$scope={dirty:_,ctx:c}),$y.$set(m9);const PNe={};_&2&&(PNe.$$scope={dirty:_,ctx:c}),Ry.$set(PNe);const BNe={};_&2&&(BNe.$$scope={dirty:_,ctx:c}),By.$set(BNe);const c9={};_&2&&(c9.$$scope={dirty:_,ctx:c}),Ny.$set(c9)},i(c){zso||(E(m.$$.fragment,c),E(on.$$.fragment,c),E(E$.$$.fragment,c),E(C$.$$.fragment,c),E(Yf.$$.fragment,c),E(w$.$$.fragment,c),E(A$.$$.fragment,c),E(x$.$$.fragment,c),E(yu.$$.fragment,c),E($$.$$.fragment,c),E(k$.$$.fragment,c),E(S$.$$.fragment,c),E(B$.$$.fragment,c),E(gp.$$.fragment,c),E(I$.$$.fragment,c),E(N$.$$.fragment,c),E(q$.$$.fragment,c),E(G$.$$.fragment,c),E(l_.$$.fragment,c),E(i_.$$.fragment,c),E(O$.$$.fragment,c),E(V$.$$.fragment,c),E(X$.$$.fragment,c),E(W$.$$.fragment,c),E(P_.$$.fragment,c),E(B_.$$.fragment,c),E(U$.$$.fragment,c),E(H$.$$.fragment,c),E(J$.$$.fragment,c),E(Z$.$$.fragment,c),E(q_.$$.fragment,c),E(K$.$$.fragment,c),E(ib.$$.fragment,c),E(ek.$$.fragment,c),E(ok.$$.fragment,c),E(tk.$$.fragment,c),E(mb.$$.fragment,c),E(ak.$$.fragment,c),E(lv.$$.fragment,c),E(nk.$$.fragment,c),E(sk.$$.fragment,c),E(ik.$$.fragment,c),E(dv.$$.fragment,c),E(dk.$$.fragment,c),E(eF.$$.fragment,c),E(mk.$$.fragment,c),E(ck.$$.fragment,c),E(gk.$$.fragment,c),E(rF.$$.fragment,c),E(hk.$$.fragment,c),E(sF.$$.fragment,c),E(pk.$$.fragment,c),E(_k.$$.fragment,c),E(vk.$$.fragment,c),E(iF.$$.fragment,c),E(Fk.$$.fragment,c),E(JF.$$.fragment,c),E(Tk.$$.fragment,c),E(Mk.$$.fragment,c),E(Ck.$$.fragment,c),E(ZF.$$.fragment,c),E(wk.$$.fragment,c),E(FT.$$.fragment,c),E(Ak.$$.fragment,c),E(Lk.$$.fragment,c),E(xk.$$.fragment,c),E(MT.$$.fragment,c),E($k.$$.fragment,c),E(LM.$$.fragment,c),E(kk.$$.fragment,c),E(Sk.$$.fragment,c),E(Pk.$$.fragment,c),E(xM.$$.fragment,c),E(Bk.$$.fragment,c),E(mE.$$.fragment,c),E(Ik.$$.fragment,c),E(Nk.$$.fragment,c),E(jk.$$.fragment,c),E(fE.$$.fragment,c),E(Dk.$$.fragment,c),E(TE.$$.fragment,c),E(Gk.$$.fragment,c),E(Ok.$$.fragment,c),E(Xk.$$.fragment,c),E(EE.$$.fragment,c),E(zk.$$.fragment,c),E(g4.$$.fragment,c),E(Qk.$$.fragment,c),E(Wk.$$.fragment,c),E(Hk.$$.fragment,c),E(u4.$$.fragment,c),E(Jk.$$.fragment,c),E(fC.$$.fragment,c),E(Yk.$$.fragment,c),E(Zk.$$.fragment,c),E(eS.$$.fragment,c),E(hC.$$.fragment,c),E(oS.$$.fragment,c),E(_C.$$.fragment,c),E(rS.$$.fragment,c),E(tS.$$.fragment,c),E(nS.$$.fragment,c),E(vC.$$.fragment,c),E(sS.$$.fragment,c),E(CC.$$.fragment,c),E(lS.$$.fragment,c),E(iS.$$.fragment,c),E(mS.$$.fragment,c),E(AC.$$.fragment,c),E(cS.$$.fragment,c),E(VC.$$.fragment,c),E(fS.$$.fragment,c),E(gS.$$.fragment,c),E(uS.$$.fragment,c),E(zC.$$.fragment,c),E(pS.$$.fragment,c),E(UC.$$.fragment,c),E(_S.$$.fragment,c),E(bS.$$.fragment,c),E(FS.$$.fragment,c),E(JC.$$.fragment,c),E(TS.$$.fragment,c),E(KC.$$.fragment,c),E(MS.$$.fragment,c),E(ES.$$.fragment,c),E(wS.$$.fragment,c),E(o3.$$.fragment,c),E(AS.$$.fragment,c),E(a3.$$.fragment,c),E(LS.$$.fragment,c),E(yS.$$.fragment,c),E($S.$$.fragment,c),E(s3.$$.fragment,c),E(kS.$$.fragment,c),E(_3.$$.fragment,c),E(SS.$$.fragment,c),E(RS.$$.fragment,c),E(BS.$$.fragment,c),E(v3.$$.fragment,c),E(IS.$$.fragment,c),E(A3.$$.fragment,c),E(NS.$$.fragment,c),E(qS.$$.fragment,c),E(DS.$$.fragment,c),E(y3.$$.fragment,c),E(GS.$$.fragment,c),E(D3.$$.fragment,c),E(OS.$$.fragment,c),E(VS.$$.fragment,c),E(zS.$$.fragment,c),E(O3.$$.fragment,c),E(QS.$$.fragment,c),E(W3.$$.fragment,c),E(WS.$$.fragment,c),E(US.$$.fragment,c),E(JS.$$.fragment,c),E(H3.$$.fragment,c),E(YS.$$.fragment,c),E(r5.$$.fragment,c),E(ZS.$$.fragment,c),E(KS.$$.fragment,c),E(oR.$$.fragment,c),E(a5.$$.fragment,c),E(rR.$$.fragment,c),E(m5.$$.fragment,c),E(tR.$$.fragment,c),E(aR.$$.fragment,c),E(sR.$$.fragment,c),E(f5.$$.fragment,c),E(lR.$$.fragment,c),E(v5.$$.fragment,c),E(iR.$$.fragment,c),E(dR.$$.fragment,c),E(cR.$$.fragment,c),E(T5.$$.fragment,c),E(fR.$$.fragment,c),E(C5.$$.fragment,c),E(gR.$$.fragment,c),E(hR.$$.fragment,c),E(pR.$$.fragment,c),E(A5.$$.fragment,c),E(_R.$$.fragment,c),E(R5.$$.fragment,c),E(bR.$$.fragment,c),E(vR.$$.fragment,c),E(TR.$$.fragment,c),E(B5.$$.fragment,c),E(MR.$$.fragment,c),E(q5.$$.fragment,c),E(ER.$$.fragment,c),E(CR.$$.fragment,c),E(AR.$$.fragment,c),E(D5.$$.fragment,c),E(LR.$$.fragment,c),E(V5.$$.fragment,c),E(yR.$$.fragment,c),E(xR.$$.fragment,c),E(kR.$$.fragment,c),E(z5.$$.fragment,c),E(SR.$$.fragment,c),E(H0.$$.fragment,c),E(RR.$$.fragment,c),E(PR.$$.fragment,c),E(IR.$$.fragment,c),E(Y0.$$.fragment,c),E(NR.$$.fragment,c),E(Tw.$$.fragment,c),E(qR.$$.fragment,c),E(jR.$$.fragment,c),E(GR.$$.fragment,c),E(Ew.$$.fragment,c),E(OR.$$.fragment,c),E(qw.$$.fragment,c),E(VR.$$.fragment,c),E(XR.$$.fragment,c),E(QR.$$.fragment,c),E(Dw.$$.fragment,c),E(WR.$$.fragment,c),E(Jw.$$.fragment,c),E(UR.$$.fragment,c),E(HR.$$.fragment,c),E(YR.$$.fragment,c),E(Zw.$$.fragment,c),E(ZR.$$.fragment,c),E(rA.$$.fragment,c),E(KR.$$.fragment,c),E(eP.$$.fragment,c),E(rP.$$.fragment,c),E(aA.$$.fragment,c),E(tP.$$.fragment,c),E(AA.$$.fragment,c),E(aP.$$.fragment,c),E(nP.$$.fragment,c),E(lP.$$.fragment,c),E(yA.$$.fragment,c),E(iP.$$.fragment,c),E(jA.$$.fragment,c),E(dP.$$.fragment,c),E(mP.$$.fragment,c),E(fP.$$.fragment,c),E(GA.$$.fragment,c),E(gP.$$.fragment,c),E(p6.$$.fragment,c),E(hP.$$.fragment,c),E(uP.$$.fragment,c),E(_P.$$.fragment,c),E(b6.$$.fragment,c),E(bP.$$.fragment,c),E(I6.$$.fragment,c),E(vP.$$.fragment,c),E(FP.$$.fragment,c),E(MP.$$.fragment,c),E(q6.$$.fragment,c),E(EP.$$.fragment,c),E(G6.$$.fragment,c),E(wP.$$.fragment,c),E(AP.$$.fragment,c),E(yP.$$.fragment,c),E(V6.$$.fragment,c),E(xP.$$.fragment,c),E(z6.$$.fragment,c),E($P.$$.fragment,c),E(kP.$$.fragment,c),E(RP.$$.fragment,c),E(W6.$$.fragment,c),E(PP.$$.fragment,c),E(H6.$$.fragment,c),E(BP.$$.fragment,c),E(IP.$$.fragment,c),E(qP.$$.fragment,c),E(Y6.$$.fragment,c),E(jP.$$.fragment,c),E(F7.$$.fragment,c),E(DP.$$.fragment,c),E(GP.$$.fragment,c),E(VP.$$.fragment,c),E(M7.$$.fragment,c),E(XP.$$.fragment,c),E(X7.$$.fragment,c),E(zP.$$.fragment,c),E(QP.$$.fragment,c),E(UP.$$.fragment,c),E(Q7.$$.fragment,c),E(HP.$$.fragment,c),E(U7.$$.fragment,c),E(JP.$$.fragment,c),E(YP.$$.fragment,c),E(KP.$$.fragment,c),E(J7.$$.fragment,c),E(eB.$$.fragment,c),E(K7.$$.fragment,c),E(rB.$$.fragment,c),E(tB.$$.fragment,c),E(nB.$$.fragment,c),E(o8.$$.fragment,c),E(sB.$$.fragment,c),E(x8.$$.fragment,c),E(lB.$$.fragment,c),E(iB.$$.fragment,c),E(mB.$$.fragment,c),E(k8.$$.fragment,c),E(cB.$$.fragment,c),E(O8.$$.fragment,c),E(fB.$$.fragment,c),E(gB.$$.fragment,c),E(uB.$$.fragment,c),E(X8.$$.fragment,c),E(pB.$$.fragment,c),E(aL.$$.fragment,c),E(_B.$$.fragment,c),E(bB.$$.fragment,c),E(FB.$$.fragment,c),E(sL.$$.fragment,c),E(TB.$$.fragment,c),E(_L.$$.fragment,c),E(MB.$$.fragment,c),E(EB.$$.fragment,c),E(wB.$$.fragment,c),E(vL.$$.fragment,c),E(AB.$$.fragment,c),E($L.$$.fragment,c),E(LB.$$.fragment,c),E(yB.$$.fragment,c),E($B.$$.fragment,c),E(SL.$$.fragment,c),E(kB.$$.fragment,c),E(VL.$$.fragment,c),E(SB.$$.fragment,c),E(RB.$$.fragment,c),E(BB.$$.fragment,c),E(zL.$$.fragment,c),E(IB.$$.fragment,c),E(ry.$$.fragment,c),E(NB.$$.fragment,c),E(qB.$$.fragment,c),E(DB.$$.fragment,c),E(ay.$$.fragment,c),E(GB.$$.fragment,c),E(gy.$$.fragment,c),E(OB.$$.fragment,c),E(VB.$$.fragment,c),E(zB.$$.fragment,c),E(uy.$$.fragment,c),E(QB.$$.fragment,c),E(Cy.$$.fragment,c),E(WB.$$.fragment,c),E(UB.$$.fragment,c),E(JB.$$.fragment,c),E(Ay.$$.fragment,c),E(YB.$$.fragment,c),E(yy.$$.fragment,c),E(ZB.$$.fragment,c),E(KB.$$.fragment,c),E(oI.$$.fragment,c),E($y.$$.fragment,c),E(rI.$$.fragment,c),E(Ry.$$.fragment,c),E(aI.$$.fragment,c),E(nI.$$.fragment,c),E(lI.$$.fragment,c),E(By.$$.fragment,c),E(iI.$$.fragment,c),E(Ny.$$.fragment,c),zso=!0)},o(c){C(m.$$.fragment,c),C(on.$$.fragment,c),C(E$.$$.fragment,c),C(C$.$$.fragment,c),C(Yf.$$.fragment,c),C(w$.$$.fragment,c),C(A$.$$.fragment,c),C(x$.$$.fragment,c),C(yu.$$.fragment,c),C($$.$$.fragment,c),C(k$.$$.fragment,c),C(S$.$$.fragment,c),C(B$.$$.fragment,c),C(gp.$$.fragment,c),C(I$.$$.fragment,c),C(N$.$$.fragment,c),C(q$.$$.fragment,c),C(G$.$$.fragment,c),C(l_.$$.fragment,c),C(i_.$$.fragment,c),C(O$.$$.fragment,c),C(V$.$$.fragment,c),C(X$.$$.fragment,c),C(W$.$$.fragment,c),C(P_.$$.fragment,c),C(B_.$$.fragment,c),C(U$.$$.fragment,c),C(H$.$$.fragment,c),C(J$.$$.fragment,c),C(Z$.$$.fragment,c),C(q_.$$.fragment,c),C(K$.$$.fragment,c),C(ib.$$.fragment,c),C(ek.$$.fragment,c),C(ok.$$.fragment,c),C(tk.$$.fragment,c),C(mb.$$.fragment,c),C(ak.$$.fragment,c),C(lv.$$.fragment,c),C(nk.$$.fragment,c),C(sk.$$.fragment,c),C(ik.$$.fragment,c),C(dv.$$.fragment,c),C(dk.$$.fragment,c),C(eF.$$.fragment,c),C(mk.$$.fragment,c),C(ck.$$.fragment,c),C(gk.$$.fragment,c),C(rF.$$.fragment,c),C(hk.$$.fragment,c),C(sF.$$.fragment,c),C(pk.$$.fragment,c),C(_k.$$.fragment,c),C(vk.$$.fragment,c),C(iF.$$.fragment,c),C(Fk.$$.fragment,c),C(JF.$$.fragment,c),C(Tk.$$.fragment,c),C(Mk.$$.fragment,c),C(Ck.$$.fragment,c),C(ZF.$$.fragment,c),C(wk.$$.fragment,c),C(FT.$$.fragment,c),C(Ak.$$.fragment,c),C(Lk.$$.fragment,c),C(xk.$$.fragment,c),C(MT.$$.fragment,c),C($k.$$.fragment,c),C(LM.$$.fragment,c),C(kk.$$.fragment,c),C(Sk.$$.fragment,c),C(Pk.$$.fragment,c),C(xM.$$.fragment,c),C(Bk.$$.fragment,c),C(mE.$$.fragment,c),C(Ik.$$.fragment,c),C(Nk.$$.fragment,c),C(jk.$$.fragment,c),C(fE.$$.fragment,c),C(Dk.$$.fragment,c),C(TE.$$.fragment,c),C(Gk.$$.fragment,c),C(Ok.$$.fragment,c),C(Xk.$$.fragment,c),C(EE.$$.fragment,c),C(zk.$$.fragment,c),C(g4.$$.fragment,c),C(Qk.$$.fragment,c),C(Wk.$$.fragment,c),C(Hk.$$.fragment,c),C(u4.$$.fragment,c),C(Jk.$$.fragment,c),C(fC.$$.fragment,c),C(Yk.$$.fragment,c),C(Zk.$$.fragment,c),C(eS.$$.fragment,c),C(hC.$$.fragment,c),C(oS.$$.fragment,c),C(_C.$$.fragment,c),C(rS.$$.fragment,c),C(tS.$$.fragment,c),C(nS.$$.fragment,c),C(vC.$$.fragment,c),C(sS.$$.fragment,c),C(CC.$$.fragment,c),C(lS.$$.fragment,c),C(iS.$$.fragment,c),C(mS.$$.fragment,c),C(AC.$$.fragment,c),C(cS.$$.fragment,c),C(VC.$$.fragment,c),C(fS.$$.fragment,c),C(gS.$$.fragment,c),C(uS.$$.fragment,c),C(zC.$$.fragment,c),C(pS.$$.fragment,c),C(UC.$$.fragment,c),C(_S.$$.fragment,c),C(bS.$$.fragment,c),C(FS.$$.fragment,c),C(JC.$$.fragment,c),C(TS.$$.fragment,c),C(KC.$$.fragment,c),C(MS.$$.fragment,c),C(ES.$$.fragment,c),C(wS.$$.fragment,c),C(o3.$$.fragment,c),C(AS.$$.fragment,c),C(a3.$$.fragment,c),C(LS.$$.fragment,c),C(yS.$$.fragment,c),C($S.$$.fragment,c),C(s3.$$.fragment,c),C(kS.$$.fragment,c),C(_3.$$.fragment,c),C(SS.$$.fragment,c),C(RS.$$.fragment,c),C(BS.$$.fragment,c),C(v3.$$.fragment,c),C(IS.$$.fragment,c),C(A3.$$.fragment,c),C(NS.$$.fragment,c),C(qS.$$.fragment,c),C(DS.$$.fragment,c),C(y3.$$.fragment,c),C(GS.$$.fragment,c),C(D3.$$.fragment,c),C(OS.$$.fragment,c),C(VS.$$.fragment,c),C(zS.$$.fragment,c),C(O3.$$.fragment,c),C(QS.$$.fragment,c),C(W3.$$.fragment,c),C(WS.$$.fragment,c),C(US.$$.fragment,c),C(JS.$$.fragment,c),C(H3.$$.fragment,c),C(YS.$$.fragment,c),C(r5.$$.fragment,c),C(ZS.$$.fragment,c),C(KS.$$.fragment,c),C(oR.$$.fragment,c),C(a5.$$.fragment,c),C(rR.$$.fragment,c),C(m5.$$.fragment,c),C(tR.$$.fragment,c),C(aR.$$.fragment,c),C(sR.$$.fragment,c),C(f5.$$.fragment,c),C(lR.$$.fragment,c),C(v5.$$.fragment,c),C(iR.$$.fragment,c),C(dR.$$.fragment,c),C(cR.$$.fragment,c),C(T5.$$.fragment,c),C(fR.$$.fragment,c),C(C5.$$.fragment,c),C(gR.$$.fragment,c),C(hR.$$.fragment,c),C(pR.$$.fragment,c),C(A5.$$.fragment,c),C(_R.$$.fragment,c),C(R5.$$.fragment,c),C(bR.$$.fragment,c),C(vR.$$.fragment,c),C(TR.$$.fragment,c),C(B5.$$.fragment,c),C(MR.$$.fragment,c),C(q5.$$.fragment,c),C(ER.$$.fragment,c),C(CR.$$.fragment,c),C(AR.$$.fragment,c),C(D5.$$.fragment,c),C(LR.$$.fragment,c),C(V5.$$.fragment,c),C(yR.$$.fragment,c),C(xR.$$.fragment,c),C(kR.$$.fragment,c),C(z5.$$.fragment,c),C(SR.$$.fragment,c),C(H0.$$.fragment,c),C(RR.$$.fragment,c),C(PR.$$.fragment,c),C(IR.$$.fragment,c),C(Y0.$$.fragment,c),C(NR.$$.fragment,c),C(Tw.$$.fragment,c),C(qR.$$.fragment,c),C(jR.$$.fragment,c),C(GR.$$.fragment,c),C(Ew.$$.fragment,c),C(OR.$$.fragment,c),C(qw.$$.fragment,c),C(VR.$$.fragment,c),C(XR.$$.fragment,c),C(QR.$$.fragment,c),C(Dw.$$.fragment,c),C(WR.$$.fragment,c),C(Jw.$$.fragment,c),C(UR.$$.fragment,c),C(HR.$$.fragment,c),C(YR.$$.fragment,c),C(Zw.$$.fragment,c),C(ZR.$$.fragment,c),C(rA.$$.fragment,c),C(KR.$$.fragment,c),C(eP.$$.fragment,c),C(rP.$$.fragment,c),C(aA.$$.fragment,c),C(tP.$$.fragment,c),C(AA.$$.fragment,c),C(aP.$$.fragment,c),C(nP.$$.fragment,c),C(lP.$$.fragment,c),C(yA.$$.fragment,c),C(iP.$$.fragment,c),C(jA.$$.fragment,c),C(dP.$$.fragment,c),C(mP.$$.fragment,c),C(fP.$$.fragment,c),C(GA.$$.fragment,c),C(gP.$$.fragment,c),C(p6.$$.fragment,c),C(hP.$$.fragment,c),C(uP.$$.fragment,c),C(_P.$$.fragment,c),C(b6.$$.fragment,c),C(bP.$$.fragment,c),C(I6.$$.fragment,c),C(vP.$$.fragment,c),C(FP.$$.fragment,c),C(MP.$$.fragment,c),C(q6.$$.fragment,c),C(EP.$$.fragment,c),C(G6.$$.fragment,c),C(wP.$$.fragment,c),C(AP.$$.fragment,c),C(yP.$$.fragment,c),C(V6.$$.fragment,c),C(xP.$$.fragment,c),C(z6.$$.fragment,c),C($P.$$.fragment,c),C(kP.$$.fragment,c),C(RP.$$.fragment,c),C(W6.$$.fragment,c),C(PP.$$.fragment,c),C(H6.$$.fragment,c),C(BP.$$.fragment,c),C(IP.$$.fragment,c),C(qP.$$.fragment,c),C(Y6.$$.fragment,c),C(jP.$$.fragment,c),C(F7.$$.fragment,c),C(DP.$$.fragment,c),C(GP.$$.fragment,c),C(VP.$$.fragment,c),C(M7.$$.fragment,c),C(XP.$$.fragment,c),C(X7.$$.fragment,c),C(zP.$$.fragment,c),C(QP.$$.fragment,c),C(UP.$$.fragment,c),C(Q7.$$.fragment,c),C(HP.$$.fragment,c),C(U7.$$.fragment,c),C(JP.$$.fragment,c),C(YP.$$.fragment,c),C(KP.$$.fragment,c),C(J7.$$.fragment,c),C(eB.$$.fragment,c),C(K7.$$.fragment,c),C(rB.$$.fragment,c),C(tB.$$.fragment,c),C(nB.$$.fragment,c),C(o8.$$.fragment,c),C(sB.$$.fragment,c),C(x8.$$.fragment,c),C(lB.$$.fragment,c),C(iB.$$.fragment,c),C(mB.$$.fragment,c),C(k8.$$.fragment,c),C(cB.$$.fragment,c),C(O8.$$.fragment,c),C(fB.$$.fragment,c),C(gB.$$.fragment,c),C(uB.$$.fragment,c),C(X8.$$.fragment,c),C(pB.$$.fragment,c),C(aL.$$.fragment,c),C(_B.$$.fragment,c),C(bB.$$.fragment,c),C(FB.$$.fragment,c),C(sL.$$.fragment,c),C(TB.$$.fragment,c),C(_L.$$.fragment,c),C(MB.$$.fragment,c),C(EB.$$.fragment,c),C(wB.$$.fragment,c),C(vL.$$.fragment,c),C(AB.$$.fragment,c),C($L.$$.fragment,c),C(LB.$$.fragment,c),C(yB.$$.fragment,c),C($B.$$.fragment,c),C(SL.$$.fragment,c),C(kB.$$.fragment,c),C(VL.$$.fragment,c),C(SB.$$.fragment,c),C(RB.$$.fragment,c),C(BB.$$.fragment,c),C(zL.$$.fragment,c),C(IB.$$.fragment,c),C(ry.$$.fragment,c),C(NB.$$.fragment,c),C(qB.$$.fragment,c),C(DB.$$.fragment,c),C(ay.$$.fragment,c),C(GB.$$.fragment,c),C(gy.$$.fragment,c),C(OB.$$.fragment,c),C(VB.$$.fragment,c),C(zB.$$.fragment,c),C(uy.$$.fragment,c),C(QB.$$.fragment,c),C(Cy.$$.fragment,c),C(WB.$$.fragment,c),C(UB.$$.fragment,c),C(JB.$$.fragment,c),C(Ay.$$.fragment,c),C(YB.$$.fragment,c),C(yy.$$.fragment,c),C(ZB.$$.fragment,c),C(KB.$$.fragment,c),C(oI.$$.fragment,c),C($y.$$.fragment,c),C(rI.$$.fragment,c),C(Ry.$$.fragment,c),C(aI.$$.fragment,c),C(nI.$$.fragment,c),C(lI.$$.fragment,c),C(By.$$.fragment,c),C(iI.$$.fragment,c),C(Ny.$$.fragment,c),zso=!1},d(c){t(g),c&&t(v),c&&t(u),w(m),c&&t(Qf),c&&t(Tt),c&&t(Xe),c&&t(He),c&&t(Uf),w(on,c),c&&t(Je),c&&t(Ae),c&&t(ko),c&&t(rn),c&&t(yao),c&&t(Ad),w(E$),c&&t(xao),c&&t(hs),c&&t($ao),w(C$,c),c&&t(kao),c&&t(ON),c&&t(Sao),w(Yf,c),c&&t(Rao),c&&t(Ld),w(w$),c&&t(Pao),c&&t(So),w(A$),w(x$),w(yu),w($$),c&&t(Bao),c&&t(xd),w(k$),c&&t(Iao),c&&t(Ro),w(S$),w(B$),w(gp),w(I$),c&&t(Nao),c&&t($d),w(N$),c&&t(qao),c&&t(Po),w(q$),w(G$),w(l_),w(i_),w(O$),c&&t(jao),c&&t(kd),w(V$),c&&t(Dao),c&&t(Bo),w(X$),w(W$),w(P_),w(B_),w(U$),c&&t(Gao),c&&t(Rd),w(H$),c&&t(Oao),c&&t(Io),w(J$),w(Z$),w(q_),w(K$),w(ib),c&&t(Vao),c&&t(Id),w(ek),c&&t(Xao),c&&t(No),w(ok),w(tk),w(mb),w(ak),w(lv),c&&t(zao),c&&t(jd),w(nk),c&&t(Qao),c&&t(qo),w(sk),w(ik),w(dv),w(dk),w(eF),c&&t(Wao),c&&t(Od),w(mk),c&&t(Uao),c&&t(jo),w(ck),w(gk),w(rF),w(hk),w(sF),c&&t(Hao),c&&t(zd),w(pk),c&&t(Jao),c&&t(Do),w(_k),w(vk),w(iF),w(Fk),w(JF),c&&t(Yao),c&&t(Ud),w(Tk),c&&t(Zao),c&&t(Go),w(Mk),w(Ck),w(ZF),w(wk),w(FT),c&&t(Kao),c&&t(Yd),w(Ak),c&&t(eno),c&&t(Oo),w(Lk),w(xk),w(MT),w($k),w(LM),c&&t(ono),c&&t(em),w(kk),c&&t(rno),c&&t(Vo),w(Sk),w(Pk),w(xM),w(Bk),w(mE),c&&t(tno),c&&t(tm),w(Ik),c&&t(ano),c&&t(Xo),w(Nk),w(jk),w(fE),w(Dk),w(TE),c&&t(nno),c&&t(sm),w(Gk),c&&t(sno),c&&t(zo),w(Ok),w(Xk),w(EE),w(zk),w(g4),c&&t(lno),c&&t(dm),w(Qk),c&&t(ino),c&&t(Qo),w(Wk),w(Hk),w(u4),w(Jk),w(fC),c&&t(dno),c&&t(fm),w(Yk),c&&t(mno),c&&t(Wo),w(Zk),w(eS),w(hC),w(oS),w(_C),c&&t(cno),c&&t(um),w(rS),c&&t(fno),c&&t(Uo),w(tS),w(nS),w(vC),w(sS),w(CC),c&&t(gno),c&&t(vm),w(lS),c&&t(hno),c&&t(Ho),w(iS),w(mS),w(AC),w(cS),w(VC),c&&t(uno),c&&t(Mm),w(fS),c&&t(pno),c&&t(Jo),w(gS),w(uS),w(zC),w(pS),w(UC),c&&t(_no),c&&t(wm),w(_S),c&&t(bno),c&&t(Yo),w(bS),w(FS),w(JC),w(TS),w(KC),c&&t(vno),c&&t(ym),w(MS),c&&t(Fno),c&&t(Zo),w(ES),w(wS),w(o3),w(AS),w(a3),c&&t(Tno),c&&t(km),w(LS),c&&t(Mno),c&&t(Ko),w(yS),w($S),w(s3),w(kS),w(_3),c&&t(Eno),c&&t(Pm),w(SS),c&&t(Cno),c&&t(er),w(RS),w(BS),w(v3),w(IS),w(A3),c&&t(wno),c&&t(Nm),w(NS),c&&t(Ano),c&&t(or),w(qS),w(DS),w(y3),w(GS),w(D3),c&&t(Lno),c&&t(Dm),w(OS),c&&t(yno),c&&t(rr),w(VS),w(zS),w(O3),w(QS),w(W3),c&&t(xno),c&&t(Xm),w(WS),c&&t($no),c&&t(tr),w(US),w(JS),w(H3),w(YS),w(r5),c&&t(kno),c&&t(Wm),w(ZS),c&&t(Sno),c&&t(ar),w(KS),w(oR),w(a5),w(rR),w(m5),c&&t(Rno),c&&t(Jm),w(tR),c&&t(Pno),c&&t(nr),w(aR),w(sR),w(f5),w(lR),w(v5),c&&t(Bno),c&&t(Km),w(iR),c&&t(Ino),c&&t(sr),w(dR),w(cR),w(T5),w(fR),w(C5),c&&t(Nno),c&&t(rc),w(gR),c&&t(qno),c&&t(lr),w(hR),w(pR),w(A5),w(_R),w(R5),c&&t(jno),c&&t(nc),w(bR),c&&t(Dno),c&&t(ir),w(vR),w(TR),w(B5),w(MR),w(q5),c&&t(Gno),c&&t(ic),w(ER),c&&t(Ono),c&&t(dr),w(CR),w(AR),w(D5),w(LR),w(V5),c&&t(Vno),c&&t(cc),w(yR),c&&t(Xno),c&&t(mr),w(xR),w(kR),w(z5),w(SR),w(H0),c&&t(zno),c&&t(hc),w(RR),c&&t(Qno),c&&t(cr),w(PR),w(IR),w(Y0),w(NR),w(Tw),c&&t(Wno),c&&t(_c),w(qR),c&&t(Uno),c&&t(fr),w(jR),w(GR),w(Ew),w(OR),w(qw),c&&t(Hno),c&&t(Fc),w(VR),c&&t(Jno),c&&t(gr),w(XR),w(QR),w(Dw),w(WR),w(Jw),c&&t(Yno),c&&t(Ec),w(UR),c&&t(Zno),c&&t(hr),w(HR),w(YR),w(Zw),w(ZR),w(rA),c&&t(Kno),c&&t(Lc),w(KR),c&&t(eso),c&&t(ur),w(eP),w(rP),w(aA),w(tP),w(AA),c&&t(oso),c&&t($c),w(aP),c&&t(rso),c&&t(pr),w(nP),w(lP),w(yA),w(iP),w(jA),c&&t(tso),c&&t(Rc),w(dP),c&&t(aso),c&&t(_r),w(mP),w(fP),w(GA),w(gP),w(p6),c&&t(nso),c&&t(Ic),w(hP),c&&t(sso),c&&t(br),w(uP),w(_P),w(b6),w(bP),w(I6),c&&t(lso),c&&t(jc),w(vP),c&&t(iso),c&&t(vr),w(FP),w(MP),w(q6),w(EP),w(G6),c&&t(dso),c&&t(Oc),w(wP),c&&t(mso),c&&t(Fr),w(AP),w(yP),w(V6),w(xP),w(z6),c&&t(cso),c&&t(zc),w($P),c&&t(fso),c&&t(Tr),w(kP),w(RP),w(W6),w(PP),w(H6),c&&t(gso),c&&t(Uc),w(BP),c&&t(hso),c&&t(Mr),w(IP),w(qP),w(Y6),w(jP),w(F7),c&&t(uso),c&&t(Yc),w(DP),c&&t(pso),c&&t(Er),w(GP),w(VP),w(M7),w(XP),w(X7),c&&t(_so),c&&t(ef),w(zP),c&&t(bso),c&&t(Cr),w(QP),w(UP),w(Q7),w(HP),w(U7),c&&t(vso),c&&t(tf),w(JP),c&&t(Fso),c&&t(wr),w(YP),w(KP),w(J7),w(eB),w(K7),c&&t(Tso),c&&t(sf),w(rB),c&&t(Mso),c&&t(Ar),w(tB),w(nB),w(o8),w(sB),w(x8),c&&t(Eso),c&&t(mf),w(lB),c&&t(Cso),c&&t(Lr),w(iB),w(mB),w(k8),w(cB),w(O8),c&&t(wso),c&&t(gf),w(fB),c&&t(Aso),c&&t(yr),w(gB),w(uB),w(X8),w(pB),w(aL),c&&t(Lso),c&&t(pf),w(_B),c&&t(yso),c&&t(xr),w(bB),w(FB),w(sL),w(TB),w(_L),c&&t(xso),c&&t(vf),w(MB),c&&t($so),c&&t($r),w(EB),w(wB),w(vL),w(AB),w($L),c&&t(kso),c&&t(Mf),w(LB),c&&t(Sso),c&&t(kr),w(yB),w($B),w(SL),w(kB),w(VL),c&&t(Rso),c&&t(wf),w(SB),c&&t(Pso),c&&t(Sr),w(RB),w(BB),w(zL),w(IB),w(ry),c&&t(Bso),c&&t(yf),w(NB),c&&t(Iso),c&&t(Rr),w(qB),w(DB),w(ay),w(GB),w(gy),c&&t(Nso),c&&t(kf),w(OB),c&&t(qso),c&&t(Pr),w(VB),w(zB),w(uy),w(QB),w(Cy),c&&t(jso),c&&t(Pf),w(WB),c&&t(Dso),c&&t(Br),w(UB),w(JB),w(Ay),w(YB),w(yy),c&&t(Gso),c&&t(Nf),w(ZB),c&&t(Oso),c&&t(Ir),w(KB),w(oI),w($y),w(rI),w(Ry),c&&t(Vso),c&&t(Df),w(aI),c&&t(Xso),c&&t(Nr),w(nI),w(lI),w(By),w(iI),w(Ny)}}}const I6a={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForDepthEstimation",title:"AutoModelForDepthEstimation"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForDocumentQuestionAnswering",title:"AutoModelForDocumentQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVideoClassification",title:"AutoModelForVideoClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.AutoModelForZeroShotObjectDetection",title:"AutoModelForZeroShotObjectDetection"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForSemanticSegmentation",title:"TFAutoModelForSemanticSegmentation"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForDocumentQuestionAnswering",title:"TFAutoModelForDocumentQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function N6a($){return Ewa(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class X6a extends vwa{constructor(g){super();Fwa(this,g,N6a,B6a,Twa,{})}}export{X6a as default,I6a as metadata};
